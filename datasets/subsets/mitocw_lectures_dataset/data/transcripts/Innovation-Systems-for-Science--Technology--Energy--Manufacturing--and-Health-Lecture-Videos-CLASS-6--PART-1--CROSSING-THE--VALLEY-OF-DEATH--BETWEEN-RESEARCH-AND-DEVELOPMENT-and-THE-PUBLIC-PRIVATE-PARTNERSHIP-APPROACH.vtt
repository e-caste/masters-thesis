WEBVTT

00:00:00.090 --> 00:00:02.430
The following content is
provided under a Creative

00:00:02.430 --> 00:00:03.820
Commons license.

00:00:03.820 --> 00:00:06.030
Your support will help
MIT OpenCourseWare

00:00:06.030 --> 00:00:10.120
continue to offer high quality
educational resources for free.

00:00:10.120 --> 00:00:12.660
To make a donation or to
view additional materials

00:00:12.660 --> 00:00:16.620
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.620 --> 00:00:17.992
at ocw.mit.edu.

00:00:21.180 --> 00:00:22.680
WILLIAM BONVILLIAN:
So I just want

00:00:22.680 --> 00:00:24.840
to go back through
class five, because it's

00:00:24.840 --> 00:00:26.880
kind of foundational
for the ideas

00:00:26.880 --> 00:00:28.690
that come up in this class.

00:00:28.690 --> 00:00:35.940
So just very quickly, David Hart
taught us about the ideologies

00:00:35.940 --> 00:00:37.500
behind US innovation.

00:00:37.500 --> 00:00:41.280
And he takes a look at
really the 1920s ideology

00:00:41.280 --> 00:00:43.620
around science and
technology policy.

00:00:43.620 --> 00:00:50.970
And as we discussed, the
same debates are with us.

00:00:50.970 --> 00:00:55.380
And the leading theologies,
we could call them,

00:00:55.380 --> 00:00:58.980
are the associationalists,
which we would now

00:00:58.980 --> 00:01:03.870
translate as public-private
collaborations,

00:01:03.870 --> 00:01:08.350
versus conservative,
which, you know, there

00:01:08.350 --> 00:01:13.450
is no federal governmental role
except in the national security

00:01:13.450 --> 00:01:14.860
territory.

00:01:14.860 --> 00:01:17.380
And then the national
security rationale,

00:01:17.380 --> 00:01:21.160
which I would argue
is, do whatever

00:01:21.160 --> 00:01:26.710
it takes to establish national
security based technologies.

00:01:26.710 --> 00:01:31.270
These ideologies fit the US than
honestly fit other countries,

00:01:31.270 --> 00:01:33.550
but they are a significant
part of the story

00:01:33.550 --> 00:01:37.990
about how policy has evolved
in science and technology.

00:01:37.990 --> 00:01:42.610
Then we had a long
dissertation on Alfred Loomis

00:01:42.610 --> 00:01:45.940
and the beginning of
the Rad Lab at MIT,

00:01:45.940 --> 00:01:49.600
which we argued was really
a foundational model for how

00:01:49.600 --> 00:01:52.720
the US R&D system is
going to get organized.

00:01:52.720 --> 00:01:55.030
So that's taking
place right here,

00:01:55.030 --> 00:01:59.800
and Loomis really
designs a system

00:01:59.800 --> 00:02:09.580
that teaches us a lot about how
we're going to organize R&D.

00:02:09.580 --> 00:02:15.850
So flat, non-hierarchical, team
based, very cross disciplinary,

00:02:15.850 --> 00:02:19.840
collaborative, keep R&D
out of uniform and out

00:02:19.840 --> 00:02:22.780
of uniform bureaucracies.

00:02:22.780 --> 00:02:25.270
Keep it out of
the civil service.

00:02:25.270 --> 00:02:28.870
Create a kind of flat,
non-hierarchical system

00:02:28.870 --> 00:02:32.401
that enables maximum
exchange of ideas.

00:02:32.401 --> 00:02:35.110
Vannevar Bush at
the end of the war

00:02:35.110 --> 00:02:39.490
writes The Endless
Frontier, and that's

00:02:39.490 --> 00:02:42.040
the foundational
document for US R&D.

00:02:42.040 --> 00:02:44.530
And what he's concerned
about at the end of the war

00:02:44.530 --> 00:02:48.915
is salvaging some
federal role in science.

00:02:48.915 --> 00:02:50.290
So the growth of
the federal role

00:02:50.290 --> 00:02:54.350
in science in the course of
World War II was profound.

00:02:54.350 --> 00:03:00.830
As I mentioned in
class five, MIT

00:03:00.830 --> 00:03:02.948
receives 80 times
more federal funding

00:03:02.948 --> 00:03:04.490
in the course of
World War II than it

00:03:04.490 --> 00:03:06.740
does in all its previous
80 years of history.

00:03:06.740 --> 00:03:08.960
And that story is not unique.

00:03:08.960 --> 00:03:11.750
Other universities are having
comparable experiences.

00:03:11.750 --> 00:03:15.050
So that's when the federally
funded research university

00:03:15.050 --> 00:03:17.450
begins.

00:03:17.450 --> 00:03:19.490
And that's, obviously,
a foundational model

00:03:19.490 --> 00:03:21.560
in the US system.

00:03:21.560 --> 00:03:24.050
Vannevar Bush wants
to salvage it.

00:03:24.050 --> 00:03:29.930
So in the midst of a kind
of a huge rapid scale down

00:03:29.930 --> 00:03:33.050
to the defense establishment at
the end of World War II where

00:03:33.050 --> 00:03:37.670
everything is being canceled,
he works with Franklin Roosevelt

00:03:37.670 --> 00:03:42.160
to keep a federal
government research

00:03:42.160 --> 00:03:43.675
focus in basic research.

00:03:46.180 --> 00:03:50.020
Peter Singer reminded
us of how productive

00:03:50.020 --> 00:03:51.250
that system has been.

00:03:51.250 --> 00:03:55.120
So his paper on 22
examples of federal R&D

00:03:55.120 --> 00:04:01.630
that translated into
major technology sectors--

00:04:01.630 --> 00:04:07.300
so Peter argues
that that basic R&D

00:04:07.300 --> 00:04:11.770
model has, in fact,
yielded enormous technology

00:04:11.770 --> 00:04:12.880
development.

00:04:12.880 --> 00:04:14.620
That's not an easy
thing to trace.

00:04:14.620 --> 00:04:18.190
Waht are the originating
scientific advances

00:04:18.190 --> 00:04:21.140
in a 20 year project
towards technology advance,

00:04:21.140 --> 00:04:22.570
or perhaps longer.

00:04:22.570 --> 00:04:26.140
But Peter kind of did what we
called genealogical research

00:04:26.140 --> 00:04:28.870
to figure out what the
core elements were.

00:04:28.870 --> 00:04:30.550
But it's there.

00:04:30.550 --> 00:04:35.200
So it's not that Vannevar Bush's
basic research model in itself

00:04:35.200 --> 00:04:38.230
is bad or wrong.

00:04:38.230 --> 00:04:40.270
But it's an important one.

00:04:40.270 --> 00:04:43.120
And William Blanpied
told us the story of NSF.

00:04:43.120 --> 00:04:46.570
So the second Vannevar
Bush story is--

00:04:46.570 --> 00:04:48.770
story one is support
basic research.

00:04:48.770 --> 00:04:51.570
Story two, how are you
going to organize science

00:04:51.570 --> 00:04:52.820
in the federal government?

00:04:52.820 --> 00:04:58.640
And his vision was there
was going to be one tent.

00:04:58.640 --> 00:05:01.740
And science was going
to fit under one tent.

00:05:01.740 --> 00:05:04.080
You wouldn't have a
multitude of agencies.

00:05:04.080 --> 00:05:06.750
He was not successful in
pushing that argument, remember.

00:05:06.750 --> 00:05:11.850
Because Harry Truman vetoed the
National Science Foundation law

00:05:11.850 --> 00:05:14.240
that he proposed.

00:05:14.240 --> 00:05:16.650
Because Vannevar Bush
wanted scientists alone

00:05:16.650 --> 00:05:20.640
to control science and
left out a significant role

00:05:20.640 --> 00:05:22.810
for the executive branch.

00:05:22.810 --> 00:05:24.330
So it got vetoed.

00:05:24.330 --> 00:05:26.910
And therefore, NSF didn't
really get stood up

00:05:26.910 --> 00:05:28.030
for another five years.

00:05:28.030 --> 00:05:31.590
So other agencies
pop up in the void.

00:05:31.590 --> 00:05:33.220
So that, in turn, meant--

00:05:33.220 --> 00:05:34.980
this kind of funny
accident of time

00:05:34.980 --> 00:05:38.730
meant that the US was going
to have a very decentralized

00:05:38.730 --> 00:05:41.880
system of a multitude
of agencies working

00:05:41.880 --> 00:05:44.610
on science and research.

00:05:44.610 --> 00:05:47.940
That's how it happened.

00:05:47.940 --> 00:05:51.060
And Blanpied lays out
that debate for us.

00:05:51.060 --> 00:05:56.100
We then looked at Donald Stokes
as the kind of closing reading

00:05:56.100 --> 00:05:57.790
last week.

00:05:57.790 --> 00:05:59.930
And Stokes's book,
Pasteur's Quadrant

00:05:59.930 --> 00:06:04.430
is something of a classic in
the science policy literature.

00:06:04.430 --> 00:06:10.040
And Stokes argues that Vannevar
Bush saddled the country

00:06:10.040 --> 00:06:13.230
with a disconnected system.

00:06:13.230 --> 00:06:18.510
All very well and good, but
he missed a crucial quadrant.

00:06:18.510 --> 00:06:24.090
He missed the quadratic of
use-based fundamental research.

00:06:24.090 --> 00:06:27.640
In other words, you have an idea
about what you want to achieve.

00:06:27.640 --> 00:06:29.760
But you use basic
research to get there.

00:06:29.760 --> 00:06:32.970
He argues that
Pasteur's quadrant--

00:06:32.970 --> 00:06:36.690
because Pasteur is out to save
kids in France from bad milk,

00:06:36.690 --> 00:06:38.910
he knows what he wants.

00:06:38.910 --> 00:06:44.250
But he goes back and develops
microbiology to get there.

00:06:44.250 --> 00:06:47.550
So Stokes's argument
is Vannevar Bush

00:06:47.550 --> 00:06:51.240
focuses us on curiosity
driven basic research.

00:06:51.240 --> 00:06:56.210
He missed use-based
basic research.

00:06:56.210 --> 00:06:59.060
And that was a big
gap in the system.

00:06:59.060 --> 00:07:03.460
So what that meant in
the US was that we would

00:07:03.460 --> 00:07:05.500
be good at the basic research.

00:07:05.500 --> 00:07:07.580
We would have a
disconnected system.

00:07:07.580 --> 00:07:10.450
It would be hard to
do the implementation

00:07:10.450 --> 00:07:13.697
stages to achieve the
technology advances here.

00:07:13.697 --> 00:07:15.280
And we have seen
that again and again.

00:07:15.280 --> 00:07:19.540
The US would often originate
the foundational technologies.

00:07:19.540 --> 00:07:21.830
I was just working on
lithium ion batteries.

00:07:21.830 --> 00:07:24.510
A lot of those early
advances came out of the US.

00:07:24.510 --> 00:07:26.110
It was not commercialized here.

00:07:26.110 --> 00:07:32.720
So Vannevar Bush, of course,
understood connected science,

00:07:32.720 --> 00:07:36.500
because he created that in World
War II, a brilliantly connected

00:07:36.500 --> 00:07:37.168
model.

00:07:37.168 --> 00:07:38.960
I would argue that what
he was trying to do

00:07:38.960 --> 00:07:43.280
was salvage what he could
at the end of the war.

00:07:43.280 --> 00:07:47.120
But Stokes critiques
him essentially

00:07:47.120 --> 00:07:49.820
argues that we got a
disconnected system out

00:07:49.820 --> 00:07:51.110
of this.

00:07:51.110 --> 00:07:54.320
And that was very problematic
for the ability of the US

00:07:54.320 --> 00:07:58.400
to stand up subsequent follow
on technology advances.

00:07:58.400 --> 00:08:01.160
And we've seen that
again and again.

00:08:01.160 --> 00:08:06.950
So that's a look at some of
the foundational issues on how

00:08:06.950 --> 00:08:11.150
we organize science
and R&D in our system.

00:08:11.150 --> 00:08:16.640
And today, we're going to
take a really deep look

00:08:16.640 --> 00:08:20.670
at what we could call the
valley of death problem.

00:08:20.670 --> 00:08:22.680
In other words, it's
precisely this problem

00:08:22.680 --> 00:08:25.110
that Stokes talked
about, the disconnect

00:08:25.110 --> 00:08:30.270
between the research stage
and late stage development.

00:08:30.270 --> 00:08:32.120
And we're going to--

00:08:32.120 --> 00:08:33.679
the Branscomb and
Auerswald reading

00:08:33.679 --> 00:08:36.620
will lay that valley
of death problem out.

00:08:36.620 --> 00:08:39.409
And then we'll
talk about actually

00:08:39.409 --> 00:08:44.250
how the US is actually
on the side running

00:08:44.250 --> 00:08:48.380
all parallel universe of
much more connected defense

00:08:48.380 --> 00:08:49.830
research.

00:08:49.830 --> 00:08:51.850
It's a very different system.

00:08:51.850 --> 00:08:56.090
So we have two very
different innovation systems

00:08:56.090 --> 00:08:57.840
that the federal
government is supporting.

00:08:57.840 --> 00:08:59.490
And we'll go through
those two models.

00:09:02.230 --> 00:09:05.957
So who's got got Branscomb and
Auerswald, which of you three?

00:09:05.957 --> 00:09:06.790
Matthew, you got it?

00:09:06.790 --> 00:09:07.290
OK.

00:09:10.390 --> 00:09:15.100
That's Lew Branscomb, a noted
professor at the Kennedy

00:09:15.100 --> 00:09:18.460
School, now emeritus.

00:09:18.460 --> 00:09:21.150
He was vice president and
chief scientist at IBM.

00:09:21.150 --> 00:09:25.270
He was a director of NIST,
a noted physicist working

00:09:25.270 --> 00:09:28.300
in the atomic molecular fields.

00:09:28.300 --> 00:09:31.990
He won the National Science
Foundation's Vannevar Bush

00:09:31.990 --> 00:09:36.400
award, appropriately enough,
which is its top award.

00:09:36.400 --> 00:09:39.550
A remarkable and lovely and
wonderful guy, and a real kind

00:09:39.550 --> 00:09:45.160
of statesperson of science who
used to help young kids like me

00:09:45.160 --> 00:09:48.250
and help us learn the system.

00:09:48.250 --> 00:09:53.060
And his colleague,
Phil Auerswald,

00:09:53.060 --> 00:09:56.990
is now on his third
or fourth book,

00:09:56.990 --> 00:10:01.023
and has gone into the
field of innovation policy

00:10:01.023 --> 00:10:02.690
in a deep way, and
is a real contributor

00:10:02.690 --> 00:10:03.730
in that field as well.

00:10:03.730 --> 00:10:06.680
So Phil is a spokesman in
his own right at this point.

00:10:06.680 --> 00:10:08.360
He teaches at George
Mason University,

00:10:08.360 --> 00:10:11.810
which has a strong science
and technology policy group.

00:10:14.620 --> 00:10:16.510
So those are our authors.

00:10:16.510 --> 00:10:21.370
And let me just
go to the charts.

00:10:21.370 --> 00:10:24.880
This is a chart that was used
in the House Science Committee.

00:10:24.880 --> 00:10:28.580
And it wasn't-- the term,
valley of death, between, again,

00:10:28.580 --> 00:10:32.280
research and later
stage development--

00:10:32.280 --> 00:10:35.220
that wasn't a term that
Branscomb and Auerswald

00:10:35.220 --> 00:10:36.420
invented.

00:10:36.420 --> 00:10:39.600
It kind of came into
currency, however,

00:10:39.600 --> 00:10:42.870
in the time period in
which they're writing.

00:10:42.870 --> 00:10:46.350
And the idea here is--
it's a very simple one,

00:10:46.350 --> 00:10:49.350
that you've got one
set of institutions

00:10:49.350 --> 00:10:52.400
working on basic research.

00:10:52.400 --> 00:10:54.800
You've got another set
of institutions working

00:10:54.800 --> 00:11:00.670
on the later stage, applied
side, later stage development

00:11:00.670 --> 00:11:02.810
in particular.

00:11:02.810 --> 00:11:06.790
And there are very few bridging
mechanisms in our system

00:11:06.790 --> 00:11:10.190
across this gap between the two.

00:11:10.190 --> 00:11:16.790
So as we tried to understand
innovation 20 years ago,

00:11:16.790 --> 00:11:19.760
this was the major
idea in the system.

00:11:19.760 --> 00:11:22.030
And it comes right out
of Stokes's thinking.

00:11:22.030 --> 00:11:23.530
We're seeing this.

00:11:23.530 --> 00:11:26.770
And what's happening
at the time is

00:11:26.770 --> 00:11:32.490
that Japan has created this
brilliant quality manufacturing

00:11:32.490 --> 00:11:33.750
system.

00:11:33.750 --> 00:11:36.570
It amounts to a real
innovation wave in itself.

00:11:36.570 --> 00:11:39.750
The US misses it and
then loses leadership

00:11:39.750 --> 00:11:42.180
on two huge industrial
sectors, autos

00:11:42.180 --> 00:11:46.530
and consumer electronics as a
result of getting this wrong.

00:11:49.080 --> 00:11:54.280
So this is another
chart of the same thing.

00:11:54.280 --> 00:11:57.800
This is more of
a pipeline chart.

00:11:57.800 --> 00:12:02.277
And arguably, Vannevar Bush
set up the pipeline model

00:12:02.277 --> 00:12:03.860
where the federal
role was going to be

00:12:03.860 --> 00:12:09.380
dump basic research into the
end of this innovation pipeline.

00:12:09.380 --> 00:12:11.480
Mysterious things will occur.

00:12:11.480 --> 00:12:13.850
Great products will
emerge at the end.

00:12:13.850 --> 00:12:15.860
That's essentially the
organizational model

00:12:15.860 --> 00:12:19.430
for US civilian R&D.

00:12:19.430 --> 00:12:21.500
This is a way to
try and understand

00:12:21.500 --> 00:12:24.170
what's going on
within that pipeline

00:12:24.170 --> 00:12:28.340
and who the actors are that can
influence different stages, who

00:12:28.340 --> 00:12:30.380
can do the bridging.

00:12:30.380 --> 00:12:33.980
And what Branscomb and
Auerswald set out is--

00:12:33.980 --> 00:12:35.060
there's basic research.

00:12:35.060 --> 00:12:38.420
There's the proof of
concept invention stage.

00:12:38.420 --> 00:12:41.840
Then there's
technology development.

00:12:41.840 --> 00:12:44.120
Then you move on to product
development and production

00:12:44.120 --> 00:12:45.990
and marketing.

00:12:45.990 --> 00:12:48.385
And then helping at
these different stages

00:12:48.385 --> 00:12:49.260
are different actors.

00:12:49.260 --> 00:12:51.660
So the basic research
agency's here.

00:12:51.660 --> 00:12:55.110
And maybe they'll help you get
to the proof of concept stage.

00:12:55.110 --> 00:12:57.210
But they're not going
to reach beyond that.

00:12:57.210 --> 00:13:01.920
But then angel investors,
sometimes corporate allies,

00:13:01.920 --> 00:13:04.290
sometimes the small
business innovation research

00:13:04.290 --> 00:13:05.730
program that we've
talked about--

00:13:05.730 --> 00:13:09.360
that might help you
move from here to here.

00:13:09.360 --> 00:13:12.660
Venture capital, they
point out, doesn't really

00:13:12.660 --> 00:13:14.860
come to bear in this stage.

00:13:14.860 --> 00:13:17.670
Venture capital, as we talked
about in the first class,

00:13:17.670 --> 00:13:21.240
is really only interested in
supporting your technology

00:13:21.240 --> 00:13:25.020
if it's only about two years
away from actual production.

00:13:25.020 --> 00:13:26.970
So they're not
going to help you,

00:13:26.970 --> 00:13:30.120
by and large, with the
exception of the biotech area,

00:13:30.120 --> 00:13:34.590
bridge across this
kind of gap territory.

00:13:34.590 --> 00:13:37.440
When you get to here, there's
corporate venture, and equity,

00:13:37.440 --> 00:13:39.310
and commercial debt
that will help you.

00:13:39.310 --> 00:13:42.030
But they argue that this
is the gap in the system.

00:13:42.030 --> 00:13:47.620
But they also note,
it's not a pipeline.

00:13:47.620 --> 00:13:50.310
It's much more complicated.

00:13:50.310 --> 00:13:56.400
And in the end, they adopt
this phrase, a Darwinian sea

00:13:56.400 --> 00:13:58.500
between a struggle
for life and a sea

00:13:58.500 --> 00:14:01.380
of technical and
entrepreneurship risk.

00:14:01.380 --> 00:14:05.970
Because things don't move
smoothly down the pipeline.

00:14:05.970 --> 00:14:08.538
You'll get to proof
of concept stage

00:14:08.538 --> 00:14:10.080
and realize you've
got to rethink it.

00:14:10.080 --> 00:14:11.185
You go back here.

00:14:11.185 --> 00:14:12.810
And then maybe you
get to here and then

00:14:12.810 --> 00:14:14.910
you realize, well, I'm not
going to be able to get

00:14:14.910 --> 00:14:15.868
to product development.

00:14:15.868 --> 00:14:17.080
I've got to go back to there.

00:14:17.080 --> 00:14:19.530
In other words, it's a much
more convoluted process

00:14:19.530 --> 00:14:23.290
with a lot of iterations
and feedback in that system.

00:14:23.290 --> 00:14:27.297
So they argue, in the
end, it's more like this.

00:14:27.297 --> 00:14:29.130
The innovation and new
business on one side,

00:14:29.130 --> 00:14:31.200
research and invention
on the other,

00:14:31.200 --> 00:14:34.740
and this kind of struggle,
in a Darwinian sense,

00:14:34.740 --> 00:14:38.040
going on between the two.

00:14:38.040 --> 00:14:42.690
But frankly, a pipeline model
is much more convenient and easy

00:14:42.690 --> 00:14:44.550
to understand, even
though we should all

00:14:44.550 --> 00:14:49.230
know that it
overstates the model,

00:14:49.230 --> 00:14:51.210
that it's really more
like a Darwinian sea.

00:14:54.700 --> 00:14:57.640
And then they go through
what are the funding sources

00:14:57.640 --> 00:15:01.630
and note, really pretty
limited funding sources

00:15:01.630 --> 00:15:04.120
that are available
for that bridge

00:15:04.120 --> 00:15:05.290
over the valley of death.

00:15:05.290 --> 00:15:08.380
It's a pretty limited panoply.

00:15:08.380 --> 00:15:10.960
So why don't we
leave that there.

00:15:10.960 --> 00:15:14.730
And I'll turn it
over to you, Matthew.

00:15:14.730 --> 00:15:18.130
AUDIENCE: I think the summary
was pretty comprehensive.

00:15:18.130 --> 00:15:21.490
So I mean, most of the
questions that I had really

00:15:21.490 --> 00:15:24.640
focused on that stage theory,
that early stage technology

00:15:24.640 --> 00:15:26.140
development.

00:15:26.140 --> 00:15:27.820
As you could say,
it's the Darwinian sea

00:15:27.820 --> 00:15:29.410
or the valley of death.

00:15:29.410 --> 00:15:36.070
And one of the questions
I wanted to ask here

00:15:36.070 --> 00:15:39.460
was-- we saw a lot
previously about metrics

00:15:39.460 --> 00:15:42.660
to measure how much we're
putting into basic research.

00:15:42.660 --> 00:15:44.890
And then we also have all
the economic indicators

00:15:44.890 --> 00:15:47.230
on the other side.

00:15:47.230 --> 00:15:49.720
Right now, is there any
good way to measure just

00:15:49.720 --> 00:15:53.770
how effective a country
is at actually translating

00:15:53.770 --> 00:15:55.540
technologies that
are being developed

00:15:55.540 --> 00:15:58.170
into commercialized products?

00:16:08.500 --> 00:16:10.250
AUDIENCE: Could you
rephrase the question?

00:16:10.250 --> 00:16:11.610
AUDIENCE: Sure, yeah.

00:16:11.610 --> 00:16:17.650
So I mean, could you
imagine any good way to--

00:16:17.650 --> 00:16:21.095
or any good metric to measure
just how effective-- or would

00:16:21.095 --> 00:16:25.820
it even make sense to measure
how effective a country is

00:16:25.820 --> 00:16:28.870
kind of traversing
that valley of death?

00:16:28.870 --> 00:16:30.680
Because there's a lot
of metrics in terms

00:16:30.680 --> 00:16:34.530
of just how much we're spending
on one side on basic research.

00:16:34.530 --> 00:16:38.480
And then on the other side
you have economic indicators,

00:16:38.480 --> 00:16:39.535
productivity.

00:16:39.535 --> 00:16:40.910
AUDIENCE: Well,
one idea for that

00:16:40.910 --> 00:16:44.885
could be the sheer number of
startups that are produced,

00:16:44.885 --> 00:16:47.540
which was something that I
think one of the later readings

00:16:47.540 --> 00:16:48.700
had mentioned.

00:16:48.700 --> 00:16:50.995
Or you could just look at
the success rate of startups.

00:16:50.995 --> 00:16:52.370
So how long does
it take for them

00:16:52.370 --> 00:16:58.080
on average to foreclose, or just
to go bankrupt, or to just--

00:16:58.080 --> 00:17:00.680
how many of them do so?

00:17:00.680 --> 00:17:03.020
And how many of them are
able to actually produce

00:17:03.020 --> 00:17:03.920
a viable product?

00:17:03.920 --> 00:17:04.640
Et cetera.

00:17:04.640 --> 00:17:08.819
You could measure something
along the lines of that.

00:17:08.819 --> 00:17:14.040
AUDIENCE: Longevity
and percentage of--

00:17:14.040 --> 00:17:18.280
make it through first
year, five year, 10 year.

00:17:18.280 --> 00:17:20.280
AUDIENCE: And I think it
would be important also

00:17:20.280 --> 00:17:23.880
to measure how
much of that value

00:17:23.880 --> 00:17:25.880
you actually capture
as a country.

00:17:25.880 --> 00:17:27.839
You have countries
like Israel where

00:17:27.839 --> 00:17:29.760
you have tons and
tons of startups,

00:17:29.760 --> 00:17:31.543
but they all end up
getting exported.

00:17:31.543 --> 00:17:33.960
They don't stay in the country,
because all of the venture

00:17:33.960 --> 00:17:36.855
financing is in the US.

00:17:36.855 --> 00:17:39.230
WILLIAM BONVILLIAN: There's
another possible measure too,

00:17:39.230 --> 00:17:39.730
Matthew.

00:17:39.730 --> 00:17:41.640
It's probably on your list.

00:17:41.640 --> 00:17:43.710
Patents.

00:17:43.710 --> 00:17:49.170
And patents have to list
the scientific research

00:17:49.170 --> 00:17:51.448
on which they draw.

00:17:51.448 --> 00:17:53.490
So you can actually go
into the patent literature

00:17:53.490 --> 00:17:55.500
and understand the
scientific advances

00:17:55.500 --> 00:17:57.630
behind the patent application.

00:17:57.630 --> 00:18:01.260
But of course, many patents
sit completely unused.

00:18:01.260 --> 00:18:02.790
They go on the shelf.

00:18:02.790 --> 00:18:05.520
So it's just-- the
total number of patents

00:18:05.520 --> 00:18:07.870
doesn't necessarily
tell you much.

00:18:07.870 --> 00:18:10.020
AUDIENCE: Look at the
citations on the patents--

00:18:10.020 --> 00:18:11.937
WILLIAM BONVILLIAN: Yeah,
but it does tell you

00:18:11.937 --> 00:18:14.520
what the early stage research
was, often, that's behind them.

00:18:14.520 --> 00:18:17.040
And look, the amount
of early stage research

00:18:17.040 --> 00:18:20.730
that's being cited in
patent applications

00:18:20.730 --> 00:18:22.800
has been growing profoundly.

00:18:22.800 --> 00:18:25.770
So we know that some
of this research

00:18:25.770 --> 00:18:30.570
is getting out of the left
hand side of the pipeline

00:18:30.570 --> 00:18:32.820
out the end of it.

00:18:32.820 --> 00:18:36.217
So it's important
from that perspective.

00:18:41.090 --> 00:18:41.990
Other indicators?

00:18:47.678 --> 00:18:50.010
AUDIENCE: I think
there's also something

00:18:50.010 --> 00:18:54.090
to say for maybe the
economic impact per capita.

00:18:54.090 --> 00:18:57.510
Really assessing, how
much does the innovation

00:18:57.510 --> 00:19:01.290
end up impacting the
country's well-being?

00:19:01.290 --> 00:19:04.140
And how do individuals--
whether or not

00:19:04.140 --> 00:19:07.440
individuals benefit from it who
are regular citizens, rather

00:19:07.440 --> 00:19:10.068
than just the industry
capturing that profit.

00:19:10.068 --> 00:19:12.360
I think there's something to
be said about establishing

00:19:12.360 --> 00:19:16.080
a metric for impact as well
that's based specifically

00:19:16.080 --> 00:19:18.900
on per capita or
per citizen in order

00:19:18.900 --> 00:19:21.660
to make it sort of
comparable to other countries

00:19:21.660 --> 00:19:24.820
and the resources that they
have available to them or not.

00:19:24.820 --> 00:19:26.820
AUDIENCE: So you're saying
non-monetary results.

00:19:26.820 --> 00:19:29.730
AUDIENCE: No, I think they
can be monetary results too.

00:19:29.730 --> 00:19:31.410
I mean, the
regression analysis is

00:19:31.410 --> 00:19:32.950
going to be more complicated.

00:19:32.950 --> 00:19:35.310
But I feel like if you do
measures of well-being,

00:19:35.310 --> 00:19:38.250
both on economic impact
and also on well-being sort

00:19:38.250 --> 00:19:40.437
of statistical measurements
on, say, like--

00:19:40.437 --> 00:19:42.270
I mean, I know people
measure happiness now.

00:19:42.270 --> 00:19:43.860
That could be a really
interesting impact.

00:19:43.860 --> 00:19:45.390
And I know that
you could do that--

00:19:45.390 --> 00:19:49.170
for example, when we need
biotech, the people who you're

00:19:49.170 --> 00:19:51.180
impacting, do they
feel like their lives

00:19:51.180 --> 00:19:53.220
any better as a result
of your invention,

00:19:53.220 --> 00:19:58.045
in addition to the economic
benefits of your advance.

00:19:58.045 --> 00:19:59.490
AUDIENCE: Yeah, I would say no.

00:19:59.490 --> 00:20:00.948
I think it was
polio, that somebody

00:20:00.948 --> 00:20:03.078
discovered it, and then
just kind of gave it away.

00:20:03.078 --> 00:20:04.120
So that has a big impact.

00:20:04.120 --> 00:20:07.530
You make a lot of money, but it
was important to [INAUDIBLE]..

00:20:07.530 --> 00:20:09.390
WILLIAM BONVILLIAN:
The issue here

00:20:09.390 --> 00:20:12.750
is that often that
social impact is

00:20:12.750 --> 00:20:17.460
going to take a very long
time to evolve at scale.

00:20:17.460 --> 00:20:23.480
So if you're willing to take
a long-term look to reach

00:20:23.480 --> 00:20:26.210
a level of a
reasonable assessment,

00:20:26.210 --> 00:20:28.442
it's going to be a
very extended period.

00:20:28.442 --> 00:20:30.397
AUDIENCE: It's such
a difficult metric.

00:20:30.397 --> 00:20:32.730
AUDIENCE: What metric do you
have for measuring it, too?

00:20:32.730 --> 00:20:35.760
Because you can say, oh, I
have x amount of Apple stock,

00:20:35.760 --> 00:20:37.570
and I've made x
amount of dollars.

00:20:37.570 --> 00:20:41.600
And that's improved my
assets over this many years.

00:20:41.600 --> 00:20:44.280
WILLIAM BONVILLIAN: Well, you're
driving at its societal impact,

00:20:44.280 --> 00:20:44.850
right?

00:20:44.850 --> 00:20:45.780
AUDIENCE: But then
how do you measure--

00:20:45.780 --> 00:20:46.950
AUDIENCE: But it could
also be specifically

00:20:46.950 --> 00:20:47.910
in technical advances.

00:20:47.910 --> 00:20:50.670
Like I wouldn't say
necessarily, from an investment

00:20:50.670 --> 00:20:54.300
standpoint, that I
would care so much

00:20:54.300 --> 00:20:57.180
about the happiness of the
stakeholder or the shareholder,

00:20:57.180 --> 00:20:58.530
specifically.

00:20:58.530 --> 00:21:00.240
AUDIENCE: But I
was going to go on

00:21:00.240 --> 00:21:02.210
to say, how do I
measure how much this

00:21:02.210 --> 00:21:05.340
has improved my
life, when you get

00:21:05.340 --> 00:21:08.295
into issues with measurement.

00:21:08.295 --> 00:21:09.750
It's complicated.

00:21:09.750 --> 00:21:11.760
AUDIENCE: When it
comes to a measurement,

00:21:11.760 --> 00:21:14.095
like you can have the best
invention, but you don't win.

00:21:14.095 --> 00:21:14.970
You know what I mean?

00:21:14.970 --> 00:21:16.810
Like you can come up with
something that's really great,

00:21:16.810 --> 00:21:19.410
but if you're not a great
executioner-- like for Fitbit,

00:21:19.410 --> 00:21:22.080
I met the guy who now
works for Google X,

00:21:22.080 --> 00:21:24.350
and he created the
Fitbit, but way better

00:21:24.350 --> 00:21:25.593
and had way more customers.

00:21:25.593 --> 00:21:27.510
But because he didn't
raise a round of funding

00:21:27.510 --> 00:21:29.520
before the economic
collapse, the product

00:21:29.520 --> 00:21:30.660
never got to market.

00:21:30.660 --> 00:21:33.110
So it might just
be chance, right?

00:21:33.110 --> 00:21:35.825
So Darwinian sea
is a good example.

00:21:35.825 --> 00:21:37.200
Your research can
be really good.

00:21:37.200 --> 00:21:38.070
It can be really compelling.

00:21:38.070 --> 00:21:39.000
You can be a great team.

00:21:39.000 --> 00:21:40.320
But there's a lot
of other factors

00:21:40.320 --> 00:21:42.778
that we don't take into account,
a lot of hidden variables.

00:21:45.457 --> 00:21:47.790
WILLIAM BONVILLIAN: How about
another question, Matthew?

00:21:47.790 --> 00:21:49.840
MATTHEW: Yeah,
actually one thing

00:21:49.840 --> 00:21:53.970
that kind of a lot of
people caught on to was--

00:21:53.970 --> 00:22:00.070
so Branscomb and Auerswald, they
detail three main challenges

00:22:00.070 --> 00:22:01.540
to crossing the Valley of Death.

00:22:01.540 --> 00:22:06.700
And the three challenges were
motivation on the R&D side,

00:22:06.700 --> 00:22:11.560
to reducing that to practice,
trust between the technologist

00:22:11.560 --> 00:22:13.210
and the business manager.

00:22:13.210 --> 00:22:15.400
And then the third
is the sources

00:22:15.400 --> 00:22:19.030
of funding for entrepreneurs.

00:22:19.030 --> 00:22:22.660
And focusing in on that
trust or understanding even

00:22:22.660 --> 00:22:24.910
between the technologist
and the business manager,

00:22:24.910 --> 00:22:28.960
someone asked, is there
value in maybe changing

00:22:28.960 --> 00:22:32.530
the way we educate
people, or having

00:22:32.530 --> 00:22:37.070
more joint technology
in business degrees

00:22:37.070 --> 00:22:39.800
or courses of study to
help bridge that gap?

00:22:48.985 --> 00:22:51.110
WILLIAM BONVILLIAN: Matthew,
I can give you a hint.

00:22:51.110 --> 00:22:55.820
You can ask the person who
wrote the question to respond.

00:22:55.820 --> 00:23:00.168
MATTHEW: He's double major, or--

00:23:00.168 --> 00:23:02.210
WILLIAM BONVILLIAN: No,
which one of the students

00:23:02.210 --> 00:23:04.010
who wrote the question
that you're drawing on,

00:23:04.010 --> 00:23:04.885
you can call on them.

00:23:04.885 --> 00:23:06.388
AUDIENCE: It was a lot at once.

00:23:06.388 --> 00:23:07.680
WILLIAM BONVILLIAN: It was you?

00:23:07.680 --> 00:23:09.020
AUDIENCE: So if you have
an answer, just like,

00:23:09.020 --> 00:23:10.050
it was a lot at once.

00:23:10.050 --> 00:23:12.175
MATTHEW: Yeah, so what do
you think the value would

00:23:12.175 --> 00:23:16.460
be in maybe restructuring
the way we do education

00:23:16.460 --> 00:23:19.590
or offering more
interdisciplinary

00:23:19.590 --> 00:23:23.000
degrees in maybe, say, science
or engineering and business

00:23:23.000 --> 00:23:25.530
to help bridge that gap?

00:23:25.530 --> 00:23:28.150
AUDIENCE: I would look into
the top most successful

00:23:28.150 --> 00:23:29.150
technologists right now.

00:23:29.150 --> 00:23:31.970
So like Zuckerberg was
psychology and computer

00:23:31.970 --> 00:23:33.800
science.

00:23:33.800 --> 00:23:37.880
I think Larry Ellison,
he was medicine,

00:23:37.880 --> 00:23:40.610
but then he switched and
then went to Silicon Valley.

00:23:40.610 --> 00:23:43.250
Elon Musk was
economics and physics.

00:23:43.250 --> 00:23:46.430
So I don't know if
that's a good answer.

00:23:46.430 --> 00:23:48.950
AUDIENCE: So frankly, I'd
say you're in support of it,

00:23:48.950 --> 00:23:51.080
because a lot of these
people that were successful.

00:23:51.080 --> 00:23:53.600
Of course, correlation
does not imply causation.

00:23:53.600 --> 00:23:57.955
So just because Mark
Zuckerberg happened

00:23:57.955 --> 00:23:59.580
to use computer
science and psychology,

00:23:59.580 --> 00:24:00.670
it doesn't mean that--

00:24:00.670 --> 00:24:02.587
AUDIENCE: But I was
trying to-- the education,

00:24:02.587 --> 00:24:05.010
in terms, like, has there
a bit a really, really

00:24:05.010 --> 00:24:12.310
great technologist who was just
pure science, or like just one?

00:24:12.310 --> 00:24:14.660
AUDIENCE: Maybe 100 years ago.

00:24:14.660 --> 00:24:16.617
AUDIENCE: I think during
the transistor era,

00:24:16.617 --> 00:24:18.200
there was a lot of
great technologists

00:24:18.200 --> 00:24:22.115
that could execute well,
like Bardeen, Shockley.

00:24:22.115 --> 00:24:23.615
And then that's
where Intel started.

00:24:23.615 --> 00:24:25.760
AUDIENCE: Well, I don't
know about Shockley.

00:24:25.760 --> 00:24:27.510
AUDIENCE: Yeah, he
didn't take the credit,

00:24:27.510 --> 00:24:28.835
but he was still there.

00:24:28.835 --> 00:24:30.960
WILLIAM BONVILLIAN: Well,
that's next week's story,

00:24:30.960 --> 00:24:32.450
or two weeks from now story.

00:24:32.450 --> 00:24:34.310
No, next week-- right, sorry.

00:24:34.310 --> 00:24:36.110
Luyao, you asked that question?

00:24:36.110 --> 00:24:37.270
So do you want to oppose?

00:24:37.270 --> 00:24:39.430
Do you want to give us an
answer or your thoughts?

00:24:39.430 --> 00:24:41.570
AUDIENCE: Like to me, I
realize the American system

00:24:41.570 --> 00:24:43.670
is more flexible and
allows you to take

00:24:43.670 --> 00:24:45.950
cross-disciplinary course.

00:24:45.950 --> 00:24:47.540
But from my home
university, like

00:24:47.540 --> 00:24:51.000
England has really
kind of narrowed

00:24:51.000 --> 00:24:52.730
choices for each student.

00:24:52.730 --> 00:24:57.410
So you see less students
choose a double degree

00:24:57.410 --> 00:24:59.880
or double major courses.

00:24:59.880 --> 00:25:02.690
I do think that plays
an important role

00:25:02.690 --> 00:25:08.850
in the development of
innovations in the States.

00:25:08.850 --> 00:25:12.190
This is a cross-country
comparison.

00:25:12.190 --> 00:25:13.690
WILLIAM BONVILLIAN:
As you all know,

00:25:13.690 --> 00:25:15.420
there's lots of MIT
students who are

00:25:15.420 --> 00:25:19.770
doing business minors and
engineering or science degrees,

00:25:19.770 --> 00:25:23.310
and lots of
entrepreneurship courses

00:25:23.310 --> 00:25:27.040
that people from both
sides are taking.

00:25:27.040 --> 00:25:32.045
So I think it's a development
that's starting to occur.

00:25:32.045 --> 00:25:34.170
Matthew, do you have a
closing thought on Branscomb

00:25:34.170 --> 00:25:37.110
and Auerswald for us?

00:25:37.110 --> 00:25:38.750
MATTHEW: I can give a personal--

00:25:38.750 --> 00:25:40.052
WILLIAM BONVILLIAN: Please.

00:25:40.052 --> 00:25:42.010
MATTHEW: I actually am
a mechanical engineering

00:25:42.010 --> 00:25:44.510
and business minor.

00:25:44.510 --> 00:25:47.190
And I do think it's
really valuable.

00:25:47.190 --> 00:25:49.920
At the same time, I
think specialization

00:25:49.920 --> 00:25:52.890
is important to
keep, because I know

00:25:52.890 --> 00:25:56.460
I'll never take as in-depth
mechanical engineering classes

00:25:56.460 --> 00:25:57.990
as people who are
just that studying

00:25:57.990 --> 00:25:59.860
that throughout their
four years here.

00:25:59.860 --> 00:26:01.980
But I do think
having more people

00:26:01.980 --> 00:26:07.440
with interdisciplinary degrees
can help transition that gap.

00:26:07.440 --> 00:26:09.660
WILLIAM BONVILLIAN:
Great, thank you.

00:26:09.660 --> 00:26:12.210
All right, so we're going to
push along to our next reading

00:26:12.210 --> 00:26:14.340
here.

00:26:14.340 --> 00:26:20.550
And Vernon Ruttan is another one
of our great growth economists.

00:26:20.550 --> 00:26:23.140
Ruttan taught at the
University of Minnesota.

00:26:23.140 --> 00:26:30.930
And he really develops the whole
concept of induced innovation.

00:26:30.930 --> 00:26:33.600
In other words, how
does industry innovate,

00:26:33.600 --> 00:26:35.310
is really the problem
he's looking at.

00:26:35.310 --> 00:26:37.770
Obviously, it's not just
government agencies for sure.

00:26:37.770 --> 00:26:40.300
Industry does the great
bulk of the innovation.

00:26:40.300 --> 00:26:44.710
So he studies induced innovation
through his whole career,

00:26:44.710 --> 00:26:49.080
and develops a whole set of
thinking about that doctrine.

00:26:49.080 --> 00:26:53.100
And then towards
the end of his life,

00:26:53.100 --> 00:26:56.550
because he dies only a couple of
years after writing this book,

00:26:56.550 --> 00:27:02.500
he goes back and looks at the
Defense Innovation system.

00:27:02.500 --> 00:27:05.910
So he's looking at
where these big strands

00:27:05.910 --> 00:27:11.700
of the American economy come
from, things like aviation,

00:27:11.700 --> 00:27:19.720
space, electronics, nuclear
power, computing, the internet.

00:27:19.720 --> 00:27:22.220
And I wouldn't say
he stumbles, but he

00:27:22.220 --> 00:27:25.970
focuses on the Defense
Innovation system,

00:27:25.970 --> 00:27:29.880
and starts to lay out
for us what that's like.

00:27:29.880 --> 00:27:32.900
So we've just talked about the
Vannevar Bush basic research

00:27:32.900 --> 00:27:36.470
only, peer-reviewed,
basic science agency

00:27:36.470 --> 00:27:39.530
model that we tend to
think of when we think

00:27:39.530 --> 00:27:42.170
about US R&D. That's
the dominant model,

00:27:42.170 --> 00:27:44.330
certainly on the civilian side.

00:27:44.330 --> 00:27:47.060
But then there's this
whole parallel universe

00:27:47.060 --> 00:27:50.330
that's organized in
a very different way.

00:27:50.330 --> 00:27:53.630
And he goes back and
traces the history,

00:27:53.630 --> 00:27:56.570
and has this very
provocative title--

00:27:56.570 --> 00:27:59.240
Is War Necessary
for Economic Growth?

00:27:59.240 --> 00:28:03.650
Because the big innovation
waves of the latter part

00:28:03.650 --> 00:28:07.580
of the 20th century,
frankly, came out

00:28:07.580 --> 00:28:11.330
of that Defense
Innovation system.

00:28:11.330 --> 00:28:13.790
Those are the big ways
that I just listed.

00:28:13.790 --> 00:28:17.000
So what's going on here?

00:28:17.000 --> 00:28:23.290
And Ruttan tells a very
interesting story that--

00:28:23.290 --> 00:28:24.550
this didn't happen yesterday.

00:28:24.550 --> 00:28:26.092
He tells the story
of the development

00:28:26.092 --> 00:28:29.380
of interchangeable machine-made
parts, which, as you all know,

00:28:29.380 --> 00:28:33.235
is the core initial step
towards mass production.

00:28:33.235 --> 00:28:35.110
And that gets developed
in the United States.

00:28:35.110 --> 00:28:38.440
And how does it get developed?

00:28:38.440 --> 00:28:41.590
It gets developed by
the War Department.

00:28:41.590 --> 00:28:44.530
And the War Department
is, essentially--

00:28:44.530 --> 00:28:49.390
you think of the
early 19th century,

00:28:49.390 --> 00:28:52.790
muskets are made by hand.

00:28:52.790 --> 00:28:55.210
They're made by blacksmiths.

00:28:55.210 --> 00:28:57.070
Armorers they were called.

00:28:57.070 --> 00:29:01.960
And every army had to bring
along a whole group of armorers

00:29:01.960 --> 00:29:04.810
to constantly keep
its muskets repaired.

00:29:04.810 --> 00:29:07.268
And every time a part
would break down,

00:29:07.268 --> 00:29:08.560
they'd have to make a new part.

00:29:08.560 --> 00:29:11.110
So they'd have to pull out
their forge and their anvils

00:29:11.110 --> 00:29:14.620
and their hammers, and then
model that part exactly

00:29:14.620 --> 00:29:16.300
so it would actually fit.

00:29:16.300 --> 00:29:18.760
Because no two
parts were the same.

00:29:18.760 --> 00:29:21.110
They were not interchangeable.

00:29:21.110 --> 00:29:25.620
So Eli Whitney has a vision for
interchangeable machine-made

00:29:25.620 --> 00:29:26.120
parts.

00:29:26.120 --> 00:29:27.900
Why Eli Whitney?

00:29:27.900 --> 00:29:29.650
You've heard of the
cotton gin, of course,

00:29:29.650 --> 00:29:34.030
one of the key early 19th
century simple machines

00:29:34.030 --> 00:29:37.570
that launched the industrial
economy in the United States.

00:29:37.570 --> 00:29:42.300
But Whitney's got a big
problem with the cotton gin.

00:29:42.300 --> 00:29:43.200
Anybody can make one.

00:29:43.200 --> 00:29:47.220
You can see this thing,
and any decent mechanic

00:29:47.220 --> 00:29:50.190
all over the country could
essentially replicate it.

00:29:50.190 --> 00:29:53.940
So he's faced with
massive patent violations.

00:29:53.940 --> 00:29:56.110
And he's handling lawsuits
all over the country.

00:29:56.110 --> 00:29:57.480
He can't manage this.

00:29:57.480 --> 00:30:01.440
So he has this
remarkable invention,

00:30:01.440 --> 00:30:03.780
but he can't capture
any revenue off it.

00:30:03.780 --> 00:30:09.940
So being a good US
industrialist, what do you do?

00:30:09.940 --> 00:30:13.780
The War Department bailout,
that's what you do, right?

00:30:13.780 --> 00:30:17.830
So he goes to his friends
and colleagues in the War

00:30:17.830 --> 00:30:20.095
Department and
paints this vision.

00:30:23.240 --> 00:30:25.900
Why make muskets by hand?

00:30:25.900 --> 00:30:29.370
I'll give you interchangeable
machine-made parts.

00:30:29.370 --> 00:30:32.590
We'll drive the costs
through the floor.

00:30:32.590 --> 00:30:36.190
And you won't have to have
these armor trains dragging down

00:30:36.190 --> 00:30:38.500
the speed of your armies.

00:30:38.500 --> 00:30:41.350
We'll just have a bunch
of parts in boxes.

00:30:41.350 --> 00:30:44.690
And you'll just snap them in,
and they'll be interchangeable.

00:30:44.690 --> 00:30:49.545
It's a wonderful vision, and he
sells it to the War Department.

00:30:49.545 --> 00:30:50.170
And guess what?

00:30:50.170 --> 00:30:51.820
He gets something
that's the equivalent

00:30:51.820 --> 00:30:56.020
of a cost-plus contract,
every industrialist's dream.

00:30:56.020 --> 00:30:59.770
Whatever you need
to spend, spend it.

00:30:59.770 --> 00:31:02.340
It's consistent with
our contract terms.

00:31:02.340 --> 00:31:06.580
So he turns his factory in North
Haven, Connecticut, just north

00:31:06.580 --> 00:31:10.990
of New Haven, into
an attempt to develop

00:31:10.990 --> 00:31:12.460
interchangeable
machine-made parts.

00:31:12.460 --> 00:31:15.040
He doesn't quite get there.

00:31:15.040 --> 00:31:17.590
This requires really creating
the whole first generation

00:31:17.590 --> 00:31:20.100
of machine tools.

00:31:20.100 --> 00:31:21.900
And he isn't quite
able to pull it off.

00:31:21.900 --> 00:31:25.290
You have a whole new way
of organizing the workforce

00:31:25.290 --> 00:31:28.560
around division of labor and
around specific differentiated

00:31:28.560 --> 00:31:30.390
tasks for the workforce.

00:31:30.390 --> 00:31:33.450
So it carries all kinds of
organizational implications

00:31:33.450 --> 00:31:37.940
with it, so that each
part of the labor force

00:31:37.940 --> 00:31:41.150
is mastering one set of tasks
related to a production system.

00:31:41.150 --> 00:31:43.310
All these things are
starting to happen

00:31:43.310 --> 00:31:46.780
in that North Haven
facility of his.

00:31:46.780 --> 00:31:49.348
And there's now a
museum setting that's

00:31:49.348 --> 00:31:51.890
around this, so you can go tramp
the sites where all this was

00:31:51.890 --> 00:31:54.050
happening in North Haven.

00:31:54.050 --> 00:31:55.460
But he doesn't
quite pull it off.

00:31:55.460 --> 00:32:01.910
But meanwhile,
there's two armories,

00:32:01.910 --> 00:32:05.270
one in Harpers
Ferry, West Virginia,

00:32:05.270 --> 00:32:08.540
and the other in
Springfield, Massachusetts.

00:32:08.540 --> 00:32:13.430
And these armories are
pursuing the same project,

00:32:13.430 --> 00:32:16.790
because it's so key
to the War Department.

00:32:16.790 --> 00:32:19.130
It's an absolutely critical
technology capability

00:32:19.130 --> 00:32:21.530
the War Department needs.

00:32:21.530 --> 00:32:25.460
And the story that
Ruttan picks up

00:32:25.460 --> 00:32:30.770
is the story of John Hall, who
runs the Harpers Ferry arsenal.

00:32:30.770 --> 00:32:35.830
And over an extended period of
time, over many, many years,

00:32:35.830 --> 00:32:40.780
he eventually perfects
the machine tools

00:32:40.780 --> 00:32:43.810
that will enable the creation
of these interchangeable

00:32:43.810 --> 00:32:46.210
machine-made parts.

00:32:46.210 --> 00:32:49.550
And it's a remarkable story.

00:32:49.550 --> 00:32:55.810
And only the long-term
patience and capital

00:32:55.810 --> 00:32:59.050
of a government agency
is going to tolerate

00:32:59.050 --> 00:33:00.685
this kind of 20-year project.

00:33:04.130 --> 00:33:07.540
Interesting, the
minute he gets it done,

00:33:07.540 --> 00:33:11.740
other industrialists understand
what the accomplishment is.

00:33:11.740 --> 00:33:17.880
So Congress forces
Hall and the Army

00:33:17.880 --> 00:33:20.790
to throw the patent
essentially into the commons

00:33:20.790 --> 00:33:22.830
and be accessible to others.

00:33:22.830 --> 00:33:27.960
So that stands up the whole
early industrial economy

00:33:27.960 --> 00:33:31.380
of New England, building
these simple machines.

00:33:31.380 --> 00:33:33.720
So you can go to
Connecticut towns,

00:33:33.720 --> 00:33:36.420
Massachusetts towns,
which are blessed

00:33:36.420 --> 00:33:39.550
with fairly small,
slow-moving water power,

00:33:39.550 --> 00:33:43.350
because that's the power source,
that moves fairly steadily.

00:33:43.350 --> 00:33:44.460
It doesn't flood a lot.

00:33:44.460 --> 00:33:50.820
This is an ideal region
for water-powered energy

00:33:50.820 --> 00:33:53.864
do the building here
to power the mills.

00:33:53.864 --> 00:33:57.690
AUDIENCE: So you said
John Hall goes and makes

00:33:57.690 --> 00:34:00.803
the patents open to the public?

00:34:00.803 --> 00:34:02.720
WILLIAM BONVILLIAN: Well,
the Congress force--

00:34:02.720 --> 00:34:06.970
Congress passes legislation
that precludes the Army and Hall

00:34:06.970 --> 00:34:07.970
from having the patents.

00:34:07.970 --> 00:34:10.489
In effect, they make
them available to others.

00:34:10.489 --> 00:34:12.383
That turns out to
be of great benefit,

00:34:12.383 --> 00:34:14.300
because then this
interchangeable machine-made

00:34:14.300 --> 00:34:16.694
parts model can get
picked up by everybody.

00:34:16.694 --> 00:34:19.194
AUDIENCE: I guess it would be
a huge benefit of the country.

00:34:19.194 --> 00:34:21.739
But then people like
John Hall, doesn't it

00:34:21.739 --> 00:34:24.170
give them a pretty strong
incentive not to do something

00:34:24.170 --> 00:34:24.380
like that?

00:34:24.380 --> 00:34:25.520
WILLIAM BONVILLIAN: Yes,
it would give someone

00:34:25.520 --> 00:34:27.440
a pretty strong
incentive not to spend

00:34:27.440 --> 00:34:30.123
20 years of their lives
working on this stuff, yes.

00:34:30.123 --> 00:34:32.040
But of course, he is
working for the military.

00:34:32.040 --> 00:34:36.600
So it's not as if he would
capitalize alone on this.

00:34:36.600 --> 00:34:38.949
But overall, it's a positive.

00:34:38.949 --> 00:34:42.280
And the power of those
New England companies

00:34:42.280 --> 00:34:44.530
to get their
congressional delegation

00:34:44.530 --> 00:34:47.520
to kind of take that
patent away and put it out,

00:34:47.520 --> 00:34:49.389
it's an important
political lesson.

00:34:49.389 --> 00:34:51.820
It was just too valuable
for the Army to own it.

00:34:54.429 --> 00:34:58.870
So this creates the
Connecticut River Valley

00:34:58.870 --> 00:35:01.570
of all these small,
simple machine industries.

00:35:01.570 --> 00:35:04.330
Clocks are famous
in New England.

00:35:04.330 --> 00:35:08.740
Muskets are famous up and down
the Connecticut River Valley.

00:35:08.740 --> 00:35:12.430
All these kind of early fairly
simple machines get built here,

00:35:12.430 --> 00:35:15.610
and that's the New England
industrial economy.

00:35:15.610 --> 00:35:18.550
That is the first place
the US to really--

00:35:18.550 --> 00:35:20.680
obviously textiles are
developing in parallel,

00:35:20.680 --> 00:35:22.330
including in Massachusetts.

00:35:22.330 --> 00:35:24.940
But this system of
other hard technologies

00:35:24.940 --> 00:35:28.990
and simpler machines starts to
take off pretty explosively.

00:35:28.990 --> 00:35:34.000
So the lesson here that
Ruttan is pointing us towards

00:35:34.000 --> 00:35:37.180
is how the military can
operate and the private sector

00:35:37.180 --> 00:35:38.020
can't operate.

00:35:38.020 --> 00:35:42.910
The military is willing to take
a couple of decades-long effort

00:35:42.910 --> 00:35:46.750
and spend whatever is needed to
get that technology perfected,

00:35:46.750 --> 00:35:48.640
because they really need it.

00:35:48.640 --> 00:35:51.370
Those risks are too
high and the cost

00:35:51.370 --> 00:35:55.240
is too high for the
private sector to manage.

00:35:55.240 --> 00:35:58.180
So that's his
underlying point here,

00:35:58.180 --> 00:36:01.600
that the military is going
to be able to do things

00:36:01.600 --> 00:36:03.790
that the civilian
sector is not going

00:36:03.790 --> 00:36:09.640
to be able to do in the
technology standup process.

00:36:09.640 --> 00:36:13.800
We skip time, right?

00:36:13.800 --> 00:36:17.040
I always try to provide some
MIT material in the class.

00:36:17.040 --> 00:36:20.870
And this is Whirlwind, right?

00:36:27.980 --> 00:36:32.870
Mainframe computers had been
created by the late '40s,

00:36:32.870 --> 00:36:34.560
early '50s.

00:36:34.560 --> 00:36:37.260
So there are a number-- you
can number them on one hand,

00:36:37.260 --> 00:36:39.870
but there's a number being
stood up around the country,

00:36:39.870 --> 00:36:42.290
particularly coming out
of Mauchly and Eckert.

00:36:46.550 --> 00:36:48.840
And the UNIVAC
generation machines

00:36:48.840 --> 00:36:51.090
came out of the University
of Pennsylvania Engineering

00:36:51.090 --> 00:36:52.730
School.

00:36:52.730 --> 00:36:54.950
But MIT, of course, wants
to play in this game.

00:36:54.950 --> 00:36:59.780
So Jay Forrester, a
great MIT technologist,

00:36:59.780 --> 00:37:08.010
persuades the Navy to develop
a mainframe flight simulator.

00:37:08.010 --> 00:37:10.740
Now, the problem with
having a flight simulator

00:37:10.740 --> 00:37:13.320
is that it has to
operate in real-time.

00:37:13.320 --> 00:37:18.490
So the other mainframes tended
to be gigantic calculators.

00:37:18.490 --> 00:37:20.980
This thing is different.

00:37:20.980 --> 00:37:24.310
And to operate in real-time,
you have to have memory.

00:37:24.310 --> 00:37:27.730
And Forrester and one
of his graduate students

00:37:27.730 --> 00:37:31.120
create the magnetic
core memory that's

00:37:31.120 --> 00:37:35.200
part of this Whirlwind system.

00:37:35.200 --> 00:37:39.010
Now, this is a time also
of Defense cutbacks.

00:37:39.010 --> 00:37:43.830
So the Navy actually
pulls the contract

00:37:43.830 --> 00:37:46.410
on the Whirlwind system.

00:37:46.410 --> 00:37:51.510
But also at MIT is a
professor named George Valley.

00:37:51.510 --> 00:37:56.260
And George Valley was a veteran
of the Rad Lab in World War II,

00:37:56.260 --> 00:37:58.030
teaching at MIT.

00:37:58.030 --> 00:38:07.120
And he comes to the realization
that the Soviet Union

00:38:07.120 --> 00:38:12.560
has developed a bomber fleet
of sufficient long-range

00:38:12.560 --> 00:38:14.990
that they could
undertake a first strike

00:38:14.990 --> 00:38:17.000
with atomic weapons,
because they developed

00:38:17.000 --> 00:38:19.740
the atomic bomb in 1949.

00:38:19.740 --> 00:38:23.430
And there was nothing,
nothing standing in their way.

00:38:23.430 --> 00:38:27.180
We would have no idea they were
coming until it was too late.

00:38:27.180 --> 00:38:31.370
So Valley is an advisor
to the Air Force.

00:38:31.370 --> 00:38:34.123
And he gets the Air
Force in particular

00:38:34.123 --> 00:38:35.790
are really concerned
about this problem.

00:38:35.790 --> 00:38:37.310
And boy, is it a real problem.

00:38:37.310 --> 00:38:39.680
It's a real problem.

00:38:39.680 --> 00:38:43.167
So Valley persuades
the Air Force

00:38:43.167 --> 00:38:44.750
that they're going
to have to stand up

00:38:44.750 --> 00:38:48.490
a whole new airborne
warning defense system.

00:38:52.110 --> 00:38:53.520
What's he going to do?

00:38:53.520 --> 00:38:55.650
It's an incredibly
complex network.

00:38:55.650 --> 00:38:59.100
It's going to have to get stood
up all across, like, the Arctic

00:38:59.100 --> 00:39:02.047
and out into the North
Atlantic on ships.

00:39:02.047 --> 00:39:03.630
And there's going
to have to be planes

00:39:03.630 --> 00:39:05.130
with radar systems flying.

00:39:05.130 --> 00:39:08.010
And there's going to have
to be radar installations

00:39:08.010 --> 00:39:11.760
all over northern Canada.

00:39:11.760 --> 00:39:14.670
In effect, they're going to have
to build a radar interception

00:39:14.670 --> 00:39:15.570
network.

00:39:15.570 --> 00:39:18.120
And then these varying
messages are all

00:39:18.120 --> 00:39:20.670
going to have to come
to a single place.

00:39:20.670 --> 00:39:23.400
And you don't have
a lot of time here.

00:39:23.400 --> 00:39:26.040
And the messages have got
to be understood, and then

00:39:26.040 --> 00:39:28.410
transmitted to
decision-makers to make

00:39:28.410 --> 00:39:30.573
a decision on what they do.

00:39:30.573 --> 00:39:31.990
It's a really
complicated problem.

00:39:31.990 --> 00:39:35.710
So Valley realizes, I'm
going to need a computer.

00:39:38.838 --> 00:39:43.350
He's walking around MIT, where
else but the Infinite Corridor.

00:39:43.350 --> 00:39:47.360
And he bumps into Forrester,
and discovers Forrester

00:39:47.360 --> 00:39:52.420
is actually building a
big computer, Whirlwind.

00:39:52.420 --> 00:39:59.800
And Valley says, we need it for
this new early warning defense

00:39:59.800 --> 00:40:01.390
system.

00:40:01.390 --> 00:40:07.650
And he enlists Forrester,
who's over here.

00:40:10.950 --> 00:40:13.980
Because it's real-time
computing, it's different.

00:40:13.980 --> 00:40:15.570
It's not just a big calculator.

00:40:19.203 --> 00:40:20.620
Look at this lady
sitting in front

00:40:20.620 --> 00:40:23.200
of a keyboard with
a cathode ray tube.

00:40:26.960 --> 00:40:27.720
That's this.

00:40:27.720 --> 00:40:29.900
That's this thing.

00:40:29.900 --> 00:40:34.370
That's not a standard
mainframe from ENIAC or UNIVAC.

00:40:34.370 --> 00:40:37.550
That's this thing, right?

00:40:37.550 --> 00:40:41.680
That's what they stumble on to.

00:40:41.680 --> 00:40:43.680
And look at this.

00:40:43.680 --> 00:40:46.200
Here's an Air Force
corporal sitting in front

00:40:46.200 --> 00:40:48.450
of the cathode ray tube.

00:40:48.450 --> 00:40:50.690
Signaling is coming in.

00:40:50.690 --> 00:40:54.760
You guessed it-- signals
across telephone lines.

00:40:58.600 --> 00:41:01.180
So the radar signals are being
sent to a central location

00:41:01.180 --> 00:41:04.830
across telephone lines.

00:41:04.830 --> 00:41:09.040
He's got this kind
of gun in his hand.

00:41:11.590 --> 00:41:14.020
It's like an electronic gun.

00:41:14.020 --> 00:41:15.640
It's the mouse.

00:41:15.640 --> 00:41:17.370
That's what it is.

00:41:17.370 --> 00:41:20.170
You point on it,
you get a readout

00:41:20.170 --> 00:41:21.970
of what the signal means.

00:41:21.970 --> 00:41:26.050
So here it is, like
in the early '50s.

00:41:26.050 --> 00:41:26.910
That's Whirlwind.

00:41:26.910 --> 00:41:28.600
That's SAGE.

00:41:28.600 --> 00:41:32.710
Lincoln Lab has to get created
to really drive the research,

00:41:32.710 --> 00:41:35.470
because it's not just going
to happen in professors' labs

00:41:35.470 --> 00:41:37.990
in MIT.

00:41:37.990 --> 00:41:41.320
MIT starts to make these
computers, and decides,

00:41:41.320 --> 00:41:44.190
we don't want to be in
the computer business.

00:41:44.190 --> 00:41:51.670
So the contract is given to
IBM to make the computers.

00:41:51.670 --> 00:41:55.480
And that becomes
IBM 700 series, it's

00:41:55.480 --> 00:41:58.370
first really big important
set of computers.

00:41:58.370 --> 00:42:01.660
So you begin to get an idea of
the ramifications of pursuing

00:42:01.660 --> 00:42:07.003
this Defense
project at the scale

00:42:07.003 --> 00:42:08.920
that the Air Force is
willing to pursue it at.

00:42:08.920 --> 00:42:10.582
I'll just tell you
one more story.

00:42:10.582 --> 00:42:12.040
At the end of World
War II, there's

00:42:12.040 --> 00:42:16.800
two countries that are making
a lot of progress on computing.

00:42:16.800 --> 00:42:20.650
The British have made
a lot of progress

00:42:20.650 --> 00:42:23.770
at Bletchley Park on
computing, because they have

00:42:23.770 --> 00:42:25.720
to cope with the U-boat threat.

00:42:25.720 --> 00:42:30.250
And they have to decipher
these incredibly complex Enigma

00:42:30.250 --> 00:42:34.820
signals that the German
communication system relies on.

00:42:34.820 --> 00:42:38.293
It's really quite
capable cryptography.

00:42:38.293 --> 00:42:40.210
And they develop computers
to be able to break

00:42:40.210 --> 00:42:41.002
those signals down.

00:42:41.002 --> 00:42:42.370
So the British are going well.

00:42:42.370 --> 00:42:44.578
And they share a lot of that
information with the US,

00:42:44.578 --> 00:42:49.050
and we develop comparable
encryption capability.

00:42:49.050 --> 00:42:54.470
End of Wordl War II, Britain
dismantles its war machine,

00:42:54.470 --> 00:42:58.790
cancels its nascent
computing operations.

00:42:58.790 --> 00:43:06.000
There is one company in Britain
that picks up computing.

00:43:06.000 --> 00:43:07.140
It's a tea biscuit company.

00:43:09.990 --> 00:43:13.770
At 4 o'clock, everybody's
got to get tea.

00:43:13.770 --> 00:43:17.283
And at 4 o'clock, everybody's
got to have fresh tea biscuits

00:43:17.283 --> 00:43:18.450
right there in the tea shop.

00:43:21.130 --> 00:43:23.590
It's a very complicated problem.

00:43:23.590 --> 00:43:27.190
It involves incredibly complex
railroad time schedules

00:43:27.190 --> 00:43:31.660
and analysis of delay
and delay factors.

00:43:31.660 --> 00:43:33.550
And they need a
computer, so they

00:43:33.550 --> 00:43:36.667
take the wartime computers the
British have been developing.

00:43:36.667 --> 00:43:38.500
And they develop this
whole computing system

00:43:38.500 --> 00:43:41.320
for getting tea biscuits
throughout the British Isles

00:43:41.320 --> 00:43:44.770
at 4 o'clock in the afternoon
at all the tea shops.

00:43:44.770 --> 00:43:47.920
That's one development project.

00:43:47.920 --> 00:43:51.520
The other development project on
the other side of the Atlantic

00:43:51.520 --> 00:43:55.150
is the United States Air Force.

00:43:55.150 --> 00:43:57.970
They're beginning to
develop missile technology

00:43:57.970 --> 00:44:00.040
and ballistic
missile technology.

00:44:00.040 --> 00:44:01.900
And boy, does that
require computing.

00:44:01.900 --> 00:44:06.020
Getting those trajectories
right really requires computing.

00:44:06.020 --> 00:44:08.610
Who does the IT revolution,
the tea company or the US Air

00:44:08.610 --> 00:44:09.110
Force?

00:44:09.110 --> 00:44:10.130
Who wins?

00:44:10.130 --> 00:44:12.680
You can only guess.

00:44:12.680 --> 00:44:15.050
So that's how these
things happen.

00:44:15.050 --> 00:44:16.950
There's often
foundational stories.

00:44:16.950 --> 00:44:18.530
They're pretty key here.

00:44:18.530 --> 00:44:19.905
But you get that
rough comparison

00:44:19.905 --> 00:44:22.072
of what you're up against,
if you're the British tea

00:44:22.072 --> 00:44:24.350
company trying to develop
computing versus the US Air

00:44:24.350 --> 00:44:24.850
Force.

00:44:24.850 --> 00:44:27.950
The US Air Force is
doing this stuff--

00:44:27.950 --> 00:44:32.210
magnetic core memory, the
mouse, the cathode ray.

00:44:32.210 --> 00:44:34.930
They're putting all
these pieces together

00:44:34.930 --> 00:44:38.590
that become foundational.

00:44:38.590 --> 00:44:42.920
The Whirlwind project
becomes the SAGE project.

00:44:42.920 --> 00:44:46.130
And that becomes really
critical for a lot

00:44:46.130 --> 00:44:50.500
of early computing, particularly
real-time computing.

00:44:50.500 --> 00:44:52.840
The Defense Department
goes on to semiconductors.

00:44:52.840 --> 00:44:57.670
It goes on with key work in
all kinds of semiconductor

00:44:57.670 --> 00:44:58.382
technologies.

00:44:58.382 --> 00:45:00.490
It goes on to
supercomputing, leading

00:45:00.490 --> 00:45:02.515
that, all kinds of
advances in software.

00:45:04.930 --> 00:45:06.430
When we talk about
DARPA, we'll talk

00:45:06.430 --> 00:45:09.520
about the development
of personal computing

00:45:09.520 --> 00:45:13.200
in the network and the internet.

00:45:13.200 --> 00:45:21.670
But it's a powerful story of
this Defense Innovation system

00:45:21.670 --> 00:45:26.780
and the role that it
plays in the US economy

00:45:26.780 --> 00:45:29.990
in the second half
of the 20th century.

00:45:29.990 --> 00:45:32.970
So which of you has got--

00:45:32.970 --> 00:45:34.700
Matthew again, all right.

00:45:34.700 --> 00:45:35.580
You're up.

00:45:35.580 --> 00:45:39.230
MATTHEW: Yeahl so there are
definitely a lot of examples

00:45:39.230 --> 00:45:41.340
that Ruttan gives.

00:45:41.340 --> 00:45:45.090
And his thesis was that
maybe these technological

00:45:45.090 --> 00:45:48.420
developments would have happened
anyway, but that urgency of war

00:45:48.420 --> 00:45:50.320
made these happen a lot faster.

00:45:50.320 --> 00:45:53.160
And you see the DOD
becoming, in his eyes,

00:45:53.160 --> 00:45:55.710
the major organization
that's kind of funding

00:45:55.710 --> 00:45:58.005
this technological development.

00:45:58.005 --> 00:46:00.080
So I think the one
question we really

00:46:00.080 --> 00:46:03.892
to need to ask is, is war
necessary for economic growth?

00:46:03.892 --> 00:46:06.350
WILLIAM BONVILLIAN: That would
be the foundational question

00:46:06.350 --> 00:46:08.330
at the least.

00:46:08.330 --> 00:46:09.330
That's a great question.

00:46:09.330 --> 00:46:12.770
I mean, it's a great question.

00:46:12.770 --> 00:46:16.550
AUDIENCE: Well, I have a
counter question to that.

00:46:16.550 --> 00:46:19.400
Maybe rather than war,
maybe what's really required

00:46:19.400 --> 00:46:20.750
is DOD funding.

00:46:23.503 --> 00:46:24.920
Throughout a lot
of this, granted,

00:46:24.920 --> 00:46:27.710
there was a lot of Cold War
paranoia that was fueling this.

00:46:27.710 --> 00:46:30.410
And that was fueled
on all these advances.

00:46:30.410 --> 00:46:35.900
But you could still paint
a lot of the problems that

00:46:35.900 --> 00:46:39.067
face us today as
national security risks.

00:46:39.067 --> 00:46:41.150
And then you could get a
similar level of urgency.

00:46:41.150 --> 00:46:42.525
Even though we're
not technically

00:46:42.525 --> 00:46:46.997
at a war with, say, the climate,
you can't really shoot that.

00:46:46.997 --> 00:46:48.330
And you kind of need it to live.

00:46:48.330 --> 00:46:55.926
So maybe it's less
about war and more just

00:46:55.926 --> 00:46:58.185
a sense of priorities.

00:46:58.185 --> 00:47:00.060
AUDIENCE: I think that's
a really good point.

00:47:00.060 --> 00:47:04.470
Pretty much every
presidential campaign debate

00:47:04.470 --> 00:47:06.040
I've ever watched,
there's always

00:47:06.040 --> 00:47:08.373
the essential question they
ask, where they're like, oh,

00:47:08.373 --> 00:47:10.065
what's the biggest
risk that you think

00:47:10.065 --> 00:47:11.190
is facing our nation today.

00:47:11.190 --> 00:47:13.680
And often one of the
answers is climate change.

00:47:13.680 --> 00:47:18.180
So I think that might be a
really key part of rephrasing

00:47:18.180 --> 00:47:21.900
or reorienting our
perspective to maybe start

00:47:21.900 --> 00:47:24.150
re-allocating
funding towards what

00:47:24.150 --> 00:47:26.640
is necessary for the welfare
of the nation that might not

00:47:26.640 --> 00:47:31.490
always be another
nation's intentions.

00:47:31.490 --> 00:47:34.370
AUDIENCE: Yeah, I think he
used it as a provocative title.

00:47:34.370 --> 00:47:36.860
But it should have
actually been called,

00:47:36.860 --> 00:47:40.190
Is the Threat of War
Necessary for Economic Growth,

00:47:40.190 --> 00:47:42.980
because I think there's a
stronger argument for that.

00:47:42.980 --> 00:47:49.700
Yeah, threat makes us put
funding into national security

00:47:49.700 --> 00:47:50.900
technologies.

00:47:50.900 --> 00:47:55.160
Also we've talked a bit
about Japan's manufacturing

00:47:55.160 --> 00:47:55.790
innovation.

00:47:55.790 --> 00:47:58.435
And I don't think that
was spurred by war

00:47:58.435 --> 00:47:59.310
or the threat of war.

00:47:59.310 --> 00:48:01.785
So it's caveats.

00:48:01.785 --> 00:48:04.160
WILLIAM BONVILLIAN: Yeah, and
you make an important point

00:48:04.160 --> 00:48:04.660
here, too.

00:48:04.660 --> 00:48:09.290
Which is, the US is
pretty unique in putting

00:48:09.290 --> 00:48:12.720
national security at the center
of its innovation system.

00:48:12.720 --> 00:48:13.970
Other countries don't do that.

00:48:13.970 --> 00:48:15.410
For sure, Japan doesn't.

00:48:15.410 --> 00:48:18.350
For sure, Germany does
not at this stage.

00:48:18.350 --> 00:48:22.470
So other countries have other
organizational motivations

00:48:22.470 --> 00:48:25.700
than, as you put it,
the threat of war.

00:48:25.700 --> 00:48:27.350
But it's a powerful
one in our country.

00:48:27.350 --> 00:48:29.683
AUDIENCE: Yeah, that's the
other point I wanted to make,

00:48:29.683 --> 00:48:32.300
is that I think Ruttan was
very United States-centric just

00:48:32.300 --> 00:48:36.590
throughout our entire reading.

00:48:36.590 --> 00:48:39.470
MATTHEW: So with that
in mind, is there

00:48:39.470 --> 00:48:44.620
anything to worry
about the $54 billion

00:48:44.620 --> 00:48:50.390
cut to science and
basic science research,

00:48:50.390 --> 00:48:53.870
and reallocating that
towards national security

00:48:53.870 --> 00:48:57.590
defense, if that's going
to go to the DOD anyway?

00:48:57.590 --> 00:49:01.578
AUDIENCE: Well, I guess I could
get a job flipping burgers.

00:49:01.578 --> 00:49:03.620
WILLIAM BONVILLIAN: I
don't think the $54 billion

00:49:03.620 --> 00:49:08.040
will necessarily go
into Defense R&D.

00:49:08.040 --> 00:49:09.590
And obviously, the
entire $54 billion

00:49:09.590 --> 00:49:12.270
didn't come out of the
domestic side either,

00:49:12.270 --> 00:49:15.210
but there are very
significant cuts to US science

00:49:15.210 --> 00:49:16.385
on the civilian side.

00:49:16.385 --> 00:49:17.760
I don't think
they're going to be

00:49:17.760 --> 00:49:21.970
offset by corresponding
increases on the defense side.

00:49:21.970 --> 00:49:24.328
We should be so lucky.

00:49:24.328 --> 00:49:26.745
But I think, Matthew, you're
driving an interesting point.

00:49:29.350 --> 00:49:31.460
Suppose there's no war, right?

00:49:31.460 --> 00:49:34.870
What's the motivator
we're going to use

00:49:34.870 --> 00:49:37.381
to drive a technology advance?

00:49:44.600 --> 00:49:47.030
MATTHEW: I think one person
mentioned in their question

00:49:47.030 --> 00:49:51.220
if maybe international
competition could replace

00:49:51.220 --> 00:49:53.210
kind of that sense of urgency.

00:49:56.970 --> 00:49:59.522
AUDIENCE: Yeah, I think
it's just a question of,

00:49:59.522 --> 00:50:01.480
what are your priorities
at the current moment,

00:50:01.480 --> 00:50:03.760
and what can you make
urgent enough just

00:50:03.760 --> 00:50:10.510
to justify kind of large-scale,
huge, not just funding,

00:50:10.510 --> 00:50:15.260
but reorganization around maybe
computers or key principles.

00:50:15.260 --> 00:50:17.530
And so in this case, I guess
it was a threat of war.

00:50:17.530 --> 00:50:23.420
But you could probably
argue, around the time of--

00:50:23.420 --> 00:50:24.290
man, I'm forgetting.

00:50:24.290 --> 00:50:27.400
But there's probably some
public health epidemic

00:50:27.400 --> 00:50:28.900
that you could argue
that would have

00:50:28.900 --> 00:50:34.650
spurred massive
bioresearch in that area.

00:50:34.650 --> 00:50:37.120
And I think that can also
happen internationally.

00:50:37.120 --> 00:50:38.590
So you think maybe
the development

00:50:38.590 --> 00:50:40.180
of an epidemic in
a different country

00:50:40.180 --> 00:50:43.150
could also spur bioresearch
in other countries

00:50:43.150 --> 00:50:45.320
to supplement or help.

00:50:45.320 --> 00:50:48.430
And so I think we could
even generalize even further

00:50:48.430 --> 00:50:53.210
and just say, is threat
necessary for economic growth?

00:50:53.210 --> 00:50:55.660
AUDIENCE: I think the
big point about war

00:50:55.660 --> 00:50:58.270
is that you're a kind
of centralizing everyone

00:50:58.270 --> 00:50:59.500
towards a common cause.

00:50:59.500 --> 00:51:01.450
So I think a lot
of the initiatives

00:51:01.450 --> 00:51:06.040
nowadays, like the Cancer
Moonshoot or even the push

00:51:06.040 --> 00:51:08.860
around getting a drug
out there for CF,

00:51:08.860 --> 00:51:12.640
like those targeted initiatives
towards a certain cause,

00:51:12.640 --> 00:51:16.690
I think those could
be one way to target

00:51:16.690 --> 00:51:20.380
the need for development
in a certain area,

00:51:20.380 --> 00:51:26.800
in times of peace, where you
don't have a war impending.

00:51:26.800 --> 00:51:28.880
AUDIENCE: One thing I
thought was interesting,

00:51:28.880 --> 00:51:31.640
especially when people were
discussing the increase in DOD

00:51:31.640 --> 00:51:33.670
funding, despite the fact
that we're not really

00:51:33.670 --> 00:51:39.910
in a World War II era of
war, I've noticed that--

00:51:39.910 --> 00:51:41.625
how much of MIT's
funding is DOD?

00:51:41.625 --> 00:51:42.892
It's like half, right?

00:51:42.892 --> 00:51:43.850
WILLIAM BONVILLIAN: No.

00:51:43.850 --> 00:51:44.190
AUDIENCE: It's not.

00:51:44.190 --> 00:51:45.440
WILLIAM BONVILLIAN: Not close.

00:51:45.440 --> 00:51:48.103
AUDIENCE: Oh, it might be just
the Nuclear department then,

00:51:48.103 --> 00:51:49.030
which makes sense.

00:51:49.030 --> 00:51:53.340
WILLIAM BONVILLIAN:
Yes, that makes sense.

00:51:53.340 --> 00:51:54.330
I don't know.

00:51:54.330 --> 00:51:58.500
It's like in the 18% range
of federal research funding.

00:51:58.500 --> 00:52:03.120
So NIH and DOD are just
about equal at MIT,

00:52:03.120 --> 00:52:08.070
in terms of originating research
funding for the university.

00:52:08.070 --> 00:52:11.400
MIT tends to be somewhat
higher in defense research

00:52:11.400 --> 00:52:12.690
than most universities.

00:52:15.550 --> 00:52:16.565
It's not close to half.

00:52:16.565 --> 00:52:18.440
AUDIENCE: So the point
that I wanted to make,

00:52:18.440 --> 00:52:23.200
though, regardless
of the exact number,

00:52:23.200 --> 00:52:26.080
I'm sure that a lot of DOD
money is spent on things that

00:52:26.080 --> 00:52:27.880
don't necessarily
have applications

00:52:27.880 --> 00:52:30.610
of, say, building a better
tank or a better missile

00:52:30.610 --> 00:52:33.070
or anything like that.

00:52:33.070 --> 00:52:35.590
So just because some
things have the label

00:52:35.590 --> 00:52:37.548
and are under the
Department of Defense,

00:52:37.548 --> 00:52:39.340
that does not necessarily
mean that they're

00:52:39.340 --> 00:52:42.651
going strictly toward learning
how to fight a new enemy.

00:52:42.651 --> 00:52:45.950
I'm just curious what
your thoughts are.

00:52:45.950 --> 00:52:47.430
AUDIENCE: Can you rephrase that?

00:52:47.430 --> 00:52:47.972
AUDIENCE: OK.

00:52:51.450 --> 00:52:54.780
So MIT, we don't really
research building

00:52:54.780 --> 00:52:56.520
better guns and bombs, right?

00:52:56.520 --> 00:52:57.860
WILLIAM BONVILLIAN: Correct.

00:52:57.860 --> 00:52:59.895
And we don't do classified
research either.

00:52:59.895 --> 00:53:00.520
AUDIENCE: Yeah.

00:53:00.520 --> 00:53:05.185
So just because we have a lot
of DOD funding coming our way,

00:53:05.185 --> 00:53:06.810
it does not necessarily
mean that we're

00:53:06.810 --> 00:53:09.180
researching better
ways to kill people

00:53:09.180 --> 00:53:11.190
or to keep ourselves
from being killed.

00:53:11.190 --> 00:53:13.440
AUDIENCE: Does that funding
come to MIT the institute,

00:53:13.440 --> 00:53:15.113
or Lincoln Lab as part of MIT?

00:53:15.113 --> 00:53:16.530
WILLIAM BONVILLIAN:
So Lincoln Lab

00:53:16.530 --> 00:53:20.280
is a separate entity
from MIT and, in fact,

00:53:20.280 --> 00:53:22.140
undertakes a lot
of Defense work.

00:53:22.140 --> 00:53:26.940
But it is defense, not offense,
is kind of a general rule

00:53:26.940 --> 00:53:29.690
that they apply.

00:53:29.690 --> 00:53:31.680
AUDIENCE: So that 18%
doesn't go to just MIT.

00:53:31.680 --> 00:53:34.055
WILLIAM BONVILLIAN: I'm not
counting Lincoln Lab in that.

00:53:36.358 --> 00:53:38.400
AUDIENCE: So my thought
on that is basically just

00:53:38.400 --> 00:53:41.880
that, you're taking this
money, but it's not necessarily

00:53:41.880 --> 00:53:44.840
trying to make us a
better war machine.

00:53:47.790 --> 00:53:49.630
WILLIAM BONVILLIAN:
So Max, in our reading

00:53:49.630 --> 00:53:52.510
of Glenn Fong, which
I think comes next,

00:53:52.510 --> 00:53:55.640
we're actually going to
derive after this exact point.

00:53:55.640 --> 00:53:59.590
So we can really lay out
some of those nuances

00:53:59.590 --> 00:54:02.665
when we look at his piece.

00:54:02.665 --> 00:54:04.040
So Matthew, do
you have a closing

00:54:04.040 --> 00:54:07.835
thought for us on Vernon Ruttan?

00:54:10.540 --> 00:54:13.430
MATTHEW: I think I thought
very similarly to other people

00:54:13.430 --> 00:54:17.500
here, that it seems
more than war itself.

00:54:17.500 --> 00:54:19.840
A sense of urgency and
threat, whether it's

00:54:19.840 --> 00:54:26.077
military or health-related,
that's really what drives us.

00:54:26.077 --> 00:54:27.160
WILLIAM BONVILLIAN: Right.

00:54:27.160 --> 00:54:31.300
And that'll drive a
societal, scaled-up effort,

00:54:31.300 --> 00:54:33.650
those kinds of concerns.

00:54:33.650 --> 00:54:35.602
I think you're absolutely right.

00:54:35.602 --> 00:54:37.310
AUDIENCE: My main
concern with this piece

00:54:37.310 --> 00:54:40.108
was like, you're overspending
to move very quickly, which

00:54:40.108 --> 00:54:40.900
isn't really great.

00:54:40.900 --> 00:54:43.347
But also right after--
like once your initiative

00:54:43.347 --> 00:54:44.930
is done, that's like
saying, yeah, I'm

00:54:44.930 --> 00:54:46.940
going to diet up until
Friday, like right

00:54:46.940 --> 00:54:48.470
after you kind of go all out.

00:54:48.470 --> 00:54:51.050
So I wonder if these things,
if you move the science forward

00:54:51.050 --> 00:54:54.310
very quickly, and then people
just kind of drop it after.

00:54:54.310 --> 00:54:56.327
So there's this
kind of lost cause,

00:54:56.327 --> 00:54:57.410
and they don't advance it.

00:54:57.410 --> 00:54:58.850
Because also, like
for most technologies,

00:54:58.850 --> 00:55:00.620
like we can't do
certain technologies

00:55:00.620 --> 00:55:02.660
that we would have been
able to do 50 years ago,

00:55:02.660 --> 00:55:04.820
because the experts in
that kind of thinking

00:55:04.820 --> 00:55:06.320
are not here anymore.

00:55:11.180 --> 00:55:15.340
AUDIENCE: I had a quick
operations question for Bill.

00:55:15.340 --> 00:55:23.440
When it comes to increasing R&D
funding for agencies like DOD,

00:55:23.440 --> 00:55:26.590
is it the Congresspeople
and Senators acting sort of

00:55:26.590 --> 00:55:28.840
in an executive capacity
for their districts,

00:55:28.840 --> 00:55:30.700
or is there pressure
from the district

00:55:30.700 --> 00:55:35.470
to sort of increase the
policymaking for that,

00:55:35.470 --> 00:55:37.160
in terms of national defense?

00:55:37.160 --> 00:55:42.070
So I guess I'm asking, are
legislators acting autonomously

00:55:42.070 --> 00:55:43.690
in defense of the
country, or is there

00:55:43.690 --> 00:55:46.210
pressure coming from
their districts, as well?

00:55:48.510 --> 00:55:50.260
WILLIAM BONVILLIAN:
So members of Congress

00:55:50.260 --> 00:55:55.140
tend to be much more concerned
about defense spending that's

00:55:55.140 --> 00:55:58.620
part of big
acquisition programs.

00:55:58.620 --> 00:56:03.210
Who's going to get the next
award for the next Air Force

00:56:03.210 --> 00:56:04.950
aircraft?

00:56:04.950 --> 00:56:07.410
That's significant scale.

00:56:07.410 --> 00:56:11.380
R&D spending tends to be at
a much more modest scale.

00:56:11.380 --> 00:56:14.560
And Congress itself has
eliminated the appropriations

00:56:14.560 --> 00:56:15.700
earmarking system.

00:56:15.700 --> 00:56:17.680
So members can no
longer go into bills

00:56:17.680 --> 00:56:21.385
and stick money in for
projects in their district.

00:56:24.190 --> 00:56:26.690
That system has really
been significantly--

00:56:26.690 --> 00:56:28.190
I wouldn't say it's
been eliminated,

00:56:28.190 --> 00:56:29.960
but it's been
significantly reduced.

00:56:29.960 --> 00:56:33.670
So the Congress itself, to some
extent, has reformed itself.

00:56:33.670 --> 00:56:36.130
Now, the problem for that
is that it gives members

00:56:36.130 --> 00:56:39.852
much less at the stake
in federal expenditures.

00:56:39.852 --> 00:56:42.310
If they can't affect what's
going on in their own district,

00:56:42.310 --> 00:56:45.820
why should they care what
federal appropriations levels

00:56:45.820 --> 00:56:46.630
are?

00:56:46.630 --> 00:56:49.910
So it's a two-edged sword here.

00:56:49.910 --> 00:56:52.060
But by and large,
members of Congress

00:56:52.060 --> 00:56:58.100
have stayed out of R&D. They
don't really touch DARPA.

00:56:58.100 --> 00:57:00.050
They certainly don't touch NSF.

00:57:00.050 --> 00:57:03.140
They don't touch NIH.

00:57:03.140 --> 00:57:04.850
And part of this
is that the amount

00:57:04.850 --> 00:57:08.530
of funding awards for a research
project are relatively modest

00:57:08.530 --> 00:57:10.940
and really don't affect
anything at scale.

00:57:10.940 --> 00:57:13.730
What they worry about are these
larger acquisition projects.

00:57:13.730 --> 00:57:16.195
AUDIENCE: Was that also the
case for the [INAUDIBLE]

00:57:16.195 --> 00:57:20.123
observation that
Ruttan undertook?

00:57:20.123 --> 00:57:22.040
WILLIAM BONVILLIAN: I'm
not sure I follow you.

00:57:22.040 --> 00:57:27.890
AUDIENCE: Was it
the pre-earmark era?

00:57:27.890 --> 00:57:29.907
Was it present
[INAUDIBLE] observation?

00:57:29.907 --> 00:57:30.990
WILLIAM BONVILLIAN: Right.

00:57:30.990 --> 00:57:35.000
The earmark era is only in it
in the last four or five years.

00:57:35.000 --> 00:57:37.920
AUDIENCE: So then Ruttan was
operating under that system.

00:57:37.920 --> 00:57:39.670
WILLIAM BONVILLIAN:
Yeah, but again, there

00:57:39.670 --> 00:57:43.760
wasn't very much earmarking
of R&D funding, which

00:57:43.760 --> 00:57:44.887
is really what--

00:57:44.887 --> 00:57:46.470
he's focused on the
innovation system.

00:57:50.810 --> 00:57:56.450
OK, so Glenn Fong--

00:57:56.450 --> 00:58:01.380
and he starts his
piece with a quote

00:58:01.380 --> 00:58:03.240
from a former White
House chief of staff,

00:58:03.240 --> 00:58:10.250
John Sununu of New Hampshire,
who states, "We don't do

00:58:10.250 --> 00:58:13.620
industrial policy," in the US.

00:58:13.620 --> 00:58:20.020
And Glenn takes that line on and
essentially proves otherwise,

00:58:20.020 --> 00:58:23.550
that we actually are operating,
at least through the defense

00:58:23.550 --> 00:58:26.490
sector, with what can
only be viewed as a pretty

00:58:26.490 --> 00:58:29.200
significant industrial policy.

00:58:29.200 --> 00:58:34.770
So how does case studies
of various agencies.

00:58:34.770 --> 00:58:36.180
It's not all defense.

00:58:36.180 --> 00:58:40.050
He also looks at
Commerce and NIST.

00:58:40.050 --> 00:58:42.882
But he concludes
that the significance

00:58:42.882 --> 00:58:45.090
of the governmental role,
particularly on the defense

00:58:45.090 --> 00:58:49.140
side, is really quite strong.

00:58:49.140 --> 00:58:53.600
And that because of the volume
of the spending, in particular,

00:58:53.600 --> 00:58:58.930
that's particularly powerful
on the defense side.

00:58:58.930 --> 00:59:04.520
And he argues that there are
about four models to drive it.

00:59:04.520 --> 00:59:06.780
The question, Max,
you were asking about,

00:59:06.780 --> 00:59:09.570
there's about four
models by which

00:59:09.570 --> 00:59:12.600
DOD undertakes its
spending that happen

00:59:12.600 --> 00:59:17.230
to have spillover effects
into the civilian sector.

00:59:17.230 --> 00:59:21.300
So one model is what he
calls the byproduct model.

00:59:21.300 --> 00:59:24.900
Military R&D will have
unintended spillovers

00:59:24.900 --> 00:59:26.830
into the commercial sector.

00:59:26.830 --> 00:59:34.140
And he cites ARPA-NET
as an example of this.

00:59:34.140 --> 00:59:37.100
In other words, when
DOD is setting up

00:59:37.100 --> 00:59:42.370
the internet, the ARPA-NET,
for its own internal purposes,

00:59:42.370 --> 00:59:45.230
it's a defense communication
system, and a communication

00:59:45.230 --> 00:59:49.370
system between the early
computer science departments

00:59:49.370 --> 00:59:51.853
that DARPA has been supporting.

00:59:51.853 --> 00:59:54.020
It's a way for them to
communicate and transfer data

00:59:54.020 --> 00:59:55.310
amongst themselves.

00:59:55.310 --> 00:59:57.768
They're not
envisioning that this

00:59:57.768 --> 00:59:59.810
is going to be the standard
form of communication

00:59:59.810 --> 01:00:01.900
of the 21st century.

01:00:01.900 --> 01:00:05.230
They were thinking about a
much more immediate problem.

01:00:05.230 --> 01:00:07.780
But the byproduct
is that we create

01:00:07.780 --> 01:00:11.290
this massive economic sector.

01:00:11.290 --> 01:00:13.630
Then there's an
intentional spinoff model.

01:00:13.630 --> 01:00:18.600
So commercial
spinoffs get expressly

01:00:18.600 --> 01:00:23.210
contemplated during the
program planning around an R&D

01:00:23.210 --> 01:00:25.470
initiative.

01:00:25.470 --> 01:00:32.670
And [? E-side ?] strategic
computing and VHSIC as examples

01:00:32.670 --> 01:00:38.150
where DARPA know that what
it was going to create

01:00:38.150 --> 01:00:40.610
in the computing sector was
going to benefit all parts

01:00:40.610 --> 01:00:43.190
of the computing
sector, not simply DOD.

01:00:43.190 --> 01:00:47.110
But the gains were
significant enough for DOD

01:00:47.110 --> 01:00:50.380
that it was really
important to pursue this.

01:00:50.380 --> 01:00:53.260
And in fact, DARPA
and the IT revolution

01:00:53.260 --> 01:00:57.980
in general consciously
worked on standing up

01:00:57.980 --> 01:01:02.120
a lot of these technologies
in the civilian sector.

01:01:02.120 --> 01:01:03.080
Why is that?

01:01:03.080 --> 01:01:07.210
Because the Defense
Department is often

01:01:07.210 --> 01:01:11.500
quite good at standing up the
early prototypes of a pretty

01:01:11.500 --> 01:01:14.170
radical set of technologies.

01:01:14.170 --> 01:01:16.960
But they don't have
the follow-on capital

01:01:16.960 --> 01:01:20.470
that the civilian sector
can muster, a big financing

01:01:20.470 --> 01:01:22.910
follow-on capability.

01:01:22.910 --> 01:01:25.648
So DARPA consciously
understood this,

01:01:25.648 --> 01:01:27.440
realized there was
going to have to be huge

01:01:27.440 --> 01:01:29.740
incremental advances
in the technologies

01:01:29.740 --> 01:01:31.280
it was standing up.

01:01:31.280 --> 01:01:35.420
It would help create
the model, make

01:01:35.420 --> 01:01:38.000
it available in the civilian
sector, on the assumption

01:01:38.000 --> 01:01:42.290
that a rising IT sector and
financial support system

01:01:42.290 --> 01:01:45.230
would come in and scale this up.

01:01:45.230 --> 01:01:47.060
It would radically
drive the price down,

01:01:47.060 --> 01:01:51.020
enabling DOD to buy
the technologies back

01:01:51.020 --> 01:01:54.380
at a fraction of the cost and
with much greater capability

01:01:54.380 --> 01:01:57.110
than their own system
would be able to do this.

01:01:57.110 --> 01:02:00.890
So DARPA's decision to stand
up a lot of the IT revolution

01:02:00.890 --> 01:02:03.740
around computing on
the civilian side

01:02:03.740 --> 01:02:09.070
comes from a pretty
conscious effort

01:02:09.070 --> 01:02:11.800
to understand the dynamics
of what was going to be.

01:02:11.800 --> 01:02:13.870
And they all understood
it to be a very large

01:02:13.870 --> 01:02:15.610
potential economic sector.

01:02:15.610 --> 01:02:18.430
And how DOD could be
the initiator and then

01:02:18.430 --> 01:02:22.420
leverage off what were going
to be much higher investments

01:02:22.420 --> 01:02:23.350
on the civilian side.

01:02:23.350 --> 01:02:26.260
So for example, for a
long period of time,

01:02:26.260 --> 01:02:29.180
DOD would be the initial market.

01:02:29.180 --> 01:02:32.170
So when we talked about how
Kilby and Noyce developed

01:02:32.170 --> 01:02:34.870
the integrated circuit,
the core breakthrough

01:02:34.870 --> 01:02:41.410
technology in semiconductors,
and really in computing,

01:02:41.410 --> 01:02:43.390
the only customer for
the first four years

01:02:43.390 --> 01:02:47.730
were the Defense
Department and NASA.

01:02:47.730 --> 01:02:50.820
So the Defense Department
carried all those advances

01:02:50.820 --> 01:02:53.760
through the first four years
of new generations of advances

01:02:53.760 --> 01:02:54.780
for integrated circuits.

01:02:54.780 --> 01:02:58.830
It wasn't until four years
later that a civilian sector

01:02:58.830 --> 01:02:59.970
started to evolve.

01:02:59.970 --> 01:03:03.420
So DOD can play this
initiator model.

01:03:03.420 --> 01:03:06.360
And what Glenn Fong
is driving at here is,

01:03:06.360 --> 01:03:10.090
that's an intentional spinoff
model that works well for DOD.

01:03:12.690 --> 01:03:17.340
Also, DOD has an
explicit dual use model.

01:03:17.340 --> 01:03:20.820
So a defense project could
have the explicit goal

01:03:20.820 --> 01:03:22.650
of developing a
military technology

01:03:22.650 --> 01:03:25.500
and a civilian
technology in parallel.

01:03:25.500 --> 01:03:33.080
And advances in lithography
in semiconductor etching

01:03:33.080 --> 01:03:34.560
are a pretty good
example of that.

01:03:34.560 --> 01:03:37.050
High performance
computing, which Al Gore

01:03:37.050 --> 01:03:40.560
helped to originate and pass
the original legislation before,

01:03:40.560 --> 01:03:42.810
these were going to have
benefits on the military side

01:03:42.810 --> 01:03:46.740
big-time, but obviously
corresponding big benefits

01:03:46.740 --> 01:03:47.790
on the civilian side.

01:03:47.790 --> 01:03:49.980
And then kind of the
fourth model, Glenn

01:03:49.980 --> 01:03:56.190
points out, for how DOD thinks
about its role in the economy

01:03:56.190 --> 01:03:58.200
and intervenes in
the economy and has,

01:03:58.200 --> 01:04:01.770
in effect, an industrial
policy, is what he calls

01:04:01.770 --> 01:04:03.570
the industrial base model.

01:04:03.570 --> 01:04:05.790
So sometimes, DOD
is going to decide

01:04:05.790 --> 01:04:10.090
that it must have an industrial
base in a particular sector,

01:04:10.090 --> 01:04:13.260
and will consciously
support the development

01:04:13.260 --> 01:04:16.320
of an industrial base
in the civilian sector.

01:04:16.320 --> 01:04:20.340
The best example
of this I know of

01:04:20.340 --> 01:04:23.220
is that both the
Navy and the Army,

01:04:23.220 --> 01:04:28.010
in the early days of aviation
in the 1920s and '30s,

01:04:28.010 --> 01:04:30.440
are consciously
attempting to create

01:04:30.440 --> 01:04:34.097
a very strong civilian
industrial base in aviation.

01:04:34.097 --> 01:04:35.930
Because they know how
powerful and important

01:04:35.930 --> 01:04:37.280
that's going to be.

01:04:37.280 --> 01:04:39.740
So Admiral Moffett, who
was leading the Navy's

01:04:39.740 --> 01:04:44.000
early aviation program,
carefully makes

01:04:44.000 --> 01:04:46.640
sure, in the
appropriations process,

01:04:46.640 --> 01:04:49.310
the congressional
appropriations process,

01:04:49.310 --> 01:04:55.370
that there are a multitude of
projects for engine makers,

01:04:55.370 --> 01:04:58.100
for airframe makers, for
different types of aircraft.

01:04:58.100 --> 01:05:00.620
So that he's going
to start to stand up

01:05:00.620 --> 01:05:02.340
a whole industrial
base and aviation.

01:05:02.340 --> 01:05:05.360
It's done very consciously.

01:05:05.360 --> 01:05:07.695
I think that's the best example.

01:05:07.695 --> 01:05:09.320
But there are other
examples like that,

01:05:09.320 --> 01:05:14.920
too including in the IT
side, such as Semitech.

01:05:14.920 --> 01:05:18.940
When Japan came very close
to capturing leadership

01:05:18.940 --> 01:05:22.060
in the semiconductor sector--
and we talked about this

01:05:22.060 --> 01:05:24.830
in the manufacturing class--

01:05:24.830 --> 01:05:26.660
DOD intervenes.

01:05:26.660 --> 01:05:30.590
So under President Reagan,
DARPA jumps in here

01:05:30.590 --> 01:05:35.510
and cost-shares the development
of new advanced manufacturing

01:05:35.510 --> 01:05:39.910
approaches in semiconductors,
so that the US

01:05:39.910 --> 01:05:41.980
could get back into that game.

01:05:41.980 --> 01:05:45.070
Japan had figured out better
processes, better production

01:05:45.070 --> 01:05:50.810
systems, more efficiency,
higher quality in semiconductor

01:05:50.810 --> 01:05:51.830
fabrication.

01:05:51.830 --> 01:05:53.600
The US had missed these.

01:05:53.600 --> 01:05:55.850
This was a conscious
attempt to keep up,

01:05:55.850 --> 01:05:57.530
because the Defense
Department felt

01:05:57.530 --> 01:06:01.590
it had to have an industrial
base in semiconductors.

01:06:01.590 --> 01:06:06.920
So these are four ways by which
DOD is willing to intervene.

01:06:06.920 --> 01:06:09.140
It will not intervene
just for straight economic

01:06:09.140 --> 01:06:10.250
competitiveness reasons.

01:06:13.160 --> 01:06:15.563
So getting back to our
conversation earlier, Max,

01:06:15.563 --> 01:06:17.480
it's not going to do
something just because it

01:06:17.480 --> 01:06:19.590
will help US competitiveness.

01:06:19.590 --> 01:06:21.980
It will only do
it if it can find

01:06:21.980 --> 01:06:26.100
one of these very close military
needs associated with it.

01:06:26.100 --> 01:06:28.850
And these are the
four models they use.

01:06:28.850 --> 01:06:31.103
Who's got the Q&A
on this, Chris?

01:06:31.103 --> 01:06:32.020
I think we're Through.

01:06:32.020 --> 01:06:34.457
Yeah, we're through this.

01:06:34.457 --> 01:06:36.040
Why don't you lead
us off in some Q&A.

01:06:36.040 --> 01:06:38.215
And Max has got a question, too.

01:06:38.215 --> 01:06:38.840
AUDIENCE: Sure.

01:06:38.840 --> 01:06:43.300
So as we just went
through pretty briefly,

01:06:43.300 --> 01:06:45.280
he mentions a lot
of different models

01:06:45.280 --> 01:06:47.830
and different
agency projects that

01:06:47.830 --> 01:06:53.170
have been kind of case
studies of opportunities

01:06:53.170 --> 01:06:57.640
that the DOD largely
has used to advance

01:06:57.640 --> 01:07:01.960
technological innovation,
somewhat indirectly.

01:07:01.960 --> 01:07:04.960
So maybe we could start
off by discussing,

01:07:04.960 --> 01:07:07.870
which model do you guys
think is most effective?

01:07:07.870 --> 01:07:10.300
Do you think it changes
when you consider

01:07:10.300 --> 01:07:13.690
different industries
or different focuses?

01:07:13.690 --> 01:07:18.509
And how applicable is this kind
of structure to present day?

01:07:26.325 --> 01:07:28.950
AUDIENCE: I think what's really
cool about all these is they're

01:07:28.950 --> 01:07:32.940
separated by intent, really.

01:07:32.940 --> 01:07:38.707
So if you're intending to
have a sort of dual use--

01:07:38.707 --> 01:07:41.290
it's probably easier to see the
bottom two than the first one.

01:07:41.290 --> 01:07:44.580
But the dual use and
the intentional spinoff

01:07:44.580 --> 01:07:48.450
are pretty strong arguments
for how DARPA projects could

01:07:48.450 --> 01:07:51.060
be effective and useful and why
you should advocate for them.

01:07:51.060 --> 01:07:56.460
It'd be pretty hard to
do the byproduct model

01:07:56.460 --> 01:07:59.542
with that sort of
intent for spinoff,

01:07:59.542 --> 01:08:01.500
just because you have
absolutely no idea of how

01:08:01.500 --> 01:08:02.700
that's going to turn out.

01:08:02.700 --> 01:08:05.490
But because they're
separated by intent,

01:08:05.490 --> 01:08:08.850
I think it's pretty fair
to say that, depending

01:08:08.850 --> 01:08:10.950
on what sort of project
you're looking at,

01:08:10.950 --> 01:08:13.840
you're going to see which
model is going to be better.

01:08:13.840 --> 01:08:17.277
And it's nice that you can
do that from the get-go.

01:08:17.277 --> 01:08:19.069
When you start the
project, you can kind of

01:08:19.069 --> 01:08:20.506
see where that's going.

01:08:24.819 --> 01:08:28.450
AUDIENCE: So just personally,
it seems like some of these

01:08:28.450 --> 01:08:31.779
might be hard to kind of create
a project around, oh, I'm

01:08:31.779 --> 01:08:33.939
going to have
unintended spillovers

01:08:33.939 --> 01:08:36.010
into the commercial sector.

01:08:36.010 --> 01:08:38.950
In some sense to me,
it seems like a bit

01:08:38.950 --> 01:08:43.149
like post-classification
of what has been done.

01:08:43.149 --> 01:08:47.290
So thinking about
the DOD as they're

01:08:47.290 --> 01:08:49.930
trying to fund projects,
what do you think

01:08:49.930 --> 01:08:52.090
are their main
priorities, in terms

01:08:52.090 --> 01:08:56.979
of potential commercialization
and potential kind of benefits

01:08:56.979 --> 01:09:00.550
that way, and also benefiting
their military efforts?

01:09:00.550 --> 01:09:02.020
What do you think
is that balance,

01:09:02.020 --> 01:09:04.930
and what kind of
characteristics would they

01:09:04.930 --> 01:09:08.890
be looking for in, maybe,
a funding proposal?

01:09:08.890 --> 01:09:11.598
AUDIENCE: Well, I'd
say one characteristic

01:09:11.598 --> 01:09:13.390
that they look for and
definitely emphasize

01:09:13.390 --> 01:09:15.910
would be superiority
over other countries

01:09:15.910 --> 01:09:17.590
who are working
in similar fields.

01:09:17.590 --> 01:09:20.260
So with the semiconductor
thing, the moment they saw,

01:09:20.260 --> 01:09:22.479
hey, Japan's doing this,
they're like, oh no.

01:09:22.479 --> 01:09:25.520
OK, now we need to get on this.

01:09:25.520 --> 01:09:27.090
What was the direct implication?

01:09:27.090 --> 01:09:28.582
That was my
question, by the way.

01:09:28.582 --> 01:09:30.040
WILLIAM BONVILLIAN:
Semiconductors?

01:09:30.040 --> 01:09:30.250
AUDIENCE: Yeah.

01:09:30.250 --> 01:09:32.625
WILLIAM BONVILLIAN: [INAUDIBLE]
for the computing system.

01:09:32.625 --> 01:09:33.189
AUDIENCE: OK.

01:09:33.189 --> 01:09:36.250
Because you said
the DOD does not

01:09:36.250 --> 01:09:38.830
support different
industries unless it

01:09:38.830 --> 01:09:43.920
has a direct national
security application.

01:09:43.920 --> 01:09:46.140
So I guess I'm just
trying to figure out

01:09:46.140 --> 01:09:50.010
how we could implement
these ideas today,

01:09:50.010 --> 01:09:55.062
so that we could, I guess, boost
our current innovation system.

01:09:55.062 --> 01:09:57.270
AUDIENCE: I don't know if
it would be military-based,

01:09:57.270 --> 01:09:58.840
but you just go
with a focus point,

01:09:58.840 --> 01:10:01.080
have that kind of
military ideology of like,

01:10:01.080 --> 01:10:03.030
we need to get here
by X amount of time.

01:10:03.030 --> 01:10:04.710
And let's put these
efforts and try

01:10:04.710 --> 01:10:07.545
to think more as
a system, rather

01:10:07.545 --> 01:10:09.240
than different departments.

01:10:09.240 --> 01:10:11.400
But you would put initiatives.

01:10:11.400 --> 01:10:14.120
Like in private capital that's
been happening recently,

01:10:14.120 --> 01:10:15.870
like [INAUDIBLE] made
a private initiative

01:10:15.870 --> 01:10:19.050
to cancer and certain diseases.

01:10:19.050 --> 01:10:20.670
But if you have a
national effort--

01:10:20.670 --> 01:10:21.237
I don't know.

01:10:21.237 --> 01:10:23.570
I wasn't alive during this,
but I think during the '70s,

01:10:23.570 --> 01:10:25.020
during the Cold War, there
was a huge initiative

01:10:25.020 --> 01:10:26.400
for science and rockets.

01:10:26.400 --> 01:10:27.570
I don't know.

01:10:27.570 --> 01:10:28.800
You probably know.

01:10:28.800 --> 01:10:30.420
I haven't seen a
[INAUDIBLE] this.

01:10:30.420 --> 01:10:32.040
WILLIAM BONVILLIAN: We'll get
into that in a later reading

01:10:32.040 --> 01:10:32.540
today.

01:10:32.540 --> 01:10:34.165
AUDIENCE: But I think
definitely having

01:10:34.165 --> 01:10:36.748
a strong national interest, but
not just financial incentives.

01:10:36.748 --> 01:10:38.332
Because from a
management perspective,

01:10:38.332 --> 01:10:40.260
people have different
ideas of what's good

01:10:40.260 --> 01:10:41.610
and what they want out of life.

01:10:41.610 --> 01:10:44.310
So I would do financial
incentives, social incentives,

01:10:44.310 --> 01:10:47.250
in terms of, you solve this
problem, you're a superstar.

01:10:47.250 --> 01:10:51.030
Kind of like an Einstein,
it'll get you on TV.

01:10:51.030 --> 01:10:52.990
And then also educational,
in terms of like,

01:10:52.990 --> 01:10:55.220
oh, these are our star
students, from five years old,

01:10:55.220 --> 01:10:59.443
10 years old, 15 years old, so
they're part of the community.

01:10:59.443 --> 01:11:00.860
And that's probably
how I'd do it.

01:11:00.860 --> 01:11:03.000
And getting rid of
egos, like finding a way

01:11:03.000 --> 01:11:06.660
to do that in a system, that's
how I would think about it.

01:11:06.660 --> 01:11:11.310
But I'm interested in
what policy people think,

01:11:11.310 --> 01:11:13.230
people who focus on policy.

01:11:13.230 --> 01:11:14.670
I don't know policy.

01:11:18.750 --> 01:11:22.360
Have there been policies in the
past that do something similar?

01:11:22.360 --> 01:11:23.860
AUDIENCE: Well,
apparently, right?

01:11:23.860 --> 01:11:25.860
AUDIENCE: I mean
outside of this.

01:11:31.360 --> 01:11:32.920
WILLIAM BONVILLIAN:
Martin, you're

01:11:32.920 --> 01:11:36.190
laying out a whole new set
of initiative drivers here.

01:11:36.190 --> 01:11:38.290
And it's an interesting list.

01:11:38.290 --> 01:11:42.220
And in fact, in the
Sputnik era, which

01:11:42.220 --> 01:11:44.350
we'll talk about
a little bit, we

01:11:44.350 --> 01:11:46.700
do see a tremendous
focus on education,

01:11:46.700 --> 01:11:50.530
for example, and training,
and the importance

01:11:50.530 --> 01:11:52.330
of being a scientist.

01:11:52.330 --> 01:11:55.180
Those all come to the
forefront in American society

01:11:55.180 --> 01:11:57.344
for a reasonable period of time.

01:12:02.162 --> 01:12:04.162
AUDIENCE: And coming back
to what I was actually

01:12:04.162 --> 01:12:08.350
saying, because it's
less obvious, or at least

01:12:08.350 --> 01:12:11.430
it's not as advertised
to the American people,

01:12:11.430 --> 01:12:13.480
that, in a lot of
aspects, we're not really

01:12:13.480 --> 01:12:20.110
doing all that well, like
education or in manufacturing.

01:12:20.110 --> 01:12:21.940
Because it's not
advertised as much,

01:12:21.940 --> 01:12:24.820
perhaps that's
why maybe we spend

01:12:24.820 --> 01:12:27.590
some time resting on our laurels
from the '70s or whatever.

01:12:27.590 --> 01:12:33.018
And maybe that's why we're
progressing less quickly

01:12:33.018 --> 01:12:33.685
in other places.

01:12:37.600 --> 01:12:40.450
AUDIENCE: To bring in the
question you asked earlier,

01:12:40.450 --> 01:12:45.200
Chris, I really like
the diagram, I guess,

01:12:45.200 --> 01:12:48.580
he poses on page 161.

01:12:48.580 --> 01:12:58.400
I guess I can zoom into it on my
computer, where he essentially

01:12:58.400 --> 01:13:02.290
shows where each of
these fit on the models.

01:13:02.290 --> 01:13:06.530
And I like this trend line was
in between intentional spinoff

01:13:06.530 --> 01:13:08.600
and explicit dual use.

01:13:08.600 --> 01:13:10.610
And I appreciate
that in particular,

01:13:10.610 --> 01:13:12.440
because I think it
really highlights--

01:13:12.440 --> 01:13:14.990
and even within the context
of him choosing those as case

01:13:14.990 --> 01:13:15.740
studies--

01:13:15.740 --> 01:13:17.660
a point that he had made
towards the beginning

01:13:17.660 --> 01:13:20.158
on structural attributes
of the United States.

01:13:20.158 --> 01:13:21.950
And he argues something
along the lines of,

01:13:21.950 --> 01:13:24.470
structural attributes determine
industrial policymaking

01:13:24.470 --> 01:13:25.520
capabilities.

01:13:25.520 --> 01:13:28.430
And the US has deficiencies
in industrial policymaking,

01:13:28.430 --> 01:13:30.620
because we don't care,
or rather because we

01:13:30.620 --> 01:13:33.750
don't put an
emphasis on creating

01:13:33.750 --> 01:13:35.150
that policy explicitly.

01:13:35.150 --> 01:13:37.040
And I guess I question
how much of that

01:13:37.040 --> 01:13:41.680
is, I guess, a cultural
barrier almost, that we have,

01:13:41.680 --> 01:13:45.020
or a perception barrier, more
so than a policymaking barrier.

01:13:45.020 --> 01:13:49.820
Because if policymakers
don't conceive of themselves

01:13:49.820 --> 01:13:52.860
as change agents, maybe--

01:13:52.860 --> 01:13:56.350
was there a reading in this
concept for this week that--

01:13:56.350 --> 01:13:59.725
was it yours, Bill,
the fifth reading?

01:13:59.725 --> 01:14:01.100
Yeah, that talked
about changing,

01:14:01.100 --> 01:14:02.933
because if policymakers
don't see themselves

01:14:02.933 --> 01:14:05.540
as change agents within
the economic context,

01:14:05.540 --> 01:14:08.090
and they feel like that should
be left up to private markets,

01:14:08.090 --> 01:14:10.970
then they might not feel like
it is their position or even

01:14:10.970 --> 01:14:12.890
something in their
area of expertise

01:14:12.890 --> 01:14:14.740
to promote industrial
policymaking

01:14:14.740 --> 01:14:16.610
as a key to economic growth.

01:14:16.610 --> 01:14:20.420
But if, I guess, someone
were to articulate--

01:14:20.420 --> 01:14:21.890
or maybe, Bill, that was you.

01:14:21.890 --> 01:14:23.610
Maybe that was your position
in the Senate, right?

01:14:23.610 --> 01:14:25.652
If there was someone who
was clearly articulating

01:14:25.652 --> 01:14:27.740
the link between
industrial policymaking

01:14:27.740 --> 01:14:33.840
and economic growth as of the
utmost importance, then maybe

01:14:33.840 --> 01:14:35.070
they would do it more often.

01:14:35.070 --> 01:14:39.180
So I think that's where
that diagram that he draws

01:14:39.180 --> 01:14:41.640
is really important in
establishing that trend

01:14:41.640 --> 01:14:43.410
line between intentional
M off modeling

01:14:43.410 --> 01:14:45.000
and the explicit dual use model.

01:14:45.000 --> 01:14:47.370
Because it is perhaps
precisely trending

01:14:47.370 --> 01:14:50.130
towards explicit dual
use that you can convince

01:14:50.130 --> 01:14:54.780
policymakers to invest in
R&D, and not in basic research

01:14:54.780 --> 01:14:58.780
and not explicitly at
the hands of the market.

01:14:58.780 --> 01:15:02.270
WILLIAM BONVILLIAN: Chris,
do you want to react?

01:15:02.270 --> 01:15:03.536
AUDIENCE: Yes.

01:15:03.536 --> 01:15:05.530
AUDIENCE: That was a lot.

01:15:07.708 --> 01:15:09.500
WILLIAM BONVILLIAN:
No, go ahead, go ahead.

01:15:09.500 --> 01:15:10.625
AUDIENCE: Oh, no, go ahead.

01:15:10.625 --> 01:15:12.730
I'm still trying to
gather my thoughts.

01:15:12.730 --> 01:15:14.032
WILLIAM BONVILLIAN: Yeah, no.

01:15:14.032 --> 01:15:16.490
I'll say just a couple words,
then Rasheed and then, Chris.

01:15:19.480 --> 01:15:22.540
Industrial policy is a negative
term in the United States.

01:15:22.540 --> 01:15:26.650
And what it's come to suggest is
that the government is playing

01:15:26.650 --> 01:15:29.320
a role, intervening
in the marketplace

01:15:29.320 --> 01:15:32.650
to pick, as the phrase
goes, winners and losers--

01:15:32.650 --> 01:15:34.900
in other words, who's going
to be the successful firms

01:15:34.900 --> 01:15:37.030
and who's not.

01:15:37.030 --> 01:15:40.570
And what Glenn is arguing
is, like it or not,

01:15:40.570 --> 01:15:45.160
as the military moves into these
very applied areas in the IT

01:15:45.160 --> 01:15:49.420
revolution, it is playing
an industrial policy,

01:15:49.420 --> 01:15:53.470
industrial organizational
kind of role, like it or not.

01:15:53.470 --> 01:15:56.650
And even though we deny we have
industrial policy in the United

01:15:56.650 --> 01:16:00.660
States, Glenn is arguing,
look, as a practical matter,

01:16:00.660 --> 01:16:02.150
the Defense
Department definitely

01:16:02.150 --> 01:16:04.470
has tendencies in
this direction.

01:16:04.470 --> 01:16:07.640
So this is a debate about pros
and cons of industrial policy.

01:16:07.640 --> 01:16:09.530
I think Glenn is
arguing, you want

01:16:09.530 --> 01:16:11.090
to see these
technologies stood up,

01:16:11.090 --> 01:16:13.382
you're going to have to think
about how you're actually

01:16:13.382 --> 01:16:16.190
organizing to implement them.

01:16:16.190 --> 01:16:18.130
AUDIENCE: As a
quick followup, do

01:16:18.130 --> 01:16:20.710
you think that he would argue
that calling it by its name

01:16:20.710 --> 01:16:22.060
is important?

01:16:22.060 --> 01:16:25.150
Rather than having these sort of
disambiguations about research

01:16:25.150 --> 01:16:26.890
and development
funding, we really

01:16:26.890 --> 01:16:28.690
talk about it in
an economic sense

01:16:28.690 --> 01:16:29.910
as industrial policymaking.

01:16:29.910 --> 01:16:32.110
And if we call it
like it is, then

01:16:32.110 --> 01:16:35.020
perhaps we would sort
of destigmatize market

01:16:35.020 --> 01:16:37.335
interventions, at
least in this context.

01:16:37.335 --> 01:16:38.710
WILLIAM BONVILLIAN:
You're right.

01:16:38.710 --> 01:16:43.630
We invent a lot of phrases
to not use that term.

01:16:43.630 --> 01:16:46.780
For example, in the
civilian research side,

01:16:46.780 --> 01:16:49.510
when the Advanced Technology
Program is being put together

01:16:49.510 --> 01:16:53.110
that funds industry-applied
research projects,

01:16:53.110 --> 01:16:56.680
the argument is, this is
not industrial policy.

01:16:56.680 --> 01:16:59.440
We are funding
pre-competitive research,

01:16:59.440 --> 01:17:02.320
which is going to land and
be accessible to a number

01:17:02.320 --> 01:17:03.760
of firms.

01:17:03.760 --> 01:17:06.490
So we're not particularly
picking one firm as opposed

01:17:06.490 --> 01:17:07.480
to another.

01:17:07.480 --> 01:17:10.560
We're funding pre-competitive
research that will benefit all.

01:17:10.560 --> 01:17:13.060
And that's not a bad theory.

01:17:13.060 --> 01:17:16.090
There are issues, as
Charles Shultze taught us,

01:17:16.090 --> 01:17:18.690
about governmental intervention
and industrial policy.

01:17:18.690 --> 01:17:21.970
This is not a simple landscape.

01:17:21.970 --> 01:17:23.620
It's rife with problems.

01:17:23.620 --> 01:17:26.050
We'll get to In-Q-Tel as
soon as we take a break.

01:17:26.050 --> 01:17:29.980
But that's the ultimate
interventionist governmental

01:17:29.980 --> 01:17:30.940
mechanism.

01:17:30.940 --> 01:17:32.650
But Rashid, go ahead.

01:17:32.650 --> 01:17:33.548
You had a point.

01:17:33.548 --> 01:17:35.590
AUDIENCE: There are two
things that are separate.

01:17:35.590 --> 01:17:38.267
I think one, very
quickly, is DARPA.

01:17:38.267 --> 01:17:39.850
I think it was in
one of the readings.

01:17:39.850 --> 01:17:45.310
They do actually, at each stage
of their project development,

01:17:45.310 --> 01:17:48.040
they sort of kind of have you
hash out just a white paper,

01:17:48.040 --> 01:17:51.010
identifying what would be the
potential commercial impacts

01:17:51.010 --> 01:17:54.260
of this research if it
were to go to market.

01:17:54.260 --> 01:17:56.625
So they have sort
of staged places

01:17:56.625 --> 01:17:58.000
where they're
thinking about, how

01:17:58.000 --> 01:18:00.730
are we going to
transition in toward

01:18:00.730 --> 01:18:03.780
to this byproduct
intentional spinoff

01:18:03.780 --> 01:18:05.020
in an explicit dual use.

01:18:05.020 --> 01:18:06.580
Because they
realized like, yeah,

01:18:06.580 --> 01:18:08.447
we're doing research,
that's great for us.

01:18:08.447 --> 01:18:10.780
But obviously, this is going
to have benefits elsewhere.

01:18:10.780 --> 01:18:12.880
But I think what's
important is DARPA actually

01:18:12.880 --> 01:18:14.600
has stages where they
identify, and they

01:18:14.600 --> 01:18:15.850
make you sort of write it out.

01:18:15.850 --> 01:18:17.620
And it's not
punitive or binding.

01:18:17.620 --> 01:18:19.503
But they say that
they're thinking about,

01:18:19.503 --> 01:18:21.670
how are we going to actually
transition this defense

01:18:21.670 --> 01:18:24.330
research into
commercial applications?

01:18:24.330 --> 01:18:25.510
And that's really important.

01:18:25.510 --> 01:18:28.630
Because they're kind of
speeding through a lot of steps

01:18:28.630 --> 01:18:33.490
here in the R&D space, by
putting so much money in it,

01:18:33.490 --> 01:18:37.300
doing these high risk,
high reward opportunities.

01:18:37.300 --> 01:18:39.100
But they're thinking
actively about how

01:18:39.100 --> 01:18:41.200
they're going to
benefit the consumer

01:18:41.200 --> 01:18:42.670
and commercial efforts.

01:18:42.670 --> 01:18:45.520
And then two, I
think policymakers

01:18:45.520 --> 01:18:47.380
as change agents is pretty key.

01:18:47.380 --> 01:18:50.230
And Martin and Steph kind
of hit on it a little bit.

01:18:50.230 --> 01:18:52.470
But I think it's just a
different way of thinking.

01:18:52.470 --> 01:18:54.220
And maybe it's just
calling it like it is.

01:18:54.220 --> 01:18:57.640
Maybe it's just saying,
industrial policy or kind

01:18:57.640 --> 01:19:01.120
of adopting these
methods, without--

01:19:01.120 --> 01:19:03.760
so adopting the best of what we
like about industrial policy,

01:19:03.760 --> 01:19:05.885
which is this byproduct
model and all these things,

01:19:05.885 --> 01:19:08.020
without really
getting into picking

01:19:08.020 --> 01:19:12.230
winners and losers, sort of
this In-Q-Tell kind of mechanism

01:19:12.230 --> 01:19:12.730
here.

01:19:12.730 --> 01:19:15.730
And I think it might be a
little bit easier to decide what

01:19:15.730 --> 01:19:17.770
we like about industrial
policy if we just

01:19:17.770 --> 01:19:19.420
call it industrial
policy instead

01:19:19.420 --> 01:19:21.400
of just avoiding market
intervention as a term

01:19:21.400 --> 01:19:22.210
entirely.

01:19:22.210 --> 01:19:25.415
Like if you just decided, yes,
it's a market intervention,

01:19:25.415 --> 01:19:27.040
and yes, we're doing
industrial policy,

01:19:27.040 --> 01:19:29.272
but we want to do this
kind of market intervention

01:19:29.272 --> 01:19:30.730
and this kind of
industrial policy,

01:19:30.730 --> 01:19:33.560
instead of kind of masking
it with ambiguous terms,

01:19:33.560 --> 01:19:35.000
things might get
a little easier.

01:19:35.000 --> 01:19:38.290
And then third, I think
the call for things

01:19:38.290 --> 01:19:40.270
is a nice way to
get around this.

01:19:40.270 --> 01:19:42.680
So I think there's
a lot of examples

01:19:42.680 --> 01:19:45.495
about the government putting
out calls and initiations.

01:19:45.495 --> 01:19:46.870
And even DARPA
kind of does this,

01:19:46.870 --> 01:19:47.953
where they initiate calls.

01:19:47.953 --> 01:19:50.218
They say, we'd
like to do research

01:19:50.218 --> 01:19:51.760
in this particular
area, or we'd like

01:19:51.760 --> 01:19:53.135
to solve this
particular problem.

01:19:56.385 --> 01:19:58.510
And it's not a way to pick
these winners and losers

01:19:58.510 --> 01:19:59.468
and decide who does it.

01:19:59.468 --> 01:20:04.480
But like, the person who comes
up with the best proposal

01:20:04.480 --> 01:20:06.430
and can prove that
they can meet these

01:20:06.430 --> 01:20:08.290
staged deadlines
will win in the end.

01:20:08.290 --> 01:20:11.070
And it's a pretty
tried and true method

01:20:11.070 --> 01:20:12.880
you see in things like that.

01:20:12.880 --> 01:20:16.450
But it's just like, are we
giving room for policymakers

01:20:16.450 --> 01:20:19.390
to make these same
judgments and put out

01:20:19.390 --> 01:20:23.080
these calls for advancements
in R&D funding and all

01:20:23.080 --> 01:20:26.140
these other things, with
these staged metrics.

01:20:26.140 --> 01:20:27.640
WILLIAM BONVILLIAN:
So Chris, do you

01:20:27.640 --> 01:20:30.520
want to give us some closing
thoughts on Glenn Fong's work?

01:20:30.520 --> 01:20:31.390
AUDIENCE: Sure.

01:20:31.390 --> 01:20:33.850
So I guess the general
theme that we've

01:20:33.850 --> 01:20:36.640
been talking about is that
industrial policy in the US

01:20:36.640 --> 01:20:41.230
is kind of obscured or
hidden behind these programs,

01:20:41.230 --> 01:20:42.370
by the DOD.

01:20:42.370 --> 01:20:46.810
And they're only manifested
when innovations are really

01:20:46.810 --> 01:20:53.290
pushed towards that
explicit competitiveness.

01:20:53.290 --> 01:20:56.950
And he claims that
increasing US capacity

01:20:56.950 --> 01:20:58.990
to undertake these
programs is directly

01:20:58.990 --> 01:21:02.463
relevant to economic
competitiveness.

01:21:02.463 --> 01:21:03.880
Which is interesting,
because this

01:21:03.880 --> 01:21:05.800
is kind of in direct
contrast to what

01:21:05.800 --> 01:21:09.100
we've been talking about in
some of the past lectures,

01:21:09.100 --> 01:21:11.650
that there's this post-war
paradigm, that they're

01:21:11.650 --> 01:21:15.140
focusing government
R&D to basic research.

01:21:15.140 --> 01:21:19.870
Or I believe he calls
it like mission agency.

01:21:19.870 --> 01:21:22.410
So I think this is a
pretty interesting reading.

01:21:22.410 --> 01:21:25.080
And also, I guess,
a side point was

01:21:25.080 --> 01:21:28.200
that, one thing that came up
for me was this kind of conflict

01:21:28.200 --> 01:21:31.140
between a focus on
economic competitiveness

01:21:31.140 --> 01:21:35.430
and more I guess social
impacts or ramifications that

01:21:35.430 --> 01:21:40.510
could result. Like he mentions
a couple of times that,

01:21:40.510 --> 01:21:44.550
like welfare policies and
stuff aren't considered

01:21:44.550 --> 01:21:46.080
economic competitiveness.

01:21:46.080 --> 01:21:52.410
And using those as metrics
isn't exactly a good way

01:21:52.410 --> 01:21:55.090
to look at competitiveness.

01:21:55.090 --> 01:21:57.840
And I thought that was a
really interesting way to kind

01:21:57.840 --> 01:22:01.530
of segregate, I
guess, the impact

01:22:01.530 --> 01:22:03.298
of these kind of programs.

01:22:03.298 --> 01:22:05.340
And obviously, they're
two very different things.

01:22:05.340 --> 01:22:09.600
And DOD probably has
to stay out of it.

01:22:09.600 --> 01:22:11.400
And just like we've
been mentioning,

01:22:11.400 --> 01:22:13.290
can't really pick
winners or losers.

01:22:13.290 --> 01:22:15.540
But yeah, I thought that
was another interesting kind

01:22:15.540 --> 01:22:17.780
of subtext theme.