WEBVTT

00:00:00.500 --> 00:00:01.984
[SQUEAKING]

00:00:01.984 --> 00:00:03.968
[RUSTLING]

00:00:03.968 --> 00:00:07.440
[CLICKING]

00:00:16.337 --> 00:00:18.920
VIJAY GADEPALLY: I hope you all
are enjoying the class so far.

00:00:18.920 --> 00:00:20.730
It's always
interesting-- we have

00:00:20.730 --> 00:00:22.440
people with a variety
of backgrounds

00:00:22.440 --> 00:00:26.130
here, so it's just great to kind
of hear the questions as we're

00:00:26.130 --> 00:00:27.460
going along.

00:00:27.460 --> 00:00:30.870
So I'm going to
give a quick example

00:00:30.870 --> 00:00:33.180
to begin the class right
now that kind of drive

00:00:33.180 --> 00:00:35.338
in some of the concepts
that we talked about

00:00:35.338 --> 00:00:36.130
on the first class.

00:00:36.130 --> 00:00:37.770
But this is kind
of real rather than

00:00:37.770 --> 00:00:39.860
sort of cartoon neural networks.

00:00:39.860 --> 00:00:43.950
But it's sort of a real
research result that we have.

00:00:43.950 --> 00:00:45.627
Before I begin,
I'd like to thank

00:00:45.627 --> 00:00:47.460
Emily Do who was one
of my graduate students

00:00:47.460 --> 00:00:48.770
who actually did all the work.

00:00:48.770 --> 00:00:50.940
I just put some of the
slides together-- not even

00:00:50.940 --> 00:00:52.500
all of them, just a few.

00:00:52.500 --> 00:00:55.920
So really, the credit for
this work goes to Emily.

00:00:55.920 --> 00:00:59.580
Anything I misrepresent
is my fault, not hers.

00:00:59.580 --> 00:01:03.330
She graduated, so I'll
take the blame for anything

00:01:03.330 --> 00:01:04.330
that's not interesting.

00:01:04.330 --> 00:01:07.680
So with that, we'll begin.

00:01:07.680 --> 00:01:09.780
All right, so the overall
goal of this project

00:01:09.780 --> 00:01:12.180
was really to detect and
classify network attacks

00:01:12.180 --> 00:01:13.990
from real internet traffic.

00:01:13.990 --> 00:01:16.950
And in order to do this,
as many of you can imagine,

00:01:16.950 --> 00:01:19.000
we had to find a data
set that was of interest.

00:01:19.000 --> 00:01:20.370
So this is probably
a problem many of you

00:01:20.370 --> 00:01:21.840
are currently
thinking about, which

00:01:21.840 --> 00:01:24.810
is what data set should
I get my hands on?

00:01:24.810 --> 00:01:26.700
Right, so we have a
variety of data sets.

00:01:26.700 --> 00:01:28.380
Some are sensitive
in nature, right?

00:01:28.380 --> 00:01:31.140
So think of internal
network traffic

00:01:31.140 --> 00:01:32.520
that we're trying to collect.

00:01:32.520 --> 00:01:36.600
No one's going to let us hand
this over to graduate students

00:01:36.600 --> 00:01:39.565
to kind of work on, and then
more importantly, publish.

00:01:39.565 --> 00:01:41.190
So the first thing
that we wanted to do

00:01:41.190 --> 00:01:45.060
was look for a data set that
was kind of open and out there.

00:01:45.060 --> 00:01:48.480
And we're fortunate that there
is a group in Japan called

00:01:48.480 --> 00:01:51.420
the MAWI working group, which
stands for the measurement--

00:01:51.420 --> 00:01:53.270
and I'll use my cool tool--

00:01:53.270 --> 00:01:55.500
the measurement and
analysis of wide area

00:01:55.500 --> 00:01:57.450
internet traffic
working group, that

00:01:57.450 --> 00:02:00.000
actually has 10 gig
link that they've

00:02:00.000 --> 00:02:01.868
tapped using a network tap.

00:02:01.868 --> 00:02:03.660
And they actually make
this data available.

00:02:03.660 --> 00:02:07.060
It's actually continuously
updated even to today.

00:02:07.060 --> 00:02:10.919
So that's really cool,
and this is within that.

00:02:10.919 --> 00:02:14.460
It's called the Day-in-the-Life
of the Internet.

00:02:14.460 --> 00:02:17.670
And so this has been going
on for multiple years.

00:02:17.670 --> 00:02:20.190
The data set is reasonably
large when you convert it

00:02:20.190 --> 00:02:22.740
into what we call an
analyst friendly form, which

00:02:22.740 --> 00:02:26.130
is something that you or I could
read and make some sense out

00:02:26.130 --> 00:02:26.630
of.

00:02:03:14.386 --> 00:03:16.297
take the results
of the manipulation

00:03:16.297 --> 00:03:17.890
back into the real world.

00:03:17.890 --> 00:03:21.367
That's a really productive
way to think about things

00:03:21.367 --> 00:03:26.800
and, really, the basis for a
lot of what we do here at MIT.

00:03:26.800 --> 00:03:32.828
This concept is essentially
the basis of modern

00:03:32.828 --> 00:03:37.349
or ancient Western
thought on mathematics.

00:03:37.349 --> 00:03:39.595
If you remember your
history courses,

00:03:39.595 --> 00:03:42.590
this concept of ideal
shapes and ideal circles

00:03:42.590 --> 00:03:47.810
is the foundation of
platonic mathematics

00:03:47.810 --> 00:03:51.290
some 2,500 years ago.

00:03:51.290 --> 00:03:55.509
And at the time, though,
that they were developing

00:03:55.509 --> 00:03:58.322
that concept, this
idea that there

00:03:58.322 --> 00:04:01.307
are ideal shapes out there
and that thinking about them

00:04:01.307 --> 00:04:03.579
and manipulating them
was a more effective way

00:04:03.579 --> 00:04:09.349
to reason about the real world,
there was a lot of skepticism.

00:04:09.349 --> 00:04:11.033
You could imagine
2,500 years ago

00:04:11.033 --> 00:04:12.717
someone is walking
around and saying,

00:04:12.717 --> 00:04:15.036
I believe there are
these things called

00:04:15.036 --> 00:04:17.988
ideal circles and ideal
squares and ideal shapes.

00:04:17.988 --> 00:04:20.829
But they don't actually
exist in nature.

00:04:20.829 --> 00:04:22.839
That would probably
not be well-received.

00:04:22.839 --> 00:04:25.749
In fact, it was
not well-received.

00:04:25.749 --> 00:04:31.674
Many of those philosophers
who were thinking about this

00:04:31.674 --> 00:04:34.308
were very negatively received.

00:04:34.308 --> 00:04:36.744
And, in fact, if
you want to learn

00:04:36.744 --> 00:04:39.180
about how negative the
response was to this,

00:04:39.180 --> 00:04:43.211
I encourage you to go and read
the Allegory of the Cave, which

00:04:43.211 --> 00:04:45.623
is essentially the story of
these philosophers talking

00:04:45.623 --> 00:04:47.027
about how they're
trying to bring

00:04:47.027 --> 00:04:49.233
the light of this knowledge
to the broader world

00:04:49.233 --> 00:04:52.239
and how they essentially
get killed because of it,

00:04:52.239 --> 00:04:54.909
because people don't
want to see it.

00:04:54.909 --> 00:04:58.639
So that struggle they
experienced 2,500 years ago,

00:04:58.639 --> 00:05:00.039
it exists today.

00:05:00.039 --> 00:05:04.322
You as people at MIT will try
and bring mathematical concepts

00:05:04.322 --> 00:05:06.407
into environments
where people are like,

00:05:06.407 --> 00:05:07.740
I don't see why that's relevant.

00:05:07.740 --> 00:05:12.050
And you will experience
negative inputs.

00:05:12.050 --> 00:05:16.119
But you should rest assured
that this is a good bet.

00:05:16.119 --> 00:05:18.759
It's worked well for
thousands of years.

00:05:18.759 --> 00:05:20.789
You know, it's what
I base my career on.

00:05:20.789 --> 00:05:22.622
People ask me, well,
what's the basis of it?

00:05:22.622 --> 00:05:24.159
Well, I'm just
betting on math here.

00:05:24.159 --> 00:05:26.100
It's been a good tool.

00:05:26.100 --> 00:05:29.704
So this is why we're beginning
to think this way when

00:05:29.704 --> 00:05:32.999
we talk about big data
and machine learning.

00:05:32.999 --> 00:05:35.560
So really looking at
the fundamentals, what

00:05:35.560 --> 00:05:39.557
are the ideals that we need
in order to effectively reason

00:05:39.557 --> 00:05:41.928
about the problems
that we're facing today

00:05:41.928 --> 00:05:44.906
in the virtual world,
right, and the fact

00:05:44.906 --> 00:05:50.363
that this mathematical concept
described the natural world so

00:05:50.363 --> 00:05:54.422
well and also described
in the virtual world

00:05:54.422 --> 00:05:56.872
is sometimes called the
unreasonable effectiveness

00:05:56.872 --> 00:05:57.689
of mathematics.

00:05:57.689 --> 00:05:58.689
You can look that up.

00:05:58.689 --> 00:06:00.889
But people talk about math.

00:06:00.889 --> 00:06:04.539
Why does it do such a good job
of describing so many things?

00:06:04.539 --> 00:06:07.319
And people say, well,
they don't really know.

00:06:07.319 --> 00:06:11.379
But it seems to be a good bit of
luck that it happens that way.

00:06:11.379 --> 00:06:16.449
So circles, that gets
us a certain way.

00:06:16.449 --> 00:06:20.770
But in most of the
fields that we work with,

00:06:20.770 --> 00:06:25.096
and I would say that, in
almost any introductory course

00:06:25.096 --> 00:06:29.030
that you take in college,
whatever the discipline is,

00:06:29.030 --> 00:06:32.620
whether it be chemistry
or mechanical engineering

00:06:32.620 --> 00:06:36.917
or electrical engineering
or physics or biology,

00:06:36.917 --> 00:06:39.725
the basic fundamental
theoretical ideas

00:06:39.725 --> 00:06:43.590
that they will
introduce to you will be

00:06:43.590 --> 00:06:46.490
the concept of a linear model.

00:06:46.490 --> 00:06:50.939
So there we have a
linear model, right?

00:06:50.939 --> 00:06:53.850
And why do we like
linear models?

00:06:53.850 --> 00:06:55.058
And again, it can be physics.

00:06:55.058 --> 00:06:59.429
It can be as simple as F
= MA Or, in chemistry, it

00:06:59.429 --> 00:07:02.119
can be some kind of
chemical rate equation.

00:07:02.119 --> 00:07:04.873
Or in mechanical
engineering it can

00:07:04.873 --> 00:07:07.169
be basic concepts of friction.

00:07:07.169 --> 00:07:11.181
The reason we like these
basic linear models

00:07:11.181 --> 00:07:14.190
is because we can
project, right?

00:07:14.190 --> 00:07:17.283
I know that if that
solid line represents

00:07:17.283 --> 00:07:20.376
what I believe
to-- you know, if I

00:07:20.376 --> 00:07:23.287
have evidence to support
that that is correct,

00:07:23.287 --> 00:07:27.231
then I feel pretty good about
projecting maybe where I don't

00:07:27.231 --> 00:07:29.909
have data or into a new domain.

00:07:29.909 --> 00:07:33.308
So linear models allow
us to do this reasoning.

00:07:33.308 --> 00:07:36.749
And that's why in the
first few weeks of almost

00:07:36.749 --> 00:07:40.029
any introductory course they
begin with these linear models,

00:07:40.029 --> 00:07:43.509
because they have proven
to be so effective.

00:07:43.509 --> 00:07:47.645
Now, there are many
non-linear phenomena that

00:07:47.645 --> 00:07:50.009
are tremendously important, OK?

00:07:50.009 --> 00:07:54.239
And as a person who deals
with large-scale computation,

00:07:54.239 --> 00:07:58.529
those are a staple
of what people do.

00:07:58.529 --> 00:08:02.341
But in order to do non-linear
calculations or reason

00:08:02.341 --> 00:08:04.459
about things
non-linearly, it usually

00:08:04.459 --> 00:08:09.325
requires a much more complicated
analysis and much more

00:08:09.325 --> 00:08:11.489
computation, much more data.

00:08:11.489 --> 00:08:14.783
And so our ability
to extrapolate

00:08:14.783 --> 00:08:16.979
is very limited, OK?

00:08:16.979 --> 00:08:18.120
It's very limited.

00:08:18.120 --> 00:08:23.205
So here I am talking
about the benefits

00:08:23.205 --> 00:08:27.020
of thinking mathematically,
talking about linearity.

00:08:27.020 --> 00:08:32.679
What does this have to do with
big data and machine learning?

00:08:32.679 --> 00:08:37.096
So we would like to be able to
do the same things that we've

00:08:37.096 --> 00:08:41.795
been able to do in other
fields in this new emerging

00:08:41.795 --> 00:08:44.039
field of big data.

00:08:44.039 --> 00:08:47.399
And this often
deals with data that

00:08:47.399 --> 00:08:50.759
doesn't look like the
traditional measurements we

00:08:50.759 --> 00:08:53.350
see in science.

00:08:53.350 --> 00:08:58.778
This can be data that has to do
with words or images, pictures

00:08:58.778 --> 00:09:01.831
of people, other types
of things that don't feel

00:09:01.831 --> 00:09:04.043
like the kinds of data
that we traditionally

00:09:04.043 --> 00:09:06.899
deal with in science
and engineering.

00:09:06.899 --> 00:09:11.350
But we know we want
to use linear models.

00:09:11.350 --> 00:09:13.259
So how are we going to do that?

00:09:13.259 --> 00:09:15.689
How can we take this
concept of linearity,

00:09:15.689 --> 00:09:18.558
which has been so powerful
across so many disciplines,

00:09:18.558 --> 00:09:21.627
and bring them to
this field that

00:09:21.627 --> 00:09:25.394
just feels completely
different than the kinds data

00:09:25.394 --> 00:09:26.970
that we have?

00:09:26.970 --> 00:09:33.806
So to begin with, I need to
refresh for you what it really

00:09:33.806 --> 00:09:35.910
means to be linear.

00:09:35.910 --> 00:09:39.470
Before, I showed you a line
and, hence, the line, linear.

00:09:39.470 --> 00:09:43.720
But mathematically, linearity
means something much deeper.

00:09:43.720 --> 00:09:48.591
And so here's an equation
that you may have first seen

00:09:48.591 --> 00:09:49.920
in elementary school.

00:09:49.920 --> 00:09:52.316
We basically have
to two times three

00:09:52.316 --> 00:09:57.120
plus four is equal to two times
three plus two times four.

00:09:57.120 --> 00:09:59.250
That is called the
distributive property.

00:09:59.250 --> 00:10:03.810
It basically says multiplication
distributes over addition.

00:10:03.810 --> 00:10:06.198
And this is the
fundamental reason

00:10:06.198 --> 00:10:10.180
why I would say mathematics
works in our world, right?

00:10:10.180 --> 00:10:14.103
If this wasn't true very
early on in the earliest

00:10:14.103 --> 00:10:16.850
days of inventing
mathematics, it would not

00:10:16.850 --> 00:10:19.050
have been very useful, right?

00:10:19.050 --> 00:10:24.030
To say that I have two of three
plus four of something, OK,

00:10:24.030 --> 00:10:27.559
and then I can
change it and do it

00:10:27.559 --> 00:10:31.660
in this other way, that's really
what makes mathematics useful.

00:10:31.660 --> 00:10:36.562
And from a deeper perspective,
the distributive property

00:10:36.562 --> 00:10:40.240
is basically what
makes math linear.

00:10:40.240 --> 00:10:44.713
This is the property that,
if this property holds,

00:10:44.713 --> 00:10:48.689
then we can reason
about a system linearly.

00:10:48.689 --> 00:10:52.289
Now, you're very familiar
with this type of mathematics,

00:10:52.289 --> 00:10:54.690
but there's other
types of mathematics.

00:10:54.690 --> 00:10:57.457
So if you'll allow
me, hopefully you

00:10:57.457 --> 00:11:00.620
will let me just replace
those multiplication symbols

00:11:00.620 --> 00:11:04.879
and addition symbols with this
funny circle times and circle

00:11:04.879 --> 00:11:05.379
plus.

00:11:05.379 --> 00:11:08.199
And we'll get to why
I'm going to do that.

00:11:08.199 --> 00:11:10.938
Because it turns
out that, while you

00:11:10.938 --> 00:11:14.487
have done most of your careers
with traditional arithmetic

00:11:14.487 --> 00:11:16.580
multiplication and
addition, the kind

00:11:16.580 --> 00:11:19.930
you would do on your
calculator or have

00:11:19.930 --> 00:11:24.015
done in elementary
school, it turns out

00:11:24.015 --> 00:11:26.934
there's other
pairs of operations

00:11:26.934 --> 00:11:31.229
that also obey this property,
this distributive property,

00:11:31.229 --> 00:11:34.659
and, therefore, allow
us to potentially build

00:11:34.659 --> 00:11:38.530
linear models of very
different types of data

00:11:38.530 --> 00:11:39.980
using this property.

00:11:39.980 --> 00:11:43.545
So, as I mentioned,
the classic two

00:11:43.545 --> 00:11:48.639
are circle plus is just equal
to regular arithmetic addition,

00:11:48.639 --> 00:11:51.918
as we show on the first
line, and circle times is

00:11:51.918 --> 00:11:53.709
equal to regular
arithmetic multiplication.

00:11:53.709 --> 00:11:55.779
So those are the standard ones.

00:11:55.779 --> 00:11:59.665
And, by far, this pair,
this is the most common pair

00:11:59.665 --> 00:12:02.139
that we use across
the world today.

00:12:02.139 --> 00:12:03.550
But there are others.

00:12:03.550 --> 00:12:09.753
So, for instance, I can
replace the plus operation

00:12:09.753 --> 00:1e I'm using other contexts. Maybe
it's next to a table or stuff like that. Some

00:12:29.760 --> 00:12:35.220
early research going on in that area. And
certainly, the next wave of this is what we

00:12:35.220 --> 00:12:39.230
call abstraction. And there is very little
work on this, but if we have to think out

00:12:39.230 --> 00:12:40.260
in the future.

00:12:40.260 --> 00:12:46.649
But this is really the system of the ability
of an AI system to actually abstract information

00:12:46.649 --> 00:12:51.870
that it's learning. So instead of learning
that a chair or a table is something with

00:12:51.870 --> 00:12:56.480
a leg at the bottom, it learns that a table
is something you put things on and is able

00:12:56.480 --> 00:13:04.350
to abstract that information or that knowledge
to any other domain or any other field. Do

00:13:04.350 --> 00:13:13.300
we have any questions before I continue from
here? OK, great.

00:13:13.300 --> 00:13:18.120
So that's a little bit on the evolution of
AI. The reason we like to go through this

00:13:18.120 --> 00:13:23.860
is because there is great work going on in
each of these waves. And nothing that people

00:13:23.860 --> 00:13:28.820
are doing in any of these waves is any lesser
or more. It's typically dependent on what

00:13:28.820 --> 00:13:31.100
you have at your disposal.

00:13:31.100 --> 00:13:35.280
What I like to tell people sometimes is the
way to think about all of this is you have

00:13:35.280 --> 00:13:41.570
a couple of dials at your disposal-- turning
dials. The first dial is, how much compute?

00:13:41.570 --> 00:13:47.870
Right? How much ability do you have to crunch
data? The second piece is, how much data do

00:13:47.870 --> 00:13:51.540
you actually have available? This can be labeled
data in many cases.

00:13:51.540 --> 00:13:56.471
And the third dial is, how much knowledge
are you able to embed into an algorithm? In

00:13:56.471 --> 00:14:02.370
certain cases where maybe you have very little
computing, very little labeled data availability,

00:14:02.370 --> 00:14:07.670
but a lot of expert knowledge or a lot of
ability to encode information into an algorithm,

00:14:07.670 --> 00:14:11.720
you might be able to use an expert system,
right? And that's a very good use case for

00:14:11.720 --> 00:14:12.720
that.

00:14:12.720 --> 00:14:17.870
An example may be on another dimension where
you want to encode very little human knowledge,

00:14:17.870 --> 00:14:22.529
but you have a lot of computing and data available,
would be rare neural networks fall in, where

00:14:22.529 --> 00:14:27.360
they're essentially learning what the human
knowledge-- what that encoded information

00:14:27.360 --> 00:14:28.360
should be.

00:14:28.360 --> 00:14:32.170
A lot of statistical techniques also fall
into that camp where maybe you encode a little

00:14:32.170 --> 00:14:37.519
bit of information as to what the background
distribution of the process is. But it learns

00:14:37.519 --> 00:14:44.170
the details of exactly how that distribution
is modeled, based on the data that it sees.

00:14:44.170 --> 00:14:48.230
So you have a lot of different settings that
you can use. And there are a number of different

00:14:48.230 --> 00:14:55.230
techniques within the broader AI context that
you can use to achieve your mission. And I'm

00:14:55.230 --> 00:15:01.050
sure many of you are going to be doing different
types of algorithms. And a lot of that decision

00:15:01.050 --> 00:15:06.139
will be dependent on, well, how much data
was I given? Right? How good is this data

00:15:06.139 --> 00:15:10.070
that I'm using? Is there an ability to learn
anything from this?

00:15:10.070 --> 00:15:13.670
And if not, you might have to encode some
knowledge of your own into it saying, well,

00:15:13.670 --> 00:15:19.649
I know that this process looks like that,
so let me tell the algorithm to not waste

00:15:19.649 --> 00:15:23.330
too much time crunching the data to learn
the underlying distribution, which I can tell

00:15:23.330 --> 00:15:28.279
you. Why don't you learn the pa:15:13.767 --> 00:15:16.749
and the linear equation
will still hold.

00:15:16.749 --> 00:15:22.385
And, in fact, that's probably
the key concept in big data,

00:15:22.385 --> 00:15:26.142
is the necessity to
reason about data

00:15:26.142 --> 00:15:30.920
as whole collections and
transforming whole collections.

00:15:30.920 --> 00:15:34.972
Going and looking at things
one element at a time

00:15:34.972 --> 00:15:40.249
is essentially the thing that is
extremely difficult to do when

00:15:40.249 --> 00:15:43.910
you have large amounts of data.

00:15:43.910 --> 00:15:50.730
A, B, and C can be
database tables, right?

00:15:50.730 --> 00:15:52.720
Those don't differ too
much from spreadsheets.

00:15:52.720 --> 00:15:57.220
And as I talked to you
in the previous slide,

00:15:57.220 --> 00:16:00.262
that union/intersection
pair naturally lines up

00:16:00.262 --> 00:16:05.812
and we can reason
about whole tables

00:16:05.812 --> 00:16:10.569
in a database using
linear properties.

00:16:10.569 --> 00:16:11.939
They can be matrices.

00:16:11.939 --> 00:16:15.433
I think, for those of you
who have had a linear algebra

00:16:15.433 --> 00:16:17.502
and matrix mathematics,
that would have been

00:16:17.502 --> 00:16:21.180
the first example, right, when
I substituted the A, B, and C

00:16:21.180 --> 00:16:23.689
and had these linear equations.

00:16:23.689 --> 00:16:27.539
Often, in many of
the sciences, we

00:16:27.539 --> 00:16:30.839
think about matrix
operations and linearity

00:16:30.839 --> 00:16:36.420
as being coupled together.

00:16:36.420 --> 00:16:39.762
And through the duality
between matrices and graphs

00:16:39.762 --> 00:16:43.314
and networks, we can
represent graphs and networks

00:16:43.314 --> 00:16:44.360
through matrices.

00:16:44.360 --> 00:16:47.308
Any time you work
with a neural network,

00:16:47.308 --> 00:16:49.889
you're representing that
network as a matrix.

00:16:49.889 --> 00:16:53.257
And, of course, all these
equations apply there as well

00:16:53.257 --> 00:16:56.889
and you can reason about
those systems linearly.

00:16:56.889 --> 00:17:03.529
So that provides a
little motivation there.

00:17:03.529 --> 00:17:05.950
As we like to say,
enough about me,

00:17:05.950 --> 00:17:08.069
let me tell you about my book.

00:17:08.069 --> 00:17:12.209
So this will be the text that
will we use in the class.

00:17:12.209 --> 00:17:15.745
We are not going to go
through the full text,

00:17:15.745 --> 00:17:19.623
but we have printed out copies
of the first seven chapters

00:17:19.623 --> 00:17:21.359
that we will go through.

00:17:21.359 --> 00:17:29.280
And we will hand those out
later when you do the class.

00:17:29.280 --> 00:17:33.055
So let me now switch
gears a little bit

00:17:33.055 --> 00:17:36.831
and talk about how this
relates to, I think,

00:17:36.831 --> 00:17:38.831
one of the most
wonderful breakthroughs

00:17:38.831 --> 00:17:41.992
that we have seen, or
I've seen in my career,

00:17:41.992 --> 00:17:45.489
and many of my colleagues
here at MIT have seen,

00:17:45.489 --> 00:17:48.670
which is what's been going
on in machine learning,

00:17:48.670 --> 00:17:53.760
right, which is-- it's not hype.

00:17:53.760 --> 00:17:58.450
There's a real real there there
and it's tremendously exciting.

00:17:58.450 --> 00:18:01.650
So let me give you a little
history, basic history

00:18:01.650 --> 00:18:02.610
of this field.

00:18:02.610 --> 00:18:08.707
So in a certain sense,
before 2010, machine learning

00:18:08.707 --> 00:18:10.740
looked like this.

00:18:10.740 --> 00:18:17.720
And then, after 2015, it
kind of looks like this.

00:18:17.720 --> 00:18:21.519
So when people talk about
the hype in machine learning,

00:18:21.519 --> 00:18:23.799
or AI, really deep
neural networks

00:18:23.799 --> 00:18:28.360
are the elephant inside
the machine learning snake.

00:18:28.360 --> 00:18:32.488
It has stormed onto the
scene in the last five years

00:18:32.488 --> 00:18:38.316
and basically allowed us to do
things that we had almost taken

00:18:38.316 --> 00:18:40.700
for granted were impossible.

00:18:40.700 --> 00:18:44.756
Just the fact that you're
able to talk to computers

00:18:44.756 --> 00:18:48.989
and they can understand you,
that we can have computers that

00:18:48.989 --> 00:18:53.693
can see at least in a way that
approximates the way humans do,

00:18:53.693 --> 00:18:55.997
these are really almost
technological miracles

00:18:55.997 --> 00:18:59.387
that, for those of us
who have been working

00:18:59.387 --> 00:19:02.884
on this field for fifty years,
we had almost literally given

00:19:02.884 --> 00:19:03.520
up on.

00:19:03.520 --> 00:19:06.710
And then all of a sudden
it became possible.

00:19:06.710 --> 00:19:09.796
So let me give you a little
sense of appreciation

00:19:09.796 --> 00:19:11.649
for this field and its roots.

00:19:11.649 --> 00:19:15.361
So machine learning,
like any field,

00:19:15.361 --> 00:19:20.929
is defined as a set of
techniques and problems.

00:19:20.929 --> 00:19:23.435
When you ask what defines
a field, you ask, well,

00:19:23.435 --> 00:19:26.552
what are the problems that they
work on that other fields don't

00:19:26.552 --> 00:19:27.370
really work on?

00:19:27.370 --> 00:19:30.635
And what are the techniques
they employ that really are not

00:19:30.635 --> 00:19:32.120
really being employed by them?

00:19:32.120 --> 00:19:35.706
So the core techniques,
as I mentioned earlier,

00:19:35.706 --> 00:19:37.500
are these neural networks.

00:19:37.500 --> 00:19:41.514
These are meant to crudely
approximate maybe the way

00:19:41.514 --> 00:19:43.299
humans think about problems.

00:19:43.299 --> 00:19:45.549
We have these circles
which are neurons.

00:19:45.549 --> 00:19:47.980
They have connections
to other neurons.

00:19:47.980 --> 00:19:50.612
You know, those connections
have different weights

00:19:50.612 --> 00:19:51.740
associated with them.

00:19:51.740 --> 00:19:53.636
As information
comes in, they get

00:19:53.636 --> 00:19:54.900
multiplied by those weights.

00:19:54.900 --> 00:19:56.240
They get summed together.

00:19:56.240 --> 00:19:58.842
And if they pass certain
thresholds or criteria,

00:19:58.842 --> 00:20:01.770
then they send a signal
on to another neuron.

00:20:01.770 --> 00:20:04.267
And this is, to
a certain degree,

00:20:04.267 --> 00:20:07.479
how we believe the
human brain works and is

00:20:07.479 --> 00:20:10.338
a natural starting
point for, how could

00:20:10.338 --> 00:20:13.020
we make computers
do similar things?

00:20:13.020 --> 00:20:17.484
The big problems that
people have worked on

00:20:17.484 --> 00:20:21.390
are these classic problems
in machine learning,

00:20:21.390 --> 00:20:24.955
are language, how do we
make computers understand

00:20:24.955 --> 00:20:28.520
human language, vision,
how do we make computers

00:20:28.520 --> 00:20:31.460
see pictures or explain
pictures back to us the way

00:20:31.460 --> 00:20:34.876
we would like, and strategy and
games and other types of things

00:20:34.876 --> 00:20:35.419
like that.

00:20:35.419 --> 00:20:38.390
So how do we get them
to solve problems?

00:20:38.390 --> 00:20:40.900
This is not new.

00:20:40.900 --> 00:20:45.557
These core concepts trace
back to the earliest days

00:20:45.557 --> 00:20:47.110
of the field.

00:20:47.110 --> 00:20:50.531
In fact, these four
figures here, each one

00:20:50.531 --> 00:20:53.952
is taken from a paper
that was presented

00:20:53.952 --> 00:20:58.041
at the very first
machine learning

00:20:58.041 --> 00:21:00.680
conference in the mid-1950s.

00:21:00.680 --> 00:21:03.179
So there was a machine learning
conference in the mid-1950s.

00:21:03.179 --> 00:21:06.370
It was in Los Angeles.

00:21:06.370 --> 00:21:09.700
It had four papers presented.

00:21:09.700 --> 00:21:12.930
These were the four papers.

00:21:12.930 --> 00:21:16.779
And I will say
that three of them

00:21:16.779 --> 00:21:21.110
were done by folks at MIT
Lincoln Laboratory, which

00:21:21.110 --> 00:21:22.570
is where I work.

00:21:22.570 --> 00:21:25.290
And so that was basically
the neural networks

00:21:25.290 --> 00:21:26.650
of language and vision.

00:21:26.650 --> 00:21:31.510
And we didn't play
games, so that was it.

00:21:31.510 --> 00:21:33.309
And you might say,
well, why is it?

00:21:33.309 --> 00:21:36.198
Why was there so
much work going on

00:21:36.198 --> 00:21:38.366
in Lincoln Laboratory
in the mid-1950s

00:21:38.366 --> 00:21:43.740
that they would want to
pioneer in these directions?

00:21:43.740 --> 00:21:48.065
At that time, people were
first building computers

00:21:48.065 --> 00:21:51.310
and computers were
very special purpose.

00:21:51.310 --> 00:21:53.691
So different organizations
around the world

00:21:53.691 --> 00:21:56.470
were building computers
to do different things.

00:21:56.470 --> 00:22:06.886
Some were doing them to simulate
complex fluid dynamics systems,

00:22:06.886 --> 00:22:11.097
think about designing
ships or other types

00:22:11.097 --> 00:22:13.650
of things like
that or airplanes.

00:22:13.650 --> 00:22:17.162
Others were doing them to,
say, like what Alan Turing was

00:22:17.162 --> 00:22:18.120
doing, break codes.

00:22:18.120 --> 00:22:23.079
And our task was
to help people who

00:22:23.079 --> 00:22:27.419
were watching radar scopes
make decisions, right?

00:22:27.419 --> 00:22:32.761
How could computers enable
humans to watch more sensors

00:22:32.761 --> 00:22:35.730
and see where they're going?

00:22:35.730 --> 00:22:36.730
How could we do that?

00:22:36.730 --> 00:22:40.136
So at Lincoln Laboratory, we
were building special purpose

00:22:40.136 --> 00:22:41.650
computers to do this.

00:22:41.650 --> 00:22:46.257
And we built the
first large computer

00:22:46.257 --> 00:22:48.890
with reliable, fast memory.

00:22:48.890 --> 00:22:57.242
This system had 4,096 bytes
of memory, which, at the time,

00:22:57.242 --> 00:23:01.039
people thought was too much.

00:23:01.039 --> 00:23:06.490
What could you possibly
do with 4,096 numbers?

00:23:06.490 --> 00:23:08.710
The human brain, of course!

00:23:08.710 --> 00:23:10.169
Right, that's enough, right?

00:23:10.169 --> 00:23:13.590
Most of us can remember five,
six, seven digits, right?

00:23:13.590 --> 00:23:16.705
So a computer that can
remember 4,096 numbers

00:23:16.705 --> 00:23:20.790
should be able to do things
like language and vision

00:23:20.790 --> 00:23:21.760
and strategy.

00:23:21.760 --> 00:23:23.149
So why not?

00:23:23.149 --> 00:23:27.052
So they went out
and they started

00:23:27.052 --> 00:23:29.840
working on these problems, OK?

00:23:29.840 --> 00:23:33.400
But Lincoln Laboratory, being
an applied research laboratory,

00:23:33.400 --> 00:23:40.176
we are required to get answers
to our sponsors in a few years'

00:23:40.176 --> 00:23:41.350
time frame.

00:23:41.350 --> 00:23:44.341
If problems are going to
take longer than that,

00:23:44.341 --> 00:23:48.679
then they really are the
purview of the basic research

00:23:48.679 --> 00:23:50.019
community, universities.

00:23:50.019 --> 00:23:51.969
And it became
apparent pretty early

00:23:51.969 --> 00:23:55.220
on that this problem was
going to be more difficult.

00:23:55.220 --> 00:23:59.649
It was not going to
be solved right away.

00:23:59.649 --> 00:24:03.420
So we did what we often
do, is we partnered.

00:24:03.420 --> 00:24:07.266
We found some bright young
people at MIT, people

00:24:07.266 --> 00:24:08.549
just like yourselves.

00:24:08.549 --> 00:24:14.610
In this case, we found a young
professor named Marvin Minsky.

00:24:14.610 --> 00:24:18.950
And we said, why don't you go
and get some of your friends

00:24:18.950 --> 00:24:20.867
together and create
a meeting where

00:24:20.867 --> 00:24:23.096
you can lay out what the
fundamental challenges are

00:24:23.096 --> 00:24:23.840
of this field?

00:24:23.840 --> 00:24:26.885
And then we will figure out how
to get that funded so that you

00:24:26.885 --> 00:24:28.190
can go and do that research.

00:24:28.190 --> 00:24:32.116
And that was the famous
Dartmouth AI conference

00:24:32.116 --> 00:24:34.570
which kicked off the field.

00:24:34.570 --> 00:24:38.809
And the person leading this
group, Oliver Selfridge

00:24:38.809 --> 00:24:42.563
at Lincoln Laboratory, basically
arranged for that conference

00:24:42.563 --> 00:24:46.240
to happen and then subsequently
arranged for what would

00:24:46.240 --> 00:24:51.880
became the MIT AI Lab that was
founded by Professor Minsky.

00:24:51.880 --> 00:24:54.064
And likewise,
Professor Selfridge

00:24:54.064 --> 00:24:58.980
also realized that we would
need more computing power.

00:24:58.980 --> 00:25:01.530
So he left Lincoln
Laboratory and formed

00:25:01.530 --> 00:25:04.809
what was called Project MAC,
which became the Laboratory

00:25:04.809 --> 00:25:06.179
for Computer Science.

00:25:06.179 --> 00:25:11.640
And then those two entities
later merged 30 years later

00:25:11.640 --> 00:25:13.279
to become CSAIL.

00:25:13.279 --> 00:25:16.000
So that was the initial thing.

00:25:16.000 --> 00:25:20.199
Now, it was pretty clear that,
when this problem was handed

00:25:20.199 --> 00:25:22.490
off to the basic
research community,

00:25:22.490 --> 00:25:25.655
there was a feeling that
these problems would

00:25:25.655 --> 00:25:28.029
be solved in about a decade.

00:25:28.029 --> 00:25:32.404
So we were really
thinking by the mid-1960s

00:25:32.404 --> 00:25:36.779
is when these problems
would be really solved.

00:25:36.779 --> 00:25:40.639
So it's like giving someone
an assignment, right?

00:25:40.639 --> 00:25:43.360
You all are given
assignments by professors

00:25:43.360 --> 00:25:46.860
and they give you
a week to do it.

00:25:46.860 --> 00:25:49.460
But it took a little longer.

00:25:49.460 --> 00:25:55.294
In this case, it took five weeks
or, in this case, five decades

00:25:55.294 --> 00:25:57.090
to solve this problem.

00:25:57.090 --> 00:25:58.090
But we have.

00:25:58.090 --> 00:26:01.966
We have now really,
using those techniques,

00:26:01.966 --> 00:26:05.289
made tremendous progress
on those problems.

00:26:05.289 --> 00:26:07.740
But we don't know why it works.

00:26:07.740 --> 00:26:09.198
So we made this
tremendous progress

00:26:09.198 --> 00:26:09.770
but we don't really
understand why this works.

00:26:09.770 --> 00:26:12.490
So let me show you a little
bit what we have learned,

00:26:12.490 --> 00:26:15.084
and this course will explore
the deeper mathematics

00:26:15.084 --> 00:26:18.135
to help us gain insight.

00:26:18.135 --> 00:26:19.510
We still don't
know why it works.

00:26:19.510 --> 00:26:22.195
At least we can
lay the foundations

00:26:22.195 --> 00:26:24.880
and maybe you can figure it out.

00:26:24.880 --> 00:26:30.040
So here I am, fifty
years later, a person

00:26:30.040 --> 00:26:33.480
from Lincoln Laboratory
saying, "All right.

00:26:33.480 --> 00:26:36.030
Question one has been answered.

00:26:36.030 --> 00:26:37.370
Here's question two."

00:26:37.370 --> 00:26:38.370
Ha.

00:26:38.370 --> 00:26:41.357
Why does this work and
hopefully you can begin,

00:26:41.357 --> 00:26:43.150
be the generation
figured it out.

00:26:43.150 --> 00:26:45.140
Hopefully it'll take
less than fifty years.

00:26:45.140 --> 00:26:48.295
Historically this type
once we know how it works,

00:26:48.295 --> 00:26:51.970
it usually takes about twenty
years to figure out why.

00:26:51.970 --> 00:26:54.715
So I mean impasses
but maybe maybe you

00:26:54.715 --> 00:26:58.779
know some people are smarter and
they'll figure it out faster.

00:26:58.779 --> 00:27:05.870
So this is what a neural
network looks like.

00:27:05.870 --> 00:27:10.130
On the left you have your input,
in this case, a vector, y zero.

00:27:10.130 --> 00:27:15.090
It's just these dots
that are called features.

00:27:15.090 --> 00:27:17.760
What is a feature?

00:27:17.760 --> 00:27:20.210
Anything can be a feature.

00:27:20.210 --> 00:27:23.418
That is the power
of neural networks,

00:27:23.418 --> 00:27:28.002
is they don't require you
to a priori state what

00:27:28.002 --> 00:27:29.461
the inputs can be.

00:27:29.461 --> 00:27:31.130
They can be anything.

00:27:31.130 --> 00:27:32.506
People have said,
well, you know,

00:27:32.506 --> 00:27:33.921
neural networks,
machine learning,

00:27:33.921 --> 00:27:34.980
it's just curve fitting.

00:27:34.980 --> 00:27:38.380
Yeah, but it's curve fitting
without domain knowledge.

00:27:38.380 --> 00:27:42.065
Because domain knowledge
is so costly and expensive

00:27:42.065 --> 00:27:47.415
to create that having a
general system that can do this

00:27:47.415 --> 00:27:50.000
is really what's so powerful.

00:27:50.000 --> 00:27:52.480
So the inputs: we
have a input feature.

00:27:52.480 --> 00:27:56.380
It could be a vector,
which we call y sub zero.

00:27:56.380 --> 00:28:00.010
And that can just be an image,
right, the canonical thing

00:28:00.010 --> 00:28:02.320
being an image of a cat, right?

00:28:02.320 --> 00:28:05.484
And that can just be
the pixels, values just

00:28:05.484 --> 00:28:10.419
rolled out into a vector,
and they will be the inputs.

00:28:10.419 --> 00:28:12.100
And then we have a
series of layers.

00:28:12.100 --> 00:28:14.560
These are called hidden layers.

00:28:14.560 --> 00:28:19.639
The circles are often
referred to as neurons, OK?

00:28:19.639 --> 00:28:22.682
And each line
connecting each dot

00:28:22.682 --> 00:28:26.740
has a value associated
with it, a weight.

00:28:26.740 --> 00:28:28.863
And the strength
of the connection

00:28:28.863 --> 00:28:32.049
between any two neurons
is given by that weight.

00:28:32.049 --> 00:28:36.375
And then, ultimately,
the output, in this case,

00:28:36.375 --> 00:28:40.871
the output classification,
the series of blue dots there,

00:28:40.871 --> 00:28:43.110
are the different
possible categories.

00:28:43.110 --> 00:28:46.455
So if I put in a cat picture,
one of those dots would be cat,

00:28:46.455 --> 00:28:51.189
maybe one would be dog, maybe
one would be apple or orange,

00:28:51.189 --> 00:28:52.740
whatever I desired.

00:28:52.740 --> 00:28:57.040
And the whole idea is that,
if I put in a picture of a cat

00:28:57.040 --> 00:28:59.302
and I set all these
values correctly,

00:28:59.302 --> 00:29:02.558
then the dot
corresponding to cat

00:29:02.558 --> 00:29:06.900
will end up with the
highest score, right?

00:29:06.900 --> 00:29:11.596
And then I mentioned earlier
that each one of these neurons

00:29:11.596 --> 00:29:12.450
collects inputs.

00:29:12.450 --> 00:29:14.606
And if it's above a
certain threshold,

00:29:14.606 --> 00:29:18.380
it then chooses to pass on
information to the next.

00:29:18.380 --> 00:29:21.234
And that's where these b
values, which are vectors,

00:29:21.234 --> 00:29:22.820
are just the
thresholds associated

00:29:22.820 --> 00:29:24.000
with each one of those.

00:29:24.000 --> 00:29:29.194
It's a vector, one value
associated with each one

00:29:29.194 --> 00:29:32.080
of those that does those.

00:29:32.080 --> 00:29:35.897
This entire system can
be represented relatively

00:29:35.897 --> 00:29:39.169
simply with one
equation, which is

00:29:39.169 --> 00:29:44.477
that yi plus one, which is
the next vector in the layer,

00:29:44.477 --> 00:29:48.780
OK, can be computed by
the previous vector, yi

00:29:48.780 --> 00:29:52.834
matrix multiplied
by the weight, W.

00:29:52.834 --> 00:29:56.213
So whenever you
see transformations

00:29:56.213 --> 00:30:02.267
from one set of neurons to the
next layer, you should think,

00:30:02.267 --> 00:30:06.401
oh, I have a matrix that
represents all those weights

00:30:06.401 --> 00:30:09.720
and I'm going to multiply it by
the vector to get the next one.

00:30:09.720 --> 00:30:13.700
Then we apply these
thresholds, all right?

00:30:13.700 --> 00:30:17.492
So we add these,
the bi's, and then

00:30:17.492 --> 00:30:21.759
we have a function that
we pass it through.

00:30:21.759 --> 00:30:27.316
Typically, this h function
has been given the name

00:30:27.316 --> 00:30:29.169
rectified linear unit.

00:30:29.169 --> 00:30:30.409
It's much simpler than that.

00:30:30.409 --> 00:30:34.369
It's just, if the value is
greater than what comes out

00:30:34.369 --> 00:30:37.445
of this matrix multiplied,
if the value is greater

00:30:37.445 --> 00:30:38.970
than zero, don't touch it.

00:30:38.970 --> 00:30:40.190
Just let it pass through.

00:30:40.190 --> 00:30:43.259
If it's less than zero,
make it zero, right?

00:30:43.259 --> 00:30:46.812
You know, it's a
pretty complicated name

00:30:46.812 --> 00:30:49.350
for a very simple function.

00:30:49.350 --> 00:30:50.750
That's actually critical.

00:30:50.750 --> 00:30:53.290
If you didn't have
that h function,

00:30:53.290 --> 00:30:55.467
this nonlinear
function there, then we

00:30:55.467 --> 00:30:57.722
could roll up all
of these together

00:30:57.722 --> 00:31:00.399
and we would just have one
big matrix equation, right?

00:31:00.399 --> 00:31:03.490
So that's really considered a
pretty important part of it.

00:31:03.490 --> 00:31:05.415
So that's pretty
much what's going on.

00:31:05.415 --> 00:31:07.998
When you want to know what the
big deal is of neural networks,

00:31:07.998 --> 00:31:09.940
that's all that's going on.

00:31:09.940 --> 00:31:12.480
It's just that equation.

00:31:12.480 --> 00:31:16.870
The challenge is we don't know
what the W's and the b's are.

00:31:16.870 --> 00:31:19.559
And we don't know how many
layers there should be.

00:31:19.559 --> 00:31:23.750
And we don't know how
many neurons there

00:31:23.750 --> 00:31:26.370
should be in each layer.

00:31:26.370 --> 00:31:28.776
And although the features
can be arbitrary,

00:31:28.776 --> 00:31:30.449
picking the right
ones do matter.

00:31:30.449 --> 00:31:32.240
And picking the right
categories do matter.

00:31:32.240 --> 00:31:35.355
So when people talk about,
I do machine learning

00:31:35.355 --> 00:31:37.779
or I'm off working
on-- they're basically

00:31:37.779 --> 00:31:39.960
playing with all
of these parameters

00:31:39.960 --> 00:31:42.869
to try and find
the ones that will

00:31:42.869 --> 00:31:45.470
work best for their problem.

00:31:45.470 --> 00:31:47.100
And there's a lot
of trial and error.

00:31:47.100 --> 00:31:48.532
And you'll hear
about there's now

00:31:48.532 --> 00:31:50.680
systems that try and use
machine learning to do

00:31:50.680 --> 00:31:51.940
that process automatically.

00:31:51.940 --> 00:31:56.851
You know, how do you
make machines that learn

00:31:56.851 --> 00:31:59.580
how to do machine learning?

00:31:59.580 --> 00:32:03.580
The basic approach is a
trial and error approach.

00:32:03.580 --> 00:32:07.643
I take a whole bunch
of pictures of cats

00:32:07.643 --> 00:32:13.610
that I now have cats in them,
OK, and other things, right?

00:32:13.610 --> 00:32:18.769
And I randomly set all those
weights and thresholds.

00:32:18.769 --> 00:32:22.549
And I put in the vector
and I see what the system--

00:32:22.549 --> 00:32:26.078
I guess what I think the
number of layers and neurons

00:32:26.078 --> 00:32:30.111
and all that should be and
I run it through the system

00:32:30.111 --> 00:32:33.013
and I get an estimate
or a calculation

00:32:33.013 --> 00:32:36.422
for what I think these
final values should be

00:32:36.422 --> 00:32:38.649
and I compare it with the truth.

00:32:38.649 --> 00:32:40.960
That is, I just
basically subtract it.

00:32:40.960 --> 00:32:46.317
And then I use those corrections
to very carefully adjust

00:32:46.317 --> 00:32:47.389
the weights.

00:32:47.389 --> 00:32:49.919
Basically, with the
last weights first, I

00:32:49.919 --> 00:32:53.486
do what's called back propagate
these little changes to try

00:32:53.486 --> 00:32:57.289
and make a better guess on
what these weights should be.

00:32:57.289 --> 00:32:59.977
So if you hear the
term back propagation,

00:32:59.977 --> 00:33:02.330
that's that process of
taking those differences

00:33:02.330 --> 00:33:07.210
and using them to adjust
these weights by about

00:33:07.210 --> 00:33:09.379
0.01% at a time.

00:33:09.379 --> 00:33:12.321
And then we just do
this over and over

00:33:12.321 --> 00:33:15.263
again until eventually
we get a set of weights

00:33:15.263 --> 00:33:19.310
that we think does the problem
well enough for our purpose.

00:33:19.310 --> 00:33:21.899
So that's called back
propagation, all right?

00:33:21.899 --> 00:33:23.604
Once we have the set
of weights and we

00:33:23.604 --> 00:33:25.500
have a new picture that
we want to know what

00:33:25.500 --> 00:33:28.233
it is, we drop it in
there and it tells us

00:33:28.233 --> 00:33:30.269
it's a cat or a dog or whatever.

00:33:30.269 --> 00:33:32.100
That forward step
is called inference.

00:33:32.100 --> 00:33:34.442
These are two words
you'll hear frequently

00:33:34.442 --> 00:33:37.200
in machine learning, back
propagation and inference.

00:33:37.200 --> 00:33:38.450
And that's all there is to it.

00:33:38.450 --> 00:33:40.970
There's really
nothing else to that.

00:33:40.970 --> 00:33:42.867
If you can understand
this equation,

00:33:42.867 --> 00:33:46.029
you'll be way ahead of most
people in machine learning,

00:33:46.029 --> 00:33:47.029
you know?

00:33:47.029 --> 00:33:49.028
You know, there's
lots of people who

00:33:49.028 --> 00:33:51.314
understand about all the
software and the packages

00:33:51.314 --> 00:33:52.600
and the data.

00:33:52.600 --> 00:33:54.529
All of them are just doing that.

00:33:54.529 --> 00:33:58.027
And I'd say this is one
of the most powerful ways

00:33:58.027 --> 00:34:01.470
to be ahead in your field,
is to actually understand

00:34:01.470 --> 00:34:03.210
the mathematical principles.

00:34:03.210 --> 00:34:05.944
Because then the software
and what it's doing

00:34:05.944 --> 00:34:06.970
is much clearer.

00:34:06.970 --> 00:34:08.809
And other people
who don't understand

00:34:08.809 --> 00:34:11.100
these mathematical principles,
they're really guessing.

00:34:11.100 --> 00:34:12.968
They're like, oh,
well, I do this

00:34:12.968 --> 00:34:14.570
and I throw this module in.

00:34:14.570 --> 00:34:17.838
They don't really know
that all it's doing

00:34:17.838 --> 00:34:20.699
is making adjustments to
these various equations,

00:34:20.699 --> 00:34:24.230
how many different layers
there are and stuff like that.

00:34:24.230 --> 00:34:25.996
Now, why is this important?

00:34:25.996 --> 00:34:27.620
You're like, well,
what does it matter?

00:34:27.620 --> 00:34:29.909
As I said before,
we have this system.

00:34:29.909 --> 00:34:32.000
It works but we don't know why.

00:34:32.000 --> 00:34:34.389
Well, why is it
important to know why?

00:34:34.389 --> 00:34:36.139
Well, there's two reasons.

00:34:36.139 --> 00:34:40.519
One is that, if we want
to be able to apply

00:34:40.519 --> 00:34:43.962
this incredible innovation to
other domains-- so many of you

00:34:43.962 --> 00:34:45.280
probably want to do that.

00:34:45.280 --> 00:34:48.738
Many of you want to say,
how can I apply machine

00:34:48.738 --> 00:34:52.217
learning to something else
other than language or vision

00:34:52.217 --> 00:34:56.690
or some of these other
standard problems?

00:34:56.690 --> 00:34:58.570
I kind of need some
theory to know.

00:34:58.570 --> 00:35:01.081
Like, OK, if I have a problem
that's like this one over here

00:35:01.081 --> 00:35:03.228
and I changed it in
this way, there's

00:35:03.228 --> 00:35:05.700
a good chance it'll work.

00:35:05.700 --> 00:35:10.169
There's some basis for why I'm
going to try something, right?

00:35:10.169 --> 00:35:11.960
Right now there's a
lot of trial and error.

00:35:11.960 --> 00:35:13.209
It's like, well, it's an idea.

00:35:13.209 --> 00:35:15.385
But if you can have
some math that says,

00:35:15.385 --> 00:35:17.460
you know, I think that
will probably work,

00:35:17.460 --> 00:35:21.091
that really is a great way
to guide your reasoning

00:35:21.091 --> 00:35:22.590
and guide your efforts.

00:35:22.590 --> 00:35:25.928
Another reason is
that-- so here's

00:35:25.928 --> 00:35:30.380
a picture of a very
cute poodle, right?

00:35:30.380 --> 00:35:34.214
And the machine learning
system correctly

00:35:34.214 --> 00:35:36.770
identifies it as poodle.

00:35:36.770 --> 00:35:39.430
One thing we realized
is that the way you

00:35:39.430 --> 00:35:42.520
and I see that picture is
actually very, very different

00:35:42.520 --> 00:35:47.260
than the way the neural network
sees that picture, all right?

00:35:47.260 --> 00:35:51.167
And, in fact, I can make
changes to that picture that

00:35:51.167 --> 00:35:54.321
are imperceptible to you
or me but will completely

00:35:54.321 --> 00:35:56.189
change how the
neural network-- that

00:35:56.189 --> 00:36:00.428
is, given our neural network,
I can basically make it

00:36:00.428 --> 00:36:03.050
think anything, right?

00:36:03.050 --> 00:36:05.760
And so, for instance,
this is a famous paper.

00:36:05.760 --> 00:36:08.508
And they got the system
to think that that

00:36:08.508 --> 00:36:09.730
was an ostrich, right?

00:36:09.730 --> 00:36:12.890
And you can basically show
this for anything, right?

00:36:12.890 --> 00:36:15.980
So what's called robust AI,
or robust machine learning,

00:36:15.980 --> 00:36:18.040
machine learning that
can't be tricked,

00:36:18.040 --> 00:36:21.030
is going to become more
and more important.

00:36:21.030 --> 00:36:25.188
And again, having a deeper
understanding of the theory

00:36:25.188 --> 00:36:27.960
is very, very critical of that.

00:36:27.960 --> 00:36:31.850
So how are we going to do this?

00:36:31.850 --> 00:36:34.015
What's the main concept
that we are going

00:36:34.015 --> 00:36:35.640
to go through in this class?

00:36:35.640 --> 00:36:37.770
This has mostly
been motivational.

00:36:37.770 --> 00:36:40.320
But how are we going to
understand the data at a deeper

00:36:40.320 --> 00:36:40.820
level?

00:36:40.820 --> 00:36:42.770
You know, what's the big idea?

00:36:42.770 --> 00:36:46.179
And the big idea is
captured now in this,

00:36:46.179 --> 00:36:48.831
I apologize for this
eye chart slide,

00:36:48.831 --> 00:36:52.277
which is what we call
declarative mathematically

00:36:52.277 --> 00:36:53.300
rigorous data.

00:36:53.300 --> 00:36:56.504
So we have this
mathematical concept

00:36:56.504 --> 00:36:58.640
called an associative array.

00:36:58.640 --> 00:37:01.960
And it's corresponding algebra
that basically encompasses

00:37:01.960 --> 00:37:05.763
the data you would put
in databases, the data

00:37:05.763 --> 00:37:07.938
that you would put in
graphs, the data that

00:37:07.938 --> 00:37:11.560
would put in matrices and it
makes it all a linear system.

00:37:11.560 --> 00:37:14.240
And the key operations are
outlined there at the bottom.

00:37:14.240 --> 00:37:17.479
If you recall, we have
our basic little addition

00:37:17.479 --> 00:37:18.270
and multiplication.

00:37:18.270 --> 00:37:20.462
And then what's going
to be very important,

00:37:20.462 --> 00:37:22.707
probably the real
workhorse for this-- and i

00:37:22.707 --> 00:37:24.724
didn't show it before--
is called essentially

00:37:24.724 --> 00:37:26.640
array multiplication or
matrix multiplication.

00:37:26.640 --> 00:37:29.294
And that's the far
one on the right

00:37:29.294 --> 00:37:33.354
there, which we often abbreviate
just with no symbol, just A B.

00:37:33.354 --> 00:37:36.578
But if we really want
to explicitly call out

00:37:36.578 --> 00:37:39.037
that its matrix multiplication
as a combination

00:37:39.037 --> 00:37:40.706
of both multiplication
and addition,

00:37:40.706 --> 00:37:44.210
we put in what we call the
punch-drunk emoji, which

00:37:44.210 --> 00:37:46.710
is a plus dot times.

00:37:46.710 --> 00:37:50.370
You're probably all young
enough that you don't even

00:37:50.370 --> 00:37:53.585
remember emojis when
they had to type them out

00:37:53.585 --> 00:37:56.170
with just little characters and
we didn't have icons, right?

00:37:56.170 --> 00:38:00.620
So that meant you went to the
bar and lost to the fight,

00:38:00.620 --> 00:38:01.120
right?

00:38:01.120 --> 00:38:04.616
But, anyway, that's really going
to be the workhorse of what

00:38:04.616 --> 00:38:06.502
we're doing here.0:31:08.020
to cover in a few minutes.

00:31:08.020 --> 00:31:10.850
That is, it takes people
a long time to figure out,

00:31:10.850 --> 00:31:14.470
oh simple tables are good.

00:31:14.470 --> 00:31:16.510
We can organize
our data that way.

00:31:16.510 --> 00:31:20.290
And just having a good set of
folder names and file names

00:31:20.290 --> 00:31:24.423
really solves most of
the problem, right?

00:31:24.423 --> 00:31:25.840
That's the beauty
of the solution.

00:31:25.840 --> 00:31:28.210
It sounds so
phenomenally simple.

00:31:28.210 --> 00:31:30.670
How could it possibly work?

00:31:30.670 --> 00:31:32.440
That's actually--
you know, if there's

00:31:32.440 --> 00:31:33.940
one thing we figure
out here at MIT,

00:31:33.940 --> 00:31:38.020
it's that simple can be
very good and very powerful.

00:31:38.020 --> 00:31:42.520
So as was mentioned before,
sort of these neural networks,

00:31:42.520 --> 00:31:47.770
as depicted here, drive
this space of applications.

00:31:47.770 --> 00:31:50.650
Most of the innovations we've
seen in the past few years

00:31:50.650 --> 00:31:53.290
have been using these
neural networks.

00:31:53.290 --> 00:31:56.290
This one slide sort of covers
all of neural networks.

00:31:56.290 --> 00:31:58.780
In one slide, you
have the picture,

00:31:58.780 --> 00:32:01.690
you have the input features,
which are shown in gray dots,

00:32:01.690 --> 00:32:03.520
you have the output
classifications

00:32:03.520 --> 00:32:05.248
that are shown in
blue dots, and then

00:32:05.248 --> 00:32:06.790
you have their neural
network and all

00:32:06.790 --> 00:32:13.000
their various weight matrices
or weight tables in between.

00:32:13.000 --> 00:32:18.040
If you had one goal, in
terms of understanding AI,

00:32:18.040 --> 00:32:22.070
making a commitment to
understanding this one slide,

00:32:22.070 --> 00:32:24.610
then you pretty much
understand a good fraction

00:32:24.610 --> 00:32:27.190
of the entire field.

00:32:27.190 --> 00:32:30.490
And while you are
here at MIT, please

00:32:30.490 --> 00:32:35.470
feel free to talk to any
of us about this slide

00:32:35.470 --> 00:32:39.460
or these concepts and
we will work with you

00:32:39.460 --> 00:32:41.470
to help you understand it.

00:32:41.470 --> 00:32:43.630
Because anyone who's
ever coming to you

00:32:43.630 --> 00:32:46.690
and offering an AI solution
that uses neural networks, which

00:32:46.690 --> 00:32:51.280
is a significant fraction of
them, they're just doing this.

00:32:51.280 --> 00:32:52.870
This is all they're doing.

00:32:52.870 --> 00:32:54.850
It's all on this one slide.

00:32:54.850 --> 00:32:59.650
Many of them, by the
way, do not know the math

00:32:59.650 --> 00:33:02.110
that one equation here
that's in this this.

00:33:02.110 --> 00:33:04.000
They have software,
they play with knobs,

00:33:04.000 --> 00:33:07.150
but they don't even understand
the underlying mathematics.

00:33:07.150 --> 00:33:10.720
And just understanding this
math, taking the time to do it,

00:33:10.720 --> 00:33:14.590
you will know more than
anyone who is actually trying

00:33:14.590 --> 00:33:18.890
to sell you AI solutions.

00:33:18.890 --> 00:33:23.690
Now, as Sid said, he
talked about batch size--

00:33:23.690 --> 00:33:26.690
I just added batches
to this figure

00:33:26.690 --> 00:33:31.160
to emphasize the fact
that all of these letters

00:33:31.160 --> 00:33:33.970
are mostly uppercase.

00:33:33.970 --> 00:33:37.850
And if you want to know one
thing about matrix math,

00:33:37.850 --> 00:33:41.330
it is the easiest way to
go from a vector equation

00:33:41.330 --> 00:33:44.990
to a matrix equation is to
take all the lowercase letters

00:33:44.990 --> 00:33:46.580
and make them uppercase.

00:33:46.580 --> 00:33:49.790
And most of the time,
that actually just works.

00:33:49.790 --> 00:33:51.650
In fact, typically
what we do if you're

00:33:51.650 --> 00:33:54.500
a linear algebraic
person, is we do that,

00:33:54.500 --> 00:33:56.155
and see if it breaks anything.

00:33:56.155 --> 00:33:57.530
And if it doesn't
break anything,

00:33:57.530 --> 00:33:58.970
well, we assume it's right.

00:33:58.970 --> 00:34:02.600
And all of these matrices,
right, are tabular.

00:34:02.600 --> 00:34:04.490
A matrix is just a big table.

00:34:04.490 --> 00:34:06.530
It's a great big spreadsheet.

00:34:06.530 --> 00:34:10.550
So basically, all of
neural networks in AI

00:34:10.550 --> 00:34:13.489
is just about taking
spreadsheets and transforming

00:34:13.489 --> 00:34:14.699
them.

00:34:14.699 --> 00:34:16.909
And so, this is just
motivation for why

00:34:16.909 --> 00:34:19.040
these tables are so important.

00:34:19.040 --> 00:34:20.620
Here is the standard pipeline.

00:34:20.620 --> 00:34:23.179
Vijay talked about it briefly.

00:34:23.179 --> 00:34:26.449
And again, what we discovered
is that, in most data

00:34:26.449 --> 00:34:30.320
analysis, which includes
AI, this pipeline

00:34:30.320 --> 00:34:34.219
represents, pretty much, what
most applications are doing.

00:34:34.219 --> 00:34:36.989
It's not that any
application does all of that,

00:34:36.989 --> 00:34:38.780
but most of the steps
in an application

00:34:38.780 --> 00:34:40.610
fall into this pipeline.

00:34:40.610 --> 00:34:43.550
Basically, you have raw
data, you parse it, usually

00:34:43.550 --> 00:34:47.639
into some tabular format, you
may ingest it into a database.

00:34:47.639 --> 00:34:51.690
You then query that database
for a subset to do analysis,

00:34:51.690 --> 00:34:55.260
or you might scan
the whole database

00:34:55.260 --> 00:34:57.230
if you're doing all
the files, if you

00:34:57.230 --> 00:35:00.530
want to do some application
that involves all the data.

00:35:00.530 --> 00:35:03.380
And then, you analyze it,
and then you visualize it.

00:35:03.380 --> 00:35:06.800
And so, this is sort of
the big steps in a pipeline

00:35:06.800 --> 00:35:07.850
that we see.

00:35:07.850 --> 00:35:09.970
And again, most
applications that we'll will

00:35:09.970 --> 00:35:11.710
use three of these steps.

00:35:11.710 --> 00:35:13.610
They're not using
all of them, but it's

00:35:13.610 --> 00:35:17.270
a great framework for looking
at any data analysis pipeline.

00:35:17.270 --> 00:35:20.300
It's easy to use, it's
easy to understand,

00:35:20.300 --> 00:35:21.530
and it's easy to maintain.

00:35:21.530 --> 00:35:25.010
And you know, we like
all of those features.

00:35:25.010 --> 00:35:27.957
And I'll get into
those in more detail.

00:35:27.957 --> 00:35:30.290
And then finally, I've already
talked with significantly

00:35:30.290 --> 00:35:31.460
about data sharing.

00:35:31.460 --> 00:35:33.110
There's just some
examples of data

00:35:33.110 --> 00:35:36.290
we've put up for sharing,
the moments in time

00:35:36.290 --> 00:35:38.140
challenge, the graph challenge.

00:35:38.140 --> 00:35:40.970
And again, creating,
sharing quality data,

00:35:40.970 --> 00:35:45.560
really, it's not just a
service to the community.

00:35:45.560 --> 00:35:48.620
It's principally a
service to yourself.

00:35:48.620 --> 00:35:52.490
And in fact, we've worked
with a number of applications

00:35:52.490 --> 00:35:55.550
and sponsors where
we help them do this,

00:35:55.550 --> 00:35:58.250
and they find the data that
they made shareable is instantly

00:35:58.250 --> 00:36:00.350
the most valuable data
in their organization

00:36:00.350 --> 00:36:02.600
because it's shareable within
their organization too.

00:36:02.600 --> 00:36:04.808
The same things that make
it shareable to the broader

00:36:04.808 --> 00:36:07.070
community make it shareable
within your organization

00:36:07.070 --> 00:36:08.070
to other partners.

00:36:08.070 --> 00:36:09.570
So that's really important.

00:36:09.570 --> 00:36:11.920
And again, as I said
before, co-designing

00:36:11.920 --> 00:36:15.020
the sharing and the
purpose of the data,

00:36:15.020 --> 00:36:17.660
is quite you need to do that.

00:36:17.660 --> 00:36:19.400
In order to do
effective sharing,

00:36:19.400 --> 00:36:23.120
you can't just share
data arbitrarily.

00:36:23.120 --> 00:36:25.070
That can be very
difficult to do,

00:36:25.070 --> 00:36:27.500
but if you have a particular
application in mind,

00:36:27.500 --> 00:36:29.390
sharing the data
is quite simple.

00:36:29.390 --> 00:36:31.872
And I'll get into that later.

00:36:31.872 --> 00:36:33.830
So I'm just going to,
then, sort of hammer home

00:36:33.830 --> 00:36:35.630
some of these points, here.

00:36:35.630 --> 00:36:37.965
So nothing really
new, here, just sort

00:36:37.965 --> 00:36:40.880
of repeating what I've already
said about these things

00:36:40.880 --> 00:36:43.370
but with adding a little
bit more texture, to them.

00:36:43.370 --> 00:36:45.920
So why do we like tables?

00:36:45.920 --> 00:36:48.590
Well, we've been using
tables to analyze data

00:36:48.590 --> 00:36:51.210
for thousands of years.

00:36:51.210 --> 00:36:54.740
So on the right is a
12th century manuscript.

00:36:54.740 --> 00:36:56.960
It's actually a table of pies.

00:36:56.960 --> 00:36:59.610
And if you can read
Latin and Roman numerals,

00:36:59.610 --> 00:37:01.610
you already can tell it
is probably, oh, there's

00:37:01.610 --> 00:37:03.590
some columns, and
there's some rows.

00:37:03.590 --> 00:37:05.570
And those Roman
numerals are numbers.

00:37:05.570 --> 00:37:09.410
Even 800 years
later, we can still

00:37:09.410 --> 00:37:11.660
see that this is a data table.

00:37:11.660 --> 00:37:12.950
And it goes back further.

00:37:12.950 --> 00:37:17.120
You can find cuneiform tablets
that are thousands of years old

00:37:17.120 --> 00:37:19.670
that are clearly written
in a tabular form.

00:37:19.670 --> 00:37:23.180
So humans have been looking
at data in a tabular form

00:37:23.180 --> 00:37:25.670
for thousands of years.

00:37:25.670 --> 00:37:29.700
Part of that is how our
brain is actually wired.

00:37:29.700 --> 00:37:34.160
One, the 2D projection,
since we live in 3D space,

00:37:34.160 --> 00:37:35.990
is the only projection
that will show you

00:37:35.990 --> 00:37:37.965
all the data without occlusion.

00:37:37.965 --> 00:37:39.590
So if you want to
look at all the data,

00:37:39.590 --> 00:37:41.390
it kind of has to be
presented in 2D form.

00:37:41.390 --> 00:37:43.740
We have a 2D optical system.

00:37:43.740 --> 00:37:48.170
In addition, we have special
hard wired parts of our eyes

00:37:48.170 --> 00:37:52.550
that detect vertical and
horizontal lines for,

00:37:52.550 --> 00:37:54.950
presumably, detecting
the horizon or trees

00:37:54.950 --> 00:37:56.210
or who knows what.

00:37:56.210 --> 00:37:59.420
And that makes it
very easy for our eyes

00:37:59.420 --> 00:38:02.130
to look at tabular data.

00:38:02.130 --> 00:38:04.640
And because of
this, tabular data

00:38:04.640 --> 00:38:07.220
is compatible with
almost every data

00:38:07.220 --> 00:38:09.800
analysis software on earth.

00:38:09.800 --> 00:38:11.490
If I make data analysis
software and it

00:38:11.490 --> 00:38:13.940
can't read tables
or write out tables,

00:38:13.940 --> 00:38:16.010
it's going to have a
very small market share.

00:38:16.010 --> 00:38:20.800
And this is just an example of
some of the software out there

00:38:20.800 --> 00:38:22.420
that is designed to use tables.

00:38:22.420 --> 00:38:26.410
So whether it be spreadsheets or
databases or the neural network

00:38:26.410 --> 00:38:28.480
packages that we've
already looked at,

00:38:28.480 --> 00:38:30.783
various languages and
libraries, and even

00:38:30.783 --> 00:38:32.200
things that you
wouldn't think are

00:38:32.200 --> 00:38:36.010
tabular like hierarchical file
formats, like JSON and XML,

00:38:36.010 --> 00:38:40.130
can actually be made compatible
with a tablet format.

00:38:40.130 --> 00:38:42.040
So I'm just going to
walk through these

00:38:42.040 --> 00:38:44.450
in a little more detail.

00:38:44.450 --> 00:38:47.200
So of course, our
favorite is spreadsheets.

00:38:47.200 --> 00:38:50.242
Here's an example of a
spreadsheet, on the left.

00:38:50.242 --> 00:38:51.700
And what's great
about it is that I

00:38:51.700 --> 00:38:55.810
have four different types
of data that are very, very

00:38:55.810 --> 00:38:57.460
different, and you
can all look at them

00:38:57.460 --> 00:38:59.800
and sort of get a
sense of what they are.

00:38:59.800 --> 00:39:03.490
And that just shows how flexible
this tabular spreadsheet

00:39:03.490 --> 00:39:07.810
form is, is that we can handle
really, really diverse types

00:39:07.810 --> 00:39:10.660
of data in a way
that's intuitive to us.

00:39:10.660 --> 00:39:12.460
Some of the biggest
pieces of software

00:39:12.460 --> 00:39:14.530
that are used that
implement this

00:39:14.530 --> 00:39:18.490
are Microsoft Excel, Google
Sheets, Apple Numbers.

00:39:18.490 --> 00:39:22.480
It's used by about 100
million people every day.

00:39:22.480 --> 00:39:27.220
And so, this is the most popular
tool for using data analysis,

00:39:27.220 --> 00:39:29.160
and there's a good
reason for it.

00:39:29.160 --> 00:39:32.150
And thinking of things
in a tabular format

00:39:32.150 --> 00:39:34.390
so they can be pulled
into this really makes

00:39:34.390 --> 00:39:36.350
communication a lot easier.

00:39:36.350 --> 00:39:39.100
And so again, just sort of
hammering home this element

00:39:39.100 --> 00:39:40.150
of tables.

00:39:40.150 --> 00:39:42.400
Within that, there's
specific formats

00:39:42.400 --> 00:39:44.660
that we have found
to be very popular.

00:39:44.660 --> 00:39:50.560
So CSV and TSV are just
non-proprietary, plain text

00:39:50.560 --> 00:39:52.350
ways of organizing data.

00:39:52.350 --> 00:39:54.730
We highly encourage people
to use them because then it

00:39:54.730 --> 00:39:56.930
can be used by any tool.

00:39:56.930 --> 00:39:59.920
CSV just stands for
comma separated values.

00:39:59.920 --> 00:40:03.940
It's usually filename.csv in
lower case or filename.CSV

00:40:03.940 --> 00:40:05.050
in upper case.

00:40:05.050 --> 00:40:08.530
And all it means is
that the columns--

00:40:08.530 --> 00:40:12.700
So each row is terminated by a
new line, and within each row

00:40:12.700 --> 00:40:14.920
the columns are
separated by a comma.

00:40:14.920 --> 00:40:17.110
That's all that means.

00:40:17.110 --> 00:40:19.420
We tend to encourage
people to use

00:40:19.420 --> 00:40:22.960
TSV, which stands for
tab separated values,

00:40:22.960 --> 00:40:26.200
because we can replace
the comma with a tab.

00:40:26.200 --> 00:40:29.110
And that allows us to
write higher performance

00:40:29.110 --> 00:40:30.580
readers and writers.

00:40:30.580 --> 00:40:35.830
Because it is not uncommon to
have a comma within a value,

00:40:35.830 --> 00:40:39.160
and so it makes it very
difficult to write parsers

00:40:39.160 --> 00:40:41.170
that can do that fast.

00:40:41.170 --> 00:40:44.810
But it's OK to say to a
person generating data,

00:40:44.810 --> 00:40:50.800
if you put a tab inside a
value that's a foul on you.

00:40:50.800 --> 00:40:52.270
You shouldn't do that.

00:40:52.270 --> 00:40:54.820
And so that means I can
write a program that

00:40:54.820 --> 00:40:57.160
can read this data
really fast, and it can

00:40:57.160 --> 00:40:58.820
write this data really fast.

00:40:58.820 --> 00:41:01.960
And that's why, in the
big data or AI space,

00:41:01.960 --> 00:41:05.430
people often tend to use TSV.

00:41:05.430 --> 00:41:07.840
And again, it's easily
readable and writable

00:41:07.840 --> 00:41:09.640
by all those
spreadsheet programs

00:41:09.640 --> 00:41:12.250
that I have said before.

00:41:12.250 --> 00:41:14.890
Databases play a very
important role as well.

00:41:14.890 --> 00:41:18.750
There's several different types
of databases that are called

00:41:18.750 --> 00:41:21.790
SQL, NoSQL, and NewSQL .

00:41:21.790 --> 00:41:23.620
They're good for
different things.

00:41:23.620 --> 00:41:26.080
I won't dwell on that
here, but there are

00:41:26.080 --> 00:41:27.820
different types of databases.

00:41:27.820 --> 00:41:30.670
All of them operate on tables.

00:41:30.670 --> 00:41:32.800
In fact, the central
object in a database

00:41:32.800 --> 00:41:35.230
is literally called
a database table.

00:41:35.230 --> 00:41:37.720
And so, databases play
an important role.

00:41:37.720 --> 00:41:41.440
I won't go into detail here,
but I just want to mention this.

00:41:41.440 --> 00:41:44.080
Likewise, you've already
had some demonstrations

00:41:44.080 --> 00:41:45.700
of different languages
and libraries.

00:41:45.700 --> 00:41:47.860
I think everything
you saw was in Python.

00:41:47.860 --> 00:41:51.700
There's other languages--
Julia, MATLAB, Octave, R--

00:41:51.700 --> 00:41:53.890
many other languages
that play important roles

00:41:53.890 --> 00:41:55.120
in data analysis.

00:41:55.120 --> 00:41:56.920
We've talked about
Jupyter Notebooks, which

00:41:56.920 --> 00:42:00.850
is a universal interface to
these different languages

00:42:00.850 --> 00:42:03.940
and libraries to allow you to
do data analysis in addition

00:42:03.940 --> 00:42:06.700
to the various machine
learning tools.

00:42:06.700 --> 00:42:08.297
We've talked a lot
about TensorFlow,

00:42:08.297 --> 00:42:09.130
but there's others--

00:42:09.130 --> 00:42:11.980
Theano, Caffe, Nvidia Digits--

00:42:11.980 --> 00:42:15.940
all are examples of
different tools for doing AI.

00:42:15.940 --> 00:42:19.540
And again, they love
to ingest tabular data,

00:42:19.540 --> 00:42:23.890
and they're very good at writing
out tabular data completely

00:42:23.890 --> 00:42:26.360
consistent with that here.

00:42:26.360 --> 00:42:30.310
And then finally, I want
to mention XML and JSON,

00:42:30.310 --> 00:42:33.730
which are very popular in
object-oriented languages,

00:42:33.730 --> 00:42:38.650
like C++, Java, and Python.

00:42:38.650 --> 00:42:44.830
Those languages rely on data
structures, which are basically

00:42:44.830 --> 00:42:48.130
just a set of fields,
and then those fields

00:42:48.130 --> 00:42:51.190
can also be data structures,
and this can continue on.

00:42:51.190 --> 00:42:53.890
These are called
hierarchical data structures,

00:42:53.890 --> 00:42:56.540
the way these languages
are organized.

00:42:56.540 --> 00:42:59.080
And so it's very natural
for them to have formats

00:42:59.080 --> 00:43:02.560
that they can just say, write
out this whole blob of data,

00:43:02.560 --> 00:43:05.350
and it will write it out into
a hierarchical form called

00:43:05.350 --> 00:43:07.300
XML or JSON.

00:43:07.300 --> 00:43:10.990
However, it's not
very human readable.

00:43:10.990 --> 00:43:14.680
And I just told you that
all the data analysis tools

00:43:14.680 --> 00:43:18.040
want tables, which means
that these formats aren't

00:43:18.040 --> 00:43:22.060
necessarily very good for
doing data analysis on.

00:43:22.060 --> 00:43:24.520
Fortunately, we've
discovered some ways

00:43:24.520 --> 00:43:28.600
that we can basically convert
these hierarchical formats

00:43:28.600 --> 00:43:31.540
into a giant, what we
call, sparse table.

00:43:31.540 --> 00:43:35.260
And sparse just means a table
where lots of the values

00:43:35.260 --> 00:43:38.470
are empty.

00:43:38.470 --> 00:43:40.280
The entries are empty.

00:43:40.280 --> 00:43:42.610
And so we can just
use that space

00:43:42.610 --> 00:43:45.490
to represent this
hierarchy, and all the tools

00:43:45.490 --> 00:43:51.180
we've just talked about can
ingest this data pretty easily.

00:43:51.180 --> 00:43:57.720
Because tables are so popular,
every single different approach

00:43:57.720 --> 00:43:58.980
or software package--

00:43:58.980 --> 00:44:02.550
and we have a bunch of them
listed in the first column,

00:44:02.550 --> 00:44:04.020
here--

00:44:04.020 --> 00:44:07.080
assign different names
to the standard ways

00:44:07.080 --> 00:44:10.170
we refer to the
elements of a table.

00:44:10.170 --> 00:44:11.440
And there aren't that many.

00:44:11.440 --> 00:44:13.107
So when you think
about a table, there's

00:44:13.107 --> 00:44:15.990
certain standard terms
for dealing with what

00:44:15.990 --> 00:44:17.640
do we call the table?

00:44:17.640 --> 00:44:19.140
In Excel it's called a sheet.

00:44:21.660 --> 00:44:24.570
How do we refer to
a particular row?

00:44:24.570 --> 00:44:26.550
What do we call a whole row?

00:44:26.550 --> 00:44:29.160
How do we refer to
a particular column?

00:44:29.160 --> 00:44:31.260
What do we call a whole column?

00:44:31.260 --> 00:44:33.030
What do we call an entry?

00:44:33.030 --> 00:44:35.530
And what kind of
math can we do on it?

00:44:35.530 --> 00:44:37.620
And so, whenever
you're encountering

00:44:37.620 --> 00:44:38.970
a new piece of software--

00:44:38.970 --> 00:44:41.160
And we deal with it all the
time, but a lot of times

00:44:41.160 --> 00:44:43.620
you'll get software, and
maybe it's related to data

00:44:43.620 --> 00:44:46.540
analysis seems really,
really confusing.

00:44:46.540 --> 00:44:48.960
It's probably working on
tables, and so all you

00:44:48.960 --> 00:44:53.320
have to need to learn is what
are they calling these things.

00:44:53.320 --> 00:44:55.800
And different software
gives it different names,

00:44:55.800 --> 00:44:58.830
just for arbitrary
historical reasons.

00:44:58.830 --> 00:45:03.060
And so, if you can figure out
what it's calling these things,

00:45:03.060 --> 00:45:04.630
then you'll discover
the software

00:45:04.630 --> 00:45:06.610
is a lot easier to understand.

00:45:06.610 --> 00:45:10.740
So we definitely encourage you
to just map whatever software

00:45:10.740 --> 00:45:12.810
into these concepts,
and all of sudden life

00:45:12.810 --> 00:45:15.970
becomes a lot easier.

00:45:15.970 --> 00:45:20.070
And because tabular data
is used so commonly,

00:45:20.070 --> 00:45:23.070
whether it be in spreadsheets
or analyzing graphs or databases

00:45:23.070 --> 00:45:26.190
or matrices, it's a
natural interchange format.

00:45:26.190 --> 00:45:30.930
So by reading in tabular data
and writing out tabular data,

00:45:30.930 --> 00:45:34.800
you're preserving your
ability to have that data go

00:45:34.800 --> 00:45:36.390
into any application.

00:45:36.390 --> 00:45:38.250
Again, you have to be
careful about people

00:45:38.250 --> 00:45:40.740
who want to write
proprietary formats

00:45:40.740 --> 00:45:42.300
because they're
basically, sort of,

00:45:42.300 --> 00:45:45.420
preventing you from
basically working

00:45:45.420 --> 00:45:47.310
with other tools and
other communities.

00:45:47.310 --> 00:45:51.035
And this is another reason
why tabular data is so great.

00:45:51.035 --> 00:45:53.160
All right, so moving on
here, I wanted to just talk

00:45:53.160 --> 00:45:55.150
about basic files and folders.

00:45:55.150 --> 00:45:58.710
So hopefully, you
know, tables are good.

00:45:58.710 --> 00:46:00.630
That's sort of lesson one.

00:46:00.630 --> 00:46:03.720
And we're going to talk about
how files and folder names,

00:46:03.720 --> 00:46:05.980
well chosen is also good.

00:46:05.980 --> 00:46:06.480
Right?

00:46:06.480 --> 00:46:09.280
Again, this sounds so obvious,
but it's really the thing

00:46:09.280 --> 00:46:11.280
that we've discovered,
in working with thousands

00:46:11.280 --> 00:46:13.910
of MIT researchers
over the past decade,

00:46:13.910 --> 00:46:17.370
that these are the
fundamentals that help you out.

00:46:17.370 --> 00:46:21.160
I've already mentioned this
pipeline that we talked about.

00:46:21.160 --> 00:46:25.300
It's a way we organize the data.

00:46:25.300 --> 00:46:26.580
It's easy to build.

00:46:26.580 --> 00:46:30.660
It has built in tools
in every single computer

00:46:30.660 --> 00:46:33.810
you have to support this to
just create folders and files.

00:46:33.810 --> 00:46:35.895
That means it has
no technical debt.

00:46:35.895 --> 00:46:37.770
That is, you never have
to worry about if you

00:46:37.770 --> 00:46:40.080
have folders and files
that in 10 years,

00:46:40.080 --> 00:46:43.030
oh my god, folders and
files are going to go away.

00:46:43.030 --> 00:46:45.230
They've been around
for 50 years,

00:46:45.230 --> 00:46:47.310
in pretty much
their present form.

00:46:47.310 --> 00:46:49.720
We don't anticipate
them changing.

00:46:49.720 --> 00:46:51.570
They're easier to understand.

00:46:51.570 --> 00:46:53.760
I already talked about
tabular file formats

00:46:53.760 --> 00:46:55.710
and how useful they are.

00:46:55.710 --> 00:46:57.480
And we will talk
about a simple naming

00:46:57.480 --> 00:46:59.800
scheme for your data files.

00:46:59.800 --> 00:47:02.400
AI requires a lot of
data, which means,

00:47:02.400 --> 00:47:05.280
often, thousands or
millions of files.

00:47:05.280 --> 00:47:10.290
Having good schemes for naming
them really helps you and helps

00:47:10.290 --> 00:47:12.450
share the data amongst
people in your team.

00:47:12.450 --> 00:47:14.840
They can just look at
the folders and files

00:47:14.840 --> 00:47:17.110
and sort of understand
what's going on.

00:47:17.110 --> 00:47:19.735
And again, this folder structure
is very easy to maintain,

00:47:19.735 --> 00:47:21.360
doesn't require any
special technology,

00:47:21.360 --> 00:47:24.270
and anyone can look at it

00:47:24.270 --> 00:47:27.330
Getting into some more details
about this table format,

00:47:27.330 --> 00:47:30.715
some sort of real, sort of in
the weeds types of things that

00:47:30.715 --> 00:47:31.590
are really important.

00:47:31.590 --> 00:47:33.340
I've always talked
about you want to avoid

00:47:33.340 --> 00:47:35.880
proprietary formats if you can.

00:47:35.880 --> 00:47:39.570
Using CSV and TSV are great.

00:47:39.570 --> 00:47:41.340
They might be a little bulkier.

00:47:41.340 --> 00:47:43.140
You can compress them.

00:47:43.140 --> 00:47:45.330
No problem with doing that.

00:47:45.330 --> 00:47:47.450
Then you get pretty
much all the benefits

00:47:47.450 --> 00:47:50.910
of a proprietary format but in
a way that's generally usable.

00:47:53.850 --> 00:47:57.180
Within a TSV or CSV
file, it's good practice

00:47:57.180 --> 00:48:00.150
to make sure that each
column label is unique.

00:48:00.150 --> 00:48:01.920
So that's actually a big help.

00:48:01.920 --> 00:48:03.420
You don't want to
have, essentially,

00:48:03.420 --> 00:48:07.500
the same column label or column
name occur over and over again.

00:48:07.500 --> 00:48:11.910
And likewise, it's helpful if
the first column are the row

00:48:11.910 --> 00:48:15.330
labels, and those are
each unique as well.

00:48:15.330 --> 00:48:18.840
And just those two practices
make it a lot easier

00:48:18.840 --> 00:48:21.730
to read and organize the data.

00:48:21.730 --> 00:48:25.770
Otherwise, you end up having
to do various transformations.

00:48:25.770 --> 00:48:28.630
If a lot of the entries
are empty, i.e.,

00:48:28.630 --> 00:48:31.980
the table is very sparse,
there's another format we use,

00:48:31.980 --> 00:48:34.410
which is sometimes
called triples format.

00:48:34.410 --> 00:48:36.600
Basically, every
single entry in a table

00:48:36.600 --> 00:48:39.090
can be referred to
by its row label,

00:48:39.090 --> 00:48:40.560
it's column label,
and it's value.

00:48:40.560 --> 00:48:41.880
That forms a triple.

00:48:41.880 --> 00:48:45.690
So you can just write another
file, can be a TSV file,

00:48:45.690 --> 00:48:47.320
that has three columns.

00:48:47.320 --> 00:48:49.050
The first column
is the row label,

00:48:49.050 --> 00:48:52.250
the next column is
the column label,

00:48:52.250 --> 00:48:54.490
and the next column
is the value label.

00:48:54.490 --> 00:48:57.988
And most software can
read this in pretty nice--

00:48:57.988 --> 00:48:59.530
it's a very convenient
way of dealing

00:48:59.530 --> 00:49:04.110
with very, very sparse data
without losing any benefits.

00:49:04.110 --> 00:49:07.000
So that's a very good thing.

00:49:07.000 --> 00:49:10.430
In terms of actual file
naming, as I said before,

00:49:10.430 --> 00:49:12.890
you want to avoid having
lots of tiny files.

00:49:12.890 --> 00:49:15.640
Most file systems,
most data systems,

00:49:15.640 --> 00:49:19.540
do not work with small
files really well.

00:49:19.540 --> 00:49:21.670
You do want to compress.

00:49:21.670 --> 00:49:24.370
Decompression doesn't
take much time.

00:49:24.370 --> 00:49:26.570
It's usually quite beneficial.

00:49:26.570 --> 00:49:30.180
And so, it's better to
have fewer larger files.

00:49:30.180 --> 00:49:32.170
A sweet spot, for
a long time, has

00:49:32.170 --> 00:49:36.370
been file serving the one
megabyte to 100 megabyte range.

00:49:36.370 --> 00:49:39.070
This one megabyte
is big enough so

00:49:39.070 --> 00:49:42.460
that you can read it in
and get high bandwidth,

00:49:42.460 --> 00:49:46.060
get the data into
your program quickly.

00:49:46.060 --> 00:49:49.030
And up to 100 megabyte, once
you start going beyond that,

00:49:49.030 --> 00:49:52.430
you maybe can start exhausting
the memory of your computer

00:49:52.430 --> 00:49:54.290
or your processor.

00:49:54.290 --> 00:49:56.740
So this is one megabyte
to 100 megabyte

00:49:56.740 --> 00:50:00.220
range has been a sweet
spot for quite a while.

00:50:00.220 --> 00:50:05.410
You want to keep directories
to less than 1,000 files.

00:50:05.410 --> 00:50:07.180
That's pretty common nowadays.

00:50:07.180 --> 00:50:10.930
Creating directories with a
really large number of files,

00:50:10.930 --> 00:50:13.540
most systems don't
really like that.

00:50:13.540 --> 00:50:15.978
You'll find it's also
hard to work with.

00:50:15.978 --> 00:50:17.020
And so, that's something.

00:50:17.020 --> 00:50:20.320
You want to keep your
directories less than 1,000.

00:50:20.320 --> 00:50:23.830
And so, you do that by using
hierarchical directories.

00:50:23.830 --> 00:50:25.690
And so, when it
comes to naming files

00:50:25.690 --> 00:50:28.900
to things that tend to
be pretty universal,

00:50:28.900 --> 00:50:33.020
is source and time of data.

00:50:33.020 --> 00:50:35.230
Right?

00:50:35.230 --> 00:50:38.200
Where you collected it
and when you collected

00:50:38.200 --> 00:50:41.350
it are pretty fundamental
aspects that you

00:50:41.350 --> 00:50:45.490
can rely on being a part
of almost all data sets.

00:50:45.490 --> 00:50:47.590
And so, this is a
simple naming scheme

00:50:47.590 --> 00:50:50.650
that we use that we
find is very accessible.

00:50:50.650 --> 00:50:53.560
We just create a
hierarchical directory here.

00:50:53.560 --> 00:50:55.990
It begins with
source, and then we

00:50:55.990 --> 00:50:59.890
have the years, the months, the
days, the hours, the minutes,

00:50:59.890 --> 00:51:02.365
however far you need
to go to kind of hit

00:51:02.365 --> 00:51:05.500
your sort of 1,000
files per folder window.

00:51:05.500 --> 00:51:07.090
And then, we repeat
all that name

00:51:07.090 --> 00:51:09.730
within the file name itself,
so that if the file ever

00:51:09.730 --> 00:51:12.380
gets separated from its
directory structure,

00:51:12.380 --> 00:51:14.390
you still have that information.

00:51:14.390 --> 00:51:16.930
And that's really important
because it's easy for files

00:51:16.930 --> 00:51:18.820
to get separated,
and then, you know,

00:51:18.820 --> 00:51:21.280
it's like a kid wandering
around without his parents.

00:51:21.280 --> 00:51:24.880
But if it's got a little
label on it that says,

00:51:24.880 --> 00:51:29.360
this is my address, then you can
get the get the kid back home.

00:51:29.360 --> 00:51:31.360
And likewise,
sometimes you'll do

00:51:31.360 --> 00:51:33.610
the time first and then source.

00:51:33.610 --> 00:51:35.740
It really depends
on the application.

00:51:35.740 --> 00:51:36.670
They're both fine.

00:51:36.670 --> 00:51:38.710
But again, this
sounds really simple,

00:51:38.710 --> 00:51:41.740
but it solves a lot of problems.

00:51:41.740 --> 00:51:45.610
If you give data to
people in this form,

00:51:45.610 --> 00:51:47.200
they're going to
know what it means.

00:51:47.200 --> 00:51:47.700
Right?

00:51:47.700 --> 00:51:49.510
It doesn't require a
lot of explanations.

00:51:49.510 --> 00:51:51.880
Like, dates are pretty
obvious, source names

00:51:51.880 --> 00:51:54.070
are pretty obvious, and
then they can, basically,

00:51:54.070 --> 00:51:56.500
work through it pretty nicely.

00:51:56.500 --> 00:51:58.930
Databases and files
can work together.

00:51:58.930 --> 00:52:02.130
You'll have some people like,
we do everything with files,

00:52:02.130 --> 00:52:03.880
or we do everything
with databases.

00:52:03.880 --> 00:52:05.920
They do different things.

00:52:05.920 --> 00:52:07.890
They serve different purposes.

00:52:07.890 --> 00:52:11.200
So databases are good for
quickly finding a small amount

00:52:11.200 --> 00:52:13.840
of data in a big data set.

00:52:13.840 --> 00:52:16.660
So if I want to look up a little
bit of data in a big data set,

00:52:16.660 --> 00:52:18.700
that's what databases do well.

00:52:18.700 --> 00:52:21.190
Likewise, if I want
to read a ton of data,

00:52:21.190 --> 00:52:24.280
like all of the data,
and I want it analyzed,

00:52:24.280 --> 00:52:26.140
that's what file
systems do well.

00:52:26.140 --> 00:52:28.870
So you, a lot of times,
keep them both around.

00:52:28.870 --> 00:52:31.780
You have databases for looking
up little elements quickly,

00:52:31.780 --> 00:52:34.690
and you have data
and file system

00:52:34.690 --> 00:52:36.090
if I want to read a lot of data.

00:52:36.090 --> 00:52:38.440
So they work together
very harmoniously, they

00:52:38.440 --> 00:52:40.130
serve different purposes.

00:52:40.130 --> 00:52:43.990
And again, different databases
are good for different things.

00:52:43.990 --> 00:52:47.990
I won't belabor these, you
can read them yourself.

00:52:47.990 --> 00:52:50.200
But there are a variety
of database technologies

00:52:50.200 --> 00:52:52.370
out there, and they
serve different purposes.

00:52:52.370 --> 00:52:55.450
So let me talk about the folder
structure in a little bit

00:52:55.450 --> 00:52:56.070
more detail.

00:52:56.070 --> 00:52:58.390
This is getting really like--

00:52:58.390 --> 00:53:00.080
It is really just this simple.

00:53:00.080 --> 00:53:02.350
When we talk about
our standard pipeline,

00:53:02.350 --> 00:53:04.960
it's just a bunch of
folders that we name,

00:53:04.960 --> 00:53:07.150
like we show on the right.

00:53:07.150 --> 00:53:14.390
So we have an overall folder
that we usually call pipeline,

00:53:14.390 --> 00:53:21.880
and then we basically label
each step with step 0, step 1,

00:53:21.880 --> 00:53:24.860
so people know which is the
beginning and which is the end

00:53:24.860 --> 00:53:26.110
and what's happening in there.

00:53:26.110 --> 00:53:29.560
So we have step 0 raw,
step one parse, step two

00:53:29.560 --> 00:53:32.530
ingest, step three query,
step four analysis,

00:53:32.530 --> 00:53:36.590
step five is viz, if
you're doing that.

00:53:36.590 --> 00:53:42.340
And then, within each one of
those, we'll have a folder,

00:53:42.340 --> 00:53:44.710
we'll have a readme, which
basically tells people

00:53:44.710 --> 00:53:46.900
something about, OK,
what's going on there.

00:53:46.900 --> 00:53:48.790
Those readmes are really good.

00:53:48.790 --> 00:53:53.230
Even if you never share
this data with anybody else,

00:53:53.230 --> 00:53:55.630
as you get on in
life, you will often

00:53:55.630 --> 00:53:58.360
be asked to revisit
things, and just

00:53:58.360 --> 00:54:01.300
having this information so
that two years later, you

00:54:01.300 --> 00:54:04.773
can go back and look at it,
is really, really helpful.

00:54:04.773 --> 00:54:06.190
Because otherwise,
you'll discover

00:54:06.190 --> 00:54:08.440
that you don't remember
what it is you were doing.

00:54:08.440 --> 00:54:09.880
So you write a
little readmes that

00:54:09.880 --> 00:54:12.320
give you some information
about what's going on.

00:54:12.320 --> 00:54:13.330
And then, within
each step, there's

00:54:13.330 --> 00:54:14.770
usually readme that
talks to you about what

00:54:14.770 --> 00:54:15.820
the instructions in here.

00:54:15.820 --> 00:54:17.195
And then, we have
a folder called

00:54:17.195 --> 00:54:18.930
code and folder called data.

00:54:18.930 --> 00:54:21.610
And basically, the
code describes how

00:54:21.610 --> 00:54:24.980
you put data into this folder.

00:54:24.980 --> 00:54:28.870
So in the step 0 raw, this
is often the code, maybe,

00:54:28.870 --> 00:54:31.750
for downloading the
data from the internet

00:54:31.750 --> 00:54:33.520
or how you collected your data.

00:54:33.520 --> 00:54:37.420
That's the code that, basically,
puts the data into that folder.

00:54:37.420 --> 00:54:39.250
And then, with the
next folder here,

00:54:39.250 --> 00:54:42.910
parse, this is the code
that takes this raw data

00:54:42.910 --> 00:54:46.480
and parses it and puts
it into this folder.

00:54:46.480 --> 00:54:49.060
And then, for
ingest, this will be

00:54:49.060 --> 00:54:52.030
the code that takes the
data from the parse form,

00:54:52.030 --> 00:54:53.620
sticks it in a
database, and these

00:54:53.620 --> 00:54:55.930
might be the log files
of the database entry.

00:54:55.930 --> 00:54:59.920
So a lot of times, when you
just data into a database,

00:54:59.920 --> 00:55:03.400
you'll have log files that keep
track of what that happened.

00:55:03.400 --> 00:55:05.860
And likewise, this
continues on down.

00:55:05.860 --> 00:55:07.120
So very simple.

00:55:07.120 --> 00:55:12.550
And I would offer to you, if
you someone gave you this,

00:55:12.550 --> 00:55:15.370
and you looked at it,
without any documentation,

00:55:15.370 --> 00:55:17.980
you'd probably have a pretty
good idea of what's going on.

00:55:17.980 --> 00:55:19.750
Oh, this is some
kind of pipeline.

00:55:19.750 --> 00:55:21.460
I wonder where it begins.

00:55:21.460 --> 00:55:22.870
Probably step 0.

00:55:22.870 --> 00:55:24.220
I wonder what that is.

00:55:24.220 --> 00:55:26.450
It's probably raw data.

00:55:26.450 --> 00:55:26.950
Right?

00:55:26.950 --> 00:55:28.270
It's that simple.

00:55:28.270 --> 00:55:29.680
And this just makes it so easy.

00:55:29.680 --> 00:55:31.600
The more you can
get stuff to people

00:55:31.600 --> 00:55:33.520
and they can just
understand it without

00:55:33.520 --> 00:55:37.150
any additional explanation,
that's incredibly valuable.

00:55:37.150 --> 00:55:40.838
And again, allows your teams to
contribute quickly to projects.

00:55:40.838 --> 00:55:42.880
And then, finally, we'll
add a little thing here,

00:55:42.880 --> 00:55:44.870
which is a data file list.

00:55:44.870 --> 00:55:47.860
This is a list of the
full names of all the data

00:55:47.860 --> 00:55:51.610
files because, especially
on our systems,

00:55:51.610 --> 00:55:54.310
people are often processing
lots of data, which

00:55:54.310 --> 00:55:56.920
contain millions of files.

00:55:56.920 --> 00:56:00.480
If you're going to be using
many processors to do that,

00:56:00.480 --> 00:56:03.950
it really punishes
the file system

00:56:03.950 --> 00:56:08.650
if you ask 1,000 processors to
all traverse a data directory

00:56:08.650 --> 00:56:11.080
and build up the file name
so they can figure out which

00:56:11.080 --> 00:56:13.180
files they should each process.

00:56:13.180 --> 00:56:14.770
Really, that's
actually a great way

00:56:14.770 --> 00:56:17.080
to get kicked off a
computer is to have

00:56:17.080 --> 00:56:21.700
1,000 processes all
doing ls-l on all

00:56:21.700 --> 00:56:25.670
the folders in a new directory
with millions of files.

00:56:25.670 --> 00:56:28.580
Right, it will bring the
file system to its knees.

00:56:28.580 --> 00:56:30.820
So if you just
have this one file

00:56:30.820 --> 00:56:32.290
that you generate
once that lists

00:56:32.290 --> 00:56:35.410
all the names of the files,
then every single process

00:56:35.410 --> 00:56:37.390
can just read into
that file, pick

00:56:37.390 --> 00:56:40.690
which files they want to
read, and then do their work,

00:56:40.690 --> 00:56:44.760
and then even know what the
names to write the files are.

00:56:44.760 --> 00:56:47.020
And that's, really,
a very efficient way.

00:56:47.020 --> 00:56:50.530
It dramatically speeds
up your processing

00:56:50.530 --> 00:56:53.938
and keeps the pressure on
the file system at a minimum.

00:56:53.938 --> 00:56:56.230
In addition, if you just want
to look at what you have,

00:56:56.230 --> 00:56:59.290
you don't have to type ls
to list the directory, which

00:56:59.290 --> 00:57:00.220
might ls while.

00:57:00.220 --> 00:57:03.400
You can just look at this
file and see what do I have.

00:57:03.400 --> 00:57:03.900
Right?

00:57:03.900 --> 00:57:06.540
It's very convenient to be able
to know what the data sets are.

00:57:06.540 --> 00:57:08.290
And then you can go
in there, and you see,

00:57:08.290 --> 00:57:12.430
oh, I see all these, you
know, time stamps and sources.

00:57:12.430 --> 00:57:13.390
I know what I have.

00:57:13.390 --> 00:57:13.890
Right?

00:57:13.890 --> 00:57:17.150
It makes it really easy for
people to get through this.

00:57:17.150 --> 00:57:20.410
So finally, I want to talk
about using and sharing.

00:57:20.410 --> 00:57:24.400
And so, again, co-design is
using and sharing together.

00:57:24.400 --> 00:57:28.510
Most data that you will deal
with starts out unusable

00:57:28.510 --> 00:57:30.460
and unshareable,
that is, the data

00:57:30.460 --> 00:57:33.460
is not suited for the purpose
that you wanted to use it for,

00:57:33.460 --> 00:57:36.890
and you do not have permission
to share with anybody.

00:57:36.890 --> 00:57:39.400
And so, if you understand
the data and its purpose,

00:57:39.400 --> 00:57:42.520
you can get through
both of those problems.

00:57:42.520 --> 00:57:47.480
So, really practical aspects,
here, of data sharing.

00:57:47.480 --> 00:57:50.290
We're going to talk about a
few different roles that are

00:57:50.290 --> 00:57:52.270
very common in data sharing.

00:57:52.270 --> 00:57:55.490
The first is the
keeper of the data.

00:57:55.490 --> 00:57:58.120
This is the actual person
who has the ability

00:57:58.120 --> 00:58:00.250
to make a copy of the data.

00:58:00.250 --> 00:58:02.710
You can talk to lots of
people, but until you

00:58:02.710 --> 00:58:06.610
find the keeper of the data, you
haven't really gotten anywhere.

00:58:06.610 --> 00:58:07.110
Right?

00:58:07.110 --> 00:58:09.670
Because lots-- Oh, yes, we
have data, and we can share it,

00:58:09.670 --> 00:58:11.170
or we can give it
to you, et cetera.

00:58:11.170 --> 00:58:14.050
And there's someone who
can eventually type a copy

00:58:14.050 --> 00:58:16.090
command to the data.

00:58:16.090 --> 00:58:17.562
You want to find that person.

00:58:17.562 --> 00:58:19.520
That's the person you
really need to work with.

00:58:19.520 --> 00:58:22.030
They're the one person who
can really, really help you

00:58:22.030 --> 00:58:25.360
because they actually have
hands on access to the data.

00:58:25.360 --> 00:58:27.400
So you want to find that.

00:58:27.400 --> 00:58:31.300
Then, you want to get a
sample or a copy of the data

00:58:31.300 --> 00:58:35.350
to your team to assess.

00:58:35.350 --> 00:58:39.870
It is always good to
do good opsec, which

00:58:39.870 --> 00:58:44.020
is good operational security,
which means fewer accounts,

00:58:44.020 --> 00:58:46.520
fewer people having
access is better.

00:58:46.520 --> 00:58:49.360
A lot of times people
say, oh, here's the data.

00:58:49.360 --> 00:58:54.220
Give me a list of names that
you want to have access to it.

00:58:54.220 --> 00:58:57.400
If you provide them one name,
that's often pretty easy

00:58:57.400 --> 00:58:59.340
to get approved.

00:58:59.340 --> 00:59:03.850
If you provide 10 names,
now questions will happen.

00:59:03.850 --> 00:59:07.160
Why are we giving 10
people access to this data?

00:59:07.160 --> 00:59:10.070
You don't really need 10 people
to have access to the data.

00:59:10.070 --> 00:59:14.200
You can just have one person get
the data on behalf of the team.

00:59:14.200 --> 00:59:16.090
That's relatively
easy to approve.

00:59:16.090 --> 00:59:19.090
You start giving a list of
20 names have access data,

00:59:19.090 --> 00:59:21.060
now there's all
kinds of questions,

00:59:21.060 --> 00:59:24.490
and that may just end
the exercise right there.

00:59:24.490 --> 00:59:28.300
And once the question starts
happening, you'll discover,

00:59:28.300 --> 00:59:31.270
well, maybe we've lost
that one, and we need

00:59:31.270 --> 00:59:33.430
to move on to someone else.

00:59:33.430 --> 00:59:36.520
And guess what, that
keeper, do they like you now

00:59:36.520 --> 00:59:38.290
that they've raised
all kinds of questions

00:59:38.290 --> 00:59:39.998
because of something
they thought was OK?

00:59:39.998 --> 00:59:40.810
Well, now we're--

00:59:40.810 --> 00:59:43.190
No, you may no
longer have a friend.

00:59:43.190 --> 00:59:43.690
Right?

00:59:43.690 --> 00:59:46.120
So you've lost a friend,
you've lost a source of data,

00:59:46.120 --> 00:59:49.720
so minimizing the
access to the data,

00:59:49.720 --> 00:59:51.610
getting just the
people access to it who

00:59:51.610 --> 00:59:55.240
need you to make your next
step is a really good practice.

00:59:55.240 --> 00:59:56.800
I have been that keeper.

00:59:56.800 --> 00:59:59.050
I have been the person
who has to approve things,

00:59:59.050 --> 01:00:01.720
and nothing makes me
shut something down

01:00:01.720 --> 01:00:04.630
quicker than when someone says,
well, I want 20 people to have

01:00:04.630 --> 01:00:05.130
accesses.

01:00:05.130 --> 01:00:07.560
I'm like, well, no.

01:00:07.560 --> 01:00:10.060
Zero works for me.

01:00:10.060 --> 01:00:11.803
That's a number in 20.

01:00:11.803 --> 01:00:14.205
(LAUGHS) Right?

01:00:14.205 --> 01:00:15.580
That's one of the
numbers, there.

01:00:15.580 --> 01:00:16.300
How about zero?

01:00:16.300 --> 01:00:17.620
That works for me.

01:00:17.620 --> 01:00:20.230
So then, once you get
a copy of the data,

01:00:20.230 --> 01:00:23.560
you then convert a sample
of it to a tabular form,

01:00:23.560 --> 01:00:27.190
you can identify the useful
columns or features in that,

01:00:27.190 --> 01:00:29.410
and then you can
get rid of the rest.

01:00:29.410 --> 01:00:31.570
That's a huge service
to your community

01:00:31.570 --> 01:00:33.850
is if you have a volume of
data, and you know, like,

01:00:33.850 --> 01:00:36.410
all of this stuff is
not going to be useful.

01:00:36.410 --> 01:00:38.350
Now you're just giving
people useful data.

01:00:38.350 --> 01:00:39.880
That's really, really valuable.

01:00:39.880 --> 01:00:41.160
That's sort of a --

01:00:41.160 --> 01:00:43.360
And since you're talking
the keeper of the data,

01:00:43.360 --> 01:00:45.100
they may have the
most information

01:00:45.100 --> 01:00:48.100
about what these different
columns or features mean.

01:00:48.100 --> 01:00:50.050
That's not a conversation
that a lot of people

01:00:50.050 --> 01:00:51.350
are going to get to have.

01:00:51.350 --> 01:00:53.600
And so, if you get to help
your whole team by saying,

01:00:53.600 --> 01:00:55.990
oh we know these
columns mean this.

01:00:55.990 --> 01:00:58.340
They're not relevant,
let's get rid of them.

01:00:58.340 --> 01:01:00.010
That's a huge service
to your community.

01:01:00.010 --> 01:01:01.030
It's less data.

01:01:01.030 --> 01:01:03.880
It makes it easier to release.

01:01:03.880 --> 01:01:08.230
You then, maybe, will, if there
is data columns or features

01:01:08.230 --> 01:01:10.270
that are sensitive
in some way, there's

01:01:10.270 --> 01:01:13.810
a variety of techniques you
can use to minimize, anonymize,

01:01:13.810 --> 01:01:17.110
possibly simulate, or use
surrogate information to make

01:01:17.110 --> 01:01:19.060
it so that you can
share that data.

01:01:19.060 --> 01:01:21.160
And there's lots of
techniques, but those

01:01:21.160 --> 01:01:23.960
are only applicable when
you know your application.

01:01:23.960 --> 01:01:26.500
So if I look at this data,
and I see this one column that

01:01:26.500 --> 01:01:29.950
might be sensitive but
valuable for my application,

01:01:29.950 --> 01:01:32.380
I can often come up
with a minimization

01:01:32.380 --> 01:01:34.240
scheme that will work for that.

01:01:34.240 --> 01:01:35.980
Because all data
analysis is based

01:01:35.980 --> 01:01:38.597
on tables, which is
mathematically just matrices,

01:01:38.597 --> 01:01:40.180
one of the most
fundamental properties

01:01:40.180 --> 01:01:42.610
of matrices that we
really, really like is

01:01:42.610 --> 01:01:44.620
that reordering the
rows or the columns

01:01:44.620 --> 01:01:46.120
doesn't change any of the math.

01:01:46.120 --> 01:01:49.210
That's kind of, like, the big
deal of matrices and tables.

01:01:49.210 --> 01:01:51.292
You can move the row,
reorder the rows,

01:01:51.292 --> 01:01:53.500
reorder the columns, and
everything should still just

01:01:53.500 --> 01:01:56.080
work, which means if
you relabel the columns

01:01:56.080 --> 01:02:00.220
or leave relabel the rows,
things should still just work,

01:02:00.220 --> 01:02:04.320
and you'll be able to
do the science you need.

01:02:04.320 --> 01:02:07.690
So a lot of times, when you
share data with researchers,

01:02:07.690 --> 01:02:10.660
information that normally
you would delete,

01:02:10.660 --> 01:02:13.050
that you would think would be
valuable for someone else--

01:02:13.050 --> 01:02:14.770
The researcher is
like, I don't care.

01:02:14.770 --> 01:02:15.270
Right?

01:02:17.680 --> 01:02:19.780
As long as it doesn't
change something fundamental

01:02:19.780 --> 01:02:22.608
about the structure of the
data, I can work with that.

01:02:22.608 --> 01:02:24.400
And again, that's
something you would never

01:02:24.400 --> 01:02:26.980
know unless you have
an end purpose in mind.

01:02:26.980 --> 01:02:30.580
So then, you want to obtain
preliminary approval to take--

01:02:30.580 --> 01:02:32.633
I have a data set, I've
worked with the keeper,

01:02:32.633 --> 01:02:35.050
is it OK for me to share this
with a broader set of people

01:02:35.050 --> 01:02:37.180
to make sure that
they like it too?

01:02:37.180 --> 01:02:38.460
That's usually easy to do.

01:02:38.460 --> 01:02:40.360
It's just a small sample.

01:02:40.360 --> 01:02:42.280
And then, you can test
with your AI users.

01:02:42.280 --> 01:02:45.190
You repeat this process until
you, basically, have data.

01:02:45.190 --> 01:02:47.145
It's like, yeah,
this is what we want,

01:02:47.145 --> 01:02:49.480
this is what we want to share,
and then, you can sort of

01:02:49.480 --> 01:02:51.460
go through the process
of how do we really get

01:02:51.460 --> 01:02:53.560
an agreement in
place to do that.

01:02:53.560 --> 01:02:55.150
You also, then,
create the folder

01:02:55.150 --> 01:02:58.690
naming structure for scaling
out to more data files.

01:02:58.690 --> 01:03:00.880
And then finally,
what's great is

01:03:00.880 --> 01:03:04.510
if you can then automate this
process at the data owner's

01:03:04.510 --> 01:03:05.620
site.

01:03:05.620 --> 01:03:07.240
It's tremendously valuable.

01:03:07.240 --> 01:03:10.540
Then you have just gifted
them a data architecture

01:03:10.540 --> 01:03:13.030
that makes their data AI ready.

01:03:13.030 --> 01:03:15.550
And then, moving
forward, they can now

01:03:15.550 --> 01:03:19.640
share with you, within their own
organization, or with others.

01:03:19.640 --> 01:03:20.140
Right?

01:03:20.140 --> 01:03:23.020
So this is incredibly valuable.

01:03:23.020 --> 01:03:25.660
Right, we said data architecture
and wrangling is often

01:03:25.660 --> 01:03:27.040
80% of the effort.

01:03:27.040 --> 01:03:29.530
You do this, you've now
eliminated potentially

01:03:29.530 --> 01:03:31.780
80% of the effort
of anyone else who

01:03:31.780 --> 01:03:34.370
ever wants to do data
analysis or AI in this data.

01:03:34.370 --> 01:03:34.870
Right?

01:03:34.870 --> 01:03:39.160
This is a phenomenally
huge win for anyone

01:03:39.160 --> 01:03:42.400
that you partnered with is to
give them a very simple data

01:03:42.400 --> 01:03:44.680
architecture they can
maintain going forward.

01:03:44.680 --> 01:03:49.670
It's a huge potential
savings to them.

01:03:49.670 --> 01:03:51.670
All right, so another
role we want to talk about

01:03:51.670 --> 01:03:55.600
is the data owner subject
matter expert, or SME.

01:03:55.600 --> 01:03:57.790
So we've talked about
the keeper of the data.

01:03:57.790 --> 01:03:59.500
There's often a
subject matter expert

01:03:59.500 --> 01:04:02.410
associated with the data
that is an advocate.

01:04:02.410 --> 01:04:04.900
The keeper is often like,
hey, I maintain the data.

01:04:04.900 --> 01:04:08.170
I do with these subject
matter experts tell me to do.

01:04:08.170 --> 01:04:09.560
But there's someone
out there who

01:04:09.560 --> 01:04:12.760
wants to help you get the
data because they see it's

01:04:12.760 --> 01:04:14.950
going to be valuable to you.

01:04:14.950 --> 01:04:20.020
And all these AI data products
are generally best made

01:04:20.020 --> 01:04:21.550
by people with AI knowledge.

01:04:21.550 --> 01:04:24.370
So we are highly
motivated to engage

01:04:24.370 --> 01:04:26.140
with these subject
matter experts,

01:04:26.140 --> 01:04:28.600
pull them into the
AI community so they

01:04:28.600 --> 01:04:30.430
can see the best practices.

01:04:30.430 --> 01:04:32.740
That will allow
them to understand

01:04:32.740 --> 01:04:36.190
which data they have, how
it might be useful to AI,

01:04:36.190 --> 01:04:39.130
and how to prepare
it, so that's better.

01:04:39.130 --> 01:04:42.100
So whenever we get engaged
with subject matter experts

01:04:42.100 --> 01:04:44.560
at other communities,
at data owners,

01:04:44.560 --> 01:04:46.870
we really want to pull
them into the community,

01:04:46.870 --> 01:04:48.430
have them come to
our environments

01:04:48.430 --> 01:04:52.260
so they can see what's going on
and help us identify new data

01:04:52.260 --> 01:04:54.910
sets and help make
those data sets

01:04:54.910 --> 01:04:58.870
appropriate for our consumption.

01:04:58.870 --> 01:05:01.630
So one of the big
things you'll run into

01:05:01.630 --> 01:05:05.070
is that there are concerns
with sharing data.

01:05:05.070 --> 01:05:07.000
That is, there's
a lot of confusion

01:05:07.000 --> 01:05:11.650
about the liability of
sharing data with researchers.

01:05:11.650 --> 01:05:15.250
And data owners often have
to think about the lowest

01:05:15.250 --> 01:05:16.510
common denominator.

01:05:16.510 --> 01:05:18.250
If it's a company,
they have to think

01:05:18.250 --> 01:05:21.040
about US and EU and
other requirements,

01:05:21.040 --> 01:05:22.420
all kinds of
different frameworks

01:05:22.420 --> 01:05:24.550
for thinking about that.

01:05:24.550 --> 01:05:27.610
The good news is there are
standard practices that

01:05:27.610 --> 01:05:30.700
meet these requirements.

01:05:30.700 --> 01:05:33.400
And I'm going to list what
these standard practices are.

01:05:33.400 --> 01:05:35.380
We have worked
with many folks who

01:05:35.380 --> 01:05:38.380
have tried to share
data successfully,

01:05:38.380 --> 01:05:42.100
and these are the properties
of successful data sharing

01:05:42.100 --> 01:05:43.180
activities.

01:05:43.180 --> 01:05:46.450
And the activities that
don't do these things often

01:05:46.450 --> 01:05:47.710
are unsuccessful.

01:05:47.710 --> 01:05:49.790
We didn't invent any of this.

01:05:49.790 --> 01:05:53.560
This is just our observations
from working with many people

01:05:53.560 --> 01:05:55.300
who've tried to share data.

01:05:55.300 --> 01:05:59.080
One, you want data available
in curated repositories.

01:05:59.080 --> 01:06:02.590
Just taking data and
posting it somewhere

01:06:02.590 --> 01:06:08.890
without proper curation really
does no good for anyone.

01:06:08.890 --> 01:06:11.230
You want to use standard
and anonymization

01:06:11.230 --> 01:06:12.560
methods where needed.

01:06:12.560 --> 01:06:14.890
Hashing, sampling,
simulation, I've already

01:06:14.890 --> 01:06:19.990
talked about those, but those
do work, particularly when they

01:06:19.990 --> 01:06:23.470
are coupled with access
requires registration

01:06:23.470 --> 01:06:25.690
with a repository
and legitimate need.

01:06:25.690 --> 01:06:29.410
So there's a data
agreement associated

01:06:29.410 --> 01:06:34.150
with getting the data in
some way, shape, or form.

01:06:34.150 --> 01:06:37.840
And those two together
really, really work well.

01:06:37.840 --> 01:06:40.685
And you also want
to focus on getting

01:06:40.685 --> 01:06:42.310
the data to the people
who are actually

01:06:42.310 --> 01:06:43.930
going to add value to it.

01:06:43.930 --> 01:06:46.390
So one of the misnomers is,
oh, we'll just take data,

01:06:46.390 --> 01:06:48.820
and we'll make it available
to all 10 billion souls

01:06:48.820 --> 01:06:52.390
on the planet earth, when,
really, less than 100

01:06:52.390 --> 01:06:56.140
could ever actually
add value to us.

01:06:56.140 --> 01:06:59.500
So why are we going through
all the trouble and the issues

01:06:59.500 --> 01:07:02.290
associated with making data
available to anyone, when

01:07:02.290 --> 01:07:05.860
really we only want to get that
data to people with the skills

01:07:05.860 --> 01:07:09.490
and legitimate research
needs to make use of it?

01:07:09.490 --> 01:07:12.820
And so, by setting up
curated repositories,

01:07:12.820 --> 01:07:14.300
people then apply--

01:07:14.300 --> 01:07:15.880
I want to get access to data--

01:07:15.880 --> 01:07:17.920
they talk about
what their need is.

01:07:17.920 --> 01:07:19.330
That sets, sort of, a swim lane.

01:07:19.330 --> 01:07:21.495
You can't just do anything
you want with the data.

01:07:21.495 --> 01:07:23.620
When you say, I'm going to
use it for this purpose,

01:07:23.620 --> 01:07:25.507
you have to stick
to those guidelines.

01:07:25.507 --> 01:07:28.090
If you want to change them, you
have to go back and say, look,

01:07:28.090 --> 01:07:29.980
I want to do
something different.

01:07:29.980 --> 01:07:31.390
If you're a
legitimate researcher

01:07:31.390 --> 01:07:34.540
with legitimate research needs,
that's usually pretty easy

01:07:34.540 --> 01:07:36.230
to approve.

01:07:36.230 --> 01:07:39.950
And then, recipients agree not
to repost the whole data set

01:07:39.950 --> 01:07:41.410
or to deanonymize it.

01:07:41.410 --> 01:07:43.840
This is what makes
anonymization work.

01:07:43.840 --> 01:07:46.120
Not that the anonymization
or the encryption

01:07:46.120 --> 01:07:48.130
is so strong it's
unbreakable, it's

01:07:48.130 --> 01:07:50.980
that people agree
not to reverse it.

01:07:50.980 --> 01:07:53.740
And the good thing about working
with legitimate researchers

01:07:53.740 --> 01:07:57.640
is they're highly motivated
not to break their agreements.

01:07:57.640 --> 01:08:00.220
If you're at MIT or any
of these universities

01:08:00.220 --> 01:08:02.260
and you break your data
sharing agreements,

01:08:02.260 --> 01:08:05.650
that is professionally
very detrimental to you

01:08:05.650 --> 01:08:09.430
because it is very detrimental
to the organization.

01:08:09.430 --> 01:08:11.770
No research or
organization ever wants

01:08:11.770 --> 01:08:16.720
to have a reputation that it
does not respect its data usage

01:08:16.720 --> 01:08:17.560
agreements.

01:08:17.560 --> 01:08:20.750
That will put that research
organization out of business.

01:08:20.750 --> 01:08:23.560
So there's a lot of incentive
for legitimate researchers

01:08:23.560 --> 01:08:25.810
to honor these
agreements, which may not

01:08:25.810 --> 01:08:29.500
be the same for just general
people who are working

01:08:29.500 --> 01:08:31.880
in other types of environments.

01:08:31.880 --> 01:08:35.410
So they can publish their
analysis and data examples

01:08:35.410 --> 01:08:38.279
as necessary, they agree
to cite the repository

01:08:38.279 --> 01:08:40.609
and provide the
publications back,

01:08:40.609 --> 01:08:43.740
and the repository can
curate enriched products.

01:08:43.740 --> 01:08:47.950
So if a researcher discovers
some derivative product--

01:08:47.950 --> 01:08:50.779
Look, I can apply
this to all the data.

01:08:50.779 --> 01:08:54.609
I'd like to have that
be posted somewhere.

01:08:54.609 --> 01:08:57.520
They can often use the
original repository to do that.

01:08:57.520 --> 01:09:00.760
And again, we encourage
everyone to encourage people

01:09:00.760 --> 01:09:02.850
to follow these guidelines.

01:09:02.850 --> 01:09:05.510
They're very beneficial.

01:09:05.510 --> 01:09:11.260
So I've talked about
the data keeper.

01:09:11.260 --> 01:09:14.170
I've talked about the
subject matter expert.

01:09:14.170 --> 01:09:16.930
Now, I'm going to talk about
a final critical role, which

01:09:16.930 --> 01:09:21.040
is the ISO, the information
security officer.

01:09:21.040 --> 01:09:25.600
In almost every single
organization that has data,

01:09:25.600 --> 01:09:27.670
there is an information
security officer

01:09:27.670 --> 01:09:31.510
that needs to sign off on making
the data available to anyone

01:09:31.510 --> 01:09:32.680
else.

01:09:32.680 --> 01:09:36.399
They're the person whose
neck is on the line

01:09:36.399 --> 01:09:40.840
and is saying that it's
OK to share this data,

01:09:40.840 --> 01:09:44.950
that the benefits outweigh
the potential risks.

01:09:44.950 --> 01:09:49.537
And subject matter experts
need to communicate the info

01:09:49.537 --> 01:09:51.120
with the information
security officer.

01:09:51.120 --> 01:09:53.109
They're often the ones
advocating for this data

01:09:53.109 --> 01:09:57.640
to be released, but they don't
know the language information

01:09:57.640 --> 01:09:59.000
security officers.

01:09:59.000 --> 01:10:01.430
And this causes huge problems.

01:10:01.430 --> 01:10:05.350
And, I would say, 90%
of data sharing efforts

01:10:05.350 --> 01:10:11.440
die because of miscommunication
between subject matter experts

01:10:11.440 --> 01:10:13.750
and information
security officers.

01:10:13.750 --> 01:10:16.720
Because the information
security officer fundamentally

01:10:16.720 --> 01:10:19.240
needs to believe that
the subject matter

01:10:19.240 --> 01:10:22.870
expert understands the risks,
understands basic security

01:10:22.870 --> 01:10:26.740
concepts in order for them to
trust them with their signature

01:10:26.740 --> 01:10:28.760
to get it released.

01:10:28.760 --> 01:10:31.630
And so, typically,
what happens is

01:10:31.630 --> 01:10:37.210
that an ISO needs a very basic
information from the subject

01:10:37.210 --> 01:10:39.190
matter expert in
order to approve

01:10:39.190 --> 01:10:41.330
the release of information.

01:10:41.330 --> 01:10:42.530
What's the project?

01:10:42.530 --> 01:10:43.520
What's the need?

01:10:43.520 --> 01:10:45.590
Where is the data going to be?

01:10:45.590 --> 01:10:48.730
Who's going to be
using it for how long?

01:10:48.730 --> 01:10:55.150
They are expecting one sentence
answers to each of these.

01:10:55.150 --> 01:10:57.190
A subject matter
expert typically

01:10:57.190 --> 01:11:01.150
replies with an entire
research proposal.

01:11:01.150 --> 01:11:04.090
And so, if I'm an
ISO and I'm trying

01:11:04.090 --> 01:11:06.760
to assess whether a subject
matter expert knows anything

01:11:06.760 --> 01:11:12.070
about security, and I gave them
really easy softball questions,

01:11:12.070 --> 01:11:13.780
and they come back
with something

01:11:13.780 --> 01:11:17.350
that clearly took them
way more time and effort

01:11:17.350 --> 01:11:19.810
that answers none of
my questions, what's

01:11:19.810 --> 01:11:23.200
my opinion going to be of
that subject matter expert

01:11:23.200 --> 01:11:25.720
and how much I
should trust them?

01:11:25.720 --> 01:11:27.065
It's going to be zero.

01:11:27.065 --> 01:11:31.360
And from that moment
onward, I'll be polite but,

01:11:31.360 --> 01:11:33.340
you know, how about zero data?

01:11:33.340 --> 01:11:34.860
That works for me.

01:11:34.860 --> 01:11:36.430
(LAUGHS) Right?

01:11:36.430 --> 01:11:38.030
That's a good number, right?

01:11:38.030 --> 01:11:40.763
So this is really important.

01:11:40.763 --> 01:11:42.430
And so, if there's
one thing we can do--

01:11:42.430 --> 01:11:44.380
Because very few
of you are ISOs.

01:11:44.380 --> 01:11:46.780
And something that my team
gets involved on a lot

01:11:46.780 --> 01:11:50.380
is to intercept this
conversation before it goes

01:11:50.380 --> 01:11:55.630
bad, is we can help
you work with ISOs,

01:11:55.630 --> 01:11:57.640
work with people who have
to release with data,

01:11:57.640 --> 01:11:59.840
and help answer these
questions in a proper way.

01:11:59.840 --> 01:12:02.720
And so, I'm going to go
through a few examples, here.

01:12:02.720 --> 01:12:06.490
So, a really common question
is, what is the data

01:12:06.490 --> 01:12:07.750
you're seeking to share?

01:12:07.750 --> 01:12:09.430
So this is a very
common question

01:12:09.430 --> 01:12:10.810
to get back from an ISO.

01:12:10.810 --> 01:12:13.373
Describe the data to be
shared, focusing on its risk

01:12:13.373 --> 01:12:15.790
to the organization if it were
to be accidentally released

01:12:15.790 --> 01:12:18.400
to the public or
otherwise misused.

01:12:18.400 --> 01:12:20.396
Very common question.

01:12:20.396 --> 01:12:23.380
And so, here's an
example answer.

01:12:23.380 --> 01:12:25.060
Very short answer.

01:12:25.060 --> 01:12:27.100
The data was collected
on these dates

01:12:27.100 --> 01:12:29.543
at this location in
accordance with our mission.

01:12:29.543 --> 01:12:31.210
The risk has been
assessed and addressed

01:12:31.210 --> 01:12:33.310
by an appropriate
combination of excision,

01:12:33.310 --> 01:12:35.380
anonymization,
and/or agreements.

01:12:35.380 --> 01:12:37.570
The release to appropriate
legitimate researchers

01:12:37.570 --> 01:12:40.870
will further our mission and
is endorsed by leadership.

01:12:40.870 --> 01:12:43.960
Very, very, very short
answer, but we've

01:12:43.960 --> 01:12:47.120
covered a lot of ground
in that short answer.

01:12:47.120 --> 01:12:48.230
And I will explain.

01:12:48.230 --> 01:12:52.480
Sentence one establishes
the, identity finite scope,

01:12:52.480 --> 01:12:55.840
and proper collection of
the data in one sentence.

01:12:55.840 --> 01:12:58.300
Sentence two establishes
that risk was assessed

01:12:58.300 --> 01:13:00.040
and that mitigations were taken.

01:13:00.040 --> 01:13:02.920
Sentence three establishes the
finite scope of the recipients,

01:13:02.920 --> 01:13:06.200
an appropriate reason for
release, and mission approval.

01:13:06.200 --> 01:13:09.220
We've covered-- we've answered
nine questions in three

01:13:09.220 --> 01:13:12.400
sentences at the level
of detail an ISO wants.

01:13:12.400 --> 01:13:15.850
An ISO can always ask you more
questions for more detail,

01:13:15.850 --> 01:13:18.950
and they're usually looking for
another one sentence answer.

01:13:18.950 --> 01:13:21.220
And you build these
up to be three, four,

01:13:21.220 --> 01:13:23.290
five sentence things
that cover broadly

01:13:23.290 --> 01:13:24.880
what you're wanting to do.

01:13:24.880 --> 01:13:27.220
And you see here, you
don't want to do anything

01:13:27.220 --> 01:13:30.095
that requires the ISO to have
detailed technical knowledge

01:13:30.095 --> 01:13:30.970
of what you're doing.

01:13:30.970 --> 01:13:34.870
They're looking for overall
scope, overall limiters

01:13:34.870 --> 01:13:37.000
on what you're doing
so that is somehow

01:13:37.000 --> 01:13:41.050
contained to a reasonable risk.

01:13:41.050 --> 01:13:44.740
Another question, here, that's
very common is where, to whom

01:13:44.740 --> 01:13:45.700
is the data going?

01:13:45.700 --> 01:13:48.310
So please describe the
intended recipients.

01:13:48.310 --> 01:13:51.070
So an example answer is the data
will be shared with researchers

01:13:51.070 --> 01:13:53.480
at a specific set
of institutions,

01:13:53.480 --> 01:13:55.630
that it will be processed
on those institution's

01:13:55.630 --> 01:13:58.810
own systems, meaning their
institutions security policies,

01:13:58.810 --> 01:14:01.060
which include password
controlled access,

01:14:01.060 --> 01:14:03.355
regular application of
system updates, encryption

01:14:03.355 --> 01:14:05.440
of mobile devices,
such as laptops,

01:14:05.440 --> 01:14:08.530
all provided access to data will
be limited to personnel working

01:14:08.530 --> 01:14:10.120
as part of this effort.

01:14:10.120 --> 01:14:13.180
Again, we've covered a
lot of ground very simply.

01:14:13.180 --> 01:14:15.430
We didn't really go
into too many details

01:14:15.430 --> 01:14:18.880
that are specific to
this particular case.

01:14:18.880 --> 01:14:22.330
And then, a final one is
what controls are there

01:14:22.330 --> 01:14:25.180
on further release,
either policy or legal?

01:14:25.180 --> 01:14:28.094
So an example is an
acceptable use guidelines

01:14:28.094 --> 01:14:30.302
that prohibit attempting to
deanonymize the data will

01:14:30.302 --> 01:14:32.344
be provided to all personnel
working on the data,

01:14:32.344 --> 01:14:34.302
publication guidelines
have been agreed to that

01:14:34.302 --> 01:14:36.810
allow for high-level statistical
findings to be published,

01:14:36.810 --> 01:14:39.760
but prohibit including any
individual data records.

01:14:39.760 --> 01:14:41.250
A set of notional
records has been

01:14:41.250 --> 01:14:43.750
provided that can be published
an example of the data format

01:14:43.750 --> 01:14:45.565
but is not part of
the actual data set.

01:14:45.565 --> 01:14:47.440
The research agreement
requires that all data

01:14:47.440 --> 01:14:48.700
be deleted at the
end of the engagement

01:14:48.700 --> 01:14:50.570
except those items
retained for publication.

01:14:50.570 --> 01:14:52.070
I'm not saying you
have to use this.

01:14:52.070 --> 01:14:53.487
But again, this
is another example

01:14:53.487 --> 01:14:55.660
of what ISOs are expecting.

01:14:55.660 --> 01:14:59.245
You give them language like
this, their confidence swells.

01:14:59.245 --> 01:15:01.400
They're like, ah, I'm
dealing with someone

01:15:01.400 --> 01:15:04.890
that understands the risks
I'm taking on their behalf.

01:15:04.890 --> 01:15:07.430
And we can move forward
in a very productive way.

01:15:07.430 --> 01:15:09.870
And if you ever have questions
about how to do this,

01:15:09.870 --> 01:15:12.050
feel free to talk to
my team or other people

01:15:12.050 --> 01:15:14.750
or other ISOs who've
had to deal with this.

01:15:14.750 --> 01:15:17.060
We actually are
working with a lot

01:15:17.060 --> 01:15:19.730
of people on this language, a
lot of people the government,

01:15:19.730 --> 01:15:22.070
to sort of get these
best practices out there.

01:15:22.070 --> 01:15:24.710
We have socialized this with
a fair number of experts

01:15:24.710 --> 01:15:27.080
in this field, and
there's general consensus

01:15:27.080 --> 01:15:29.752
this is a very good method
for helping you get data out.

01:15:29.752 --> 01:15:31.460
So that brings me to
the end of the talk.

01:15:31.460 --> 01:15:35.120
So as I said before, data
wrangling is very important,

01:15:35.120 --> 01:15:37.640
significant part of the effort.

01:15:37.640 --> 01:15:40.080
Analysis really relies
on tabular data,

01:15:40.080 --> 01:15:41.750
so that's a really good format.

01:15:41.750 --> 01:15:45.262
You can do it in very simple,
non-proprietary formats.

01:15:45.262 --> 01:15:46.970
You're going to have
to name your folders

01:15:46.970 --> 01:15:49.310
and file something,
you might as well

01:15:49.310 --> 01:15:52.130
name something that's
really generally usable.

01:15:52.130 --> 01:15:55.190
And then, finally,
co-designing, the sharing,

01:15:55.190 --> 01:15:58.840
and what the intent is at
the same time, that's doable.

01:15:58.840 --> 01:16:02.300
Generalized release of
data is very, very hard.

01:16:02.300 --> 01:16:04.340
Tailored release for
specific applications

01:16:04.340 --> 01:16:08.037
is very, very doable if you
have good communication from all

01:16:08.037 --> 01:16:09.120
the stakeholders involved.

01:16:09.120 --> 01:16:11.210
So these are just
really practical things.

01:16:11.210 --> 01:16:13.412
This isn't, sort of, fancy AI.

01:16:13.412 --> 01:16:14.870
This is, sort of,
bread and butter,

01:16:14.870 --> 01:16:17.390
how do you actually
get data analysis done.

01:16:17.390 --> 01:16:21.010
And with that, I'm happy
to take any questions. questions.