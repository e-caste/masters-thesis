WEBVTT

00:00:00.030 --> 00:00:02.420
The following content is
provided under a Creative

00:00:02.420 --> 00:00:03.840
Commons license.

00:00:03.840 --> 00:00:06.860
Your support will help MIT
OpenCourseWare continue to

00:00:06.860 --> 00:00:10.540
offer high quality educational
resources for free.

00:00:10.540 --> 00:00:13.410
To make a donation or view
additional materials from

00:00:13.410 --> 00:00:17.610
hundreds of MIT courses, visit
MIT OpenCourseWare at

00:00:17.610 --> 00:00:18.860
ocw.mit.edu.

00:00:21.020 --> 00:00:26.106
PROFESSOR: So we have Arvind
today going to talk about how

00:00:26.106 --> 00:00:30.833
actually do parallelism much
closer to hardware and all the

00:00:30.833 --> 00:00:32.470
work we have been doing.

00:00:32.470 --> 00:00:34.750
ARVIND: So first, just
a clarification.

00:00:34.750 --> 00:00:37.600
This talk is not really
about any techniques.

00:00:37.600 --> 00:00:41.590
This is some very primary ideas
that I have some new

00:00:41.590 --> 00:00:44.470
ideas on parallel programming.

00:00:44.470 --> 00:00:48.120
The second thing is 5, 6 years
ago I was going around the

00:00:48.120 --> 00:00:51.640
country giving a talk, why
hardware design can't be left

00:00:51.640 --> 00:00:54.890
to hardware designers.

00:00:54.890 --> 00:00:59.770
Because I think the way they
expressed their ideas is very,

00:00:59.770 --> 00:01:01.790
very low level from software
point of view.

00:01:01.790 --> 00:01:05.750
So I have worked pretty hard
on injecting some fairly

00:01:05.750 --> 00:01:09.350
sophisticated ideas from
software into hardware design.

00:01:09.350 --> 00:01:13.780
But it often happens when you
deal with powerful people, you

00:01:13.780 --> 00:01:15.260
get effected by it.

00:01:15.260 --> 00:01:17.240
So I have sort of come
the full cirlce.

00:01:17.240 --> 00:01:20.670
Now I'm going to show you how
hardware design can influence

00:01:20.670 --> 00:01:22.520
software design and
that's really the

00:01:22.520 --> 00:01:24.360
idea behind this talk.

00:01:24.360 --> 00:01:27.760
So that's borrowing some ideas
from hardware design.

00:01:32.600 --> 00:01:36.360
Cell processor is a very good
example of a system on a chip

00:01:36.360 --> 00:01:38.570
and this is what everybody
believes the

00:01:38.570 --> 00:01:40.570
future will look like.

00:01:40.570 --> 00:01:46.430
That you'll have fairly
symmetric things in some sense

00:01:46.430 --> 00:01:49.450
and that is needed by hardware
because hardware gets out of

00:01:49.450 --> 00:01:52.410
hand if you have wires running
all over the place.

00:01:52.410 --> 00:01:57.600
So people would like these
things to be fairly regular in

00:01:57.600 --> 00:02:03.290
some sense, but that doesn't
mean that all these styles

00:02:03.290 --> 00:02:04.200
have to be the same.

00:02:04.200 --> 00:02:09.000
So for example, you may have
very application specific

00:02:09.000 --> 00:02:12.060
blocks on your chip.

00:02:12.060 --> 00:02:16.610
So for example, in your cell
phone you have many, many

00:02:16.610 --> 00:02:19.840
blocks which are specialized,
especially all the radio

00:02:19.840 --> 00:02:21.080
communication.

00:02:21.080 --> 00:02:24.210
Because if you did that stuff
in software you may not be

00:02:24.210 --> 00:02:26.490
able to meet the performance and
even if you can meet the

00:02:26.490 --> 00:02:30.850
performance your battery will
drain instantaneously.

00:02:30.850 --> 00:02:33.590
I mean, it just takes too much
power to do that kind of

00:02:33.590 --> 00:02:36.570
computation in software.

00:02:36.570 --> 00:02:40.430
So for various reasons we need
application specific

00:02:40.430 --> 00:02:43.330
processing units and I'm
sure cell processor has

00:02:43.330 --> 00:02:46.090
quite a few of these.

00:02:46.090 --> 00:02:48.490
By the way, these application
specific units, they're often

00:02:48.490 --> 00:02:50.120
called ASICs.

00:02:50.120 --> 00:02:53.220
And you can think of them as
a separate chip, but in due

00:02:53.220 --> 00:02:56.780
course of time they become
blocks of a bigger thing.

00:02:56.780 --> 00:02:59.680
You may have general
purpose processors.

00:02:59.680 --> 00:03:03.020
Already, systems have more
than one such thing.

00:03:03.020 --> 00:03:04.470
Cell processor has how many?

00:03:04.470 --> 00:03:05.590
Like 8.

00:03:05.590 --> 00:03:05.960
PROFESSOR: Depends.

00:03:05.960 --> 00:03:09.900
Some have 8, but they
don't [OBSCURED]

00:03:09.900 --> 00:03:12.730
So the current Playstations
already list supposedly 7, but

00:03:12.730 --> 00:03:14.540
we've had only 6.

00:03:14.540 --> 00:03:18.380
So, the [OBSCURED].

00:03:18.380 --> 00:03:21.380
PROFESSOR: And high-end cell
phones have 2 general purpose

00:03:21.380 --> 00:03:31.960
processors and 2 DSPs on it,
so you certainly have --

00:03:31.960 --> 00:03:36.420
multiple processors you will
have memory banks, et cetera.

00:03:36.420 --> 00:03:38.080
And you will have structured
on-chip

00:03:38.080 --> 00:03:40.250
interconnection networks.

00:03:40.250 --> 00:03:44.080
ARVIND: So I think this
is not controllers.

00:03:44.080 --> 00:03:46.830
That this is what the trajectory
will look like in

00:03:46.830 --> 00:03:48.040
the future.

00:03:48.040 --> 00:03:50.760
That doesn't mean that all the
chips will look the same.

00:03:50.760 --> 00:03:52.900
You may have different mixes of
things depending upon the

00:03:52.900 --> 00:03:57.470
application and one of the
interesting things is can you

00:03:57.470 --> 00:04:00.250
put together one of these things
fast enough because

00:04:00.250 --> 00:04:02.660
it's very, very expensive
to design and

00:04:02.660 --> 00:04:04.210
implement these things.

00:04:04.210 --> 00:04:07.690
So really one issue that comes
up all the time is can we

00:04:07.690 --> 00:04:11.290
rapidly produce high quality
chips and surrounding systems

00:04:11.290 --> 00:04:13.310
and software for such thing?

00:04:17.240 --> 00:04:20.630
So this talk, as I said, it's
about ideas and what I'm going

00:04:20.630 --> 00:04:24.420
to do is I'm first going to tell
you how I used to think

00:04:24.420 --> 00:04:25.670
about parallel programming.

00:04:28.660 --> 00:04:31.750
And this way is all
about threads.

00:04:31.750 --> 00:04:33.350
You know, where are
my threads?

00:04:33.350 --> 00:04:36.330
And I worked on this problem
for a very, very long time.

00:04:36.330 --> 00:04:40.450
Like 20 years and this is not
necessarily wrong, You know

00:04:40.450 --> 00:04:44.550
I'm sure in this course itself
you have seen quite a bit

00:04:44.550 --> 00:04:47.090
about this and I think
tomorrow's lecture is on Cilk

00:04:47.090 --> 00:04:49.610
so you will see even
more about threads.

00:04:52.260 --> 00:04:57.500
And lately, I've been thinking
about it differently.

00:04:57.500 --> 00:05:00.870
And really the main point I
would like to get across

00:05:00.870 --> 00:05:05.250
somehow to you is now I think of
parallel little programming

00:05:05.250 --> 00:05:08.070
module as a resource.

00:05:08.070 --> 00:05:09.370
What do you mean
as a resource?

00:05:09.370 --> 00:05:13.470
I'll try to make it more
concrete, this idea.

00:05:13.470 --> 00:05:18.770
And the whole issue here is
I think this viewpoint is

00:05:18.770 --> 00:05:21.880
valuable, but it's
not proven yet.

00:05:21.880 --> 00:05:24.120
You know, so it may
not be right.

00:05:24.120 --> 00:05:27.870
So just a warning.

00:05:27.870 --> 00:05:32.690
I've been working with this on
students, in particular.

00:05:32.690 --> 00:05:34.730
Now those of you who have
heard of transactional

00:05:34.730 --> 00:05:38.580
programming, lots of things I
will say you'll say oh, you

00:05:38.580 --> 00:05:40.140
mean a transaction?

00:05:40.140 --> 00:05:43.580
Yes, I mean there are very, very
strong connections for

00:05:43.580 --> 00:05:45.960
transactional stuff, but that's
not the language I'm

00:05:45.960 --> 00:05:48.870
going to be using here.

00:05:48.870 --> 00:05:50.220
These slides are color-coded.

00:05:50.220 --> 00:05:54.130
So when I was talking about old
world thinking it's yellow

00:05:54.130 --> 00:05:57.930
and when it's new thinking
then it's white.

00:05:57.930 --> 00:06:01.390
So well, I think you probably
have already heard this.

00:06:01.390 --> 00:06:05.180
That the only reason for
parallel programming used to

00:06:05.180 --> 00:06:06.250
be performance.

00:06:06.250 --> 00:06:08.980
This made programming
extremely difficult.

00:06:08.980 --> 00:06:11.730
You had to know a lot
about the machine.

00:06:11.730 --> 00:06:14.300
You were programming in code
were not portable.

00:06:14.300 --> 00:06:16.490
Endless performance tuning,
all this still goes on.

00:06:16.490 --> 00:06:19.630
I mean, very few of these
things have changed.

00:06:19.630 --> 00:06:21.740
Parallel libraries were
not composable.

00:06:21.740 --> 00:06:25.230
And this is one of the main
things I worry about a lot and

00:06:25.230 --> 00:06:27.550
I think Allen was alluding
to it too.

00:06:27.550 --> 00:06:29.710
Somebody has code, he just wants
to run the damn thing.

00:06:29.710 --> 00:06:31.880
You know, even at factor
of 2 speed that

00:06:31.880 --> 00:06:33.420
would be what fantastic.

00:06:33.420 --> 00:06:35.060
You know, often it
runs slower.

00:06:35.060 --> 00:06:38.200
Very, very fun, machines.

00:06:38.200 --> 00:06:40.580
Very different to deal with
heap structures and memory

00:06:40.580 --> 00:06:42.530
hierarchies.

00:06:42.530 --> 00:06:48.060
And then there is always the
synchronization cost issue.

00:06:48.060 --> 00:06:50.340
In some sense parallel
programming doesn't make sense

00:06:50.340 --> 00:06:53.480
if there is no synchronization
going on and that's like this

00:06:53.480 --> 00:06:56.820
embarrsingly parallel
computation you just start off

00:06:56.820 --> 00:06:58.770
and things never talk
to each other.

00:06:58.770 --> 00:07:01.880
In even moderately interesting
parallel programs there's

00:07:01.880 --> 00:07:06.740
always some communication
between various tasks and when

00:07:06.740 --> 00:07:10.290
that happens synchronization
cost becomes an issue and it

00:07:10.290 --> 00:07:13.570
is such a major issue right
now that you have to think

00:07:13.570 --> 00:07:14.530
about it out front.

00:07:14.530 --> 00:07:18.620
Oh, if I synchronize too much
then I know for a fact that my

00:07:18.620 --> 00:07:21.240
program's going to
run like a dog.

00:07:21.240 --> 00:07:23.750
So you try to avoid
synchronization and make

00:07:23.750 --> 00:07:26.590
things coarser and so on.

00:07:26.590 --> 00:07:30.240
Really the whole issue used to
be how to exploit hundreds of

00:07:30.240 --> 00:07:34.480
threads from software because
new hardware will support

00:07:34.480 --> 00:07:35.730
many, many threads.

00:07:38.190 --> 00:07:40.760
But at the same time, it's
important to understand that

00:07:40.760 --> 00:07:44.180
in this world there's always
virtualization.

00:07:44.180 --> 00:07:46.590
So number of threads in your
machine is never going to

00:07:46.590 --> 00:07:50.000
match exactly what you have
in your application.

00:07:50.000 --> 00:07:53.720
So any programming model you
have, virtualization is a very

00:07:53.720 --> 00:07:55.130
important aspect of it.

00:07:55.130 --> 00:07:59.320
That I have n threads and n may
be dynamic, maybe varying

00:07:59.320 --> 00:08:02.820
with time in my application,
but in hardware I have some

00:08:02.820 --> 00:08:05.000
fixed number of threads.

00:08:05.000 --> 00:08:08.970
Which is significantly smaller
in general than what you have

00:08:08.970 --> 00:08:10.680
in your application.

00:08:10.680 --> 00:08:13.830
So the thing I was most
interested in all those days

00:08:13.830 --> 00:08:17.410
was what I call implicit
parallelism.

00:08:17.410 --> 00:08:20.550
And from the questions I was
hearing about analysis you're

00:08:20.550 --> 00:08:24.550
doing of your programs, all
those issues come up there.

00:08:24.550 --> 00:08:27.560
You know, given some code can I
figure out what can be done

00:08:27.560 --> 00:08:31.470
in parallel and just
run it like that?

00:08:31.470 --> 00:08:35.860
So expect parallelism from
programs written in sequential

00:08:35.860 --> 00:08:40.200
languages and people like some
of the champions in this and I

00:08:40.200 --> 00:08:42.740
have also spent lots
and lots of time on

00:08:42.740 --> 00:08:45.480
this research problem.

00:08:45.480 --> 00:08:48.690
So this is one of those areas
which certainly has not

00:08:48.690 --> 00:08:51.490
suffered because of
lack of research.

00:08:51.490 --> 00:08:54.540
There's tons and tons
of research in this.

00:08:54.540 --> 00:08:58.110
You know, you can go to IBM and
there will be 50 Ph.D.'s

00:08:58.110 --> 00:08:59.990
working on Fortran compiler.

00:08:59.990 --> 00:09:01.300
Trying to extract parallelism.

00:09:04.060 --> 00:09:06.050
But the success is limited.

00:09:06.050 --> 00:09:09.220
In fact, the main takeaway from
this research is people

00:09:09.220 --> 00:09:12.520
have learned now how they should
write their programs so

00:09:12.520 --> 00:09:15.930
that compiler has a chance of
extracting parallelism.

00:09:15.930 --> 00:09:18.000
Because now people look at your
code, they say, well,

00:09:18.000 --> 00:09:19.140
this is a bad code.

00:09:19.140 --> 00:09:19.410
Why?

00:09:19.410 --> 00:09:22.890
Because compiler can't
analyze it.

00:09:22.890 --> 00:09:27.180
You become part of the
equation in this.

00:09:27.180 --> 00:09:31.470
Now the methodology I was
pushing for a long time was

00:09:31.470 --> 00:09:33.080
functional languages.

00:09:33.080 --> 00:09:35.460
Programs in functional languages
which may not

00:09:35.460 --> 00:09:38.350
obscure parallelism in
the first place.

00:09:38.350 --> 00:09:41.160
I'm not going to talk about
functional languages.

00:09:41.160 --> 00:09:45.110
It's immaterial, you know,
whether this is a good idea or

00:09:45.110 --> 00:09:49.460
a bad idea, the fact of matter
is in real life people's

00:09:49.460 --> 00:09:51.520
reaction is functional
languages--

00:09:51.520 --> 00:09:52.770
are you kidding me?

00:09:55.210 --> 00:09:57.970
So it doesn't get off ground.

00:09:57.970 --> 00:10:00.580
It's one of those things I can
come and preach to you is good

00:10:00.580 --> 00:10:01.700
for your soul.

00:10:01.700 --> 00:10:03.710
And they leave me alone.

00:10:03.710 --> 00:10:08.630
I don't do movies
with subtitles.

00:10:08.630 --> 00:10:11.790
AUDIENCE: Sorry to temporarily
derail you--

00:10:11.790 --> 00:10:11.970
ARVIND: Sorry?

00:10:11.970 --> 00:10:17.380
AUDIENCE: Sorry to temporarily
derail you, so what kind of

00:10:17.380 --> 00:10:22.180
parallelism is easier
to extract from

00:10:22.180 --> 00:10:23.520
a functional language?

00:10:23.520 --> 00:10:29.330
I can clearly see some task
parallelism, can you also

00:10:29.330 --> 00:10:31.940
extract data parallelism
or pipeline

00:10:31.940 --> 00:10:34.400
parallelism or what not?

00:10:34.400 --> 00:10:36.290
ARVIND: It turns out that's
actually not that right

00:10:36.290 --> 00:10:39.430
question to ask in the
functional language because

00:10:39.430 --> 00:10:43.220
functional language doesn't
obscure the parallelism that

00:10:43.220 --> 00:10:44.440
was there in the first place.

00:10:44.440 --> 00:10:48.150
So you already have a partial
order on operations as opposed

00:10:48.150 --> 00:10:49.470
to a sequential order.

00:10:49.470 --> 00:11:00.580
You see when you write in
Fortran even a simple thing

00:11:00.580 --> 00:11:08.790
like f of g of x, h of y.

00:11:08.790 --> 00:11:11.380
It may be obvious to a
functional programmer that

00:11:11.380 --> 00:11:12.680
these things can be
done in parallel.

00:11:12.680 --> 00:11:15.510
Perhaps, the execution of these
can overlap with the

00:11:15.510 --> 00:11:18.830
evaluation of f, but that's not
the semantics of Fortran

00:11:18.830 --> 00:11:20.900
or any other sequential
language.

00:11:20.900 --> 00:11:22.960
The semantics is you're supposed
to execute the

00:11:22.960 --> 00:11:25.690
program left to right,
top to bottom.

00:11:25.690 --> 00:11:29.390
So you will go and execute g
first and you'll go inside g

00:11:29.390 --> 00:11:33.450
and execute it and then you will
go and execute h and then

00:11:33.450 --> 00:11:36.190
you will go and execute f.

00:11:36.190 --> 00:11:37.280
Why is that important?

00:11:37.280 --> 00:11:40.550
Because there are side effects,
so it's conceivable

00:11:40.550 --> 00:11:45.920
that you do something in this
which affects this and so on.

00:11:45.920 --> 00:11:49.880
So you're given a sequential
order and then compiler does

00:11:49.880 --> 00:11:52.660
deep analysis, the kind you're
doing right now it terms of

00:11:52.660 --> 00:11:55.540
dependence and anti-dependence
and so on.

00:11:55.540 --> 00:11:59.760
Which says it's OK to do
g and h in parallel.

00:11:59.760 --> 00:12:02.790
Well, if it was a functional
program then you know by the

00:12:02.790 --> 00:12:06.830
semantics of the language g and
h can be done in parallel.

00:12:06.830 --> 00:12:09.630
That doesn't mean it's a good
idea to do it in parallel.

00:12:09.630 --> 00:12:11.930
So when we get to the second
point of mapping this

00:12:11.930 --> 00:12:16.870
computation onto a given
substrate off 2 processors or

00:12:16.870 --> 00:12:19.320
10 processors then problems
become similar.

00:12:19.320 --> 00:12:23.440
But the problem of detecting
parallelism is very different.

00:12:23.440 --> 00:12:25.940
Because you don't talk of
detecting parallelism in

00:12:25.940 --> 00:12:28.480
functional languages,
it's already there.

00:12:28.480 --> 00:12:30.280
You don't obscure it.

00:12:30.280 --> 00:12:32.090
Does that make sense?

00:12:32.090 --> 00:12:35.560
AUDIENCE: Yeah, maybe.

00:12:35.560 --> 00:12:38.970
ARVIND: And it goes without
saying that if your algorithm

00:12:38.970 --> 00:12:42.010
has low parallelism then
functional languages or any

00:12:42.010 --> 00:12:43.750
other language and there's
no magic--

00:12:43.750 --> 00:12:46.440
you can't suck blood
out of stone.

00:12:46.440 --> 00:12:47.660
You have to know
your algorithm.

00:12:47.660 --> 00:12:49.640
You have to know
what operations

00:12:49.640 --> 00:12:52.080
can be done in parallel.

00:12:52.080 --> 00:12:54.690
So language only is an aid.

00:12:54.690 --> 00:12:57.380
In some sense that if it was
parallel I could express it

00:12:57.380 --> 00:13:00.670
more easily as a parallel
program.

00:13:00.670 --> 00:13:03.070
And if it's a bad language, you
obscure it and then you

00:13:03.070 --> 00:13:04.320
try to undo the damage.

00:13:06.820 --> 00:13:10.410
Now as I said, there has been
a lot of success in this in

00:13:10.410 --> 00:13:14.810
terms of dense matrix kind of
stuff, but more irregular the

00:13:14.810 --> 00:13:19.500
computation harder it gets to
do these things statically.

00:13:19.500 --> 00:13:23.410
So when you can't do it then
people of course, designed

00:13:23.410 --> 00:13:27.090
explicitly parallel programming
models and some of

00:13:27.090 --> 00:13:32.070
the most successful ones in
this are data parallel and

00:13:32.070 --> 00:13:32.820
you'll hear about

00:13:32.820 --> 00:13:36.130
multithreading tomorrow in Cilk.

00:13:36.130 --> 00:13:38.060
And then there are very low
level models where you are

00:13:38.060 --> 00:13:42.690
doing actual message passing
between various modules that

00:13:42.690 --> 00:13:46.700
are sitting over there and I
can expose you threads and

00:13:46.700 --> 00:13:48.600
synchronizations that are
very low-level fork

00:13:48.600 --> 00:13:50.590
and joint, et cetera.

00:13:50.590 --> 00:13:55.220
So of course, high-level models
are preferable because

00:13:55.220 --> 00:13:58.330
you're likely to make fewer
errors in them.

00:13:58.330 --> 00:14:00.510
The question is, can
we compile them?

00:14:00.510 --> 00:14:05.190
And in some cases what turns out
is this is a good model,

00:14:05.190 --> 00:14:07.010
but it is not general enough.

00:14:07.010 --> 00:14:11.230
So if you have a data parallel
algorithm, fine.

00:14:11.230 --> 00:14:12.800
I mean, you should
use these things.

00:14:12.800 --> 00:14:17.000
But not all applications fit
the data parallel model,

00:14:17.000 --> 00:14:21.500
multithreading in some sense
is more general.

00:14:21.500 --> 00:14:28.280
This is what I mean by a
multithreaded model that you

00:14:28.280 --> 00:14:32.210
may have a main which
spawn off things.

00:14:32.210 --> 00:14:35.790
So not only these things can
be done in parallel, but

00:14:35.790 --> 00:14:39.380
execution of these can overlap
the execution of f.

00:14:39.380 --> 00:14:42.870
So parents and children may be
executing simultaneously.

00:14:42.870 --> 00:14:46.930
So if you look at this as an
activation tree, this invokes

00:14:46.930 --> 00:14:50.450
a loop which has many, many
iterations in it.

00:14:50.450 --> 00:14:53.460
When we talk of sequential
computing you're always

00:14:53.460 --> 00:14:57.780
sitting on one branch of this.

00:14:57.780 --> 00:14:59.230
So that's the stack.

00:14:59.230 --> 00:15:02.670
This stack, this stack,
stack frames.

00:15:02.670 --> 00:15:06.130
When you talk of parallel
computing then part of this

00:15:06.130 --> 00:15:09.570
activation tree is concurrently
active.

00:15:09.570 --> 00:15:11.350
So all problems get harder.

00:15:11.350 --> 00:15:13.410
Storage management
gets harder.

00:15:13.410 --> 00:15:16.410
And what gets especially harder
is that there is this

00:15:16.410 --> 00:15:17.920
global heap.

00:15:17.920 --> 00:15:21.130
You always have heap in
interesting programs, global

00:15:21.130 --> 00:15:22.320
data structures.

00:15:22.320 --> 00:15:25.880
Now the problem is if this and
this are active at the same

00:15:25.880 --> 00:15:27.900
time or this and this are active
at the same time and

00:15:27.900 --> 00:15:30.360
they are both reading and
writing into the data

00:15:30.360 --> 00:15:32.340
structure then naturally
there's a race

00:15:32.340 --> 00:15:34.280
condition in this.

00:15:34.280 --> 00:15:38.030
Even if only 1 guy's writing and
5 people are reading it.

00:15:38.030 --> 00:15:41.490
It's a question of the guy
should not read it too soon.

00:15:41.490 --> 00:15:45.370
So the moment you do any kind
of parallel programming,

00:15:45.370 --> 00:15:48.220
synchronization issues
arise immediately.

00:15:48.220 --> 00:15:51.780
You know, you always have to
worry about, how do I indicate

00:15:51.780 --> 00:15:54.300
that it's OK to read this?

00:15:54.300 --> 00:15:56.040
Well, you can follow
some control ideas.

00:15:56.040 --> 00:15:57.860
You say, this guy was writing.

00:15:57.860 --> 00:16:00.870
He has finished execution, so
it must be OK to write.

00:16:00.870 --> 00:16:03.310
Or you can go to very
fine-grained synchronization,

00:16:03.310 --> 00:16:06.550
you can have some bit here which
says, oh this data has

00:16:06.550 --> 00:16:10.240
been updated, now it's
OK to unlock it and

00:16:10.240 --> 00:16:11.730
read it and so on.

00:16:11.730 --> 00:16:14.175
So all these ideas have been
explored and they're still

00:16:14.175 --> 00:16:17.580
being explored in
this context.

00:16:17.580 --> 00:16:22.270
The main takeaway is instead
of a stack you will have a

00:16:22.270 --> 00:16:25.380
tree which is active
at the same time.

00:16:25.380 --> 00:16:26.880
Many, many things
are going on.

00:16:26.880 --> 00:16:29.050
And the second thing is that
there is a competition.

00:16:29.050 --> 00:16:32.750
There is a race in reading the
heap data structures and

00:16:32.750 --> 00:16:35.770
therefore you have to worry
about that you don't read it

00:16:35.770 --> 00:16:38.200
too soon or you don't write it
too soon because if you write

00:16:38.200 --> 00:16:40.720
it too soon you may clobber
before somebody else gets a

00:16:40.720 --> 00:16:42.320
chance to read it.

00:16:42.320 --> 00:16:44.830
So these issues are
quite serious.

00:16:48.180 --> 00:16:50.870
Now it's really possible--

00:16:50.870 --> 00:16:54.890
I mean, I claim you know, I
have languages which can

00:16:54.890 --> 00:16:58.290
express computation very
efficiently this way.

00:16:58.290 --> 00:16:59.486
Efficiently is not
the right word.

00:16:59.486 --> 00:17:03.130
Very easily you can express
computation in this way.

00:17:03.130 --> 00:17:07.700
But at the end of the day the
goal is to take that stuff and

00:17:07.700 --> 00:17:11.000
run it somewhere on some
parallel machine.

00:17:11.000 --> 00:17:13.600
Whether it was cell processor in
the old days if would have

00:17:13.600 --> 00:17:15.920
been parallel machines
of various ergs.

00:17:15.920 --> 00:17:20.230
And that has proven to be quite
difficult, efficient

00:17:20.230 --> 00:17:23.610
mapping of these things because
it turns out that you

00:17:23.610 --> 00:17:25.990
say, oh, you didn't tell me
before you have only 2

00:17:25.990 --> 00:17:27.550
processors.

00:17:27.550 --> 00:17:31.970
Then I would have expressed the
computation differently.

00:17:31.970 --> 00:17:34.720
Or you didn't tell me that
you have 1000 processors.

00:17:34.720 --> 00:17:38.740
So there is this kind of yes,
there is virtualization.

00:17:38.740 --> 00:17:41.310
But it's not virtualization
enough.

00:17:41.310 --> 00:17:43.030
Qualitatively matters a lot.

00:17:43.030 --> 00:17:44.070
You know, what is the target?

00:17:44.070 --> 00:17:46.820
And that effects how you would
have expressed the

00:17:46.820 --> 00:17:49.360
computation.

00:17:49.360 --> 00:17:53.940
So I used to go around saying
this all the time that

00:17:53.940 --> 00:17:57.370
parallel programming
is so important.

00:17:57.370 --> 00:17:59.920
That really sequential
programming will be taught as

00:17:59.920 --> 00:18:03.310
a special case of parallel
programming because it will be

00:18:03.310 --> 00:18:05.630
all parallel.

00:18:05.630 --> 00:18:07.710
If you have only one processor
then we can teach you some

00:18:07.710 --> 00:18:11.540
special tricks how to run it
efficiently on one processor.

00:18:11.540 --> 00:18:16.450
So this as you can see, is
largely an unrealized dream.

00:18:16.450 --> 00:18:19.360
AUDIENCE: That's an old idea,
but not one to be dismissed.

00:18:19.360 --> 00:18:20.560
ARVIND: Not one to
be dismissed.

00:18:20.560 --> 00:18:21.640
Absolutely.

00:18:21.640 --> 00:18:25.960
So the question is, has
the situation changed?

00:18:25.960 --> 00:18:29.730
And the situation has
certainly changed.

00:18:29.730 --> 00:18:30.980
So multicores have arrived.

00:18:33.090 --> 00:18:33.810
This is a big deal.

00:18:33.810 --> 00:18:38.410
I mean, Microsoft wants to
exploit parallelism.

00:18:38.410 --> 00:18:43.030
There can be no bigger
indication than this.

00:18:43.030 --> 00:18:46.700
And there is explosion
of cell phones.

00:18:46.700 --> 00:18:49.290
And if you don't understand what
that means economically,

00:18:49.290 --> 00:18:51.550
you know there are 100 million
PCs that will be sold this

00:18:51.550 --> 00:18:56.890
year and 950 million
cell phones that'll

00:18:56.890 --> 00:18:58.420
be sold this year.

00:18:58.420 --> 00:19:00.560
This is the same kind of
transition that is taking

00:19:00.560 --> 00:19:03.180
place that happened in the early
80s when we went from

00:19:03.180 --> 00:19:06.920
mainframes and mini- computers
to micros.

00:19:06.920 --> 00:19:08.930
So what happens there determines
what happens

00:19:08.930 --> 00:19:09.580
everywhere else.

00:19:09.580 --> 00:19:13.020
So it's quite possible then what
happens on these small

00:19:13.020 --> 00:19:17.050
devices, hand-held devices
will determine the

00:19:17.050 --> 00:19:19.070
architecture of everything
else just

00:19:19.070 --> 00:19:20.270
because of the numbers.

00:19:20.270 --> 00:19:23.750
People are willing to invest
a lot more money into this

00:19:23.750 --> 00:19:26.330
explosion of game boxes.

00:19:26.330 --> 00:19:28.410
AUDIENCE: [OBSCURED]

00:19:28.410 --> 00:19:29.170
ARVIND: I'm sorry?

00:19:29.170 --> 00:19:31.900
AUDIENCE: The explosion of
laptops is also happening.

00:19:31.900 --> 00:19:35.610
ARVIND: Yeah, but still that
number is 100 million.

00:19:35.610 --> 00:19:38.810
While cell phone is 950 million,
at least in 2000.

00:19:38.810 --> 00:19:40.240
AUDIENCE: These are
cell processors.

00:19:40.240 --> 00:19:41.630
ARVIND: Right.

00:19:41.630 --> 00:19:43.220
Absolutely.

00:19:43.220 --> 00:19:48.760
So look, if I'm talking to you
as a teacher I mean, my

00:19:48.760 --> 00:19:52.170
message to my colleagues in
the department is it's no

00:19:52.170 --> 00:19:54.780
longer good enough to say well
we'll teach you parallelism

00:19:54.780 --> 00:19:57.890
when you're a sophomore.

00:19:57.890 --> 00:19:59.940
I mean, it is the thing that
people want to deal with.

00:19:59.940 --> 00:20:01.300
You say, what do you
mean telling me how

00:20:01.300 --> 00:20:02.520
to program one processor.

00:20:02.520 --> 00:20:06.040
I have 10 of them
in my pocket.

00:20:06.040 --> 00:20:08.670
So I think we have to
deal with this.

00:20:08.670 --> 00:20:10.350
You know, how do we introduce
parallelism?

00:20:10.350 --> 00:20:14.740
What method we should have for
teaching parallel programming

00:20:14.740 --> 00:20:17.030
so that is the default
programming

00:20:17.030 --> 00:20:20.630
model in your head?

00:20:20.630 --> 00:20:21.830
So it's all about
parallelism now.

00:20:21.830 --> 00:20:24.590
No longer an advanced topic.

00:20:24.590 --> 00:20:27.590
It has to be the first topic.

00:20:27.590 --> 00:20:30.390
Just another word of
caution in this.

00:20:30.390 --> 00:20:31.800
So let's look at cell phones.

00:20:34.810 --> 00:20:40.630
So mine has some bugs in it so
sometimes it misses a call

00:20:40.630 --> 00:20:43.280
when I'm surfing the web.

00:20:43.280 --> 00:20:44.530
It doesn't rate.

00:20:47.896 --> 00:20:51.330
So this is the deep question
now, so whose fault is it?

00:20:54.000 --> 00:20:56.410
So for example, to what extent
the phone call software should

00:20:56.410 --> 00:21:00.570
be aware of web surfing software
or vice versa.

00:21:00.570 --> 00:21:03.220
So now you have to understand
how these things are done.

00:21:03.220 --> 00:21:05.973
Of course, how the phone calls
are made, that software has

00:21:05.973 --> 00:21:07.640
been evolving, right?

00:21:07.640 --> 00:21:11.825
You can look at it all in the
last 15 years and you'll be

00:21:11.825 --> 00:21:13.190
able to trace a continuum.

00:21:13.190 --> 00:21:16.470
You know how phone calls are
made and that's not trivial

00:21:16.470 --> 00:21:20.870
among the software on
your cell phone.

00:21:20.870 --> 00:21:24.000
Well, when it comes to web
surfing software I can

00:21:24.000 --> 00:21:27.770
guarantee you it was not
written from scratch.

00:21:27.770 --> 00:21:29.420
People went to your PC,
they say, what do

00:21:29.420 --> 00:21:30.340
you do on your web?

00:21:30.340 --> 00:21:32.840
They take all that software
say, let's port

00:21:32.840 --> 00:21:35.180
it on the cell phone.

00:21:35.180 --> 00:21:38.330
Now the guy who wrote the web
software never thought that

00:21:38.330 --> 00:21:41.300
you would be talking on
telephone while you're surfing

00:21:41.300 --> 00:21:44.670
the web or at least not
on the same device.

00:21:44.670 --> 00:21:47.290
And vice versa, the guy who
wrote the phone software never

00:21:47.290 --> 00:21:51.210
thought you would be surfing the
web while you're talking

00:21:51.210 --> 00:21:52.350
on the phone.

00:21:52.350 --> 00:21:57.740
I mean even 1995 or 1998 if
somebody had said, you'll be

00:21:57.740 --> 00:21:59.510
surfing the web at
the same time.

00:21:59.510 --> 00:22:00.850
It would have sounded
pretty bizarre.

00:22:07.890 --> 00:22:09.100
Is it merely a scheduling
issue?

00:22:09.100 --> 00:22:11.790
So this is the answer saying
ah, they didn't process the

00:22:11.790 --> 00:22:13.830
interrupt properly.

00:22:13.830 --> 00:22:16.540
I'm sorry, this is not just
a scheduling issue.

00:22:16.540 --> 00:22:19.160
I don't even know the
semantics of this.

00:22:19.160 --> 00:22:22.370
So for example, if you're
surfing the web and the phone

00:22:22.370 --> 00:22:25.390
rings do you really want to stop
surfing the web and pick

00:22:25.390 --> 00:22:27.010
up the phone?

00:22:27.010 --> 00:22:28.440
I mean, what's so special
about phone?

00:22:28.440 --> 00:22:31.180
There is nothing being indicated
from the language

00:22:31.180 --> 00:22:32.070
point of view.

00:22:32.070 --> 00:22:35.850
It may be application
requirement that you want to

00:22:35.850 --> 00:22:38.120
stop it or not stop
it and so on.

00:22:40.800 --> 00:22:42.160
Is it a performance issue?

00:22:42.160 --> 00:22:44.820
That oh, it's because you have
only 2 processors in this.

00:22:44.820 --> 00:22:47.670
If you had 4 this problem
will go away.

00:22:47.670 --> 00:22:50.510
Or if you could just run it
faster it will go away.

00:22:50.510 --> 00:22:53.800
I don't think any of these
answers are right.

00:22:53.800 --> 00:22:57.550
I mean, the bottom line in this
is sequential modules are

00:22:57.550 --> 00:23:00.930
often used in concurrent
environments with unforeseen

00:23:00.930 --> 00:23:03.510
consequences.

00:23:03.510 --> 00:23:06.520
So your mindset has to be that
I'm going to put together a

00:23:06.520 --> 00:23:11.620
parallel program with lots
of existing things.

00:23:11.620 --> 00:23:14.260
Because you can't keep giving
the answer oh, let's just

00:23:14.260 --> 00:23:16.650
rewrite it again from scratch.

00:23:16.650 --> 00:23:20.250
Because amount of software
is so enormous in this.

00:23:20.250 --> 00:23:22.580
What we should worry about
now is how we should

00:23:22.580 --> 00:23:23.750
design these modules.

00:23:23.750 --> 00:23:28.080
How we should write pieces of
software or design hardware so

00:23:28.080 --> 00:23:32.420
that we can put together an
ensemble of them, a collection

00:23:32.420 --> 00:23:36.800
of such modules so that they
do something useful.

00:23:36.800 --> 00:23:38.000
And it's all about
parallelism.

00:23:38.000 --> 00:23:41.990
And how to do all this in
a parallel setting.

00:23:41.990 --> 00:23:44.800
OK, so new goals as opposed
to old goals.

00:23:44.800 --> 00:23:47.740
So I don't want to think in
terms of decomposition.

00:23:47.740 --> 00:23:49.770
I don't want to think in terms
of here is my clever

00:23:49.770 --> 00:23:54.590
algorithm, how do I decompose it
so that this runs here and

00:23:54.590 --> 00:23:56.320
this runs here and so on.

00:23:56.320 --> 00:23:59.280
Instead I want to think
in terms of synthesis.

00:23:59.280 --> 00:24:03.630
That you've already given me
lots of modules, which are

00:24:03.630 --> 00:24:04.360
very useful.

00:24:04.360 --> 00:24:06.440
Which perhaps are written
by domain experts.

00:24:06.440 --> 00:24:09.170
They know something
about that stuff.

00:24:09.170 --> 00:24:11.660
And can I put together a
bigger application very

00:24:11.660 --> 00:24:13.820
quickly from it?

00:24:13.820 --> 00:24:16.520
And you know, another favorite
example of mine in this regard

00:24:16.520 --> 00:24:19.650
is FFTW and linear
algebra packages.

00:24:19.650 --> 00:24:21.830
Both have been optimized
to the hilt, right?

00:24:21.830 --> 00:24:26.910
And if somebody gives you an
application which calls FFT

00:24:26.910 --> 00:24:30.540
and uses enough linear algebra
I guarantee you that program

00:24:30.540 --> 00:24:33.870
will not be easy to write in
spite of the existence of both

00:24:33.870 --> 00:24:38.210
these packages, which are
extremely well optimized.

00:24:38.210 --> 00:24:41.240
So there is something we're not
paying attention to is,

00:24:41.240 --> 00:24:45.080
how do we bring parallel modules
together in such a way

00:24:45.080 --> 00:24:47.460
so that the functionality, the
performance, et cetera are

00:24:47.460 --> 00:24:49.330
unpredictable in some sense?

00:24:49.330 --> 00:24:49.760
AUDIENCE: I'm sorry.

00:24:49.760 --> 00:24:52.730
What's your point?

00:24:52.730 --> 00:24:54.970
I think I agree with your point,
I just want to make

00:24:54.970 --> 00:24:56.960
sure I understand your point.

00:24:56.960 --> 00:25:00.030
That FFTW linear algorithm
is not enough and

00:25:00.030 --> 00:25:01.670
so there will be--

00:25:01.670 --> 00:25:02.260
ARVIND: No, no.

00:25:02.260 --> 00:25:04.870
I think it's very
well done, FFTW.

00:25:04.870 --> 00:25:07.040
Linear algebra is
very well done.

00:25:07.040 --> 00:25:10.900
But we still haven't provided
any good way of thinking in

00:25:10.900 --> 00:25:12.700
terms of two parallel things.

00:25:12.700 --> 00:25:15.110
You know, what happens
when they interact?

00:25:15.110 --> 00:25:18.500
So if my program is calling
FFTW often and then it's

00:25:18.500 --> 00:25:20.820
calling linear algebra often.

00:25:20.820 --> 00:25:24.805
AUDIENCE: You weren't here when
I mentioned that but I

00:25:24.805 --> 00:25:26.990
was actually bringing up the
point of linear algebra and

00:25:26.990 --> 00:25:28.710
FFTW working together.

00:25:28.710 --> 00:25:29.690
Just working.

00:25:29.690 --> 00:25:31.940
ARVIND: Exactly.

00:25:36.100 --> 00:25:37.400
Absolutely.

00:25:37.400 --> 00:25:40.680
I'm saying in that sense, you
see, this is a difference way

00:25:40.680 --> 00:25:43.600
of thinking because the old way
of thinking well, give me

00:25:43.600 --> 00:25:44.640
your application.

00:25:44.640 --> 00:25:46.320
Now let's decompose it.

00:25:46.320 --> 00:25:51.090
The point is I don't have
experts who can write FFTW as

00:25:51.090 --> 00:25:53.420
well as Matel wrote it.

00:25:53.420 --> 00:25:55.910
Or who's linear algebra packages
are being written.

00:25:55.910 --> 00:25:57.770
I want to use those things.

00:25:57.770 --> 00:26:00.590
I want to synthesize large
parallel programs quickly.

00:26:00.590 --> 00:26:00.900
Yes?

00:26:00.900 --> 00:26:04.210
AUDIENCE: How does the Apple
iPhone work with--

00:26:04.210 --> 00:26:05.623
ARVIND: I'm sorry, how does?

00:26:05.623 --> 00:26:06.596
AUDIENCE: The iPhone.

00:26:06.596 --> 00:26:07.570
AUDIENCE: Apple iPhone.

00:26:07.570 --> 00:26:08.050
ARVIND: Apple iPhone?

00:26:08.050 --> 00:26:12.090
AUDIENCE: Yes, they have the
operating system on there--

00:26:12.090 --> 00:26:14.090
ARVIND: I think from our point
of view that's the same thing.

00:26:14.090 --> 00:26:17.490
Is just that the user interface
is guaranteed to be

00:26:17.490 --> 00:26:21.470
far superior because in my phone
when I see the icons I'm

00:26:21.470 --> 00:26:24.490
a techie and I still can't
understand half of them.

00:26:24.490 --> 00:26:26.160
So I like Apples idea.

00:26:26.160 --> 00:26:28.520
You know, phone, pictures.

00:26:28.520 --> 00:26:30.650
[OBSCURED]

00:26:30.650 --> 00:26:33.160
PROFESSOR: The way Apple might
be with that is going to not

00:26:33.160 --> 00:26:34.680
let anybody program it.

00:26:34.680 --> 00:26:37.400
It's going to have a very
restrictive development

00:26:37.400 --> 00:26:40.804
program internally so they can
basically say, I'm going to

00:26:40.804 --> 00:26:42.830
take this person from this
person and put it together.

00:26:42.830 --> 00:26:46.510
They will try to do everything
in one unified way.

00:26:46.510 --> 00:26:50.150
So to some extent it might work,
but then you suddenly

00:26:50.150 --> 00:26:53.710
realize Apple hired programmers
to keep up with

00:26:53.710 --> 00:26:55.290
all the needs.

00:26:55.290 --> 00:27:00.010
So it may even start to have
other people running things.

00:27:00.010 --> 00:27:01.750
ARVIND: Internally their
software is--

00:27:01.750 --> 00:27:03.280
AUDIENCE: So is there something

00:27:03.280 --> 00:27:05.700
parallel going on in there?

00:27:05.700 --> 00:27:07.290
ARVIND: Guaranteed there
will be parallel

00:27:07.290 --> 00:27:08.150
stuff going on there.

00:27:08.150 --> 00:27:11.690
Guaranteed because all the
communication stuff has to go

00:27:11.690 --> 00:27:15.420
on in parallel with the
computation stuff.

00:27:15.420 --> 00:27:21.320
So I mean, phones have to lots
of things in parallel if for

00:27:21.320 --> 00:27:23.180
no other reason just
because of power.

00:27:23.180 --> 00:27:26.110
It takes less power when you
do things in parallel as

00:27:26.110 --> 00:27:28.735
opposed to when you do
sequentially because then you

00:27:28.735 --> 00:27:34.500
have to run much
faster in that.

00:27:34.500 --> 00:27:37.440
OK, so a method of designing
and connecting modules has

00:27:37.440 --> 00:27:41.470
that functionality and
performance are predictable.

00:27:41.470 --> 00:27:45.000
And must facilitate natural
description of concurrent

00:27:45.000 --> 00:27:50.710
systems. A method of refining
individual modules into

00:27:50.710 --> 00:27:53.900
hardware or software for
systems on a chip.

00:27:53.900 --> 00:27:57.880
So refinement is a highly
technical word.

00:27:57.880 --> 00:28:02.660
What that means is that you have
written a program and you

00:28:02.660 --> 00:28:05.340
move on to rewrite it, but
nobody can tell from outside

00:28:05.340 --> 00:28:06.810
that you rewrote it.

00:28:06.810 --> 00:28:09.270
All right, so you refine
it and you can to

00:28:09.270 --> 00:28:10.120
refine it into hardware.

00:28:10.120 --> 00:28:13.720
I mean, you may implement it in
hardware in this as opposed

00:28:13.720 --> 00:28:15.010
to transformation.

00:28:15.010 --> 00:28:16.340
Transformation is automatic.

00:28:16.340 --> 00:28:19.170
We're doing something, it's
guaranteed it's correct.

00:28:19.170 --> 00:28:22.620
Refinement you may have to work
a little bit more to show

00:28:22.620 --> 00:28:24.120
that it is correct
in some sense.

00:28:24.120 --> 00:28:27.460
It's a correct refinement of
whatever you were doing.

00:28:27.460 --> 00:28:32.470
So basically, just to get the
application going, which as

00:28:32.470 --> 00:28:36.600
Allen is pointing out is the
major task and this is true

00:28:36.600 --> 00:28:38.450
regardless of what people say.

00:28:38.450 --> 00:28:41.340
When you get to complex system,
if people start

00:28:41.340 --> 00:28:44.780
talking about performance
you're 90% there.

00:28:44.780 --> 00:28:47.140
That means the damn
thing works.

00:28:47.140 --> 00:28:50.110
So even the people may say, oh,
performance will be lousy.

00:28:50.110 --> 00:28:51.810
Most of the energy is
just consumed in

00:28:51.810 --> 00:28:53.760
getting it to work.

00:28:53.760 --> 00:28:55.220
So never forget that.

00:28:55.220 --> 00:28:58.610
So a refinement idea becomes
very important because you

00:28:58.610 --> 00:29:03.330
want to take as many things as
possible, which are available.

00:29:03.330 --> 00:29:06.290
Make it work and then
individually refine; modular

00:29:06.290 --> 00:29:08.910
refinement of things.

00:29:08.910 --> 00:29:10.875
AUDIENCE: Maybe just also
underscore, just to emphasis

00:29:10.875 --> 00:29:15.130
what you're saying Arvind, our
salesmen will go and say

00:29:15.130 --> 00:29:17.660
explicitly that they can
sell a factor of 2.

00:29:17.660 --> 00:29:19.210
Just like you were saying.

00:29:19.210 --> 00:29:24.963
Just a factor of 2 on 100
processors or whatever, they

00:29:24.963 --> 00:29:26.687
can sell that if it works.

00:29:26.687 --> 00:29:26.850
If it gives the right answer.

00:29:26.850 --> 00:29:27.610
AUDIENCE: It's the ease.

00:29:27.610 --> 00:29:30.080
ARVIND: The ease and confidence
that it's really

00:29:30.080 --> 00:29:31.840
doing what you expect
it to do.

00:29:31.840 --> 00:29:35.350
AUDIENCE: So it's really
performance second, ease of

00:29:35.350 --> 00:29:40.550
use first. We've got it
backwards in academia.

00:29:40.550 --> 00:29:42.540
ARVIND: But everybody set
designs on 2 multicores.

00:29:46.150 --> 00:29:49.140
So why multicore problems
becomes hard and this where

00:29:49.140 --> 00:29:52.940
hardware and software starts
diverging a little bit.

00:29:52.940 --> 00:29:55.060
So what happens in
hardware design?

00:29:55.060 --> 00:29:57.620
Everything is in parallel.

00:29:57.620 --> 00:30:00.670
It's sitting right there,
this blog does this,

00:30:00.670 --> 00:30:02.540
this blog does that.

00:30:02.540 --> 00:30:04.410
So there's no confusion
in your mind

00:30:04.410 --> 00:30:06.640
what's going on in parallel.

00:30:06.640 --> 00:30:10.200
If you have to multiplex some
thing in hardware, that first

00:30:10.200 --> 00:30:13.390
we'll do this then we'll do
that, that's also expressed

00:30:13.390 --> 00:30:16.590
explicitly in the design.

00:30:16.590 --> 00:30:17.930
Software is not like that.

00:30:17.930 --> 00:30:21.850
You know, software have n
threads, but I have only 10 in

00:30:21.850 --> 00:30:23.790
my hardware.

00:30:23.790 --> 00:30:28.020
So there is another layer of
software or operating system

00:30:28.020 --> 00:30:30.620
or whatever you want to call
it, runtime system.

00:30:30.620 --> 00:30:33.400
Whose sole job is to virtualize
or to do time

00:30:33.400 --> 00:30:36.410
multiplexing of underlying
resources and that makes the

00:30:36.410 --> 00:30:38.060
problem harder.

00:30:38.060 --> 00:30:40.220
You know, that makes the problem
harder whether you're

00:30:40.220 --> 00:30:42.490
doing it in a way
that preserves

00:30:42.490 --> 00:30:44.100
some performance goals.

00:30:44.100 --> 00:30:46.410
Whether you're doing it so that
you want cause deadlocks,

00:30:46.410 --> 00:30:49.800
so there are many, many issues
that come up in this.

00:30:49.800 --> 00:30:52.970
And basically, when I said this
is an ideas kind of a

00:30:52.970 --> 00:30:56.590
talk, I do know how to do this
and I still haven't worked

00:30:56.590 --> 00:31:00.850
enough on this problem of
how to take this kind of

00:31:00.850 --> 00:31:03.100
methodology where I can write
these parallel modules,

00:31:03.100 --> 00:31:04.450
compose them.

00:31:04.450 --> 00:31:05.780
How to map it onto multicores.

00:31:08.900 --> 00:31:11.980
OK, so now let me tell
you something

00:31:11.980 --> 00:31:14.460
technical about this stuff.

00:31:14.460 --> 00:31:17.270
So this hardware inspired
methodology for synthesizing

00:31:17.270 --> 00:31:21.000
parallel programs. Now I'm going
to use some fancy words.

00:31:21.000 --> 00:31:24.390
So this is a rule-based
specifications or what I call

00:31:24.390 --> 00:31:26.730
guarded atomic actions.

00:31:26.730 --> 00:31:30.100
I will explain in a second
what that means.

00:31:30.100 --> 00:31:32.520
It will let you think about
parallel systems in a very

00:31:32.520 --> 00:31:33.220
different way.

00:31:33.220 --> 00:31:39.380
So it's like saying look, if
this register is 2 and this

00:31:39.380 --> 00:31:44.860
register is 3, you can add them
and put them here, 5.

00:31:44.860 --> 00:31:47.470
And you can do this
any time you want.

00:31:47.470 --> 00:31:48.900
So this is like a rule.

00:31:48.900 --> 00:31:50.090
Invariant.

00:31:50.090 --> 00:31:51.100
You're saying, I don't
care what's

00:31:51.100 --> 00:31:52.120
happening in the machine.

00:31:52.120 --> 00:31:54.600
This is always safe to do.

00:31:54.600 --> 00:31:57.870
Now what I'm going to ask
you to do is take a huge

00:31:57.870 --> 00:32:00.430
intellectual jump from this.

00:32:00.430 --> 00:32:03.640
That if you give me enough
such rules you would have

00:32:03.640 --> 00:32:07.870
completely described the
hardware, what it does.

00:32:07.870 --> 00:32:09.600
Now why am I thinking
like this?

00:32:09.600 --> 00:32:14.060
Because these invariants
are stated properly.

00:32:14.060 --> 00:32:16.850
It's always possible to
understand the behavior of the

00:32:16.850 --> 00:32:20.950
system as if one things at
a time is happening.

00:32:20.950 --> 00:32:25.430
When 2 plus 3 is becoming 5, if
you want you can have this

00:32:25.430 --> 00:32:29.120
mental picture-- the rest
of the world is frozen.

00:32:29.120 --> 00:32:31.020
Nothing is changing
there, only that

00:32:31.020 --> 00:32:32.430
change is taking place.

00:32:32.430 --> 00:32:35.490
And you can think it terms of
these small, small changes and

00:32:35.490 --> 00:32:39.730
all legal behaviors will be
explainable as some sequence

00:32:39.730 --> 00:32:41.270
of these changes.

00:32:41.270 --> 00:32:44.840
It's possible to describe
all kinds of hardware

00:32:44.840 --> 00:32:47.040
using things like that.

00:32:47.040 --> 00:32:51.730
Composition of modules with
guarded interfaces.

00:32:51.730 --> 00:32:56.250
So this is the language called
Bluespec and it has a very

00:32:56.250 --> 00:33:00.270
strong echoes of a language that
was designed in the 80s

00:33:00.270 --> 00:33:02.140
by two guys, Chandry
and Misra, the

00:33:02.140 --> 00:33:04.720
language called Unity.

00:33:04.720 --> 00:33:06.620
But they never used it
for hardware design.

00:33:06.620 --> 00:33:09.300
Their goals were different and
they didn't really have a

00:33:09.300 --> 00:33:13.040
concept of a module
in that language.

00:33:13.040 --> 00:33:16.530
So let me show you
3 examples here.

00:33:16.530 --> 00:33:19.310
Greatest common divisor, just
to get off ground and then I

00:33:19.310 --> 00:33:24.220
will show you 2 very different
problems: airlines reservation

00:33:24.220 --> 00:33:28.910
query problem and the
video codec H.264.

00:33:28.910 --> 00:33:31.610
We won't have time to get into
ordered list, but if somebody

00:33:31.610 --> 00:33:35.560
wants to discuss that I've
be happy to show you.

00:33:35.560 --> 00:33:41.510
OK, so now let's look at how do
I think of my design of my

00:33:41.510 --> 00:33:43.640
program in Bluespec?

00:33:43.640 --> 00:33:45.300
I always think in terms
of a bunch of modules.

00:33:47.890 --> 00:33:48.880
And what's a module.

00:33:48.880 --> 00:33:52.880
A module is going to have some
state elements in it.

00:33:52.880 --> 00:33:57.020
If you're thinking software just
think each module guards

00:33:57.020 --> 00:34:00.580
some variables, which nobody
else can touch.

00:34:00.580 --> 00:34:02.340
You're the only one.

00:34:02.340 --> 00:34:06.560
So you have a variable xyz, he
has some abcd, et cetera.

00:34:06.560 --> 00:34:08.750
So each module has some.

00:34:08.750 --> 00:34:10.650
That's what I'm showing
in red.

00:34:10.650 --> 00:34:13.680
If you were thinking hardware,
think of thse things as

00:34:13.680 --> 00:34:15.820
stateful elements like
registers or

00:34:15.820 --> 00:34:18.170
flip flops of memories.

00:34:18.170 --> 00:34:22.960
But the main point is if it is
here then it's not here.

00:34:22.960 --> 00:34:26.040
You own something, this module
owns something, this module

00:34:26.040 --> 00:34:26.300
owns something.

00:34:26.300 --> 00:34:28.030
One.

00:34:28.030 --> 00:34:33.010
Second thing is every module
has internal rules for

00:34:33.010 --> 00:34:36.260
manipulating the state and the
rules are always going to be

00:34:36.260 --> 00:34:40.050
of the form that if some
condition is true on this

00:34:40.050 --> 00:34:44.130
you're allowed to make the
following changes to that.

00:34:44.130 --> 00:34:45.800
So that's what the
rule looks like.

00:34:45.800 --> 00:34:49.600
Some condition, if it holds
that by action I

00:34:49.600 --> 00:34:51.350
mean, change the state.

00:34:51.350 --> 00:34:53.310
Change the state of
those variables.

00:34:53.310 --> 00:34:54.690
And it's all or nothing.

00:34:54.690 --> 00:34:57.180
So if you have 2 variables and
if you want to change both of

00:34:57.180 --> 00:35:01.030
them in a rule then the
execution of a rule means

00:35:01.030 --> 00:35:04.340
either both of them will change
or neither will change.

00:35:04.340 --> 00:35:06.320
There's nothing in between
you can see.

00:35:06.320 --> 00:35:08.440
That's disallowed
by this model.

00:35:13.250 --> 00:35:14.780
I mean, the reason
I have modules is

00:35:14.780 --> 00:35:16.240
they're not totally disjoined.

00:35:16.240 --> 00:35:18.940
You can actually access
the state.

00:35:18.940 --> 00:35:23.350
Both read it and write it, but
you can't just arbitrarily

00:35:23.350 --> 00:35:24.540
reach it and do something.

00:35:24.540 --> 00:35:27.680
You have to go through some
interface methods the moment

00:35:27.680 --> 00:35:29.520
you talk to some
other modules.

00:35:29.520 --> 00:35:32.610
So this is the standard
information hiding principle.

00:35:32.610 --> 00:35:36.150
You know, abstract data types,
whatever you want to call it.

00:35:36.150 --> 00:35:38.360
You know, so there's an
interface through which you

00:35:38.360 --> 00:35:41.570
will enter and if you're just
reading the values I think we

00:35:41.570 --> 00:35:45.550
call them read methods or value
methods and if you're

00:35:45.550 --> 00:35:48.380
going to effect the state of one
of the modules we'll call

00:35:48.380 --> 00:35:50.380
those action methods.

00:35:50.380 --> 00:35:51.850
Because you're actually
going to change the

00:35:51.850 --> 00:35:53.360
state in some module.

00:35:56.240 --> 00:35:59.280
So now, very strange execution
model here.

00:35:59.280 --> 00:36:03.060
Very, very different from
sequential execution model.

00:36:03.060 --> 00:36:04.770
So repeatedly you do
the following.

00:36:04.770 --> 00:36:07.110
You pick a rule to execute.

00:36:07.110 --> 00:36:10.350
Any rule, I don't care.

00:36:10.350 --> 00:36:14.900
And select a rule to execute,
compute the state, what

00:36:14.900 --> 00:36:18.480
updates should be made,
make the state update.

00:36:18.480 --> 00:36:22.210
And then go and do it again,
so repeatedly you do this.

00:36:22.210 --> 00:36:24.530
So this is a highly
nondeterministic thing,

00:36:24.530 --> 00:36:25.790
selective rule.

00:36:25.790 --> 00:36:29.110
There may be a gazillion
rules in your system.

00:36:29.110 --> 00:36:32.360
So system privileges are
provided to control the

00:36:32.360 --> 00:36:34.160
selection if you want.

00:36:34.160 --> 00:36:37.070
But it's a detail that
we won't get into to.

00:36:37.070 --> 00:36:40.370
So does everybody get the
model right here?

00:36:40.370 --> 00:36:42.690
That you have a lot of
state elements and

00:36:42.690 --> 00:36:44.870
you have lot of rules.

00:36:44.870 --> 00:36:51.170
Many rules may be applicable,
pick one of them to execute.

00:36:51.170 --> 00:36:52.780
Execute and that will
change the state.

00:36:52.780 --> 00:36:55.410
Ask the same question again,
which rules are enabled?

00:36:55.410 --> 00:36:58.950
No, pick any rule amongst
them and keep doing it.

00:36:58.950 --> 00:37:03.220
Now semantics say one
rule at a time.

00:37:03.220 --> 00:37:05.560
In any implementation we're
going to do many,

00:37:05.560 --> 00:37:07.590
many rule in parallel.

00:37:07.590 --> 00:37:08.660
But you don't have to
worry about that.

00:37:08.660 --> 00:37:10.860
That will be done all
automatically.

00:37:10.860 --> 00:37:14.740
That we can do many
rules in parallel.

00:37:14.740 --> 00:37:18.300
OK, so now let's look at GCD.

00:37:18.300 --> 00:37:20.310
So this is an ordinary
GCD program.

00:37:20.310 --> 00:37:23.880
You can write it in any language
you want if y is zero

00:37:23.880 --> 00:37:28.070
then x otherwise if this is
greater than GCD of y, x.

00:37:28.070 --> 00:37:31.410
Otherwise you subtract.

00:37:31.410 --> 00:37:35.080
So no problem and I'm sure
you know how it executes.

00:37:35.080 --> 00:37:39.720
So if I was to take GCD of 6,15
you will see there is a

00:37:39.720 --> 00:37:43.830
recursive call that'll go on
because 6 is less than 15 so

00:37:43.830 --> 00:37:45.570
it will be this.

00:37:45.570 --> 00:37:47.950
You get this and you get
this, et cetera.

00:37:47.950 --> 00:37:51.070
Ultimately you get
3 as an answer.

00:37:51.070 --> 00:37:51.960
Everybody is with me?

00:37:51.960 --> 00:37:52.790
You know you all know GCD?

00:37:52.790 --> 00:37:55.850
You can all write it in your
favorite language.

00:37:55.850 --> 00:38:02.230
Now the question is, what does
it mean to execute this

00:38:02.230 --> 00:38:04.000
program in a concurrent
setting?

00:38:07.530 --> 00:38:11.450
We were not thinking parallel
or sequential, right?

00:38:11.450 --> 00:38:14.430
This is GCD.

00:38:14.430 --> 00:38:16.550
Someone who's teaching this
class says run it in parallel.

00:38:16.550 --> 00:38:19.450
You say, what do you mean,
run it in parallel?

00:38:19.450 --> 00:38:23.250
Oh, you mean that maybe I should
try to do several GCD

00:38:23.250 --> 00:38:26.160
calls, recursive calls
in parallel?

00:38:26.160 --> 00:38:29.070
That also doesn't make too
much sense in this.

00:38:29.070 --> 00:38:30.400
Perhaps, this is what
someone meant.

00:38:30.400 --> 00:38:33.100
You know that if he has some
program where there are 2

00:38:33.100 --> 00:38:37.960
calls to GCD, he would like you
to do those 2 in parallel.

00:38:43.160 --> 00:38:44.860
I mean, what does it mean
to do GCD in parallel?

00:38:49.140 --> 00:38:53.420
Now let me contrast this with
how you would think about this

00:38:53.420 --> 00:38:55.990
problem as a hardware person.

00:38:55.990 --> 00:38:58.940
So your job is to build
a GCD machine.

00:38:58.940 --> 00:38:59.820
You're going to make
millions of

00:38:59.820 --> 00:39:03.030
dollars, GCD is very popular.

00:39:03.030 --> 00:39:05.160
So you build this GCD machine.

00:39:05.160 --> 00:39:08.030
You know, it has 2 inputs,
it has an output.

00:39:08.030 --> 00:39:10.580
And this will be my module
I'm going to sell this

00:39:10.580 --> 00:39:14.280
intellectual property
to everyone.

00:39:14.280 --> 00:39:20.330
OK, so now let me talk of
parallel invocations of this.

00:39:20.330 --> 00:39:23.790
You see in hardware there can
be no confusion, either you

00:39:23.790 --> 00:39:28.300
have 2 GCD boxes or you
have 1 GCD box.

00:39:28.300 --> 00:39:30.430
I mean, you can have as many
boxes as you want, but there

00:39:30.430 --> 00:39:32.170
is no confusion about that.

00:39:32.170 --> 00:39:36.330
You know how many GCDs you have.
So in some sense, if you

00:39:36.330 --> 00:39:40.520
have many of them, you're
talking of independent calls.

00:39:40.520 --> 00:39:42.400
Who knows what about
recursive calls?

00:39:42.400 --> 00:39:44.310
I mean, that's internal story.

00:39:44.310 --> 00:39:46.220
You know, that's a different
level of questions.

00:39:46.220 --> 00:39:50.110
So this question will
automatically get asked.

00:39:50.110 --> 00:39:52.720
In hardware you will ask the
question, does the answer come

00:39:52.720 --> 00:39:55.820
out immediately?

00:39:55.820 --> 00:39:58.110
Does it come out in
particular time?

00:39:58.110 --> 00:39:59.750
Why's this question important?

00:39:59.750 --> 00:40:01.790
Because if it's going to take
some time then while it's

00:40:01.790 --> 00:40:03.800
computing the question I'm going
to ask is can I give

00:40:03.800 --> 00:40:05.050
another set of inputs?

00:40:07.540 --> 00:40:09.330
Are you with me?

00:40:09.330 --> 00:40:11.250
I mean, that's a legitimate
question to ask.

00:40:11.250 --> 00:40:15.160
If it's going to take half an
hour to compute the GCD can I

00:40:15.160 --> 00:40:19.310
give it another input
while it's thinking?

00:40:19.310 --> 00:40:22.160
Can the machine be shared
by 2 different users?

00:40:25.020 --> 00:40:27.700
Can it be pipelined?

00:40:27.700 --> 00:40:30.300
So you agree that all these
questions are meaningful in

00:40:30.300 --> 00:40:31.620
hardware setting?

00:40:31.620 --> 00:40:34.870
And I claim all these questions
are also meaningful

00:40:34.870 --> 00:40:36.290
in software setting.

00:40:36.290 --> 00:40:37.540
We just don't think like that.

00:40:41.110 --> 00:40:44.390
This is exactly the problem we
are having right now when we

00:40:44.390 --> 00:40:46.260
say that we have optimized
something

00:40:46.260 --> 00:40:49.710
and we call it again.

00:40:49.710 --> 00:40:53.380
We think off it as starting
a fresh, maybe not.

00:40:53.380 --> 00:40:54.000
Maybe not.

00:40:54.000 --> 00:40:55.700
You know, maybe we
should think of

00:40:55.700 --> 00:40:57.210
it in terms of resources.

00:41:00.370 --> 00:41:04.560
And the point I want to make
is I want to think of GCD

00:41:04.560 --> 00:41:07.950
module as a resource.

00:41:07.950 --> 00:41:11.360
Even in software I want to think
of it as a resource.

00:41:11.360 --> 00:41:14.140
So that there is no ambiguity in
your mind whether you have

00:41:14.140 --> 00:41:15.670
1 GCD or you have 2 GCDs.

00:41:18.750 --> 00:41:21.870
If you're going to multiplex it
we'll write it differently.

00:41:21.870 --> 00:41:24.090
If you're going to have 2
independent ones, which can go

00:41:24.090 --> 00:41:28.050
on in parallel we'll write
it differently.

00:41:28.050 --> 00:41:31.650
OK, so that's the idea I want
to borrow from the hardware

00:41:31.650 --> 00:41:33.820
side of this.

00:41:33.820 --> 00:41:35.930
So how would you do-- yes?

00:41:35.930 --> 00:41:40.120
AUDIENCE: But how would you
decide how many GCDs to

00:41:40.120 --> 00:41:40.800
instantiate?

00:41:40.800 --> 00:41:43.910
Would that be is this model
left up to the programmer?

00:41:43.910 --> 00:41:45.340
ARVIND: Well, you see that's
the big difference between

00:41:45.340 --> 00:41:46.350
hardware and software.

00:41:46.350 --> 00:41:50.070
That in hardware you have no
design until you have taken

00:41:50.070 --> 00:41:51.920
that decision.

00:41:51.920 --> 00:41:53.060
AUDIENCE: Right.

00:41:53.060 --> 00:41:57.440
I mean, hardware designs once
it's built, it's built.

00:41:57.440 --> 00:42:00.910
Software designs you want the
same module of software to

00:42:00.910 --> 00:42:03.360
seamlessly run on different
kinds of hardware.

00:42:03.360 --> 00:42:06.230
ARVIND: That doesn't mean that
I can't recompile it or can't

00:42:06.230 --> 00:42:08.300
resynthesize it or something.

00:42:08.300 --> 00:42:10.700
So it may be same source
description in software.

00:42:10.700 --> 00:42:12.510
AUDIENCE: Right, if your source
subscription specifies

00:42:12.510 --> 00:42:17.160
2 GCD modules and you have 8
cores, you're not necessarily

00:42:17.160 --> 00:42:18.590
going to take very
good advantage of

00:42:18.590 --> 00:42:19.930
this, so how do you--

00:42:19.930 --> 00:42:20.320
ARVIND: No, no.

00:42:20.320 --> 00:42:23.900
The way I would like to think
about that is that it'll be

00:42:23.900 --> 00:42:26.120
highly parameterized code and
you will plug in some

00:42:26.120 --> 00:42:29.310
information like that
and resynthesize

00:42:29.310 --> 00:42:30.650
the parallel program.

00:42:30.650 --> 00:42:33.450
AUDIENCE: So the software or
some sort of macro meta

00:42:33.450 --> 00:42:38.870
software has to determine the
extent to which the problem

00:42:38.870 --> 00:42:41.490
should be distributed.

00:42:41.490 --> 00:42:44.950
ARVIND: Well, you can think
like that, but really this

00:42:44.950 --> 00:42:46.790
integration will be much
tighter than you think.

00:42:46.790 --> 00:42:51.930
So for example, let me just
give you some more insight

00:42:51.930 --> 00:42:53.510
from the hardware side.

00:42:53.510 --> 00:42:56.500
So in the hardware side it's
standard practice that will

00:42:56.500 --> 00:42:59.700
have some RTL code, I'll
have some code.

00:42:59.700 --> 00:43:01.400
And I plug in the library.

00:43:01.400 --> 00:43:02.820
What kind of gates have I got?

00:43:02.820 --> 00:43:05.830
Have I got 2 input gates,
4 input gates, whatever.

00:43:05.830 --> 00:43:07.750
There will be a huge library.

00:43:07.750 --> 00:43:12.670
The same code can be compiled
using different libraries.

00:43:12.670 --> 00:43:16.310
So you choose something
at synthesis time.

00:43:16.310 --> 00:43:19.140
Another thing that'll happen in
hardware is what is called

00:43:19.140 --> 00:43:20.800
generic statements.

00:43:20.800 --> 00:43:25.940
So you may have a loop
which assigns a

00:43:25.940 --> 00:43:28.830
register file with n registers.

00:43:28.830 --> 00:43:31.100
Which will conceptually makes
sense, it will make sense in

00:43:31.100 --> 00:43:33.460
simulation, but when it comes
to synthesizing it you

00:43:33.460 --> 00:43:35.600
have to specify n.

00:43:35.600 --> 00:43:39.240
So I'm going towards that
kind of methodology.

00:43:39.240 --> 00:43:41.840
That you will have highly
parameterized code, but many

00:43:41.840 --> 00:43:45.150
parameters you have to specify
before you will say, now my

00:43:45.150 --> 00:43:48.350
program is ready to run on
this parallel machine.

00:43:48.350 --> 00:43:51.170
And this is totally
unexplored.

00:43:51.170 --> 00:43:53.720
As I said, this is an idea
level them being.

00:43:53.720 --> 00:43:56.870
AUDIENCE: So this adds a
problem that is not in

00:43:56.870 --> 00:43:58.450
traditional hardware
synthesis, mainly

00:43:58.450 --> 00:44:00.380
picking all the n's.

00:44:00.380 --> 00:44:03.110
Ideally you wouldn't want to
have to have the programmer to

00:44:03.110 --> 00:44:04.610
come up with creative algorithms
because they're

00:44:04.610 --> 00:44:05.770
going to have lots
and lots of .

00:44:05.770 --> 00:44:07.010
ARVIND: Absolutely.

00:44:07.010 --> 00:44:08.770
We may have lots of defaults.

00:44:08.770 --> 00:44:11.890
We may other level of smart
programs, which look at this

00:44:11.890 --> 00:44:14.590
and they instantly go and
set many parameters.

00:44:14.590 --> 00:44:17.300
You know, so there will
be a practical side,

00:44:17.300 --> 00:44:18.480
many issues like that.

00:44:18.480 --> 00:44:21.690
But main point I'm trying to
make is that I really want to

00:44:21.690 --> 00:44:23.460
synthesize.

00:44:23.460 --> 00:44:27.470
I want to instantiate a program,
synthesize a program

00:44:27.470 --> 00:44:32.710
for a given configuration
of hardware.

00:44:32.710 --> 00:44:36.180
Let's look at the
GCD in Bluespec.

00:44:36.180 --> 00:44:40.700
If I'm going to find the GCD
of 2 numbers I need 2

00:44:40.700 --> 00:44:43.430
registers, x and y; so
that's what this is.

00:44:43.430 --> 00:44:45.950
Make me a register.

00:44:45.950 --> 00:44:47.530
If you want, make
me 2 variables.

00:44:47.530 --> 00:44:49.620
You know, make me variable
x and y,

00:44:49.620 --> 00:44:52.330
initial values are zero.

00:44:52.330 --> 00:44:56.160
So this is what is called
the state of the module.

00:44:56.160 --> 00:44:57.930
It knows about and x
and y, nobody else

00:44:57.930 --> 00:45:00.490
knows about x and y.

00:45:00.490 --> 00:45:01.770
What are the dynamics of it?

00:45:01.770 --> 00:45:05.090
How do I compute this?

00:45:05.090 --> 00:45:08.960
So internal behavior is being
described and this is exactly

00:45:08.960 --> 00:45:12.240
what you saw earlier in saying
that there is a swap rule.

00:45:12.240 --> 00:45:15.520
If x is greater than y and y is
not equal to zero then you

00:45:15.520 --> 00:45:18.556
swap x and y, so this is a
parallel composition. x gets

00:45:18.556 --> 00:45:19.806
y, y gets x.

00:45:23.480 --> 00:45:27.480
In this system all the reads
take place instantaneously and

00:45:27.480 --> 00:45:30.930
then you do all the writes
at the end of it.

00:45:30.930 --> 00:45:34.720
Don't read this sequentially,
you read x and y in parallel

00:45:34.720 --> 00:45:38.210
and then you go and
update x and y.

00:45:38.210 --> 00:45:39.320
Does this rule make sense?

00:45:39.320 --> 00:45:41.110
I mean, if you know
anything GCD--

00:45:41.110 --> 00:45:44.120
if x is greater than y than
you're going to swap it and

00:45:44.120 --> 00:45:47.830
subtraction, if x is less than
or equal to y than y

00:45:47.830 --> 00:45:50.190
gets y minus x.

00:45:50.190 --> 00:45:53.210
So this is very interesting.

00:45:53.210 --> 00:45:57.180
Now you have 2 registers x and
y and I've given 2 rules and

00:45:57.180 --> 00:46:00.650
I'm saying you can apply these
rules anytime you want.

00:46:00.650 --> 00:46:03.580
Just repeatedly keep
doing these rules.

00:46:03.580 --> 00:46:05.450
Now what does the outside
world know about this?

00:46:08.400 --> 00:46:10.630
What do you want to advertise
about GCD

00:46:10.630 --> 00:46:11.870
to the outside world?

00:46:11.870 --> 00:46:13.670
You don't want to give
away your secret.

00:46:13.670 --> 00:46:16.280
This is your intellectual
property of how you're

00:46:16.280 --> 00:46:18.530
computing the GCD.

00:46:18.530 --> 00:46:21.090
You just want to be use GCD.

00:46:21.090 --> 00:46:25.210
So the outside world can say,
oh find me start it.

00:46:25.210 --> 00:46:29.750
With a and b. x gets
a, y gets b.

00:46:29.750 --> 00:46:33.540
It's going to give you 2
parameters, but we may be busy

00:46:33.540 --> 00:46:37.730
computing so we have a guard
here which says, if y is

00:46:37.730 --> 00:46:39.240
zero-- this is internal,
outside

00:46:39.240 --> 00:46:41.360
world doesn't see this.

00:46:41.360 --> 00:46:45.890
If y is zero then only then can
you start it, otherwise

00:46:45.890 --> 00:46:46.650
you can't start it.

00:46:46.650 --> 00:46:50.290
Otherwise it means it's
busy computing.

00:46:50.290 --> 00:46:52.930
OK, similarly when is the
result available?

00:46:52.930 --> 00:46:54.970
When the y is zero then you
have the result and

00:46:54.970 --> 00:46:56.640
you will return x.

00:46:56.640 --> 00:46:58.720
AUDIENCE: [OBSCURED]

00:46:58.720 --> 00:46:59.280
ARVIND: That's right.

00:46:59.280 --> 00:47:02.260
So that'll be more
sophisticated.

00:47:02.260 --> 00:47:05.000
And that's exactly the kind
of decision I do want the

00:47:05.000 --> 00:47:08.700
designers to take because you
may want to put a five hole.

00:47:08.700 --> 00:47:11.150
You may just keep spitting
out results.

00:47:11.150 --> 00:47:12.810
You can make it as sophisticated
as you want.

00:47:12.810 --> 00:47:14.250
Tag it if you want.

00:47:14.250 --> 00:47:16.790
No predetermined thing.

00:47:22.540 --> 00:47:24.400
So first question I ask you,
what happened to those

00:47:24.400 --> 00:47:25.650
recursive calls?

00:47:30.850 --> 00:47:34.080
You know, if you go back to the
previous slide there was a

00:47:34.080 --> 00:47:37.940
recursively called GCD, which
you were all comfortable with.

00:47:37.940 --> 00:47:42.154
There is no GCD call here.

00:47:42.154 --> 00:47:44.280
AUDIENCE: [OBSCURED]

00:47:44.280 --> 00:47:46.020
ARVIND: Right, so there's
a notion of a

00:47:46.020 --> 00:47:48.590
cycle event or something.

00:47:48.590 --> 00:47:51.040
Look at it now, update
it, look at it again.

00:47:51.040 --> 00:47:54.040
You know, so there's like an
infinite loop here, which is

00:47:54.040 --> 00:47:55.710
always going.

00:47:55.710 --> 00:47:57.280
Which is exactly how
hardware works.

00:48:00.660 --> 00:48:02.570
It doesn't have to be
synchronous, but if you want

00:48:02.570 --> 00:48:04.960
to have a simple model
in your head just

00:48:04.960 --> 00:48:06.580
think, there's the clock.

00:48:06.580 --> 00:48:09.730
You know, look at this state,
pick one route to execute,

00:48:09.730 --> 00:48:13.370
update it, then it's the
next clock cycle.

00:48:13.370 --> 00:48:16.220
Keep doing this repeatedly.

00:48:16.220 --> 00:48:19.510
It's details here, but I can
take such a description and

00:48:19.510 --> 00:48:23.810
actually produce that machine
for you, which does the GCD.

00:48:23.810 --> 00:48:26.880
What I'm much more interested
in is, this is how I want to

00:48:26.880 --> 00:48:29.760
think about my GCD now.

00:48:29.760 --> 00:48:32.450
So I've hidden everything
inside it.

00:48:32.450 --> 00:48:37.190
And it has 2 methods: start and
result and there is a very

00:48:37.190 --> 00:48:41.450
strong notion of when
a method is ready--

00:48:41.450 --> 00:48:43.320
because it may be busy
computing, it doesn't want to

00:48:43.320 --> 00:48:45.420
listen to you.

00:48:45.420 --> 00:48:48.930
So there is this notion of
something being ready and if

00:48:48.930 --> 00:48:52.260
it's an action method then
you're only allowed to enable

00:48:52.260 --> 00:48:55.560
it when it's ready.

00:48:55.560 --> 00:48:57.320
So this is a high-level
protocol that

00:48:57.320 --> 00:48:58.420
compiler will enforce.

00:48:58.420 --> 00:49:03.950
It'll never ever set this,
it'll never execute this

00:49:03.950 --> 00:49:06.700
unless it is ready
to be executed.

00:49:06.700 --> 00:49:08.690
And of course, when you're going
to enable it then you

00:49:08.690 --> 00:49:13.010
have to give me 2 arguments
that go with it.

00:49:13.010 --> 00:49:14.290
And what does this
really mean?

00:49:16.990 --> 00:49:19.930
The result is valid.

00:49:19.930 --> 00:49:21.900
So if are to do types et cetera,
this would easily be

00:49:21.900 --> 00:49:24.500
baby type or something.

00:49:24.500 --> 00:49:28.490
Tag union type that validates
is being coded here.

00:49:32.230 --> 00:49:35.080
So really to the world
you are just

00:49:35.080 --> 00:49:37.430
advertising this interface.

00:49:37.430 --> 00:49:40.520
There is a GCD interface
and it has 2 methods.

00:49:40.520 --> 00:49:44.100
An action method, which is
called start and a result

00:49:44.100 --> 00:49:46.650
method, which is just a
value kind of a thing.

00:49:46.650 --> 00:49:48.470
And in order to do this
you have to give me an

00:49:48.470 --> 00:49:50.720
int a into b in this.

00:49:50.720 --> 00:49:52.650
An end of interface.

00:49:52.650 --> 00:49:55.670
Now this is borrowing a lot
from modern programming

00:49:55.670 --> 00:50:02.020
languages so for example,
I can easily make it

00:50:02.020 --> 00:50:03.570
polymorphic.

00:50:03.570 --> 00:50:05.870
It doesn't have to
be ints here.

00:50:05.870 --> 00:50:07.270
You know, what is the
meaning of int?

00:50:11.950 --> 00:50:15.390
You can specify the
type in this.

00:50:15.390 --> 00:50:20.490
So it'll be a's of type t,
b's of type t et cetera.

00:50:20.490 --> 00:50:23.620
What are the examples
of type t here?

00:50:23.620 --> 00:50:26.990
It could be a 32 bit integer, it
could be 16 bit integer, it

00:50:26.990 --> 00:50:30.170
could be 17 bit integer,
whatever you want and whatever

00:50:30.170 --> 00:50:31.410
makes sense.

00:50:31.410 --> 00:50:34.210
So this is the kind of thing
that you always take care of

00:50:34.210 --> 00:50:36.250
when you synthesize things.

00:50:36.250 --> 00:50:39.990
It won't synthesize until you
specify the type, but the

00:50:39.990 --> 00:50:42.240
description remains the same.

00:50:42.240 --> 00:50:45.430
And you will instantiate
it for a given type.

00:50:45.430 --> 00:50:47.470
This I'm showing you
for one reason.

00:50:47.470 --> 00:50:50.880
If you are coming from the
hardware side really these

00:50:50.880 --> 00:50:54.400
ideas and types and sensations
are very sophisticated.

00:50:54.400 --> 00:50:57.240
I mean, this is getting
as advanced as

00:50:57.240 --> 00:51:00.990
you can have in software.

00:51:00.990 --> 00:51:03.490
The other very interesting
thing is, and this is the

00:51:03.490 --> 00:51:06.880
abstract data type kind of
thinking, you can go and

00:51:06.880 --> 00:51:11.280
completely change the
implementation of this.

00:51:11.280 --> 00:51:15.240
If you have a clever algorithm
for doing GCD, fine, go

00:51:15.240 --> 00:51:15.800
ahead and do it.

00:51:15.800 --> 00:51:19.280
You know, it doesn't effect
the users of this.

00:51:19.280 --> 00:51:22.410
So this is a very important
property for composition.

00:51:22.410 --> 00:51:25.770
All I insist on is that every
method has this ready thing

00:51:25.770 --> 00:51:29.690
coming on so that I don't make
mistakes in wiring it.

00:51:29.690 --> 00:51:32.240
I will involve this method
only when it's ready.

00:51:32.240 --> 00:51:36.020
So in some sense if you forget
about the ready thing, I'm

00:51:36.020 --> 00:51:39.480
just borrowing ideas from object
oriented languages.

00:51:39.480 --> 00:51:42.600
You know, you have a class, you
have methods on it, and

00:51:42.600 --> 00:51:44.940
all I'm saying is oh, you should
manipulate this state

00:51:44.940 --> 00:51:48.280
in a very systematic manner
using these methods.

00:51:48.280 --> 00:51:51.790
But then I'm injecting some
hardware idea here, which

00:51:51.790 --> 00:51:54.280
doesn't exist in
software today.

00:51:54.280 --> 00:51:58.030
That is, oh, a method
may not be ready.

00:51:58.030 --> 00:52:01.490
And even that can be captured
very abstractly and done

00:52:01.490 --> 00:52:03.270
properly in this.

00:52:03.270 --> 00:52:04.950
Yep?

00:52:04.950 --> 00:52:07.366
AUDIENCE: So then in the case
of making models I was

00:52:07.366 --> 00:52:08.610
thinking of spy nature.

00:52:08.610 --> 00:52:12.620
So if you want to basically
synthesize the hardware you

00:52:12.620 --> 00:52:15.880
may also better efficiency by
having set of synchronized

00:52:15.880 --> 00:52:18.958
protocol by taking the
output [OBSCURED]

00:52:18.958 --> 00:52:22.150
number of cycles.

00:52:22.150 --> 00:52:23.770
ARVIND: I think, yes.

00:52:23.770 --> 00:52:26.670
That'll be a low-level detail
that if it is synchronized

00:52:26.670 --> 00:52:31.030
then you will actually try to
manipulate it like that.

00:52:31.030 --> 00:52:33.000
AUDIENCE: [OBSCURED]

00:52:33.000 --> 00:52:35.160
ARVIND: OK, right.

00:52:35.160 --> 00:52:38.475
So let me just quickly say
what the languages is.

00:52:38.475 --> 00:52:40.935
So you have modules, then you
have state variables, and you

00:52:40.935 --> 00:52:43.690
have rules and you have action
methods and read methods.

00:52:43.690 --> 00:52:45.720
What I wanted to show
you is what is

00:52:45.720 --> 00:52:48.290
the language of actions.

00:52:48.290 --> 00:52:52.630
So when I write an action here
or an action here, what is it?

00:52:52.630 --> 00:52:56.500
So simplest action is assignment
to a variable,

00:52:56.500 --> 00:52:59.390
assigment to a register.

00:52:59.390 --> 00:53:03.150
This is a conditional action,
so if predicate is true then

00:53:03.150 --> 00:53:08.060
do this action, otherwise no
action, no change in state.

00:53:08.060 --> 00:53:09.780
This is a parallel
composition.

00:53:09.780 --> 00:53:13.520
Do a1 and a2 in parallel.

00:53:13.520 --> 00:53:16.410
Sequential composition, the
effects of this are visible to

00:53:16.410 --> 00:53:18.070
this, et cetera.

00:53:18.070 --> 00:53:21.820
This is a call to a method
of one of the module.

00:53:21.820 --> 00:53:23.210
And then there is a guard.

00:53:27.550 --> 00:53:31.870
And you have an expression
language, which is there's

00:53:31.870 --> 00:53:33.140
nothing special here.

00:53:33.140 --> 00:53:37.100
So this is just simply you
can read a variable,

00:53:37.100 --> 00:53:38.570
you can have constants.

00:53:38.570 --> 00:53:41.550
These are just names
and there's nothing

00:53:41.550 --> 00:53:42.820
special going on here.

00:53:42.820 --> 00:53:44.060
Let me explain you guards.

00:53:44.060 --> 00:53:49.150
So people find guards versus
if's confusing.

00:53:49.150 --> 00:53:51.760
And this is one way
to understand it.

00:53:51.760 --> 00:53:53.590
So guards affect the
surroundings.

00:53:53.590 --> 00:54:00.500
If I wrote here a1 when p1 in
parallel with a2 think of

00:54:00.500 --> 00:54:03.250
guard as something to
do with resources.

00:54:03.250 --> 00:54:10.170
I really don't want you to
do a1 unless p1 is true.

00:54:10.170 --> 00:54:14.080
p1 made a fact that the
module was busy.

00:54:14.080 --> 00:54:15.880
Some predicate here.

00:54:15.880 --> 00:54:20.330
But I want the effect of this
whole thing to be atomic.

00:54:20.330 --> 00:54:23.100
So if any part of it can't be
done then the whole thing

00:54:23.100 --> 00:54:24.780
can't be done.

00:54:24.780 --> 00:54:29.370
And therefore the affect of
guard is as if you wrote a1 in

00:54:29.370 --> 00:54:31.240
parallel with a2 when p1.

00:54:31.240 --> 00:54:34.420
In other words, guard on
anything becomes guard on

00:54:34.420 --> 00:54:36.250
everything in that parallel
composition.

00:54:38.920 --> 00:54:40.390
Do you understand what
I just said?

00:54:42.980 --> 00:54:46.350
This is very important for
composition of guards.

00:54:46.350 --> 00:54:47.850
Because I want the
atomicity of the

00:54:47.850 --> 00:54:48.950
whole thing to be preserved.

00:54:48.950 --> 00:54:51.470
So if anything can't be done
that means the whole thing

00:54:51.470 --> 00:54:54.370
can't be done.

00:54:54.370 --> 00:54:56.480
On the other hand, conditional
action is

00:54:56.480 --> 00:54:57.440
just conditional action.

00:54:57.440 --> 00:55:02.000
So if I have if p1 than a1 in
parallel with a2, well that's

00:55:02.000 --> 00:55:06.080
like saying if p1 was true then
I want to do a1 and a2 in

00:55:06.080 --> 00:55:10.570
parallel, otherwise I
just want to do a2.

00:55:10.570 --> 00:55:14.230
So there is a very big
difference between conditional

00:55:14.230 --> 00:55:15.560
actions and guards.

00:55:15.560 --> 00:55:17.530
Guards are something
about resources.

00:55:17.530 --> 00:55:20.730
I need it for proper composition
of atomic actions.

00:55:24.300 --> 00:55:25.550
AUDIENCE: I have question.

00:55:27.650 --> 00:55:28.990
So are they entirely
equal into.

00:55:28.990 --> 00:55:33.490
Because this is maybe a
low-level question, but in the

00:55:33.490 --> 00:55:36.780
first case-- so the first
case in the left.

00:55:36.780 --> 00:55:39.002
Can't you start doing a2
and then roll it back

00:55:39.002 --> 00:55:40.240
or something [OBSCURED]

00:55:40.240 --> 00:55:43.276
ARVIND: Oh, I think there may be
many tricks you can play in

00:55:43.276 --> 00:55:43.540
implentation.

00:55:43.540 --> 00:55:44.890
You can be optimistic,
you can--

00:55:44.890 --> 00:55:45.700
[INTERPOSING VOICES]

00:55:45.700 --> 00:55:45.850
ARVIND: No.

00:55:45.850 --> 00:55:45.950
No.

00:55:45.950 --> 00:55:47.110
No.

00:55:47.110 --> 00:55:50.740
Semantically this is this
defining the semantics.

00:55:50.740 --> 00:55:52.110
I mean, this is the algebra.

00:55:52.110 --> 00:55:55.300
This has to be true because
I'm saying this is

00:55:55.300 --> 00:55:56.310
what a guard is.

00:55:56.310 --> 00:55:57.344
AUDIENCE: Right, so the
semantically equal but not

00:55:57.344 --> 00:56:02.860
[OBSCURED].

00:56:02.860 --> 00:56:04.520
ARVIND: Well I mean, that's
probably not the

00:56:04.520 --> 00:56:05.210
right way to say it.

00:56:05.210 --> 00:56:07.230
I mean, semantics are
being defined.

00:56:07.230 --> 00:56:08.520
You have choice in
implementations.

00:56:11.050 --> 00:56:13.760
I mean I'm not telling you
how to implement this.

00:56:13.760 --> 00:56:15.030
Let me go on with this.

00:56:15.030 --> 00:56:20.520
So here is a problem that was
posed to me by Jayadev Misra.

00:56:20.520 --> 00:56:23.790
This is quasi realistic
problem.

00:56:23.790 --> 00:56:25.980
Ask for codes from 2 airlines.

00:56:25.980 --> 00:56:30.700
If one code is below $300,
buy immediately.

00:56:30.700 --> 00:56:34.520
$300 is sort of the cheapest
ticket you get these dates.

00:56:34.520 --> 00:56:38.240
Buy the lower quote
if over $300.

00:56:38.240 --> 00:56:41.360
But as some-- say your patience
runs out, say I can't

00:56:41.360 --> 00:56:42.900
wait anymore.

00:56:42.900 --> 00:56:48.370
So after one minute buy from
whosoever has quoted otherwise

00:56:48.370 --> 00:56:51.130
flag error.

00:56:51.130 --> 00:56:52.410
Is this a realistic scenario?

00:56:56.170 --> 00:56:58.850
You can express it
using threads.

00:56:58.850 --> 00:57:03.480
And you can write a scheduler
to do this, et cetera.

00:57:05.990 --> 00:57:09.780
Those things are not as succint
as you would like.

00:57:09.780 --> 00:57:13.130
I mean, you'd be surprised, in
this simple a problem how

00:57:13.130 --> 00:57:15.550
complicated and how many
questions will arise if you

00:57:15.550 --> 00:57:18.000
express this as a threaded
computation.

00:57:18.000 --> 00:57:21.890
Now let me show you
what you will do--

00:57:26.200 --> 00:57:29.110
in Bluuspec.

00:57:29.110 --> 00:57:32.720
OK, so we are going to make
a module, which does what?

00:57:32.720 --> 00:57:35.590
Make get quotes.

00:57:35.590 --> 00:57:38.600
This module's job is
to get quotes.

00:57:38.600 --> 00:57:43.000
So what kind of state elements
do you expect it to have?

00:57:43.000 --> 00:57:46.030
Well airline a may be quoting
some value, airline b may be

00:57:46.030 --> 00:57:47.400
quoting some value.

00:57:47.400 --> 00:57:50.290
Whether we are done or not
there's a timer, which we're

00:57:50.290 --> 00:57:53.080
going to be bumping,
et cetera.

00:57:53.080 --> 00:57:58.120
And they'll be rules you know,
get a quote from a, which will

00:57:58.120 --> 00:58:01.060
be when not done do something.

00:58:01.060 --> 00:58:04.360
Executes when a responds.

00:58:04.360 --> 00:58:06.530
Get b, timeout, et cetera.

00:58:06.530 --> 00:58:10.090
There are there ruls
of this sort.

00:58:10.090 --> 00:58:13.700
Let me just show you
one methodd.

00:58:13.700 --> 00:58:17.600
So method, this is how
you will start it--

00:58:17.600 --> 00:58:20.230
you have this module get quotes
and you're saying book

00:58:20.230 --> 00:58:23.660
me a ticket and this
is your request r.

00:58:23.660 --> 00:58:25.430
Now obviously this can
only be done when the

00:58:25.430 --> 00:58:27.250
module is not busy.

00:58:27.250 --> 00:58:30.300
If module is busy the
you can't do it.

00:58:30.300 --> 00:58:32.870
So what will you do when
you get such a request?

00:58:32.870 --> 00:58:35.660
Tell me this makes sense.

00:58:35.660 --> 00:58:36.910
So what is this saying?

00:58:39.720 --> 00:58:46.190
Try to get a request
from a in parallel.

00:58:46.190 --> 00:58:48.780
Try to get a request from b.

00:58:51.630 --> 00:58:53.380
Now you are busy.

00:58:53.380 --> 00:58:58.620
The module is busy so done
equals false here.

00:58:58.620 --> 00:59:00.350
And I'm initializing this.

00:59:00.350 --> 00:59:04.120
I'm just saying that a quote
right now is infinity and b

00:59:04.120 --> 00:59:09.190
quote is infinity and
timer is zero.

00:59:09.190 --> 00:59:11.900
Fair?

00:59:11.900 --> 00:59:14.350
And when will I get ticket?

00:59:14.350 --> 00:59:17.780
Well, when done then you'll
return the ticket from this.

00:59:17.780 --> 00:59:20.950
Now let's look at example
of a rule.

00:59:23.870 --> 00:59:31.020
So you may have a rule like
this, pick cheapest. You see

00:59:31.020 --> 00:59:33.590
the interesting thing in this is
you'll be able to read this

00:59:33.590 --> 00:59:36.980
independently of what else is
going on in this system.

00:59:36.980 --> 00:59:39.760
And let's see, what does
this rule say?

00:59:39.760 --> 00:59:41.830
Is it succint?

00:59:41.830 --> 00:59:48.200
Rules says when you are not done
and if the quote from a

00:59:48.200 --> 00:59:54.840
is not infinite that
means a has quoted.

00:59:54.840 --> 01:00:04.760
And b has also quoted, then
what should happen?

01:00:04.760 --> 01:00:09.340
If a is less than b then
buy the ticket from a.

01:00:09.340 --> 01:00:14.270
Otherwise you'll buy the ticket
from b and you're done.

01:00:19.370 --> 01:00:22.330
I'm not going to write all these
rules, but I think you

01:00:22.330 --> 01:00:25.080
should be able to--

01:00:25.080 --> 01:00:29.770
I'm certain you can
write these rules.

01:00:29.770 --> 01:00:34.180
What's happening here that is
just separation of concerns.

01:00:34.180 --> 01:00:36.830
It's all concurrenct stuff.

01:00:36.830 --> 01:00:38.261
Yes?

01:00:38.261 --> 01:00:43.370
AUDIENCE: [OBSCURED]

01:00:43.370 --> 01:00:44.840
ARVIND: Parallel?

01:00:44.840 --> 01:00:46.530
AUDIENCE: Or like, for
lack of better words

01:00:46.530 --> 01:00:50.980
the type in the name.

01:00:50.980 --> 01:00:51.720
ARVIND: Sorry, say it again.

01:00:51.720 --> 01:00:56.417
AUDIENCE: So as the ampersand,
how does that

01:00:56.417 --> 01:00:56.850
interact with the--

01:00:56.850 --> 01:00:58.386
PROFESSOR: Can you hold that
question first because we will

01:00:58.386 --> 01:00:59.636
run out of space.

01:01:01.990 --> 01:01:10.634
AUDIENCE: So the ampersand after
not done that is, what

01:01:10.634 --> 01:01:14.020
sort of ordering is that?

01:01:14.020 --> 01:01:16.760
ARVIND: It's just, I mean,
associative, commutative.

01:01:16.760 --> 01:01:18.360
Kind of thing.

01:01:18.360 --> 01:01:19.350
It's all happening
in parallel.

01:01:19.350 --> 01:01:22.890
AUDIENCE: [OBSCURED].

01:01:22.890 --> 01:01:26.040
ARVIND: This thing, right?

01:01:26.040 --> 01:01:29.800
I mean, think of it like this,
these are variables and you're

01:01:29.800 --> 01:01:32.310
checking their values
right now.

01:01:32.310 --> 01:01:35.310
So it's just a combination
kind of a query

01:01:35.310 --> 01:01:36.400
that you have here.

01:01:36.400 --> 01:01:38.297
AUDIENCE: So I guess you're
checking there's

01:01:38.297 --> 01:01:39.410
new activity happening.

01:01:39.410 --> 01:01:40.300
ARVIND: That's right.

01:01:40.300 --> 01:01:44.481
AUDIENCE: Doesn't matter
which order you check.

01:01:44.481 --> 01:01:45.984
AUDIENCE: So I guess what I'm
trying to get is that the

01:01:45.984 --> 01:01:47.988
whole block at the top is
executed in parallel with the

01:01:47.988 --> 01:01:51.780
block at the bottom?

01:01:51.780 --> 01:01:52.340
ARVIND: No.

01:01:52.340 --> 01:01:55.050
Those things are not
in parallel.

01:01:55.050 --> 01:01:56.300
AUDIENCE:
[UNINTELLIGIBLE PHRASE]

01:02:09.660 --> 01:02:12.010
ARVIND: Now I just want to show
you this because it's

01:02:12.010 --> 01:02:15.510
completely different from
airline reservations.

01:02:15.510 --> 01:02:19.490
You know, H.264 this is a
codec that is being used

01:02:19.490 --> 01:02:23.740
everywhere and we'll
be used even more.

01:02:23.740 --> 01:02:27.420
And this is a typical data flow
diagram you will find for

01:02:27.420 --> 01:02:28.350
this kind of thing.

01:02:28.350 --> 01:02:31.940
You don't have to understand
anything about this except

01:02:31.940 --> 01:02:36.250
that conceptually you just
have five flows for

01:02:36.250 --> 01:02:41.120
communicating between them and
in all such things the goal is

01:02:41.120 --> 01:02:43.190
that it has to be able to
sustain a certain amount of

01:02:43.190 --> 01:02:46.590
rate at which dat is to be
processed and it's usually

01:02:46.590 --> 01:02:50.140
forgiving in terms
of latencies.

01:02:50.140 --> 01:02:52.500
So if latency increases a little
bit here and there it's

01:02:52.500 --> 01:02:56.910
usually OK-- when things
go in and come out.

01:02:56.910 --> 01:03:00.320
A data flow like network.

01:03:00.320 --> 01:03:02.540
And another reason why this
example is fascinating is

01:03:02.540 --> 01:03:06.350
because it's done regularly both
in hardware and software

01:03:06.350 --> 01:03:08.250
and any mixture of the two.

01:03:08.250 --> 01:03:11.040
So for example, when it runs
on your PC it's being done

01:03:11.040 --> 01:03:17.420
100% in software and I think
on iPods there are special

01:03:17.420 --> 01:03:20.870
purpose hardware for doing it
and therefore the battery can

01:03:20.870 --> 01:03:23.530
last much longer.

01:03:23.530 --> 01:03:27.010
And on cell phones it's kind of
in between in this and it's

01:03:27.010 --> 01:03:30.420
a question of what frame rate
you want to process?

01:03:30.420 --> 01:03:33.050
If you're procssing very high
frame rate then it'll have to

01:03:33.050 --> 01:03:36.800
be done in hardware.

01:03:36.800 --> 01:03:41.770
So when we got into this thing
we said, OK, we wanted to

01:03:41.770 --> 01:03:44.030
build hardware for doing this.

01:03:44.030 --> 01:03:48.200
And reference codes that are
available, it's 80,000 lines

01:03:48.200 --> 01:03:50.010
and it sort of gives
you a heart attack.

01:03:50.010 --> 01:03:52.520
You know, you read this
and you say, whoa!

01:03:52.520 --> 01:03:54.880
And it doesn't need
the performance.

01:03:54.880 --> 01:03:57.230
I mean, that reference code, if
it ran on your laptop you

01:03:57.230 --> 01:04:01.180
won't be able to watch
a movie with this.

01:04:01.180 --> 01:04:05.210
And there is the Linux version
of it, which gives you even a

01:04:05.210 --> 01:04:09.930
bigger heart attack because
it's 200,000 lies and many

01:04:09.930 --> 01:04:12.430
different codecs are
mixed in this.

01:04:15.620 --> 01:04:20.180
The biggest problem here it is
none of these codes reflect

01:04:20.180 --> 01:04:23.660
that picture I showed you
of the previous diagram.

01:04:23.660 --> 01:04:28.060
Because the way people approach
it in software is

01:04:28.060 --> 01:04:32.770
they take some input from
here and they push it

01:04:32.770 --> 01:04:34.020
as far as they can.

01:04:37.410 --> 01:04:37.990
And that's it.

01:04:37.990 --> 01:04:40.540
Then they will take the next
input and push it.

01:04:40.540 --> 01:04:44.500
So different boxes keep
modifying it as they see fit

01:04:44.500 --> 01:04:48.735
and as a reader you can't tell,
oh, this is this part

01:04:48.735 --> 01:04:49.700
and this is this part.

01:04:49.700 --> 01:04:50.940
I mean, there are no 54Q's.

01:04:50.940 --> 01:04:51.710
Why?

01:04:51.710 --> 01:04:54.870
Because 54Q's are expensive
in software.

01:04:54.870 --> 01:04:56.380
You know, it will
involve copying.

01:04:56.380 --> 01:04:58.920
You know, you'll write it here
then you'll read it again,

01:04:58.920 --> 01:05:01.710
which is a bad idea
in software.

01:05:01.710 --> 01:05:05.830
So in some sense, the software
will thinking already entered.

01:05:09.690 --> 01:05:14.050
In this style of coding there
is no model of concurrency.

01:05:14.050 --> 01:05:16.720
So it's not clear to me when
you give me that quote what

01:05:16.720 --> 01:05:19.720
all I can do in parallel in
order to preserve the

01:05:19.720 --> 01:05:21.020
semantics of this.

01:05:21.020 --> 01:05:23.790
I mean the problem is much,
much harder here.

01:05:23.790 --> 01:05:26.730
So you will just do some
high-level analysis of the

01:05:26.730 --> 01:05:30.100
code, but you have lost a lot
of information that was all

01:05:30.100 --> 01:05:32.380
present in the source--

01:05:32.380 --> 01:05:34.150
could've been present
in the source.

01:05:34.150 --> 01:05:35.990
And my claim is it can
be done differently.

01:05:35.990 --> 01:05:41.620
So this has been done by
Chun-Chieh and this I'm

01:05:41.620 --> 01:05:44.870
showing you a month old slide,
but he has done a lot more

01:05:44.870 --> 01:05:49.970
work since then and the total
code in Bluespec is 9000 lines

01:05:49.970 --> 01:05:54.650
for this contrasting it with
80,000 versus 200,000 kind of

01:05:54.650 --> 01:05:59.090
stuff and this is telling you
the amount of code in various

01:05:59.090 --> 01:06:02.080
blocks in this.

01:06:02.080 --> 01:06:04.940
And since it's done in Bluespec
you can take it and

01:06:04.940 --> 01:06:08.290
you can go and implement it all
in hardware, so you can

01:06:08.290 --> 01:06:10.980
synthesize it.

01:06:10.980 --> 01:06:15.380
It actually does now 45 frames
per second, actually 90 frames

01:06:15.380 --> 01:06:17.510
even per second today.

01:06:17.510 --> 01:06:20.410
You know, so this
is a month old.

01:06:20.410 --> 01:06:23.180
This is the main point.

01:06:23.180 --> 01:06:26.440
Once you have done this
now you can refine it.

01:06:26.440 --> 01:06:28.120
You have a different
preference.

01:06:28.120 --> 01:06:30.830
You say, oh, I want to
do this differently.

01:06:30.830 --> 01:06:34.640
So you can go and rewrite
any module again.

01:06:34.640 --> 01:06:38.110
It will be very, very easy
to do this in the system.

01:06:38.110 --> 01:06:41.840
It is very difficult to do this
in the reference code, so

01:06:41.840 --> 01:06:43.940
that's one point to be made.

01:06:43.940 --> 01:06:46.220
The second thing is you
don't have to do

01:06:46.220 --> 01:06:47.180
everything in hardware.

01:06:47.180 --> 01:06:49.520
If you wanted you could have
implemented any part of it in

01:06:49.520 --> 01:06:52.510
software, so you can take the
same kind of a description and

01:06:52.510 --> 01:06:55.680
generate software
from it as well.

01:06:55.680 --> 01:06:57.530
So each module can be
refined separately.

01:06:57.530 --> 01:07:00.610
Behaviors of modules
are composable.

01:07:00.610 --> 01:07:05.190
You know, you can take these
things and it's predictable

01:07:05.190 --> 01:07:07.400
what will happen when you
compose these things in terms

01:07:07.400 --> 01:07:11.480
of performance and in terms of
resources also, it's very

01:07:11.480 --> 01:07:12.820
clear what's happening.

01:07:12.820 --> 01:07:14.950
In hardware the resources
will be area and time

01:07:14.950 --> 01:07:17.100
and so on in this.

01:07:17.100 --> 01:07:18.730
So takeaway.

01:07:18.730 --> 01:07:21.400
Parallel programming should be
based on well-defined modules

01:07:21.400 --> 01:07:24.580
and parallel composition
of such modules.

01:07:24.580 --> 01:07:28.140
Modules must embody a notion of
resources and consequently,

01:07:28.140 --> 01:07:31.020
sharing in time multiplex use.

01:07:31.020 --> 01:07:33.510
This is a controversial point.

01:07:33.510 --> 01:07:35.820
And guard atomic actions and
modules with guarded

01:07:35.820 --> 01:07:39.800
interfaces provide a solid
foundation for doing so.

01:07:39.800 --> 01:07:41.050
PROFESSOR: Thank you.

01:07:44.996 --> 01:07:47.151
Now we ran a little bit late,
so if you have questions you

01:07:47.151 --> 01:07:50.050
can ask about programs.