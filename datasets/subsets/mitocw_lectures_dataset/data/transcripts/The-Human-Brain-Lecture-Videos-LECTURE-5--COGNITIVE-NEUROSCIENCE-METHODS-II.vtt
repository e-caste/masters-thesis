WEBVTT

00:00:00.000 --> 00:00:02.420
[SQUEAKING]

00:00:02.420 --> 00:00:03.872
[RUSTLING]

00:00:03.872 --> 00:00:07.260
[CLICKING]

00:00:10.115 --> 00:00:11.740
NANCY KANWISHER: All
right, it's 11:05.

00:00:11.740 --> 00:00:12.890
Let's get started.

00:00:12.890 --> 00:00:15.820
So the agenda for today,
we're doing this whole thing

00:00:15.820 --> 00:00:18.310
on the methods in human
cognitive neuroscience.

00:00:18.310 --> 00:00:19.810
And I'm illustrating
those methods

00:00:19.810 --> 00:00:21.580
with the case of
face perception.

00:00:21.580 --> 00:00:23.710
Not just because I'm
into face perception,

00:00:23.710 --> 00:00:26.710
but it's a particularly
rich domain of research

00:00:26.710 --> 00:00:28.750
where there's lots to
say about it from all

00:00:28.750 --> 00:00:30.460
these different methods.

00:00:30.460 --> 00:00:31.930
And so last time,
we talked a bit

00:00:31.930 --> 00:00:34.240
about applying Marr's
computational theory

00:00:34.240 --> 00:00:35.590
level to face perception.

00:00:35.590 --> 00:00:38.110
We talked a teeny bit
about some behavioral data

00:00:38.110 --> 00:00:40.060
and a little bit
about functional MRI.

00:00:40.060 --> 00:00:41.890
What I'm going to
do today is quickly

00:00:41.890 --> 00:00:44.562
zoom through a speeded-up
review of those things,

00:00:44.562 --> 00:00:47.020
and then we're going to get to
some of these other methods.

00:00:47.020 --> 00:00:48.640
And there's a quiz at the end.

00:00:48.640 --> 00:00:50.020
All right?

00:00:50.020 --> 00:00:56.440
OK, so methods in
any field of science

00:00:56.440 --> 00:00:59.650
are just there to enable us to
answer scientific questions.

00:00:59.650 --> 00:01:01.870
They're not to
impress our friends

00:01:01.870 --> 00:01:03.700
with all the fancy
things we know how to do

00:01:03.700 --> 00:01:05.470
or our colleagues.

00:01:05.470 --> 00:01:06.925
They're just to
answer questions.

00:01:06.925 --> 00:01:09.050
And so you always have to
start with the questions.

00:01:09.050 --> 00:01:11.800
And so last time, I listed
a bunch of questions.

00:01:11.800 --> 00:01:13.540
Not all of them, but
a bunch of questions

00:01:13.540 --> 00:01:16.000
one would really want to
know about face perception

00:01:16.000 --> 00:01:19.690
if we were to understand
how it works in the brain.

00:01:19.690 --> 00:01:22.300
And last time, we focused
on these first three.

00:01:22.300 --> 00:01:24.580
So let me just do a
super quick review.

00:01:24.580 --> 00:01:27.100
The questions at the level of
Marr's computational theory,

00:01:27.100 --> 00:01:29.830
we ask, what is the
problem that's being solved

00:01:29.830 --> 00:01:32.020
and why is that important
to the organism?

00:01:32.020 --> 00:01:34.030
What is the input,
what is the output?

00:01:34.030 --> 00:01:37.120
How much you get from that
input to that output, right?

00:01:37.120 --> 00:01:39.070
So for the case of
face perception,

00:01:39.070 --> 00:01:40.973
here's a very simple
version of it.

00:01:40.973 --> 00:01:42.265
Here's an example of the input.

00:01:42.265 --> 00:01:44.290
It goes in, hits the retina.

00:01:44.290 --> 00:01:46.600
The stuff that we want to
understand happens in here,

00:01:46.600 --> 00:01:47.830
and you have an output.

00:01:47.830 --> 00:01:50.770
OK, so just even thinking
about it that way,

00:01:50.770 --> 00:01:53.140
we can already just
see, with common sense,

00:01:53.140 --> 00:01:56.080
that one of the big challenges
in solving this problem

00:01:56.080 --> 00:01:59.350
is that faces look different
every time you see them.

00:01:59.350 --> 00:02:01.300
The lighting changes,
the orientation

00:02:01.300 --> 00:02:04.240
of the face changes, the hair
changes, the mood changes,

00:02:04.240 --> 00:02:05.350
all this stuff happens.

00:02:05.350 --> 00:02:08.539
People put on makeup, they
shave off their facial hair,

00:02:08.539 --> 00:02:11.470
they do all these things
to make it a big challenge

00:02:11.470 --> 00:02:12.790
to recognize faces.

00:02:12.790 --> 00:02:14.870
And yet, we manage really well.

00:02:14.870 --> 00:02:16.910
So how do we do that?

00:02:16.910 --> 00:02:20.680
Well, our field has many methods
to address this question.

00:02:20.680 --> 00:02:23.320
Last time, I talked
about one little example

00:02:23.320 --> 00:02:26.740
of a behavioral study--
simple, cognitive psychology

00:02:26.740 --> 00:02:31.660
study measuring behavior--
where we showed that the way

00:02:31.660 --> 00:02:33.670
people solve this
problem is fundamentally

00:02:33.670 --> 00:02:35.620
different with
people they know well

00:02:35.620 --> 00:02:37.300
and people they don't know well.

00:02:37.300 --> 00:02:40.390
So I showed an example
that all of you

00:02:40.390 --> 00:02:42.910
presumably would have
no trouble determining

00:02:42.910 --> 00:02:45.130
that those are all pictures
of the same person,

00:02:45.130 --> 00:02:48.670
even though at the pixel level
they're wildly different.

00:02:48.670 --> 00:02:51.130
And yet, you have a hell of
a time saying which of those

00:02:51.130 --> 00:02:53.810
images are of the same
people and which aren't.

00:02:53.810 --> 00:02:56.050
And so the point
is that our ability

00:02:56.050 --> 00:02:58.750
to extract this invariant
representation, that

00:02:58.750 --> 00:03:02.800
is to figure out
abstractly who is that,

00:03:02.800 --> 00:03:06.190
is really-- well, to figure
out that any of these images

00:03:06.190 --> 00:03:08.800
are the same as each other
is much better for familiar

00:03:08.800 --> 00:03:10.120
than unfamiliar faces.

00:03:10.120 --> 00:03:13.060
And that means we don't have
a perfectly general ability

00:03:13.060 --> 00:03:18.310
to take any face and
abstract out this completely

00:03:18.310 --> 00:03:20.150
image-independent version of it.

00:03:20.150 --> 00:03:21.940
That's what invariant
representation is.

00:03:21.940 --> 00:03:23.040
Yeah?

00:03:23.040 --> 00:03:25.390
AUDIENCE: For the case
of the Dutch politicians,

00:03:25.390 --> 00:03:27.610
did they ever do
the study on people

00:03:27.610 --> 00:03:30.132
who were super recognizers?

00:03:30.132 --> 00:03:31.840
NANCY KANWISHER: I
don't know about that,

00:03:31.840 --> 00:03:35.770
but they did do it
on people who are

00:03:35.770 --> 00:03:40.120
professional TSA-type people.

00:03:40.120 --> 00:03:40.840
AUDIENCE: OK.

00:03:40.840 --> 00:03:41.080
NANCY KANWISHER: Right?

00:03:41.080 --> 00:03:42.747
And I'll tell you
guys about that later.

00:03:42.747 --> 00:03:45.040
But you could think
about whether you

00:03:45.040 --> 00:03:49.360
think it might work better
with those people or not.

00:03:49.360 --> 00:03:51.460
OK, everybody get this
general point here?

00:03:51.460 --> 00:03:53.200
All right.

00:03:53.200 --> 00:03:56.350
So I skipped over another
simple behavioral finding

00:03:56.350 --> 00:03:58.720
last time that I
want to mention now.

00:03:58.720 --> 00:04:01.540
And that is an
extremely low tech--

00:04:01.540 --> 00:04:05.170
charmingly low tech, and yet, I
think very powerful-- discovery

00:04:05.170 --> 00:04:06.350
about face perception.

00:04:06.350 --> 00:04:09.310
One of the most
important original bits

00:04:09.310 --> 00:04:11.110
of evidence that
face perception might

00:04:11.110 --> 00:04:14.530
be a different thing in the
brain came from a PhD thesis

00:04:14.530 --> 00:04:17.050
in this department by
a guy named Robert Yin.

00:04:17.050 --> 00:04:20.620
And he used the extremely
high tech equipment

00:04:20.620 --> 00:04:24.340
of a stopwatch and paper.

00:04:24.340 --> 00:04:26.060
OK, so what did he do?

00:04:26.060 --> 00:04:28.450
He presented faces
to people upright.

00:04:28.450 --> 00:04:30.820
And he said, study
these 20 faces.

00:04:30.820 --> 00:04:32.183
And then he tested them later.

00:04:32.183 --> 00:04:33.100
Did you see this face?

00:04:33.100 --> 00:04:34.017
Did you see this face?

00:04:34.017 --> 00:04:35.680
Did you see this face?

00:04:35.680 --> 00:04:37.750
And then he did the
exact same experiment

00:04:37.750 --> 00:04:40.750
on a different set of faces,
but they were all upside down.

00:04:40.750 --> 00:04:44.350
Studied upside down
and tested upside down.

00:04:44.350 --> 00:04:45.950
And what did he find?

00:04:45.950 --> 00:04:49.000
He found what's known as
the face inversion effect.

00:04:49.000 --> 00:04:52.030
Namely, people do much
worse at this task

00:04:52.030 --> 00:04:54.040
when the faces are upside down.

00:04:54.040 --> 00:04:56.380
Here's errors for
inverted upside down,

00:04:56.380 --> 00:04:58.600
errors for upright at this task.

00:04:58.600 --> 00:05:01.660
Even though, importantly,
they were studied and tested

00:05:01.660 --> 00:05:05.830
upside down or studied
and tested inverted--

00:05:05.830 --> 00:05:07.390
upright.

00:05:07.390 --> 00:05:09.630
OK, everybody got
what this shows?

00:05:09.630 --> 00:05:14.013
OK, so that's cool that
this face inversion--

00:05:14.013 --> 00:05:16.680
but the further cool thing is he
showed that this face inversion

00:05:16.680 --> 00:05:21.190
effect is greater for faces
than for other kinds of stimuli.

00:05:21.190 --> 00:05:22.900
So he tested lots
of other things,

00:05:22.900 --> 00:05:25.800
including houses
and stick figures.

00:05:25.800 --> 00:05:27.990
And he showed that
that cost, when

00:05:27.990 --> 00:05:29.670
you turn the
stimuli upside down,

00:05:29.670 --> 00:05:31.470
is greater, that
difference is greater

00:05:31.470 --> 00:05:35.340
for faces than for other
classes of stimuli.

00:05:35.340 --> 00:05:40.380
So what that suggests is that
face recognition may just

00:05:40.380 --> 00:05:43.980
work differently in some
deep way from recognition

00:05:43.980 --> 00:05:46.410
of other classes of stimuli.

00:05:46.410 --> 00:05:50.070
And Robert Yin actually
inferred in his PhD thesis--

00:05:50.070 --> 00:05:52.740
way, way back before
any imaging method--

00:05:52.740 --> 00:05:54.360
that maybe there
are special parts

00:05:54.360 --> 00:05:56.340
of the brain for
face recognition.

00:05:56.340 --> 00:05:59.040
And maybe face recognition is
just a totally different thing,

00:05:59.040 --> 00:06:01.500
that's why it is more
affected by inversion

00:06:01.500 --> 00:06:03.550
than recognition of
other kinds of things.

00:06:03.550 --> 00:06:05.040
Was there a question back there?

00:06:05.040 --> 00:06:05.745
Yeah.

00:06:05.745 --> 00:06:07.920
AUDIENCE: I was going to
ask, could that just be

00:06:07.920 --> 00:06:11.670
because faces are much more
complex than houses or stick

00:06:11.670 --> 00:06:12.638
figures and that--

00:06:12.638 --> 00:06:13.930
NANCY KANWISHER: Good question.

00:06:13.930 --> 00:06:14.390
Hang on to--

00:06:14.390 --> 00:06:14.790
AUDIENCE: --backwards.

00:06:14.790 --> 00:06:16.082
NANCY KANWISHER: Good question.

00:06:16.082 --> 00:06:17.460
That's a very good question.

00:06:17.460 --> 00:06:20.730
And many people have tried
to grapple with that.

00:06:20.730 --> 00:06:23.040
And actually,
about 10 years ago,

00:06:23.040 --> 00:06:25.440
the idea that this
disproportionate effect

00:06:25.440 --> 00:06:30.570
for faces was standard
textbook, completely accepted.

00:06:30.570 --> 00:06:33.480
And now there's another
round of people doubting it

00:06:33.480 --> 00:06:34.720
with other kinds of stimuli.

00:06:34.720 --> 00:06:35.800
So it's kind of ongoing.

00:06:35.800 --> 00:06:39.420
It's a very robust difference,
but to say exactly what it

00:06:39.420 --> 00:06:42.822
is about face stimuli versus
other kinds of things that

00:06:42.822 --> 00:06:44.280
is responsible for
that difference,

00:06:44.280 --> 00:06:46.890
you can imagine it's subtle.

00:06:46.890 --> 00:06:49.560
For the purposes
of this course, I'm

00:06:49.560 --> 00:06:51.120
trying to not quite
lie to you guys,

00:06:51.120 --> 00:06:54.210
but give you the most standard
view without freighting you

00:06:54.210 --> 00:06:57.210
with every possible objection
to every little thing.

00:06:57.210 --> 00:06:59.010
Because pretty
much every finding,

00:06:59.010 --> 00:07:01.385
there's somebody who
has a beef with it.

00:07:01.385 --> 00:07:02.760
We'll tell you,
that's not really

00:07:02.760 --> 00:07:03.870
true because blah-di-blah.

00:07:03.870 --> 00:07:04.380
OK?

00:07:04.380 --> 00:07:07.825
So yes, there's a little
bit of debate going on

00:07:07.825 --> 00:07:08.700
about this right now.

00:07:08.700 --> 00:07:10.330
But for the purposes
of this course,

00:07:10.330 --> 00:07:15.270
it's pretty damn rock solid, at
least as an empirical result.

00:07:15.270 --> 00:07:16.590
All right.

00:07:16.590 --> 00:07:20.020
So there's in fact lots of
versions of the face inversion

00:07:20.020 --> 00:07:20.520
effect.

00:07:20.520 --> 00:07:23.400
One you may have seen before
but which is very amusing.

00:07:23.400 --> 00:07:26.010
If you look at faces like
this that are upside down,

00:07:26.010 --> 00:07:28.890
they look sort of normal.

00:07:28.890 --> 00:07:31.350
But then if you rotate
them, you realize

00:07:31.350 --> 00:07:34.235
there's something
deeply weird going on.

00:07:34.235 --> 00:07:35.610
So the point is,
you're much more

00:07:35.610 --> 00:07:39.090
sensitive to those
grotesquely distorted faces

00:07:39.090 --> 00:07:41.340
when you see them right side
up than when you see them

00:07:41.340 --> 00:07:42.040
upside down.

00:07:42.040 --> 00:07:44.650
So that's another version of
the face inversion effect,

00:07:44.650 --> 00:07:47.130
and there are many, many
incarnations of this effect.

00:07:47.130 --> 00:07:50.910
You'll see another one
later in the lecture.

00:07:50.910 --> 00:07:53.580
So where did we get last
time with these questions?

00:07:53.580 --> 00:07:57.600
We got that one of the major, if
not the major central challenge

00:07:57.600 --> 00:08:00.000
in face recognition at
a computational level,

00:08:00.000 --> 00:08:03.390
is the fact that we deal
with huge image variation

00:08:03.390 --> 00:08:04.530
each time we see a face.

00:08:04.530 --> 00:08:06.880
And yet, somehow we're
able to grapple with it.

00:08:06.880 --> 00:08:08.920
So to understand how face
recognition works will

00:08:08.920 --> 00:08:11.340
be to understand,
what is the code,

00:08:11.340 --> 00:08:13.017
ultimately-- nobody
knows right now--

00:08:13.017 --> 00:08:14.850
but what is a code
running in our heads that

00:08:14.850 --> 00:08:16.050
enables us to do that?

00:08:16.050 --> 00:08:17.610
What is our mental
representation

00:08:17.610 --> 00:08:21.960
of a face that enables us
to deal with this problem?

00:08:21.960 --> 00:08:25.170
By looking at behavioral
data, we got some evidence

00:08:25.170 --> 00:08:28.140
from the Dutch politician
study that whatever

00:08:28.140 --> 00:08:30.940
that representation is
that we extract from faces,

00:08:30.940 --> 00:08:33.929
it's not independent of
the particular image.

00:08:33.929 --> 00:08:37.350
It's not that we have some
platonic ideal of the face

00:08:37.350 --> 00:08:39.000
that we can extract
from any face

00:08:39.000 --> 00:08:42.960
that lands on our retina,
platonic ideal of that person's

00:08:42.960 --> 00:08:43.770
face, right?

00:08:43.770 --> 00:08:47.430
So whatever we're doing, it's
not completely invariant,

00:08:47.430 --> 00:08:54.000
because we can't do that so
well with unfamiliar faces.

00:08:54.000 --> 00:08:56.280
Also, as I just
showed you-- related,

00:08:56.280 --> 00:08:58.210
but not exactly the same point--

00:08:58.210 --> 00:08:59.910
our mental
representations of faces

00:08:59.910 --> 00:09:02.700
are very sensitive to the
orientation of the face

00:09:02.700 --> 00:09:04.410
more than our mental
representations

00:09:04.410 --> 00:09:07.500
of other classes of stimuli.

00:09:07.500 --> 00:09:12.300
So those are just very simple
insights about whatever

00:09:12.300 --> 00:09:14.550
our representations of
faces are in our heads,

00:09:14.550 --> 00:09:18.150
just from simple
behavioral data.

00:09:18.150 --> 00:09:21.960
OK, so let me just review some
of the strengths and weaknesses

00:09:21.960 --> 00:09:23.730
of simple behavioral methods.

00:09:23.730 --> 00:09:25.680
Strengths are, they're
good for characterizing

00:09:25.680 --> 00:09:27.510
the internal
representation, right?

00:09:27.510 --> 00:09:30.360
Not with huge
computational precision,

00:09:30.360 --> 00:09:33.295
they're more like with
gisty kind of ideas.

00:09:33.295 --> 00:09:34.920
They're not very
invariant, they depend

00:09:34.920 --> 00:09:36.030
on the orientation, right?

00:09:36.030 --> 00:09:38.340
That's not very precise,
but it's a whole lot better

00:09:38.340 --> 00:09:41.280
than nothing.

00:09:41.280 --> 00:09:44.280
That's what I mean by
at least qualitatively.

00:09:44.280 --> 00:09:46.890
They're good for disassociating
mental phenomena.

00:09:46.890 --> 00:09:50.040
So you've already seen that
when the inversion effect,

00:09:50.040 --> 00:09:52.210
it happens more for
faces than other things.

00:09:52.210 --> 00:09:54.853
So that already starts
to tell us, OK, maybe

00:09:54.853 --> 00:09:56.520
whatever the code in
our head is that we

00:09:56.520 --> 00:09:58.260
use for face
recognition, maybe it's

00:09:58.260 --> 00:10:00.990
pretty different than the
code that we use in our head

00:10:00.990 --> 00:10:01.950
to recognize objects.

00:10:05.610 --> 00:10:07.560
OK, it's also cheap.

00:10:07.560 --> 00:10:08.640
It's really cheap.

00:10:08.640 --> 00:10:11.650
Much cheaper than all
the other methods.

00:10:11.650 --> 00:10:15.310
OK, weaknesses--
behavioral methods

00:10:15.310 --> 00:10:17.860
alone don't have any
relationship to the brain,

00:10:17.860 --> 00:10:20.690
at least without
doing extra work.

00:10:20.690 --> 00:10:24.370
And it's not that they're
useless until you link them

00:10:24.370 --> 00:10:26.080
to the, brain it's
just that the brain is

00:10:26.080 --> 00:10:27.370
a whole source of other data.

00:10:27.370 --> 00:10:29.230
And it's nice to link
them, because then you

00:10:29.230 --> 00:10:33.040
can connect with all
those other data.

00:10:33.040 --> 00:10:35.530
Also, behavioral data
are pretty sparse.

00:10:35.530 --> 00:10:38.830
For the most part, you have
accuracy and reaction time,

00:10:38.830 --> 00:10:40.010
and that's it.

00:10:40.010 --> 00:10:42.670
And that's just not a whole
lot of data to work with.

00:10:42.670 --> 00:10:44.440
You have to actually
be much smarter

00:10:44.440 --> 00:10:47.300
to be a behavioral
cognitive psychologist,

00:10:47.300 --> 00:10:51.070
than you have to be a
cognitive neuroscientist,

00:10:51.070 --> 00:10:53.410
where you have much richer
data to reason from.

00:10:53.410 --> 00:10:57.130
Cognitive psychologists really
have very, very clever designs

00:10:57.130 --> 00:11:00.040
because they're taking
this extremely limited data

00:11:00.040 --> 00:11:02.890
and trying to pull out
interesting insights

00:11:02.890 --> 00:11:04.820
about mental function.

00:11:04.820 --> 00:11:07.240
Another way of
looking at that is,

00:11:07.240 --> 00:11:10.840
here's an eyeball and a bunch
of processing going over stages

00:11:10.840 --> 00:11:12.850
and a response, right?

00:11:12.850 --> 00:11:16.360
With behavioral data, all
you have is that response.

00:11:16.360 --> 00:11:19.425
But presumably, for most of
the mental processes that

00:11:19.425 --> 00:11:21.550
go on in our heads, there
are many different stages

00:11:21.550 --> 00:11:23.860
of processing where different
things are going on.

00:11:23.860 --> 00:11:26.110
Computations tend to
have multiple stages

00:11:26.110 --> 00:11:27.520
and unfold over time.

00:11:27.520 --> 00:11:30.650
And all we have is the output.

00:11:30.650 --> 00:11:33.040
So really, what we
want to be able to do

00:11:33.040 --> 00:11:36.010
is characterize the whole
sequence of processes.

00:11:36.010 --> 00:11:37.995
And it's not that you
can't get insights

00:11:37.995 --> 00:11:39.370
about some of
those intermediates

00:11:39.370 --> 00:11:42.590
from behavioral data, it's
just much more challenging.

00:11:42.590 --> 00:11:45.610
So if we had a way to look at
those things independently,

00:11:45.610 --> 00:11:49.200
wouldn't that be awesome?

00:11:49.200 --> 00:11:51.570
OK, so there's lots
of ways to do that.

00:11:51.570 --> 00:11:54.160
And a particularly good
one is functional MRI.

00:11:54.160 --> 00:11:55.980
So as I mentioned before--

00:11:55.980 --> 00:11:59.400
I mentioned this very briefly--

00:11:59.400 --> 00:12:03.510
this very early experiment
that I did way back asking

00:12:03.510 --> 00:12:05.970
whether there is a region of
the brain that's selectively

00:12:05.970 --> 00:12:08.183
involved in processing faces.

00:12:08.183 --> 00:12:10.350
And I'm going to put a
slightly different spin on it

00:12:10.350 --> 00:12:11.308
from what I put before.

00:12:11.308 --> 00:12:12.820
It's the same
experiment, same data,

00:12:12.820 --> 00:12:15.930
but I want to emphasize
more the logic

00:12:15.930 --> 00:12:18.030
of the experimental design
because you guys will

00:12:18.030 --> 00:12:23.970
be designing an experiment on
a different topic due Monday

00:12:23.970 --> 00:12:24.900
night.

00:12:24.900 --> 00:12:27.780
That we're going to discuss
Sunday night-- that we're going

00:12:27.780 --> 00:12:30.240
to discuss in class on Monday.

00:12:30.240 --> 00:12:34.140
So we start with a
hypothesis that there's

00:12:34.140 --> 00:12:36.600
a region of the brain
that's selectively

00:12:36.600 --> 00:12:37.560
responsive to faces.

00:12:37.560 --> 00:12:38.940
That's the hypothesis.

00:12:38.940 --> 00:12:42.270
The way we test it is to
pop people in a scanner

00:12:42.270 --> 00:12:44.140
and show them faces and objects.

00:12:44.140 --> 00:12:45.660
The data that I
showed you before

00:12:45.660 --> 00:12:47.550
is that this little
patch of the brain--

00:12:47.550 --> 00:12:49.980
remember, this is a horizontal
slice, back of the head,

00:12:49.980 --> 00:12:51.370
left and right are flipped.

00:12:51.370 --> 00:12:54.240
So that little region in
me is right about in there.

00:12:54.240 --> 00:12:55.590
Everybody oriented?

00:12:55.590 --> 00:12:56.730
OK.

00:12:56.730 --> 00:13:00.720
That region responds much
more to faces than objects.

00:13:00.720 --> 00:13:02.460
Is that clear to
everybody what that is?

00:13:02.460 --> 00:13:03.510
OK.

00:13:03.510 --> 00:13:07.470
So yes, you see that
in most subjects.

00:13:07.470 --> 00:13:09.780
So yes, there's a bit that
responds more to faces

00:13:09.780 --> 00:13:11.520
than objects.

00:13:11.520 --> 00:13:14.040
But now, let's
consider the hypothesis

00:13:14.040 --> 00:13:17.400
that that region is really
selective to faces per se.

00:13:17.400 --> 00:13:20.550
And the way you evaluate
whether these data,

00:13:20.550 --> 00:13:23.308
how strongly these data
support that hypothesis--

00:13:23.308 --> 00:13:24.850
they're certainly
consistent with it,

00:13:24.850 --> 00:13:27.660
but do they nail that
hypothesis fully--

00:13:27.660 --> 00:13:30.870
is to consider, are there
any other alternative

00:13:30.870 --> 00:13:34.200
accounts we can think of that
are consistent with these data

00:13:34.200 --> 00:13:36.600
and different from
that hypothesis?

00:13:36.600 --> 00:13:37.650
Is that clear?

00:13:37.650 --> 00:13:38.580
It's really important.

00:13:38.580 --> 00:13:42.600
That's just the whole kernel
of scientific thinking

00:13:42.600 --> 00:13:45.420
and evaluating evidence is
asking yourself that question.

00:13:45.420 --> 00:13:48.090
Is there any other way we
could get those data where

00:13:48.090 --> 00:13:50.130
that hypothesis wasn't true?

00:13:50.130 --> 00:13:52.540
And if so, you've got
to grapple with it.

00:13:52.540 --> 00:13:57.000
So what you do next is you
think up alternative hypotheses

00:13:57.000 --> 00:13:59.220
to the one you
started with, that

00:13:59.220 --> 00:14:01.690
is different accounts
of the same data.

00:14:01.690 --> 00:14:04.560
And so in our case, you guys
suggested a whole bunch,

00:14:04.560 --> 00:14:06.120
I suggested a bunch.

00:14:06.120 --> 00:14:08.130
And then the next
thing I showed you

00:14:08.130 --> 00:14:10.740
is that we can test those
alternative hypotheses,

00:14:10.740 --> 00:14:15.022
at least these ones
here, by first--

00:14:15.022 --> 00:14:16.980
what we did was, I didn't
really emphasize this

00:14:16.980 --> 00:14:19.380
before-- but we
reran that experiment

00:14:19.380 --> 00:14:22.380
in a new bunch of subjects,
each subject individually.

00:14:22.380 --> 00:14:25.900
We found in each subject the
little bit that does this.

00:14:25.900 --> 00:14:30.090
We write down exactly where
that is in that person's brain.

00:14:30.090 --> 00:14:32.730
Now that we found that region--
that's called a localizer

00:14:32.730 --> 00:14:35.070
run, because we're finding
that region in each subject

00:14:35.070 --> 00:14:39.060
individually-- now we
can ask it new questions.

00:14:39.060 --> 00:14:41.940
And so the new questions
we asked it last time

00:14:41.940 --> 00:14:44.280
was to present faces and hands.

00:14:44.280 --> 00:14:48.970
And we found, oh, that region
right there responds like this.

00:14:48.970 --> 00:14:52.810
So the key ideas here
is that we can identify

00:14:52.810 --> 00:14:54.670
that region in each
subject individually

00:14:54.670 --> 00:14:56.210
with a functional scan.

00:14:56.210 --> 00:14:58.840
The reason that's important--
which I'll carry on about

00:14:58.840 --> 00:15:00.220
in more detail later--

00:15:00.220 --> 00:15:03.670
is that the exact location of
that region varies from one

00:15:03.670 --> 00:15:05.470
subject to the next.

00:15:05.470 --> 00:15:08.350
So if we just grab
the whole fusiform

00:15:08.350 --> 00:15:11.410
gyrus or the whole lateral
side of the fusiform

00:15:11.410 --> 00:15:14.560
gyrus in each subject,
we'll get lots of stuff

00:15:14.560 --> 00:15:16.930
that is that region and
lots of cortical neighbors

00:15:16.930 --> 00:15:19.120
that's something else.

00:15:19.120 --> 00:15:22.240
And if we took
the exact location

00:15:22.240 --> 00:15:24.280
of that region in my
brain and registered it

00:15:24.280 --> 00:15:25.780
to any of your
brains and said, OK,

00:15:25.780 --> 00:15:27.155
let's take the
part of your brain

00:15:27.155 --> 00:15:29.890
that registers spatially as
well as we can with mine,

00:15:29.890 --> 00:15:32.720
we're not going to
exactly get the right bit.

00:15:32.720 --> 00:15:34.540
So to study that
thing, we've got

00:15:34.540 --> 00:15:36.040
to first find it functionally.

00:15:36.040 --> 00:15:38.390
And then we can ask
it new questions.

00:15:38.390 --> 00:15:40.250
Does that make sense?

00:15:40.250 --> 00:15:41.860
OK, if anybody's
unclear about that,

00:15:41.860 --> 00:15:43.720
I have actually
online talks that

00:15:43.720 --> 00:15:45.970
go through the whole logic
of this in painful detail.

00:15:45.970 --> 00:15:49.210
And I'm happy to answer other
questions about it later.

00:15:49.210 --> 00:15:52.600
OK, so I put the word
conditions in red

00:15:52.600 --> 00:15:55.900
because somebody asked one of
the TAs what a condition was.

00:15:55.900 --> 00:15:59.060
And that's not stupid, I
should have made that clear.

00:15:59.060 --> 00:16:04.630
This is just experimental design
gobbledygook that means any--

00:16:07.330 --> 00:16:09.100
OK, what is the
definition of condition?

00:16:09.100 --> 00:16:11.560
In an experimental
design, you have

00:16:11.560 --> 00:16:14.950
things that you are
manipulating and measuring.

00:16:14.950 --> 00:16:18.040
So in this case, we're
manipulating the stimulus.

00:16:18.040 --> 00:16:20.350
And we're measuring the
magnitude of response

00:16:20.350 --> 00:16:24.860
in the fusiform face
area or in the brain.

00:16:24.860 --> 00:16:26.830
So what we're
manipulating, in this case,

00:16:26.830 --> 00:16:28.990
is the stimulus condition.

00:16:28.990 --> 00:16:30.610
So that would be one
condition, that's

00:16:30.610 --> 00:16:33.070
another condition,
that's another condition.

00:16:33.070 --> 00:16:34.580
Does that make sense?

00:16:34.580 --> 00:16:39.370
OK, so for your experimental
design assignment for Monday

00:16:39.370 --> 00:16:43.300
night, you will be designing
one or more experiments.

00:16:43.300 --> 00:16:46.000
And you will be describing
exactly what conditions you are

00:16:46.000 --> 00:16:47.260
going to test.

00:16:47.260 --> 00:16:48.670
Everybody clear on that?

00:16:48.670 --> 00:16:50.110
OK.

00:16:50.110 --> 00:16:53.020
All right, so these
data enable us

00:16:53.020 --> 00:16:55.720
to rule out those hypotheses.

00:16:55.720 --> 00:16:58.780
And now what you could
ask, OK, once you

00:16:58.780 --> 00:17:00.790
get more data like this,
have you completely

00:17:00.790 --> 00:17:02.080
nailed that hypothesis?

00:17:02.080 --> 00:17:04.720
Is there just no way that
hypothesis could be wrong now

00:17:04.720 --> 00:17:06.640
given these data and those data?

00:17:06.640 --> 00:17:08.349
And I'll let you
percolate on that.

00:17:08.349 --> 00:17:10.329
There are ways it
could be wrong,

00:17:10.329 --> 00:17:12.790
but you have to work harder
to come up with them.

00:17:15.430 --> 00:17:19.900
OK, so skipping ahead,
just to give you the gist.

00:17:19.900 --> 00:17:22.810
This field has been
going on for a long time.

00:17:22.810 --> 00:17:24.700
And there are now
many, many studies--

00:17:24.700 --> 00:17:28.240
100 maybe even, I don't know,
God, maybe even thousands,

00:17:28.240 --> 00:17:32.230
I don't know-- studies
of this region in which--

00:17:32.230 --> 00:17:35.140
and so this is sort of a summary
statement from a long time ago.

00:17:35.140 --> 00:17:37.630
In my lab, we've tested
the response of this region

00:17:37.630 --> 00:17:39.670
to lots of different
kinds of stimuli.

00:17:39.670 --> 00:17:41.770
With that same
method, localize it

00:17:41.770 --> 00:17:44.350
in each subject, measure
its response when people

00:17:44.350 --> 00:17:47.500
look at that kind of stimulus,

00:17:47.500 --> 00:17:49.780
And so what we know now
was that this region

00:17:49.780 --> 00:17:53.560
is found in roughly the
same location in pretty

00:17:53.560 --> 00:17:55.360
much every normal subject.

00:17:55.360 --> 00:17:58.510
It responds more to faces than
to any other kind of stimuli

00:17:58.510 --> 00:18:00.520
anyone has ever tested.

00:18:00.520 --> 00:18:03.020
Let me just give you
one example here.

00:18:03.020 --> 00:18:05.208
If you haven't seen
this stimulus before,

00:18:05.208 --> 00:18:07.000
raise your hand if you
can tell what it is.

00:18:10.525 --> 00:18:12.400
Raise your hand if you
can tell what that is.

00:18:14.970 --> 00:18:16.860
OK, some of you didn't
quite get it yet.

00:18:16.860 --> 00:18:17.890
If you don't see
it, don't worry.

00:18:17.890 --> 00:18:18.660
There's nothing wrong with you.

00:18:18.660 --> 00:18:19.830
It's a little subtle.

00:18:19.830 --> 00:18:22.590
It's a face in profile,
eyes, nose, mouth.

00:18:22.590 --> 00:18:24.240
Everyone got it?

00:18:24.240 --> 00:18:25.350
OK, so here's the thing.

00:18:25.350 --> 00:18:28.200
That's the same stimulus,
it's just upside down.

00:18:28.200 --> 00:18:30.420
Another version of the
face inversion effect.

00:18:30.420 --> 00:18:33.630
In this case, you can't even
make yourself see the face

00:18:33.630 --> 00:18:34.890
when it's upside down.

00:18:34.890 --> 00:18:37.505
If you think you see the upside
down version of the face,

00:18:37.505 --> 00:18:38.880
you probably have
the wrong bits.

00:18:38.880 --> 00:18:41.340
The thing you think is a nose
probably isn't, et cetera.

00:18:41.340 --> 00:18:44.070
OK, so this is an extreme
version of the face inversion

00:18:44.070 --> 00:18:44.700
effect.

00:18:44.700 --> 00:18:47.940
And it's a gift to an
experimental psychologist.

00:18:47.940 --> 00:18:49.680
Why is that such a gift?

00:18:49.680 --> 00:18:51.780
Because it's the
same damn stimulus.

00:18:51.780 --> 00:18:54.690
But in one case you see a face,
in another case you don't.

00:18:54.690 --> 00:18:56.670
All we did was tip
it upside down.

00:18:56.670 --> 00:19:00.090
And the response of the fusiform
face area is much stronger

00:19:00.090 --> 00:19:02.610
to the upright version
when you see the face than

00:19:02.610 --> 00:19:05.170
to the inverted
version when you don't.

00:19:05.170 --> 00:19:09.480
So that enables us to stifle
a whole line of attack

00:19:09.480 --> 00:19:12.330
from all of these hard
core vision people who

00:19:12.330 --> 00:19:14.790
early on said,
Kanwisher, your face area

00:19:14.790 --> 00:19:16.350
isn't really
selective for faces.

00:19:16.350 --> 00:19:20.790
It's selective for these
spatial frequencies or those,

00:19:20.790 --> 00:19:23.370
that kind of contrast, or this
kind of shading information.

00:19:23.370 --> 00:19:25.170
It's like, no, same stimulus.

00:19:25.170 --> 00:19:26.087
It's just upside down.

00:19:26.087 --> 00:19:27.253
It makes all the difference.

00:19:27.253 --> 00:19:29.100
It's really whether
you see a face or not.

00:19:29.100 --> 00:19:29.370
Yeah?

00:19:29.370 --> 00:19:30.745
AUDIENCE: When
you were measuring

00:19:30.745 --> 00:19:34.380
the response of
that example, did

00:19:34.380 --> 00:19:37.260
you have it so that at first,
when people that the first time

00:19:37.260 --> 00:19:39.702
didn't recognize it
and then you told them?

00:19:39.702 --> 00:19:41.160
NANCY KANWISHER:
We did that later.

00:19:41.160 --> 00:19:43.350
Not in this experiment,
but we did that later.

00:19:43.350 --> 00:19:46.830
AUDIENCE: Are they looked see
like what changed [INAUDIBLE]??

00:19:46.830 --> 00:19:49.110
NANCY KANWISHER: OK, so
it's a great question.

00:19:49.110 --> 00:19:50.400
And there's a lot you
could do with that.

00:19:50.400 --> 00:19:52.170
And actually, I think
other people have published

00:19:52.170 --> 00:19:53.310
studies like that since.

00:19:53.310 --> 00:19:56.890
I can't quite remember
who all has done it.

00:19:56.890 --> 00:19:59.040
But what we did was
most of our subjects,

00:19:59.040 --> 00:20:01.110
especially in the context
of a whole experiment,

00:20:01.110 --> 00:20:04.230
we chose stimuli so that most
people could see the face

00:20:04.230 --> 00:20:07.380
in most of the upright stimuli
and most people could not

00:20:07.380 --> 00:20:09.780
see the face in most of
the inverted stimuli.

00:20:09.780 --> 00:20:11.370
It wasn't perfect at all.

00:20:11.370 --> 00:20:13.650
They didn't see faces in
all of the upright ones

00:20:13.650 --> 00:20:16.530
and they didn't fail to see them
in all of the inverted ones.

00:20:16.530 --> 00:20:18.960
And that's probably why
this difference in response

00:20:18.960 --> 00:20:22.122
is not 2 to 1, but it's close.

00:20:22.122 --> 00:20:24.330
But you could do lots of
other experiments like that,

00:20:24.330 --> 00:20:25.950
and you should think about
what kinds of designs

00:20:25.950 --> 00:20:27.990
would be good ones to
do and what it would

00:20:27.990 --> 00:20:29.235
enable you to test exactly.

00:20:31.740 --> 00:20:33.690
All right.

00:20:33.690 --> 00:20:36.762
So OK, I'm, as usual taking
too long to do things

00:20:36.762 --> 00:20:38.970
so I'm just going to throw
out some questions for you

00:20:38.970 --> 00:20:41.095
to percolate on and we will
come back to them later

00:20:41.095 --> 00:20:42.570
in the course.

00:20:42.570 --> 00:20:45.840
Do these data-- the fact that
you can see this so robustly

00:20:45.840 --> 00:20:48.120
in all subjects and that
all this evidence suggests

00:20:48.120 --> 00:20:50.550
it's really very
selective for faces--

00:20:50.550 --> 00:20:55.040
does that tell us that
this region is innate?

00:20:55.040 --> 00:20:58.700
It's in the same place, more or
less, in pretty much everyone.

00:20:58.700 --> 00:21:00.380
Does that mean it's innate?

00:21:00.380 --> 00:21:01.880
Think about it, OK?

00:21:01.880 --> 00:21:04.590
It's not immediately obvious.

00:21:04.590 --> 00:21:08.720
Another question, does the fact
that this thing responds so

00:21:08.720 --> 00:21:12.530
selectively to faces
in pretty much everyone

00:21:12.530 --> 00:21:14.900
mean that it's necessary
for face recognition?

00:21:17.503 --> 00:21:18.920
What do you guys
think about that?

00:21:23.800 --> 00:21:26.440
In the sense of,
does that necessarily

00:21:26.440 --> 00:21:28.060
mean that if you
lost that thing,

00:21:28.060 --> 00:21:30.410
you wouldn't be able
to recognize faces?

00:21:30.410 --> 00:21:30.910
Isabelle.

00:21:30.910 --> 00:21:31.920
Is that Isabelle?

00:21:31.920 --> 00:21:32.560
AUDIENCE: Yes.

00:21:32.560 --> 00:21:35.750
Well, I would think to
really test that hypothesis,

00:21:35.750 --> 00:21:38.214
you'd have to find
someone that [INAUDIBLE]

00:21:38.214 --> 00:21:40.110
in that specific area.

00:21:40.110 --> 00:21:41.370
NANCY KANWISHER: Exactly.

00:21:41.370 --> 00:21:42.560
Exactly.

00:21:42.560 --> 00:21:45.040
Exactly, and we'll talk
more about that in a moment.

00:21:45.040 --> 00:21:48.638
The critical thing is that it's
fabulous and powerful and cool

00:21:48.638 --> 00:21:50.430
to be able to find this
thing in everybody,

00:21:50.430 --> 00:21:51.570
measure its response.

00:21:51.570 --> 00:21:53.040
It's taken us very far.

00:21:53.040 --> 00:21:55.650
But just the fact that
people have that thing

00:21:55.650 --> 00:21:57.930
doesn't tell us that you
need it for face recognition.

00:21:57.930 --> 00:22:01.968
It just tells you it turns
on when you recognize faces.

00:22:01.968 --> 00:22:03.010
This is really important.

00:22:03.010 --> 00:22:06.900
We'll keep coming
around to this.

00:22:06.900 --> 00:22:09.180
Does this tell us how
face recognition actually

00:22:09.180 --> 00:22:11.670
works in the human brain?

00:22:11.670 --> 00:22:13.080
No.

00:22:13.080 --> 00:22:16.172
I mean, it's important,
but it's barely step zero.

00:22:16.172 --> 00:22:17.880
Unfortunately, the
field is kind of still

00:22:17.880 --> 00:22:20.820
at step zero for most things.

00:22:20.820 --> 00:22:23.190
Step zero's better than
I guess, I don't know,

00:22:23.190 --> 00:22:25.080
maybe I should call it step one.

00:22:25.080 --> 00:22:28.470
Anyway, it's something, but
doesn't tell us how it works.

00:22:28.470 --> 00:22:30.390
OK.

00:22:30.390 --> 00:22:32.730
All right, so advantages
and disadvantages

00:22:32.730 --> 00:22:33.720
of functional MRI.

00:22:33.720 --> 00:22:35.820
Advantages, it
is, as I mentioned

00:22:35.820 --> 00:22:37.620
last time, the best
spatial resolution

00:22:37.620 --> 00:22:40.080
available for studies
on normal subjects

00:22:40.080 --> 00:22:43.590
without opening their heads.

00:22:43.590 --> 00:22:45.780
That's what it means
to say noninvasive.

00:22:45.780 --> 00:22:48.990
Disadvantages, as
I just said, we

00:22:48.990 --> 00:22:51.660
don't know-- just because we see
a response there doesn't mean

00:22:51.660 --> 00:22:54.210
that that region is causally
involved in perception

00:22:54.210 --> 00:22:58.260
or cognition or experience.

00:22:58.260 --> 00:23:01.590
We don't know exactly what
is going on at a neural level

00:23:01.590 --> 00:23:04.530
underlying that bold response,
that blood flow change.

00:23:04.530 --> 00:23:07.560
It could be any metabolic
change, not necessarily

00:23:07.560 --> 00:23:09.332
neuronal spiking.

00:23:09.332 --> 00:23:11.040
So it's a little bit--
it's very indirect

00:23:11.040 --> 00:23:13.200
and a little imprecise.

00:23:13.200 --> 00:23:14.610
Spatial resolution
is much better

00:23:14.610 --> 00:23:17.640
than anything else in humans,
but it's appallingly bad

00:23:17.640 --> 00:23:21.090
compared to anything that people
who work on animals can do

00:23:21.090 --> 00:23:23.670
or they routinely record
from individual neurons

00:23:23.670 --> 00:23:27.790
or even dendrites on a neuron.

00:23:27.790 --> 00:23:30.630
We are summing over
hundreds of thousands

00:23:30.630 --> 00:23:33.120
of neurons in each
pixel or voxel

00:23:33.120 --> 00:23:35.670
that we measure
with functional MRI.

00:23:35.670 --> 00:23:37.387
It's very expensive.

00:23:37.387 --> 00:23:39.720
It's a little cheaper than
that here, but in most places

00:23:39.720 --> 00:23:41.610
it's more than $600 an hour.

00:23:41.610 --> 00:23:44.010
That is a lot.

00:23:44.010 --> 00:23:46.620
There are other-- there are
parts of the brain where

00:23:46.620 --> 00:23:48.240
it's really hard
to get any signal

00:23:48.240 --> 00:23:49.960
for various physics-y reasons.

00:23:52.710 --> 00:23:55.650
And it makes a loud noise,
which is not always a problem,

00:23:55.650 --> 00:23:58.770
but it's a problem for some
things like scanning infants

00:23:58.770 --> 00:24:03.180
or like doing
auditory experiments.

00:24:03.180 --> 00:24:07.230
The temporal resolution is
not even close to the time

00:24:07.230 --> 00:24:09.300
scale on which vision happens.

00:24:09.300 --> 00:24:15.010
So vision is really fast and
functional MRI is really slow.

00:24:15.010 --> 00:24:15.510
Right?

00:24:15.510 --> 00:24:17.100
It's slow, why is it slow?

00:24:20.210 --> 00:24:20.930
Yeah.

00:24:20.930 --> 00:24:22.460
AUDIENCE: Blood levels
take time to change.

00:24:22.460 --> 00:24:23.377
NANCY KANWISHER: Yeah.

00:24:23.377 --> 00:24:25.430
Just takes a long
time for blood flow

00:24:25.430 --> 00:24:28.760
to change after the
increase in neural activity.

00:24:28.760 --> 00:24:30.200
All right.

00:24:30.200 --> 00:24:32.360
OK, so back to our
questions that we're

00:24:32.360 --> 00:24:34.010
asking about face perception.

00:24:34.010 --> 00:24:36.050
Where do we get
with functional MRI?

00:24:36.050 --> 00:24:38.450
Well, actually from both
behavior and functional MRI,

00:24:38.450 --> 00:24:40.760
it kind of looks like we
have a distinct system

00:24:40.760 --> 00:24:44.690
for recognizing faces than for
recognizing everything else.

00:24:44.690 --> 00:24:46.310
I don't think we've
totally nailed it.

00:24:46.310 --> 00:24:46.970
Yes.

00:24:46.970 --> 00:24:48.980
AUDIENCE: So quick question
regarding the fMRI.

00:24:48.980 --> 00:24:52.940
So the resolution is field
of a couple of seconds?

00:24:52.940 --> 00:24:53.630
[INAUDIBLE]?

00:24:53.630 --> 00:24:54.560
NANCY KANWISHER:
Yeah, some people

00:24:54.560 --> 00:24:56.685
would say you could get it
down to a couple hundred

00:24:56.685 --> 00:24:59.030
milliseconds but that's debated.

00:24:59.030 --> 00:25:00.950
You have to go to great
lengths to do that.

00:25:00.950 --> 00:25:03.856
Normal functional MRI, a
couple of seconds at best.

00:25:03.856 --> 00:25:04.356
Yeah.

00:25:08.820 --> 00:25:10.080
All right.

00:25:10.080 --> 00:25:12.460
So let's consider
this next question.

00:25:12.460 --> 00:25:15.270
How fast does face
recognition happen?

00:25:15.270 --> 00:25:18.120
Now, that may seem like a
completely arbitrary question

00:25:18.120 --> 00:25:19.410
to ask, but it's not.

00:25:19.410 --> 00:25:20.910
Remember, we're
trying to understand

00:25:20.910 --> 00:25:22.827
the computations that
are running in your head

00:25:22.827 --> 00:25:24.600
when you recognize faces.

00:25:24.600 --> 00:25:26.940
And you might imagine
some computations

00:25:26.940 --> 00:25:31.140
that are iterative-- that
involve multiple repeated

00:25:31.140 --> 00:25:34.170
testing of hypotheses,
generative models, whatever--

00:25:34.170 --> 00:25:37.980
things that involve lots of
iterated feedback versus things

00:25:37.980 --> 00:25:40.200
where you just have a
feed forward sweep up

00:25:40.200 --> 00:25:41.140
the visual system.

00:25:41.140 --> 00:25:43.260
And so there might be
very different time scales

00:25:43.260 --> 00:25:48.100
for those different kinds
of mental processes.

00:25:48.100 --> 00:25:49.373
So we just went through this.

00:25:49.373 --> 00:25:51.540
Functional MRI is not going
to answer this question.

00:25:51.540 --> 00:25:52.590
It's just not.

00:25:52.590 --> 00:25:53.940
It's a bummer, but that's life.

00:25:53.940 --> 00:25:55.523
We're adults, we're
going to just move

00:25:55.523 --> 00:25:57.277
on and use a different method.

00:25:57.277 --> 00:25:59.110
OK, so there's a bunch
of different methods.

00:25:59.110 --> 00:26:01.680
One is kind of been
around forever.

00:26:01.680 --> 00:26:04.830
You glue electrodes
on the head, right?

00:26:04.830 --> 00:26:06.210
Sometimes you push
the hair apart

00:26:06.210 --> 00:26:10.320
or try to find bald people and
glue electrodes right on there.

00:26:10.320 --> 00:26:13.500
And you can use, in the old
days, about 10 electrodes,

00:26:13.500 --> 00:26:16.020
or you can use in
more modern devices

00:26:16.020 --> 00:26:19.980
these nets with a few
hundred electrodes

00:26:19.980 --> 00:26:21.630
that you settle onto the head.

00:26:21.630 --> 00:26:25.170
And so then you just measure
directly electrical potentials

00:26:25.170 --> 00:26:27.360
right on the scalp.

00:26:27.360 --> 00:26:30.960
So what's cool about that is
it's totally non-invasive.

00:26:30.960 --> 00:26:33.780
And it gives you a beautiful
online temporal measure

00:26:33.780 --> 00:26:36.000
of underlying neural activity.

00:26:36.000 --> 00:26:39.780
What's not so cool about it is
that electrical potentials blur

00:26:39.780 --> 00:26:41.940
all over the scalp and
the spatial resolution

00:26:41.940 --> 00:26:44.520
is really awful.

00:26:44.520 --> 00:26:47.490
So the analogy has
been made that it

00:26:47.490 --> 00:26:49.470
would be like
sticking a microphone

00:26:49.470 --> 00:26:54.450
on the inside of the top
of a football stadium

00:26:54.450 --> 00:26:57.750
and collecting audio there.

00:26:57.750 --> 00:27:00.287
You would know when a
touchdown was scored.

00:27:00.287 --> 00:27:01.620
There's a lot of noise all over.

00:27:01.620 --> 00:27:04.245
It's like, OK, there's an event,
we detected that event, right?

00:27:04.245 --> 00:27:06.703
You might be able to tell a
touchdown from something else.

00:27:06.703 --> 00:27:09.120
I don't know about football
so I can't tell you what else.

00:27:09.120 --> 00:27:11.578
Anyway, something else, some
other event that could happen.

00:27:11.578 --> 00:27:18.210
OK, so that will be useful for
some things, but kind of crude.

00:27:18.210 --> 00:27:20.500
But you'd have a hell of a
time telling anything else,

00:27:20.500 --> 00:27:22.500
like what one person is
saying to another person

00:27:22.500 --> 00:27:24.780
in the bleachers.

00:27:24.780 --> 00:27:26.040
So that's the old analogy.

00:27:26.040 --> 00:27:30.850
This is changing slightly,
and we'll get to that later.

00:27:30.850 --> 00:27:32.610
But first, I want
to briefly mention

00:27:32.610 --> 00:27:34.837
one of the assigned
readings that I just

00:27:34.837 --> 00:27:36.670
hoped you guys could
figure out on your own.

00:27:36.670 --> 00:27:38.880
But just in case you
were confused about it,

00:27:38.880 --> 00:27:42.690
the point I wanted you to
get from the Thorpe reading

00:27:42.690 --> 00:27:46.950
is he's asking how quickly can
we tell if an image contains

00:27:46.950 --> 00:27:48.180
an animal or not?

00:27:48.180 --> 00:27:51.990
It's a kind of way to say, how
fast is object recognition?

00:27:51.990 --> 00:27:52.930
So what does he do?

00:27:52.930 --> 00:27:56.040
He has people look at a bunch
of images and they press this

00:27:56.040 --> 00:27:58.980
button if it has an animal
in this button if it doesn't.

00:27:58.980 --> 00:28:00.580
Really simple task.

00:28:00.580 --> 00:28:03.728
So first question is, why not
just use those reaction times?

00:28:03.728 --> 00:28:06.270
We can measure how fast it takes
for people to press a button

00:28:06.270 --> 00:28:07.920
after the image comes on.

00:28:07.920 --> 00:28:10.200
Why not just use that?

00:28:10.200 --> 00:28:12.960
Does that tell us how fast
object recognition occurs?

00:28:12.960 --> 00:28:14.400
Yeah, Jimmy.

00:28:14.400 --> 00:28:17.070
AUDIENCE: It doesn't because
if you perceive that and then

00:28:17.070 --> 00:28:18.695
it also activates
the motor neurons

00:28:18.695 --> 00:28:19.903
and it takes time to respond.

00:28:19.903 --> 00:28:22.528
NANCY KANWISHER: Yeah, you have
to take all that time to figure

00:28:22.528 --> 00:28:24.210
out, OK, I see the animal.

00:28:24.210 --> 00:28:25.530
OK, which button is that?

00:28:25.530 --> 00:28:27.102
And then which finger do I push?

00:28:27.102 --> 00:28:29.310
And then you've got to send
a signal all the way down

00:28:29.310 --> 00:28:31.727
here, conduction velocity all
the way down to your finger,

00:28:31.727 --> 00:28:32.800
that takes a long time.

00:28:32.800 --> 00:28:34.740
And so it includes
all that motor stuff

00:28:34.740 --> 00:28:36.450
in with the perceptual stuff.

00:28:36.450 --> 00:28:39.570
We could make some guesses
about how long that motor

00:28:39.570 --> 00:28:42.210
stuff takes, but it's
still not very precise.

00:28:42.210 --> 00:28:44.010
So the point of
the Thorpe paper is

00:28:44.010 --> 00:28:46.590
they're basically trying to
collect a reaction time out

00:28:46.590 --> 00:28:48.510
of the neurons in
the head, right?

00:28:48.510 --> 00:28:50.190
So they're trying to
actually collect--

00:28:50.190 --> 00:28:51.857
it's essentially what
they're collecting

00:28:51.857 --> 00:28:54.150
in this case is more
of the motor response

00:28:54.150 --> 00:28:56.590
because they're collecting
responses over frontal lobes,

00:28:56.590 --> 00:28:57.090
right?

00:28:57.090 --> 00:28:58.673
And we haven't talked
about this much.

00:28:58.673 --> 00:29:01.170
But all of the visual stuff
we've been talking about all

00:29:01.170 --> 00:29:03.960
happens in the back of the head.

00:29:03.960 --> 00:29:05.868
More motor planning
stuff mostly happens

00:29:05.868 --> 00:29:06.910
in the front of the head.

00:29:06.910 --> 00:29:09.270
And so they're collecting
responses out of here,

00:29:09.270 --> 00:29:12.030
averaging over a bunch
of frontal responses.

00:29:12.030 --> 00:29:14.070
And they see the average
response when there's

00:29:14.070 --> 00:29:16.140
an animal-- this is
just potential average

00:29:16.140 --> 00:29:19.320
over those frontal
electrodes-- is like this.

00:29:19.320 --> 00:29:21.760
And when there's no
animal it's like that.

00:29:21.760 --> 00:29:26.040
And so what does that tell
us about how fast people can

00:29:26.040 --> 00:29:28.980
distinguish whether an
image has an animal or not?

00:29:32.270 --> 00:29:33.020
Yes?

00:29:33.020 --> 00:29:33.670
Yeah.

00:29:33.670 --> 00:29:35.212
AUDIENCE: It's less
than that number.

00:29:35.212 --> 00:29:37.330
NANCY KANWISHER: Less than?

00:29:37.330 --> 00:29:39.020
AUDIENCE: 150, 160.

00:29:39.020 --> 00:29:41.680
NANCY KANWISHER: OK,
why less than 150?

00:29:41.680 --> 00:29:44.230
AUDIENCE: I've read the paper
so it's kind of cheating, so.

00:29:44.230 --> 00:29:44.930
NANCY KANWISHER: That's OK.

00:29:44.930 --> 00:29:45.760
That's good.

00:29:45.760 --> 00:29:46.360
That's fine.

00:29:46.360 --> 00:29:46.860
Go ahead.

00:29:49.530 --> 00:29:51.540
AUDIENCE: It gives you around--

00:29:51.540 --> 00:29:53.400
the 150 second is
giving you a [INAUDIBLE]

00:29:53.400 --> 00:29:56.700
saying some process
has been registered

00:29:56.700 --> 00:29:58.950
and now you're trying
to do something else

00:29:58.950 --> 00:30:00.272
in the case of non-animals.

00:30:00.272 --> 00:30:01.230
NANCY KANWISHER: Right.

00:30:01.230 --> 00:30:03.540
AUDIENCE: So the
deviation starts

00:30:03.540 --> 00:30:05.700
getting you that OK, two
different actions have

00:30:05.700 --> 00:30:06.630
started taking place.

00:30:06.630 --> 00:30:07.505
NANCY KANWISHER: Yep.

00:30:07.505 --> 00:30:09.150
AUDIENCE: So by
that time, the image

00:30:09.150 --> 00:30:11.280
ought to have been sort
of fully processed.

00:30:11.280 --> 00:30:13.533
So that should be something
less than that number.

00:30:13.533 --> 00:30:14.450
NANCY KANWISHER: Yeah.

00:30:14.450 --> 00:30:16.990
Yeah, did everybody get that?

00:30:16.990 --> 00:30:18.180
It's actually quite subtle.

00:30:18.180 --> 00:30:22.350
So the key thing
is, these curves

00:30:22.350 --> 00:30:24.420
diverge right there at 150.

00:30:24.420 --> 00:30:27.535
So that tells you that
by 150 milliseconds,

00:30:27.535 --> 00:30:29.910
something in your brain is
happening different if there's

00:30:29.910 --> 00:30:32.100
an animal and not an animal.

00:30:32.100 --> 00:30:33.360
That's the key question.

00:30:33.360 --> 00:30:35.040
But what is that something?

00:30:35.040 --> 00:30:38.340
It may be your motor
preparation of the response.

00:30:38.340 --> 00:30:40.188
In that case, the
actual visual part

00:30:40.188 --> 00:30:41.730
happened before,
because you wouldn't

00:30:41.730 --> 00:30:43.730
know which button to press
if you hadn't already

00:30:43.730 --> 00:30:45.120
recognized it.

00:30:45.120 --> 00:30:49.790
So it's an upper bound for
when that process happened,

00:30:49.790 --> 00:30:51.540
because maybe it
happened before and we're

00:30:51.540 --> 00:30:54.510
looking at a later stage, OK?

00:30:54.510 --> 00:30:56.850
Does that make sense?

00:30:56.850 --> 00:31:01.170
But also, it's an upper bound
for the beginning of that

00:31:01.170 --> 00:31:02.130
process.

00:31:02.130 --> 00:31:04.950
Because the fact that those
electrode responses have

00:31:04.950 --> 00:31:07.320
diverged doesn't mean
you've finished processing

00:31:07.320 --> 00:31:09.810
whether it's an animal or not.

00:31:09.810 --> 00:31:12.270
So it's kind of a subtle
business reasoning from this.

00:31:15.090 --> 00:31:18.840
OK, so that's all that.

00:31:18.840 --> 00:31:21.990
So that's a case with
detecting animals.

00:31:21.990 --> 00:31:26.220
What about faces, to get
back to our theme for today?

00:31:26.220 --> 00:31:29.550
Yes, you can learn about
the speed of face detection

00:31:29.550 --> 00:31:31.710
at least with the ERPs.

00:31:31.710 --> 00:31:35.010
And so here's the first paper
that did that back in 1996.

00:31:35.010 --> 00:31:37.690
They had electrodes
where are these?

00:31:37.690 --> 00:31:39.120
Just right around here and here.

00:31:39.120 --> 00:31:44.130
I actually have those electrode
locations tattooed on my scalp,

00:31:44.130 --> 00:31:45.420
color-coded anyway.

00:31:45.420 --> 00:31:46.085
Yes?

00:31:46.085 --> 00:31:48.505
AUDIENCE: Is ERP just
the same as an EEG, just

00:31:48.505 --> 00:31:49.380
in a specific plan e?

00:31:49.380 --> 00:31:52.520
NANCY KANWISHER: Yes, exactly.

00:31:52.520 --> 00:31:55.410
It's the same as an
EEG except what you do

00:31:55.410 --> 00:31:59.670
is you time lock the data
collection to stimulus onset.

00:31:59.670 --> 00:32:02.640
So it actually stands for
Event-Related Potential.

00:32:02.640 --> 00:32:04.140
And the reason
it's event-related

00:32:04.140 --> 00:32:06.510
is you collect all those
trials and you time

00:32:06.510 --> 00:32:10.363
lock to stimulus onset, and
then you signal average.

00:32:10.363 --> 00:32:12.030
I had a slide on that
but I took it out.

00:32:12.030 --> 00:32:12.863
It was too detailed.

00:32:12.863 --> 00:32:15.300
But that's exactly
the idea, yeah.

00:32:15.300 --> 00:32:18.930
So here, stimulus onset
is right around here.

00:32:18.930 --> 00:32:20.432
This is time going this way.

00:32:20.432 --> 00:32:22.140
And what you see--
it's hard to see here,

00:32:22.140 --> 00:32:23.640
but the faces are right there.

00:32:23.640 --> 00:32:27.000
And at 170 milliseconds
after stimulus onset,

00:32:27.000 --> 00:32:31.470
there's a bigger bump
for faces at an electrode

00:32:31.470 --> 00:32:33.330
approximately here.

00:32:33.330 --> 00:32:34.920
And even more so--

00:32:34.920 --> 00:32:38.340
actually, even more so over the
right hemisphere right there.

00:32:38.340 --> 00:32:41.880
Compared to cars and scrambled
faces and stuff like that.

00:32:41.880 --> 00:32:42.658
Yeah?

00:32:42.658 --> 00:32:44.325
AUDIENCE: What is ERP
exactly measuring?

00:32:44.325 --> 00:32:45.163
Is it just activity?

00:32:45.163 --> 00:32:46.080
NANCY KANWISHER: Yeah.

00:32:46.080 --> 00:32:50.970
So again, it's electrodes
glued on your scalp

00:32:50.970 --> 00:32:54.600
or just stuck there with
some kind of icky gel.

00:32:54.600 --> 00:32:56.640
And so they're just
measuring potentials.

00:32:56.640 --> 00:32:59.400
And so the idea is that's
neural activity somewhere

00:32:59.400 --> 00:33:04.440
underneath those electrodes, but
maybe anywhere within inches.

00:33:04.440 --> 00:33:07.200
Like a long-- probably average
is over much of the whole lobe

00:33:07.200 --> 00:33:07.740
underneath.

00:33:07.740 --> 00:33:09.870
So it's very spatially
blurry, but it's

00:33:09.870 --> 00:33:14.370
giving you summed idea of
activity under that electrode.

00:33:14.370 --> 00:33:15.390
Make sense?

00:33:15.390 --> 00:33:17.040
Electrical activity,
because it's

00:33:17.040 --> 00:33:19.980
the direct electrical
consequence of neural activity,

00:33:19.980 --> 00:33:24.870
it's very precisely time locked,
unlike functional MRI, which

00:33:24.870 --> 00:33:26.130
is going by way of blood flow.

00:33:28.770 --> 00:33:32.490
OK, so that tells us that we
have a face-specific response

00:33:32.490 --> 00:33:35.580
at 170 milliseconds.

00:33:35.580 --> 00:33:38.070
And that's sort of more
evidence that there

00:33:38.070 --> 00:33:40.680
might be something special in
the brain for face recognition.

00:33:40.680 --> 00:33:41.940
That's useful.

00:33:41.940 --> 00:33:46.530
It tells us that faces are
discriminated from non-faces,

00:33:46.530 --> 00:33:48.960
or they've begun
to be discriminated

00:33:48.960 --> 00:33:51.540
from non-faces by
170 milliseconds

00:33:51.540 --> 00:33:53.520
after the stimulus comes on.

00:33:53.520 --> 00:33:55.050
Make sense?

00:33:55.050 --> 00:33:58.230
OK, now do we know
whether the signals coming

00:33:58.230 --> 00:34:00.420
from the fusiform face area?

00:34:00.420 --> 00:34:02.460
No, we have no idea.

00:34:02.460 --> 00:34:04.500
It's probably somewhere
in the back of the head,

00:34:04.500 --> 00:34:05.820
because you get it
better with electrodes

00:34:05.820 --> 00:34:07.237
back here than
electrodes up here.

00:34:07.237 --> 00:34:08.170
But that's about it.

00:34:08.170 --> 00:34:11.460
That's all you can tell.

00:34:11.460 --> 00:34:14.190
So can we do a little
bit better localizing

00:34:14.190 --> 00:34:15.540
the source of that signal?

00:34:15.540 --> 00:34:18.960
Well, maybe a hair better
using a very similar method

00:34:18.960 --> 00:34:22.030
called magnetoencephalography.

00:34:22.030 --> 00:34:26.670
So this is a picture that
Chris Brewer took of Leyla Isik

00:34:26.670 --> 00:34:29.820
postdoc in my lab, and
me and the MEG system.

00:34:29.820 --> 00:34:32.730
This is in on the other
side of the building.

00:34:32.730 --> 00:34:37.380
So MEG is a lot
like EEG and ERPs

00:34:37.380 --> 00:34:41.520
except that it detects magnetic
fields, not electric fields.

00:34:41.520 --> 00:34:47.070
And it does this by having these
several hundred devices that

00:34:47.070 --> 00:34:48.690
are placed right
next to your head

00:34:48.690 --> 00:34:50.130
in this big hairdryer thing.

00:34:50.130 --> 00:34:53.159
There's 300 devices
in there that measure

00:34:53.159 --> 00:34:56.639
teeny tiny magnetic
field changes that

00:34:56.639 --> 00:34:58.780
happen with neural activity.

00:34:58.780 --> 00:35:02.460
And the crux of the idea
is this is a cross-section

00:35:02.460 --> 00:35:03.280
through the brain.

00:35:03.280 --> 00:35:07.860
So remember in Graybiel's
dissection, this is cortex here

00:35:07.860 --> 00:35:09.060
and this is underlying.

00:35:09.060 --> 00:35:13.040
What is this stuff
underneath it?

00:35:13.040 --> 00:35:13.942
Sorry?

00:35:13.942 --> 00:35:14.900
AUDIENCE: White matter.

00:35:14.900 --> 00:35:15.830
NANCY KANWISHER:
White matter, yeah.

00:35:15.830 --> 00:35:17.210
Well, those are all the fibers.

00:35:17.210 --> 00:35:21.340
OK, so the activity that
underlies perception

00:35:21.340 --> 00:35:23.840
and cognition mostly
happens in the gray matter

00:35:23.840 --> 00:35:26.010
where the cell bodies are.

00:35:26.010 --> 00:35:29.060
And so a lot of that
activity goes in a direction

00:35:29.060 --> 00:35:31.730
perpendicular to the
cortical orientation

00:35:31.730 --> 00:35:35.730
with these cells that cross
the cortical surface like that.

00:35:35.730 --> 00:35:38.960
So if you remember 8.02--

00:35:38.960 --> 00:35:40.340
if you have activity
that's going

00:35:40.340 --> 00:35:43.790
through the cortex like
this, right hand rule,

00:35:43.790 --> 00:35:46.940
the magnetic field
here is going to be

00:35:46.940 --> 00:35:50.480
a consequence of that electrical
activity in this direction.

00:35:50.480 --> 00:35:53.030
It's going to mostly
stay within the cortex.

00:35:53.030 --> 00:35:54.500
Everybody see how that's true?

00:35:54.500 --> 00:35:57.290
That's not so great, because
our detectors are out there,

00:35:57.290 --> 00:35:59.060
outside the cortex.

00:35:59.060 --> 00:36:02.570
However, consider the activity
that's in the sulcus in here,

00:36:02.570 --> 00:36:04.760
in this fold of the brain.

00:36:04.760 --> 00:36:07.970
Electrical activity in this
direction, right hand rule,

00:36:07.970 --> 00:36:09.830
will stick outside the brain.

00:36:09.830 --> 00:36:12.170
And we can detect it with
our magnetic sensors.

00:36:12.170 --> 00:36:13.980
Does that make sense?

00:36:13.980 --> 00:36:17.900
So you can sort of see
most cortical activity

00:36:17.900 --> 00:36:21.080
better if it's in a
sulcus, or at least in part

00:36:21.080 --> 00:36:23.750
of the cortical surface that's
perpendicular to the scalp

00:36:23.750 --> 00:36:26.600
where the detectors are just
because of the orientation

00:36:26.600 --> 00:36:28.310
in the right hand rule.

00:36:28.310 --> 00:36:35.540
OK, so it primarily sees
activity in the folds or sulci,

00:36:35.540 --> 00:36:39.440
not in the outer bumps gyri.

00:36:39.440 --> 00:36:42.650
Field strengths are
minuscule as a consequence

00:36:42.650 --> 00:36:43.920
of neural activity.

00:36:43.920 --> 00:36:48.470
So the fields we measure are
10 to the minus 13th Tesla,

00:36:48.470 --> 00:36:51.600
a million times weaker than
the Earth's magnetic field.

00:36:51.600 --> 00:36:55.190
So you can imagine that if
you set up an MEG system

00:36:55.190 --> 00:36:57.200
you need a lot of shielding.

00:36:57.200 --> 00:37:00.590
We had a whole rigmarole when
the MEG system was set up

00:37:00.590 --> 00:37:03.380
in this building because
it's right near the subway

00:37:03.380 --> 00:37:05.180
and the train.

00:37:05.180 --> 00:37:07.400
And so there are
many, many layers

00:37:07.400 --> 00:37:09.180
of copper shielding
to protect it.

00:37:09.180 --> 00:37:12.680
So we can detect these
teeny tiny magnetic fields

00:37:12.680 --> 00:37:15.700
from the brain's
activity separated

00:37:15.700 --> 00:37:17.450
from the noise of the
outside world, which

00:37:17.450 --> 00:37:20.000
is much greater in magnitude.

00:37:20.000 --> 00:37:22.610
OK, so-- all right.

00:37:22.610 --> 00:37:25.640
So actually, MEG was
invented here at MIT

00:37:25.640 --> 00:37:27.410
by this guy, David Cohen.

00:37:27.410 --> 00:37:31.880
And this is the first MEG
device ever built, very cool,

00:37:31.880 --> 00:37:36.230
way back in 1968.

00:37:36.230 --> 00:37:39.000
And what can it tell us
about face perception?

00:37:39.000 --> 00:37:39.680
Well, a lot.

00:37:39.680 --> 00:37:43.190
I'll give you just one
rudimentary example.

00:37:43.190 --> 00:37:46.670
That M170 that you can
detect with scalp electrodes,

00:37:46.670 --> 00:37:49.800
you can also detect with
magnetic sensors on the head.

00:37:49.800 --> 00:37:52.320
So here's some of our
data from a long time ago.

00:37:52.320 --> 00:37:55.400
This is the strength
of the magnetic field

00:37:55.400 --> 00:37:58.760
at sites right about out here.

00:37:58.760 --> 00:38:01.670
And you can see a
face-selective response also

00:38:01.670 --> 00:38:09.320
at 170 milliseconds, just like
you can with scalp electrodes.

00:38:09.320 --> 00:38:12.740
So that tells us
that at least you've

00:38:12.740 --> 00:38:15.710
started to detect faces
by 170 milliseconds.

00:38:15.710 --> 00:38:18.470
That's pretty fast.

00:38:18.470 --> 00:38:20.480
And again, it's more
evidence that there's

00:38:20.480 --> 00:38:21.710
specialized machinery.

00:38:21.710 --> 00:38:26.030
These data don't yet go beyond
the EEG data, the ERP data

00:38:26.030 --> 00:38:27.920
from electrical potentials.

00:38:27.920 --> 00:38:29.810
But they might, in
principle, and there's

00:38:29.810 --> 00:38:32.630
lots of ongoing work
trying to do that.

00:38:32.630 --> 00:38:36.290
OK, overview, advantages
of these methods,

00:38:36.290 --> 00:38:38.690
both EEG and MEG.

00:38:38.690 --> 00:38:40.310
They're non-invasive--
that means you

00:38:40.310 --> 00:38:41.477
don't need to open the head.

00:38:41.477 --> 00:38:44.840
A very good thing, especially
if you're the subject.

00:38:44.840 --> 00:38:46.920
They have very good
temporal resolution.

00:38:46.920 --> 00:38:48.470
And if we want to
see computations

00:38:48.470 --> 00:38:53.780
unfolding over time in the
brain, this is a good way.

00:38:53.780 --> 00:38:57.410
I just said why we'd
I care about that.

00:38:57.410 --> 00:39:01.658
OK, so far-- well, never mind,
I'm going to skip this point.

00:39:01.658 --> 00:39:02.450
Not that important.

00:39:02.450 --> 00:39:05.360
We will get back and do more
sophisticated things with EEG

00:39:05.360 --> 00:39:07.790
and MEG in subsequent lectures.

00:39:07.790 --> 00:39:11.780
Disadvantages-- spatial
resolution is terrible.

00:39:11.780 --> 00:39:14.700
And this is another kind
of ill-posed problem.

00:39:14.700 --> 00:39:16.490
So just as the
brain is facing lots

00:39:16.490 --> 00:39:20.060
of ill-posed problems in
perception and cognition,

00:39:20.060 --> 00:39:22.520
we scientists are facing
ill-posed problems

00:39:22.520 --> 00:39:26.390
when we collect electrical or
magnetic activity at the scalp

00:39:26.390 --> 00:39:28.730
and try to infer the exact
location in the brain

00:39:28.730 --> 00:39:30.560
where it's coming from.

00:39:30.560 --> 00:39:33.200
It's a similar problem to the
problem of invariant object

00:39:33.200 --> 00:39:34.140
recognition.

00:39:34.140 --> 00:39:36.380
There are many
possible configurations

00:39:36.380 --> 00:39:38.900
of sources in the brain
that could give rise

00:39:38.900 --> 00:39:41.570
to the same set of electrical
and magnetic fields out

00:39:41.570 --> 00:39:42.530
of the scalp.

00:39:42.530 --> 00:39:44.210
And that means it's ill-posed.

00:39:44.210 --> 00:39:47.210
We don't have a way to
get a unique solution.

00:39:47.210 --> 00:39:51.020
So all that to say we can't
figure out the exact sources.

00:39:51.020 --> 00:39:54.360
We can make some guesses,
but it's not very good.

00:39:54.360 --> 00:39:55.610
So what do we do?

00:39:55.610 --> 00:39:56.860
Just give up?

00:39:56.860 --> 00:40:00.300
No, we use another method.

00:40:00.300 --> 00:40:03.450
So here's an amazing method.

00:40:03.450 --> 00:40:06.230
This is the one
method in humans that

00:40:06.230 --> 00:40:10.200
gives us high resolution
in both space and time.

00:40:10.200 --> 00:40:12.740
And that's when we have
the very rare opportunity

00:40:12.740 --> 00:40:16.410
to record directly from
inside the human brain.

00:40:16.410 --> 00:40:20.480
This happens only in the
context of neurosurgery.

00:40:20.480 --> 00:40:25.010
So neurosurgical patients--
like this guy here,

00:40:25.010 --> 00:40:27.620
who you'll meet
in a little bit--

00:40:27.620 --> 00:40:30.740
this guy had
intractable epilepsy.

00:40:30.740 --> 00:40:32.570
And most people
with epilepsy are

00:40:32.570 --> 00:40:36.170
treated well by drugs
that suppress seizures.

00:40:36.170 --> 00:40:39.470
But some people are just
not responsive to drugs.

00:40:39.470 --> 00:40:41.090
And if the seizures
are bad enough,

00:40:41.090 --> 00:40:43.490
they can be totally
life disrupting.

00:40:43.490 --> 00:40:46.020
If they happen dozens
of times a day,

00:40:46.020 --> 00:40:47.450
you just can't
live a normal life.

00:40:47.450 --> 00:40:50.810
And under those rather
extreme circumstances,

00:40:50.810 --> 00:40:53.240
sometimes the best
option is neurosurgery.

00:40:53.240 --> 00:40:57.110
That is, trying to find the
source of those seizures

00:40:57.110 --> 00:40:59.060
and trying to remove
it surgically.

00:40:59.060 --> 00:41:02.090
OK, so you hope you never have
to go through this or anyone

00:41:02.090 --> 00:41:03.590
you care about has
to go through it.

00:41:03.590 --> 00:41:04.970
It's no picnic.

00:41:04.970 --> 00:41:06.920
But actually, this
surgical treatment

00:41:06.920 --> 00:41:10.460
is often very effective.

00:41:10.460 --> 00:41:13.550
So when neurosurgeons
decide to do this,

00:41:13.550 --> 00:41:17.150
they have to remove a
whole piece of skull bone

00:41:17.150 --> 00:41:19.050
to get access to the brain.

00:41:19.050 --> 00:41:20.660
They have to go
through what structure

00:41:20.660 --> 00:41:26.115
that Ann Graybiel showed you in
her dissection the other day.

00:41:26.115 --> 00:41:26.990
What do you have to--

00:41:26.990 --> 00:41:30.570
after you take off
the a skull patch?

00:41:30.570 --> 00:41:31.070
Yes.

00:41:31.070 --> 00:41:31.970
AUDIENCE: Dura mater.

00:41:31.970 --> 00:41:33.512
NANCY KANWISHER:
Dura mater, exactly.

00:41:33.512 --> 00:41:35.870
That nice big piece of
white, leathery stuff

00:41:35.870 --> 00:41:38.010
that was sitting over
the surface of the brain.

00:41:38.010 --> 00:41:40.610
So you to take off
a piece of skull,

00:41:40.610 --> 00:41:44.210
then you need to cut through
and push apart the dura.

00:41:44.210 --> 00:41:46.850
And then what they sometimes
do is stick electrodes straight

00:41:46.850 --> 00:41:48.890
on the surface of the brain.

00:41:48.890 --> 00:41:50.820
And they do that
for two reasons.

00:41:50.820 --> 00:41:54.738
One, if they have enough of
them sampled far enough apart,

00:41:54.738 --> 00:41:56.780
they can kind of triangulate
and figure out where

00:41:56.780 --> 00:41:58.410
is the source of the seizure.

00:41:58.410 --> 00:42:00.710
So the patient hangs out
in the hospital for a week

00:42:00.710 --> 00:42:03.200
or so with these electrodes
in their head waiting

00:42:03.200 --> 00:42:03.943
to have seizures.

00:42:03.943 --> 00:42:05.360
And then when they
have a seizure,

00:42:05.360 --> 00:42:07.670
the clinicians can
figure out where

00:42:07.670 --> 00:42:11.510
the source is so they
know what bit to cut out.

00:42:11.510 --> 00:42:14.150
The other reason to do
this is to map functions.

00:42:14.150 --> 00:42:17.570
Because once the surgeons decide
they have to go in and cut,

00:42:17.570 --> 00:42:19.700
they want to try
to not cut out any

00:42:19.700 --> 00:42:21.290
of the most important parts.

00:42:21.290 --> 00:42:23.207
I don't know what it
means to have unimportant

00:42:23.207 --> 00:42:26.780
parts of the brain, but they
try to avoid language regions

00:42:26.780 --> 00:42:29.090
and stuff like that because
then patients really

00:42:29.090 --> 00:42:32.823
notice if they lose those
things or motor control regions.

00:42:32.823 --> 00:42:34.490
OK, so they map out
functions where they

00:42:34.490 --> 00:42:36.350
might be planning their route.

00:42:36.350 --> 00:42:38.310
OK, make sense?

00:42:38.310 --> 00:42:43.640
Now, some of these patients
are very kind and generous

00:42:43.640 --> 00:42:47.060
to the world and say,
yes, you scientists

00:42:47.060 --> 00:42:48.530
can measure
responses in my brain

00:42:48.530 --> 00:42:52.320
while I look at
your damn stimuli.

00:42:52.320 --> 00:42:55.550
And so whenever we can, we ask
them please, please, please,

00:42:55.550 --> 00:42:57.800
can we show you some pictures
or play you some tones

00:42:57.800 --> 00:42:59.690
or have you read some
sentences while we

00:42:59.690 --> 00:43:01.310
record from your brain.

00:43:01.310 --> 00:43:04.410
And some of those patients
very kindly let us do that.

00:43:04.410 --> 00:43:07.040
And that gives us
the most amazing data

00:43:07.040 --> 00:43:08.870
you can get from human brains.

00:43:08.870 --> 00:43:11.270
So for example, I had
a rare opportunity

00:43:11.270 --> 00:43:14.090
to do this a few years ago
from this lovely guy who

00:43:14.090 --> 00:43:16.850
was undergoing
neurosurgery in Japan.

00:43:16.850 --> 00:43:19.790
And while he had electrodes in
his brain, a colleague of mine

00:43:19.790 --> 00:43:22.500
was there and
emailed me and said,

00:43:22.500 --> 00:43:23.990
look where these
electrodes are--

00:43:23.990 --> 00:43:25.820
right near regions
I care about--

00:43:25.820 --> 00:43:27.710
do you want to show
us some stimuli

00:43:27.710 --> 00:43:30.320
and we'll record responses
from those electrodes?

00:43:30.320 --> 00:43:34.260
And I said, damn straight I
want to send you some stimuli.

00:43:34.260 --> 00:43:37.130
So my students and I stayed
up for a couple of days

00:43:37.130 --> 00:43:39.260
and made some stimuli
and shot them to Japan

00:43:39.260 --> 00:43:43.650
and got some responses
from those very electrodes.

00:43:43.650 --> 00:43:44.780
And here they are.

00:43:44.780 --> 00:43:50.690
So this is a strip of two
parallel strips of electrodes

00:43:50.690 --> 00:43:52.520
right along the
fusiform gyrus, right

00:43:52.520 --> 00:43:55.640
where the fusiform face area
should be in most people.

00:43:55.640 --> 00:43:58.220
And here are the responses
of each of those electrodes.

00:43:58.220 --> 00:44:01.680
174 is here, what's
173 and so forth.

00:44:01.680 --> 00:44:04.670
And what you see is this batch
of electrodes right here--

00:44:04.670 --> 00:44:07.688
this is a response when the
patient was looking at faces.

00:44:07.688 --> 00:44:09.230
And these are the
responses when they

00:44:09.230 --> 00:44:11.630
looked at a whole bunch of
different kinds of stimuli.

00:44:11.630 --> 00:44:13.490
Objects, and this
guy is Japanese

00:44:13.490 --> 00:44:16.430
so we showed him Kana and
Kanji and digit strings

00:44:16.430 --> 00:44:17.990
and other kinds of stuff.

00:44:17.990 --> 00:44:20.150
Very low response to
those other things.

00:44:20.150 --> 00:44:23.300
This is a extremely
selective response.

00:44:23.300 --> 00:44:26.270
It's much more selective than
you see with functional MRI

00:44:26.270 --> 00:44:27.800
because we were
recording directly

00:44:27.800 --> 00:44:29.870
from the surface of the brain.

00:44:29.870 --> 00:44:32.310
Further, we have
time information.

00:44:32.310 --> 00:44:34.550
This axis here is
time, and you can

00:44:34.550 --> 00:44:36.890
see that that response--
well, you can't see the axis,

00:44:36.890 --> 00:44:39.830
but that response
starts up at around 1:30

00:44:39.830 --> 00:44:42.920
milliseconds and peaks
up there at around 170.

00:44:42.920 --> 00:44:44.900
Everybody clear what
we're seeing here

00:44:44.900 --> 00:44:48.200
and why this is so vastly better
than either functional MRI

00:44:48.200 --> 00:44:51.140
or MEG or ERPs or anything else?

00:44:51.140 --> 00:44:53.195
Make sense?

00:44:53.195 --> 00:44:55.480
OK, so these are very,
very precious data.

00:45:00.340 --> 00:45:04.870
OK, nonetheless, the
electrodes in this case

00:45:04.870 --> 00:45:08.710
are about 2 millimeters
across, each electrode.

00:45:08.710 --> 00:45:12.610
And that is about the
size of a functional MRI

00:45:12.610 --> 00:45:17.770
pixel or voxel, a
little bit smaller.

00:45:17.770 --> 00:45:21.400
It has less blurring because
functional MRI blurs spatially

00:45:21.400 --> 00:45:23.180
because it's looking
at blood flow.

00:45:23.180 --> 00:45:25.660
So this is a more precise
spatial measurement

00:45:25.660 --> 00:45:28.030
than functional
MRI, but it is still

00:45:28.030 --> 00:45:31.240
averaging over probably tens
of thousands of neurons,

00:45:31.240 --> 00:45:35.470
down from hundreds of thousands
of neurons with functional MRI.

00:45:35.470 --> 00:45:38.950
So can we ever get responses
from individual neurons

00:45:38.950 --> 00:45:40.930
in the human brain?

00:45:40.930 --> 00:45:43.300
Yes, occasionally.

00:45:43.300 --> 00:45:47.590
In fact, a paper came out on the
bioRxiv a couple of months ago.

00:45:47.590 --> 00:45:50.500
I was on this guy's
PhD thesis defense.

00:45:50.500 --> 00:45:54.700
And this is a guy who works with
a neurosurgeon on Long Island.

00:45:54.700 --> 00:45:57.130
And this neurosurgeon
specializes

00:45:57.130 --> 00:45:59.770
in epilepsy neurosurgery.

00:45:59.770 --> 00:46:04.570
And he's very interested in
not damaging people's ability

00:46:04.570 --> 00:46:06.100
to recognize faces.

00:46:06.100 --> 00:46:11.410
And so he sticks electrodes
to map out neural activity

00:46:11.410 --> 00:46:13.510
and to discover seizure foci.

00:46:13.510 --> 00:46:15.610
Before the
neurosurgery, he sticks

00:46:15.610 --> 00:46:20.410
electrodes in parts of the brain
near the fusiform face area.

00:46:20.410 --> 00:46:22.810
So this is a slice like
this through the brain.

00:46:22.810 --> 00:46:26.080
I showed you before horizontal
slices, OK, so left and right

00:46:26.080 --> 00:46:29.740
are flipped, that region is
right in there, everybody

00:46:29.740 --> 00:46:31.820
oriented with this picture here?

00:46:31.820 --> 00:46:34.950
So this is an MRI
image of this person.

00:46:34.950 --> 00:46:36.460
It was scanned
with functional MRI

00:46:36.460 --> 00:46:38.050
before the electrodes
were put in.

00:46:38.050 --> 00:46:42.100
And that shows you their
fusiform face area right there.

00:46:42.100 --> 00:46:44.680
So now, the neurosurgeons
put in electrodes

00:46:44.680 --> 00:46:48.340
for clinical reasons, but the
electrodes this surgeon uses

00:46:48.340 --> 00:46:50.080
have these little
tiny micro wires

00:46:50.080 --> 00:46:52.210
that come out of the tip
of the electrode that

00:46:52.210 --> 00:46:56.560
enable him to record
from individual neurons.

00:46:56.560 --> 00:46:59.170
And so these guys,
for the first time,

00:46:59.170 --> 00:47:01.900
have recorded from individual
neurons in the fusiform face

00:47:01.900 --> 00:47:03.370
area in humans.

00:47:03.370 --> 00:47:06.770
And here's an example
of one of these neurons.

00:47:06.770 --> 00:47:09.220
So here are the
different stimuli here.

00:47:09.220 --> 00:47:12.130
A bunch of different face
stimuli, body stimuli, houses,

00:47:12.130 --> 00:47:13.630
patterns, and tools.

00:47:13.630 --> 00:47:16.690
And this shows you
time across here.

00:47:16.690 --> 00:47:18.598
Each one of those dots is--

00:47:18.598 --> 00:47:20.890
this is all the response of
a single neuron that's been

00:47:20.890 --> 00:47:23.020
identified in a human brain.

00:47:23.020 --> 00:47:27.230
Each dot is an action potential,
is a spike out of that neuron.

00:47:27.230 --> 00:47:29.410
So you can see them
happening over time here

00:47:29.410 --> 00:47:30.702
to all the faces.

00:47:30.702 --> 00:47:32.410
And this is an average
amount of activity

00:47:32.410 --> 00:47:35.320
to all of the faces and
average amount of activity

00:47:35.320 --> 00:47:38.050
to all the other stimuli.

00:47:38.050 --> 00:47:39.310
Make sense?

00:47:39.310 --> 00:47:41.080
So that's pretty
breathtaking to me

00:47:41.080 --> 00:47:43.630
because I've been using
these very indirect methods

00:47:43.630 --> 00:47:46.720
for a long time, inferring
that they must result

00:47:46.720 --> 00:47:49.120
from the average across a
lot of neurons doing that,

00:47:49.120 --> 00:47:50.890
but it's pretty
awesome to actually see

00:47:50.890 --> 00:47:52.900
individual neurons doing that.

00:47:52.900 --> 00:47:53.980
Yeah?

00:47:53.980 --> 00:47:55.300
OK.

00:47:55.300 --> 00:47:57.880
Here's the time course of
responses just averaging

00:47:57.880 --> 00:47:59.800
over this raster over
time, showing you

00:47:59.800 --> 00:48:04.180
a similar time course to
what I've shown before.

00:48:04.180 --> 00:48:07.460
And in this guy's thesis,
he found three other face

00:48:07.460 --> 00:48:10.720
selective neurons in the
FFA, but the electrodes

00:48:10.720 --> 00:48:12.400
are so rarely in
the right location

00:48:12.400 --> 00:48:14.428
that they only have a
few in this whole thesis,

00:48:14.428 --> 00:48:15.220
and there they are.

00:48:15.220 --> 00:48:16.680
Yeah?

00:48:16.680 --> 00:48:19.100
AUDIENCE: Even if we could
measure individual neurons,

00:48:19.100 --> 00:48:21.970
we don't really know
which neuron it is, right?

00:48:21.970 --> 00:48:24.800
If I wanted to go back and
find the same neuron Again,

00:48:24.800 --> 00:48:26.050
That's pretty much impossible.

00:48:26.050 --> 00:48:27.175
NANCY KANWISHER: Forget it.

00:48:27.175 --> 00:48:27.742
Yep.

00:48:27.742 --> 00:48:29.200
Yep.

00:48:29.200 --> 00:48:31.210
So people like me
who almost never

00:48:31.210 --> 00:48:33.550
get to see responses
from individual neurons

00:48:33.550 --> 00:48:35.713
in human brains have
kind of neuron envy.

00:48:35.713 --> 00:48:37.630
It's like everyone else
in this building has--

00:48:37.630 --> 00:48:40.900
they can measure stuff
from dendrites or ion

00:48:40.900 --> 00:48:42.280
channels or individual neurons.

00:48:42.280 --> 00:48:43.990
They can do all
this amazing stuff.

00:48:43.990 --> 00:48:47.200
But actually, there are a lot
of limitations in those methods

00:48:47.200 --> 00:48:47.837
too.

00:48:47.837 --> 00:48:49.670
And you just put your
finger on one of them.

00:48:49.670 --> 00:48:51.370
So they're like, OK they
found those neurons,

00:48:51.370 --> 00:48:52.450
there are four neurons.

00:48:52.450 --> 00:48:54.490
We can't go back and
find those neurons again.

00:48:54.490 --> 00:48:55.690
That's that, right?

00:48:55.690 --> 00:48:58.730
And they're probably subtly
different in different brains,

00:48:58.730 --> 00:48:59.230
right?

00:48:59.230 --> 00:49:04.900
So it's cool and powerful but
has still has many limitations.

00:49:04.900 --> 00:49:09.970
OK, does this tell us that
these neurons are involved

00:49:09.970 --> 00:49:11.950
in discriminating
one face from another

00:49:11.950 --> 00:49:13.870
or just detecting faces?

00:49:13.870 --> 00:49:17.020
Can we tell from these data?

00:49:17.020 --> 00:49:18.850
Are they just
saying, here's a face

00:49:18.850 --> 00:49:21.930
or are they saying, that's Joe?

00:49:21.930 --> 00:49:23.940
AUDIENCE: Did they have
different conditions

00:49:23.940 --> 00:49:25.645
for different people?

00:49:25.645 --> 00:49:27.645
NANCY KANWISHER: These
are different faces here.

00:49:31.710 --> 00:49:32.610
What do you think?

00:49:32.610 --> 00:49:33.870
What are these neurons doing?

00:49:37.890 --> 00:49:38.580
Yeah?

00:49:38.580 --> 00:49:43.610
AUDIENCE: They're just
recognizing faces [INAUDIBLE]..

00:49:43.610 --> 00:49:45.590
NANCY KANWISHER: You
mean just detecting?

00:49:45.590 --> 00:49:47.150
No, just say more.

00:49:47.150 --> 00:49:48.800
What do you think they're doing?

00:49:48.800 --> 00:49:51.338
AUDIENCE: They're just
selecting for faces.

00:49:51.338 --> 00:49:52.880
There's no evidence
to show that they

00:49:52.880 --> 00:49:54.907
distinguished different faces.

00:49:54.907 --> 00:49:56.490
NANCY KANWISHER:
Well, how about this?

00:49:56.490 --> 00:49:59.220
These are different faces here.

00:49:59.220 --> 00:50:02.810
These are different faces here.

00:50:02.810 --> 00:50:05.640
AUDIENCE: But one could ask,
if it does involve them sort

00:50:05.640 --> 00:50:08.730
of acknowledging
what faces, did they

00:50:08.730 --> 00:50:10.050
have to put a name to the face?

00:50:10.050 --> 00:50:11.508
NANCY KANWISHER:
Nope, they're just

00:50:11.508 --> 00:50:14.040
sitting there looking at stuff.

00:50:14.040 --> 00:50:16.560
So bottom line is, we
don't know from this.

00:50:16.560 --> 00:50:18.930
It could be just responding
and saying essentially,

00:50:18.930 --> 00:50:20.190
there's a face.

00:50:20.190 --> 00:50:22.350
But the fact that there's
different responses

00:50:22.350 --> 00:50:25.290
to different faces
suggests that maybe there's

00:50:25.290 --> 00:50:27.210
some information in there.

00:50:27.210 --> 00:50:30.420
If you ran some machine
learning code on this,

00:50:30.420 --> 00:50:33.120
you could tell a little bit,
which face was being presented.

00:50:33.120 --> 00:50:35.120
Because those neurons are
responding differently

00:50:35.120 --> 00:50:36.630
to different faces.

00:50:36.630 --> 00:50:38.010
Yeah?

00:50:38.010 --> 00:50:40.170
AUDIENCE: Is it really
like if they just

00:50:40.170 --> 00:50:42.280
showed the same face
repeatedly, wouldn't it just

00:50:42.280 --> 00:50:43.710
be like [INAUDIBLE]?

00:50:43.710 --> 00:50:45.570
NANCY KANWISHER: OK,
very good question.

00:50:45.570 --> 00:50:46.600
Very good question.

00:50:46.600 --> 00:50:48.420
That's why I said
suggest, right?

00:50:48.420 --> 00:50:49.560
You're absolutely right.

00:50:49.560 --> 00:50:50.615
That could be just noise.

00:50:50.615 --> 00:50:51.990
It could be that
if you presented

00:50:51.990 --> 00:50:54.407
the same face every time you'd
get that same distribution.

00:50:54.407 --> 00:50:55.560
You're exactly right.

00:50:55.560 --> 00:50:56.820
And so we will talk--

00:50:56.820 --> 00:50:59.080
not next time, I think
Wednesday next week.

00:50:59.080 --> 00:51:00.720
But anyways, very
soon we'll talk

00:51:00.720 --> 00:51:03.660
about methods that enable us to
exactly deal with that question

00:51:03.660 --> 00:51:06.480
and ask, is there
actually information

00:51:06.480 --> 00:51:09.780
in this pattern of response
across neurons or voxels

00:51:09.780 --> 00:51:11.530
or whatever it is?

00:51:11.530 --> 00:51:15.240
Or is that just the
noise of variation?

00:51:15.240 --> 00:51:15.960
Yeah?

00:51:15.960 --> 00:51:16.770
OK.

00:51:16.770 --> 00:51:19.530
AUDIENCE: But how many
neurons are in [INAUDIBLE]??

00:51:19.530 --> 00:51:21.820
NANCY KANWISHER:
Oh good question.

00:51:21.820 --> 00:51:23.370
Let's see.

00:51:23.370 --> 00:51:25.730
I would say, I
think a few million.

00:51:25.730 --> 00:51:26.730
So let's think about it.

00:51:26.730 --> 00:51:31.800
Each voxel is about
a half a million,

00:51:31.800 --> 00:51:35.440
and they are typically maybe
like 30 voxels, something

00:51:35.440 --> 00:51:35.940
like that.

00:51:35.940 --> 00:51:38.760
Somewhere on the order of 20
million, something like that.

00:51:38.760 --> 00:51:40.260
I mean, with huge error bars.

00:51:43.060 --> 00:51:47.200
OK, so this is cool
and tantalizing,

00:51:47.200 --> 00:51:49.818
but it doesn't even tell us what
these neurons-- what exactly

00:51:49.818 --> 00:51:50.860
they're participating in.

00:51:50.860 --> 00:51:53.350
It doesn't tell us if
those neurons are telling

00:51:53.350 --> 00:51:57.520
that person which face is there
or maybe what facial expression

00:51:57.520 --> 00:51:59.135
the person has or
how old they are

00:51:59.135 --> 00:52:01.510
or whether they're male or
female or God knows what else,

00:52:01.510 --> 00:52:02.710
right?

00:52:02.710 --> 00:52:05.110
And it certainly doesn't
tell us how those neurons

00:52:05.110 --> 00:52:07.270
get that information.

00:52:07.270 --> 00:52:09.010
Still, it's cool.

00:52:09.010 --> 00:52:12.790
OK, so intracranial
recording, both with the grids

00:52:12.790 --> 00:52:15.250
that I showed you and
the single unit version.

00:52:15.250 --> 00:52:17.800
Advantages are, this
is the only method

00:52:17.800 --> 00:52:20.560
in humans that has both
pretty good spatial resolution

00:52:20.560 --> 00:52:24.550
and temporal resolution
at the same time.

00:52:24.550 --> 00:52:28.210
Disadvantage-- well, you need
to have a craniotomy, which

00:52:28.210 --> 00:52:30.260
is no picnic, to put it mildly.

00:52:30.260 --> 00:52:32.500
You need to have a huge
piece of your skull removed

00:52:32.500 --> 00:52:33.933
and neurosurgery.

00:52:33.933 --> 00:52:35.350
And that means
that the only times

00:52:35.350 --> 00:52:38.500
we get to do this are when
it's required clinically

00:52:38.500 --> 00:52:40.930
and everything is under
control of the doctors,

00:52:40.930 --> 00:52:42.250
as it should be.

00:52:42.250 --> 00:52:43.930
So the doctors make
all the choices

00:52:43.930 --> 00:52:46.792
about where the
electrodes go, and we just

00:52:46.792 --> 00:52:49.000
get to sit in the background
and say, please, please,

00:52:49.000 --> 00:52:52.570
please, look at these
stimuli, but try not to hassle

00:52:52.570 --> 00:52:54.190
the patients too much.

00:52:54.190 --> 00:52:55.970
Right now there's a
patient in Albany,

00:52:55.970 --> 00:52:57.910
New York who has
electrodes right

00:52:57.910 --> 00:52:59.800
over a really exciting
part of the brain

00:52:59.800 --> 00:53:03.040
to us that I'll talk
about in a few months.

00:53:03.040 --> 00:53:06.880
This patient has electrodes that
respond specifically to music.

00:53:06.880 --> 00:53:08.270
We will talk about that later.

00:53:08.270 --> 00:53:09.950
It's pretty amazing.

00:53:09.950 --> 00:53:12.460
And for the last couple
of days, Dana and I

00:53:12.460 --> 00:53:15.010
have been-- mostly Dana
has been collecting stimuli

00:53:15.010 --> 00:53:17.110
because we really
want to ask questions

00:53:17.110 --> 00:53:19.060
about the response
of those electrodes.

00:53:19.060 --> 00:53:20.560
And this patient
is not too thrilled

00:53:20.560 --> 00:53:21.950
listening to our stimuli.

00:53:21.950 --> 00:53:24.490
So we finally said, oh,
OK, tell the patient

00:53:24.490 --> 00:53:26.230
they can just do
Instagram on their phone

00:53:26.230 --> 00:53:28.105
and we'll play the
stimuli in the background.

00:53:28.105 --> 00:53:32.350
So hopefully, we'll have
cool data from that soon.

00:53:32.350 --> 00:53:36.760
OK, so to say that these data
are limited and hard to control

00:53:36.760 --> 00:53:37.810
is an understatement.

00:53:37.810 --> 00:53:39.610
We basically can't
control it at all.

00:53:39.610 --> 00:53:41.950
All we can control
occasionally is the stimuli.

00:53:45.700 --> 00:53:47.740
And it also, like
functional MRI,

00:53:47.740 --> 00:53:49.750
just because we see those
beautiful responses,

00:53:49.750 --> 00:53:52.930
it doesn't tell us
how those responses

00:53:52.930 --> 00:53:55.810
are connected to behavior.

00:53:55.810 --> 00:53:58.520
So that's a real challenge.

00:53:58.520 --> 00:54:00.430
So that won't do.

00:54:00.430 --> 00:54:02.350
We need to get
beyond this problem.

00:54:02.350 --> 00:54:03.940
I keep saying this
method is great,

00:54:03.940 --> 00:54:05.860
but it doesn't tell
us the causal role

00:54:05.860 --> 00:54:10.210
of that neural phenomenon
in cognition and behavior.

00:54:10.210 --> 00:54:12.910
As scientists, science
is all about discovering

00:54:12.910 --> 00:54:13.973
causal mechanisms.

00:54:13.973 --> 00:54:16.390
We're not just interested in
what is correlated with what,

00:54:16.390 --> 00:54:17.740
we want to know
what's causing what.

00:54:17.740 --> 00:54:19.480
That's really of the
essence, and so we

00:54:19.480 --> 00:54:21.620
need to do better here.

00:54:21.620 --> 00:54:22.780
So what are we going to do?

00:54:22.780 --> 00:54:24.700
Somebody mentioned a
while ago, maybe it

00:54:24.700 --> 00:54:26.590
was Isabelle, that
one of the ways

00:54:26.590 --> 00:54:30.130
to do that and ask whether the
face area is causally involved

00:54:30.130 --> 00:54:33.370
in face perception
is to look at a case

00:54:33.370 --> 00:54:35.680
where the face area is altered.

00:54:35.680 --> 00:54:38.810
So there's a bunch
of ways to do that.

00:54:38.810 --> 00:54:40.510
And one of them--

00:54:40.510 --> 00:54:41.810
OK, that's just a review.

00:54:41.810 --> 00:54:43.360
We said faces are
recognized fast

00:54:43.360 --> 00:54:46.360
but we haven't
learned much more.

00:54:46.360 --> 00:54:48.610
How do we test causality?

00:54:48.610 --> 00:54:52.090
OK, patients with
focal brain damage.

00:54:52.090 --> 00:54:53.450
Here is a patient.

00:54:53.450 --> 00:54:56.290
These are vertical
slices through the back

00:54:56.290 --> 00:54:57.380
of this patient's head.

00:54:57.380 --> 00:54:58.380
OK, let me get oriented.

00:54:58.380 --> 00:54:59.995
The slice is maybe this here.

00:54:59.995 --> 00:55:01.870
And as you go rightward,
you're marching back

00:55:01.870 --> 00:55:03.250
in the brain like that.

00:55:03.250 --> 00:55:04.990
Everybody oriented?

00:55:04.990 --> 00:55:06.848
What's this thing right there?

00:55:06.848 --> 00:55:08.640
AUDIENCE: Cerebellum.

00:55:08.640 --> 00:55:10.620
NANCY KANWISHER: Yeah,
cerebellum, right.

00:55:10.620 --> 00:55:13.230
That thing right there
is this patient's lesion

00:55:13.230 --> 00:55:16.560
that spans several slices
going back like that.

00:55:16.560 --> 00:55:21.600
And this patient's lesion
looks a whole lot like my FFA.

00:55:21.600 --> 00:55:25.830
There's my FFA, greater
response to faces than objects,

00:55:25.830 --> 00:55:27.630
on similar slices.

00:55:27.630 --> 00:55:30.130
We don't have functional
MRI from this patient

00:55:30.130 --> 00:55:32.850
so we don't know exactly
where this guy's FFA was.

00:55:32.850 --> 00:55:36.660
But there's a good bet that
it was blitzed by that lesion,

00:55:36.660 --> 00:55:39.690
because it's right in the
zone where it usually lands.

00:55:39.690 --> 00:55:45.330
And this patient can't
recognize faces at all.

00:55:45.330 --> 00:55:48.210
And importantly, the
patient is absolutely

00:55:48.210 --> 00:55:50.550
normal at recognizing objects.

00:55:50.550 --> 00:55:53.145
No problem whatsoever
at recognizing objects.

00:55:55.740 --> 00:55:57.660
How does this take us
beyond functional MRI?

00:56:00.520 --> 00:56:01.020
Yeah?

00:56:01.020 --> 00:56:03.537
AUDIENCE: It implies causation.

00:56:03.537 --> 00:56:04.620
NANCY KANWISHER: Speak up.

00:56:04.620 --> 00:56:05.912
AUDIENCE: It implies causation.

00:56:05.912 --> 00:56:07.320
NANCY KANWISHER: Yeah, say more.

00:56:07.320 --> 00:56:08.220
What does it tell us?

00:56:08.220 --> 00:56:11.640
AUDIENCE: So because of the
fact that area's damaged

00:56:11.640 --> 00:56:14.625
and then it makes it to not
be able to recognize faces

00:56:14.625 --> 00:56:16.500
and I can see that
there's causality that oh,

00:56:16.500 --> 00:56:17.430
that area's [INAUDIBLE].

00:56:17.430 --> 00:56:18.540
NANCY KANWISHER: Exactly.

00:56:18.540 --> 00:56:19.040
Exactly.

00:56:19.040 --> 00:56:21.460
It says you need that
bit to recognize faces.

00:56:21.460 --> 00:56:23.700
But also says something else.

00:56:23.700 --> 00:56:24.450
What else does it?

00:56:24.450 --> 00:56:26.490
AUDIENCE: That you don't need
it for recognizing objects.

00:56:26.490 --> 00:56:28.210
NANCY KANWISHER: You don't need
it for recognizing objects.

00:56:28.210 --> 00:56:30.240
So this is actually
really strong evidence

00:56:30.240 --> 00:56:34.800
that that bit of brain is
very specialized for face

00:56:34.800 --> 00:56:36.360
recognition.

00:56:36.360 --> 00:56:39.155
Specialized and necessary
for face recognition.

00:56:41.820 --> 00:56:43.125
OK, so--

00:56:46.770 --> 00:56:49.230
AUDIENCE: Can that person
still detect faces?

00:56:49.230 --> 00:56:50.272
NANCY KANWISHER: Oh, yes.

00:56:50.272 --> 00:56:51.780
Good question, absolutely.

00:56:51.780 --> 00:56:55.860
OK, so let me just distinguish--
this person here has

00:56:55.860 --> 00:56:59.100
prosopagnosia-- that means
a selective deficit in face

00:56:59.100 --> 00:57:00.180
recognition--

00:57:00.180 --> 00:57:03.300
like Jacob Hodes, who
I described yesterday,

00:57:03.300 --> 00:57:05.210
who has no brain
damage whatsoever

00:57:05.210 --> 00:57:07.710
but has just never been able
to recognize faces at any point

00:57:07.710 --> 00:57:08.800
in his life.

00:57:08.800 --> 00:57:11.910
So this syndrome can arise just
from some weird developmental

00:57:11.910 --> 00:57:14.850
thing where you're atypical and
you're just really bad at it,

00:57:14.850 --> 00:57:17.940
or it can result from damage
to that part of the brain.

00:57:17.940 --> 00:57:21.300
So now we're talking
about the case of damage,

00:57:21.300 --> 00:57:24.600
but in both cases,
people with prosopagnosia

00:57:24.600 --> 00:57:27.150
have no problem knowing
that a face is a face.

00:57:27.150 --> 00:57:29.880
They just don't know who it is.

00:57:29.880 --> 00:57:30.922
Yeah?

00:57:30.922 --> 00:57:32.940
AUDIENCE: Has there
ever been a case

00:57:32.940 --> 00:57:37.100
of problems of people who
can't recognize faces who

00:57:37.100 --> 00:57:38.090
[INAUDIBLE]?

00:57:41.060 --> 00:57:42.350
NANCY KANWISHER: Indeed.

00:57:42.350 --> 00:57:43.130
Indeed.

00:57:43.130 --> 00:57:45.950
Jacob Hodes, who I talked
about last time who is just

00:57:45.950 --> 00:57:48.140
absolutely awful at
face recognition,

00:57:48.140 --> 00:57:50.420
including family
members, close friends,

00:57:50.420 --> 00:57:52.910
can't do it, like not at all.

00:57:52.910 --> 00:57:56.750
He has a very normal
looking fusiform face area.

00:57:56.750 --> 00:57:59.360
So after I told you that I
had that conversation with him

00:57:59.360 --> 00:58:03.440
a dozen years ago or something
like that, I scanned him.

00:58:03.440 --> 00:58:06.980
And he had a beautiful fusiform
face area, like textbook.

00:58:06.980 --> 00:58:11.000
It looked-- well, looked like
mine, which is a damn fine one

00:58:11.000 --> 00:58:13.470
if I do say so myself.

00:58:13.470 --> 00:58:17.360
And I looked at that
and I went, oh shit.

00:58:17.360 --> 00:58:19.610
I better publish this
before someone else does.

00:58:19.610 --> 00:58:21.120
And I didn't get
my act together,

00:58:21.120 --> 00:58:22.610
and then a whole bunch of
papers came out saying,

00:58:22.610 --> 00:58:24.620
oh, people with
developmental prosopagnosia

00:58:24.620 --> 00:58:26.120
have normal looking face areas.

00:58:26.120 --> 00:58:27.050
Take that, Kanwisher.

00:58:27.050 --> 00:58:30.360
What do you say about that?

00:58:30.360 --> 00:58:32.780
And it was a little shocking.

00:58:32.780 --> 00:58:35.400
But upon further reflection,
it's not really devastating,

00:58:35.400 --> 00:58:35.900
right?

00:58:35.900 --> 00:58:38.660
I mean, it's bracing,
it's informative.

00:58:38.660 --> 00:58:42.560
But it tells you that
having a face area that

00:58:42.560 --> 00:58:45.500
is a region that responds
more to faces and objects

00:58:45.500 --> 00:58:49.610
isn't sufficient for normal
face recognition, right?

00:58:49.610 --> 00:58:51.630
You need other stuff.

00:58:51.630 --> 00:58:52.950
What might that other stuff be?

00:58:52.950 --> 00:58:55.670
Well, the circuits in
there need to work right.

00:58:55.670 --> 00:58:58.550
It's not enough to just respond
more to faces and objects.

00:58:58.550 --> 00:59:01.190
To recognize faces, they need
to be able to distinguish faces

00:59:01.190 --> 00:59:01.760
from objects.

00:59:01.760 --> 00:59:03.740
We don't know if
that's working right.

00:59:03.740 --> 00:59:05.052
What else do you need?

00:59:05.052 --> 00:59:06.200
AUDIENCE: Memory.

00:59:06.200 --> 00:59:09.110
NANCY KANWISHER:
Memory, absolutely.

00:59:09.110 --> 00:59:11.180
Yes, you need to remember faces.

00:59:11.180 --> 00:59:12.044
What else?

00:59:12.044 --> 00:59:23.200
AUDIENCE: [INAUDIBLE]

00:59:23.200 --> 00:59:25.420
NANCY KANWISHER: Could
be, but in Jacob's case,

00:59:25.420 --> 00:59:28.113
it was close friends
he couldn't recognize.

00:59:28.113 --> 00:59:29.530
So what's another
possible account

00:59:29.530 --> 00:59:32.350
of how could he have a
normal face area and yeah?

00:59:32.350 --> 00:59:32.850
David?

00:59:32.850 --> 00:59:37.930
AUDIENCE: It might be a gap
between recognizing a face

00:59:37.930 --> 00:59:41.133
and connecting that to
recognizing a person.

00:59:41.133 --> 00:59:42.050
NANCY KANWISHER: Yeah.

00:59:42.050 --> 00:59:42.550
Yeah.

00:59:42.550 --> 00:59:44.430
Or to put that
neuroanatomically,

00:59:44.430 --> 00:59:47.190
you got to get the
information out of there.

00:59:47.190 --> 00:59:50.550
maybe, for all we know,
that little face area

00:59:50.550 --> 00:59:51.480
is working perfectly.

00:59:51.480 --> 00:59:54.840
Maybe that face area knows who
that person is, in a sense.

00:59:54.840 --> 00:59:56.730
But if the connection's
out of that brain

00:59:56.730 --> 00:59:59.970
region to the rest of
the brain are messed up,

00:59:59.970 --> 01:00:01.957
it doesn't do you any good.

01:00:01.957 --> 01:00:04.290
You need to be able to read
that information out and act

01:00:04.290 --> 01:00:06.390
on the basis of it.

01:00:06.390 --> 01:00:08.310
Anyway, that's a big sidebar.

01:00:08.310 --> 01:00:10.110
Point is, you can
have prosopagnosia

01:00:10.110 --> 01:00:13.860
either as just a
developmental disorder

01:00:13.860 --> 01:00:16.172
or as a result of brain damage.

01:00:16.172 --> 01:00:17.880
Oh, God, I knew this
was going to happen.

01:00:17.880 --> 01:00:24.300
All right, so OK, so very
briefly, it messes up ability

01:00:24.300 --> 01:00:26.970
to discriminate and recognize
faces, not your ability

01:00:26.970 --> 01:00:28.080
to detect a face, right?

01:00:28.080 --> 01:00:29.455
So as [INAUDIBLE]
had asked, it's

01:00:29.455 --> 01:00:31.682
not just you can't tell
the thing is a face,

01:00:31.682 --> 01:00:32.640
they're fine with that.

01:00:32.640 --> 01:00:36.330
Importantly, they are normal
and voice recognition.

01:00:36.330 --> 01:00:37.830
So it's not that
they're confused

01:00:37.830 --> 01:00:40.150
about distinguishing
one person from another.

01:00:40.150 --> 01:00:43.905
They can do it fine from
audition, just not from vision.

01:00:46.740 --> 01:00:48.900
In the rare cases where
the lesion is small,

01:00:48.900 --> 01:00:52.650
it can be very specific, leaving
object recognition intact.

01:00:52.650 --> 01:00:54.480
More often, there's
kind of a blurry mess.

01:00:54.480 --> 01:00:57.930
You have a big lesion and a
bunch of things are affected.

01:00:57.930 --> 01:00:59.790
OK, so we've talked about that.

01:00:59.790 --> 01:01:05.250
OK now, it's very important
in neuropsychology reasoning--

01:01:05.250 --> 01:01:07.320
like we want to say, OK,
that's really powerful,

01:01:07.320 --> 01:01:08.610
the case of prosopagnosia.

01:01:08.610 --> 01:01:12.900
You lose that bit, you
can't recognize faces.

01:01:12.900 --> 01:01:15.990
And that establishes
a kind of causality

01:01:15.990 --> 01:01:19.290
that we didn't have before
with just functional MRI.

01:01:19.290 --> 01:01:22.950
But is that sufficient to say
that that region is specialized

01:01:22.950 --> 01:01:24.390
for face recognition only?

01:01:29.960 --> 01:01:30.560
It's not.

01:01:30.560 --> 01:01:32.400
Whenever I ask this,
the answer's no.

01:01:32.400 --> 01:01:35.270
Your task is to say, why?

01:01:35.270 --> 01:01:39.140
How could you have great
difficulty at recognizing faces

01:01:39.140 --> 01:01:40.880
and be OK at object recognition?

01:01:40.880 --> 01:01:44.150
And yet, not have a deficit
that's specific to faces?

01:01:44.150 --> 01:01:47.030
How might that arise?

01:01:47.030 --> 01:01:49.550
You guys have suggested this
hypothesis in different context

01:01:49.550 --> 01:01:50.050
before.

01:01:57.120 --> 01:01:57.780
Yes?

01:01:57.780 --> 01:01:58.738
You look like you know.

01:01:58.738 --> 01:01:59.250
No?

01:01:59.250 --> 01:02:01.910
AUDIENCE: But I just you
could do other things.

01:02:01.910 --> 01:02:06.980
It doesn't have to only
be for facial recognition.

01:02:06.980 --> 01:02:11.420
Because it response to
animals [INAUDIBLE],, right?

01:02:11.420 --> 01:02:13.010
NANCY KANWISHER: Sort of.

01:02:13.010 --> 01:02:16.880
But the question here is--

01:02:16.880 --> 01:02:18.980
OK, let's just start bare bones.

01:02:18.980 --> 01:02:22.490
You have a lesion, you get
around fine in the world,

01:02:22.490 --> 01:02:24.740
you can do everything else
but you have a real problem

01:02:24.740 --> 01:02:26.840
recognizing faces.

01:02:26.840 --> 01:02:32.750
Does that mean that the
region lesioned is specialized

01:02:32.750 --> 01:02:35.405
for face recognition per se?

01:02:35.405 --> 01:02:38.315
AUDIENCE: There might
be other [INAUDIBLE]..

01:02:41.132 --> 01:02:42.340
NANCY KANWISHER: That's true.

01:02:42.340 --> 01:02:44.530
There could be other things
going on, absolutely.

01:02:44.530 --> 01:02:45.580
But let's suppose they're not.

01:02:45.580 --> 01:02:47.290
Let's suppose you had good
reason to think there weren't.

01:02:47.290 --> 01:02:48.010
Yeah?

01:02:48.010 --> 01:02:50.620
AUDIENCE: It could be--

01:02:50.620 --> 01:02:52.390
it'd be a path--

01:02:52.390 --> 01:02:54.280
it could be one
point in a pathway.

01:02:54.280 --> 01:02:54.850
NANCY KANWISHER: That's true.

01:02:54.850 --> 01:02:56.470
It could be totally
a point in a pathway.

01:02:56.470 --> 01:02:57.928
Absolutely, that's
another account.

01:02:57.928 --> 01:02:59.416
What else?

01:02:59.416 --> 01:03:01.720
AUDIENCE: Well, I couldn't
get last comment, so.

01:03:01.720 --> 01:03:03.887
NANCY KANWISHER: He said
maybe you damage a pathway.

01:03:06.740 --> 01:03:07.610
Yeah?

01:03:07.610 --> 01:03:09.402
AUDIENCE: Maybe there's
some other function

01:03:09.402 --> 01:03:10.790
we haven't tested
in that person.

01:03:10.790 --> 01:03:11.900
NANCY KANWISHER: All
these are very good

01:03:11.900 --> 01:03:12.860
alternative hypotheses.

01:03:12.860 --> 01:03:14.152
You guys are very good at this.

01:03:14.152 --> 01:03:16.010
The one I'm fishing
for is, maybe

01:03:16.010 --> 01:03:19.670
face recognition is just
harder than object recognition.

01:03:19.670 --> 01:03:23.570
Maybe the part that's damaged
is just generically involved

01:03:23.570 --> 01:03:26.180
in object recognition,
but you damage

01:03:26.180 --> 01:03:28.940
part of the object recognition
system and face recognition

01:03:28.940 --> 01:03:31.820
takes a bigger hit
because it's harder.

01:03:31.820 --> 01:03:32.330
Right?

01:03:32.330 --> 01:03:33.810
Does that make sense?

01:03:33.810 --> 01:03:35.780
Do you see how the
case of prosopagnosia

01:03:35.780 --> 01:03:37.200
is consistent with that?

01:03:37.200 --> 01:03:40.910
So that means we cannot infer
from these data alone that that

01:03:40.910 --> 01:03:43.490
region's specialized
for face recognition.

01:03:43.490 --> 01:03:45.380
Now, we can do various
things like test

01:03:45.380 --> 01:03:48.470
them on really hard versions
of object recognition.

01:03:48.470 --> 01:03:49.940
And people have done that.

01:03:49.940 --> 01:03:53.570
But there's another kind of data
that are really powerful here.

01:03:53.570 --> 01:03:57.500
And that's when we have
the opposite syndrome.

01:03:57.500 --> 01:04:00.560
So there's only a
couple of cases of this.

01:04:00.560 --> 01:04:04.177
The best one is called CK,
published in a paper in 1997.

01:04:04.177 --> 01:04:05.510
You don't need to remember that.

01:04:05.510 --> 01:04:07.490
The point about this
is that this guy

01:04:07.490 --> 01:04:09.630
has the opposite syndrome.

01:04:09.630 --> 01:04:12.290
He's severely impaired
at object recognition.

01:04:12.290 --> 01:04:14.390
He can't tell a
chair from a table

01:04:14.390 --> 01:04:16.910
from a car from a
toaster, but he's

01:04:16.910 --> 01:04:19.790
100% normal at face recognition.

01:04:19.790 --> 01:04:21.800
Totally normal at
face recognition.

01:04:21.800 --> 01:04:23.030
In fact, better than average.

01:04:25.833 --> 01:04:27.250
Do you see how
that's in some ways

01:04:27.250 --> 01:04:31.030
even more powerful evidence
that face recognition goes

01:04:31.030 --> 01:04:32.890
on in specialized
brain machinery

01:04:32.890 --> 01:04:35.500
than the case of prosopagnosia?

01:04:35.500 --> 01:04:37.930
Face recognition isn't
even a special thing

01:04:37.930 --> 01:04:40.120
that sits on top of
normal object recognition.

01:04:40.120 --> 01:04:41.830
It's a totally
different pathway.

01:04:41.830 --> 01:04:44.020
You can have no ability
to recognize objects

01:04:44.020 --> 01:04:45.860
and your OK a face recognition.

01:04:45.860 --> 01:04:48.010
Does everybody see how
that's really powerful?

01:04:48.010 --> 01:04:50.110
And how those two
kinds of evidence

01:04:50.110 --> 01:04:55.270
together are vastly more
powerful than either one alone.

01:04:55.270 --> 01:04:59.110
Well, that's called
a double association.

01:04:59.110 --> 01:05:00.610
We'll skip all of that for now.

01:05:00.610 --> 01:05:03.400
Doubled associations are
particularly powerful

01:05:03.400 --> 01:05:05.230
examples--

01:05:05.230 --> 01:05:07.960
powerful forms of
evidence in cognitive

01:05:07.960 --> 01:05:10.810
neuroscience where we have
opposite syndromes that

01:05:10.810 --> 01:05:13.480
collectively make it really
hard to wiggle out and come up

01:05:13.480 --> 01:05:15.250
with alternative
accounts other than

01:05:15.250 --> 01:05:18.460
that there's a bit of brain
that's really specialized

01:05:18.460 --> 01:05:19.450
for face recognition.

01:05:19.450 --> 01:05:21.730
It's not just that face
recognition is harder,

01:05:21.730 --> 01:05:25.540
or else you'd never
get this syndrome.

01:05:25.540 --> 01:05:27.550
All right, I just wanted
to finish that point.

01:05:27.550 --> 01:05:29.785
OK now, how much time do
I have until the quiz?

01:05:33.930 --> 01:05:35.423
15 minutes, OK good.

01:05:35.423 --> 01:05:36.310
AUDIENCE: 13.

01:05:36.310 --> 01:05:36.780
NANCY KANWISHER: OK, good.

01:05:36.780 --> 01:05:38.190
We're going to skip over TMS.

01:05:38.190 --> 01:05:39.060
I'm sorry about that, guys.

01:05:39.060 --> 01:05:40.980
Someday I'll learn to
time things in a lecture.

01:05:40.980 --> 01:05:43.105
Actually, I knew this was
going to happen, I just--

01:05:43.105 --> 01:05:44.880
we'll get back to TMS later.

01:05:44.880 --> 01:05:49.020
And we will skip to
the most amazing method

01:05:49.020 --> 01:05:52.680
in all of cognitive
neuroscience for which-- we're

01:05:52.680 --> 01:05:55.530
going to come back to this
dude who you met before who

01:05:55.530 --> 01:05:59.100
has the face selective responses
in that part of his brain.

01:05:59.100 --> 01:06:01.710
Remember how I said that
even though these data are

01:06:01.710 --> 01:06:03.840
gorgeous and spectacular
and the only way

01:06:03.840 --> 01:06:06.300
we can get high spatial and
temporal resolution together,

01:06:06.300 --> 01:06:08.860
but they don't
tell us causality?

01:06:08.860 --> 01:06:09.360
Right?

01:06:09.360 --> 01:06:11.040
That's true here?

01:06:11.040 --> 01:06:12.990
Resolution doesn't
get you causality.

01:06:12.990 --> 01:06:14.790
To test the causal
role of something,

01:06:14.790 --> 01:06:17.670
you need to mess with it.

01:06:17.670 --> 01:06:21.870
So it turns out that sometimes
the neurosurgeons electrically

01:06:21.870 --> 01:06:24.600
stimulate through
those same electrodes.

01:06:24.600 --> 01:06:28.260
And they do that to test the
function of those regions

01:06:28.260 --> 01:06:29.970
causally.

01:06:29.970 --> 01:06:34.260
They also do it to test their
hypotheses about the location

01:06:34.260 --> 01:06:36.960
of the seizure foci.

01:06:36.960 --> 01:06:39.090
So in those rare
cases, where you

01:06:39.090 --> 01:06:41.280
have a patient like this
with selective electrodes

01:06:41.280 --> 01:06:44.670
like that where the clinicians
decide that they are going

01:06:44.670 --> 01:06:46.350
to electrically
stimulate through some

01:06:46.350 --> 01:06:48.270
of those electrodes,
then we're in a position

01:06:48.270 --> 01:06:50.493
to kind of have it all
scientifically, right?

01:06:50.493 --> 01:06:51.660
I don't mean to be so crude.

01:06:51.660 --> 01:06:54.360
This is a horrible situation
for that lovely guy to be in,

01:06:54.360 --> 01:06:57.220
but scientifically,
it's extremely powerful.

01:06:57.220 --> 01:07:00.570
So I'm going to show you--

01:07:00.570 --> 01:07:02.430
we did in fact have
an opportunity.

01:07:02.430 --> 01:07:04.980
The same guys in
Japan emailed me

01:07:04.980 --> 01:07:07.880
and said, OK, we're going to
be stimulating that electrode.

01:07:07.880 --> 01:07:10.230
What do we do?

01:07:10.230 --> 01:07:12.750
And I said, OK, have
him look at faces

01:07:12.750 --> 01:07:14.310
and have them look
at other objects

01:07:14.310 --> 01:07:15.932
and ask him if anything changes.

01:07:15.932 --> 01:07:17.640
And I'm going to show
you a video of what

01:07:17.640 --> 01:07:19.680
happens when that goes on.

01:07:19.680 --> 01:07:23.040
OK, here we go.

01:07:23.040 --> 01:07:24.570
Oh, and I need to
turn on the audio.

01:07:27.360 --> 01:07:31.320
OK, he's getting stimulated
right there and he says--

01:07:31.320 --> 01:07:32.310
[VIDEO PLAYBACK]

01:07:32.310 --> 01:07:36.270
- [NON-ENGLISH SPEECH]

01:07:53.340 --> 01:07:56.250
NANCY KANWISHER: He's such
a good subject, this guy.

01:07:56.250 --> 01:07:57.188
- One more time.

01:08:09.638 --> 01:08:12.550
- [NON-ENGLISH SPEECH]

01:08:20.740 --> 01:08:23.210
- His eyes.

01:08:23.210 --> 01:08:24.700
- [NON-ENGLISH SPEECH]

01:08:30.833 --> 01:08:32.250
NANCY KANWISHER:
OK, that tells us

01:08:32.250 --> 01:08:34.890
that that region is causally
involved in face perception.

01:08:34.890 --> 01:08:36.660
Is it causally
involved in perception

01:08:36.660 --> 01:08:38.609
of things that aren't faces?

01:08:38.609 --> 01:08:40.529
He's getting stimulated
in the same electrode.

01:08:40.529 --> 01:08:42.479
He doesn't know that
there's a face area.

01:08:42.479 --> 01:08:43.537
- [NON-ENGLISH SPEECH]

01:08:43.537 --> 01:08:45.120
NANCY KANWISHER: He
doesn't know which

01:08:45.120 --> 01:08:47.855
electrode is being stimulated.

01:08:47.855 --> 01:08:50.069
- [NON-ENGLISH SPEECH]

01:09:26.703 --> 01:09:29.120
NANCY KANWISHER: This is a
Kanji character on a card here.

01:09:29.120 --> 01:09:32.599
- [NON-ENGLISH SPEECH]

01:09:39.557 --> 01:09:41.048
- One more time.

01:09:50.520 --> 01:09:52.611
- [NON-ENGLISH SPEECH]

01:09:59.720 --> 01:10:00.630
[END PLAYBACK]

01:10:00.630 --> 01:10:01.880
NANCY KANWISHER: Awesome, huh?

01:10:01.880 --> 01:10:02.990
What did we just learn?

01:10:05.750 --> 01:10:07.020
AUDIENCE: You can trigger it.

01:10:07.020 --> 01:10:08.770
NANCY KANWISHER: You
can trigger it, yeah.

01:10:08.770 --> 01:10:09.560
Yeah.

01:10:09.560 --> 01:10:12.060
So what does that tell us about
the function of that region?

01:10:19.480 --> 01:10:22.120
Why is this-- I mean, it's
amazing to see, no question,

01:10:22.120 --> 01:10:24.235
but what does it tell
us scientifically?

01:10:24.235 --> 01:10:26.200
AUDIENCE: It's specific.

01:10:26.200 --> 01:10:27.190
NANCY KANWISHER: Yeah.

01:10:27.190 --> 01:10:29.380
How does it tell us
that it's specific?

01:10:29.380 --> 01:10:31.900
AUDIENCE: Because
when you stimulate it,

01:10:31.900 --> 01:10:35.630
it particularly sees a face.

01:10:35.630 --> 01:10:36.853
NANCY KANWISHER: Yeah.

01:10:36.853 --> 01:10:38.270
And what happens
when he's looking

01:10:38.270 --> 01:10:42.090
at things that aren't faces?

01:10:42.090 --> 01:10:43.520
AUDIENCE: [INAUDIBLE]

01:10:43.520 --> 01:10:44.690
NANCY KANWISHER: Yeah.

01:10:44.690 --> 01:10:47.900
So if that region
was causally involved

01:10:47.900 --> 01:10:50.240
in perception of things
that aren't faces,

01:10:50.240 --> 01:10:53.000
you might think that
it would distort--

01:10:53.000 --> 01:10:55.670
the box would look different or
the ball would look different

01:10:55.670 --> 01:10:57.120
or the Kanji would
look different.

01:10:57.120 --> 01:10:59.510
It doesn't, there's
just a face on top.

01:10:59.510 --> 01:11:01.310
So I think that's
very strong evidence

01:11:01.310 --> 01:11:03.260
that that region is not
only causally involved

01:11:03.260 --> 01:11:07.160
in face perception, but very
specifically causally involved

01:11:07.160 --> 01:11:08.960
in face perception only.

01:11:08.960 --> 01:11:10.400
Everybody get that?

01:11:10.400 --> 01:11:11.810
Do I have to stop?

01:11:11.810 --> 01:11:13.160
OK.

01:11:13.160 --> 01:11:14.900
OK, I have another video.

01:11:14.900 --> 01:11:17.660
Consider-- and we'll
get back to this later--

01:11:17.660 --> 01:11:22.475
consider other alternative
hypotheses to this.

01:11:22.475 --> 01:11:23.905
This is pretty powerful.

01:11:23.905 --> 01:11:26.030
This is more powerful than
most of the other things

01:11:26.030 --> 01:11:28.245
I showed you, but
there's always ways

01:11:28.245 --> 01:11:29.870
to come up with
alternative hypotheses,

01:11:29.870 --> 01:11:31.740
and that's the
business we're in here.

01:11:31.740 --> 01:11:34.070
So be percolating on
what other control

01:11:34.070 --> 01:11:36.680
conditions you'd
want from this guy

01:11:36.680 --> 01:11:39.490
to really believe these data.