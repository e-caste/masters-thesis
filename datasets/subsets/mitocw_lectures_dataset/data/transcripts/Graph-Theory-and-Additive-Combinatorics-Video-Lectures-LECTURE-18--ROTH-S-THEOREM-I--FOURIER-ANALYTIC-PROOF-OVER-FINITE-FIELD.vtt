WEBVTT

00:00:17.865 --> 00:00:18.490
YUFEI ZHAO: OK.

00:00:18.490 --> 00:00:20.950
So let's get started.

00:00:20.950 --> 00:00:23.170
So we spent quite a bit
of time with graph theory

00:00:23.170 --> 00:00:25.010
in the first part
of this course,

00:00:25.010 --> 00:00:27.760
and today I want to
move beyond that.

00:00:27.760 --> 00:00:31.630
So we're going to talk
about more central topics

00:00:31.630 --> 00:00:33.730
and additive
combinatorics, starting

00:00:33.730 --> 00:00:37.180
with the Fourier analytic
proof of Roth's theorem.

00:00:48.760 --> 00:00:51.340
We discussed Roth's theorem,
and we gave a proof,

00:00:51.340 --> 00:00:54.760
during the course, using
similarities, graph regularity

00:00:54.760 --> 00:00:59.220
lemma, as well as the
triangle removal lemma.

00:00:59.220 --> 00:01:01.810
Today, I want to show
you a different approach

00:01:01.810 --> 00:01:05.540
to proving Roth's theorem that
goes through Fourier analysis.

00:01:05.540 --> 00:01:07.240
So this is a very
important proof,

00:01:07.240 --> 00:01:13.330
and it's one of the main tools
in additive combinatorics.

00:01:13.330 --> 00:01:15.520
Let me remind you what
Roth's theorem says.

00:01:15.520 --> 00:01:24.710
So Roth proved, in
1953, that if we

00:01:24.710 --> 00:01:36.140
write our sub-3 of interval n
to be the maximum size of a 3AP3

00:01:36.140 --> 00:01:52.820
subset of 1 through n, then
Roth showed that our 3 of n

00:01:52.820 --> 00:01:58.280
is little O of n.

00:01:58.280 --> 00:02:01.790
So in other words, if you
have a positive density

00:02:01.790 --> 00:02:06.560
subset of the
integers, then it must

00:02:06.560 --> 00:02:09.150
contain a three-term
arithmetic progression then.

00:02:09.150 --> 00:02:13.740
So what I said is equivalent
to the statement here.

00:02:13.740 --> 00:02:16.831
So previously, we gave a
proof using regularity.

00:02:23.000 --> 00:02:25.500
Actually the regularity approach
of SzemerÃ©di was only found

00:02:25.500 --> 00:02:28.530
the '70s so Roth's original
proof was through Fourier

00:02:28.530 --> 00:02:29.460
analysis.

00:02:29.460 --> 00:02:32.520
And we'll see that tomorrow.

00:02:32.520 --> 00:02:35.843
Today, we'll see a toy
version of this proof.

00:02:35.843 --> 00:02:37.260
But it's not really
a toy version.

00:02:37.260 --> 00:02:40.430
It has the same ideas, but
in a slightly easier setting

00:02:40.430 --> 00:02:42.330
that has fewer technicalities.

00:02:44.553 --> 00:02:46.220
But before showing
you that, let me just

00:02:46.220 --> 00:02:48.320
discuss a bit of history
around Roth's theorem.

00:02:51.230 --> 00:02:55.600
We will show, next
time, the next lecture,

00:02:55.600 --> 00:02:59.405
we'll show the bound.

00:02:59.405 --> 00:03:02.717
Also by regularity, we get some
bound, which is little O then,

00:03:02.717 --> 00:03:04.550
but because of the use
of regularity lemmas,

00:03:04.550 --> 00:03:06.880
it's pretty poor dependence.

00:03:06.880 --> 00:03:11.370
We got something like
n over log star n.

00:03:11.370 --> 00:03:16.680
Next lecture, and basically
Roth's original proof,

00:03:16.680 --> 00:03:20.340
gives you a bound which
is n over log-log n.

00:03:20.340 --> 00:03:23.100
So it's a much more
reasonable bound.

00:03:23.100 --> 00:03:29.880
The current best
upper bound known

00:03:29.880 --> 00:03:43.000
has the form, essentially,
n over log n raised to 1

00:03:43.000 --> 00:03:47.470
plus little 1,
roughly n over log n.

00:03:47.470 --> 00:03:49.870
We do not know, or even
have great guesses on,

00:03:49.870 --> 00:03:51.840
what the answer should be.

00:03:51.840 --> 00:03:57.250
So the best lower bound,
and this is a construction

00:03:57.250 --> 00:04:02.620
that we saw earlier in
the course due to Behrend

00:04:02.620 --> 00:04:10.360
is of the form n over
E to the c root log n.

00:04:10.360 --> 00:04:12.550
It seems it may be very
difficult to improve

00:04:12.550 --> 00:04:16.070
this upper bound without
some genuine new ideas.

00:04:16.070 --> 00:04:18.940
On the other hand,
there is some evidence

00:04:18.940 --> 00:04:20.529
that the lower bound
might be closer

00:04:20.529 --> 00:04:24.617
to the truth in that there are
variants of the Roth problem

00:04:24.617 --> 00:04:27.200
for which we know that the lower
bound is basically the truth.

00:04:32.390 --> 00:04:34.670
What I want to do today
is look at a variant

00:04:34.670 --> 00:04:37.760
of this problem in what's
called a finite field model.

00:04:47.520 --> 00:04:49.480
And that basically
just means we're

00:04:49.480 --> 00:04:52.870
going to be looking at Roth's
theorem, not in the integers,

00:04:52.870 --> 00:04:56.170
but in some finite field
vector space, specifically F3

00:04:56.170 --> 00:04:57.200
to the n.

00:04:57.200 --> 00:05:00.110
So we're going to define
our sub-3 of this F3

00:05:00.110 --> 00:05:06.100
to the n to be the
maximum size of the 3AP3

00:05:06.100 --> 00:05:13.700
subset of this finite
field vector space.

00:05:16.588 --> 00:05:18.380
So the finite field
model is really useful.

00:05:18.380 --> 00:05:22.140
We're going to see this again
later in the course as well.

00:05:22.140 --> 00:05:24.140
Many of the ideas
and techniques that

00:05:24.140 --> 00:05:28.940
work for the real problem, so to
speak, many of those techniques

00:05:28.940 --> 00:05:31.040
also work in the
finite field model,

00:05:31.040 --> 00:05:34.320
but they are technically
simpler to execute.

00:05:34.320 --> 00:05:36.470
So this is often--

00:05:36.470 --> 00:05:39.980
you view it as a sandbox, a
playing ground, for testing out

00:05:39.980 --> 00:05:41.295
many of the ideas.

00:05:41.295 --> 00:05:42.920
And once you have
those ideas, then you

00:05:42.920 --> 00:05:46.430
can see if you can bring
them to the integer setting.

00:05:46.430 --> 00:05:48.560
And this is a very
successful program,

00:05:48.560 --> 00:05:52.130
and we'll see one aspect of
what happens when we do this.

00:05:55.220 --> 00:05:59.450
For this specific problem of
Roth's theorem, in F3 to the n,

00:05:59.450 --> 00:06:00.950
there are some nice
interpretations

00:06:00.950 --> 00:06:02.660
of what this problem means.

00:06:02.660 --> 00:06:05.750
So here's a pretty
easy fact that for--

00:06:05.750 --> 00:06:13.460
so n F3 to the n for
three elements, x, y, z,

00:06:13.460 --> 00:06:17.370
the following interpretation,
so what it means to be a 3AP,

00:06:17.370 --> 00:06:18.680
are equivalent.

00:06:18.680 --> 00:06:23.060
So x. y, z form a 3AP.

00:06:27.540 --> 00:06:31.680
So 3AP means the y is x
plus D. Z is x plus 2D.

00:06:34.640 --> 00:06:38.560
Equivalently, they satisfy this
equation, x minus 2y plus z

00:06:38.560 --> 00:06:40.430
equals zero.

00:06:40.430 --> 00:06:40.930
OK.

00:06:40.930 --> 00:06:43.630
In F3, minus 2 is plus 1.

00:06:43.630 --> 00:06:47.770
So it's the same as this
even nicer looking equation,

00:06:47.770 --> 00:06:49.350
x plus y plus z equals 2.

00:06:53.588 --> 00:06:55.880
It also turns out to be the
same as saying that x, y, z

00:06:55.880 --> 00:07:00.880
would lie on a line.

00:07:00.880 --> 00:07:01.760
But they are aligned.

00:07:06.780 --> 00:07:10.050
So the line has
three points in F3.

00:07:10.050 --> 00:07:13.650
And if you look at the
coordinate for every i,

00:07:13.650 --> 00:07:28.820
the i-th coordinate of x, y, z
are all distinct or all equal.

00:07:32.187 --> 00:07:33.730
So easy to check
all these things

00:07:33.730 --> 00:07:35.280
are equivalent to each other.

00:07:35.280 --> 00:07:37.990
And the last one is
a nice interpretation

00:07:37.990 --> 00:07:43.460
in terms of a game that
many of you know, Set.

00:07:43.460 --> 00:07:45.580
So in the game Set, you
have a bunch of cards.

00:07:45.580 --> 00:07:47.740
There have some number of
properties, n properties,

00:07:47.740 --> 00:07:50.560
like color, the number
of symbols, the shape.

00:07:50.560 --> 00:07:53.560
And you want to form
a set being three

00:07:53.560 --> 00:07:56.030
cards such that every
property, they're

00:07:56.030 --> 00:07:58.120
all same or all different.

00:07:58.120 --> 00:08:02.777
So that's exactly
this model over here.

00:08:02.777 --> 00:08:04.360
So what can we say
about this problem?

00:08:04.360 --> 00:08:06.520
What's the size of
the maximum subset

00:08:06.520 --> 00:08:09.760
of F3 to the n-th without 3-AP.

00:08:09.760 --> 00:08:11.740
If you look at the proof
that we did earlier

00:08:11.740 --> 00:08:14.440
in this course, the one
using triangle removal lemma,

00:08:14.440 --> 00:08:16.522
you see the proof
works verbatim.

00:08:16.522 --> 00:08:17.980
Previously, we
worked over Z mod n.

00:08:17.980 --> 00:08:21.388
Now, you work over a
different group, same proof.

00:08:21.388 --> 00:08:25.090
So triangle removal
lemma, it tells you

00:08:25.090 --> 00:08:34.490
that this r3 is always little
o of the size of the space.

00:08:34.490 --> 00:08:35.860
But we would like to do better.

00:08:35.860 --> 00:08:37.710
So this gives you
something like log star.

00:08:37.710 --> 00:08:39.659
It's not very good dependence.

00:08:39.659 --> 00:08:41.820
So we would like to do better.

00:08:41.820 --> 00:08:45.165
So what we will show
today, so this theorem

00:08:45.165 --> 00:08:47.020
is attributed to Meshulam.

00:08:51.010 --> 00:08:54.350
So in this case, the order of
history is somewhat reversed.

00:08:54.350 --> 00:08:57.010
So we'll see the
finite field toy model,

00:08:57.010 --> 00:09:00.020
but it historically
actually came afterwards.

00:09:00.020 --> 00:09:03.950
But you'll see that the Fourier
analytic proof that we'll

00:09:03.950 --> 00:09:08.510
see today, it's basically the
same proof in the two settings.

00:09:08.510 --> 00:09:19.730
So F is r3, we will prove a
bound, well, just like that.

00:09:19.730 --> 00:09:23.990
So much better than what you
get from the regularity method.

00:09:27.470 --> 00:09:28.495
In terms of--

00:09:28.495 --> 00:09:30.620
OK, so let me tell you a
bit more about the history

00:09:30.620 --> 00:09:32.078
of this problem in
terms of what we

00:09:32.078 --> 00:09:35.300
know in terms of upper
bounds and lower bounds.

00:09:40.770 --> 00:09:42.920
So let me say more about F3.

00:09:45.920 --> 00:09:49.200
So what's the best that
you might hope for?

00:09:49.200 --> 00:09:58.350
So the best lower
bound is due to E del.

00:09:58.350 --> 00:10:01.890
And it's some construction,
some very specific construction,

00:10:01.890 --> 00:10:04.590
which gives you a
bound that's something

00:10:04.590 --> 00:10:08.870
like 2.21 to the n-th.

00:10:08.870 --> 00:10:11.470
And the upper bound
is 3 to the n-th--

00:10:11.470 --> 00:10:13.920
on the-- 3 minus
little 1 to the n-th.

00:10:13.920 --> 00:10:25.750
So for a long time, it was
open whether the answer

00:10:25.750 --> 00:10:29.080
should be basically
roughly like 3

00:10:29.080 --> 00:10:33.690
to the n-th or some constant
less than 3 to the n-th.

00:10:33.690 --> 00:10:36.960
And improvements on the
upper bound were very slow,

00:10:36.960 --> 00:10:40.170
and/or some very difficult
works that nudge that down

00:10:40.170 --> 00:10:42.120
below just a little bit.

00:10:42.120 --> 00:10:44.940
And then a couple years
ago, a few years ago, there

00:10:44.940 --> 00:10:48.210
was this incredible
breakthrough,

00:10:48.210 --> 00:10:52.770
where in this paper that was
just a couple pages long,

00:10:52.770 --> 00:10:56.160
they managed to significantly
improve the upper bound

00:10:56.160 --> 00:11:07.030
to basically 2.76 to the n-th.

00:11:07.030 --> 00:11:09.100
So this was an incredible
breakthrough that

00:11:09.100 --> 00:11:11.020
happened just a few years ago.

00:11:11.020 --> 00:11:14.330
And we'll talk about this
proof in a couple of lectures.

00:11:14.330 --> 00:11:17.710
It turns out this proof,
which uses what's now

00:11:17.710 --> 00:11:19.300
called the polynomial method--

00:11:22.030 --> 00:11:24.950
so not Fourier analytic,
but a different method--

00:11:24.950 --> 00:11:28.100
unfortunately does
not seem to generalize

00:11:28.100 --> 00:11:30.580
to the original Roth's theorem.

00:11:30.580 --> 00:11:32.510
In fact, you shouldn't
expect it to generalize

00:11:32.510 --> 00:11:35.610
in a straightforward
way, because up there you

00:11:35.610 --> 00:11:38.630
we know that you do not have a
power saving, whereas here you

00:11:38.630 --> 00:11:39.780
have a power saving.

00:11:39.780 --> 00:11:43.360
So the exponent goes down.

00:11:43.360 --> 00:11:45.690
OK, so this is roughly the
history of this theorem.

00:11:49.150 --> 00:11:50.356
Any questions?

00:11:53.272 --> 00:11:55.216
AUDIENCE: Do we have
to have [INAUDIBLE]??

00:11:55.216 --> 00:11:56.070
YUFEI ZHAO: Yeah.

00:11:56.070 --> 00:12:01.860
So I'll-- So I can tell you this
is known as a Croot-Lev-Pach.

00:12:01.860 --> 00:12:05.050
So I'll say more about
it in a couple lectures.

00:12:05.050 --> 00:12:09.460
But this for F3 is due to
Ellenberg and Gijswijt.

00:12:16.560 --> 00:12:18.780
So I'll tell you more about
it in a couple lectures.

00:12:21.900 --> 00:12:25.860
What I want to focus on today
is the Fourier analytic nature

00:12:25.860 --> 00:12:28.800
of the proof that gives
you this bound up there,

00:12:28.800 --> 00:12:31.080
3 to the n over n.

00:12:31.080 --> 00:12:33.395
And it may seem like a
completely different topic

00:12:33.395 --> 00:12:34.770
compared to what
we've been doing

00:12:34.770 --> 00:12:37.650
so far in the course, which
is more about graph theory.

00:12:37.650 --> 00:12:39.870
But I want you to
think about what

00:12:39.870 --> 00:12:43.590
are the relationships
between what we'll see today

00:12:43.590 --> 00:12:45.280
and what we've seen so far.

00:12:45.280 --> 00:12:46.970
And there are lots
of connections.

00:12:46.970 --> 00:12:48.720
So even though the
proof may superficially

00:12:48.720 --> 00:12:51.120
look quite different,
many of these ideas

00:12:51.120 --> 00:12:54.570
about quasirandomness versus
structure will come up.

00:12:54.570 --> 00:12:57.510
And I want to present the
proof in a way that highlights

00:12:57.510 --> 00:13:00.580
the similarities between
what we did previously

00:13:00.580 --> 00:13:02.320
and this Fourier analytic proof.

00:13:04.980 --> 00:13:07.790
So let's talk
about the strategy.

00:13:10.390 --> 00:13:15.220
In the proof of the SzemerÃ©di
graph regularity lemma,

00:13:15.220 --> 00:13:17.920
we had the strategy that we
called the energy increment

00:13:17.920 --> 00:13:19.590
strategy.

00:13:19.590 --> 00:13:22.012
So you start-- you want
to find a good partition.

00:13:22.012 --> 00:13:23.220
You start doing partitioning.

00:13:23.220 --> 00:13:26.580
And you keep track of this
thing called the energy--

00:13:26.580 --> 00:13:30.700
must go up at every step,
cannot go up forever,

00:13:30.700 --> 00:13:34.220
so has a bounded
number of steps.

00:13:34.220 --> 00:13:38.140
This strategy for Roth's theorem
is also an important strategy.

00:13:38.140 --> 00:13:40.270
It's a variant of
energy increment,

00:13:40.270 --> 00:13:42.256
but now density increment.

00:13:53.930 --> 00:13:56.240
So we start with a set--

00:13:56.240 --> 00:14:00.560
A subset of F3 to
the n-th, and we

00:14:00.560 --> 00:14:02.420
would like to
understand something

00:14:02.420 --> 00:14:07.160
about its structure
versus pseudorandomness

00:14:07.160 --> 00:14:10.040
in a way that is similar
to when we discussed

00:14:10.040 --> 00:14:13.670
the similar issue for graphs.

00:14:13.670 --> 00:14:16.280
In particular, there
will be this dichotomy

00:14:16.280 --> 00:14:24.460
that if A is in some
sense pseudorandom--

00:14:24.460 --> 00:14:28.020
so earlier, we saw what it means
for a graph to be pseudorandom.

00:14:28.020 --> 00:14:30.750
So now, what does it
mean for a subset of F3

00:14:30.750 --> 00:14:33.030
to the n-th to be pseudorandom.

00:14:33.030 --> 00:14:34.440
So we'll address that today.

00:14:34.440 --> 00:14:37.010
If A pseudorandom--

00:14:37.010 --> 00:14:43.470
OK, so the short answer is
that it is Fourier uniform--

00:14:43.470 --> 00:14:48.120
in other words, all
Fourier coefficients small.

00:14:51.220 --> 00:14:53.470
That's what pseudorandom
will refer to.

00:14:53.470 --> 00:14:56.720
So then there is
a counting lemma.

00:15:01.720 --> 00:15:03.760
And the counting lemma
will in particular

00:15:03.760 --> 00:15:07.160
imply that A has lots of 3-APs.

00:15:13.700 --> 00:15:16.880
So then you find your 3-AP.

00:15:16.880 --> 00:15:19.410
If this is not the case, then--

00:15:19.410 --> 00:15:21.890
so what's the opposite
of Fourier uniform--

00:15:21.890 --> 00:15:25.890
is that A now has some
large Fourier coefficient.

00:15:36.190 --> 00:15:39.250
And what we'll do is
to use this Fourier

00:15:39.250 --> 00:15:47.080
coefficient to extract some
codimension 1 affine subspace--

00:15:51.960 --> 00:15:57.420
it's also called a hyperplane--

00:15:57.420 --> 00:16:06.470
where the density of A
goes up significantly,

00:16:06.470 --> 00:16:09.126
if you restrict to
that sub hyperplane.

00:16:14.090 --> 00:16:15.500
And you can repeat this process.

00:16:15.500 --> 00:16:18.920
Now, restrict to this
hyperplane and ask yourself

00:16:18.920 --> 00:16:20.660
the same question.

00:16:20.660 --> 00:16:25.220
Is A, when restricted to this
hyperplane, pseudorandom?

00:16:25.220 --> 00:16:27.830
In which case, we find APs.

00:16:27.830 --> 00:16:31.230
Or is A restricted
to this hyperplane,

00:16:31.230 --> 00:16:33.420
does it have a large
Fourier coefficient?

00:16:33.420 --> 00:16:34.920
In which case, we
restrict further.

00:16:38.400 --> 00:16:42.970
And each time you iterate, you
obtain a density increment.

00:16:42.970 --> 00:16:50.130
And the density increment
cannot go on forever,

00:16:50.130 --> 00:16:53.400
because your total
density is at most 1.

00:16:57.890 --> 00:16:59.860
So the number of
steps must be bounded.

00:17:02.590 --> 00:17:04.290
So that's the strategy.

00:17:04.290 --> 00:17:06.750
So this should remind you
somewhat of the energy

00:17:06.750 --> 00:17:10.210
increment strategy from
SzemerÃ©di's regularity lemma,

00:17:10.210 --> 00:17:12.210
although there are some
fundamental differences.

00:17:12.210 --> 00:17:13.790
We're not doing partitionings.

00:17:16.603 --> 00:17:18.020
Any questions about
this strategy?

00:17:21.470 --> 00:17:23.810
OK.

00:17:23.810 --> 00:17:26.099
I want to tell you
about Fourier analysis.

00:17:34.740 --> 00:17:37.460
So probably, all of you
have seen some version

00:17:37.460 --> 00:17:40.410
of Fourier analysis, maybe
in your calculus class

00:17:40.410 --> 00:17:43.140
with Fourier series and whatnot.

00:17:43.140 --> 00:17:45.690
So you play with formulas,
and solve some differential

00:17:45.690 --> 00:17:46.930
equations.

00:17:46.930 --> 00:17:49.830
So I want to give you
more than just a bunch

00:17:49.830 --> 00:17:53.110
of ways about handling
Fourier coefficients,

00:17:53.110 --> 00:17:55.600
a way to think about
Fourier analysis.

00:17:55.600 --> 00:17:58.920
So think of this as a crash
course about Fourier analysis

00:17:58.920 --> 00:18:01.200
from the perspective
of combinatorics.

00:18:04.002 --> 00:18:05.460
And Fourier analysis,
I think, it's

00:18:05.460 --> 00:18:08.160
much easier if you
work in a finite group,

00:18:08.160 --> 00:18:11.880
in a finite abelian group,
which is what we're doing here.

00:18:11.880 --> 00:18:13.690
Many of the
technicalities go away.

00:18:13.690 --> 00:18:17.960
So we'll be looking specifically
at Fourier analysis in F3

00:18:17.960 --> 00:18:21.840
to the n-th, although
the 3 can be any prime.

00:18:21.840 --> 00:18:24.270
So it's really the same.

00:18:24.270 --> 00:18:29.700
So the main actors
in Fourier analysis

00:18:29.700 --> 00:18:31.293
are the Fourier characters.

00:18:35.370 --> 00:18:39.840
The Fourier characters
are denoted gamma sub r.

00:18:39.840 --> 00:18:42.420
And they're characters
on the group,

00:18:42.420 --> 00:18:45.030
meaning that they
are maps which--

00:18:45.030 --> 00:18:47.850
so they turn out, happen
to be homomorphisms for the

00:18:47.850 --> 00:18:50.520
multiplicative group under--

00:18:50.520 --> 00:18:53.760
so C under multiplication.

00:18:53.760 --> 00:19:02.850
And they're indexed by r,
which also elements of F3

00:19:02.850 --> 00:19:03.510
to the n-th.

00:19:03.510 --> 00:19:05.670
So I'm going to be
fairly concrete here.

00:19:05.670 --> 00:19:07.520
There are ways to do
this more abstractly.

00:19:07.520 --> 00:19:08.880
But I'll be fairly concrete.

00:19:08.880 --> 00:19:12.670
So it's defined by
gamma sub r evaluated

00:19:12.670 --> 00:19:19.470
on x equals to omega raised
to r dot product x, where

00:19:19.470 --> 00:19:24.450
here omega is a
third root of unity

00:19:24.450 --> 00:19:28.060
and the dot is a dot product.

00:19:33.050 --> 00:19:33.550
So--

00:19:42.660 --> 00:19:45.090
So that's the definition
of the Fourier transform--

00:19:45.090 --> 00:19:47.400
sorry, that's the definition
of the Fourier characters.

00:19:47.400 --> 00:19:49.140
And once you have the
Fourier characters,

00:19:49.140 --> 00:19:56.830
you can have this Fourier
transform, just defined

00:19:56.830 --> 00:19:58.010
as follows.

00:19:58.010 --> 00:20:00.086
If you start with a function--

00:20:03.814 --> 00:20:07.540
let's say, a complex-valued
function on your space--

00:20:07.540 --> 00:20:13.550
then I define the
Fourier transform

00:20:13.550 --> 00:20:20.080
to be another function,
like that, defined

00:20:20.080 --> 00:20:22.180
by the following formula.

00:20:34.240 --> 00:20:37.178
So that's the formula for
the Fourier transform.

00:20:40.770 --> 00:20:44.220
It is basically
the inner product

00:20:44.220 --> 00:20:47.520
between F and the
Fourier character.

00:20:47.520 --> 00:20:50.220
So let me make the
comment here, I

00:20:50.220 --> 00:20:52.440
think this is actually a
pretty important comment,

00:20:52.440 --> 00:20:54.003
about the normalization.

00:20:58.350 --> 00:21:03.390
Now, when you first learn
Fourier transforms, usually

00:21:03.390 --> 00:21:07.350
in the reals, there are all
these questions about what

00:21:07.350 --> 00:21:08.730
number to put in the exponent.

00:21:08.730 --> 00:21:09.660
Is it 2 pi?

00:21:09.660 --> 00:21:10.690
Is it root 2 pi?

00:21:10.690 --> 00:21:12.000
Is it some other thing?

00:21:12.000 --> 00:21:17.770
And somehow, one answer
is better than the others.

00:21:17.770 --> 00:21:19.873
And the same thing is
true here in groups.

00:21:19.873 --> 00:21:21.790
So we'll stick with the
following convention--

00:21:21.790 --> 00:21:23.957
and I want all of you to
stick with this convention,

00:21:23.957 --> 00:21:26.320
otherwise, we'll confuse
ourselves to no end--

00:21:26.320 --> 00:21:27.680
is that for a finite group--

00:21:34.940 --> 00:21:36.930
actually, let me,
start of a board.

00:21:36.930 --> 00:21:43.788
So the convention is
that, in a finite group,

00:21:43.788 --> 00:21:46.310
the Fourier transform
is defined--

00:21:46.310 --> 00:21:49.650
and more generally, anything
you do in the physical space,

00:21:49.650 --> 00:21:56.320
we always use the
averaging measure.

00:21:59.590 --> 00:22:02.660
Don't sum, always average
in the physical space.

00:22:02.660 --> 00:22:10.040
And in the frequency
space, always use sums,

00:22:10.040 --> 00:22:12.860
use the counting measure.

00:22:12.860 --> 00:22:14.458
Keep this in mind.

00:22:14.458 --> 00:22:16.250
Any of these questions
about normalization,

00:22:16.250 --> 00:22:17.667
if you stick with
this convention,

00:22:17.667 --> 00:22:19.545
things will become much easier.

00:22:19.545 --> 00:22:21.670
So there won't be any of
these questions about when

00:22:21.670 --> 00:22:23.390
you take the inverse
Fourier transform,

00:22:23.390 --> 00:22:25.750
do I put an extra
factor in front or not,

00:22:25.750 --> 00:22:27.691
if you stick with this
correct convention.

00:22:30.520 --> 00:22:33.580
So with that convention
in mind, what the Fourier

00:22:33.580 --> 00:22:40.510
transform really is is inner
product between F and a Fourier

00:22:40.510 --> 00:22:41.478
character.

00:22:49.810 --> 00:22:51.670
There are some
important properties

00:22:51.670 --> 00:22:52.760
of the Fourier transform.

00:22:52.760 --> 00:22:54.760
So let me go through a
few of the key properties

00:22:54.760 --> 00:22:55.540
that we'll need.

00:23:04.940 --> 00:23:07.970
The first one is pretty easy.

00:23:07.970 --> 00:23:14.250
What is the meaning of the
0-th Fourier coefficient?

00:23:14.250 --> 00:23:24.020
You plug it in, and you see that
it is just the average of F.

00:23:24.020 --> 00:23:27.800
So 0-th coefficient
is the average of F.

00:23:27.800 --> 00:23:32.270
The second fact goes
under one of two names,

00:23:32.270 --> 00:23:34.870
and they're often
used interchangeably--

00:23:34.870 --> 00:23:36.110
Plancherel or Parseval.

00:23:41.340 --> 00:23:48.560
And it says that if you
look at the inner product

00:23:48.560 --> 00:23:57.080
in the physical space,
then this product

00:23:57.080 --> 00:24:02.216
is preserved, if you take
the Fourier transform.

00:24:05.617 --> 00:24:07.700
But now, of course, you're
in the frequency space,

00:24:07.700 --> 00:24:10.070
so you should sum instead
of doing the inner product.

00:24:15.180 --> 00:24:20.490
So this identity can be proved
in a fairly straightforward way

00:24:20.490 --> 00:24:24.360
by plugging in what the
definition is for the Fourier

00:24:24.360 --> 00:24:25.418
transform.

00:24:25.418 --> 00:24:26.960
This is a straightforward
computation

00:24:26.960 --> 00:24:27.850
I'm not going to
do on the board,

00:24:27.850 --> 00:24:29.970
but I highly encourage you
to actually do at home,

00:24:29.970 --> 00:24:33.685
just to do it once to make sure
you understand how it goes.

00:24:33.685 --> 00:24:35.310
But there is also a
more conceptual way

00:24:35.310 --> 00:24:38.410
to understand this identity.

00:24:38.410 --> 00:24:41.490
And that's because--
now, this is also

00:24:41.490 --> 00:24:44.670
important to understand what
the Fourier transform is.

00:24:44.670 --> 00:24:46.980
It's not just some magical
formula somebody wrote down,

00:24:46.980 --> 00:24:50.080
like this is a very
natural operation.

00:24:50.080 --> 00:24:59.280
It's because the characters,
the set of characters,

00:24:59.280 --> 00:25:02.620
is an orthonormal basis.

00:25:02.620 --> 00:25:10.815
So the Fourier characters
form an orthonormal basis.

00:25:15.750 --> 00:25:18.420
As a result, what
the Fourier transform

00:25:18.420 --> 00:25:22.310
is is a unitary change of basis.

00:25:35.510 --> 00:25:36.320
You can check.

00:25:36.320 --> 00:25:37.737
It's very
straightforward to check

00:25:37.737 --> 00:25:39.800
that the Fourier
characters, indeed, form

00:25:39.800 --> 00:25:45.210
a orthonormal basis, because--

00:25:45.210 --> 00:25:51.650
well, you can evaluate the inner
product between two Fourier

00:25:51.650 --> 00:25:53.480
characters.

00:25:53.480 --> 00:25:55.730
So remember, in
the physical space,

00:25:55.730 --> 00:25:57.786
we're always doing averaging.

00:26:01.050 --> 00:26:06.240
And so now, I'll
just write down first

00:26:06.240 --> 00:26:08.310
what I mean by
the inner product.

00:26:11.100 --> 00:26:12.920
So that's the inner product.

00:26:12.920 --> 00:26:21.977
And by the definition of
the Fourier character,

00:26:21.977 --> 00:26:22.560
you have that.

00:26:25.410 --> 00:26:29.010
So think about what
this expectation is--

00:26:29.010 --> 00:26:37.470
unless r equals to s, in which
case, this expectation is 1.

00:26:37.470 --> 00:26:39.240
Unless that is the
case, you always

00:26:39.240 --> 00:26:43.360
have some coordinate
of x in the exponent.

00:26:43.360 --> 00:26:46.230
So as you average over
all possibilities,

00:26:46.230 --> 00:26:47.270
they average out to 0.

00:26:58.020 --> 00:27:01.050
So this calculation shows you
that the Fourier characters

00:27:01.050 --> 00:27:02.880
form a orthonormal basis.

00:27:02.880 --> 00:27:05.910
And a basic fact you
know from linear algebra

00:27:05.910 --> 00:27:07.470
is that if you do
a change of basis,

00:27:07.470 --> 00:27:10.510
if you do a unitary
change of basis,

00:27:10.510 --> 00:27:13.640
then inner product is preserved.

00:27:13.640 --> 00:27:15.430
It's like a rotation.

00:27:15.430 --> 00:27:18.150
It's the same-- so you're not
changing the inner product.

00:27:18.150 --> 00:27:19.660
So the inner
product is preserved

00:27:19.660 --> 00:27:21.640
under this change of basis.

00:27:21.640 --> 00:27:24.280
And that's why
Plancherel is true.

00:27:27.780 --> 00:27:30.870
Another important
thing is what's

00:27:30.870 --> 00:27:34.684
known as the Fourier
inversion formula.

00:27:34.684 --> 00:27:39.720
The Fourier transform tells
you how to go from a function

00:27:39.720 --> 00:27:42.730
to the Fourier transform.

00:27:42.730 --> 00:27:46.020
Well, now, if you are given
the Fourier transform,

00:27:46.020 --> 00:27:48.090
how do you go back?

00:27:48.090 --> 00:27:50.040
There's a formula
which tells you

00:27:50.040 --> 00:28:01.350
that you can go back by the
following formula there.

00:28:01.350 --> 00:28:04.370
So that's the Fourier
inversion formula.

00:28:04.370 --> 00:28:07.110
It allows you to
do this inversion.

00:28:07.110 --> 00:28:09.540
And again, it's one of
these formulas where

00:28:09.540 --> 00:28:12.990
I encourage you to try it
out yourself by plugging

00:28:12.990 --> 00:28:16.770
in the formula and expanding.

00:28:16.770 --> 00:28:19.660
And it's pretty easy to check.

00:28:19.660 --> 00:28:22.090
It's much easier in the finite
field setting, by the way.

00:28:22.090 --> 00:28:25.630
So if you use the usual Fourier
transform on the real line,

00:28:25.630 --> 00:28:27.070
there are some
technicalities even

00:28:27.070 --> 00:28:28.690
to prove the Fourier inversion.

00:28:28.690 --> 00:28:31.070
But in finite groups,
it's almost trivial.

00:28:31.070 --> 00:28:33.170
You expand, and then you'll see.

00:28:33.170 --> 00:28:35.025
So it's very easy to prove.

00:28:35.025 --> 00:28:37.150
But you can also see this
Fourier inversion formula

00:28:37.150 --> 00:28:39.040
more conceptually,
because you're

00:28:39.040 --> 00:28:41.550
in a unitary change of basis.

00:28:41.550 --> 00:28:45.300
So to go back, well, think about
what it means in linear algebra

00:28:45.300 --> 00:28:48.990
to revert a unitary
transformation.

00:28:48.990 --> 00:28:52.530
You simply multiply
the coefficients

00:28:52.530 --> 00:28:56.490
with the coordinates.

00:28:56.490 --> 00:29:00.335
Orthogonal, orthonormal
change of basis.

00:29:00.335 --> 00:29:06.430
Finally, Fourier
transform behaves while

00:29:06.430 --> 00:29:07.900
under convolution.

00:29:07.900 --> 00:29:15.430
So by convolution, we
define the convolution

00:29:15.430 --> 00:29:19.320
of two functions, f and g,
using the following formula.

00:29:27.510 --> 00:29:38.090
And so then the claim is that
the Fourier transform behaves

00:29:38.090 --> 00:29:39.800
very well under convolution.

00:29:39.800 --> 00:29:44.250
It's basically multiplicative
under convolution.

00:29:44.250 --> 00:29:45.860
So what this means
is, if I put in--

00:29:50.490 --> 00:29:54.670
so it's pointwise
true everywhere.

00:29:54.670 --> 00:29:59.590
Again, very easy proof, because
I just evaluate the left hand

00:29:59.590 --> 00:30:04.850
side, see what--

00:30:04.850 --> 00:30:07.730
plug in the formula for
the Fourier transform.

00:30:07.730 --> 00:30:16.170
And I find it's that.

00:30:16.170 --> 00:30:19.268
And now, I plug in the
formula for convolution.

00:30:40.450 --> 00:30:45.140
So now, you can do a
change of variables.

00:30:45.140 --> 00:30:48.865
And then you-- it's
not hard to see.

00:30:48.865 --> 00:30:50.740
You eventually end up
at the right hand side.

00:30:54.760 --> 00:30:56.260
So these are some
of the properties.

00:30:56.260 --> 00:30:58.658
So there are
important properties

00:30:58.658 --> 00:30:59.700
of the Fourier transform.

00:30:59.700 --> 00:31:01.743
So this is something
that, whenever

00:31:01.743 --> 00:31:03.160
you learn about
Fourier transform,

00:31:03.160 --> 00:31:06.720
you always see these
few properties.

00:31:06.720 --> 00:31:08.230
And so we'll use them.

00:31:08.230 --> 00:31:10.690
But we'll also need
another property

00:31:10.690 --> 00:31:14.440
that is specific to the
analysis of 3-term arithmetic

00:31:14.440 --> 00:31:15.410
progressions.

00:31:17.990 --> 00:31:22.165
So what does Fourier transform
have to do with 3-APs?

00:31:22.165 --> 00:31:24.040
So we want to use it to
prove Roth's theorem.

00:31:24.040 --> 00:31:27.400
So we better have
some tool that allows

00:31:27.400 --> 00:31:29.330
us to analyze the number 3-APs.

00:31:29.330 --> 00:31:45.250
And here is a key identity
relating Fourier with 3-APs.

00:31:45.250 --> 00:31:56.410
And it's that, if you
have three functions,

00:31:56.410 --> 00:32:02.920
then the following quantity,
which relates the number

00:32:02.920 --> 00:32:06.840
of 3-APs--

00:32:14.880 --> 00:32:18.720
So this function basically
counts the number 3-APs,

00:32:18.720 --> 00:32:21.500
if your f, g, and h are
indicator functions of a set.

00:32:24.240 --> 00:32:27.960
I want to express this formula
in terms of the Fourier

00:32:27.960 --> 00:32:29.835
transforms of these functions.

00:32:32.550 --> 00:32:35.880
The formula turns out
to be fairly simple,

00:32:35.880 --> 00:32:45.970
that it is simply that.

00:32:45.970 --> 00:32:50.190
So it's a single sum
over the r's of f hat

00:32:50.190 --> 00:32:55.240
of r, g hat of minus
2r, and h hat of r.

00:32:55.240 --> 00:32:57.880
You might wonder why I put a
minus 2 here, because minus 2

00:32:57.880 --> 00:33:00.520
is r, and it looks
certainly much nicer

00:33:00.520 --> 00:33:02.212
with just r in there.

00:33:02.212 --> 00:33:05.080
And that is true.

00:33:05.080 --> 00:33:08.170
This formula as written is
true for over any group.

00:33:13.940 --> 00:33:16.340
And our proof will show it.

00:33:16.340 --> 00:33:18.560
So it's not really about
F3 at all, but any group.

00:33:25.300 --> 00:33:29.880
So let me prove this for you
in a couple of different ways.

00:33:29.880 --> 00:33:39.520
So the first proof is
basically a straightforward no

00:33:39.520 --> 00:33:46.240
thinking involved proof, as
in we apply these formula

00:33:46.240 --> 00:33:48.250
for using either
Fourier inversion

00:33:48.250 --> 00:33:53.820
or the inverse Fourier
transform, and plug it in,

00:33:53.820 --> 00:33:56.545
and expand, and check.

00:33:56.545 --> 00:33:58.170
So it's worth doing
at least this once.

00:33:58.170 --> 00:34:01.980
So let's do this
together at least once.

00:34:01.980 --> 00:34:04.420
But this something that is
a fairly straightforward

00:34:04.420 --> 00:34:05.580
computation.

00:34:05.580 --> 00:34:10.900
The left hand side
can be expanded

00:34:10.900 --> 00:34:12.340
using Fourier inversion.

00:34:14.920 --> 00:34:21.389
so r1 f hat r1 omega
to the minus r1

00:34:21.389 --> 00:34:32.280
dot x, and sum over r2 g
hat r2 omega to the minus r2

00:34:32.280 --> 00:34:38.199
dot x plus y, and
then finally sum

00:34:38.199 --> 00:34:47.550
over r3 h hat of r3 omega to
the minus r3 dot x plus 2y.

00:34:50.989 --> 00:34:54.770
So I'm using Fourier
inversion, replace f, g, and h

00:34:54.770 --> 00:34:58.800
by their Fourier transforms.

00:34:58.800 --> 00:35:02.280
Oh, sorry, there should be--

00:35:02.280 --> 00:35:03.800
yeah, so no minus.

00:35:06.960 --> 00:35:10.620
So now, we exchange
sums and expectations,

00:35:10.620 --> 00:35:18.265
do a switch in the order of
summation, so r1, r2, r3 and f

00:35:18.265 --> 00:35:27.050
hat of r1 g hat
of r2 h hat of r3.

00:35:27.050 --> 00:35:33.860
And you have this expectation
over x and y and omega

00:35:33.860 --> 00:35:37.970
of x dot r1 plus r2 plus r3.

00:35:40.610 --> 00:35:45.340
In fact, I can even write
the x and y separately,

00:35:45.340 --> 00:35:57.180
y omega to the y
dot r2 plus 2r3.

00:35:57.180 --> 00:35:59.540
So just rearranging.

00:35:59.540 --> 00:36:01.570
And now, you see
that as you take

00:36:01.570 --> 00:36:09.110
expectation over x, this
expectation is equal to 1,

00:36:09.110 --> 00:36:19.130
if r1 plus r2 plus r3 is
equal to 0, and 0 otherwise.

00:36:19.130 --> 00:36:23.930
And likewise, the third
expectation is either 1 or 0,

00:36:23.930 --> 00:36:28.610
depending on the
sums of r2 and r3.

00:36:33.650 --> 00:36:36.760
So the only terms that
remain, after you take out

00:36:36.760 --> 00:36:43.920
these 0's, are cases where
both these two equations

00:36:43.920 --> 00:36:44.730
are satisfied.

00:36:47.350 --> 00:36:55.150
And then you see that the only
remaining terms are basically

00:36:55.150 --> 00:37:02.410
the ones given in the sum
on the right hand side.

00:37:05.410 --> 00:37:06.000
OK?

00:37:06.000 --> 00:37:07.930
So that's the proof.

00:37:07.930 --> 00:37:10.363
Pretty straightforward, you
plug in Fourier inversion.

00:37:13.540 --> 00:37:17.073
I want to show you a
different proof that

00:37:17.073 --> 00:37:19.240
hopefully will be more
familiar and more conceptual.

00:37:19.240 --> 00:37:21.657
Now, it doesn't involve carrying
through this calculation,

00:37:21.657 --> 00:37:26.380
even though this is not
at all hard calculation.

00:37:26.380 --> 00:37:31.610
But first, let me rewrite
the formula up there.

00:37:31.610 --> 00:37:37.000
So in F3, it will be
convenient, and so

00:37:37.000 --> 00:37:39.190
the formula is actually
slightly easier

00:37:39.190 --> 00:37:42.700
to interpreting F3,
in F3, the identity

00:37:42.700 --> 00:37:47.110
says that, if you
look at the quantity--

00:37:52.460 --> 00:37:53.020
I need.

00:37:58.732 --> 00:38:04.293
So let me give you a second
proof that works just in F3,

00:38:04.293 --> 00:38:06.210
but you can modify it
to work in other groups.

00:38:06.210 --> 00:38:08.950
But in F3, it's
particularly nice.

00:38:08.950 --> 00:38:14.240
The left hand side, you
see, the left hand side,

00:38:14.240 --> 00:38:21.980
I can rewrite it as
the following form,

00:38:21.980 --> 00:38:24.840
where I sum over--

00:38:24.840 --> 00:38:29.430
well, I take expectation over
all triples x, y, z that sum

00:38:29.430 --> 00:38:29.930
to 0.

00:38:32.600 --> 00:38:36.470
Because a 3-AP is the
same as three elements,

00:38:36.470 --> 00:38:38.720
three points in the
vector space summing to 0.

00:38:41.830 --> 00:38:46.000
But now, you see
that this quantity

00:38:46.000 --> 00:38:54.310
is the same as the
convolution evaluated at 0--

00:38:57.640 --> 00:39:00.610
so if you extend the definition
of convolution to more than one

00:39:00.610 --> 00:39:03.630
func-- more than two functions.

00:39:03.630 --> 00:39:05.540
But now, we apply
Fourier inversion.

00:39:09.650 --> 00:39:11.540
And we find that--

00:39:21.780 --> 00:39:22.660
OK.

00:39:22.660 --> 00:39:26.940
So by Fourier inversion,
you have that.

00:39:26.940 --> 00:39:30.700
But now, by the identity that
relates the Fourier transform

00:39:30.700 --> 00:39:41.560
and inversion, you have that.

00:39:41.560 --> 00:39:45.410
And that's the proof, because
minus 2 r is the same as r.

00:39:48.470 --> 00:39:52.100
So it's shorter, because we're
using some properties here

00:39:52.100 --> 00:39:54.310
about convolution and--

00:39:54.310 --> 00:39:56.229
yeah, so about the convolution.

00:40:03.720 --> 00:40:05.580
That formula up
there is, of course,

00:40:05.580 --> 00:40:07.530
related to counting 3-APs.

00:40:07.530 --> 00:40:22.080
Because if f, g, and h are
all indicators of some set,

00:40:22.080 --> 00:40:25.710
then the left hand
side is the same

00:40:25.710 --> 00:40:35.535
as basically the number of
triples of elements in A

00:40:35.535 --> 00:40:38.940
whose sum is equal to 0.

00:40:42.210 --> 00:40:46.680
And the right hand
side is the sum

00:40:46.680 --> 00:40:52.184
of the third power of
the Fourier coefficients.

00:40:56.360 --> 00:40:59.980
And this formula should
look somewhat familiar,

00:40:59.980 --> 00:41:03.940
because we also used
this kind of formula

00:41:03.940 --> 00:41:07.610
back when we discussed
spectral graph theory.

00:41:07.610 --> 00:41:11.350
And remember, the third
moment of the eigenvalues

00:41:11.350 --> 00:41:16.330
is the trace of the third
power, which counts closed

00:41:16.330 --> 00:41:18.880
walks in Cayley graph.

00:41:18.880 --> 00:41:21.100
So this is actually
the same formula.

00:41:21.100 --> 00:41:26.210
So in the case if
A is symmetric,

00:41:26.210 --> 00:41:34.460
let's say, then this is
the same as the formula

00:41:34.460 --> 00:41:47.530
that counts closed
walks of length three

00:41:47.530 --> 00:41:48.660
in the Cayley graph.

00:41:53.945 --> 00:41:55.820
The point of this comment
is just to tell you

00:41:55.820 --> 00:41:57.440
that Fourier
transform is somehow

00:41:57.440 --> 00:42:02.160
it's not this brand new concept
that we've never seen before.

00:42:02.160 --> 00:42:04.400
It is intimately tied
to many of the things

00:42:04.400 --> 00:42:08.866
that we have seen earlier in
this course but in disguise.

00:42:08.866 --> 00:42:11.390
So it is related to the
spectral graph theory

00:42:11.390 --> 00:42:13.640
that we discussed at length
earlier in this course.

00:42:21.290 --> 00:42:23.080
Now that we have the
Fourier transform,

00:42:23.080 --> 00:42:28.420
I want to develop some
machinery to prove

00:42:28.420 --> 00:42:32.930
Roth's theorem following
the strategy up there.

00:42:32.930 --> 00:42:34.100
So let's take a quick break.

00:42:34.100 --> 00:42:36.392
And then when we come back,
we'll prove Roth's theorem.

00:42:40.570 --> 00:42:41.500
Any questions so far?

00:42:45.204 --> 00:42:50.596
AUDIENCE: So for
this one, you said--

00:42:50.596 --> 00:42:53.150
is it like we only
used the fact that it's

00:42:53.150 --> 00:42:57.255
F3 to the n-th at the end of the
proof, like in that last step?

00:42:57.255 --> 00:42:57.880
YUFEI ZHAO: OK.

00:42:57.880 --> 00:43:01.040
So question is, where do we
use that in F3 to the n-th?

00:43:01.040 --> 00:43:04.970
This formula here holds in
every finite abelian group,

00:43:04.970 --> 00:43:07.190
if you use the correct
definition of Fourier

00:43:07.190 --> 00:43:10.240
transform with the
averaging normalization.

00:43:10.240 --> 00:43:15.020
So in the other formula where
you replace minus 2 by 1,

00:43:15.020 --> 00:43:17.890
that requires F3.

00:43:17.890 --> 00:43:18.850
But you can--

00:43:18.850 --> 00:43:22.280
I mean, you can follow
the proof and come up

00:43:22.280 --> 00:43:27.080
with a similar formula
for every equation.

00:43:27.080 --> 00:43:28.580
So there's a general
principle here,

00:43:28.580 --> 00:43:30.600
which I'll discuss
more at length

00:43:30.600 --> 00:43:34.120
in a bit, that for
patterns that are

00:43:34.120 --> 00:43:36.760
governed by a single equation--

00:43:36.760 --> 00:43:41.260
in this case, 3-APs, x
minus 2y plus z equal to 0--

00:43:41.260 --> 00:43:43.900
patterns that can be
governed by a single equation

00:43:43.900 --> 00:43:46.196
can be controlled by
a Fourier transform.

00:43:49.770 --> 00:43:53.210
So let's begin our proof,
the Fourier analytic proof

00:43:53.210 --> 00:43:55.636
of Roth's theorem
in F3 to the n-th.

00:43:55.636 --> 00:43:57.695
AUDIENCE: So at
the end, you said

00:43:57.695 --> 00:43:59.445
it was going to be
connected with counting

00:43:59.445 --> 00:44:00.362
the [INAUDIBLE] graph.

00:44:00.362 --> 00:44:03.045
Does this mean that
the Fourier transform

00:44:03.045 --> 00:44:06.982
of the indicator of A, those
are exactly the eigenvalues

00:44:06.982 --> 00:44:08.304
of the Cayley graph?

00:44:08.304 --> 00:44:09.387
Or is it like [INAUDIBLE]?

00:44:09.387 --> 00:44:12.050
YUFEI ZHAO: OK, so you're asking
about the final step, where

00:44:12.050 --> 00:44:13.505
we're talking about--

00:44:13.505 --> 00:44:15.380
so I mentioned that
there was this connection

00:44:15.380 --> 00:44:18.170
between counting walks in graphs
and spectral graph theory.

00:44:18.170 --> 00:44:27.230
So you can check that, if you
have a subset A of an abelian

00:44:27.230 --> 00:44:31.840
group, then the
Fourier transforms of A

00:44:31.840 --> 00:44:39.180
are exactly the eigenvalues
of the Cayley graph.

00:44:44.090 --> 00:44:46.350
AUDIENCE: So then
I guess, have we

00:44:46.350 --> 00:44:48.810
done anything so far
that could have been done

00:44:48.810 --> 00:44:50.950
in a spectral way yet?

00:44:50.950 --> 00:44:54.190
Well, I guess, where is
the Fourier analysis better

00:44:54.190 --> 00:44:55.555
than the spectral [INAUDIBLE]?

00:44:55.555 --> 00:44:56.280
YUFEI ZHAO: OK.

00:44:56.280 --> 00:44:57.950
Question, where is
the Fourier analysis

00:44:57.950 --> 00:44:59.130
better than the spectral posts?

00:44:59.130 --> 00:45:00.170
Well, let's see the proof first.

00:45:00.170 --> 00:45:01.520
And then you'll see, yeah.

00:45:01.520 --> 00:45:03.470
So there's no graphs anymore.

00:45:03.470 --> 00:45:05.535
So we're going to work
inside F3 to the n-th.

00:45:08.270 --> 00:45:10.528
But just like the proof
of regularity in counting,

00:45:10.528 --> 00:45:12.070
we're going to have
a counting lemma.

00:45:12.070 --> 00:45:14.240
So all of these are analytic.

00:45:14.240 --> 00:45:19.243
And at this point, they should
be very familiar to you.

00:45:19.243 --> 00:45:20.660
They may come in
a different form.

00:45:20.660 --> 00:45:22.790
They may be dressed
in different clothing.

00:45:22.790 --> 00:45:24.738
But it's still a counting lemma.

00:45:24.738 --> 00:45:25.280
So let's see.

00:45:34.360 --> 00:45:36.190
The counting lemma,
in this case,

00:45:36.190 --> 00:45:44.170
says that if you are in the
setting of A F3 to the n-th--

00:45:44.170 --> 00:45:47.470
and I'm going to
throughout write

00:45:47.470 --> 00:45:56.460
the density of A as
alpha, then let me write,

00:45:56.460 --> 00:46:06.420
let me define this lambda 3
of A to be the function which

00:46:06.420 --> 00:46:17.470
basically counts 3-APs in
A but with the averaging

00:46:17.470 --> 00:46:18.762
normalization.

00:46:21.660 --> 00:46:23.590
So this is-- we
saw this earlier.

00:46:26.550 --> 00:46:33.550
So the counting lemma says that
this normalized number of 3-APs

00:46:33.550 --> 00:46:34.900
in A--

00:46:34.900 --> 00:46:37.970
so including trivial 3-APs;
that's why this is a nice

00:46:37.970 --> 00:46:39.650
analytic expression--

00:46:39.650 --> 00:46:46.490
differs from what you might
guess based on density alone.

00:46:46.490 --> 00:46:50.960
This difference should be small
if all the nonzero Fourier

00:46:50.960 --> 00:46:53.920
coefficients of A are small.

00:47:04.190 --> 00:47:07.330
So in this strategy, I said
that if-- so the counting

00:47:07.330 --> 00:47:10.330
lemma tells you, if
A is Fourier uniform,

00:47:10.330 --> 00:47:11.550
then it is pseudorandom.

00:47:11.550 --> 00:47:13.630
And this is where it comes in.

00:47:13.630 --> 00:47:16.940
If A has all small
Fourier coefficients,

00:47:16.940 --> 00:47:19.890
then you have a counting
lemma, which tells you

00:47:19.890 --> 00:47:21.810
that the counts
of A should not be

00:47:21.810 --> 00:47:25.980
so different from the
guess based on density.

00:47:34.290 --> 00:47:36.880
So the proof is very short.

00:47:36.880 --> 00:47:41.310
It's based on the identity
that we saw earlier.

00:47:41.310 --> 00:47:47.040
The 3-AP count of A by
the identity earlier

00:47:47.040 --> 00:47:51.890
is simply the third power
of the Fourier transforms.

00:47:55.180 --> 00:47:58.585
And all of these calculations
should be reminiscent,

00:47:58.585 --> 00:48:00.460
because we've done these
kind of calculations

00:48:00.460 --> 00:48:03.460
in some form or another
earlier in this course.

00:48:03.460 --> 00:48:06.370
So we're going to
separate out the main term

00:48:06.370 --> 00:48:07.690
and subsequent terms.

00:48:07.690 --> 00:48:13.750
So the main term is the one
corresponding to r equals to 0.

00:48:13.750 --> 00:48:15.970
So that's the density.

00:48:15.970 --> 00:48:18.640
And all the other
terms I'm going

00:48:18.640 --> 00:48:24.310
to lump together into this sum.

00:48:24.310 --> 00:48:33.610
So we now know
that the difference

00:48:33.610 --> 00:48:36.850
we're trying to bound
is upper bounded

00:48:36.850 --> 00:48:47.850
by the third moment of the
absolute values of the Fourier

00:48:47.850 --> 00:48:50.730
transform.

00:48:50.730 --> 00:48:53.040
And I want to upper
bound this quantity here,

00:48:53.040 --> 00:48:58.320
assuming that all of these
Fourier coefficients are small.

00:48:58.320 --> 00:49:00.540
We've also done this kind
of calculations before.

00:49:00.540 --> 00:49:01.957
So where have we
seen this before?

00:49:06.310 --> 00:49:08.240
We saw this calculation
earlier in the class

00:49:08.240 --> 00:49:09.700
with the 3 replaced by a 4.

00:49:15.640 --> 00:49:18.160
So in counting four cycles
in a proof equivalent

00:49:18.160 --> 00:49:21.940
of quasirandomness, we said
that, if all the eigenvalues

00:49:21.940 --> 00:49:24.010
other than the top
one are small, then

00:49:24.010 --> 00:49:26.980
you can count four cycles.

00:49:26.980 --> 00:49:28.320
It's the same proof.

00:49:28.320 --> 00:49:30.370
And remember, in
that proof, there

00:49:30.370 --> 00:49:34.510
was a important trick,
where you do not uniformly

00:49:34.510 --> 00:49:38.470
bound each term by the
max, because then you lose.

00:49:38.470 --> 00:49:40.900
You lose by an extra factor
of n that you don't want.

00:49:40.900 --> 00:49:45.100
So you only take out one factor.

00:49:45.100 --> 00:49:47.260
So you take out one factor.

00:49:53.840 --> 00:49:56.900
And you keep the rest in there.

00:49:56.900 --> 00:49:59.980
In fact, I can be
more generous and even

00:49:59.980 --> 00:50:02.860
throw the r equal
to 0 term back in.

00:50:06.460 --> 00:50:10.950
And now, by Plancherel--

00:50:10.950 --> 00:50:15.290
so by Plancherel/Parseval,
this here

00:50:15.290 --> 00:50:22.740
is equal to the expectation
of the indicator

00:50:22.740 --> 00:50:23.910
function of A squared.

00:50:23.910 --> 00:50:25.775
So you take this--

00:50:25.775 --> 00:50:30.170
you go back to physical space,
and that's simply the density.

00:50:30.170 --> 00:50:33.710
So then that proves the theorem.

00:50:39.175 --> 00:50:41.550
So the moral of the counting
lemma is the same as the one

00:50:41.550 --> 00:50:43.550
that we've seen before
when we discussed graphs.

00:50:43.550 --> 00:50:46.440
If you're in pseudorandom,
then you have good counting.

00:50:46.440 --> 00:50:49.890
And here, pseudorandom
means having small Fourier

00:50:49.890 --> 00:50:55.040
coefficients, uniformly
small Fourier coefficients.

00:50:55.040 --> 00:50:57.890
So now, let's begin the
proof of Roth's theorem.

00:50:57.890 --> 00:51:01.858
The Roth's theorem proof
will have three steps.

00:51:01.858 --> 00:51:08.455
The first step, we will
observe that if you're

00:51:08.455 --> 00:51:14.700
in the 3-AP-free set, then
there exists a large Fourier

00:51:14.700 --> 00:51:15.731
coefficient.

00:51:26.050 --> 00:51:28.990
Throughout, I'm going to
use uppercase N to denote

00:51:28.990 --> 00:51:32.620
the size of the ambient group.

00:51:32.620 --> 00:51:36.560
And specifically, we
will prove the following.

00:51:36.560 --> 00:51:41.320
And also throughout, A is
a subset of F3 to the n-th

00:51:41.320 --> 00:51:45.075
and with density alpha.

00:51:45.075 --> 00:51:47.420
So I'll keep this convention
throughout this proof.

00:51:50.380 --> 00:52:05.230
We will show that if A is
3-AP-free and N is at least 2

00:52:05.230 --> 00:52:09.030
to the alpha to the minus 2--

00:52:09.030 --> 00:52:11.680
so N is at least
somewhat large--

00:52:11.680 --> 00:52:16.750
then there exists
a nonzero r such

00:52:16.750 --> 00:52:23.230
that the r-th Fourier
coefficient is at least alpha

00:52:23.230 --> 00:52:24.520
squared over 2.

00:52:27.450 --> 00:52:30.900
If you're 3-AP-free,
free then provided

00:52:30.900 --> 00:52:34.290
that you're working in a
large enough ambient space,

00:52:34.290 --> 00:52:37.763
you always have some
large Fourier coefficient.

00:52:40.601 --> 00:52:43.720
So the proof is
essentially-- well,

00:52:43.720 --> 00:52:50.213
this claim is essentially a
corollary of counting lemma,

00:52:50.213 --> 00:52:51.130
by the counting lemma.

00:52:54.820 --> 00:52:57.860
And using the fact
that in a 3-AP-free

00:52:57.860 --> 00:53:02.611
set, what is the
quantity lambda 3 of A?

00:53:02.611 --> 00:53:08.170
Up there, you only have
the trivial 3-APs present.

00:53:08.170 --> 00:53:11.590
So this quantity
lambda must then

00:53:11.590 --> 00:53:17.770
be the size of A divided by N
squared or alpha over N, which

00:53:17.770 --> 00:53:22.100
are precisely counting
the trivial 3-APs.

00:53:26.040 --> 00:53:28.220
So by the counting
lemma, then we

00:53:28.220 --> 00:53:32.540
have that the upper
bound on the right hand

00:53:32.540 --> 00:53:43.120
side, which we now write
alpha max over nonzero r's, is

00:53:43.120 --> 00:53:49.840
at least alpha cubed minus
the lambda 3 term, which

00:53:49.840 --> 00:53:55.370
should be alpha
over N. So provided

00:53:55.370 --> 00:53:57.380
that N is large enough--

00:53:57.380 --> 00:53:58.890
big N is large enough--

00:53:58.890 --> 00:54:02.450
then the trivial 3-APs should
not contribute very much.

00:54:02.450 --> 00:54:06.770
So I can lower bound the
right hand side by, let's say,

00:54:06.770 --> 00:54:07.570
alpha 3--

00:54:07.570 --> 00:54:10.020
alpha cubed over 2.

00:54:10.020 --> 00:54:13.945
So then you deduce
the conclusion.

00:54:13.945 --> 00:54:16.070
I want you to think about
how this proof is related

00:54:16.070 --> 00:54:19.270
to SzemerÃ©di's graph
regularity lemma.

00:54:19.270 --> 00:54:21.020
The analogy will break
down at some point.

00:54:21.020 --> 00:54:23.780
But we've seen this
step before as well.

00:54:23.780 --> 00:54:30.050
From lack of 3-APs, you
extract some useful information

00:54:30.050 --> 00:54:32.980
and from this will
extract some structure.

00:54:32.980 --> 00:54:34.430
And the structure here--

00:54:34.430 --> 00:54:36.590
and this is where the
proof now diverges

00:54:36.590 --> 00:54:40.190
from that of regularity--

00:54:40.190 --> 00:54:46.540
having a large
Fourier coefficient

00:54:46.540 --> 00:54:56.946
will now imply a density
increment on a hyperplane.

00:55:04.730 --> 00:55:06.950
Specifically, if you have--

00:55:11.390 --> 00:55:15.070
so keeping the same
convention as before,

00:55:15.070 --> 00:55:21.100
if the Fourier
coefficient of A at r

00:55:21.100 --> 00:55:29.310
is at least delta
for some nonzero r,

00:55:29.310 --> 00:55:42.160
then A has density at least
alpha plus delta over 2

00:55:42.160 --> 00:55:44.460
when restricted to a hyperplane.

00:55:55.280 --> 00:55:57.640
So if you have a large
Fourier coefficient,

00:55:57.640 --> 00:56:00.730
then I can pass down to a
smaller part of the space

00:56:00.730 --> 00:56:03.518
where the density of A
goes up significantly.

00:56:10.210 --> 00:56:11.980
To see why this is
true, let's go back

00:56:11.980 --> 00:56:15.910
to the definition of the
Fourier coefficient, the Fourier

00:56:15.910 --> 00:56:16.510
transform.

00:56:19.120 --> 00:56:25.040
So recall that Fourier transform
is given by the following

00:56:25.040 --> 00:56:32.030
formula, where I'm looking at
this expectation over points

00:56:32.030 --> 00:56:39.610
in F3 to the n-th together
with indicator of A multiplied

00:56:39.610 --> 00:56:43.840
by this Fourier character.

00:56:43.840 --> 00:56:49.840
And you see that this
function here, it

00:56:49.840 --> 00:57:01.090
is constant on cosets of
the hyperplane defined

00:57:01.090 --> 00:57:06.930
by the orthogonal
complement of r.

00:57:10.400 --> 00:57:14.550
So the value of this dot
product is this constant

00:57:14.550 --> 00:57:17.780
on the three hyperplanes.

00:57:17.780 --> 00:57:22.130
So I can rewrite this
expectation simply

00:57:22.130 --> 00:57:28.010
as 1/3 of alpha 0
plus alpha 1 omega

00:57:28.010 --> 00:57:37.220
plus alpha 2 omega squared,
where alpha 0, alpha 1, alpha 2

00:57:37.220 --> 00:57:48.451
are the densities of A on
the three cosets of r perp.

00:57:52.139 --> 00:57:56.697
So group this expectation
into these three hyperplanes.

00:57:59.320 --> 00:58:05.300
So now, you see that
if this guy is large,

00:58:05.300 --> 00:58:12.570
then you should expect that
alpha 0, alpha 1, and alpha 2

00:58:12.570 --> 00:58:15.550
are not all too
close to each other.

00:58:15.550 --> 00:58:19.260
So if they were all equal to
each other, you should get 0.

00:58:19.260 --> 00:58:22.380
But you should not expect them
to be too close to each other.

00:58:22.380 --> 00:58:27.150
In particular, we would want to
say that one of them goes up--

00:58:27.150 --> 00:58:29.520
is much bigger than alpha.

00:58:29.520 --> 00:58:32.730
So one of these, they must
be much bigger than alpha.

00:58:32.730 --> 00:58:34.230
That's an elementary inequality.

00:58:34.230 --> 00:58:36.522
This is something that I'm
sure I give you five minutes

00:58:36.522 --> 00:58:37.320
you can figure out.

00:58:37.320 --> 00:58:41.170
But let me show you a
small trick to show this.

00:58:41.170 --> 00:58:46.200
And the reason for this trick
is because in next lecture, when

00:58:46.200 --> 00:58:48.900
we look at Roth's theorem
over the integers,

00:58:48.900 --> 00:58:50.220
we'll need this extra trick.

00:58:55.290 --> 00:58:56.850
And the trick here is this.

00:58:56.850 --> 00:59:01.560
We now know that because
of the hypothesis,

00:59:01.560 --> 00:59:08.430
3 delta is lower bound to
the absolute value of alpha 0

00:59:08.430 --> 00:59:12.240
plus alpha 1 omega plus
alpha 2 omega squared.

00:59:16.010 --> 00:59:21.680
OK, so note here that the
average of the three alphas

00:59:21.680 --> 00:59:28.840
is equal to the original alpha
by definition of density.

00:59:28.840 --> 00:59:35.430
So this inner sum I can
read write like that.

00:59:44.620 --> 00:59:46.900
So the sum of the three
groups of unity add up to 0.

00:59:49.410 --> 01:00:02.260
And now, I apply
triangle inequality

01:00:02.260 --> 01:00:06.220
to extract the terms.

01:00:06.220 --> 01:00:07.820
So now, you should
already deduce

01:00:07.820 --> 01:00:12.080
that one of the alphas i's
has to be significantly

01:00:12.080 --> 01:00:14.157
larger than alpha.

01:00:14.157 --> 01:00:15.740
And has to be
significantly different,

01:00:15.740 --> 01:00:16.730
but there are only three times.

01:00:16.730 --> 01:00:18.620
One of them has to be
significantly larger.

01:00:18.620 --> 01:00:21.590
But let me do this
one extra trick, which

01:00:21.590 --> 01:00:24.740
we'll need next time,
which is that let

01:00:24.740 --> 01:00:34.850
me add an extra term like
that, which sums out to 0.

01:00:34.850 --> 01:00:39.894
But now, you see that each
summand is always nonnegative.

01:00:45.700 --> 01:00:49.120
So one of the--

01:00:52.050 --> 01:00:58.830
so there exists some j such
that delta lower abounds

01:00:58.830 --> 01:01:01.290
the j-th summand.

01:01:01.290 --> 01:01:06.960
And if you look at what
that means, then alpha lower

01:01:06.960 --> 01:01:11.370
bounds the j-th summand.

01:01:11.370 --> 01:01:15.588
So in particular, this sum
here should be nonnegative.

01:01:21.480 --> 01:01:22.480
So you have that.

01:01:22.480 --> 01:01:22.980
Good.

01:01:26.390 --> 01:01:30.413
So we obtained a density
increment of this hyperplane.

01:01:34.760 --> 01:01:42.130
And finally, I want to iterate
this density increment.

01:01:42.130 --> 01:01:44.749
So I want to iterate
this density increment--

01:02:01.400 --> 01:02:07.520
so summary so far
is that we have--

01:02:07.520 --> 01:02:20.520
so if A is 3-AP-free with
density alpha and N at least 2

01:02:20.520 --> 01:02:26.300
to the alpha to
the minus 2, then A

01:02:26.300 --> 01:02:35.510
has density at least alpha
plus alpha squared over 4

01:02:35.510 --> 01:02:37.175
on some hyperplane.

01:02:40.430 --> 01:02:44.740
So you combine step one and step
two, we obtain this conclusion.

01:02:48.340 --> 01:02:54.970
Well, I can now
repeat this operation.

01:02:54.970 --> 01:03:09.890
So I can repeat by restricting
A to this hyperplane.

01:03:09.890 --> 01:03:13.590
If A is originally 3-AP-free,
I restrict it to a hyperplane,

01:03:13.590 --> 01:03:15.460
it's still 3-AP-free.

01:03:15.460 --> 01:03:17.790
So I can keep going.

01:03:17.790 --> 01:03:20.400
I can keep going provided
that my space is still

01:03:20.400 --> 01:03:27.500
large enough, because I still
need this lower bound on F.

01:03:27.500 --> 01:03:29.640
So don't forget this one here.

01:03:29.640 --> 01:03:40.340
So I can keep going
as long as N is--

01:03:44.960 --> 01:03:47.110
so I'm using N sub
j to denote what

01:03:47.110 --> 01:03:50.240
happens after the j-th step.

01:03:50.240 --> 01:03:53.840
I can keep going as long
as this is still satisfied.

01:03:53.840 --> 01:03:56.540
But of course, you cannot
keep on going forever,

01:03:56.540 --> 01:04:00.030
because the density is bounded.

01:04:00.030 --> 01:04:01.970
So density cannot exceed 1.

01:04:01.970 --> 01:04:06.420
So these two will give you a
bound on the total dimension.

01:04:06.420 --> 01:04:08.750
So let's work this out.

01:04:08.750 --> 01:04:18.140
So let alpha i
denote the density

01:04:18.140 --> 01:04:25.770
after step i in this iteration.

01:04:25.770 --> 01:04:35.910
And we see from over here that
you start with density alpha,

01:04:35.910 --> 01:04:44.940
and each step you go up by an
increment, which is basically

01:04:44.940 --> 01:04:46.260
what--

01:04:46.260 --> 01:04:48.720
so you go up by some increment.

01:04:48.720 --> 01:04:51.570
And you want to know,
if you start with alpha,

01:04:51.570 --> 01:04:57.690
how many steps at most can you
take before you blow out 1.

01:05:00.440 --> 01:05:02.530
So can you give me some bound?

01:05:06.640 --> 01:05:08.160
So what's the maximum--

01:05:08.160 --> 01:05:09.590
at most, how many steps?

01:05:17.160 --> 01:05:24.184
So we know that the
density cannot exceed 1.

01:05:24.184 --> 01:05:27.523
AUDIENCE: 4 by alpha squared.

01:05:27.523 --> 01:05:31.920
YUFEI ZHAO: So you see
that you have at most 4

01:05:31.920 --> 01:05:38.850
over alpha squared steps,
because density is at most 1.

01:05:38.850 --> 01:05:44.710
And if you plug this in,
you get something which

01:05:44.710 --> 01:05:46.810
is not quite what I stated.

01:05:46.810 --> 01:05:50.920
So it turns out that
if you plug this in,

01:05:50.920 --> 01:05:53.620
you find that alpha is--

01:05:53.620 --> 01:05:57.730
you find that the
size of A is at most 3

01:05:57.730 --> 01:05:59.660
to the n-th over square root n.

01:06:03.210 --> 01:06:04.945
So let me do a
little bit better,

01:06:04.945 --> 01:06:09.730
so then simply seeing
that this term here is

01:06:09.730 --> 01:06:13.260
at least alpha squared over 4.

01:06:13.260 --> 01:06:15.970
And the point is that
when you increment,

01:06:15.970 --> 01:06:19.040
you increment faster and faster.

01:06:19.040 --> 01:06:21.680
So I can use that
to give a better

01:06:21.680 --> 01:06:24.420
bound on the number of steps.

01:06:24.420 --> 01:06:26.840
And here's the way to see it.

01:06:26.840 --> 01:06:29.810
So let me-- we can do better.

01:06:33.600 --> 01:06:39.540
So starting at alpha, I then
now ask, how many steps do you

01:06:39.540 --> 01:06:42.594
need to take before it doubles?

01:06:42.594 --> 01:06:44.426
AUDIENCE: [INAUDIBLE]

01:06:44.426 --> 01:06:48.610
YUFEI ZHAO: It goes up
by alpha squared over 4.

01:06:48.610 --> 01:06:57.700
So it doubles after at
most 4 over alpha steps.

01:07:01.280 --> 01:07:08.860
And at which point
this alpha, new alpha,

01:07:08.860 --> 01:07:10.930
becomes at least the original--

01:07:10.930 --> 01:07:13.250
twice the original alpha?

01:07:13.250 --> 01:07:14.740
But now, you keep going.

01:07:14.740 --> 01:07:18.560
How many times does it
take to double again?

01:07:18.560 --> 01:07:21.030
2 over alpha, because the
alpha became twice as much.

01:07:26.760 --> 01:07:33.400
So it doubles again after
at most 2 over alpha steps.

01:07:33.400 --> 01:07:34.670
And then you keep going.

01:07:34.670 --> 01:07:38.390
The next iteration
is 1 over alpha.

01:07:38.390 --> 01:07:52.700
So in total-- so you see that
we must stop after at most 8

01:07:52.700 --> 01:07:56.000
over alpha steps.

01:07:58.570 --> 01:08:01.250
So the number of
times it doubles,

01:08:01.250 --> 01:08:04.830
actually it decreases by
at least half each time.

01:08:11.053 --> 01:08:11.970
So now, we know that--

01:08:14.860 --> 01:08:17.500
we see that the--

01:08:17.500 --> 01:08:19.609
so you keep on going.

01:08:19.609 --> 01:08:23.170
So you must stop after at
most 8 over alpha steps.

01:08:23.170 --> 01:08:26.859
What is the final density
when you have to stop,

01:08:26.859 --> 01:08:28.430
because when are
you forced to stop?

01:08:28.430 --> 01:08:32.399
You are forced to stop
if you run out of space.

01:08:32.399 --> 01:08:34.930
So you're forced to stop
when you run out of space.

01:08:34.930 --> 01:08:46.290
So if the process
terminates after m steps--

01:08:46.290 --> 01:09:04.305
so we're at density alpha m,
so then the final subspace

01:09:04.305 --> 01:09:16.100
has size less than 2 to the
alpha m raised to minus 2,

01:09:16.100 --> 01:09:19.130
which is--

01:09:19.130 --> 01:09:22.830
So now, I use this bound alpha.

01:09:25.490 --> 01:09:32.189
So the initial N is
upper bounded by what?

01:09:32.189 --> 01:09:34.250
So how many steps did you take?

01:09:34.250 --> 01:09:36.990
You took at most 8
over alpha steps.

01:09:36.990 --> 01:09:41.760
Each of those steps, you pass
down to codimension what?

01:09:41.760 --> 01:09:43.979
You lose a dimension
for each step.

01:09:43.979 --> 01:09:47.050
And the final subspace
has at least this--

01:09:47.050 --> 01:09:51.490
has at most that much space.

01:09:51.490 --> 01:10:01.300
So the final dimension is this,
basically log 1 over alpha.

01:10:01.300 --> 01:10:07.650
So put them together, we see
that the size of the space

01:10:07.650 --> 01:10:11.322
originally is at
most 1 over alpha.

01:10:11.322 --> 01:10:11.822
Yeah.

01:10:11.822 --> 01:10:14.466
AUDIENCE: Should this
be a lower case n?

01:10:14.466 --> 01:10:15.383
YUFEI ZHAO: Thank you.

01:10:15.383 --> 01:10:16.210
Yeah.

01:10:16.210 --> 01:10:19.499
This should be a lower
case n, so the dimension.

01:10:19.499 --> 01:10:19.999
Good.

01:10:22.780 --> 01:10:30.540
And OK, so then that's the
conclusion, that the density

01:10:30.540 --> 01:10:36.361
alpha is big O of 1 over n.

01:10:41.360 --> 01:10:44.990
That proves the main
theorem for today,

01:10:44.990 --> 01:10:48.940
so Roth's theorem
over F3 to the n-th.

01:10:48.940 --> 01:10:51.540
So we went through this
Fourier analytic proof.

01:10:51.540 --> 01:10:57.290
Next lecture, we will see
the same proof again but done

01:10:57.290 --> 01:11:00.800
in the integers for interval.

01:11:00.800 --> 01:11:05.460
And there, there are
some difficulties

01:11:05.460 --> 01:11:08.340
that we don't see over here.

01:11:08.340 --> 01:11:11.940
Because in the
finite field space,

01:11:11.940 --> 01:11:15.120
in the finite field
model, there's

01:11:15.120 --> 01:11:18.490
this very nice idea of
looking at subspaces,

01:11:18.490 --> 01:11:21.410
so looking at hyperplanes.

01:11:21.410 --> 01:11:25.820
Each Fourier coefficient gets
you down to one dimension less.

01:11:25.820 --> 01:11:29.730
But when you're working
in the integers,

01:11:29.730 --> 01:11:32.310
there are no
subspaces you can use.

01:11:34.860 --> 01:11:38.040
So we'll be looking
at ways to get around

01:11:38.040 --> 01:11:39.685
the lack of subspaces.

01:11:39.685 --> 01:11:41.310
And this is why I
said in the beginning

01:11:41.310 --> 01:11:43.790
that the finite
field model is often

01:11:43.790 --> 01:11:50.940
a very good playground for
additive combinatorics type

01:11:50.940 --> 01:11:53.940
techniques, especially
Fourier analytic techniques.

01:11:53.940 --> 01:11:55.830
Because in the additive--

01:11:55.830 --> 01:11:57.450
in all of these
techniques, they just

01:11:57.450 --> 01:11:59.050
come out to be much cleaner.

01:11:59.050 --> 01:12:01.560
If you're working in a
finite field setting,

01:12:01.560 --> 01:12:03.480
you have nice subspaces,
you have Fourier

01:12:03.480 --> 01:12:05.160
transform in a very clean way.

01:12:05.160 --> 01:12:08.130
The Fourier transform
always takes, in this case,

01:12:08.130 --> 01:12:10.220
one of three values.

01:12:10.220 --> 01:12:11.220
Everything's very clean.

01:12:11.220 --> 01:12:12.300
Everything's very simple.

01:12:12.300 --> 01:12:13.490
And you get to
see the idea here.

01:12:13.490 --> 01:12:15.615
You get to see the sense
of the increment argument.

01:12:18.210 --> 01:12:21.600
But once you
understand those ideas

01:12:21.600 --> 01:12:26.320
and you're willing to do
more work, then oftentimes,

01:12:26.320 --> 01:12:29.590
you can bring those
ideas to other settings,

01:12:29.590 --> 01:12:32.830
to other abelian
groups, to the integers,

01:12:32.830 --> 01:12:37.300
for instance, but with
more work in the--

01:12:37.300 --> 01:12:41.800
there are some extra ingredients
that you need to use.

01:12:41.800 --> 01:12:45.260
I mentioned that
there was a bound--

01:12:45.260 --> 01:12:46.330
OK, so initially--

01:12:49.812 --> 01:12:51.020
So next time, we'll see that.

01:12:51.020 --> 01:12:56.000
Next time, we'll see what
happens over the integers.

01:12:56.000 --> 01:12:58.490
Any questions?

01:12:58.490 --> 01:12:59.187
Yes.

01:12:59.187 --> 01:13:03.300
AUDIENCE: [INAUDIBLE]

01:13:03.300 --> 01:13:04.250
YUFEI ZHAO: OK, great.

01:13:04.250 --> 01:13:07.850
So question is why the process
must stop after at most 8

01:13:07.850 --> 01:13:08.840
over alpha steps?

01:13:12.430 --> 01:13:15.700
So you know that the density
doubles after this many steps,

01:13:15.700 --> 01:13:17.380
doubles again after
that many steps.

01:13:17.380 --> 01:13:20.710
So eventually, if it
keeps on doubling,

01:13:20.710 --> 01:13:24.360
it cannot keep on
doubling forever.

01:13:24.360 --> 01:13:26.570
So this process cannot
keep on doubling forever.

01:13:26.570 --> 01:13:28.820
So it must stop--

01:13:28.820 --> 01:13:39.560
so cannot double more than log
base 2 of 1 over alpha times.

01:13:42.980 --> 01:13:45.440
And that point,
you have to stop.

01:13:45.440 --> 01:13:47.270
So how many steps
have you taken?

01:13:47.270 --> 01:13:49.420
Well, you sum this
geometric series.

01:13:49.420 --> 01:13:55.940
So this-- and the
next thing is that you

01:13:55.940 --> 01:13:57.840
sum this geometric series.

01:13:57.840 --> 01:14:01.310
And that geometric series
sums to 8 over alpha.

01:14:10.230 --> 01:14:10.730
Great.

01:14:10.730 --> 01:14:12.280
So let's finish here.

01:14:12.280 --> 01:14:16.680
So next time, we'll see Roth's
proof of Roth's theorem.