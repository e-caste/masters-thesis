WEBVTT

00:00:00.000 --> 00:00:01.988 align:middle line:90%
[SQUEAKING]

00:00:01.988 --> 00:00:03.479 align:middle line:90%
[RUSTLING]

00:00:03.479 --> 00:00:05.467 align:middle line:90%
[CLICKING]

00:00:05.467 --> 00:00:11.002 align:middle line:90%


00:00:11.002 --> 00:00:11.960 align:middle line:90%
ROBERT M. TOWNSEND: OK.

00:00:11.960 --> 00:00:13.680 align:middle line:90%
Greetings, everyone.

00:00:13.680 --> 00:00:16.122 align:middle line:90%
Thank you for coming today.

00:00:16.122 --> 00:00:17.420 align:middle line:90%
I'll say a few things.

00:00:17.420 --> 00:00:20.410 align:middle line:84%
So in terms of the
calendar, and we're

00:00:20.410 --> 00:00:23.770 align:middle line:84%
finishing off this section
right before Thanksgiving break,

00:00:23.770 --> 00:00:24.670 align:middle line:90%
when I get--

00:00:24.670 --> 00:00:27.400 align:middle line:84%
excuse me, on
identification today.

00:00:27.400 --> 00:00:29.500 align:middle line:90%
We're on that momentarily.

00:00:29.500 --> 00:00:31.690 align:middle line:84%
Then, we have two
formal lectures

00:00:31.690 --> 00:00:34.600 align:middle line:84%
after the break, on
Tuesday, Thursday.

00:00:34.600 --> 00:00:37.270 align:middle line:90%
So that's the calendar.

00:00:37.270 --> 00:00:40.780 align:middle line:84%
Then, in terms of the
readings today, it's

00:00:40.780 --> 00:00:44.980 align:middle line:84%
important to point out, the
section on identification

00:00:44.980 --> 00:00:48.530 align:middle line:84%
and falsification
we're about to do,

00:00:48.530 --> 00:00:50.740 align:middle line:84%
there are three
starred readings,

00:00:50.740 --> 00:00:54.700 align:middle line:84%
and they all come from Varian,
and they're all really, really

00:00:54.700 --> 00:00:55.430 align:middle line:90%
good.

00:00:55.430 --> 00:00:58.480 align:middle line:84%
In fact, I had to abbreviate
in spots, in order

00:00:58.480 --> 00:01:00.070 align:middle line:90%
to cover all the topics.

00:01:00.070 --> 00:01:03.040 align:middle line:84%
So we are drawing on
this material in part,

00:01:03.040 --> 00:01:07.480 align:middle line:90%
and you will find it useful.

00:01:07.480 --> 00:01:08.800 align:middle line:90%
Again, it's not the whole book.

00:01:08.800 --> 00:01:10.990 align:middle line:84%
It's just Varian,
in these sections,

00:01:10.990 --> 00:01:15.490 align:middle line:90%
8.1 through 8.3, 8.5, and 8.7.

00:01:15.490 --> 00:01:20.960 align:middle line:84%
Then, from last time, let's have
a little bit of a discussion.

00:01:20.960 --> 00:01:23.300 align:middle line:90%
Let's see.

00:01:23.300 --> 00:01:26.810 align:middle line:84%
Daniel, can you
tell me, as best you

00:01:26.810 --> 00:01:30.860 align:middle line:84%
can, what the definition of
is the positive representative

00:01:30.860 --> 00:01:36.770 align:middle line:84%
consumer and the normative
representative consumer,

00:01:36.770 --> 00:01:39.950 align:middle line:84%
explaining what
they are Intuitively

00:01:39.950 --> 00:01:42.020 align:middle line:84%
AUDIENCE: So like
the idea is you're

00:01:42.020 --> 00:01:47.550 align:middle line:84%
trying to treat the entire
economy as a single person.

00:01:47.550 --> 00:01:50.150 align:middle line:84%
So a positive
representative consumer

00:01:50.150 --> 00:01:56.540 align:middle line:84%
is, at any given level
of wealth and input,

00:01:56.540 --> 00:02:05.030 align:middle line:84%
the way to maximize utility is
to spend your wealth the way

00:02:05.030 --> 00:02:11.000 align:middle line:84%
that customer would and
then distribute that

00:02:11.000 --> 00:02:14.240 align:middle line:90%
to the people like in some way.

00:02:14.240 --> 00:02:17.850 align:middle line:84%
We don't really know which
way from the consumer,

00:02:17.850 --> 00:02:21.080 align:middle line:84%
but like it'll just be
like the best distribution.

00:02:21.080 --> 00:02:25.290 align:middle line:84%
And then the normative
is very similar,

00:02:25.290 --> 00:02:28.560 align:middle line:84%
except for instead of
the utility maximizing,

00:02:28.560 --> 00:02:32.900 align:middle line:84%
it's the Pareto optimal way
to distribute the wealth.

00:02:32.900 --> 00:02:36.253 align:middle line:90%


00:02:36.253 --> 00:02:37.295 align:middle line:90%
ROBERT M. TOWNSEND: Yeah.

00:02:37.295 --> 00:02:40.290 align:middle line:90%


00:02:40.290 --> 00:02:43.050 align:middle line:84%
I guess I would sharpen up a
little bit the positive one.

00:02:43.050 --> 00:02:49.230 align:middle line:84%
The idea is to get the excess
demand curve for the economy,

00:02:49.230 --> 00:02:53.790 align:middle line:84%
as if it were coming from
this representative consumer

00:02:53.790 --> 00:02:58.170 align:middle line:84%
maximizing utility subject
to resource constraints.

00:02:58.170 --> 00:03:00.780 align:middle line:84%
And then that
representative consumer

00:03:00.780 --> 00:03:04.560 align:middle line:84%
has all the resource constraints
in the entire economy.

00:03:04.560 --> 00:03:07.950 align:middle line:84%
In particular, the budget
just says, don't spend more

00:03:07.950 --> 00:03:10.490 align:middle line:90%
than the economy-wide wealth.

00:03:10.490 --> 00:03:13.460 align:middle line:84%
And you said that,
but maybe better

00:03:13.460 --> 00:03:18.330 align:middle line:84%
for me to repeat
it a little bit.

00:03:18.330 --> 00:03:20.510 align:middle line:84%
Yeah, and then the
normative one is a way

00:03:20.510 --> 00:03:23.930 align:middle line:84%
to rank order
allocations, according

00:03:23.930 --> 00:03:27.190 align:middle line:90%
to the Pareto principal.

00:03:27.190 --> 00:03:28.900 align:middle line:84%
But ironically,
rather than keeping

00:03:28.900 --> 00:03:32.470 align:middle line:84%
track of all the individuals,
and whether they're

00:03:32.470 --> 00:03:36.460 align:middle line:84%
made better off or worse
off, we can collapse it to

00:03:36.460 --> 00:03:41.170 align:middle line:84%
as if we were maximizing
utility for the whole economy

00:03:41.170 --> 00:03:44.840 align:middle line:84%
through the lens of this
representative consumer.

00:03:44.840 --> 00:03:51.490 align:middle line:84%
And as you said, that determines
the overall allocation.

00:03:51.490 --> 00:03:57.190 align:middle line:84%
It doesn't pin down the
potential reallocation

00:03:57.190 --> 00:04:03.280 align:middle line:84%
of wealth that is necessary,
if you go from something Pareto

00:04:03.280 --> 00:04:08.590 align:middle line:84%
inferior to something Pareto
superior or Pareto optimal,

00:04:08.590 --> 00:04:12.880 align:middle line:84%
you may have to
compensate the losers

00:04:12.880 --> 00:04:17.410 align:middle line:90%
and by taxing the winners.

00:04:17.410 --> 00:04:18.039 align:middle line:90%
OK, great.

00:04:18.039 --> 00:04:22.380 align:middle line:90%


00:04:22.380 --> 00:04:26.520 align:middle line:84%
So we made a lot of use
of this Gorman form.

00:04:26.520 --> 00:04:31.980 align:middle line:84%
Caleb, can you tell me in words,
what is this Gorman polar form?

00:04:31.980 --> 00:04:37.265 align:middle line:90%


00:04:37.265 --> 00:04:37.890 align:middle line:90%
AUDIENCE: Yeah.

00:04:37.890 --> 00:04:46.930 align:middle line:84%
So like it breaks
down the equilibrium

00:04:46.930 --> 00:04:48.220 align:middle line:90%
into like a linear form.

00:04:48.220 --> 00:04:50.290 align:middle line:84%
I guess, I don't know
exactly how to explain it.

00:04:50.290 --> 00:04:54.570 align:middle line:90%


00:04:54.570 --> 00:04:57.990 align:middle line:84%
ROBERT M. TOWNSEND: Do you
remember any of the notation?

00:04:57.990 --> 00:05:00.330 align:middle line:84%
What is it breaking
down exactly?

00:05:00.330 --> 00:05:02.870 align:middle line:90%


00:05:02.870 --> 00:05:05.530 align:middle line:84%
AUDIENCE: Like the
equilibrium in the economy.

00:05:05.530 --> 00:05:09.187 align:middle line:90%


00:05:09.187 --> 00:05:11.270 align:middle line:84%
ROBERT M. TOWNSEND: Does
the word indirect utility

00:05:11.270 --> 00:05:11.990 align:middle line:90%
come to mind?

00:05:11.990 --> 00:05:18.404 align:middle line:90%


00:05:18.404 --> 00:05:19.340 align:middle line:90%
OK.

00:05:19.340 --> 00:05:23.660 align:middle line:84%
It's the indirect
utility function,

00:05:23.660 --> 00:05:28.990 align:middle line:84%
which is the maximized
utility subject to the given

00:05:28.990 --> 00:05:30.455 align:middle line:90%
vector of prices and wealth.

00:05:30.455 --> 00:05:33.120 align:middle line:90%


00:05:33.120 --> 00:05:40.250 align:middle line:84%
And the statement about Gorman
form is this form in which

00:05:40.250 --> 00:05:42.950 align:middle line:84%
that that indirect
utility function

00:05:42.950 --> 00:05:48.230 align:middle line:84%
must take in order to do this
positive and normative thing.

00:05:48.230 --> 00:05:52.420 align:middle line:84%
Can someone volunteer to tell
me what, in words if you can,

00:05:52.420 --> 00:05:55.185 align:middle line:90%
what the green form looks like?

00:05:55.185 --> 00:05:55.810 align:middle line:90%
AUDIENCE: Sure.

00:05:55.810 --> 00:05:57.647 align:middle line:90%
I can take this one.

00:05:57.647 --> 00:05:58.730 align:middle line:90%
ROBERT M. TOWNSEND: Great.

00:05:58.730 --> 00:06:03.200 align:middle line:84%
AUDIENCE: So the Gorman form is
basically an indirect utility

00:06:03.200 --> 00:06:08.030 align:middle line:84%
function that is linear
in W, the overall wealth

00:06:08.030 --> 00:06:08.760 align:middle line:90%
of the economy.

00:06:08.760 --> 00:06:11.540 align:middle line:84%
So it's some function A,
which depends on prices,

00:06:11.540 --> 00:06:15.768 align:middle line:84%
plus sum function B, which
depends on prices, plus W.

00:06:15.768 --> 00:06:16.810 align:middle line:90%
ROBERT M. TOWNSEND: Yeah.

00:06:16.810 --> 00:06:18.790 align:middle line:90%
That's exactly right.

00:06:18.790 --> 00:06:22.510 align:middle line:84%
Well, it's at the level
of the individuals.

00:06:22.510 --> 00:06:23.350 align:middle line:90%
AUDIENCE: Yes.

00:06:23.350 --> 00:06:26.290 align:middle line:84%
ROBERT M. TOWNSEND: So if
we had an individual I,

00:06:26.290 --> 00:06:28.030 align:middle line:84%
where do we put the
I in that equation?

00:06:28.030 --> 00:06:30.590 align:middle line:90%


00:06:30.590 --> 00:06:35.350 align:middle line:84%
AUDIENCE: So it is
on both the wealth

00:06:35.350 --> 00:06:37.420 align:middle line:84%
that an individual
person faces, and I

00:06:37.420 --> 00:06:41.950 align:middle line:84%
think as well on the
functions A and B.

00:06:41.950 --> 00:06:46.518 align:middle line:84%
Each individual can have their
own specific form for that.

00:06:46.518 --> 00:06:48.060 align:middle line:84%
ROBERT M. TOWNSEND:
Two out of three.

00:06:48.060 --> 00:06:51.720 align:middle line:84%
So it's on the wealth, because
at the individual level,

00:06:51.720 --> 00:06:55.860 align:middle line:84%
it's the indirect utility is
a function of the individual's

00:06:55.860 --> 00:07:02.040 align:middle line:84%
wealth, say W sub I. The
intercept term, the A of P

00:07:02.040 --> 00:07:08.730 align:middle line:84%
is the AI of P. So that's where
the heterogeneity is loaded.

00:07:08.730 --> 00:07:13.050 align:middle line:84%
But it's not on the B, and
maybe you can remember why.

00:07:13.050 --> 00:07:15.930 align:middle line:84%
What did we say about those
linear expansion paths?

00:07:15.930 --> 00:07:18.510 align:middle line:84%
AUDIENCE: Oh, those need to
be parallel linear expansion

00:07:18.510 --> 00:07:21.093 align:middle line:84%
paths, and so they need to be
identical for each consumer.

00:07:21.093 --> 00:07:22.260 align:middle line:90%
ROBERT M. TOWNSEND: Exactly.

00:07:22.260 --> 00:07:23.220 align:middle line:90%
That's perfect.

00:07:23.220 --> 00:07:28.230 align:middle line:90%
So there's no I for the B part.

00:07:28.230 --> 00:07:31.430 align:middle line:90%
OK, and then finally--

00:07:31.430 --> 00:07:36.270 align:middle line:84%
oh, I almost answer
this already,

00:07:36.270 --> 00:07:37.890 align:middle line:90%
but we can discuss it some more.

00:07:37.890 --> 00:07:41.880 align:middle line:84%
How realistic are the necessary
and sufficient conditions

00:07:41.880 --> 00:07:44.370 align:middle line:84%
for Gorman aggregation,
based on what you've

00:07:44.370 --> 00:07:45.720 align:middle line:90%
learned in previous lectures?

00:07:45.720 --> 00:07:48.420 align:middle line:90%


00:07:48.420 --> 00:07:50.460 align:middle line:84%
In other words, do
you believe it or not?

00:07:50.460 --> 00:07:55.830 align:middle line:90%


00:07:55.830 --> 00:07:56.330 align:middle line:90%
Guanpeng?

00:07:56.330 --> 00:07:59.100 align:middle line:90%


00:07:59.100 --> 00:08:00.210 align:middle line:90%
AUDIENCE: Yeah.

00:08:00.210 --> 00:08:01.920 align:middle line:84%
I believe one of the
necessary conditions

00:08:01.920 --> 00:08:05.700 align:middle line:84%
was that the aggregate
demand doesn't

00:08:05.700 --> 00:08:07.920 align:middle line:84%
depend on the distribution
of the wealth.

00:08:07.920 --> 00:08:11.443 align:middle line:84%
It has to depend only
on the total wealth.

00:08:11.443 --> 00:08:13.360 align:middle line:84%
ROBERT M. TOWNSEND:
That's true, and then what

00:08:13.360 --> 00:08:18.870 align:middle line:84%
does that imply
about the underlying

00:08:18.870 --> 00:08:20.580 align:middle line:90%
households in the economy?

00:08:20.580 --> 00:08:25.370 align:middle line:90%


00:08:25.370 --> 00:08:29.260 align:middle line:84%
AUDIENCE: I believe it
implies some uniformity.

00:08:29.260 --> 00:08:32.387 align:middle line:90%


00:08:32.387 --> 00:08:33.429 align:middle line:90%
ROBERT M. TOWNSEND: Yeah.

00:08:33.429 --> 00:08:37.909 align:middle line:84%
It's uniform in
the way that wealth

00:08:37.909 --> 00:08:40.070 align:middle line:90%
impacts marginal changes.

00:08:40.070 --> 00:08:41.659 align:middle line:90%
AUDIENCE: Right.

00:08:41.659 --> 00:08:43.929 align:middle line:90%
ROBERT M. TOWNSEND: So yeah.

00:08:43.929 --> 00:08:47.280 align:middle line:84%
Those linear expansion
paths are a shorthand way

00:08:47.280 --> 00:08:51.330 align:middle line:84%
of saying different
people can consume

00:08:51.330 --> 00:08:55.000 align:middle line:84%
different amounts, because
they have different wealth.

00:08:55.000 --> 00:08:58.840 align:middle line:84%
But if you start changing
wealth distribution,

00:08:58.840 --> 00:09:01.150 align:middle line:84%
by definition, holding the
aggregate fixed, if you're

00:09:01.150 --> 00:09:03.250 align:middle line:84%
going to change
the distribution,

00:09:03.250 --> 00:09:05.590 align:middle line:84%
you're increasing wealth
for some households

00:09:05.590 --> 00:09:07.660 align:middle line:90%
and decreasing it for others.

00:09:07.660 --> 00:09:09.620 align:middle line:90%
And those marginal changes--

00:09:09.620 --> 00:09:12.130 align:middle line:84%
and not just local
changes, global changes--

00:09:12.130 --> 00:09:17.710 align:middle line:84%
these could be big
redistributions, offset

00:09:17.710 --> 00:09:21.940 align:middle line:90%
each other in the aggregate.

00:09:21.940 --> 00:09:24.760 align:middle line:84%
The amount that
consumption of a given good

00:09:24.760 --> 00:09:26.950 align:middle line:84%
is going down for the
people who are taxed

00:09:26.950 --> 00:09:32.410 align:middle line:84%
is exactly equal to the amount
that consumption of that good

00:09:32.410 --> 00:09:35.650 align:middle line:84%
is going up for the people
who get the subsidies.

00:09:35.650 --> 00:09:38.690 align:middle line:90%


00:09:38.690 --> 00:09:42.230 align:middle line:84%
And that's why the
redistribution doesn't

00:09:42.230 --> 00:09:43.490 align:middle line:90%
matter for the aggregate.

00:09:43.490 --> 00:09:45.890 align:middle line:84%
That's why we can do this
representative consumer

00:09:45.890 --> 00:09:50.500 align:middle line:84%
thing to get the
aggregates, because only

00:09:50.500 --> 00:09:54.780 align:middle line:84%
aggregate wealth matters for
aggregate demand, as you said.

00:09:54.780 --> 00:09:59.040 align:middle line:84%
However, it matters a whole
lot for the individuals.

00:09:59.040 --> 00:10:00.840 align:middle line:84%
I mean if you're
paying taxes, lump

00:10:00.840 --> 00:10:07.420 align:middle line:84%
sum to the government for it to
be redistributed, you get hurt.

00:10:07.420 --> 00:10:09.180 align:middle line:90%
So it's not a welfare statement.

00:10:09.180 --> 00:10:13.310 align:middle line:90%


00:10:13.310 --> 00:10:16.360 align:middle line:84%
And I'll just
repeat, that's why,

00:10:16.360 --> 00:10:19.030 align:middle line:84%
depending on what we're doing
with free trade or something

00:10:19.030 --> 00:10:23.170 align:middle line:84%
else, in principle, we may
be able to make everyone

00:10:23.170 --> 00:10:27.960 align:middle line:84%
better off, as we are
told by situations

00:10:27.960 --> 00:10:30.840 align:middle line:84%
where there is a representative
in indifference curve

00:10:30.840 --> 00:10:35.610 align:middle line:84%
and we're using
implicitly Gorman's form

00:10:35.610 --> 00:10:36.870 align:middle line:90%
for the indirect utilities.

00:10:36.870 --> 00:10:39.240 align:middle line:84%
But that doesn't mean
everyone is actually

00:10:39.240 --> 00:10:42.370 align:middle line:84%
better off without
the intervention,

00:10:42.370 --> 00:10:44.290 align:middle line:84%
because the factor
prices are moving,

00:10:44.290 --> 00:10:48.710 align:middle line:84%
and some people own more labor
than capital and vice versa.

00:10:48.710 --> 00:10:53.140 align:middle line:84%
So we really do need to be
actively redistributing wealth

00:10:53.140 --> 00:10:58.360 align:middle line:84%
in order to reap the
gains for everyone

00:10:58.360 --> 00:11:02.460 align:middle line:84%
to benefit from
the gains to trade.

00:11:02.460 --> 00:11:02.960 align:middle line:90%
OK.

00:11:02.960 --> 00:11:05.480 align:middle line:90%


00:11:05.480 --> 00:11:12.330 align:middle line:84%
So this lecture from
18 was about a tool,

00:11:12.330 --> 00:11:15.000 align:middle line:84%
namely Gorman
aggregation, which you

00:11:15.000 --> 00:11:18.840 align:middle line:84%
saw in the form of
the earlier lectures

00:11:18.840 --> 00:11:21.380 align:middle line:90%
without me elaborating on it.

00:11:21.380 --> 00:11:23.890 align:middle line:84%
So this was an opportunity
to do that, but it

00:11:23.890 --> 00:11:25.480 align:middle line:84%
does take underlying
assumptions,

00:11:25.480 --> 00:11:29.850 align:middle line:84%
and in part, the microdata
seem to contradict.

00:11:29.850 --> 00:11:30.350 align:middle line:90%
Yeah.

00:11:30.350 --> 00:11:32.380 align:middle line:84%
I didn't push you
guys very hard,

00:11:32.380 --> 00:11:34.030 align:middle line:90%
but do you believe it or not?

00:11:34.030 --> 00:11:37.840 align:middle line:84%
Then, it's do we see these
differentiable wealth effects

00:11:37.840 --> 00:11:38.660 align:middle line:90%
in practice?

00:11:38.660 --> 00:11:44.170 align:middle line:84%
We have normal goods, necessary
goods, and so on and even given

00:11:44.170 --> 00:11:45.040 align:middle line:90%
goods, as I said.

00:11:45.040 --> 00:11:48.550 align:middle line:90%


00:11:48.550 --> 00:11:50.470 align:middle line:84%
To know if it's a
bad approximation,

00:11:50.470 --> 00:11:52.750 align:middle line:84%
we'd have to take a
stand on the underlying

00:11:52.750 --> 00:11:55.960 align:middle line:84%
non-Gorman indirect
utility functions

00:11:55.960 --> 00:11:59.230 align:middle line:84%
and simulate the economy, and
see if it looks almost linear,

00:11:59.230 --> 00:12:01.180 align:middle line:90%
even though it's not.

00:12:01.180 --> 00:12:03.865 align:middle line:84%
In which case, the
redistribution might be small.

00:12:03.865 --> 00:12:06.490 align:middle line:90%


00:12:06.490 --> 00:12:07.900 align:middle line:90%
Sorry.

00:12:07.900 --> 00:12:09.070 align:middle line:90%
I said that wrong.

00:12:09.070 --> 00:12:14.290 align:middle line:84%
The literal form of
Gorman aggregation

00:12:14.290 --> 00:12:16.960 align:middle line:84%
as an analytic
technique might get

00:12:16.960 --> 00:12:20.230 align:middle line:84%
us close to what we
want as a benchmark,

00:12:20.230 --> 00:12:24.140 align:middle line:84%
and since it's so tractable,
it's very tempting to use it.

00:12:24.140 --> 00:12:26.770 align:middle line:84%
But then again, for
other utility functions,

00:12:26.770 --> 00:12:29.440 align:middle line:84%
we could be really,
really far off

00:12:29.440 --> 00:12:33.220 align:middle line:90%
and be misleading policymakers.

00:12:33.220 --> 00:12:35.510 align:middle line:90%
Hence the microdata.

00:12:35.510 --> 00:12:38.480 align:middle line:84%
Where my pitch is, if you're
going to do macro policy,

00:12:38.480 --> 00:12:41.570 align:middle line:84%
you have to have
micro data, period,

00:12:41.570 --> 00:12:46.160 align:middle line:84%
but that's partly a belief
that I've acquired over time.

00:12:46.160 --> 00:12:49.550 align:middle line:90%
It's a matter of experience.

00:12:49.550 --> 00:12:52.760 align:middle line:90%
Although, it's not always true.

00:12:52.760 --> 00:12:56.160 align:middle line:84%
The approximations
can be very helpful.

00:12:56.160 --> 00:12:56.660 align:middle line:90%
OK.

00:12:56.660 --> 00:13:03.030 align:middle line:84%
So the lecture today is
kind of the reverse of that.

00:13:03.030 --> 00:13:08.820 align:middle line:84%
Instead of putting structure
on indirect utility functions,

00:13:08.820 --> 00:13:12.780 align:middle line:84%
we're going to see if we can
get by with almost no structure

00:13:12.780 --> 00:13:15.900 align:middle line:84%
at all on preferences
and still be

00:13:15.900 --> 00:13:21.300 align:middle line:84%
able to make predictions which
are testable or rejectable.

00:13:21.300 --> 00:13:25.440 align:middle line:84%
So this part, this lecture is
all about economic science.

00:13:25.440 --> 00:13:29.460 align:middle line:84%
I featured the science of
experiments in Lecture 1

00:13:29.460 --> 00:13:31.500 align:middle line:90%
as a motivation for the class.

00:13:31.500 --> 00:13:37.380 align:middle line:84%
We went through [Koopmans]
and Lucas and Josh and Matzkin

00:13:37.380 --> 00:13:38.730 align:middle line:90%
and so on.

00:13:38.730 --> 00:13:42.030 align:middle line:84%
So this is very much the
science of doing experiments,

00:13:42.030 --> 00:13:43.890 align:middle line:84%
and I'll tell you
exactly what we're

00:13:43.890 --> 00:13:46.620 align:middle line:84%
going to do with
micro data, depending

00:13:46.620 --> 00:13:50.730 align:middle line:84%
on the amount of data
available, and also macro data,

00:13:50.730 --> 00:13:54.460 align:middle line:84%
trying to put as little
structure as possible

00:13:54.460 --> 00:13:58.800 align:middle line:84%
and still get
rejectable restrictions.

00:13:58.800 --> 00:14:00.100 align:middle line:90%
Said that.

00:14:00.100 --> 00:14:02.730 align:middle line:84%
So we're going to go through
consumer optimization again,

00:14:02.730 --> 00:14:06.180 align:middle line:84%
which is, as always,
a bit of a review.

00:14:06.180 --> 00:14:07.740 align:middle line:84%
We're going to
approach that as if we

00:14:07.740 --> 00:14:10.890 align:middle line:84%
had an infinite amount of
data, and that will take us

00:14:10.890 --> 00:14:13.080 align:middle line:84%
back to the Slutsky
matrix, which

00:14:13.080 --> 00:14:17.200 align:middle line:84%
you may have forgotten by now,
but I'll try to remind you.

00:14:17.200 --> 00:14:19.000 align:middle line:84%
That's with an infinite
amount of data,

00:14:19.000 --> 00:14:23.230 align:middle line:84%
we get restrictions that we can
reject consumer rationality,

00:14:23.230 --> 00:14:24.740 align:middle line:90%
in principle.

00:14:24.740 --> 00:14:27.280 align:middle line:84%
And then we'll do the same
thing with finite data

00:14:27.280 --> 00:14:31.510 align:middle line:84%
and still derive algorithms
running on finite data

00:14:31.510 --> 00:14:36.010 align:middle line:84%
sets that would allow us to
not reject or alternatively

00:14:36.010 --> 00:14:40.360 align:middle line:84%
reject the rationality of the
household generating the data.

00:14:40.360 --> 00:14:42.430 align:middle line:84%
Then, we'll come
back to Lucas a bit

00:14:42.430 --> 00:14:45.040 align:middle line:84%
in computational
considerations, which

00:14:45.040 --> 00:14:47.410 align:middle line:84%
I think has been clear
throughout the lectures

00:14:47.410 --> 00:14:50.240 align:middle line:90%
that we visit from time to time.

00:14:50.240 --> 00:14:53.740 align:middle line:84%
And I have dug up some really
interesting computer science

00:14:53.740 --> 00:14:56.980 align:middle line:84%
material to share with
you about how hard or easy

00:14:56.980 --> 00:15:00.760 align:middle line:84%
it is to solve certain problems
and whether it matters,

00:15:00.760 --> 00:15:02.260 align:middle line:90%
be provocative.

00:15:02.260 --> 00:15:04.870 align:middle line:84%
And then we'll go to
general equilibrium theory

00:15:04.870 --> 00:15:07.850 align:middle line:84%
and kind of do the same
thing all over again.

00:15:07.850 --> 00:15:09.310 align:middle line:84%
And that's going
to again come back

00:15:09.310 --> 00:15:14.800 align:middle line:84%
to this you need micro to do
macro statement that I just

00:15:14.800 --> 00:15:16.090 align:middle line:90%
mentioned.

00:15:16.090 --> 00:15:17.320 align:middle line:90%
OK.

00:15:17.320 --> 00:15:20.260 align:middle line:84%
To get in the content
of it, this slide

00:15:20.260 --> 00:15:23.120 align:middle line:90%
appears to come out of nowhere.

00:15:23.120 --> 00:15:26.840 align:middle line:84%
It was actually almost
part of the lecture

00:15:26.840 --> 00:15:28.990 align:middle line:84%
we had on income and
substitution effects,

00:15:28.990 --> 00:15:31.150 align:middle line:84%
and I'll remind you
of that in a minute.

00:15:31.150 --> 00:15:35.140 align:middle line:84%
In particular, it has to
do with the Hicksian demand

00:15:35.140 --> 00:15:36.950 align:middle line:90%
and the expenditure function.

00:15:36.950 --> 00:15:39.060 align:middle line:90%
Well, I'll remind you now.

00:15:39.060 --> 00:15:42.210 align:middle line:84%
We did utility maximization
subject to the budget,

00:15:42.210 --> 00:15:46.570 align:middle line:84%
and we got the Walrasian
or Marshallian demand.

00:15:46.570 --> 00:15:50.340 align:middle line:84%
We also decomposed that
into income and substitution

00:15:50.340 --> 00:15:53.160 align:middle line:84%
effects, and the way we got
the substitution effects

00:15:53.160 --> 00:15:55.170 align:middle line:90%
was to do compensation.

00:15:55.170 --> 00:15:57.720 align:middle line:84%
Prices, say if they
decrease, are associated

00:15:57.720 --> 00:15:59.760 align:middle line:90%
with increases in income.

00:15:59.760 --> 00:16:01.950 align:middle line:84%
We take the income
effects away, and just

00:16:01.950 --> 00:16:05.380 align:middle line:84%
look at how demands change,
as we change prices.

00:16:05.380 --> 00:16:08.520 align:middle line:84%
In other words, we
minimize the expenditure

00:16:08.520 --> 00:16:11.280 align:middle line:84%
necessary to achieve a
certain level of utility,

00:16:11.280 --> 00:16:13.720 align:middle line:90%
and we got the Hicksian demand.

00:16:13.720 --> 00:16:18.180 align:middle line:84%
So with the Hicksian demand
and the expenditure function,

00:16:18.180 --> 00:16:21.630 align:middle line:84%
we didn't actually go through
these properties in Lecture 3,

00:16:21.630 --> 00:16:23.790 align:middle line:90%
but they are intuitive.

00:16:23.790 --> 00:16:26.430 align:middle line:84%
If the utility
function is continuous

00:16:26.430 --> 00:16:29.750 align:middle line:84%
represents locally
non-satiated preferences.

00:16:29.750 --> 00:16:32.550 align:middle line:84%
We might as well
define the consumption

00:16:32.550 --> 00:16:35.760 align:middle line:84%
set to be the non-negative
L dimensional orthont.

00:16:35.760 --> 00:16:39.240 align:middle line:84%
Then, we have the
following four properties

00:16:39.240 --> 00:16:44.100 align:middle line:84%
the expenditure function, this
minimized expenditure at prices

00:16:44.100 --> 00:16:47.400 align:middle line:84%
p to achieve a certain
utility level u,

00:16:47.400 --> 00:16:51.150 align:middle line:90%
is homogeneous of degree what?

00:16:51.150 --> 00:16:55.200 align:middle line:90%
1 in those prices p.

00:16:55.200 --> 00:16:57.750 align:middle line:84%
I think I slipped up the
other day, when I said 0,

00:16:57.750 --> 00:16:59.160 align:middle line:90%
and then I switched back to 1.

00:16:59.160 --> 00:17:00.960 align:middle line:90%
It depends on what object.

00:17:00.960 --> 00:17:03.630 align:middle line:84%
When we do utility
maximization to budgets,

00:17:03.630 --> 00:17:05.700 align:middle line:84%
if we increase
income and prices,

00:17:05.700 --> 00:17:09.900 align:middle line:84%
things are homogeneous of degree
0, because nothing changes.

00:17:09.900 --> 00:17:12.430 align:middle line:84%
But this is a property of
the expenditure function.

00:17:12.430 --> 00:17:14.940 align:middle line:84%
So logically, if prices
go up, and you're

00:17:14.940 --> 00:17:16.619 align:middle line:84%
hitting the same
level of utility,

00:17:16.619 --> 00:17:18.119 align:middle line:90%
it's going to cost you more.

00:17:18.119 --> 00:17:20.069 align:middle line:84%
So the expenditure
is just double,

00:17:20.069 --> 00:17:22.200 align:middle line:90%
if your doubling prices.

00:17:22.200 --> 00:17:24.930 align:middle line:90%
It's homogeneous of degree 1.

00:17:24.930 --> 00:17:29.880 align:middle line:84%
The expenditure function
for any given price vector p

00:17:29.880 --> 00:17:31.830 align:middle line:90%
is increasing in utility.

00:17:31.830 --> 00:17:34.320 align:middle line:84%
That makes sense, when
you think about having

00:17:34.320 --> 00:17:36.840 align:middle line:84%
nice concave indifference
curves, or even

00:17:36.840 --> 00:17:38.100 align:middle line:90%
linear indifference curves.

00:17:38.100 --> 00:17:41.253 align:middle line:84%
If you do increase u by moving
further and further north out,

00:17:41.253 --> 00:17:43.170 align:middle line:84%
hitting higher and higher
indifference curves,

00:17:43.170 --> 00:17:46.410 align:middle line:84%
then to minimize the expenditure
of achieving those points,

00:17:46.410 --> 00:17:49.090 align:middle line:90%
the expenditure has to go up.

00:17:49.090 --> 00:17:52.050 align:middle line:84%
Likewise, as prices
go up, expenditures

00:17:52.050 --> 00:17:54.510 align:middle line:84%
go up, which I kind
of already said.

00:17:54.510 --> 00:17:57.300 align:middle line:90%
And this is a key property.

00:17:57.300 --> 00:17:59.550 align:middle line:84%
In addition, the
expenditure function

00:17:59.550 --> 00:18:02.890 align:middle line:90%
is concave in the prices.

00:18:02.890 --> 00:18:07.260 align:middle line:84%
So we're given that the
utility function represents

00:18:07.260 --> 00:18:09.480 align:middle line:90%
local non-satiated preferences.

00:18:09.480 --> 00:18:11.080 align:middle line:90%
We're not given much else.

00:18:11.080 --> 00:18:13.200 align:middle line:84%
So this might be
a bit surprising.

00:18:13.200 --> 00:18:16.290 align:middle line:84%
This allows for it to be linear,
however, and in a minute,

00:18:16.290 --> 00:18:18.540 align:middle line:90%
we'll make it strictly concave.

00:18:18.540 --> 00:18:21.235 align:middle line:84%
Anyway, you remember
how these proofs go.

00:18:21.235 --> 00:18:24.720 align:middle line:84%
Pick two prices, pick
a linear combination,

00:18:24.720 --> 00:18:29.310 align:middle line:84%
prove that an intermediate
combination is also minimizing

00:18:29.310 --> 00:18:30.930 align:middle line:90%
expenditure, et cetera.

00:18:30.930 --> 00:18:33.660 align:middle line:84%
And then the utility
expenditure function

00:18:33.660 --> 00:18:38.220 align:middle line:84%
is continuous in both objects,
but what I want to focus on

00:18:38.220 --> 00:18:40.290 align:middle line:84%
is number three,
that the expenditure

00:18:40.290 --> 00:18:44.370 align:middle line:84%
function is concave in
prices for fixed utility.

00:18:44.370 --> 00:18:45.000 align:middle line:90%
OK.

00:18:45.000 --> 00:18:51.050 align:middle line:84%
Relatedly, the
Hicksian demand is,

00:18:51.050 --> 00:18:54.110 align:middle line:84%
if you're going to achieve
a target utility u,

00:18:54.110 --> 00:18:58.430 align:middle line:84%
then you will achieve
it exactly, essentially.

00:18:58.430 --> 00:19:02.030 align:middle line:84%
That is to say, the x's,
which are part of the solution

00:19:02.030 --> 00:19:04.460 align:middle line:84%
to the minimizing
expenditure problem

00:19:04.460 --> 00:19:07.190 align:middle line:84%
when substituted into
the utility function,

00:19:07.190 --> 00:19:09.170 align:middle line:90%
generate u exactly.

00:19:09.170 --> 00:19:12.410 align:middle line:84%
if preferences are,
number two, convex,

00:19:12.410 --> 00:19:15.710 align:middle line:84%
then these minimized
Hicksian demands

00:19:15.710 --> 00:19:19.820 align:middle line:84%
are convex valued,
entertaining multiple solutions

00:19:19.820 --> 00:19:22.850 align:middle line:84%
that minimize expenditure,
for given p and u.

00:19:22.850 --> 00:19:25.400 align:middle line:84%
But if preferences
are strictly convex,

00:19:25.400 --> 00:19:29.430 align:middle line:84%
then this h function is
single-valued and continuous.

00:19:29.430 --> 00:19:32.960 align:middle line:84%
So here, it's where the strict
convexity of the preferences

00:19:32.960 --> 00:19:38.750 align:middle line:84%
comes in, which we're
going to get to again in 4.

00:19:38.750 --> 00:19:42.110 align:middle line:84%
3 says, this Hicksian
demand is single value

00:19:42.110 --> 00:19:46.430 align:middle line:84%
if it's single valued, which it
would be with strictly convex

00:19:46.430 --> 00:19:47.360 align:middle line:90%
preferences.

00:19:47.360 --> 00:19:49.370 align:middle line:84%
Then, it's differentiable,
and moreover,

00:19:49.370 --> 00:19:51.020 align:middle line:84%
when you take the
derivative of it,

00:19:51.020 --> 00:19:55.190 align:middle line:84%
with respect to say a price
p of L, for the Lth good,

00:19:55.190 --> 00:19:57.380 align:middle line:90%
you get the minimized--

00:19:57.380 --> 00:19:59.180 align:middle line:90%
you get the quantities back.

00:19:59.180 --> 00:20:03.410 align:middle line:84%
So the intuition for
this is expenditure

00:20:03.410 --> 00:20:09.560 align:middle line:84%
is just p1 x1 p2 x2
dot dot dot pL xL.

00:20:09.560 --> 00:20:11.450 align:middle line:84%
You take the
derivative with respect

00:20:11.450 --> 00:20:13.940 align:middle line:90%
to p, you're going to get the x.

00:20:13.940 --> 00:20:17.750 align:middle line:84%
That's a bit sloppy, and we did
the envelope theorem earlier

00:20:17.750 --> 00:20:19.310 align:middle line:90%
and reviewed it last time.

00:20:19.310 --> 00:20:23.510 align:middle line:84%
But basically, the derivative
at the optimizing minimized

00:20:23.510 --> 00:20:27.230 align:middle line:84%
expenditures, at the
parametric price, p sub L,

00:20:27.230 --> 00:20:33.860 align:middle line:84%
is you get the solution
back, the Hicksian demand.

00:20:33.860 --> 00:20:39.440 align:middle line:84%
So these two pieces, 3
and 3, on each of the two

00:20:39.440 --> 00:20:43.190 align:middle line:90%
slides generate this statement.

00:20:43.190 --> 00:20:45.530 align:middle line:84%
That if you take
the Hicksian demands

00:20:45.530 --> 00:20:49.610 align:middle line:84%
and differentiate with
respect to prices, then--

00:20:49.610 --> 00:20:52.610 align:middle line:84%
because level h is on
the right-hand side in 8,

00:20:52.610 --> 00:20:55.650 align:middle line:84%
but the derivative is already
on the left hand side.

00:20:55.650 --> 00:20:58.280 align:middle line:84%
So if you're differentiating
the right all over

00:20:58.280 --> 00:21:01.110 align:middle line:84%
again with respect to p,
we're double differentiating,

00:21:01.110 --> 00:21:02.760 align:middle line:90%
so to speak, the left-hand side.

00:21:02.760 --> 00:21:06.740 align:middle line:84%
So we get these second-order
partial derivatives,

00:21:06.740 --> 00:21:09.260 align:middle line:84%
[? own ?] end cross
partial derivatives,

00:21:09.260 --> 00:21:12.770 align:middle line:84%
of the expenditure function,
when we differentiate

00:21:12.770 --> 00:21:14.870 align:middle line:90%
the Hicksian demands.

00:21:14.870 --> 00:21:16.670 align:middle line:90%
This is really compact notation.

00:21:16.670 --> 00:21:18.050 align:middle line:84%
Obviously, there's
a whole vector

00:21:18.050 --> 00:21:21.320 align:middle line:84%
of prices, p1 through
pL, et cetera.

00:21:21.320 --> 00:21:24.350 align:middle line:84%
We're writing it down almost
as if it were single dimension,

00:21:24.350 --> 00:21:28.310 align:middle line:84%
but it's meant to capture
the entire L by L matrix.

00:21:28.310 --> 00:21:30.980 align:middle line:84%
That is to say, derivative
of the first Hicksian

00:21:30.980 --> 00:21:34.190 align:middle line:84%
demand with respect to the
first price, the first Hicksian

00:21:34.190 --> 00:21:37.700 align:middle line:84%
demand good with respect to
the second, price and so on,

00:21:37.700 --> 00:21:39.650 align:middle line:90%
going across the row.

00:21:39.650 --> 00:21:41.130 align:middle line:90%
Fill out all the rows.

00:21:41.130 --> 00:21:48.260 align:middle line:84%
So it has all the own II, HIPI
derivatives, as well as HIJ,

00:21:48.260 --> 00:21:51.170 align:middle line:84%
Ith good with respect
to the Jth price.

00:21:51.170 --> 00:21:54.140 align:middle line:84%
It's all loaded into
this compact notation.

00:21:54.140 --> 00:21:57.920 align:middle line:84%
Now, I'm saving the best for
last, which is this guy here

00:21:57.920 --> 00:22:02.300 align:middle line:84%
is the matrix of second-order
derivatives of the expenditure

00:22:02.300 --> 00:22:05.090 align:middle line:84%
function, and three
already told us

00:22:05.090 --> 00:22:07.970 align:middle line:84%
the expenditure
function is concave.

00:22:07.970 --> 00:22:11.750 align:middle line:84%
So that means, if you think
about first-order conditions

00:22:11.750 --> 00:22:15.110 align:middle line:84%
and second-order conditions,
that second-order conditions

00:22:15.110 --> 00:22:19.170 align:middle line:84%
are going to be satisfied
for a concave function.

00:22:19.170 --> 00:22:24.440 align:middle line:84%
And in fact, if you look it up--
stuff does slip memory a bit--

00:22:24.440 --> 00:22:28.970 align:middle line:84%
it means that this matrix of own
and cross-partial derivatives

00:22:28.970 --> 00:22:32.750 align:middle line:84%
is symmetric and
negative semidefinite.

00:22:32.750 --> 00:22:35.570 align:middle line:90%
You may not remember that.

00:22:35.570 --> 00:22:37.520 align:middle line:84%
You think about one
good, then you just

00:22:37.520 --> 00:22:40.280 align:middle line:90%
have first the ii derivative.

00:22:40.280 --> 00:22:44.730 align:middle line:84%
You think about two, then you're
going to have a 2 by 2 matrix.

00:22:44.730 --> 00:22:47.180 align:middle line:84%
Then, you have the
determinant of that matrix.

00:22:47.180 --> 00:22:49.640 align:middle line:84%
If you have three goods,
then it's a bit tricky.

00:22:49.640 --> 00:22:52.130 align:middle line:84%
To factor the matrix,
got to figure out

00:22:52.130 --> 00:22:55.140 align:middle line:84%
the determinant of each of
the subcomponents and so on.

00:22:55.140 --> 00:22:57.920 align:middle line:84%
But an equivalent
way to check and see

00:22:57.920 --> 00:23:01.700 align:middle line:84%
whether all the conditions are
satisfied for concavity is just

00:23:01.700 --> 00:23:04.580 align:middle line:84%
to pre-multiply
and post-multiply

00:23:04.580 --> 00:23:10.400 align:middle line:84%
the matrix by a prime and
a, as arbitrary vectors,

00:23:10.400 --> 00:23:14.143 align:middle line:84%
and make sure the
result is negative.

00:23:14.143 --> 00:23:15.310 align:middle line:90%
So that's a bit of a review.

00:23:15.310 --> 00:23:17.410 align:middle line:84%
Don't worry about it if
you never learned it.

00:23:17.410 --> 00:23:22.000 align:middle line:84%
It's the same thing as getting
concavity of the expenditure

00:23:22.000 --> 00:23:23.170 align:middle line:90%
function.

00:23:23.170 --> 00:23:24.070 align:middle line:90%
OK.

00:23:24.070 --> 00:23:25.520 align:middle line:90%
So what?

00:23:25.520 --> 00:23:26.930 align:middle line:90%
OK.

00:23:26.930 --> 00:23:29.600 align:middle line:90%
Well, it's a bit problematic.

00:23:29.600 --> 00:23:32.000 align:middle line:84%
I said the motive today
was to get restrictions

00:23:32.000 --> 00:23:34.790 align:middle line:84%
on observables, but
we don't see this guy.

00:23:34.790 --> 00:23:37.040 align:middle line:84%
We don't see the
Hicksian demand.

00:23:37.040 --> 00:23:41.300 align:middle line:84%
We just see the Marshallian
demand, so we're in trouble.

00:23:41.300 --> 00:23:44.420 align:middle line:84%
Except this-- this
is a statement

00:23:44.420 --> 00:23:46.310 align:middle line:90%
about the Slutsky matrix.

00:23:46.310 --> 00:23:49.100 align:middle line:84%
What we want to find,
which is the derivative

00:23:49.100 --> 00:23:52.520 align:middle line:84%
of that thing we just
looked at, turns out,

00:23:52.520 --> 00:23:55.010 align:middle line:84%
it is associated
with observables.

00:23:55.010 --> 00:23:59.510 align:middle line:84%
This is the Lth good changing
with respect to the Kth price

00:23:59.510 --> 00:24:00.830 align:middle line:90%
is equal to--

00:24:00.830 --> 00:24:03.560 align:middle line:84%
the way the whole demand is
changing of the Lth good,

00:24:03.560 --> 00:24:05.930 align:middle line:90%
as we change the price pk.

00:24:05.930 --> 00:24:08.520 align:middle line:84%
But we adjust for
the income effect,

00:24:08.520 --> 00:24:10.550 align:middle line:84%
which is how the Lth
grid is changing,

00:24:10.550 --> 00:24:14.030 align:middle line:84%
as we change income or
wealth, post multiplied

00:24:14.030 --> 00:24:17.270 align:middle line:84%
by the quantity of the good
price of which is changing,

00:24:17.270 --> 00:24:19.850 align:middle line:90%
namely pxk for pk.

00:24:19.850 --> 00:24:20.660 align:middle line:90%
OK?

00:24:20.660 --> 00:24:24.000 align:middle line:84%
So then, you're probably
still struggling.

00:24:24.000 --> 00:24:25.820 align:middle line:90%
I went back to check.

00:24:25.820 --> 00:24:27.590 align:middle line:90%
You may remember this.

00:24:27.590 --> 00:24:32.090 align:middle line:84%
Remember this lecture where we
did the income and substitution

00:24:32.090 --> 00:24:35.650 align:middle line:90%
effects, these guys?

00:24:35.650 --> 00:24:40.990 align:middle line:84%
And then we decomposed
the total demand change,

00:24:40.990 --> 00:24:43.000 align:middle line:84%
as a consequence
of the price change

00:24:43.000 --> 00:24:47.860 align:middle line:84%
into the substitution effect
and the income effect.

00:24:47.860 --> 00:24:51.550 align:middle line:84%
And we had to clarify that the
income effect was negative,

00:24:51.550 --> 00:24:56.860 align:middle line:84%
because in that diagram we
had p on the wrong axis, given

00:24:56.860 --> 00:25:00.920 align:middle line:84%
the strange way economists
invented demand curves.

00:25:00.920 --> 00:25:03.700 align:middle line:84%
So then, what we're
trying to do today

00:25:03.700 --> 00:25:06.730 align:middle line:84%
is to get this
substitution effect matrix,

00:25:06.730 --> 00:25:08.860 align:middle line:84%
and we're getting
it from observables,

00:25:08.860 --> 00:25:13.510 align:middle line:84%
how demand is changing as price
changes plus how demand is

00:25:13.510 --> 00:25:15.980 align:middle line:90%
changing as income is changing.

00:25:15.980 --> 00:25:19.720 align:middle line:84%
So this simple example
equation is elaborated

00:25:19.720 --> 00:25:21.490 align:middle line:90%
in this Slutsky matrix.

00:25:21.490 --> 00:25:23.470 align:middle line:84%
The sign changes,
only because we

00:25:23.470 --> 00:25:25.450 align:middle line:84%
changed what's on
the left-hand side,

00:25:25.450 --> 00:25:28.150 align:middle line:84%
from the total demand to
the substitution effect.

00:25:28.150 --> 00:25:31.750 align:middle line:84%
Substitute effect equals total
demand plus income changes.

00:25:31.750 --> 00:25:34.060 align:middle line:84%
Substitution effect
equals change

00:25:34.060 --> 00:25:36.620 align:middle line:84%
in total demand
plus income changes.

00:25:36.620 --> 00:25:38.650 align:middle line:84%
So in fact, the
Slutsky thing is really

00:25:38.650 --> 00:25:41.620 align:middle line:84%
familiar to you from
that entire lecture

00:25:41.620 --> 00:25:44.710 align:middle line:84%
that we did on income
and substitution effects.

00:25:44.710 --> 00:25:48.340 align:middle line:84%
And now back to the
point, to reiterate.

00:25:48.340 --> 00:25:52.390 align:middle line:84%
This thing under the assumptions
on the previous slide

00:25:52.390 --> 00:25:57.040 align:middle line:84%
has to be, if we enumerated
it out for all l and k,

00:25:57.040 --> 00:26:01.120 align:middle line:84%
a symmetric negative
semidefinite matrix.

00:26:01.120 --> 00:26:04.240 align:middle line:84%
So we can fill in
the I, the row column

00:26:04.240 --> 00:26:06.880 align:middle line:84%
elements from all
these observables,

00:26:06.880 --> 00:26:11.090 align:middle line:84%
and just check and
see whether it's true.

00:26:11.090 --> 00:26:11.590 align:middle line:90%
OK.

00:26:11.590 --> 00:26:16.210 align:middle line:84%
So I should have said,
this is with infinite data,

00:26:16.210 --> 00:26:20.500 align:middle line:84%
because we're talking about
having derivatives, which

00:26:20.500 --> 00:26:22.720 align:middle line:90%
is infinitesimally small data.

00:26:22.720 --> 00:26:26.230 align:middle line:84%
But it's still good to know
that, in principle, there's

00:26:26.230 --> 00:26:27.220 align:middle line:90%
a way to do it.

00:26:27.220 --> 00:26:30.280 align:middle line:84%
If you can't identify
something with infinite data,

00:26:30.280 --> 00:26:34.150 align:middle line:84%
you're not going to identify
something with finite data.

00:26:34.150 --> 00:26:36.840 align:middle line:90%
So let's review where we are.

00:26:36.840 --> 00:26:41.130 align:middle line:84%
The goal here is to see whether
we have testable restrictions.

00:26:41.130 --> 00:26:44.580 align:middle line:84%
In particular, ask the
question whether what we see,

00:26:44.580 --> 00:26:49.530 align:middle line:84%
in terms of the demand function,
came from a utility maximizing

00:26:49.530 --> 00:26:52.120 align:middle line:90%
rational consumer or not.

00:26:52.120 --> 00:26:54.600 align:middle line:84%
So I'm just going to stick
you with a big database,

00:26:54.600 --> 00:26:57.120 align:middle line:84%
in this case an infinite
dimensional database,

00:26:57.120 --> 00:27:00.360 align:middle line:84%
and have you check and see
whether it could have come

00:27:00.360 --> 00:27:04.230 align:middle line:84%
from a rational maximizing--
maximizing some utility

00:27:04.230 --> 00:27:06.160 align:middle line:90%
function, consumer.

00:27:06.160 --> 00:27:06.870 align:middle line:90%
OK?

00:27:06.870 --> 00:27:12.450 align:middle line:84%
So what are the three properties
homogeneity of degree 0.

00:27:12.450 --> 00:27:16.530 align:middle line:84%
Again, multiplying income
and prices by a scalar,

00:27:16.530 --> 00:27:17.430 align:middle line:90%
you just get--

00:27:17.430 --> 00:27:19.770 align:middle line:90%
nothing changes.

00:27:19.770 --> 00:27:25.080 align:middle line:84%
That's a statement about not
being naive about inflation,

00:27:25.080 --> 00:27:26.370 align:middle line:90%
for example.

00:27:26.370 --> 00:27:29.460 align:middle line:84%
Although, I guess arguably,
it could be violated,

00:27:29.460 --> 00:27:33.720 align:middle line:84%
but it seems pretty reasonable
for a thoughtful consumer.

00:27:33.720 --> 00:27:36.480 align:middle line:84%
In two different situations
with prices and income

00:27:36.480 --> 00:27:38.070 align:middle line:84%
just being multiples
of one another,

00:27:38.070 --> 00:27:40.350 align:middle line:84%
they shouldn't
change what they do.

00:27:40.350 --> 00:27:43.170 align:middle line:84%
The second property
is called Walras Law,

00:27:43.170 --> 00:27:46.830 align:middle line:84%
which is a fancy name for
spending all your money.

00:27:46.830 --> 00:27:50.460 align:middle line:84%
Namely, if you have
wealth w, and you add up

00:27:50.460 --> 00:27:53.730 align:middle line:84%
all the expenses
observed to take place

00:27:53.730 --> 00:27:57.000 align:middle line:84%
at prices p, that's also
equal to your wealth.

00:27:57.000 --> 00:27:58.410 align:middle line:90%
So you don't underspend.

00:27:58.410 --> 00:28:01.830 align:middle line:84%
You can't overspend, because
that would violate the budget.

00:28:01.830 --> 00:28:03.480 align:middle line:90%
You don't have the money.

00:28:03.480 --> 00:28:05.310 align:middle line:84%
But you could, in
principle, underspend.

00:28:05.310 --> 00:28:07.860 align:middle line:84%
However, a rational
consumer with

00:28:07.860 --> 00:28:12.190 align:middle line:84%
local non-satiated preferences
would never do that.

00:28:12.190 --> 00:28:14.400 align:middle line:90%
They go right out to the budget.

00:28:14.400 --> 00:28:18.960 align:middle line:84%
Technically, Walras Law
is used to mean you only

00:28:18.960 --> 00:28:20.670 align:middle line:84%
need to solve for
the equilibrium--

00:28:20.670 --> 00:28:23.130 align:middle line:84%
if there are capital
L goods, you only

00:28:23.130 --> 00:28:26.160 align:middle line:84%
need to solve for the
equilibrium in L minus 1

00:28:26.160 --> 00:28:26.820 align:middle line:90%
of them.

00:28:26.820 --> 00:28:32.800 align:middle line:84%
Because the Lth is pinned
down by this budget equation.

00:28:32.800 --> 00:28:35.910 align:middle line:84%
So it's like no
extra restrictions.

00:28:35.910 --> 00:28:38.820 align:middle line:84%
And finally, the Slutsky
matrix, if the demand function

00:28:38.820 --> 00:28:41.970 align:middle line:84%
is differentiable
and single-valued,

00:28:41.970 --> 00:28:46.200 align:middle line:84%
then that matrix, s sub p and
w, is symmetric and negative

00:28:46.200 --> 00:28:48.130 align:middle line:90%
semidefinite.

00:28:48.130 --> 00:28:49.070 align:middle line:90%
OK.

00:28:49.070 --> 00:28:50.450 align:middle line:90%
Who cares?

00:28:50.450 --> 00:28:51.980 align:middle line:90%
Here's the content.

00:28:51.980 --> 00:28:55.430 align:middle line:84%
If the other two
things are true--

00:28:55.430 --> 00:28:58.160 align:middle line:84%
which one would
argue is likely to be

00:28:58.160 --> 00:29:00.860 align:middle line:90%
true in any generated data set--

00:29:00.860 --> 00:29:04.970 align:middle line:84%
if you can find anything
that's not symmetric or not

00:29:04.970 --> 00:29:08.030 align:middle line:84%
negative semidefinite,
then preferences

00:29:08.030 --> 00:29:11.720 align:middle line:84%
could not have come
from a locally--

00:29:11.720 --> 00:29:14.360 align:middle line:84%
from locally non-satiated
preference, as a solution

00:29:14.360 --> 00:29:15.990 align:middle line:90%
to the max problem.

00:29:15.990 --> 00:29:19.010 align:middle line:90%
So this is the necessity part.

00:29:19.010 --> 00:29:24.260 align:middle line:84%
If we have utility max, then all
three properties have to hold.

00:29:24.260 --> 00:29:28.970 align:middle line:84%
Otherwise, can't be true that it
came from utility max problem.

00:29:28.970 --> 00:29:32.610 align:middle line:84%
Now, one thing-- we'll get
to convexity in a minute,

00:29:32.610 --> 00:29:36.410 align:middle line:84%
but I'll just earmark that,
that there is no statement here

00:29:36.410 --> 00:29:41.800 align:middle line:84%
about convexity, just locally
non-satiated preferences,

00:29:41.800 --> 00:29:43.850 align:middle line:90%
and it's not quite fair.

00:29:43.850 --> 00:29:47.390 align:middle line:84%
The Slutsky thing we
derived did rely on--

00:29:47.390 --> 00:29:48.980 align:middle line:84%
at least the way
I presented it, it

00:29:48.980 --> 00:29:51.410 align:middle line:90%
relied on convex preferences.

00:29:51.410 --> 00:29:54.110 align:middle line:84%
The question here
is whether one can

00:29:54.110 --> 00:29:58.280 align:middle line:84%
test for non-convex preferences
with the data, which

00:29:58.280 --> 00:30:00.200 align:middle line:84%
is a bit of a
different question,

00:30:00.200 --> 00:30:02.580 align:middle line:90%
and I'll come back to that.

00:30:02.580 --> 00:30:05.480 align:middle line:84%
So those three
properties not only

00:30:05.480 --> 00:30:08.420 align:middle line:84%
have to be true, if
we maximize utility,

00:30:08.420 --> 00:30:12.500 align:middle line:84%
but if they're true in the
data, then we can always

00:30:12.500 --> 00:30:16.400 align:middle line:84%
find a utility function that
generated the observations,

00:30:16.400 --> 00:30:18.110 align:middle line:90%
and that's called integrability.

00:30:18.110 --> 00:30:20.610 align:middle line:84%
Let me give you the
formal statement of it.

00:30:20.610 --> 00:30:22.820 align:middle line:84%
So this is like the
sufficient part.

00:30:22.820 --> 00:30:27.470 align:middle line:84%
If preferences of a household
are strictly increasing,

00:30:27.470 --> 00:30:32.390 align:middle line:84%
strictly quasiconcave, then
the Walrasian demand function

00:30:32.390 --> 00:30:38.230 align:middle line:84%
is homogeneous of degree
0, satisfies Walras Law,

00:30:38.230 --> 00:30:41.740 align:middle line:84%
and it's Slutsky matrix
is symmetric and negative

00:30:41.740 --> 00:30:43.540 align:middle line:90%
semidefinite.

00:30:43.540 --> 00:30:45.380 align:middle line:90%
That's the first part.

00:30:45.380 --> 00:30:49.690 align:middle line:84%
The second part is, if the
demand function is homogeneous

00:30:49.690 --> 00:30:53.290 align:middle line:84%
of degree 0, satisfies
Walras's Law,

00:30:53.290 --> 00:30:55.750 align:middle line:84%
and the Slutsky matrix
is symmetric and negative

00:30:55.750 --> 00:30:59.560 align:middle line:84%
semidefinite, then there
exists a utility function that

00:30:59.560 --> 00:31:04.840 align:middle line:84%
is increasing quasiconcave that
would generate the observed

00:31:04.840 --> 00:31:06.020 align:middle line:90%
data.

00:31:06.020 --> 00:31:07.180 align:middle line:90%
So let me backtrack.

00:31:07.180 --> 00:31:10.490 align:middle line:84%
This first part A is
what we did initially.

00:31:10.490 --> 00:31:13.690 align:middle line:84%
The second part B is the
integrability theorem.

00:31:13.690 --> 00:31:16.150 align:middle line:84%
It says we can work
backwards from the data set

00:31:16.150 --> 00:31:19.810 align:middle line:84%
to an underlying utility
function, which again has

00:31:19.810 --> 00:31:23.590 align:middle line:84%
to be increasing
quasiconcave and would

00:31:23.590 --> 00:31:27.230 align:middle line:84%
generate the data as if a
solution to the max problem.

00:31:27.230 --> 00:31:32.170 align:middle line:84%
So this is the bit about
not testability of convex

00:31:32.170 --> 00:31:36.280 align:middle line:84%
preferences, and the idea
is we've deliberately

00:31:36.280 --> 00:31:40.840 align:middle line:84%
drawn underlying utility
function, which is not concave

00:31:40.840 --> 00:31:44.740 align:middle line:84%
or these upper contour sets
are not strictly convex.

00:31:44.740 --> 00:31:47.060 align:middle line:90%
You see the wiggle here.

00:31:47.060 --> 00:31:48.880 align:middle line:84%
But if we start
rotating a budget

00:31:48.880 --> 00:31:52.340 align:middle line:84%
line or along the
indifference curve

00:31:52.340 --> 00:31:54.830 align:middle line:84%
and picking out
the tangencies, we

00:31:54.830 --> 00:31:58.610 align:middle line:84%
would generate the
Hicksian demand, et cetera.

00:31:58.610 --> 00:32:02.060 align:middle line:84%
Then, we get to this
particular budget line,

00:32:02.060 --> 00:32:04.250 align:middle line:90%
where we're no longer pivoting.

00:32:04.250 --> 00:32:05.810 align:middle line:90%
We jump.

00:32:05.810 --> 00:32:08.570 align:middle line:84%
For a moment, we would be
indifferent between this point

00:32:08.570 --> 00:32:11.570 align:middle line:84%
and this point, and as
we keep rotating the line

00:32:11.570 --> 00:32:13.940 align:middle line:84%
and making it have
less and less slope,

00:32:13.940 --> 00:32:17.810 align:middle line:84%
we will start finding pivoting
along this curve indifference

00:32:17.810 --> 00:32:18.740 align:middle line:90%
curve.

00:32:18.740 --> 00:32:21.380 align:middle line:84%
That shouldn't be bending
back up again, but anyway.

00:32:21.380 --> 00:32:25.410 align:middle line:84%
So the point is we never end
up in this non-concave portion.

00:32:25.410 --> 00:32:27.740 align:middle line:84%
So we don't generate
observables in there.

00:32:27.740 --> 00:32:33.350 align:middle line:84%
What we would infer is they
have strictly concave, or weakly

00:32:33.350 --> 00:32:38.720 align:middle line:84%
linear, preferences over
certain ranges of prices, which

00:32:38.720 --> 00:32:43.520 align:middle line:84%
is consistent with an underlying
weakly quasiconcave utility

00:32:43.520 --> 00:32:44.810 align:middle line:90%
function.

00:32:44.810 --> 00:32:48.590 align:middle line:84%
Now this doesn't mean that
we can't test for convexity

00:32:48.590 --> 00:32:51.230 align:middle line:84%
of preferences in other
ways, but this whole lecture

00:32:51.230 --> 00:32:55.850 align:middle line:84%
is about restrictions on data
that come from market behavior,

00:32:55.850 --> 00:32:58.310 align:middle line:84%
maximizing utility
subject to budgets.

00:32:58.310 --> 00:33:00.230 align:middle line:84%
And if that's all
we have in the data,

00:33:00.230 --> 00:33:03.210 align:middle line:90%
we cannot test for convexity.

00:33:03.210 --> 00:33:06.840 align:middle line:84%
Again, the statement, there
exists a utility function that

00:33:06.840 --> 00:33:09.630 align:middle line:90%
is increasing in quasiconcave.

00:33:09.630 --> 00:33:11.280 align:middle line:84%
That's probably
confusing, because it

00:33:11.280 --> 00:33:13.650 align:middle line:84%
looks like we just said,
the utility function

00:33:13.650 --> 00:33:15.630 align:middle line:90%
is quasiconcave.

00:33:15.630 --> 00:33:18.960 align:middle line:90%
No, this one is not.

00:33:18.960 --> 00:33:20.790 align:middle line:84%
That's the true
underlying function,

00:33:20.790 --> 00:33:22.680 align:middle line:90%
but we can't test for that.

00:33:22.680 --> 00:33:26.010 align:middle line:84%
All we see in the
observables are the one

00:33:26.010 --> 00:33:29.280 align:middle line:84%
that as if generated
the dashed line,

00:33:29.280 --> 00:33:32.790 align:middle line:84%
and that utility
function is quasiconcave.

00:33:32.790 --> 00:33:35.970 align:middle line:84%
So that's the content
of this statement.

00:33:35.970 --> 00:33:41.400 align:middle line:84%
It's as if there were a utility
function which is quasiconcave.

00:33:41.400 --> 00:33:44.060 align:middle line:90%
Questions?

00:33:44.060 --> 00:33:45.410 align:middle line:90%
All right.

00:33:45.410 --> 00:33:49.100 align:middle line:84%
So operationally, we might as
well assume convex preferences,

00:33:49.100 --> 00:33:52.440 align:middle line:84%
because we're not going to
be able to reject it anyway.

00:33:52.440 --> 00:33:56.720 align:middle line:84%
That's an odd-sounding corollary
to this whole first part

00:33:56.720 --> 00:33:59.900 align:middle line:84%
of the lecture, which is the
goal of placing restrictions

00:33:59.900 --> 00:34:04.080 align:middle line:84%
on data, whether data place
restrictions on theory or not.

00:34:04.080 --> 00:34:07.190 align:middle line:84%
And finally, let me
say again, why are we

00:34:07.190 --> 00:34:11.330 align:middle line:84%
trying so hard to see what
we could potentially reject?

00:34:11.330 --> 00:34:13.850 align:middle line:84%
The answer is, if
say it's not Slutsky,

00:34:13.850 --> 00:34:17.989 align:middle line:84%
then it could not have come from
a rational consumer maximizing

00:34:17.989 --> 00:34:20.840 align:middle line:90%
utility, and that's good news.

00:34:20.840 --> 00:34:22.940 align:middle line:84%
If for any data
set, we can always

00:34:22.940 --> 00:34:25.730 align:middle line:84%
find a consumer
maximizing utility

00:34:25.730 --> 00:34:27.199 align:middle line:84%
that could have
generated the data,

00:34:27.199 --> 00:34:29.780 align:middle line:84%
then there's no
content to the theory.

00:34:29.780 --> 00:34:32.210 align:middle line:84%
It might be fun
to do the theory,

00:34:32.210 --> 00:34:34.710 align:middle line:84%
but it's a vacuous
empirical exercise.

00:34:34.710 --> 00:34:37.670 align:middle line:84%
It has no content,
if it's always true.

00:34:37.670 --> 00:34:39.600 align:middle line:84%
Fortunately, it's
not always true,

00:34:39.600 --> 00:34:42.469 align:middle line:84%
and these are the
conditions we can check.

00:34:42.469 --> 00:34:43.969 align:middle line:84%
It's an odd thing,
because then you

00:34:43.969 --> 00:34:46.820 align:middle line:84%
could end up with, oh my god,
where did this data come from?

00:34:46.820 --> 00:34:51.690 align:middle line:84%
It couldn't be coming from a
rational consumer, but anyway.

00:34:51.690 --> 00:34:56.610 align:middle line:84%
We actually like it if we can
reject things, strange science.

00:34:56.610 --> 00:34:59.910 align:middle line:90%
So now, let's go to finite data.

00:34:59.910 --> 00:35:01.950 align:middle line:84%
We had observed,
a minute ago, we

00:35:01.950 --> 00:35:04.140 align:middle line:84%
had the entire Walrasian
demand function

00:35:04.140 --> 00:35:08.560 align:middle line:84%
for arbitrarily small changes
in prices and wealth and so on,

00:35:08.560 --> 00:35:10.410 align:middle line:84%
but typically, we
don't see that.

00:35:10.410 --> 00:35:12.940 align:middle line:84%
We don't have an
infinite data set.

00:35:12.940 --> 00:35:15.720 align:middle line:84%
We may have a household,
and if we're lucky

00:35:15.720 --> 00:35:18.900 align:middle line:84%
we can observe that household
over long periods of time

00:35:18.900 --> 00:35:22.470 align:middle line:84%
and see what decisions
are being made,

00:35:22.470 --> 00:35:26.310 align:middle line:84%
if those things are recorded
on Alipay, for example.

00:35:26.310 --> 00:35:29.520 align:middle line:84%
And if it were true that
everything that was bought

00:35:29.520 --> 00:35:32.940 align:middle line:84%
was acquired on Alipay,
then we would see--

00:35:32.940 --> 00:35:35.550 align:middle line:84%
and if we also saw the
wealth, because they're

00:35:35.550 --> 00:35:37.590 align:middle line:84%
spending everything
on Alipay, then we

00:35:37.590 --> 00:35:40.740 align:middle line:84%
would actually, potentially,
have a very long data set,

00:35:40.740 --> 00:35:42.670 align:middle line:90%
but not infinite.

00:35:42.670 --> 00:35:46.020 align:middle line:84%
So we want to see whether
we can, nevertheless,

00:35:46.020 --> 00:35:49.110 align:middle line:84%
test the hypothesis
of rationality,

00:35:49.110 --> 00:35:51.450 align:middle line:84%
and the answer is
going to be positive.

00:35:51.450 --> 00:35:56.010 align:middle line:84%
There is a way to take the
data and run an algorithm

00:35:56.010 --> 00:36:00.990 align:middle line:84%
and see whether the results
are consistent but potentially

00:36:00.990 --> 00:36:02.730 align:middle line:90%
inconsistent.

00:36:02.730 --> 00:36:05.500 align:middle line:84%
And in the latter
case, we can reject.

00:36:05.500 --> 00:36:08.040 align:middle line:84%
So this is the
definition of the Weak

00:36:08.040 --> 00:36:10.230 align:middle line:90%
Axiom of Revealed Preference.

00:36:10.230 --> 00:36:14.190 align:middle line:84%
Let's start with just
having two observations

00:36:14.190 --> 00:36:17.580 align:middle line:84%
with different prices
and different choices.

00:36:17.580 --> 00:36:21.390 align:middle line:84%
(p1, x1) (p2, x2) is
a pair of observations

00:36:21.390 --> 00:36:23.640 align:middle line:84%
on prices and
consumption bundles,

00:36:23.640 --> 00:36:26.550 align:middle line:84%
implicitly for a
given household.

00:36:26.550 --> 00:36:31.020 align:middle line:84%
pt doesn't mean,
necessarily, t over time,

00:36:31.020 --> 00:36:34.980 align:middle line:84%
although you could
imagine we observed

00:36:34.980 --> 00:36:38.100 align:middle line:84%
at t equal 1 the first
choice and a t equal 2

00:36:38.100 --> 00:36:39.510 align:middle line:90%
the second choice.

00:36:39.510 --> 00:36:42.810 align:middle line:84%
But that's confusing, because
it raises the dynamic issues

00:36:42.810 --> 00:36:43.690 align:middle line:90%
and everything else.

00:36:43.690 --> 00:36:49.530 align:middle line:84%
So t is really only meant
here to index the data point,

00:36:49.530 --> 00:36:53.370 align:middle line:84%
and there's two data points
and hence two values for t.

00:36:53.370 --> 00:36:56.890 align:middle line:84%
And let's suppose
it's not trivial,

00:36:56.890 --> 00:36:59.610 align:middle line:90%
so these choices are different.

00:36:59.610 --> 00:37:02.970 align:middle line:84%
And we say the individual
choices, these choices,

00:37:02.970 --> 00:37:05.760 align:middle line:84%
satisfy the weak axiom
of real preference,

00:37:05.760 --> 00:37:13.260 align:middle line:84%
if whenever at the second price
is p2 with x2 chosen and x1

00:37:13.260 --> 00:37:16.470 align:middle line:84%
in the interior of the
budget, we must then have,

00:37:16.470 --> 00:37:22.200 align:middle line:84%
at prices p1, spending (p1,
x1), that x2 is not attainable.

00:37:22.200 --> 00:37:23.850 align:middle line:90%
So let me say it again.

00:37:23.850 --> 00:37:25.650 align:middle line:90%
It's an if-then thing.

00:37:25.650 --> 00:37:29.760 align:middle line:84%
If this is true in the data
that, if they had chosen x1,

00:37:29.760 --> 00:37:32.910 align:middle line:84%
they would not have been
spending all their money--

00:37:32.910 --> 00:37:35.520 align:middle line:84%
if that configuration
is true in the data,

00:37:35.520 --> 00:37:39.600 align:middle line:84%
then we better find
that, at prices p1,

00:37:39.600 --> 00:37:44.640 align:middle line:84%
the valuation of expenditures on
x2 is strictly greater than x1,

00:37:44.640 --> 00:37:47.650 align:middle line:84%
and again, the idea is
revealed preference.

00:37:47.650 --> 00:37:54.420 align:middle line:84%
So at prices p2, they are
revealed to prefer x2 over x1,

00:37:54.420 --> 00:37:57.120 align:middle line:84%
because x1 is available,
and they didn't choose it.

00:37:57.120 --> 00:38:00.480 align:middle line:84%
So it better not be the
case that, in some other way

00:38:00.480 --> 00:38:03.960 align:middle line:84%
of looking at the data,
this inequality is violated.

00:38:03.960 --> 00:38:08.640 align:middle line:84%
Because if at prices
p1, x2 were available,

00:38:08.640 --> 00:38:11.790 align:middle line:84%
because it's interior to
the budget at prices p1,

00:38:11.790 --> 00:38:14.610 align:middle line:84%
then to be consistent,
they should have chosen it,

00:38:14.610 --> 00:38:18.720 align:middle line:84%
because it's already shown
to be weakly preferred to x1.

00:38:18.720 --> 00:38:20.310 align:middle line:90%
So that's the idea.

00:38:20.310 --> 00:38:22.270 align:middle line:84%
If this is true,
then this is true.

00:38:22.270 --> 00:38:25.680 align:middle line:84%
So it's like a statement
of an algorithm running

00:38:25.680 --> 00:38:29.230 align:middle line:84%
over the data, and we're
going to generalize that.

00:38:29.230 --> 00:38:32.740 align:middle line:84%
So what happens if
this isn't true?

00:38:32.740 --> 00:38:34.840 align:middle line:90%
This is true, but this is not.

00:38:34.840 --> 00:38:37.110 align:middle line:90%
So let's look at a picture.

00:38:37.110 --> 00:38:44.140 align:middle line:84%
At prices p2, they choose
x2, so on the budget.

00:38:44.140 --> 00:38:51.680 align:middle line:84%
And x1 is interior, so
that's this condition.

00:38:51.680 --> 00:38:56.420 align:middle line:84%
x1 is interior to the
budget at prices p2.

00:38:56.420 --> 00:39:01.730 align:middle line:84%
Then, we look at prices
p2, p1, are they?

00:39:01.730 --> 00:39:03.710 align:middle line:90%
Here.

00:39:03.710 --> 00:39:05.050 align:middle line:90%
So here's x1.

00:39:05.050 --> 00:39:07.480 align:middle line:90%
It's on the budget at price p1.

00:39:07.480 --> 00:39:09.970 align:middle line:90%
The question is, where is x2?

00:39:09.970 --> 00:39:15.960 align:middle line:84%
In this case, x2 is interior
to the p1 budget line.

00:39:15.960 --> 00:39:17.400 align:middle line:90%
That violates.

00:39:17.400 --> 00:39:18.735 align:middle line:90%
We didn't want to find that.

00:39:18.735 --> 00:39:22.990 align:middle line:84%
That violates what
ought to be true,

00:39:22.990 --> 00:39:25.950 align:middle line:84%
and so it violates
the weak axiom.

00:39:25.950 --> 00:39:29.490 align:middle line:84%
Not only that, try to
draw indifference curves

00:39:29.490 --> 00:39:34.830 align:middle line:84%
from a quasiconcave or
linear or strictly convex,

00:39:34.830 --> 00:39:37.160 align:middle line:90%
you can't do it.

00:39:37.160 --> 00:39:41.600 align:middle line:84%
You'd get a tangency here,
you'd get a tangency here,

00:39:41.600 --> 00:39:45.140 align:middle line:84%
or looking at the bottom,
the indifference curves

00:39:45.140 --> 00:39:46.335 align:middle line:90%
would cross.

00:39:46.335 --> 00:39:48.710 align:middle line:84%
There's no way you can draw
this picture without crossing

00:39:48.710 --> 00:39:53.190 align:middle line:84%
the indifference curves and have
a tangent at the two choices.

00:39:53.190 --> 00:39:57.230 align:middle line:84%
Well, we learned
right in Lecture 2

00:39:57.230 --> 00:40:01.610 align:middle line:84%
that indifference curves can
cross for rational consumers.

00:40:01.610 --> 00:40:04.130 align:middle line:84%
A is preferred to B.
B is preferred to C .

00:40:04.130 --> 00:40:08.370 align:middle line:84%
A is preferred to C. You
may remember that diagram.

00:40:08.370 --> 00:40:12.110 align:middle line:84%
So that's meant to be an
intuitive proof of the picture

00:40:12.110 --> 00:40:13.950 align:middle line:90%
of the proposition.

00:40:13.950 --> 00:40:16.700 align:middle line:84%
So in conclusion,
for the weak axiom

00:40:16.700 --> 00:40:19.370 align:middle line:84%
if the agent has
preferences which

00:40:19.370 --> 00:40:21.920 align:middle line:84%
are locally non-satiated
and rational,

00:40:21.920 --> 00:40:27.080 align:middle line:84%
then given observations
on prices, expenditures,

00:40:27.080 --> 00:40:31.790 align:middle line:84%
and wealth, you must have
that the pairs of data points

00:40:31.790 --> 00:40:36.200 align:middle line:84%
satisfy this Weak Axiom of
Revealed Preference, WARP.

00:40:36.200 --> 00:40:38.210 align:middle line:90%
OK?

00:40:38.210 --> 00:40:40.530 align:middle line:90%
So now, we want to generalize.

00:40:40.530 --> 00:40:43.310 align:middle line:84%
We have here still
two data points,

00:40:43.310 --> 00:40:46.470 align:middle line:84%
just slightly
different notation.

00:40:46.470 --> 00:40:49.581 align:middle line:84%
The data points are
indexed by t and s,

00:40:49.581 --> 00:40:54.060 align:middle line:84%
and we write that
the t data point of x

00:40:54.060 --> 00:41:00.285 align:middle line:84%
is revealed directly preferred
to the data point indexed by s,

00:41:00.285 --> 00:41:03.870 align:middle line:90%
if x is available at prices pt.

00:41:03.870 --> 00:41:07.290 align:middle line:84%
So again, at prices
pt, they chose xt.

00:41:07.290 --> 00:41:09.420 align:middle line:84%
That's the way the
data are organized.

00:41:09.420 --> 00:41:12.390 align:middle line:84%
They could have chosen xs,
because it's in the budget,

00:41:12.390 --> 00:41:14.100 align:middle line:90%
but they didn't do it.

00:41:14.100 --> 00:41:17.580 align:middle line:84%
So we say directly
reveal preferred.

00:41:17.580 --> 00:41:19.860 align:middle line:84%
This might imply
strict preference,

00:41:19.860 --> 00:41:21.720 align:middle line:90%
but it doesn't really mean that.

00:41:21.720 --> 00:41:25.980 align:middle line:84%
It just means, as with the
axioms of reveal preference,

00:41:25.980 --> 00:41:27.600 align:middle line:90%
what we see is what they want.

00:41:27.600 --> 00:41:29.370 align:middle line:90%
That's all we're saying.

00:41:29.370 --> 00:41:33.930 align:middle line:84%
They reveal to prefer it, then
they continue to prefer it.

00:41:33.930 --> 00:41:36.840 align:middle line:84%
In this case, they prefer it
over other things they could

00:41:36.840 --> 00:41:38.300 align:middle line:90%
have chosen and didn't.

00:41:38.300 --> 00:41:40.380 align:middle line:90%
It's pretty simple-minded.

00:41:40.380 --> 00:41:44.500 align:middle line:84%
Then, we come to I almost want
to say indirectly revealed

00:41:44.500 --> 00:41:45.000 align:middle line:90%
preferred.

00:41:45.000 --> 00:41:47.430 align:middle line:84%
Actually, it's in
parentheses here

00:41:47.430 --> 00:41:50.460 align:middle line:84%
to contrast with the
directly revealed preferred.

00:41:50.460 --> 00:41:52.488 align:middle line:84%
So now we're going to
have a bigger data set.

00:41:52.488 --> 00:41:54.030 align:middle line:84%
We're going to have
a whole sequence,

00:41:54.030 --> 00:41:58.095 align:middle line:84%
and we say that
xt R without the d

00:41:58.095 --> 00:42:02.040 align:middle line:84%
is just revealed preferred
not directly preferred.

00:42:02.040 --> 00:42:05.820 align:middle line:84%
Or if you like, I for
indirectly preferred,

00:42:05.820 --> 00:42:10.050 align:middle line:84%
xt is revealed
preferred to xs, if we

00:42:10.050 --> 00:42:14.820 align:middle line:84%
have a sequence of data
points, such that pairwise we

00:42:14.820 --> 00:42:16.980 align:middle line:90%
have direct revelation.

00:42:16.980 --> 00:42:20.640 align:middle line:84%
So we want xt to,
at the beginning,

00:42:20.640 --> 00:42:24.130 align:middle line:90%
to be compared to xs at the end.

00:42:24.130 --> 00:42:27.240 align:middle line:84%
But we do that, we never
see, say in the data,

00:42:27.240 --> 00:42:30.570 align:middle line:84%
that they're
directly comparable.

00:42:30.570 --> 00:42:34.170 align:middle line:84%
Instead, we see
xt in a situation

00:42:34.170 --> 00:42:38.600 align:middle line:84%
where, within the budget, xt
is revealed directly preferred

00:42:38.600 --> 00:42:40.200 align:middle line:90%
to xr1.

00:42:40.200 --> 00:42:42.750 align:middle line:84%
In another piece
of the data, we see

00:42:42.750 --> 00:42:49.770 align:middle line:84%
xr1 is revealed directly to
xr2, and so on down the chain,

00:42:49.770 --> 00:42:54.430 align:middle line:84%
with xrk being revealed
directly preferred to xs.

00:42:54.430 --> 00:42:56.770 align:middle line:84%
So this is like the
transitivity axiom,

00:42:56.770 --> 00:43:01.130 align:middle line:84%
which is part of the axioms
of rational consumer.

00:43:01.130 --> 00:43:01.630 align:middle line:90%
Right?

00:43:01.630 --> 00:43:06.790 align:middle line:84%
We have a chain in which we have
directly revealed preference.

00:43:06.790 --> 00:43:09.100 align:middle line:84%
Hence, the one at
the beginning ought

00:43:09.100 --> 00:43:11.830 align:middle line:84%
to be indirectly revealed
preferred to the one

00:43:11.830 --> 00:43:12.860 align:middle line:90%
at the end.

00:43:12.860 --> 00:43:15.020 align:middle line:90%
Next xt to xs.

00:43:15.020 --> 00:43:18.700 align:middle line:84%
So then we come to
the Generalized Axiom

00:43:18.700 --> 00:43:21.700 align:middle line:84%
of Revealed
Preference, called GARP

00:43:21.700 --> 00:43:24.070 align:middle line:84%
so I don't know there was
a famous movie "The World

00:43:24.070 --> 00:43:25.030 align:middle line:90%
According to Garp."

00:43:25.030 --> 00:43:27.890 align:middle line:84%
I don't know if you-- was
a Robin Williams movie.

00:43:27.890 --> 00:43:28.870 align:middle line:90%
They didn't mean this.

00:43:28.870 --> 00:43:32.380 align:middle line:84%
So generalized
revealed preference

00:43:32.380 --> 00:43:37.790 align:middle line:84%
is building on this notion of
indirectly revealed preference.

00:43:37.790 --> 00:43:40.600 align:middle line:84%
If we have the data points
of the dimensionality--

00:43:40.600 --> 00:43:46.210 align:middle line:84%
the data set is capital T,
and we have prices and demands

00:43:46.210 --> 00:43:51.040 align:middle line:84%
for each T, then the general
axiom of revealed preference

00:43:51.040 --> 00:43:57.370 align:middle line:84%
means that, if xt is
indirectly revealed to xs, then

00:43:57.370 --> 00:43:59.830 align:middle line:84%
if we're able to
make the comparison,

00:43:59.830 --> 00:44:02.710 align:middle line:90%
we have the strict inequality.

00:44:02.710 --> 00:44:06.130 align:middle line:84%
Namely, xt is preferred
to xs, it better

00:44:06.130 --> 00:44:11.860 align:middle line:84%
be the case that, at prices
ps, xt is outside the budget,

00:44:11.860 --> 00:44:14.560 align:middle line:84%
relative to the
expenditures on xs.

00:44:14.560 --> 00:44:18.400 align:middle line:84%
And the intuition, as I wrote in
red at the bottom of the slide,

00:44:18.400 --> 00:44:22.120 align:middle line:84%
is simply imagine this
inequality is reversed.

00:44:22.120 --> 00:44:27.010 align:middle line:84%
Then, we would have, at prices
ps, xt is within the budget,

00:44:27.010 --> 00:44:31.060 align:middle line:84%
and xs ought to be at least
weakly if not strictly

00:44:31.060 --> 00:44:35.320 align:middle line:84%
preferred, because xs was
chosen, and xt was available.

00:44:35.320 --> 00:44:41.200 align:middle line:84%
So xs would be directly
revealed to be preferred to xt,

00:44:41.200 --> 00:44:42.820 align:middle line:90%
according to this definition.

00:44:42.820 --> 00:44:47.290 align:middle line:84%
But it goes the other way
here, where xt is revealed,

00:44:47.290 --> 00:44:50.260 align:middle line:84%
granted indirectly,
to be preferred to xs.

00:44:50.260 --> 00:44:54.310 align:middle line:84%
So that if this were a strict
inequality going the other way,

00:44:54.310 --> 00:44:56.740 align:middle line:90%
we would intuitively violate.

00:44:56.740 --> 00:44:59.080 align:middle line:84%
These two pieces of
information would not

00:44:59.080 --> 00:45:01.240 align:middle line:90%
be consistent with each other.

00:45:01.240 --> 00:45:05.110 align:middle line:84%
Now, again, you should think
about this as an algorithm.

00:45:05.110 --> 00:45:06.310 align:middle line:90%
Some classes do this.

00:45:06.310 --> 00:45:08.560 align:middle line:90%
I found one on the web today.

00:45:08.560 --> 00:45:10.720 align:middle line:84%
They give students
a very large data

00:45:10.720 --> 00:45:13.300 align:middle line:84%
set of prices and
quantities and just

00:45:13.300 --> 00:45:17.170 align:middle line:84%
ask them is this consistent
with a rational household?

00:45:17.170 --> 00:45:19.010 align:middle line:90%
And how do you approach that?

00:45:19.010 --> 00:45:22.400 align:middle line:84%
Well, you start looking
for these chains.

00:45:22.400 --> 00:45:26.290 align:middle line:84%
You have to construct them
algorithmically and get,

00:45:26.290 --> 00:45:29.860 align:middle line:84%
as a result when it's true,
a statement about x and t

00:45:29.860 --> 00:45:31.660 align:middle line:90%
indirectly reveal preferred.

00:45:31.660 --> 00:45:33.880 align:middle line:84%
And then in the
same data set, go

00:45:33.880 --> 00:45:37.420 align:middle line:84%
looking for an instance where
there was a direct comparison,

00:45:37.420 --> 00:45:41.110 align:middle line:84%
and it better be that
the inequality is weakly

00:45:41.110 --> 00:45:42.770 align:middle line:90%
going this direction.

00:45:42.770 --> 00:45:45.777 align:middle line:84%
So it's an algorithm,
I'm trying to say.

00:45:45.777 --> 00:45:47.860 align:middle line:84%
Because again, if it doesn't
go in this direction,

00:45:47.860 --> 00:45:51.250 align:middle line:84%
then it contradicts the whole
notion of revealed preference

00:45:51.250 --> 00:45:53.050 align:middle line:90%
and transitivity.

00:45:53.050 --> 00:45:56.770 align:middle line:90%
So again, good news, ironically.

00:45:56.770 --> 00:46:00.280 align:middle line:84%
We are potentially
able to reject.

00:46:00.280 --> 00:46:03.580 align:middle line:84%
There are comparisons
in the data which,

00:46:03.580 --> 00:46:05.980 align:middle line:84%
if this inequality
goes the other way,

00:46:05.980 --> 00:46:08.830 align:middle line:84%
would tell us there's no
way that this data came

00:46:08.830 --> 00:46:11.620 align:middle line:84%
from a rational
maximizing consumer,

00:46:11.620 --> 00:46:13.000 align:middle line:90%
and that's good for us.

00:46:13.000 --> 00:46:16.220 align:middle line:84%
Now, it doesn't mean that,
in any given data set,

00:46:16.220 --> 00:46:19.330 align:middle line:84%
you will necessarily
find a violation,

00:46:19.330 --> 00:46:21.490 align:middle line:84%
but you end up with
a weak statement

00:46:21.490 --> 00:46:25.600 align:middle line:84%
that the data set look as if
there was nothing inconsistent

00:46:25.600 --> 00:46:28.300 align:middle line:84%
in this data, with respect
to the statement that they

00:46:28.300 --> 00:46:32.090 align:middle line:84%
came from a rational
maximizing consumer.

00:46:32.090 --> 00:46:35.130 align:middle line:84%
So we should check and
make sure that that's true,

00:46:35.130 --> 00:46:36.970 align:middle line:90%
and that's the spirit of it.

00:46:36.970 --> 00:46:39.290 align:middle line:90%
Questions?

00:46:39.290 --> 00:46:40.340 align:middle line:90%
OK.

00:46:40.340 --> 00:46:43.400 align:middle line:84%
So let me get to the
computational part.

00:46:43.400 --> 00:46:46.040 align:middle line:84%
These guys at Caltech,
consumer theory

00:46:46.040 --> 00:46:49.490 align:middle line:84%
assumes consumers possess
infinite computational

00:46:49.490 --> 00:46:50.360 align:middle line:90%
abilities.

00:46:50.360 --> 00:46:54.380 align:middle line:84%
Like they can solve max problems
and potentially hard problems.

00:46:54.380 --> 00:46:56.780 align:middle line:84%
Proponents of
bounded rationality

00:46:56.780 --> 00:47:00.830 align:middle line:84%
want to require that any
reasonable model of consumer

00:47:00.830 --> 00:47:04.920 align:middle line:84%
behavior incorporate
computational constraints.

00:47:04.920 --> 00:47:08.660 align:middle line:84%
In other words, they may not be
able to solve a hard problem.

00:47:08.660 --> 00:47:10.760 align:middle line:84%
They may choose
something, but it

00:47:10.760 --> 00:47:13.190 align:middle line:84%
wouldn't be the full
solution, because they're not

00:47:13.190 --> 00:47:14.570 align:middle line:90%
able to compute it.

00:47:14.570 --> 00:47:18.560 align:middle line:84%
And Echenique and his coauthors
are saying, that's false.

00:47:18.560 --> 00:47:21.110 align:middle line:84%
Very much in the spirit
of revealed preference,

00:47:21.110 --> 00:47:24.290 align:middle line:84%
any consumption data
set that is compatible

00:47:24.290 --> 00:47:27.650 align:middle line:90%
with a rational consumer--

00:47:27.650 --> 00:47:29.930 align:middle line:84%
excuse me-- is also
compatible with

00:47:29.930 --> 00:47:33.440 align:middle line:84%
a rational and computationally
bounded consumer.

00:47:33.440 --> 00:47:36.410 align:middle line:84%
That is to say, the
data set in hand

00:47:36.410 --> 00:47:40.280 align:middle line:84%
can always be rationalized
by a utility function that's

00:47:40.280 --> 00:47:45.610 align:middle line:84%
pretty easy to solve, meaning
solved in polynomial time.

00:47:45.610 --> 00:47:47.760 align:middle line:84%
So this is very
much like not being

00:47:47.760 --> 00:47:50.530 align:middle line:84%
able to test the
convexity of preferences.

00:47:50.530 --> 00:47:53.160 align:middle line:84%
You start with
something non-convex,

00:47:53.160 --> 00:47:55.530 align:middle line:84%
but it generates a data
set that could also be

00:47:55.530 --> 00:47:58.220 align:middle line:90%
generated by something convex.

00:47:58.220 --> 00:48:00.620 align:middle line:84%
We start with
something that could

00:48:00.620 --> 00:48:04.340 align:middle line:84%
have come from the household
solving a hard problem,

00:48:04.340 --> 00:48:08.150 align:middle line:84%
but it could also have come from
a household solving a simpler

00:48:08.150 --> 00:48:09.140 align:middle line:90%
problem.

00:48:09.140 --> 00:48:11.540 align:middle line:84%
I'm not giving you any
intuition on this right now.

00:48:11.540 --> 00:48:13.790 align:middle line:84%
I'm telling you what
these computer scientists

00:48:13.790 --> 00:48:14.600 align:middle line:90%
have figured out.

00:48:14.600 --> 00:48:18.470 align:middle line:84%
And again their metric
is, how hard is it

00:48:18.470 --> 00:48:20.900 align:middle line:90%
to solve the problem?

00:48:20.900 --> 00:48:22.640 align:middle line:84%
Looking at
derivatives and so on,

00:48:22.640 --> 00:48:24.620 align:middle line:84%
how long does it
take, as we, say,

00:48:24.620 --> 00:48:26.580 align:middle line:90%
increase the number of goods?

00:48:26.580 --> 00:48:28.430 align:middle line:90%
If it's exponential, it's bad.

00:48:28.430 --> 00:48:30.830 align:middle line:90%
If it's polynomial, it's good.

00:48:30.830 --> 00:48:31.490 align:middle line:90%
All right.

00:48:31.490 --> 00:48:34.730 align:middle line:84%
Another version of this, instead
of having a single household

00:48:34.730 --> 00:48:38.930 align:middle line:84%
maximizing, or otherwise,
we have multiple agents

00:48:38.930 --> 00:48:41.220 align:middle line:90%
interacting in a market economy.

00:48:41.220 --> 00:48:45.500 align:middle line:84%
We want to say, if possible,
that the observed market

00:48:45.500 --> 00:48:50.570 align:middle line:84%
outcomes are consistent not only
with individual maximization

00:48:50.570 --> 00:48:53.550 align:middle line:90%
but with Walrasian equilibrium.

00:48:53.550 --> 00:48:56.240 align:middle line:84%
So what is the
empirical content?

00:48:56.240 --> 00:48:59.180 align:middle line:84%
Is it really hard to solve
the general equilibrium

00:48:59.180 --> 00:49:00.290 align:middle line:90%
computationally?

00:49:00.290 --> 00:49:02.930 align:middle line:84%
In which case, it's
not likely we're

00:49:02.930 --> 00:49:05.390 align:middle line:84%
going to be able to
accept in the data

00:49:05.390 --> 00:49:07.430 align:middle line:84%
that it came from the
underlying economy,

00:49:07.430 --> 00:49:11.090 align:middle line:84%
or it's a version of the
individual maximization

00:49:11.090 --> 00:49:12.260 align:middle line:90%
problem.

00:49:12.260 --> 00:49:15.860 align:middle line:84%
That there's another economy,
which is actually easier

00:49:15.860 --> 00:49:19.800 align:middle line:84%
to solve, that could have
generated the same data.

00:49:19.800 --> 00:49:22.400 align:middle line:84%
This is totally
remarkable stuff.

00:49:22.400 --> 00:49:24.410 align:middle line:84%
Because it goes
against the grain

00:49:24.410 --> 00:49:28.760 align:middle line:84%
of the way one would like to
think about it, as rational

00:49:28.760 --> 00:49:31.580 align:middle line:84%
as consumers can
possibly be, it's

00:49:31.580 --> 00:49:34.760 align:middle line:84%
unlikely they can solve in
their minds problems that

00:49:34.760 --> 00:49:37.520 align:middle line:84%
prove intractable for
computer scientists equipped

00:49:37.520 --> 00:49:39.080 align:middle line:90%
with the latest technology.

00:49:39.080 --> 00:49:40.190 align:middle line:90%
It's a cool statement.

00:49:40.190 --> 00:49:42.620 align:middle line:84%
These are really famous
theorists, by the way.

00:49:42.620 --> 00:49:45.230 align:middle line:84%
Gilboa, Schmaidler,
and Postlewaite

00:49:45.230 --> 00:49:47.210 align:middle line:90%
solve in their minds--

00:49:47.210 --> 00:49:52.700 align:middle line:84%
get it-- what you would
need for a supercomputer.

00:49:52.700 --> 00:49:55.250 align:middle line:84%
If an equilibrium is not
efficiently computed--

00:49:55.250 --> 00:49:57.230 align:middle line:90%
this is the market version--

00:49:57.230 --> 00:50:00.620 align:middle line:84%
much of the credibility of
using the predicate that we have

00:50:00.620 --> 00:50:04.370 align:middle line:84%
rational agents is lost, and
a shorthand version of that--

00:50:04.370 --> 00:50:07.740 align:middle line:84%
if your laptop can't find
it, neither can the market.

00:50:07.740 --> 00:50:10.260 align:middle line:84%
But these guys are
saying, that's just wrong.

00:50:10.260 --> 00:50:12.470 align:middle line:90%
It's just completely wrong.

00:50:12.470 --> 00:50:15.800 align:middle line:84%
Because they misunderstand
the role of models

00:50:15.800 --> 00:50:22.190 align:middle line:84%
in economics, which is as if
the model were a reality, then

00:50:22.190 --> 00:50:23.750 align:middle line:90%
there are restrictions on data.

00:50:23.750 --> 00:50:26.210 align:middle line:84%
It is not a statement
that we have

00:50:26.210 --> 00:50:29.250 align:middle line:84%
all of the reality
captured in the model.

00:50:29.250 --> 00:50:33.890 align:middle line:84%
So the reality behaves as
if the theory were true.

00:50:33.890 --> 00:50:38.880 align:middle line:84%
A consumption data set is either
not rationalizable at all--

00:50:38.880 --> 00:50:40.430 align:middle line:90%
so that's the rejection part.

00:50:40.430 --> 00:50:42.440 align:middle line:84%
They're not going
to overturn that.

00:50:42.440 --> 00:50:43.910 align:middle line:90%
There's still content.

00:50:43.910 --> 00:50:46.280 align:middle line:84%
It's either not
rationalizable at all,

00:50:46.280 --> 00:50:50.090 align:middle line:84%
or it's rationalizable by
utility function that's

00:50:50.090 --> 00:50:51.980 align:middle line:90%
fairly easy to maximize.

00:50:51.980 --> 00:50:54.800 align:middle line:84%
When I show you these slides,
I want to show you more,

00:50:54.800 --> 00:50:56.480 align:middle line:84%
but I guess we
have limited time.

00:50:56.480 --> 00:50:59.630 align:middle line:84%
So I probably should have put
this paper on the reading list

00:50:59.630 --> 00:51:01.040 align:middle line:90%
as optional.

00:51:01.040 --> 00:51:01.760 align:middle line:90%
OK.

00:51:01.760 --> 00:51:06.080 align:middle line:84%
So let's go to general
equilibrium in a paper of Brown

00:51:06.080 --> 00:51:07.970 align:middle line:84%
and Matzkin, which
all things considered,

00:51:07.970 --> 00:51:09.890 align:middle line:90%
is relatively recent.

00:51:09.890 --> 00:51:12.830 align:middle line:84%
Suppose we're given data set
on a number of households,

00:51:12.830 --> 00:51:16.340 align:middle line:84%
capital I in the
economy, and we see

00:51:16.340 --> 00:51:18.890 align:middle line:90%
their individual endowments--

00:51:18.890 --> 00:51:24.740 align:middle line:84%
private ownership economy, omega
I, across households capital I.

00:51:24.740 --> 00:51:28.730 align:middle line:84%
Then, there's something that
I'll elaborate in words now

00:51:28.730 --> 00:51:30.500 align:middle line:90%
called Anything Goes.

00:51:30.500 --> 00:51:34.460 align:middle line:84%
General equilibrium theory does
not put restrictions on data.

00:51:34.460 --> 00:51:36.770 align:middle line:90%
Anything goes.

00:51:36.770 --> 00:51:37.850 align:middle line:90%
And that was a killer.

00:51:37.850 --> 00:51:41.000 align:middle line:84%
That killed the whole
subject for a long time,

00:51:41.000 --> 00:51:42.800 align:middle line:90%
because of what I'm saying.

00:51:42.800 --> 00:51:47.570 align:middle line:84%
Now, the object in question
was our famous excess demand

00:51:47.570 --> 00:51:50.240 align:middle line:84%
function that we have used
before, the aggregate demand

00:51:50.240 --> 00:51:52.370 align:middle line:84%
function that
we've been focusing

00:51:52.370 --> 00:51:55.070 align:middle line:90%
on with aggregation and so on.

00:51:55.070 --> 00:51:57.590 align:middle line:84%
What shape does that
aggregate demand function

00:51:57.590 --> 00:51:59.960 align:middle line:90%
have, as we vary prices?

00:51:59.960 --> 00:52:02.990 align:middle line:84%
And the answer was whatever
wiggle and turn it has,

00:52:02.990 --> 00:52:06.750 align:middle line:84%
including upsloping
portions and so on.

00:52:06.750 --> 00:52:09.230 align:middle line:84%
You can always find
an underlying economy

00:52:09.230 --> 00:52:12.180 align:middle line:84%
that would have generated
that excess demand.

00:52:12.180 --> 00:52:15.800 align:middle line:84%
So this part of it is the
seeming answer to the question.

00:52:15.800 --> 00:52:18.290 align:middle line:84%
What happens if we don't
put any restrictions

00:52:18.290 --> 00:52:22.190 align:middle line:84%
on utility functions, other
than things like rationality?

00:52:22.190 --> 00:52:25.790 align:middle line:84%
And the answer is
anything could happen.

00:52:25.790 --> 00:52:27.890 align:middle line:84%
That aggregate
demand function could

00:52:27.890 --> 00:52:29.450 align:middle line:90%
look any way you want it to.

00:52:29.450 --> 00:52:31.820 align:middle line:84%
For any aggregate
demand function,

00:52:31.820 --> 00:52:35.720 align:middle line:84%
we can populate an economy with
a finite number of households,

00:52:35.720 --> 00:52:40.640 align:middle line:84%
give them certain preferences
and ownership of resources

00:52:40.640 --> 00:52:42.950 align:middle line:84%
in such a way that we can
get that aggregate demand

00:52:42.950 --> 00:52:46.080 align:middle line:84%
to shift and turn and
do whatever we want.

00:52:46.080 --> 00:52:49.010 align:middle line:84%
So again, the shorthand
is anything goes,

00:52:49.010 --> 00:52:52.340 align:middle line:84%
and because we could
never reject the model,

00:52:52.340 --> 00:52:55.580 align:middle line:84%
people thought that general
equilibrium had no content,

00:52:55.580 --> 00:52:57.050 align:middle line:90%
and they stopped doing it.

00:52:57.050 --> 00:52:59.340 align:middle line:90%
It was discredited.

00:52:59.340 --> 00:53:00.900 align:middle line:90%
This was not just one person.

00:53:00.900 --> 00:53:05.550 align:middle line:84%
It was Hugo Sonnenschein,
Debreu, and Mantel.

00:53:05.550 --> 00:53:06.840 align:middle line:90%
OK.

00:53:06.840 --> 00:53:09.150 align:middle line:90%
But let's just change this.

00:53:09.150 --> 00:53:12.270 align:middle line:84%
First, what is this seemingly
reasonable but actually crazy

00:53:12.270 --> 00:53:14.520 align:middle line:84%
thing that we actually
see the excess demand?

00:53:14.520 --> 00:53:16.500 align:middle line:90%
We never see that.

00:53:16.500 --> 00:53:18.450 align:middle line:84%
If we see market
economy, we only

00:53:18.450 --> 00:53:19.860 align:middle line:90%
see market clearing prices.

00:53:19.860 --> 00:53:23.380 align:middle line:84%
We don't see what happens
out of equilibrium.

00:53:23.380 --> 00:53:25.320 align:middle line:90%
So we only see where it crosses.

00:53:25.320 --> 00:53:28.660 align:middle line:90%
We see the fixed points.

00:53:28.660 --> 00:53:31.500 align:middle line:84%
Well, let's give us a
little more data then.

00:53:31.500 --> 00:53:33.570 align:middle line:84%
Given a set of
observations on prices

00:53:33.570 --> 00:53:36.820 align:middle line:84%
and individual endowments,
does there exist--

00:53:36.820 --> 00:53:37.320 align:middle line:90%
OK.

00:53:37.320 --> 00:53:40.380 align:middle line:90%
So T now indicates the economy.

00:53:40.380 --> 00:53:42.930 align:middle line:84%
It's as if we're going to
go in the cross section,

00:53:42.930 --> 00:53:45.930 align:middle line:84%
across several or
many economies that

00:53:45.930 --> 00:53:49.900 align:middle line:84%
vary in the individual
ownership of endowments.

00:53:49.900 --> 00:53:55.110 align:middle line:84%
So it's omega IT for the
Tth economy observation.

00:53:55.110 --> 00:53:56.970 align:middle line:84%
For any T that varies
over I, we have

00:53:56.970 --> 00:53:59.880 align:middle line:84%
a finite number of households,
but T is varying in the sample.

00:53:59.880 --> 00:54:02.520 align:middle line:84%
That's the number of
economies in the sample.

00:54:02.520 --> 00:54:05.910 align:middle line:84%
Those economies are all
alike for preferences,

00:54:05.910 --> 00:54:07.440 align:middle line:90%
that's assumed.

00:54:07.440 --> 00:54:12.660 align:middle line:84%
But they differ in the ownership
structure, the omega ITs.

00:54:12.660 --> 00:54:15.690 align:middle line:84%
So then does there
exist a sequence

00:54:15.690 --> 00:54:20.250 align:middle line:84%
of these economies, each with
its associated aggregate excess

00:54:20.250 --> 00:54:25.590 align:middle line:84%
demand, but such that
those prices that we see

00:54:25.590 --> 00:54:28.440 align:middle line:84%
stuck into the aggregated
excess demand equals 0.

00:54:28.440 --> 00:54:30.150 align:middle line:84%
This last statement
is just a statement

00:54:30.150 --> 00:54:32.535 align:middle line:84%
that the price has
come from a market.

00:54:32.535 --> 00:54:35.370 align:middle line:84%
In other words, the data
set we're going to see

00:54:35.370 --> 00:54:39.660 align:middle line:84%
would be the prices that
because it's a market

00:54:39.660 --> 00:54:44.072 align:middle line:84%
or associated with zero excess
demand, equilibrium prices.

00:54:44.072 --> 00:54:45.780 align:middle line:84%
So we're going to see
equilibrium prices,

00:54:45.780 --> 00:54:49.590 align:middle line:84%
and we're also going to
see individual endowments,

00:54:49.590 --> 00:54:52.540 align:middle line:84%
assuming preferences
are all the same.

00:54:52.540 --> 00:54:55.140 align:middle line:90%
So I'll give you the punch line.

00:54:55.140 --> 00:54:57.060 align:middle line:90%
That's Brown and Matzkin.

00:54:57.060 --> 00:55:00.000 align:middle line:84%
The punch line is going to
be what we've been saying

00:55:00.000 --> 00:55:02.190 align:middle line:90%
throughout the lecture today.

00:55:02.190 --> 00:55:04.800 align:middle line:84%
Namely, if we're
given data like this,

00:55:04.800 --> 00:55:08.460 align:middle line:84%
we can actually reject
that the data could have

00:55:08.460 --> 00:55:11.070 align:middle line:90%
come as a market equilibrium.

00:55:11.070 --> 00:55:13.110 align:middle line:84%
That is to say, that
the market the data

00:55:13.110 --> 00:55:17.790 align:middle line:84%
couldn't potentially never have
come from individual household

00:55:17.790 --> 00:55:20.670 align:middle line:84%
maximization and
market clearing.

00:55:20.670 --> 00:55:22.510 align:middle line:90%
So it has content.

00:55:22.510 --> 00:55:24.780 align:middle line:84%
Here's the differentiable
version of it.

00:55:24.780 --> 00:55:28.080 align:middle line:84%
As abstract as general
equilibrium theory is, this

00:55:28.080 --> 00:55:31.470 align:middle line:84%
Sonnenschein, Debreu,
and Mantel is overturned.

00:55:31.470 --> 00:55:33.870 align:middle line:84%
They're applying it to
an exchange economy,

00:55:33.870 --> 00:55:35.800 align:middle line:84%
where we see prices
and endowments.

00:55:35.800 --> 00:55:38.520 align:middle line:84%
They derive necessary
and sufficient conditions

00:55:38.520 --> 00:55:42.330 align:middle line:84%
for the equilibrium prices as a
function of initial endowments,

00:55:42.330 --> 00:55:45.150 align:middle line:84%
and in their language,
they show that the economy

00:55:45.150 --> 00:55:47.970 align:middle line:90%
can be generically identified.

00:55:47.970 --> 00:55:51.720 align:middle line:84%
What they mean by that is there
is an underlying economy that

00:55:51.720 --> 00:55:54.810 align:middle line:84%
would have generated
the data, but also

00:55:54.810 --> 00:55:57.570 align:middle line:84%
that, in principle,
one could have not

00:55:57.570 --> 00:55:59.820 align:middle line:84%
been able to find
such an economy.

00:55:59.820 --> 00:56:02.430 align:middle line:84%
And then to summarize
where we are,

00:56:02.430 --> 00:56:05.370 align:middle line:84%
if you only had aggregate
data, you're sunk.

00:56:05.370 --> 00:56:08.910 align:middle line:84%
You're never going
to get conditions

00:56:08.910 --> 00:56:10.710 align:middle line:90%
that allow you to reject.

00:56:10.710 --> 00:56:12.900 align:middle line:84%
But when you have
individual data,

00:56:12.900 --> 00:56:15.630 align:middle line:84%
you can get testable
restrictions

00:56:15.630 --> 00:56:19.360 align:middle line:84%
and bring back the content of
general equilibrium theory.

00:56:19.360 --> 00:56:23.580 align:middle line:84%
So again, this summarizes
my deliberately provocative

00:56:23.580 --> 00:56:28.380 align:middle line:84%
statement that you need
micro data to do macro.

00:56:28.380 --> 00:56:31.650 align:middle line:84%
And then they go on to
talk about something

00:56:31.650 --> 00:56:35.070 align:middle line:84%
you're familiar with, because
we did it in the class.

00:56:35.070 --> 00:56:37.530 align:middle line:84%
We're sharing in
Indian villages.

00:56:37.530 --> 00:56:41.340 align:middle line:84%
It's not uncommon to
observe endowments,

00:56:41.340 --> 00:56:43.960 align:middle line:90%
like crops and prices.

00:56:43.960 --> 00:56:45.840 align:middle line:84%
We did a little bit
of that, less so

00:56:45.840 --> 00:56:47.940 align:middle line:84%
with the risk
sharing, in which case

00:56:47.940 --> 00:56:51.150 align:middle line:90%
their content works directly.

00:56:51.150 --> 00:56:53.430 align:middle line:84%
If you really believed you
were going from one village

00:56:53.430 --> 00:56:55.720 align:middle line:84%
to another, each
were self-contained.

00:56:55.720 --> 00:56:58.230 align:middle line:84%
They had the same
preferences and the premise

00:56:58.230 --> 00:57:00.480 align:middle line:84%
would be we're seeing
market outcomes,

00:57:00.480 --> 00:57:03.150 align:middle line:84%
then their theory
applies directly.

00:57:03.150 --> 00:57:06.930 align:middle line:84%
You can even go to large
economies, not villages,

00:57:06.930 --> 00:57:10.320 align:middle line:84%
and think about
types of individuals,

00:57:10.320 --> 00:57:14.250 align:middle line:84%
finite number of types, but
a large number of individuals

00:57:14.250 --> 00:57:19.870 align:middle line:84%
of a given type and again
you can use their artillery.

00:57:19.870 --> 00:57:21.820 align:middle line:84%
Now, interestingly,
lest you think

00:57:21.820 --> 00:57:24.910 align:middle line:84%
economists have this
all figured out,

00:57:24.910 --> 00:57:28.330 align:middle line:84%
an interesting question is how
to extend this to production.

00:57:28.330 --> 00:57:32.380 align:middle line:84%
They refer to changes
in fact or endowments,

00:57:32.380 --> 00:57:35.660 align:middle line:84%
which have observable
impact on factor prices.

00:57:35.660 --> 00:57:39.130 align:middle line:84%
So that's an allusion to
the trade lectures we did.

00:57:39.130 --> 00:57:41.080 align:middle line:84%
And they haven't
figured it out yet.

00:57:41.080 --> 00:57:44.440 align:middle line:84%
They haven't figured
out whether there

00:57:44.440 --> 00:57:46.100 align:middle line:90%
are rejectable restrictions.

00:57:46.100 --> 00:57:50.210 align:middle line:84%
Remember, when we did the
model, the 2 by 2 case,

00:57:50.210 --> 00:57:55.460 align:middle line:84%
we had constant returns to scale
and a few other assumptions.

00:57:55.460 --> 00:57:58.780 align:middle line:84%
So they're saying like
drop all assumptions.

00:57:58.780 --> 00:58:01.960 align:middle line:84%
Could we put
restrictions on data

00:58:01.960 --> 00:58:07.330 align:middle line:84%
and say we'd never see
violations of some kind,

00:58:07.330 --> 00:58:09.250 align:middle line:90%
and they haven't figured it out.

00:58:09.250 --> 00:58:13.500 align:middle line:84%
So we're on the research
frontier at this point.

00:58:13.500 --> 00:58:17.400 align:middle line:84%
So that's what I have
for today, again, very

00:58:17.400 --> 00:58:20.770 align:middle line:84%
much part and parcel of the
whole spirit of the class.

00:58:20.770 --> 00:58:23.730 align:middle line:84%
Which is to think
about economists

00:58:23.730 --> 00:58:29.070 align:middle line:84%
as running experiments, and
you saw three of them today.

00:58:29.070 --> 00:58:37.243 align:middle line:90%