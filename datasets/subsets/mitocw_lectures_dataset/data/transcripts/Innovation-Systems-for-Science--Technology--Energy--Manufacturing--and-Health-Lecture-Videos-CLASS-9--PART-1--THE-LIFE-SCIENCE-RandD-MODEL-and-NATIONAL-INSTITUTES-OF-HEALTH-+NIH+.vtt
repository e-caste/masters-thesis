WEBVTT

00:00:00.090 --> 00:00:02.430
The following content is
provided under a Creative

00:00:02.430 --> 00:00:03.820
Commons license.

00:00:03.820 --> 00:00:06.030
Your support will help
MIT OpenCourseWare

00:00:06.030 --> 00:00:10.120
continue to offer high-quality
educational resources for free.

00:00:10.120 --> 00:00:12.660
To make a donation or to
view additional materials

00:00:12.660 --> 00:00:16.620
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.620 --> 00:00:17.992
at ocw.mit.edu.

00:00:21.080 --> 00:00:23.930
WILLIAM BONVILLIAN:
So I try to do

00:00:23.930 --> 00:00:27.380
this at least every other class
so we remember the context.

00:00:27.380 --> 00:00:30.140
But class 1, as
you remember, was

00:00:30.140 --> 00:00:32.810
all about the
economic growth theory

00:00:32.810 --> 00:00:38.240
and the economic growth
context for innovation policy.

00:00:38.240 --> 00:00:43.310
And we did growth economics
and how it broke away

00:00:43.310 --> 00:00:45.140
from classical economics
around developing

00:00:45.140 --> 00:00:47.010
a new theory of growth.

00:00:47.010 --> 00:00:51.860
So Solow argued that there's
technological related

00:00:51.860 --> 00:00:52.580
innovation.

00:00:52.580 --> 00:00:59.700
And we concluded that was a
key direct innovation factor.

00:00:59.700 --> 00:01:02.570
So we could loosely,
although in accurately,

00:01:02.570 --> 00:01:08.030
translate that concept as
saying, you've got to do R&D.

00:01:08.030 --> 00:01:09.380
And then we read Romer.

00:01:09.380 --> 00:01:12.170
And Romer argued that
behind that R&D system

00:01:12.170 --> 00:01:14.510
is human capital
engaged in research.

00:01:14.510 --> 00:01:17.880
That's another foundational
direct innovation factor.

00:01:17.880 --> 00:01:19.730
You can't build an
innovation system

00:01:19.730 --> 00:01:22.790
without these two
elements arguably.

00:01:22.790 --> 00:01:24.710
So it's the R&D and
the talent behind it.

00:01:24.710 --> 00:01:26.330
Those give us two
direct factors.

00:01:26.330 --> 00:01:30.620
Then in class 2, we talked
about the indirect elements

00:01:30.620 --> 00:01:33.410
in this larger ecosystem.

00:01:33.410 --> 00:01:35.360
And government controls some.

00:01:35.360 --> 00:01:38.060
Private sector controls more.

00:01:38.060 --> 00:01:40.580
But that gives us an idea
of looking at innovation

00:01:40.580 --> 00:01:44.420
as a system, which Richard
Nelson contributed to.

00:01:44.420 --> 00:01:47.210
And then within that system,
you look at the strength

00:01:47.210 --> 00:01:49.040
of the innovation actors.

00:01:49.040 --> 00:01:51.980
And you can begin to think of
your innovation organization

00:01:51.980 --> 00:01:55.430
as a third direct
innovation factor.

00:01:55.430 --> 00:01:57.320
And that leads us
into the whole problem

00:01:57.320 --> 00:01:59.750
of how do you cross
the valley of death

00:01:59.750 --> 00:02:02.860
if you've got a
disconnected model.

00:02:02.860 --> 00:02:05.800
Classes 3 and 4 were case
studies on manufacturing.

00:02:05.800 --> 00:02:09.310
So we took a deep dive
into a very current set

00:02:09.310 --> 00:02:13.090
of practical, ongoing problems
to try and think about some

00:02:13.090 --> 00:02:15.700
of those innovation
organization lessons

00:02:15.700 --> 00:02:17.500
in a manufacturing context.

00:02:17.500 --> 00:02:24.130
Class 5 was explicitly about
innovation organization.

00:02:24.130 --> 00:02:28.700
And we looked at David
[? Hart's ?] analysis

00:02:28.700 --> 00:02:35.240
of the ideology behind
looking at innovation

00:02:35.240 --> 00:02:38.600
in the political system
and the conservative,

00:02:38.600 --> 00:02:41.080
the associationalist, which
is the public private,

00:02:41.080 --> 00:02:44.000
the national security models.

00:02:44.000 --> 00:02:48.870
All those issues are
still very much with us.

00:02:48.870 --> 00:02:50.720
And in that class,
we also talked

00:02:50.720 --> 00:02:57.770
about Donald Stokes' work
where he critiqued the split

00:02:57.770 --> 00:02:59.900
in the US innovation
organizational system

00:02:59.900 --> 00:03:03.380
between front-end
innovation, the R

00:03:03.380 --> 00:03:06.300
side and the later stages.

00:03:06.300 --> 00:03:13.190
So when we organize to do,
essentially, a research

00:03:13.190 --> 00:03:16.400
model at the end of World War
II under that pipeline model

00:03:16.400 --> 00:03:21.660
that Vannevar Bush
gave us, we missed

00:03:21.660 --> 00:03:23.700
issues that subsequently
rose in the economy

00:03:23.700 --> 00:03:26.670
and became really deep
sources of problems

00:03:26.670 --> 00:03:30.570
about the connections to the
fall of one implementation

00:03:30.570 --> 00:03:33.240
back into the innovation
system stages.

00:03:33.240 --> 00:03:36.690
Class 6 was about crossing
this valley of death.

00:03:36.690 --> 00:03:39.030
How do you build
the bridging models

00:03:39.030 --> 00:03:42.210
that get you from a
pipeline innovation model

00:03:42.210 --> 00:03:43.660
across to the later stages.

00:03:43.660 --> 00:03:46.660
That's not easy in our system.

00:03:46.660 --> 00:03:49.170
And then we also
talked about the fact

00:03:49.170 --> 00:03:52.170
that we run two parallel
systems in the US.

00:03:52.170 --> 00:03:55.770
So Vernon Ruttan's book, Is War
Necessary for Economic Growth,

00:03:55.770 --> 00:03:59.470
introduced us into the whole
Defense Innovation system,

00:03:59.470 --> 00:04:01.500
which is not disconnected.

00:04:01.500 --> 00:04:03.840
That's a pretty connected model.

00:04:03.840 --> 00:04:05.610
And the Defense
Department will typically

00:04:05.610 --> 00:04:08.160
perform the research,
the development.

00:04:08.160 --> 00:04:10.160
It will do the demonstration.

00:04:10.160 --> 00:04:12.480
It will do the test bed.

00:04:12.480 --> 00:04:14.280
It will move to the
advanced prototypes

00:04:14.280 --> 00:04:17.459
and will often provide
an initial market

00:04:17.459 --> 00:04:18.720
for emerging technologies.

00:04:18.720 --> 00:04:20.850
That's a very different
organizational system

00:04:20.850 --> 00:04:25.650
as we discussed from what the
civilian agencies are up to.

00:04:25.650 --> 00:04:28.490
Class 7 was innovation at
the face-to-face level.

00:04:28.490 --> 00:04:30.190
That's our whole
great group's theory.

00:04:30.190 --> 00:04:35.813
So if innovation has to
do with institutions,

00:04:35.813 --> 00:04:37.980
which it certainly does--
how are those institutions

00:04:37.980 --> 00:04:39.360
organized and how
do they connect

00:04:39.360 --> 00:04:42.210
and how are the handoffs
between the actors?

00:04:42.210 --> 00:04:47.070
But in the end, people own
innovation, not institutions.

00:04:47.070 --> 00:04:48.888
It's very face to face.

00:04:48.888 --> 00:04:50.430
And then in the
great groups classes,

00:04:50.430 --> 00:04:52.560
you remember well
we talked about some

00:04:52.560 --> 00:04:57.570
of the rule sets
that tend to guide

00:04:57.570 --> 00:05:00.960
the way in which great
group-based innovation

00:05:00.960 --> 00:05:02.890
operates.

00:05:02.890 --> 00:05:05.870
And again, that drives us
back to this third innovation

00:05:05.870 --> 00:05:07.040
factor--

00:05:07.040 --> 00:05:09.410
what does innovation look
like an organizational point

00:05:09.410 --> 00:05:12.120
of view, from a
systems point of view,

00:05:12.120 --> 00:05:15.710
from an actor's point
of view, but also,

00:05:15.710 --> 00:05:19.580
how does innovation look
at the face-to-face level.

00:05:19.580 --> 00:05:21.503
And then in class 8,
we talked about DARPA,

00:05:21.503 --> 00:05:23.420
which is an institution
that actually attempts

00:05:23.420 --> 00:05:26.430
to do both on a good day.

00:05:26.430 --> 00:05:28.550
It will support
that connectedness

00:05:28.550 --> 00:05:34.160
of innovation institutions
being connected

00:05:34.160 --> 00:05:35.870
using that defense model.

00:05:35.870 --> 00:05:43.280
But it will also attempt
to build great groups.

00:05:43.280 --> 00:05:45.890
And we talked about JCR
Licklider and the evolution

00:05:45.890 --> 00:05:49.260
of the IT revolution,
a lot of the origins

00:05:49.260 --> 00:05:52.590
of which came out of
DARPA-supported research

00:05:52.590 --> 00:05:53.670
as an example of that.

00:05:53.670 --> 00:06:00.570
So now, we're going to do some
more case studies in today's

00:06:00.570 --> 00:06:04.695
class really looking at the
life science innovation system

00:06:04.695 --> 00:06:05.820
and how does that function.

00:06:05.820 --> 00:06:07.653
And we're going to take
a lot of the lessons

00:06:07.653 --> 00:06:10.020
that we've been learning
and try and fit them

00:06:10.020 --> 00:06:14.350
into analyzing this
really important piece

00:06:14.350 --> 00:06:18.120
into this territory.

00:06:18.120 --> 00:06:21.690
Let me give you a quick
NIH historical backdrop.

00:06:21.690 --> 00:06:25.290
Remember the pre World War II
and the World War II context?

00:06:25.290 --> 00:06:29.970
NIH just stood up as a
Vannevar Bush basic research

00:06:29.970 --> 00:06:31.560
organization.

00:06:31.560 --> 00:06:34.710
So Franklin Roosevelt
in Vannevar Bush

00:06:34.710 --> 00:06:37.080
see what happens
in World War II.

00:06:37.080 --> 00:06:42.120
They see the development of
antibiotics led by penicillin.

00:06:42.120 --> 00:06:44.580
And the effects are
breathtaking, absolutely

00:06:44.580 --> 00:06:45.960
breathtaking.

00:06:45.960 --> 00:06:47.370
So suddenly, we fight a war.

00:06:47.370 --> 00:06:49.800
And you probably
won't die of disease.

00:06:49.800 --> 00:06:52.440
You'll actually die of
battlefield injuries, which

00:06:52.440 --> 00:06:55.620
has never happened before.

00:06:55.620 --> 00:06:58.027
And that immediately
has an effect.

00:06:58.027 --> 00:06:59.610
It removes pneumonia
from the number 1

00:06:59.610 --> 00:07:01.568
cause of death in the
United States conceivably

00:07:01.568 --> 00:07:03.750
further down the list.

00:07:03.750 --> 00:07:05.190
It's very dramatic.

00:07:05.190 --> 00:07:07.740
Bush and Roosevelt see
this and understand

00:07:07.740 --> 00:07:09.870
how powerful that model is.

00:07:09.870 --> 00:07:13.170
And so one of the theories
in The Endless Frontier

00:07:13.170 --> 00:07:15.497
that Vannevar Bush puts
out, as you remember,

00:07:15.497 --> 00:07:17.580
is that there's going to
be a war against disease.

00:07:17.580 --> 00:07:20.420
And they've just seen
what this model is.

00:07:20.420 --> 00:07:23.020
So they want to do it.

00:07:23.020 --> 00:07:28.020
Now, Truman, as you remember,
vetoes the one agency,

00:07:28.020 --> 00:07:31.410
One Tent National
Science Foundation role.

00:07:31.410 --> 00:07:35.980
So he vetoes that in
like, is it '47 or '49?

00:07:35.980 --> 00:07:39.510
And that leaves a void.

00:07:39.510 --> 00:07:41.380
So voids tend to get filled.

00:07:41.380 --> 00:07:44.310
So this little
research outfit that's

00:07:44.310 --> 00:07:47.680
part of the Public Health
Service, the National

00:07:47.680 --> 00:07:50.030
Institutes of Health becomes
the National Institutes

00:07:50.030 --> 00:07:52.750
and really starts scaling up.

00:07:52.750 --> 00:07:58.390
So follows a Vannevar
Bush basic research model.

00:07:58.390 --> 00:08:04.990
But it evolves in this gap
of organizational leadership

00:08:04.990 --> 00:08:08.920
in a way and fills that void.

00:08:08.920 --> 00:08:13.670
And then over time,
disease groups

00:08:13.670 --> 00:08:16.760
tend to be very
active politically.

00:08:16.760 --> 00:08:19.310
If you have a disease or if
a loved one has a disease,

00:08:19.310 --> 00:08:22.340
you tend to be very active
in the disease group.

00:08:22.340 --> 00:08:28.070
And these disease groups push
their disease in Congress.

00:08:28.070 --> 00:08:31.730
And Congress keeps adding
institutes and centers

00:08:31.730 --> 00:08:33.380
onto the model.

00:08:33.380 --> 00:08:38.270
When it reaches an
unmanageable number of 27,

00:08:38.270 --> 00:08:41.015
finally, Congress actually
tries to restrain itself.

00:08:43.650 --> 00:08:48.820
But it creates an organizational
model that's problematic.

00:08:48.820 --> 00:08:50.620
Now, another feature here is--

00:08:50.620 --> 00:08:51.870
here's a line from Tony Fauci.

00:08:51.870 --> 00:08:52.840
It's one of the--

00:08:52.840 --> 00:08:57.220
He's the director of
NIAID, quite famous.

00:08:57.220 --> 00:09:00.910
NIAID was one of the
leaders in getting

00:09:00.910 --> 00:09:04.330
on all kinds of infectious
diseases, including AIDS.

00:09:04.330 --> 00:09:09.160
But Tony Fauci writes
in 2003, "the path

00:09:09.160 --> 00:09:12.610
to product development has not
been a part of NIAID's research

00:09:12.610 --> 00:09:15.665
strategy."

00:09:15.665 --> 00:09:19.460
In other words, that's
not on the table.

00:09:19.460 --> 00:09:22.700
They're worried about their
basic research results.

00:09:22.700 --> 00:09:25.610
So what did NIH--

00:09:25.610 --> 00:09:29.720
and arguably, the biotech
model that is spawned from it--

00:09:29.720 --> 00:09:30.770
what did they get right?

00:09:30.770 --> 00:09:32.228
And they get a lot
of things right.

00:09:32.228 --> 00:09:33.230
It's an amazing system.

00:09:33.230 --> 00:09:35.450
It's a remarkable
story of success.

00:09:35.450 --> 00:09:38.330
So even though we're going
to be critical today,

00:09:38.330 --> 00:09:41.340
it is an amazing success story.

00:09:41.340 --> 00:09:43.440
NIH trained everybody.

00:09:43.440 --> 00:09:50.000
It created this huge education
system that put a lot of talent

00:09:50.000 --> 00:09:53.900
on the task in Romer's terms.

00:09:53.900 --> 00:09:58.670
This knowledge base helped spawn
a remarkable entrepreneurial

00:09:58.670 --> 00:10:00.800
biotech startup model.

00:10:00.800 --> 00:10:04.490
And we talked about Genentech
during our great groups class.

00:10:04.490 --> 00:10:05.480
That's the first.

00:10:05.480 --> 00:10:10.280
But that's a very good example
of what then flourished.

00:10:10.280 --> 00:10:15.180
And Boyer and Swanson
were the founders.

00:10:15.180 --> 00:10:20.550
Boyer comes out of
that NIH-funded system.

00:10:20.550 --> 00:10:24.160
Biotechs have been able to
get venture capital support

00:10:24.160 --> 00:10:29.718
even though they have a 10 to
15 year stand-up model, which

00:10:29.718 --> 00:10:31.010
is a remarkable accomplishment.

00:10:31.010 --> 00:10:33.800
No other sector is able to
get venture capital money

00:10:33.800 --> 00:10:35.300
unless they're no
more than a couple

00:10:35.300 --> 00:10:37.310
of years out of production.

00:10:37.310 --> 00:10:43.250
Biotechs have been able to break
that and get long-term support

00:10:43.250 --> 00:10:46.130
for R&D.

00:10:46.130 --> 00:10:49.960
And the key to this has
been the value of IP.

00:10:49.960 --> 00:10:54.860
So there is a working monopoly
model in the biotech sector.

00:10:54.860 --> 00:11:01.460
So if you're first
to patent a new drug,

00:11:01.460 --> 00:11:04.820
you are given a monopoly
rent for a 20-year time

00:11:04.820 --> 00:11:07.790
period minus the
time it gets you

00:11:07.790 --> 00:11:09.860
to get through clinical
trials with NIH,

00:11:09.860 --> 00:11:11.000
which can be seven years.

00:11:11.000 --> 00:11:13.910
So it's a 13-year
run where you're

00:11:13.910 --> 00:11:15.890
assured of monopoly rents.

00:11:15.890 --> 00:11:19.130
And unlike the hard
technology sector,

00:11:19.130 --> 00:11:23.300
it's harder to
stand up, in effect,

00:11:23.300 --> 00:11:28.100
copy-cat fixes, copy-cat drugs.

00:11:28.100 --> 00:11:32.240
So you really do get a
significant run typically

00:11:32.240 --> 00:11:33.830
if you're first
to patent and you

00:11:33.830 --> 00:11:37.530
get ahead first through
the clinical trial process.

00:11:37.530 --> 00:11:42.620
So that's been the
enabler that allows

00:11:42.620 --> 00:11:44.490
this financing system to work.

00:11:44.490 --> 00:11:46.550
The other key feature
is FDA's approval.

00:11:46.550 --> 00:11:48.880
So FDA gives you--

00:11:48.880 --> 00:11:53.152
in stage 1, stage 2,
stage 3 clinical trials,

00:11:53.152 --> 00:11:54.610
if you're developing
a cancer drug,

00:11:54.610 --> 00:11:56.260
you know exactly
what your chances

00:11:56.260 --> 00:11:59.590
are on getting through
the from stage 1

00:11:59.590 --> 00:12:04.000
to stage 2 and stage 2 to
stage 3 and from stage 3

00:12:04.000 --> 00:12:05.440
to final drug approval.

00:12:05.440 --> 00:12:07.330
You know just what
your chances are.

00:12:07.330 --> 00:12:10.000
So that enables
venture capitalists

00:12:10.000 --> 00:12:13.000
to tee off their
stages of financing

00:12:13.000 --> 00:12:15.940
to your success in the
clinical trials process.

00:12:15.940 --> 00:12:19.635
There is no benchmarking system
like this in any other sector

00:12:19.635 --> 00:12:20.260
in the economy.

00:12:20.260 --> 00:12:22.330
It works amazingly well.

00:12:22.330 --> 00:12:25.000
And then another big
difference between life science

00:12:25.000 --> 00:12:28.900
and everything else is that,
if FDA approves your drug,

00:12:28.900 --> 00:12:31.240
you are guaranteed a market.

00:12:31.240 --> 00:12:32.800
In fact, our
wonderful legal system

00:12:32.800 --> 00:12:36.910
is such that, if a doctor fails
to prescribe the medicine which

00:12:36.910 --> 00:12:42.130
is fitted to your problem, the
next day, the doctor gets sued.

00:12:42.130 --> 00:12:46.240
So there's this huge forcing
mechanism in the system.

00:12:46.240 --> 00:12:48.542
There's nothing like a
certification that guarantees

00:12:48.542 --> 00:12:49.750
you a market on the next day.

00:12:49.750 --> 00:12:52.000
There's nothing like this
anywhere else in our system.

00:12:52.000 --> 00:12:54.480
It's a remarkable thing.

00:12:54.480 --> 00:12:56.230
And we can start to
think about how do you

00:12:56.230 --> 00:13:00.700
get analogous certification
processes and benchmarking

00:13:00.700 --> 00:13:02.245
processes in place
in more physical

00:13:02.245 --> 00:13:03.370
science-based technologies.

00:13:03.370 --> 00:13:05.560
It would be very interesting.

00:13:05.560 --> 00:13:06.770
We haven't done it.

00:13:06.770 --> 00:13:08.770
But there's a lot to be
learned from this sector

00:13:08.770 --> 00:13:10.145
because of the
system it's setup.

00:13:13.180 --> 00:13:14.978
Upstairs-downstairs
has historically

00:13:14.978 --> 00:13:17.020
been a problem, particularly
in European science,

00:13:17.020 --> 00:13:20.620
but also in US science, whereas
the academic researchers have

00:13:20.620 --> 00:13:24.250
disdain for the
company researchers.

00:13:24.250 --> 00:13:27.670
That has really broken
up and broken apart

00:13:27.670 --> 00:13:29.710
in the life science side.

00:13:29.710 --> 00:13:34.030
So outstanding
academics, think Boyer,

00:13:34.030 --> 00:13:37.510
who spent time in a biotech.

00:13:37.510 --> 00:13:40.450
That's not created as
a sound career path.

00:13:40.450 --> 00:13:41.710
Boyer had to break the ground.

00:13:41.710 --> 00:13:44.300
He got a lot of flak
for it at the time.

00:13:44.300 --> 00:13:46.450
But over time, it's
become accepted

00:13:46.450 --> 00:13:49.900
that you can have an academic
career, move to a biotech,

00:13:49.900 --> 00:13:51.910
move back to an academic career.

00:13:51.910 --> 00:13:53.407
That's OK.

00:13:53.407 --> 00:13:55.990
Obviously, this conflict is used
throughout that whole process

00:13:55.990 --> 00:13:57.550
that had to be dealt with.

00:13:57.550 --> 00:14:00.200
But that's an
acceptable pathway.

00:14:00.200 --> 00:14:02.530
So the whole
upstairs-downstairs relationship

00:14:02.530 --> 00:14:04.780
between the academy and
commercial development

00:14:04.780 --> 00:14:06.850
has really been broken up.

00:14:06.850 --> 00:14:12.220
So that's another thing
that this sector got right.

00:14:12.220 --> 00:14:14.080
NIH also has a huge
amount of money.

00:14:14.080 --> 00:14:16.450
It's by far the
largest R&D agency.

00:14:16.450 --> 00:14:18.610
It's got over $30
billion a year.

00:14:18.610 --> 00:14:19.360
Nobody is close.

00:14:22.870 --> 00:14:25.630
NSF, by comparison,
has $7 billion a year.

00:14:25.630 --> 00:14:28.120
The Department of Energy Office
of Science has $5 billion.

00:14:28.120 --> 00:14:30.010
DARPA has $3 billion.

00:14:30.010 --> 00:14:35.110
So this is an order of magnitude
almost different from other R&D

00:14:35.110 --> 00:14:36.020
agencies.

00:14:36.020 --> 00:14:39.940
So the political constituencies,
including the disease groups,

00:14:39.940 --> 00:14:43.240
have built a very
powerful political base

00:14:43.240 --> 00:14:47.350
for sustained funding
in this sector.

00:14:47.350 --> 00:14:49.380
Now, that's the good news.

00:14:49.380 --> 00:14:50.593
Here's the problem.

00:14:50.593 --> 00:14:52.510
We're going to talk about
the innovation train

00:14:52.510 --> 00:14:54.710
wreck that lies ahead here.

00:14:54.710 --> 00:14:57.130
So the economic model
for biotechs and pharmas

00:14:57.130 --> 00:14:59.980
really requires
blockbuster markets.

00:14:59.980 --> 00:15:03.210
It's a huge problem.

00:15:03.210 --> 00:15:06.100
So in other words, third-world
diseases, infectious diseases,

00:15:06.100 --> 00:15:10.610
small-population diseases,
it doesn't make sense

00:15:10.610 --> 00:15:12.820
to pursue those.

00:15:12.820 --> 00:15:17.090
To get a drug through the FDA
clinical process to develop

00:15:17.090 --> 00:15:20.110
in time before, during, and
during the clinical trial

00:15:20.110 --> 00:15:25.860
approval process itself, that's
around a $1.4-billion-or-more

00:15:25.860 --> 00:15:27.060
proposition.

00:15:27.060 --> 00:15:30.162
So unless you're selling
it to a major market,

00:15:30.162 --> 00:15:34.740
it doesn't make any sense
to develop the remedy.

00:15:34.740 --> 00:15:38.600
So there is a statistic
that some cite,

00:15:38.600 --> 00:15:47.260
which is that 80% of our
R&D money in life science

00:15:47.260 --> 00:15:51.540
is spent on 10% of the diseases.

00:15:51.540 --> 00:15:52.950
That's a problem.

00:15:52.950 --> 00:15:54.520
I don't think the
number is that bad.

00:15:54.520 --> 00:15:56.520
I think that's exaggerated.

00:15:56.520 --> 00:16:00.260
But we've got a
problem here because of

00:16:00.260 --> 00:16:02.540
this blockbuster drug model.

00:16:02.540 --> 00:16:06.560
Only if you're developing a drug
that sells into a major market

00:16:06.560 --> 00:16:11.170
opportunity is it going
to get into the market.

00:16:11.170 --> 00:16:13.680
So what does that leave behind?

00:16:13.680 --> 00:16:16.860
In addition to the
things I've mentioned,

00:16:16.860 --> 00:16:20.490
the precision medicine or
personalized drug model

00:16:20.490 --> 00:16:21.340
gets left behind.

00:16:21.340 --> 00:16:23.820
In other words,
if each one of you

00:16:23.820 --> 00:16:27.930
is going to have their
own remedy variant that's

00:16:27.930 --> 00:16:30.930
particularly adapted to your
genetic structure or metabolism

00:16:30.930 --> 00:16:33.120
or whatever, what
are we going to do?

00:16:33.120 --> 00:16:37.020
Run a $1.4-billion clinical
trial process for you?

00:16:37.020 --> 00:16:39.000
It's not going to work.

00:16:39.000 --> 00:16:40.980
So how do we deal with this?

00:16:40.980 --> 00:16:46.260
There's a huge looming train
wreck problem in the system

00:16:46.260 --> 00:16:48.030
because that's where it's going.

00:16:48.030 --> 00:16:50.550
These are the benefits of
being able to use big data

00:16:50.550 --> 00:16:52.530
and analytics to develop
personalized medicine.

00:16:52.530 --> 00:16:56.450
But if there's not an economic
model to get it there,

00:16:56.450 --> 00:16:58.980
it won't happen.

00:16:58.980 --> 00:17:02.730
The litigation threat makes
drug companies risk averse.

00:17:02.730 --> 00:17:04.560
So we leave a lot
of promising stuff

00:17:04.560 --> 00:17:06.900
on the table because
of that threat.

00:17:06.900 --> 00:17:12.329
Often, a drug will
cure, let's say,

00:17:12.329 --> 00:17:16.920
20%, 30%, maybe 40% of a
disease group's problem.

00:17:16.920 --> 00:17:19.050
But if it kills
some people, we'll

00:17:19.050 --> 00:17:22.391
never go to market because we
don't understand the precision

00:17:22.391 --> 00:17:23.849
medicine, the
personalized medicine

00:17:23.849 --> 00:17:25.650
implications of these things.

00:17:25.650 --> 00:17:27.780
And until we do, we're
just leaving a lot of stuff

00:17:27.780 --> 00:17:31.890
on the shelf that has potential
value because Americans,

00:17:31.890 --> 00:17:37.965
for good reason, have very low
tolerance for risk from drugs.

00:17:41.310 --> 00:17:47.530
The health care spending in
the overall system by 2025

00:17:47.530 --> 00:17:51.300
may account for
9% of GDP or more.

00:17:51.300 --> 00:17:54.040
And we'll talk about
this in a minute.

00:17:54.040 --> 00:17:58.210
But we can't afford a health
care bill of those dimensions

00:17:58.210 --> 00:17:59.770
and still have
other things going

00:17:59.770 --> 00:18:02.275
on in the society and the
economy and the government.

00:18:06.330 --> 00:18:09.190
This is what we spend money
on in the federal government.

00:18:12.050 --> 00:18:14.690
This is what we think
of as government.

00:18:14.690 --> 00:18:18.530
So that's like the national
parks and federal research,

00:18:18.530 --> 00:18:20.900
transportation, highways.

00:18:20.900 --> 00:18:22.628
That's this.

00:18:22.628 --> 00:18:24.270
That's defense.

00:18:24.270 --> 00:18:25.910
So that's actually about 16%.

00:18:25.910 --> 00:18:30.350
And that's now about
maybe a little below 20%.

00:18:30.350 --> 00:18:31.520
That's Social Security.

00:18:31.520 --> 00:18:35.900
That's Medicaid,
Medicare, and SCHIP,

00:18:35.900 --> 00:18:40.220
the big health-care-oriented
entitlement programs.

00:18:40.220 --> 00:18:42.560
That's other safety
net programs, 9%.

00:18:42.560 --> 00:18:45.110
And then we have interest on
the debt, which is actually now

00:18:45.110 --> 00:18:47.850
over 9%.

00:18:47.850 --> 00:18:52.020
So as you can see, the
federal government is mostly--

00:18:52.020 --> 00:18:55.860
we're talking 60% plus
interest in the debt--

00:18:55.860 --> 00:18:59.820
a check-writing kind
of organization.

00:18:59.820 --> 00:19:01.570
And that's what we
think of as government.

00:19:01.570 --> 00:19:03.570
And that's what we think
of as the domestic side

00:19:03.570 --> 00:19:04.220
of government.

00:19:04.220 --> 00:19:05.680
So these are pretty
small pieces.

00:19:05.680 --> 00:19:06.500
Rasheed?

00:19:06.500 --> 00:19:08.470
AUDIENCE: What year is this for?

00:19:08.470 --> 00:19:11.540
WILLIAM BONVILLIAN: This is
probably about four years old

00:19:11.540 --> 00:19:12.040
now.

00:19:12.040 --> 00:19:16.180
But the numbers are slightly
even more problematic

00:19:16.180 --> 00:19:17.170
than these.

00:19:17.170 --> 00:19:19.910
So again, this
category is now 16%.

00:19:19.910 --> 00:19:22.910
So the numbers are probably
off by a couple of percent.

00:19:22.910 --> 00:19:27.670
But it's a problem.

00:19:27.670 --> 00:19:33.440
And as we'll see
in a second, these

00:19:33.440 --> 00:19:35.610
are components of
federal spending.

00:19:35.610 --> 00:19:36.890
So that's health.

00:19:36.890 --> 00:19:39.150
And that blue line
is everything else.

00:19:39.150 --> 00:19:42.320
So you can see where
taxpayer dollars are going.

00:19:45.660 --> 00:19:47.910
This kind of demonstrates
that Social Security is not

00:19:47.910 --> 00:19:48.960
the real problem.

00:19:48.960 --> 00:19:50.760
It's really the health
care cost related

00:19:50.760 --> 00:19:53.130
to Medicare and Medicaid
that are the problem.

00:19:56.160 --> 00:20:01.257
This shows historic
levels of taxation.

00:20:01.257 --> 00:20:03.590
Remember, the United States
was founded on a tax revolt.

00:20:03.590 --> 00:20:06.695
So we're not going to
have European-style levels

00:20:06.695 --> 00:20:08.070
of taxation in
the United States.

00:20:08.070 --> 00:20:09.990
It's just not going to happen.

00:20:09.990 --> 00:20:12.720
And we start to run into
real political trouble

00:20:12.720 --> 00:20:17.520
once you get a little bit above,
say, the 20% level of taxation

00:20:17.520 --> 00:20:20.220
that's a percentage of GDP.

00:20:20.220 --> 00:20:29.720
So we're headed way up against
that threshold largely because

00:20:29.720 --> 00:20:32.210
of the demographics and
the health care spending,

00:20:32.210 --> 00:20:41.530
which means that, broken down
this way, the percentage of GDP

00:20:41.530 --> 00:20:45.770
we spend on, what we
consider most of government,

00:20:45.770 --> 00:20:49.450
is just not going
to be affordable

00:20:49.450 --> 00:20:54.510
given the acceptable
levels, around 19%, 18%,

00:20:54.510 --> 00:20:57.680
the acceptable tax range
in our political system.

00:20:57.680 --> 00:20:59.258
So Max?

00:20:59.258 --> 00:21:00.550
AUDIENCE: What are [INAUDIBLE]?

00:21:00.550 --> 00:21:01.930
WILLIAM BONVILLIAN: Expenditures
by the federal government.

00:21:01.930 --> 00:21:03.580
What they're spending
in a given year.

00:21:03.580 --> 00:21:07.120
What they were actually
outlaying to meet their costs,

00:21:07.120 --> 00:21:09.320
to meet their obligations.

00:21:09.320 --> 00:21:12.235
So these are some of the
problems that lie ahead.

00:21:12.235 --> 00:21:15.310
We got a real fiscal
train wreck because

00:21:15.310 --> 00:21:17.440
of the cost of this
health care system driven

00:21:17.440 --> 00:21:20.080
by the demographics.

00:21:20.080 --> 00:21:23.050
My generation
attempted to make you

00:21:23.050 --> 00:21:25.540
spend all of your money on me.

00:21:25.540 --> 00:21:27.040
That's essentially
what's going on.

00:21:27.040 --> 00:21:31.670
It's a massive intergenerational
transfer of wealth.

00:21:31.670 --> 00:21:35.690
And you guys need to wake up
to that because it forgoes

00:21:35.690 --> 00:21:38.600
opportunities that you have.

00:21:38.600 --> 00:21:41.330
And at the heart of this
is a really serious problem

00:21:41.330 --> 00:21:44.380
with health care expenditures.

00:21:44.380 --> 00:21:49.650
So let's now get back
into our main themes.

00:21:49.650 --> 00:21:54.148
This was a classic 2003
report, what is now

00:21:54.148 --> 00:21:55.440
called the Academy of Medicine.

00:21:55.440 --> 00:21:57.773
It used to be called the
National Institute of Medicine.

00:21:57.773 --> 00:21:59.700
It's part of the
national academies--

00:21:59.700 --> 00:22:05.230
they did on evaluating NIH.

00:22:05.230 --> 00:22:09.740
And it was a pretty
startling criticism.

00:22:09.740 --> 00:22:14.480
And they looked hard
at this NIH system.

00:22:14.480 --> 00:22:17.930
It really began to identify
some of the problems.

00:22:17.930 --> 00:22:23.330
Interestingly, this report drove
some interesting congressional

00:22:23.330 --> 00:22:26.390
reform attempts.

00:22:26.390 --> 00:22:31.145
Let me see if I can summarize
a few key points here.

00:22:31.145 --> 00:22:32.520
And Chloe, did
you have this one?

00:22:35.350 --> 00:22:36.430
You've got it, Martin?

00:22:36.430 --> 00:22:38.910
OK.

00:22:38.910 --> 00:22:40.590
All right.

00:22:40.590 --> 00:22:46.860
So as I said, NIH is more
like a feudal barony.

00:22:46.860 --> 00:22:49.380
It always has a famous director.

00:22:49.380 --> 00:22:51.870
But they don't have that much
control over these institutes

00:22:51.870 --> 00:22:52.410
and centers.

00:22:52.410 --> 00:22:55.440
There is no
centralized budgeting.

00:22:55.440 --> 00:22:57.840
And the institutes
and centers battled

00:22:57.840 --> 00:23:03.270
to protect their percentage
share of NIH's total budget.

00:23:03.270 --> 00:23:06.180
So Harold Varmus, a
famous former director

00:23:06.180 --> 00:23:09.870
of NIH, who later came back
in the Obama administration

00:23:09.870 --> 00:23:14.750
as head of the National Cancer
Institute, he said, in 2001,

00:23:14.750 --> 00:23:17.960
"NIH would be more efficient
and more manageable

00:23:17.960 --> 00:23:22.370
if a far smaller number
of larger institutes

00:23:22.370 --> 00:23:27.080
existed organized around
broad science areas."

00:23:27.080 --> 00:23:30.730
Less institutes, organized
around science areas

00:23:30.730 --> 00:23:33.328
is his twin points here.

00:23:33.328 --> 00:23:35.120
And there's a lot to
be said for that case.

00:23:35.120 --> 00:23:36.787
Instead, as we
discussed, the institutes

00:23:36.787 --> 00:23:39.710
got set up essentially at
the behest of disease groups

00:23:39.710 --> 00:23:43.320
to solve their disease problem.

00:23:43.320 --> 00:23:46.380
It turns out there
isn't a separate pathway

00:23:46.380 --> 00:23:47.430
for each disease.

00:23:47.430 --> 00:23:49.620
It turns out there's a
lot of common pathways

00:23:49.620 --> 00:23:52.090
across a lot of diseases.

00:23:52.090 --> 00:23:55.580
And we don't have a very
good mechanism in NIH

00:23:55.580 --> 00:23:58.560
for getting groups of
institutes to collaborate

00:23:58.560 --> 00:24:00.880
on a cross-cutting
set of problems.

00:24:00.880 --> 00:24:05.160
So fundamental
organizational issue.

00:24:05.160 --> 00:24:08.070
Now, there is another side
of this argument, which

00:24:08.070 --> 00:24:10.980
is, you've got a
lot of institutes

00:24:10.980 --> 00:24:14.670
with a lot of freedom
to do a lot of stuff.

00:24:14.670 --> 00:24:17.910
Maybe a desegregated
model is not all bad.

00:24:17.910 --> 00:24:21.120
There's certainly a case
to be made for that.

00:24:21.120 --> 00:24:23.070
But overall, there's
a challenge here.

00:24:23.070 --> 00:24:30.120
And NIH's budget doubled
from 1998 to 2003.

00:24:30.120 --> 00:24:36.300
So there was a federal
surplus in its budget

00:24:36.300 --> 00:24:38.310
during the IT revolution,
which was generating

00:24:38.310 --> 00:24:40.710
huge amounts of tax revenue.

00:24:40.710 --> 00:24:46.890
And two US senators saw
this emerging surplus.

00:24:46.890 --> 00:24:50.670
They were on the appropriations
subcommittee that handled NIH.

00:24:50.670 --> 00:24:52.230
And they went to
the Senate floor

00:24:52.230 --> 00:24:55.980
and took a noticeable
part of that surplus

00:24:55.980 --> 00:24:57.385
and gave it to NIH.

00:24:57.385 --> 00:25:02.190
It was a fascinating political
development, very shrewd.

00:25:02.190 --> 00:25:05.910
Arlen Specter of Pennsylvania
and Tom Harkin of Iowa

00:25:05.910 --> 00:25:09.720
were chairmen and ranking on
the appropriations subcommittee.

00:25:09.720 --> 00:25:12.000
And they created the doubling.

00:25:12.000 --> 00:25:14.538
It's a remarkable story.

00:25:14.538 --> 00:25:16.080
They were able to
do it because there

00:25:16.080 --> 00:25:17.910
was so much excitement
at that time

00:25:17.910 --> 00:25:19.350
over the genomics revolution.

00:25:19.350 --> 00:25:23.670
So we talked about Venter
and the NIH dueling battle

00:25:23.670 --> 00:25:26.880
[? Collins ?] over who's going
to get to the genome first.

00:25:26.880 --> 00:25:28.920
There was creating
huge excitement.

00:25:28.920 --> 00:25:31.440
It was a sense that
this medical research

00:25:31.440 --> 00:25:34.560
could lead to all kinds of new
fundamental understandings.

00:25:34.560 --> 00:25:36.630
Everybody was excited
about the idea.

00:25:36.630 --> 00:25:40.110
And that enabled those two
senators to double NIH.

00:25:40.110 --> 00:25:43.020
No other agency has ever been
able to do anything like this.

00:25:43.020 --> 00:25:46.590
The rest were stagnating.

00:25:46.590 --> 00:25:48.120
But the demographics
are changing.

00:25:48.120 --> 00:25:50.830
The patterns of
illness are changing.

00:25:50.830 --> 00:25:53.820
We have a threat of biothreats.

00:25:53.820 --> 00:25:57.120
Is NIH too fragmented to cope
with all these challenges?

00:25:57.120 --> 00:25:59.010
Can it respond quickly enough?

00:25:59.010 --> 00:26:02.820
These are all issues
that the report raises.

00:26:02.820 --> 00:26:05.055
It wants to avoid
proliferation of new agencies.

00:26:05.055 --> 00:26:07.590
And in fact, Congress
did that as part

00:26:07.590 --> 00:26:09.330
of its reform legislation.

00:26:09.330 --> 00:26:11.130
You can't have a
new institute in NIH

00:26:11.130 --> 00:26:12.610
unless you close
down another one.

00:26:18.410 --> 00:26:21.050
The Institute of Medicine, and
now the Academy of Medicine,

00:26:21.050 --> 00:26:26.570
urged in this report that NIH
focus on its capabilities.

00:26:26.570 --> 00:26:30.200
And it needed to do so because
it concluded that NIH is not

00:26:30.200 --> 00:26:33.500
only imperfect, but nobody would
have ever designed NIH this way

00:26:33.500 --> 00:26:35.370
at the outset.

00:26:35.370 --> 00:26:37.710
And in fact, Elias
Zerhouni once told me

00:26:37.710 --> 00:26:43.280
in a meeting and
others, if only we

00:26:43.280 --> 00:26:45.290
had thought through the
organizational model

00:26:45.290 --> 00:26:48.320
before we doubled.

00:26:48.320 --> 00:26:50.275
So we doubled first.

00:26:50.275 --> 00:26:51.650
And then there
was a mad scramble

00:26:51.650 --> 00:26:54.258
to grab the money from
the existing institutes.

00:26:54.258 --> 00:26:56.550
If only they had thought
about the organizational model

00:26:56.550 --> 00:26:57.830
up front.

00:26:57.830 --> 00:27:02.390
Zerhouni led a great
effort to try and get

00:27:02.390 --> 00:27:05.930
cross-cutting research efforts
going across the institute.

00:27:05.930 --> 00:27:08.230
So he created what he
called the roadmap.

00:27:08.230 --> 00:27:10.070
But essentially,
then Congress later

00:27:10.070 --> 00:27:12.402
institutionalized that
as the common fund.

00:27:12.402 --> 00:27:14.360
Take a little bit of
money from each institute.

00:27:14.360 --> 00:27:17.660
Create a common fund in the
control of the director who

00:27:17.660 --> 00:27:19.340
can then allocate
it to the highest

00:27:19.340 --> 00:27:21.955
cross-cutting priorities.

00:27:21.955 --> 00:27:23.330
So that was a
significant reform.

00:27:23.330 --> 00:27:25.205
But it's still a very
modest amount of money.

00:27:29.510 --> 00:27:33.410
NIH needs to pursue
an ability to go

00:27:33.410 --> 00:27:36.360
after high-risk,
high-return projects.

00:27:36.360 --> 00:27:38.048
That reaches a certain stage.

00:27:38.048 --> 00:27:39.590
And we'll talk about
this more later.

00:27:39.590 --> 00:27:45.210
But peer review is not
good at taking risk.

00:27:45.210 --> 00:27:46.980
If there's a certain
level of competition,

00:27:46.980 --> 00:27:51.720
if the award rate gets higher
than about one out of three,

00:27:51.720 --> 00:27:58.080
your ability to identify
breakthrough opportunities that

00:27:58.080 --> 00:28:01.370
are feasible gets harder.

00:28:01.370 --> 00:28:04.760
So it tends to default to--

00:28:04.760 --> 00:28:07.310
when there's a lot of
competition for an award,

00:28:07.310 --> 00:28:10.100
the one that the peer
community is most confident

00:28:10.100 --> 00:28:14.330
will yield results, albeit
they be incremental results.

00:28:14.330 --> 00:28:16.535
Why take risks on high
flyers when you've

00:28:16.535 --> 00:28:17.660
got to get the basics done.

00:28:17.660 --> 00:28:19.940
And so many people are
fighting for the money.

00:28:19.940 --> 00:28:21.920
So this is a huge
problem at NIH.

00:28:21.920 --> 00:28:25.010
How does it take the
necessary risks that

00:28:25.010 --> 00:28:28.010
need to be taken in innovation?

00:28:28.010 --> 00:28:29.960
So since then, NIH
has been working

00:28:29.960 --> 00:28:34.400
on creating categories
of higher-risk projects

00:28:34.400 --> 00:28:36.110
that have a separate
kind of review

00:28:36.110 --> 00:28:38.790
process than normal projects.

00:28:38.790 --> 00:28:41.510
So there are positive
NIH capabilities.

00:28:41.510 --> 00:28:43.670
We talked about
how decentralized

00:28:43.670 --> 00:28:44.660
can be an advantage.

00:28:44.660 --> 00:28:49.690
We talked about many
setting R&D priorities.

00:28:49.690 --> 00:28:52.850
You get a lot of
safety nets here.

00:28:52.850 --> 00:28:57.200
There are benefits to
investigator initiative grants.

00:28:57.200 --> 00:28:59.690
You don't want to just
have large-scale projects.

00:28:59.690 --> 00:29:02.418
You want bottom-up
opportunities.

00:29:02.418 --> 00:29:04.460
The issue for NIH, though,
is, historically, it's

00:29:04.460 --> 00:29:06.170
been totally
dominated by bottom up

00:29:06.170 --> 00:29:09.140
and has a modest number
of cross-cutting projects.

00:29:12.560 --> 00:29:15.650
Peer review in some ways is like
Winston Churchill's definition

00:29:15.650 --> 00:29:20.120
of democracy, the worst
possible system except

00:29:20.120 --> 00:29:21.590
for all the others.

00:29:21.590 --> 00:29:24.800
So peer review
remains competitive.

00:29:24.800 --> 00:29:27.380
And that's a very important
feature to build in.

00:29:27.380 --> 00:29:30.650
So [? IOM ?] recommended much
more centralized management

00:29:30.650 --> 00:29:34.730
giving more authority
to the director of NIH,

00:29:34.730 --> 00:29:37.370
getting the director to
engage in strategic planning

00:29:37.370 --> 00:29:43.190
across the institutes so they
got on to cross-cutting plans,

00:29:43.190 --> 00:29:45.020
doing cross-cutting budgets.

00:29:45.020 --> 00:29:48.170
So this idea of take
10% of the budget

00:29:48.170 --> 00:29:50.270
and fund the strategic
plans, actually, Congress

00:29:50.270 --> 00:29:53.090
worked on implementing that
through the common fund.

00:29:53.090 --> 00:29:57.620
Strengthening the
control of the director

00:29:57.620 --> 00:30:00.980
over these cross-agency
initiatives was key.

00:30:00.980 --> 00:30:04.310
They also recommended
creating a DARPA within NIH

00:30:04.310 --> 00:30:10.550
to go after the high-risk,
high-reward projects.

00:30:10.550 --> 00:30:13.910
They wanted improvements in
NIH as intramural programs.

00:30:13.910 --> 00:30:16.600
So NIH is also a major
research entity itself.

00:30:16.600 --> 00:30:19.963
It's not just funding
universities that historically

00:30:19.963 --> 00:30:22.130
has tended to be somewhat
weaker than the university

00:30:22.130 --> 00:30:24.350
research, which is much
more competition-based

00:30:24.350 --> 00:30:26.870
rather than kind of
entitlement-funding-based.

00:30:26.870 --> 00:30:29.160
They wanted to strengthen that.

00:30:29.160 --> 00:30:31.190
There is a desperate
need for standardization

00:30:31.190 --> 00:30:33.320
of data and information
systems across

00:30:33.320 --> 00:30:35.030
these different institutes.

00:30:35.030 --> 00:30:38.960
Because a lot of these
diseases are related,

00:30:38.960 --> 00:30:41.270
they can learn from each
other and you can't do

00:30:41.270 --> 00:30:42.860
cross-cutting data analytics.

00:30:45.580 --> 00:30:50.090
So there is a series
of reform steps here.

00:30:50.090 --> 00:30:53.570
As going back to some earlier
points we've made in the class,

00:30:53.570 --> 00:30:57.710
NIH is not a connected
organization.

00:30:57.710 --> 00:31:00.890
It's an early-stage basic
research organization.

00:31:00.890 --> 00:31:02.900
It's not connected to
the following stages.

00:31:02.900 --> 00:31:08.480
Now, it has managed to create
a model through biotechs

00:31:08.480 --> 00:31:11.450
that are venture funded
that is able to get

00:31:11.450 --> 00:31:17.120
across the valley of death if
you've got a blockbuster drug.

00:31:17.120 --> 00:31:19.430
That's pretty creative.

00:31:19.430 --> 00:31:23.180
Other agencies haven't
come up with that.

00:31:23.180 --> 00:31:26.120
It's not as if NIH was sitting
around figuring it out.

00:31:26.120 --> 00:31:29.930
But in effect, it occurred
and the training of the talent

00:31:29.930 --> 00:31:32.760
helped it occur through
people like Boyer and Swanson.

00:31:32.760 --> 00:31:33.260
Martine?

00:31:33.260 --> 00:31:34.840
AUDIENCE: Will we
define blockbuster drugs

00:31:34.840 --> 00:31:36.632
as the one that makes
a lot of money or one

00:31:36.632 --> 00:31:39.050
that impacts the disease
that a lot of people have?

00:31:39.050 --> 00:31:41.500
WILLIAM BONVILLIAN: One
that makes a lot of money.

00:31:41.500 --> 00:31:43.190
Right.

00:31:43.190 --> 00:31:46.400
I mean, in theory, it won't get
through FDA unless it actually

00:31:46.400 --> 00:31:47.210
solves a problem.

00:31:52.930 --> 00:31:55.300
NIH is primarily
small-grant research

00:31:55.300 --> 00:31:58.270
and lacks the
capability to set up

00:31:58.270 --> 00:31:59.852
initiatives across
the stovepipes

00:31:59.852 --> 00:32:01.060
as we've talked about before.

00:32:01.060 --> 00:32:04.400
It tends to be
fairly slow moving.

00:32:04.400 --> 00:32:06.190
There's a risk in peer
review of avoiding

00:32:06.190 --> 00:32:09.070
high-risk, high-payoff
approaches.

00:32:09.070 --> 00:32:11.380
There's limited
connections to industry.

00:32:11.380 --> 00:32:15.190
In other words, that
translational research effect

00:32:15.190 --> 00:32:19.510
is hard to do it at
NIH, although Collins,

00:32:19.510 --> 00:32:22.540
who's the current
director of NIH,

00:32:22.540 --> 00:32:26.170
has worked on creating a
special translational medicine

00:32:26.170 --> 00:32:28.240
institute designed
at that problem.

00:32:28.240 --> 00:32:30.100
So NIH has been
taking steps on this.

00:32:30.100 --> 00:32:31.970
I think that's a pretty good--

00:32:31.970 --> 00:32:34.690
I'll give you one more example--

00:32:34.690 --> 00:32:35.600
nanotechnology.

00:32:38.830 --> 00:32:41.117
The earliest beneficiary
of nanotechnology

00:32:41.117 --> 00:32:42.700
was probably the
semiconductor sector.

00:32:42.700 --> 00:32:45.340
But the life science sector,
the health research sector

00:32:45.340 --> 00:32:47.440
was very close.

00:32:47.440 --> 00:32:51.220
Huge potential,
opportunity spaces

00:32:51.220 --> 00:32:53.170
in understanding things
at the nanoscale here.

00:32:58.150 --> 00:33:04.290
Because of the disaggregated
structure of NIH,

00:33:04.290 --> 00:33:07.380
for many, many years after the
nanotechnology initiative was

00:33:07.380 --> 00:33:09.630
created, NIH--

00:33:09.630 --> 00:33:12.720
by far, the largest
research organization--

00:33:12.720 --> 00:33:15.900
was only spending a fraction
of what the National Science

00:33:15.900 --> 00:33:19.170
Foundation was spending
on nanotechnology, even

00:33:19.170 --> 00:33:23.220
though the gains for the
health research system

00:33:23.220 --> 00:33:27.450
were, and clearly
are, phenomenal.

00:33:27.450 --> 00:33:31.800
So that's an
example of a problem

00:33:31.800 --> 00:33:34.650
in being able to attack
a whole new approached

00:33:34.650 --> 00:33:39.060
disease across this very
disaggregated model.

00:33:42.320 --> 00:33:46.040
So that's the IOM
report of 2003.

00:33:46.040 --> 00:33:48.110
We've learned some
lessons from this.

00:33:48.110 --> 00:33:49.740
We tried to make some changes.

00:33:49.740 --> 00:33:51.740
And Congress has actually
provided a fair amount

00:33:51.740 --> 00:33:54.200
of leadership on that in
creating the common fund

00:33:54.200 --> 00:33:57.682
and capping the
number of institutes.

00:33:57.682 --> 00:34:00.140
Martin, you want to take us
through some questions in this?

00:34:00.140 --> 00:34:02.928
AUDIENCE: Do you actually want
to do the Cooke-Deegan one?

00:34:02.928 --> 00:34:04.720
Because that way I can
just integrate them.

00:34:04.720 --> 00:34:05.750
And it might be easier.

00:34:05.750 --> 00:34:06.230
WILLIAM BONVILLIAN: All right.

00:34:06.230 --> 00:34:07.760
We can do Deegan
and do it together.

00:34:07.760 --> 00:34:09.650
And we don't need to
spend a lot of time

00:34:09.650 --> 00:34:11.790
on this because last
week's class was on DARPA.

00:34:11.790 --> 00:34:15.830
So I'm not going to recap this.

00:34:15.830 --> 00:34:20.690
Robert Cooke-Deegan was
deputy when Watson was heading

00:34:20.690 --> 00:34:22.770
the Genome Project at NIH.

00:34:22.770 --> 00:34:25.409
So he knows NIH from the inside.

00:34:25.409 --> 00:34:29.860
He later went on to head
Duke's Genome Institute.

00:34:29.860 --> 00:34:33.670
So he's an outstanding
researcher.

00:34:33.670 --> 00:34:39.100
And now, he is teaching
science and technology policy

00:34:39.100 --> 00:34:43.449
at the Washington
branch of Arizona State.

00:34:43.449 --> 00:34:47.230
So he's gone over to the
dark side of science policy

00:34:47.230 --> 00:34:50.620
where people like me
inhabit the world.

00:34:50.620 --> 00:34:54.130
But he's got real talents,
unlike me actually,

00:34:54.130 --> 00:34:56.949
on the technology side.

00:34:56.949 --> 00:35:00.580
And he wrote this piece
back in 1996 fairly fresh

00:35:00.580 --> 00:35:05.890
off his own NIH experience,
Does NIH Need a DARPA?

00:35:05.890 --> 00:35:08.680
And I can't tell you how
controversial this was.

00:35:08.680 --> 00:35:11.650
NIH has always viewed itself
as better than everybody else.

00:35:11.650 --> 00:35:13.560
And the fact that
one of their own,

00:35:13.560 --> 00:35:16.240
the deputy director of
their Genome Project,

00:35:16.240 --> 00:35:18.728
was telling them there was a
better model out there that

00:35:18.728 --> 00:35:20.770
they ought to at least
consider adopting for part

00:35:20.770 --> 00:35:23.200
of their operation--
certainly, not for all--

00:35:23.200 --> 00:35:26.470
was a powerful message.

00:35:26.470 --> 00:35:28.250
And we know the DARPA story.

00:35:28.250 --> 00:35:30.790
So I'm not going to recap that.

00:35:30.790 --> 00:35:34.090
Robert Cooke-Deegan underscores
that the DARPA model

00:35:34.090 --> 00:35:38.320
suggests that peer review is
not the only way of organizing

00:35:38.320 --> 00:35:40.150
research.

00:35:40.150 --> 00:35:43.720
DARPA has far lower transaction
costs than NIH does,

00:35:43.720 --> 00:35:46.657
a lot lower review costs
per science direction.

00:35:49.520 --> 00:35:54.680
He introduces this issue of how
conservative peer review gets

00:35:54.680 --> 00:35:58.370
when it gets to an
award rate that's

00:35:58.370 --> 00:36:03.510
much worse than about one out
of three applications per grants

00:36:03.510 --> 00:36:04.010
awarded.

00:36:06.860 --> 00:36:08.750
NIH has got a very
limited ability

00:36:08.750 --> 00:36:14.790
to do the grand challenge model,
to pursue that challenge model.

00:36:14.790 --> 00:36:16.700
It's got limited ability
to take high risks

00:36:16.700 --> 00:36:19.220
and get high rewards.

00:36:19.220 --> 00:36:22.820
It's got a lower risk
acceptance capability.

00:36:22.820 --> 00:36:26.240
Those are DARPA things that NIH
should have-- not all of NIH,

00:36:26.240 --> 00:36:31.190
but certainly some part of
it-- might adopt, he argues.

00:36:31.190 --> 00:36:32.450
He cites a lot of examples.

00:36:36.540 --> 00:36:38.150
The Human Genome
Initiative actually

00:36:38.150 --> 00:36:40.790
originated in the
Department of Energy

00:36:40.790 --> 00:36:45.080
because the Department of Energy
understood supercomputers.

00:36:45.080 --> 00:36:47.210
So for the first five years
of the Genome Project,

00:36:47.210 --> 00:36:51.740
it was carried by the
supercomputer gurus

00:36:51.740 --> 00:36:53.240
at DOE, because
they understood what

00:36:53.240 --> 00:36:55.950
the potential supercomputing
was going to be in figuring out

00:36:55.950 --> 00:36:57.920
the genetic structure.

00:36:57.920 --> 00:37:02.570
NIH only picked it up when it
saw the promise of the model.

00:37:02.570 --> 00:37:05.720
NIH had terrible trouble
coping with the advances made

00:37:05.720 --> 00:37:06.650
by Leroy Hood.

00:37:06.650 --> 00:37:09.380
And we'll talk
later about Venter

00:37:09.380 --> 00:37:12.590
and how do you adapt
and incorporate

00:37:12.590 --> 00:37:15.860
a computational model
in medical research.

00:37:15.860 --> 00:37:18.560
They're locked into a
biology-only drug development

00:37:18.560 --> 00:37:19.820
model pretty much.

00:37:19.820 --> 00:37:22.450
It's hard for them to
do other territories

00:37:22.450 --> 00:37:25.280
as we'll talk about when we
get to the convergence report.

00:37:25.280 --> 00:37:30.650
So the lessons from
DARPA for handling

00:37:30.650 --> 00:37:34.640
multidisciplinary approaches in
bringing in a group of talent

00:37:34.640 --> 00:37:37.670
around a problem that comes
from different fields, there's

00:37:37.670 --> 00:37:42.660
lessons here for NIH.

00:37:42.660 --> 00:37:47.240
I mean, that's the heart
of Robert Cooke-Deegan's

00:37:47.240 --> 00:37:48.200
recommendations.

00:37:48.200 --> 00:37:52.297
And Martine, it's yours.

00:37:52.297 --> 00:37:54.755
AUDIENCE: So I think you did
a good analysis of the papers.

00:37:54.755 --> 00:37:57.800
So I won't really
summarize too much more.

00:37:57.800 --> 00:38:00.530
I think we can just go
straight into discussion.

00:38:00.530 --> 00:38:03.860
And so I think a good first
question would be, how do we--

00:38:03.860 --> 00:38:06.320
know that there's a lot of cost
in the health care industry

00:38:06.320 --> 00:38:09.220
and this system, the structure
they have isn't perfect.

00:38:09.220 --> 00:38:11.720
And so how do we create a system
so that these problems that

00:38:11.720 --> 00:38:14.240
need to get solved but don't
have economic incentive

00:38:14.240 --> 00:38:15.740
because they're
not blockbusters,

00:38:15.740 --> 00:38:19.010
how do you combine NIH with
maybe some DARPA-like abilities

00:38:19.010 --> 00:38:20.750
and industry?

00:38:20.750 --> 00:38:24.687
And if anybody's specialty
is higher research,

00:38:24.687 --> 00:38:26.770
it would be interesting
to get your insight first.

00:38:30.418 --> 00:38:32.210
AUDIENCE: What you mean
by higher research?

00:38:32.210 --> 00:38:33.627
AUDIENCE: Well,
if you're focusing

00:38:33.627 --> 00:38:37.980
on an academic career
in a national lab,

00:38:37.980 --> 00:38:39.590
you know more about
that than I would.

00:38:39.590 --> 00:38:40.700
AUDIENCE: Where is
Lilly when you need her?

00:38:40.700 --> 00:38:42.400
AUDIENCE: Yes, you got it.

00:38:46.390 --> 00:38:49.750
AUDIENCE: Yeah, I
think you probably,

00:38:49.750 --> 00:38:52.150
as Cooke-Deegan laid it out,
you just really struggle

00:38:52.150 --> 00:38:55.510
in this peer review process
if you have an idea for maybe

00:38:55.510 --> 00:38:59.680
not a blockbuster drug
but a new approach

00:38:59.680 --> 00:39:02.320
to a system that hasn't
really been tried out yet.

00:39:02.320 --> 00:39:03.460
So that's what you see.

00:39:03.460 --> 00:39:06.490
[INAUDIBLE] a mentor
have this huge problem.

00:39:06.490 --> 00:39:08.260
And I think it
really is just kind

00:39:08.260 --> 00:39:13.120
of allocating a part
of that NIH budget

00:39:13.120 --> 00:39:18.040
that they get to this
DARPA-like high-impact, maybe

00:39:18.040 --> 00:39:22.410
high-risk research and
then moving from there.

00:39:22.410 --> 00:39:25.410
But I'm not sure
because it takes

00:39:25.410 --> 00:39:28.953
so long to develop these
things, so a three to five year.

00:39:28.953 --> 00:39:31.370
And then you have to figure
out clinical trials and things

00:39:31.370 --> 00:39:32.430
like that like.

00:39:32.430 --> 00:39:34.430
Would the time scale
need to be adjusted

00:39:34.430 --> 00:39:35.930
to account for
doing the research

00:39:35.930 --> 00:39:37.430
and then moving
into clinical trials

00:39:37.430 --> 00:39:41.840
to be able to actually support
these high-risk initiatives.

00:39:41.840 --> 00:39:43.438
And a lot of these
I feel like will

00:39:43.438 --> 00:39:45.480
be building on research
that doesn't really exist

00:39:45.480 --> 00:39:46.610
or isn't really there yet.

00:39:46.610 --> 00:39:50.803
So we'll need more time
to stand up [INAUDIBLE]..

00:39:50.803 --> 00:39:52.470
AUDIENCE: Yeah, I
think there's probably

00:39:52.470 --> 00:39:55.380
two main ways that maybe
some of the later readings

00:39:55.380 --> 00:39:56.110
touch on more.

00:39:56.110 --> 00:40:00.630
But definitely,
incentives on the FDA

00:40:00.630 --> 00:40:04.110
is hard to extend and make
that process a little bit more

00:40:04.110 --> 00:40:08.490
profitable than, say, if it's
on an orphan drug where you have

00:40:08.490 --> 00:40:12.660
a very small market that
could be addressed when

00:40:12.660 --> 00:40:16.890
the drug comes out by
increasing the patent life

00:40:16.890 --> 00:40:19.020
so they have extended
patent provisions

00:40:19.020 --> 00:40:20.760
for those kind of drugs.

00:40:20.760 --> 00:40:24.060
That definitely helps
make it more profitable.

00:40:24.060 --> 00:40:27.870
And also, a lot of the later
papers talk about this.

00:40:27.870 --> 00:40:30.390
But they have a
lot of flexibility

00:40:30.390 --> 00:40:32.910
in the way they can
price their drugs.

00:40:32.910 --> 00:40:37.710
So I think that kind of helps a
lot because if they can charge

00:40:37.710 --> 00:40:43.050
a lot of money for a niche
drug that kind of compensates

00:40:43.050 --> 00:40:46.565
for the fact that you're not
giving it to as many people.

00:40:46.565 --> 00:40:48.690
AUDIENCE: And I guess my
concern with that last one

00:40:48.690 --> 00:40:50.882
is what about a Martin
Shkreli situation?

00:40:50.882 --> 00:40:51.840
AUDIENCE: I mean, yeah.

00:40:51.840 --> 00:40:53.940
Obviously, that's
going to come up

00:40:53.940 --> 00:40:55.770
because all these
companies will want

00:40:55.770 --> 00:40:58.230
to recoup their costs
because they're spending

00:40:58.230 --> 00:41:02.180
millions and billions of dollars
on these drugs to develop them.

00:41:02.180 --> 00:41:04.830
And there is kind of an
argument for both ways

00:41:04.830 --> 00:41:08.010
that it's kind of justified
but, I mean, obviously, bad

00:41:08.010 --> 00:41:10.730
for society.

00:41:10.730 --> 00:41:14.040
AUDIENCE: And also, you could
make a very similar argument

00:41:14.040 --> 00:41:17.280
for any other drug in one
of these blockbuster drugs

00:41:17.280 --> 00:41:18.630
as we say.

00:41:18.630 --> 00:41:21.090
Because well, you
can still charge

00:41:21.090 --> 00:41:22.650
an exorbitant price for them.

00:41:22.650 --> 00:41:24.630
You can get tons
of money for them.

00:41:24.630 --> 00:41:27.155
And then you're back to
square 1 where, OK, let's just

00:41:27.155 --> 00:41:28.530
keep funding the
drugs that we've

00:41:28.530 --> 00:41:33.380
been doing because don't fix
what isn't broken, right?

00:41:33.380 --> 00:41:39.140
So I'm not sure how it would
incentivize people to focus

00:41:39.140 --> 00:41:40.280
on these smaller drugs.

00:41:40.280 --> 00:41:44.570
Now, one way you could do
it, maybe tax incentives

00:41:44.570 --> 00:41:45.830
or something.

00:41:45.830 --> 00:41:48.860
Maybe force insurance companies
to foot the bill a bit more.

00:41:48.860 --> 00:41:53.177
But I don't really know the
detail on how that would work.

00:41:53.177 --> 00:41:55.760
WILLIAM BONVILLIAN: This is one
of the great societal dilemmas

00:41:55.760 --> 00:41:57.593
that we've get in health
care at the moment.

00:41:57.593 --> 00:42:03.050
You want to create enormous
incentives for researchers

00:42:03.050 --> 00:42:06.080
and the biotech
companies they may create

00:42:06.080 --> 00:42:07.890
to go after these big problems.

00:42:07.890 --> 00:42:11.280
You really want to
incentivize that process.

00:42:11.280 --> 00:42:13.460
So if you start to
disincentivize it,

00:42:13.460 --> 00:42:17.030
you're going to have less
remedies on the table.

00:42:17.030 --> 00:42:20.330
On the other hand, you've
got serious cost problems

00:42:20.330 --> 00:42:22.610
for some portion of
the population that's

00:42:22.610 --> 00:42:25.113
not going to be able to cope
with the cost structure.

00:42:25.113 --> 00:42:26.780
And you're going to
have real reluctance

00:42:26.780 --> 00:42:28.220
on the part of
government agencies

00:42:28.220 --> 00:42:32.630
to subscribe for a
huge cost burden that

00:42:32.630 --> 00:42:35.330
only helps a relatively
small number of people.

00:42:35.330 --> 00:42:39.410
So this is a dilemma that
is now upon us big time

00:42:39.410 --> 00:42:42.680
that we have not sorted
through in an intelligent way.

00:42:42.680 --> 00:42:49.500
And there's constant reviling
of drug and biotech companies.

00:42:49.500 --> 00:42:51.583
But on the other
hand, they're the ones

00:42:51.583 --> 00:42:53.250
that created these
opportunities for us.

00:42:53.250 --> 00:42:55.400
So it's a very contradictory--

00:42:55.400 --> 00:42:59.140
the politics doesn't seem
to recognize the importance

00:42:59.140 --> 00:43:00.380
of the innovation system.

00:43:00.380 --> 00:43:03.556
And yet we don't have the
right balance between the two.

00:43:03.556 --> 00:43:04.306
AUDIENCE: Yeah, [?

00:43:04.306 --> 00:43:06.150
I was just going to answer ?]
[INAUDIBLE] the policy side,

00:43:06.150 --> 00:43:06.780
or whatever
[? you want to say. ?]

00:43:06.780 --> 00:43:07.660
AUDIENCE: Oh, I
actually was going

00:43:07.660 --> 00:43:10.308
to say that also I think the
dimension that's also missing

00:43:10.308 --> 00:43:12.100
is something we touched
on last week, which

00:43:12.100 --> 00:43:13.540
is the ethical components.

00:43:13.540 --> 00:43:16.300
I think there's really a rising
bioethics community surrounding

00:43:16.300 --> 00:43:20.230
issues of utilitarianism versus
issues of human suffering.

00:43:20.230 --> 00:43:22.290
Do we seek to address
the person who

00:43:22.290 --> 00:43:25.000
is suffering the most
or the number of people

00:43:25.000 --> 00:43:26.350
who are suffering?

00:43:26.350 --> 00:43:29.830
And that is a really
difficult, I think,

00:43:29.830 --> 00:43:31.720
ethical question
that has yet to be

00:43:31.720 --> 00:43:34.490
addressed on a national level.

00:43:34.490 --> 00:43:38.575
And I think it's easier--

00:43:41.308 --> 00:43:43.350
I guess, I think about it
in terms of heuristics,

00:43:43.350 --> 00:43:45.460
like short cuts for
decision making.

00:43:45.460 --> 00:43:48.000
If we understand what our
values are nationally,

00:43:48.000 --> 00:43:51.150
we can understand where to
begin to allocate money.

00:43:51.150 --> 00:43:53.910
And if we sort out
our national values

00:43:53.910 --> 00:43:56.610
in terms of the life
sciences and what

00:43:56.610 --> 00:43:58.800
we think are our
national priorities,

00:43:58.800 --> 00:44:01.873
perhaps maybe through a
referendum-like system,

00:44:01.873 --> 00:44:03.540
I think it would
actually be a much more

00:44:03.540 --> 00:44:06.450
efficient and accountable
way for the government

00:44:06.450 --> 00:44:08.740
to make funding
priority decisions

00:44:08.740 --> 00:44:12.540
rather than for life sciences
organizations and the NIH

00:44:12.540 --> 00:44:15.420
to sort of make those
decisions for themselves

00:44:15.420 --> 00:44:16.680
or for the citizens.

00:44:16.680 --> 00:44:22.080
Because ultimately, this is
an issue at the human level.

00:44:22.080 --> 00:44:24.600
And that implies
an understanding

00:44:24.600 --> 00:44:27.308
of bioethical considerations.

00:44:27.308 --> 00:44:29.850
WILLIAM BONVILLIAN: I think that
tends to run into a problem,

00:44:29.850 --> 00:44:33.570
however, with root attitudes
of the American population.

00:44:33.570 --> 00:44:36.270
And I would say that a lot
of the American population

00:44:36.270 --> 00:44:38.820
believes that we should
be allowed to live forever

00:44:38.820 --> 00:44:40.230
because we're Americans.

00:44:40.230 --> 00:44:43.350
So we should be eternal.

00:44:43.350 --> 00:44:44.640
I'm exaggerating a bit here.

00:44:44.640 --> 00:44:46.230
But there's a lot
of thinking along

00:44:46.230 --> 00:44:48.780
those lines and a
lot of assumptions

00:44:48.780 --> 00:44:53.520
that any cost, whatever it
is, is justified in terms

00:44:53.520 --> 00:44:55.660
of the outcome for my health.

00:44:55.660 --> 00:44:59.760
So these are these are
really tough decisions.

00:44:59.760 --> 00:45:02.520
And the life science system
is now right up against this.

00:45:02.520 --> 00:45:04.940
And the whole innovation model
is right up against these.

00:45:04.940 --> 00:45:09.555
So these are these are
important considerations.

00:45:09.555 --> 00:45:10.180
AUDIENCE: Yeah.

00:45:10.180 --> 00:45:14.170
Just my concern with the
proposal as far as putting it

00:45:14.170 --> 00:45:17.350
in the hands of
American people is

00:45:17.350 --> 00:45:21.490
kind of what questions are
appropriate for letting people

00:45:21.490 --> 00:45:23.925
to be answering versus
the ones that are experts.

00:45:23.925 --> 00:45:25.300
[INAUDIBLE] A lot
of people would

00:45:25.300 --> 00:45:28.317
debate that the Brexit
question wasn't really

00:45:28.317 --> 00:45:30.400
something that the average
person could understand

00:45:30.400 --> 00:45:32.515
well enough to make
an informed decision.

00:45:32.515 --> 00:45:34.480
And so I guess if
you're asking strictly

00:45:34.480 --> 00:45:36.670
what are your ethical
beliefs, vote on that.

00:45:36.670 --> 00:45:38.712
I guess that's something
that people can vote on.

00:45:38.712 --> 00:45:40.690
But if you're given
options of should we

00:45:40.690 --> 00:45:45.250
fund something that will save x
number of people at this cost,

00:45:45.250 --> 00:45:48.130
weighing that information is
more difficult than I think

00:45:48.130 --> 00:45:51.640
the average person is willing to
put the time in to understand.

00:45:51.640 --> 00:45:54.490
So I think that,
to some extent, NIH

00:45:54.490 --> 00:45:55.990
and these kind of
organizations need

00:45:55.990 --> 00:45:59.580
to make the decisions on what
our national priorities are

00:45:59.580 --> 00:46:02.437
but, ideally, with
some input from us.

00:46:02.437 --> 00:46:04.020
WILLIAM BONVILLIAN:
I want to push you

00:46:04.020 --> 00:46:08.440
back to the issue that's
before us in this class, which

00:46:08.440 --> 00:46:12.170
is the innovation organization
model that we've got here.

00:46:12.170 --> 00:46:15.070
So we're looking at an
innovation organization that

00:46:15.070 --> 00:46:17.410
evolved in a very
historical set of ways

00:46:17.410 --> 00:46:19.990
where the problems, when
it was in the foundation

00:46:19.990 --> 00:46:22.960
level, the scientific
problems turned out

00:46:22.960 --> 00:46:26.860
to be different than
the way we see them now.

00:46:26.860 --> 00:46:29.350
We tend to see that
there are a lot

00:46:29.350 --> 00:46:31.780
of cross-cutting
scientific approaches

00:46:31.780 --> 00:46:34.870
that cut across many
disease pathways that may

00:46:34.870 --> 00:46:36.880
be critical for those diseases.

00:46:36.880 --> 00:46:39.490
Whereas back then,
we saw, oh, there

00:46:39.490 --> 00:46:42.730
will be one remedy
for each disease,

00:46:42.730 --> 00:46:46.210
a much earlier-stage
scientific notion of disease.

00:46:46.210 --> 00:46:48.070
And we're caught
up in that model.

00:46:48.070 --> 00:46:52.930
And how do we bring change here?

00:46:52.930 --> 00:46:54.895
We're up against a
legacy-sector problem

00:46:54.895 --> 00:46:57.160
as we'll talk in a little bit.

00:46:57.160 --> 00:47:00.900
How do we bring change
to that legacy sector

00:47:00.900 --> 00:47:04.050
from an organizational
point of view?

00:47:04.050 --> 00:47:07.650
AUDIENCE: I have not an
answer, but a non-answer.

00:47:07.650 --> 00:47:11.620
I am going back to the attack
on peer review as it were.

00:47:11.620 --> 00:47:16.727
I think that's a very odd place
to start in terms of something

00:47:16.727 --> 00:47:17.310
to get rid of.

00:47:17.310 --> 00:47:22.500
I think there were definitely
a lot of reasonable arguments

00:47:22.500 --> 00:47:25.730
presented in favor of adopting
something a DARPA model.

00:47:25.730 --> 00:47:27.510
And then going back
to your ethics--

00:47:27.510 --> 00:47:29.820
you raised the point of
bioethics considerations.

00:47:29.820 --> 00:47:33.290
It seems to me that peer
review in the system,

00:47:33.290 --> 00:47:35.040
appearing to be the
values of peer review,

00:47:35.040 --> 00:47:39.960
are so deeply ingrained
in the biopharmaceutical--

00:47:39.960 --> 00:47:44.687
well, more on the biological
and medical research community.

00:47:44.687 --> 00:47:46.770
It seems like it's very
much part of their values.

00:47:46.770 --> 00:47:48.840
And it would be very
odd to me to see

00:47:48.840 --> 00:47:51.090
them as separated out
because I can recognize

00:47:51.090 --> 00:47:53.260
all of the detriments of
the peer review system

00:47:53.260 --> 00:47:56.140
and how it can
favor incremental,

00:47:56.140 --> 00:48:02.100
unimportant research over big
innovations and risk takers.

00:48:02.100 --> 00:48:04.890
But it still seems like,
if you remove that barrier,

00:48:04.890 --> 00:48:07.200
then you might have a
flood of ethical problems

00:48:07.200 --> 00:48:08.940
that would just
start cropping up.

00:48:08.940 --> 00:48:10.950
WILLIAM BONVILLIAN:
Look, I mean,

00:48:10.950 --> 00:48:13.770
the DARPA model does not
work in all circumstances.

00:48:13.770 --> 00:48:16.950
In other words, the DARPA model
is very much a top-down model.

00:48:16.950 --> 00:48:20.580
A bunch of elite
program managers

00:48:20.580 --> 00:48:22.890
are looking at
things they want out

00:48:22.890 --> 00:48:25.140
of the end of the
innovation pipeline

00:48:25.140 --> 00:48:28.940
and designing
projects to get there.

00:48:28.940 --> 00:48:31.970
And we can certainly see why
there's room for this model,

00:48:31.970 --> 00:48:35.750
for that kind of projects-based,
challenge-based model.

00:48:35.750 --> 00:48:39.200
NIH offers the other
side of the coin.

00:48:39.200 --> 00:48:41.360
Researchers propose
funding, and they

00:48:41.360 --> 00:48:44.660
get funded based upon the
interest and quality of what

00:48:44.660 --> 00:48:46.100
they're proposing.

00:48:46.100 --> 00:48:47.770
That's very much
a bottom-up model.

00:48:47.770 --> 00:48:50.020
In other words, a lot of
people can see a lot of stuff

00:48:50.020 --> 00:48:52.700
in the bottom level
that a top-down model

00:48:52.700 --> 00:48:54.110
can't necessarily see.

00:48:54.110 --> 00:48:55.880
So Chloe, you're right.

00:48:55.880 --> 00:49:00.800
It's not that you want to
replace NIH with DARPA.

00:49:00.800 --> 00:49:02.480
I think what Robert
Cooke-Deegan would

00:49:02.480 --> 00:49:07.620
say is maybe there's
room within a large NIH

00:49:07.620 --> 00:49:09.870
entity for a DARPA like piece.

00:49:09.870 --> 00:49:13.320
Just as there is in the
Defense Innovation System,

00:49:13.320 --> 00:49:16.590
DARPA is only one element of
a much larger defense research

00:49:16.590 --> 00:49:17.670
portfolio.

00:49:17.670 --> 00:49:20.290
But it does provide some
interesting capability.

00:49:23.830 --> 00:49:29.880
And peer review
does have advantages

00:49:29.880 --> 00:49:33.660
from that bottom-up perspective
that a top-down strong program

00:49:33.660 --> 00:49:36.990
manager perspective will not
necessarily be able to capture.

00:49:41.247 --> 00:49:42.955
AUDIENCE: So from a
business perspective,

00:49:42.955 --> 00:49:44.080
the thing I'm
wondering about is--

00:49:44.080 --> 00:49:45.913
because there is this
trend right now called

00:49:45.913 --> 00:49:47.825
social bonds, which
what they do is

00:49:47.825 --> 00:49:50.200
they look at the parts of
society that are really wasting

00:49:50.200 --> 00:49:52.000
a lot of money and
then they create

00:49:52.000 --> 00:49:53.590
businesses to solve them.

00:49:53.590 --> 00:49:56.850
And then they give a return.

00:49:56.850 --> 00:49:58.780
That's why I asked about
the blockbuster drug.

00:49:58.780 --> 00:50:00.530
Because you get to
find a blockbuster drug

00:50:00.530 --> 00:50:02.830
is also a drug that
reduces a ton of costs

00:50:02.830 --> 00:50:03.630
for the government.

00:50:03.630 --> 00:50:05.755
And the business model is
the government is saying,

00:50:05.755 --> 00:50:08.410
oh, we're spending $100 million
here to solve this problem.

00:50:08.410 --> 00:50:11.370
We're going to send some of that
portion of the money to you.

00:50:11.370 --> 00:50:14.500
And that's a good
way to cut the fat.

00:50:14.500 --> 00:50:16.120
Because if the major
problem is we're

00:50:16.120 --> 00:50:18.730
going to use all our budget
to solve these diseases--

00:50:18.730 --> 00:50:22.887
there's probably a disease
that's 80% or a huge proportion

00:50:22.887 --> 00:50:24.970
because it's not going to
be a linear relationship

00:50:24.970 --> 00:50:26.805
with the cost.

00:50:26.805 --> 00:50:28.180
My other concern
too was when you

00:50:28.180 --> 00:50:30.408
said that they
doubled the budget,

00:50:30.408 --> 00:50:31.700
this happens a lot in software.

00:50:31.700 --> 00:50:33.880
So it's hard and
unintuitive to understand.

00:50:33.880 --> 00:50:36.580
But it's like, say we're
going to have the lunch.

00:50:36.580 --> 00:50:39.040
And I say, our
budget is $100,000.

00:50:39.040 --> 00:50:40.040
Then I have to justify--

00:50:40.040 --> 00:50:42.130
WILLIAM BONVILLIAN: That
would be quite a lunch.

00:50:42.130 --> 00:50:44.530
AUDIENCE: Yeah, that's the
thing because we're not just

00:50:44.530 --> 00:50:45.130
eating, right?

00:50:45.130 --> 00:50:49.690
It's like, OK, now, we have
to justify the $100,000.

00:50:49.690 --> 00:50:51.293
Or a cool example
is right now there

00:50:51.293 --> 00:50:53.950
is a startup in Silicon Valley
that spent like $120 million

00:50:53.950 --> 00:50:55.540
to develop a juicer.

00:50:55.540 --> 00:50:59.620
And so that you could only
juice with the machine.

00:50:59.620 --> 00:51:02.387
And then a reporter was
like, I call your bluff.

00:51:02.387 --> 00:51:03.970
And they squeezed
it with their hands.

00:51:03.970 --> 00:51:05.730
And they did it.

00:51:05.730 --> 00:51:08.170
So my concern is when
you have too much money,

00:51:08.170 --> 00:51:09.910
you tend to have
to justify things.

00:51:09.910 --> 00:51:11.723
And you come up with
this weird logic tree.

00:51:11.723 --> 00:51:13.390
And you don't really
fundamentally solve

00:51:13.390 --> 00:51:14.300
the problem.

00:51:14.300 --> 00:51:16.840
In code, if there's a piece
code that one coder could do

00:51:16.840 --> 00:51:19.007
and you put five people,
it actually complicates it.

00:51:19.007 --> 00:51:20.210
It makes it way harder.

00:51:20.210 --> 00:51:22.300
And now, you got
people infighting.

00:51:22.300 --> 00:51:25.770
So that was my big
concern with that too.

00:51:25.770 --> 00:51:28.800
AUDIENCE: I think-- and Martin
may be trying to get at it.

00:51:28.800 --> 00:51:31.080
This kind of group
theory doesn't really

00:51:31.080 --> 00:51:33.665
exists or kind of
breaks down in NIH

00:51:33.665 --> 00:51:35.790
because it's really hard
to get these cross-cutting

00:51:35.790 --> 00:51:38.140
technologies and encourage
that collaboration.

00:51:38.140 --> 00:51:42.420
And I think what I really
want to see out of the DARPA

00:51:42.420 --> 00:51:45.100
that they pull is not so much
get rid of the peer review

00:51:45.100 --> 00:51:47.280
but start--

00:51:47.280 --> 00:51:50.130
because DARPA has the ability
to pull these great groups

00:51:50.130 --> 00:51:52.697
together and just call on
a lot of different folks

00:51:52.697 --> 00:51:54.780
from a lot of different
areas and then direct them

00:51:54.780 --> 00:51:58.500
towards a specific
research problem.

00:51:58.500 --> 00:52:00.600
And I think where NIH
struggles is, yeah,

00:52:00.600 --> 00:52:02.700
they might have a call
to say we want to get rid

00:52:02.700 --> 00:52:05.442
of cancer or heart disease.

00:52:05.442 --> 00:52:07.650
But there are a lot of
different folks working on it.

00:52:07.650 --> 00:52:11.880
And not a lot of them, I would
say, probably work together

00:52:11.880 --> 00:52:14.190
in tandem to really
figure out and solve

00:52:14.190 --> 00:52:18.540
maybe one aspect of that
problem for maybe 10 years.

00:52:18.540 --> 00:52:20.280
And then they focus
on a different aspect

00:52:20.280 --> 00:52:23.670
of how a disease would
work in a different lab.

00:52:23.670 --> 00:52:27.070
And I think NIH really
struggles in pulling together

00:52:27.070 --> 00:52:29.070
these cross-cutting
technologies because there's

00:52:29.070 --> 00:52:32.490
no one pulling them together.

00:52:32.490 --> 00:52:36.350
And they just leave it up to the
discretion of the researchers

00:52:36.350 --> 00:52:38.220
and scientists and
pharmaceutical companies

00:52:38.220 --> 00:52:40.740
to come up with
incremental advances

00:52:40.740 --> 00:52:47.730
rather than not only calling
for big calls or big research

00:52:47.730 --> 00:52:49.830
projects but also
funding and making

00:52:49.830 --> 00:52:52.080
it possible for great groups
to work on these research

00:52:52.080 --> 00:52:53.400
projects.

00:52:53.400 --> 00:52:54.310
AUDIENCE: Max

00:52:54.310 --> 00:52:54.850
WILLIAM BONVILLIAN:
Martin, you want

00:52:54.850 --> 00:52:57.570
to give us some closing
thoughts on these two pieces?

00:52:57.570 --> 00:52:58.390
Oh, I'm sorry, Max.

00:52:58.390 --> 00:52:58.890
Did you--

00:52:58.890 --> 00:53:00.940
AUDIENCE: I actually
had a quick question.

00:53:00.940 --> 00:53:07.020
So given that this was published
21 years ago, give or take,

00:53:07.020 --> 00:53:07.600
I'm curious--

00:53:07.600 --> 00:53:10.017
WILLIAM BONVILLIAN: Robert
Cooke-Deegan's piece, you mean.

00:53:10.017 --> 00:53:10.690
AUDIENCE: Yeah.

00:53:10.690 --> 00:53:14.050
Did NIH ever attempt
anything like this?

00:53:14.050 --> 00:53:16.592
Because we've had some
significant time period.

00:53:16.592 --> 00:53:17.800
Did they at least look at it?

00:53:17.800 --> 00:53:18.865
Or did they decide, no?

00:53:18.865 --> 00:53:20.740
AUDIENCE: And also, how
much criticism did he

00:53:20.740 --> 00:53:23.773
get for publishing that?

00:53:23.773 --> 00:53:25.690
WILLIAM BONVILLIAN: It
was a threatening piece

00:53:25.690 --> 00:53:29.360
to the NIH and life
science community,

00:53:29.360 --> 00:53:33.590
frankly, arguing that there may
be an additional model that you

00:53:33.590 --> 00:53:35.480
all need to consider.

00:53:35.480 --> 00:53:37.970
So it was not received
with open arms.

00:53:37.970 --> 00:53:46.010
Now, in fact, the current
NIH director, Collins,

00:53:46.010 --> 00:53:50.390
has, early on in his
tenure as director,

00:53:50.390 --> 00:53:52.400
latched onto the
problem that NIH

00:53:52.400 --> 00:53:55.410
has got in doing translational
work-- in other words,

00:53:55.410 --> 00:53:57.320
moving a technology
from the basic stage

00:53:57.320 --> 00:53:59.990
into follow-on sectors
and doing the handoff

00:53:59.990 --> 00:54:01.010
to the private sector.

00:54:01.010 --> 00:54:04.280
So Collins began to
focus on that problem.

00:54:04.280 --> 00:54:08.450
And there was discussion, at
that time, of doing something

00:54:08.450 --> 00:54:09.320
like a DARPA.

00:54:09.320 --> 00:54:14.030
So his effort to create NCATS
to do translational medicine,

00:54:14.030 --> 00:54:17.090
the director that he hired
to head that new institute--

00:54:17.090 --> 00:54:18.860
and he had to close
another one to do it--

00:54:22.630 --> 00:54:25.000
actually really began
thinking seriously

00:54:25.000 --> 00:54:29.080
about should there be DARPA-like
elements in this new NCATS

00:54:29.080 --> 00:54:30.213
entity.

00:54:30.213 --> 00:54:31.630
Chris Austin who
is that director,

00:54:31.630 --> 00:54:38.290
very talented and very
interesting person, however,

00:54:38.290 --> 00:54:41.080
just didn't have the resource
to set up a whole new entity

00:54:41.080 --> 00:54:44.560
within his NCATS piece.

00:54:44.560 --> 00:54:46.150
But so it's an
idea that continues

00:54:46.150 --> 00:54:48.370
to kick around here and there.

00:54:48.370 --> 00:54:52.390
And frankly, I would view it
as an interesting additional

00:54:52.390 --> 00:54:56.380
feature for NIH to do some
things that it can't really

00:54:56.380 --> 00:54:59.920
do without this kind of
organizational model.

00:54:59.920 --> 00:55:03.220
So I think there's
organizational lessons here

00:55:03.220 --> 00:55:05.590
that we can take from the
issues we've been reviewing

00:55:05.590 --> 00:55:11.500
and apply it to a long
established research entity

00:55:11.500 --> 00:55:15.110
to create new
things in the model.

00:55:15.110 --> 00:55:17.147
How about some closing
thoughts, Martine?

00:55:17.147 --> 00:55:18.730
AUDIENCE: I mean,
the closing thoughts

00:55:18.730 --> 00:55:20.800
is that we discussed
the NIH model

00:55:20.800 --> 00:55:22.780
and how it does work
for what they're doing

00:55:22.780 --> 00:55:25.120
but also how there are a
lot of blind spots and areas

00:55:25.120 --> 00:55:29.483
that aren't being touched into
I've been trying to solve.

00:55:29.483 --> 00:55:31.150
And then we discussed
DARPA, which might

00:55:31.150 --> 00:55:32.317
be a good way of solving it.

00:55:32.317 --> 00:55:36.250
But it seems like it won't
fit in well with NIH.

00:55:36.250 --> 00:55:39.130
But there is a structural
dissonance, I would say,

00:55:39.130 --> 00:55:41.920
in terms of that this
form factor does not work

00:55:41.920 --> 00:55:43.450
for these kinds of problems.

00:55:43.450 --> 00:55:47.200
And it might also
be the groupthink

00:55:47.200 --> 00:55:49.360
in the area that affects
their ability to solve

00:55:49.360 --> 00:55:50.690
these kinds of problems.

00:55:50.690 --> 00:55:53.440
So it might be better
for there to be a DARPA

00:55:53.440 --> 00:55:57.460
NIH but not at NIH or nearby
because it might be too

00:55:57.460 --> 00:56:00.100
difficult. And also, how do
you create natural incentives

00:56:00.100 --> 00:56:01.140
for the researchers.

00:56:01.140 --> 00:56:05.110
Because it seems like they
do these kind of leapfrogging

00:56:05.110 --> 00:56:08.300
research initiatives
because it's a lot simpler

00:56:08.300 --> 00:56:10.270
and they have a lot to
lose if they do fail.

00:56:10.270 --> 00:56:12.790
And so how do you create
this kind of comfort zone

00:56:12.790 --> 00:56:15.550
for researchers so that,
even if they do fail,

00:56:15.550 --> 00:56:17.750
to get some kind of reward?

00:56:17.750 --> 00:56:21.017
And how do they get recognition
for that sacrifice of their

00:56:21.017 --> 00:56:22.350
what you call "academic career."

00:56:24.927 --> 00:56:26.010
WILLIAM BONVILLIAN: Right.

00:56:26.010 --> 00:56:28.230
I mean, that's
another issue too,

00:56:28.230 --> 00:56:32.660
which is having multiple
PIs on the problem.

00:56:32.660 --> 00:56:35.460
It's complicated in
an RO1 award process

00:56:35.460 --> 00:56:38.070
that focuses on the single PI.

00:56:38.070 --> 00:56:41.850
Let me go onto the next
couple of readings.

00:56:41.850 --> 00:56:44.490
And we'll do them as a pair.

00:56:44.490 --> 00:56:47.280
So the Infectious Disease
Society of America

00:56:47.280 --> 00:56:51.630
has this report called Bad Bugs,
No Drugs, which essentially

00:56:51.630 --> 00:56:54.750
summarizes the whole problem.

00:56:54.750 --> 00:56:56.640
And then the Food and
Drug Administration

00:56:56.640 --> 00:57:00.570
has a paper on
innovation or stagnation,

00:57:00.570 --> 00:57:04.080
which focuses on some of
the problems they face.

00:57:04.080 --> 00:57:08.580
So let's do those.

00:57:08.580 --> 00:57:10.332
And Chloe, do you have those?

00:57:10.332 --> 00:57:11.790
Or Martin, do to
have one of those?

00:57:11.790 --> 00:57:12.748
AUDIENCE: Do you have--

00:57:12.748 --> 00:57:13.630
I know I have--

00:57:13.630 --> 00:57:14.550
AUDIENCE: Which one?

00:57:14.550 --> 00:57:15.720
WILLIAM BONVILLIAN:
Bad Bugs, No Drugs,

00:57:15.720 --> 00:57:17.012
the Infectious Disease Society?

00:57:19.986 --> 00:57:21.414
AUDIENCE: I can do this one.

00:57:24.567 --> 00:57:25.970
I'm prepared for it, yeah.

00:57:25.970 --> 00:57:26.350
WILLIAM BONVILLIAN: All right.

00:57:26.350 --> 00:57:27.808
Well, Chloe, which
one do you have?

00:57:27.808 --> 00:57:28.930
You have the FDA one?

00:57:28.930 --> 00:57:30.303
Innovation, stagnation.

00:57:30.303 --> 00:57:30.970
All right, fine.

00:57:30.970 --> 00:57:33.340
OK.

00:57:33.340 --> 00:57:36.080
I mean, the title
gives this story away.

00:57:36.080 --> 00:57:38.800
And this is the Infectious
Disease Society.

00:57:38.800 --> 00:57:48.280
And they note that resistance
to bacteria, I think,

00:57:48.280 --> 00:57:51.070
as everybody in this classroom
knows is very much on the rise.

00:57:54.355 --> 00:57:56.480
And again, this report was
written a few years ago.

00:57:56.480 --> 00:57:58.150
Two million people
in US hospitals

00:57:58.150 --> 00:58:00.400
are going to get bacterial
infections in the hospital.

00:58:00.400 --> 00:58:03.600
And 90,000 of them
are going to die.

00:58:03.600 --> 00:58:09.310
That is a staggering
number, right?

00:58:09.310 --> 00:58:14.320
We lose 30,000 people a year
in automobile accidents.

00:58:14.320 --> 00:58:18.030
We're losing three times
that many in hospitals.

00:58:18.030 --> 00:58:21.280
So talk about
tolerance for risk.

00:58:21.280 --> 00:58:24.160
Americans haven't
fully woken up to this.

00:58:24.160 --> 00:58:28.420
So hospitals are increasingly
a dangerous place to be.

00:58:28.420 --> 00:58:34.120
And only two classes
of antibiotics

00:58:34.120 --> 00:58:36.460
have been developed at
the time this was written

00:58:36.460 --> 00:58:37.660
in the previous 30 years.

00:58:37.660 --> 00:58:39.550
And one of those is
already facing resistance

00:58:39.550 --> 00:58:43.150
in this kind of endless
cycle of build up

00:58:43.150 --> 00:58:48.340
of resistance that bacterial
sources go through.

00:58:48.340 --> 00:58:55.420
And by the late 1960s,
80% of staff bacteria

00:58:55.420 --> 00:58:58.030
were penicillin resistant.

00:58:58.030 --> 00:59:00.910
And in pneumonia,
40% of the infections

00:59:00.910 --> 00:59:05.920
were resistant to one drug
and 15% to the next three.

00:59:05.920 --> 00:59:09.820
So this is a serious
growing problem.

00:59:09.820 --> 00:59:15.650
Yet because of the
blockbuster drug model,

00:59:15.650 --> 00:59:18.920
there's no incentive for
drug companies or biotechs

00:59:18.920 --> 00:59:25.790
to go after these antibiotics
because they cure the problem.

00:59:28.310 --> 00:59:30.110
So you take the
antibiotic for two weeks,

00:59:30.110 --> 00:59:31.880
and the problem is solved.

00:59:31.880 --> 00:59:35.330
What you want, under the
blockbuster drug model,

00:59:35.330 --> 00:59:37.100
is something that
I'm going to have

00:59:37.100 --> 00:59:40.910
to take for the rest of my life
for $100,000 a year, right?

00:59:40.910 --> 00:59:42.320
You don't really
want to cure it.

00:59:42.320 --> 00:59:45.230
You want to create
incremental advances that

00:59:45.230 --> 00:59:46.820
manage the problem.

00:59:46.820 --> 00:59:51.260
Whereas the antibiotic
actually cures the problem.

00:59:51.260 --> 00:59:53.720
So there's very little
incentive since there's

00:59:53.720 --> 00:59:57.122
no economic return
model that works.

00:59:57.122 --> 00:59:58.580
There's very little
incentive to go

00:59:58.580 --> 01:00:01.220
after these antibiotic problems.

01:00:01.220 --> 01:00:03.260
They work too well too fast.

01:00:03.260 --> 01:00:07.040
So it's a very weak
return on investment.

01:00:07.040 --> 01:00:08.720
And successful
antibiotics are just

01:00:08.720 --> 01:00:11.690
too successful to justify
the investment cost.

01:00:11.690 --> 01:00:15.350
So everybody is aware of this.

01:00:15.350 --> 01:00:22.460
Elias Zerhouni, who preceded
Francis Collins as head of NIH,

01:00:22.460 --> 01:00:24.530
had this roadmap model.

01:00:24.530 --> 01:00:27.530
And this was certainly on that
list of cross-cutting issues

01:00:27.530 --> 01:00:29.570
that need to be dealt with.

01:00:29.570 --> 01:00:31.310
But how do you get
around the kind

01:00:31.310 --> 01:00:35.690
of model here, the economic,
problematic blockbuster drug

01:00:35.690 --> 01:00:36.380
model here?

01:00:36.380 --> 01:00:41.780
So I mean there've been a
variety of ideas advanced.

01:00:41.780 --> 01:00:46.190
There was bioshield legislation
to deal with biothreats.

01:00:46.190 --> 01:00:49.610
But it could also bear
on infectious diseases.

01:00:49.610 --> 01:00:53.140
The idea there was,
for a biothreat,

01:00:53.140 --> 01:00:56.790
why would anybody develop
a biothreat remedy?

01:00:56.790 --> 01:01:00.940
Because the drug
would only be sold

01:01:00.940 --> 01:01:03.370
if there was a
completely unpredictable

01:01:03.370 --> 01:01:05.642
terrible national disaster.

01:01:05.642 --> 01:01:07.850
So are you going to take
all the risks and go through

01:01:07.850 --> 01:01:12.110
the $1.4-billion clinical trial
process to develop a remedy

01:01:12.110 --> 01:01:14.720
for something that may
well never be used?

01:01:14.720 --> 01:01:19.370
A similar kind of problem
for antibiotic drugs.

01:01:19.370 --> 01:01:24.272
So the Infectious Disease
Society said, wait a minute.

01:01:24.272 --> 01:01:26.480
The same model that would
deal with biothreats, which

01:01:26.480 --> 01:01:28.130
is that the
government would agree

01:01:28.130 --> 01:01:32.280
to buy a certain
number of dosages,

01:01:32.280 --> 01:01:36.440
a certain volume of
the remedy, at a set

01:01:36.440 --> 01:01:39.752
price if you
developed the remedy.

01:01:39.752 --> 01:01:41.460
So the risk on the
part of the government

01:01:41.460 --> 01:01:42.418
is actually pretty low.

01:01:42.418 --> 01:01:45.660
It only has to buy something
if you solve the problem.

01:01:45.660 --> 01:01:47.820
But then of course, that's
what biotechs do anyway.

01:01:47.820 --> 01:01:50.650
That's the economic
model they work off of.

01:01:50.650 --> 01:01:52.710
So could the government
intervene in this sector

01:01:52.710 --> 01:01:56.820
and, in effect, really change
around the risk-reward model.

01:01:56.820 --> 01:01:59.953
So ideas like this
come to bear here.

01:01:59.953 --> 01:02:01.620
We certainly haven't
solved this problem

01:02:01.620 --> 01:02:04.170
and remains very much
with us but illustrates

01:02:04.170 --> 01:02:06.030
what the issues are.

01:02:06.030 --> 01:02:09.000
This other report from the
FDA, Innovation/Stagnation--

01:02:09.000 --> 01:02:10.980
Challenge and Opportunity
on the Critical Path

01:02:10.980 --> 01:02:14.220
to New Medical Products.

01:02:14.220 --> 01:02:16.980
And both these reports, by
the way, have been updated.

01:02:16.980 --> 01:02:19.320
I put the originals in, which
are fairly hard-hitting.

01:02:19.320 --> 01:02:22.840
But they've been updated since
then by these organizations

01:02:22.840 --> 01:02:24.090
so you can get later versions.

01:02:27.740 --> 01:02:31.880
FDA does not have its own
substantial research arm.

01:02:31.880 --> 01:02:35.430
NIH does the medical research.

01:02:35.430 --> 01:02:43.040
Yet we're not doing
research on how

01:02:43.040 --> 01:02:50.240
to get a better, more reliable,
and certainly speedier

01:02:50.240 --> 01:02:53.360
evaluation and approval
process for FDA.

01:02:53.360 --> 01:02:54.860
We don't have that.

01:02:54.860 --> 01:02:56.900
There's nobody on that problem.

01:02:56.900 --> 01:02:58.958
NIH does not view
that is their problem.

01:02:58.958 --> 01:03:00.500
They view their
problem as developing

01:03:00.500 --> 01:03:05.780
new drugs, new therapies, not
figuring out a safety approval

01:03:05.780 --> 01:03:07.230
set of problems.

01:03:07.230 --> 01:03:09.500
So nobody's really
on that problem

01:03:09.500 --> 01:03:14.150
except for FDA's own fairly
modest research budget.

01:03:14.150 --> 01:03:17.060
So the picture that
this report portrays

01:03:17.060 --> 01:03:22.520
is ongoing breakthrough
scientific discoveries

01:03:22.520 --> 01:03:27.590
that get nailed because the
drug approval process isn't

01:03:27.590 --> 01:03:30.350
receiving new science
and new technology

01:03:30.350 --> 01:03:33.088
advances that would
enable it to keep up

01:03:33.088 --> 01:03:34.130
with these breakthroughs.

01:03:34.130 --> 01:03:36.020
And we mentioned this earlier.

01:03:36.020 --> 01:03:40.310
But the most serious one that's
ahead is in precision medicine

01:03:40.310 --> 01:03:44.510
and personalized medicine
where it's developing a therapy

01:03:44.510 --> 01:03:48.530
or a remedy that's uniquely
appropriate for you

01:03:48.530 --> 01:03:53.060
as opposed to me, a
personalized medicine approach.

01:03:53.060 --> 01:03:55.520
How are we going to do the
approval process for that?

01:03:55.520 --> 01:03:58.430
How is FDA is going
to manage that?

01:03:58.430 --> 01:04:06.850
So it is a dilemma
here in the system.

01:04:06.850 --> 01:04:11.330
And again, it's an innovation
organization problem.

01:04:11.330 --> 01:04:13.160
We've got an
innovation organization

01:04:13.160 --> 01:04:15.110
that's focused on one
set of the problems.

01:04:15.110 --> 01:04:18.050
And they've got the
resources do the R&D on it.

01:04:18.050 --> 01:04:20.060
And yet we've got a
parallel big problem that's

01:04:20.060 --> 01:04:22.060
jeopardizing the other system.

01:04:22.060 --> 01:04:24.110
And we don't have the
organizational capability

01:04:24.110 --> 01:04:25.400
of acting on it.

01:04:25.400 --> 01:04:27.560
So then this is yet
another innovation

01:04:27.560 --> 01:04:29.030
organizational
problem that, when

01:04:29.030 --> 01:04:31.310
you think about these
things as systems,

01:04:31.310 --> 01:04:33.230
you begin to identify
what the gaps are.

01:04:33.230 --> 01:04:35.243
And here is one.

01:04:35.243 --> 01:04:36.785
That's probably
enough on this topic.

01:04:39.350 --> 01:04:43.830
So why don't we go right
into some Q&A on this.

01:04:43.830 --> 01:04:46.243
Martine, you want to lead
us on Bad Bugs, No Drugs?

01:04:46.243 --> 01:04:46.868
AUDIENCE: Yeah.

01:04:51.850 --> 01:04:53.560
So I guess the
main theme of this

01:04:53.560 --> 01:04:56.470
is their way of using policy
or subsidies to incentivize

01:04:56.470 --> 01:04:59.445
the private sector to
take on this problem.

01:04:59.445 --> 01:05:01.570
Or even is the private
sector even the right entity

01:05:01.570 --> 01:05:02.640
to handle this problem?

01:05:09.990 --> 01:05:12.620
AUDIENCE: I feel like
a little suggestion

01:05:12.620 --> 01:05:15.200
of having government
guarantee to pay

01:05:15.200 --> 01:05:17.630
for a certain amount
of dosages seems

01:05:17.630 --> 01:05:20.260
like a pretty good fix for it.

01:05:20.260 --> 01:05:24.275
If you leave the free market
alone, these companies,

01:05:24.275 --> 01:05:25.900
they currently don't
have an incentive.

01:05:25.900 --> 01:05:30.310
So I don't think that's
really an option.

01:05:30.310 --> 01:05:32.930
AUDIENCE: A professor of
mine, an economics professor

01:05:32.930 --> 01:05:36.830
at Wellesley and Cornell is
very supportive of patent

01:05:36.830 --> 01:05:39.450
extensions, which is something
that was cited in the report.

01:05:39.450 --> 01:05:41.690
And she felt like, at
least in my understanding,

01:05:41.690 --> 01:05:43.610
that would very much
motivate bio and pharma

01:05:43.610 --> 01:05:45.780
companies to do
research primarily

01:05:45.780 --> 01:05:47.780
because they're concerned
that their patents are

01:05:47.780 --> 01:05:50.660
going to run out in the
lifecycle of the innovation

01:05:50.660 --> 01:05:51.720
process.

01:05:51.720 --> 01:05:54.242
WILLIAM BONVILLIAN: And explain
how that would work, Steph?

01:05:54.242 --> 01:05:56.700
AUDIENCE: Oh, man, I don't know
that I could do it justice.

01:05:56.700 --> 01:05:58.970
WILLIAM BONVILLIAN:
Just briefly.

01:05:58.970 --> 01:06:00.150
Give us a snapshot.

01:06:00.150 --> 01:06:00.650
Or Chris.

01:06:00.650 --> 01:06:02.960
AUDIENCE: So I think,
my understanding

01:06:02.960 --> 01:06:05.820
of the patent-extension
process is that,

01:06:05.820 --> 01:06:10.160
especially for orphan drugs
where it's like under like

01:06:10.160 --> 01:06:12.560
10,000 people or
something like that--

01:06:12.560 --> 01:06:16.880
so a smaller market size
or it's targeting children

01:06:16.880 --> 01:06:19.280
like adolescents, you
get patent extensions.

01:06:19.280 --> 01:06:21.440
And that could be three
to five years extra,

01:06:21.440 --> 01:06:26.810
which is pretty significant
in terms of drug companies.

01:06:26.810 --> 01:06:30.020
And yeah, I think those
are the main ones.

01:06:30.020 --> 01:06:33.560
And there's also breakthrough
therapy designations.

01:06:33.560 --> 01:06:36.740
And those not only help speed
up the approval process, which

01:06:36.740 --> 01:06:39.050
is really valuable for these
companies that really want

01:06:39.050 --> 01:06:41.600
to push through these
drugs really quickly

01:06:41.600 --> 01:06:43.400
and get it to market.

01:06:43.400 --> 01:06:47.280
And then they also extend a
little bit in certain cases.

01:06:47.280 --> 01:06:49.940
So there's a lot of
different small ways

01:06:49.940 --> 01:06:52.230
FDA is trying to
get more incentive,

01:06:52.230 --> 01:06:54.050
which is nice to see.

01:06:54.050 --> 01:06:55.500
I think it's a good policy.

01:06:55.500 --> 01:06:58.510
AUDIENCE: And to add
a lower-order analysis

01:06:58.510 --> 01:07:02.106
from microeconomics,
I think the way

01:07:02.106 --> 01:07:04.790
that she explained it was
essentially-- and all of you

01:07:04.790 --> 01:07:05.510
may know this.

01:07:05.510 --> 01:07:07.400
I did not know this
until two years ago.

01:07:07.400 --> 01:07:09.600
So maybe this is
new to someone--

01:07:09.600 --> 01:07:13.023
is that researchers,
I mean, from the time

01:07:13.023 --> 01:07:14.690
that they apply for
a patent, they have,

01:07:14.690 --> 01:07:16.590
what is it, 15, 17
years or something

01:07:16.590 --> 01:07:18.090
like that to
commercialization where

01:07:18.090 --> 01:07:19.230
their patent is protected.

01:07:19.230 --> 01:07:19.970
AUDIENCE: I thought it was 20.

01:07:19.970 --> 01:07:20.450
AUDIENCE: 20?

01:07:20.450 --> 01:07:21.170
AUDIENCE: It changed.

01:07:21.170 --> 01:07:22.545
WILLIAM BONVILLIAN:
Yeah, it did.

01:07:22.545 --> 01:07:25.520
[INAUDIBLE] is now 20 from 17.

01:07:25.520 --> 01:07:26.900
AUDIENCE: So it used to be 17.

01:07:26.900 --> 01:07:28.490
And now, it is 20.

01:07:28.490 --> 01:07:30.410
And so the way that
she explained it to us

01:07:30.410 --> 01:07:35.390
is that, because a lot of
the research-and-development

01:07:35.390 --> 01:07:38.090
process could take
20 years by the time

01:07:38.090 --> 01:07:39.972
they get a drug to
market, they may

01:07:39.972 --> 01:07:41.180
have already lost the patent.

01:07:41.180 --> 01:07:45.320
So it no longer becomes
economically advantageous

01:07:45.320 --> 01:07:47.270
for the company to
pursue commercialization

01:07:47.270 --> 01:07:50.450
of a particular therapy, and
thus what Chris was saying.

01:07:50.450 --> 01:07:54.140
So that's just sort of
the small connections.

01:07:54.140 --> 01:07:58.030
AUDIENCE: Separate concerns
sort of from like a scientific

01:07:58.030 --> 01:07:59.910
or a biological perspective.

01:07:59.910 --> 01:08:03.860
So I wonder if, is it that
these drugs are super effective

01:08:03.860 --> 01:08:05.690
or antibiotics are
the best mechanism

01:08:05.690 --> 01:08:07.315
to get rid of these
bacteria in the way

01:08:07.315 --> 01:08:09.740
that we traditionally
think about them to say

01:08:09.740 --> 01:08:14.990
that one is the way that
we think about bacteria?

01:08:14.990 --> 01:08:16.993
Is that the actual
most effective means?

01:08:16.993 --> 01:08:18.410
Or is that actually
how they work?

01:08:18.410 --> 01:08:20.090
Or do we not
understand the pathways

01:08:20.090 --> 01:08:21.640
of how they're
actually becoming more

01:08:21.640 --> 01:08:24.319
resistant to these technologies?

01:08:24.319 --> 01:08:30.200
So my question, is there just
like a group think in a way

01:08:30.200 --> 01:08:34.550
that we think about antibiotics
and bacterial theory

01:08:34.550 --> 01:08:39.560
in biology or in medicine.

01:08:39.560 --> 01:08:41.750
We're just kind of following
along the same path.

01:08:41.750 --> 01:08:44.600
So I would love to talk
to a bacteriologist.

01:08:44.600 --> 01:08:48.770
And then 2, is this problem
one that we will ever solve?

01:08:48.770 --> 01:08:50.510
Or will it just get
exponentially worse?

01:08:50.510 --> 01:08:52.218
Because I can imagine,
even if we come up

01:08:52.218 --> 01:08:54.500
with a faster and
faster mechanism

01:08:54.500 --> 01:08:56.990
to get out these antibiotics
and reach more people,

01:08:56.990 --> 01:08:59.840
will these bacteria just
kind of keep growing

01:08:59.840 --> 01:09:01.220
and get faster
and more resistant

01:09:01.220 --> 01:09:03.710
and we'll always
have this problem?

01:09:03.710 --> 01:09:05.479
And then thirdly,
does that mean that we

01:09:05.479 --> 01:09:12.680
should have an established
kind of entity within the FDA

01:09:12.680 --> 01:09:16.640
that just deals with
antibiotics if they deem it

01:09:16.640 --> 01:09:19.680
as a serious enough problem and
it's going to be persistent?

01:09:19.680 --> 01:09:24.420
AUDIENCE: [INAUDIBLE]

01:09:24.420 --> 01:09:26.441
AUDIENCE: Yeah, I can
try to speak to that.

01:09:26.441 --> 01:09:28.149
AUDIENCE: The question
I was going to ask

01:09:28.149 --> 01:09:29.877
is you can about
this theoretically.

01:09:29.877 --> 01:09:32.210
But I was going to ask, so
if you had to start a company

01:09:32.210 --> 01:09:34.521
right and you're relatively
young in your career

01:09:34.521 --> 01:09:36.229
and this might be a
career-ender in terms

01:09:36.229 --> 01:09:39.140
of if there's no success, what
incentives would incentivize

01:09:39.140 --> 01:09:43.060
you to start a company or solve
this problem or an organization

01:09:43.060 --> 01:09:44.540
to work on this exactly?

01:09:44.540 --> 01:09:47.359
AUDIENCE: Presuming you have
the equipment and resources.

01:09:47.359 --> 01:09:51.470
AUDIENCE: So antibiotics are
pretty difficult, first of all,

01:09:51.470 --> 01:09:55.848
because they're becoming too
effective for their own good.

01:09:55.848 --> 01:09:57.890
I think it was Pfizer or
one of the big companies

01:09:57.890 --> 01:10:01.680
produce a very famous
kind of antibiotic drug.

01:10:01.680 --> 01:10:06.080
And now, it's just so effective
that they've kind of become

01:10:06.080 --> 01:10:07.760
a victim of their own success.

01:10:07.760 --> 01:10:11.120
And also, it's also really
hard to pass antibiotic drugs

01:10:11.120 --> 01:10:14.330
through clinical trials,
disproportionately so

01:10:14.330 --> 01:10:15.750
compared to other diseases.

01:10:15.750 --> 01:10:19.310
So that's also kind of
like a barrier to entry.

01:10:19.310 --> 01:10:24.470
I think, honestly, if I were
to want to get into this field,

01:10:24.470 --> 01:10:27.080
you have to come up
with a new approach,

01:10:27.080 --> 01:10:29.650
something better than
is being done right now.

01:10:29.650 --> 01:10:35.440
Because I think antibiotics
it's a very broad field.

01:10:35.440 --> 01:10:37.270
There's so many
different strains.

01:10:37.270 --> 01:10:39.400
And if they mutate
a bit your drug

01:10:39.400 --> 01:10:41.680
can be already
rendered ineffective.

01:10:41.680 --> 01:10:45.500
So it's just one of those
fields that is always evolving.

01:10:45.500 --> 01:10:47.875
So not only do you have to
have very strong basic science

01:10:47.875 --> 01:10:51.280
to keep up with what's
happening with these bacteria,

01:10:51.280 --> 01:10:55.090
how are they like mutating, and
how are they kind of evolving,

01:10:55.090 --> 01:10:58.000
and then you have to come up
with drugs to help target them.

01:10:58.000 --> 01:11:00.340
So it's like a very
twofold problem

01:11:00.340 --> 01:11:03.280
that you need to
simultaneously target.

01:11:03.280 --> 01:11:05.290
And then obviously,
they're evolving

01:11:05.290 --> 01:11:09.250
so rapidly that you have to
kind of pivot very quickly.

01:11:09.250 --> 01:11:13.320
So I think it's one of those
fast-changing fields that

01:11:13.320 --> 01:11:14.830
is kind of hard to target.

01:11:14.830 --> 01:11:16.540
But definitely important.

01:11:16.540 --> 01:11:18.670
I'm not really sure
what mechanisms

01:11:18.670 --> 01:11:22.120
they have in place
or organization-wise

01:11:22.120 --> 01:11:24.430
to kind of target
this specifically.

01:11:24.430 --> 01:11:27.020
But I think it definitely
should be a focus.

01:11:27.020 --> 01:11:32.110
AUDIENCE: You talked about
your pipeline getting approved.

01:11:32.110 --> 01:11:34.310
What if they could speed
that up very quickly

01:11:34.310 --> 01:11:35.890
so it's a priority?

01:11:35.890 --> 01:11:37.930
AUDIENCE: I mean,
speeding it up would help.

01:11:37.930 --> 01:11:43.020
But also, it's just hard to
produce a good clinical trial

01:11:43.020 --> 01:11:44.065
for these drugs.

01:11:44.065 --> 01:11:45.940
So I think that's also
a fundamental problem.

01:11:45.940 --> 01:11:47.410
It's just like
psychiatric drugs.

01:11:47.410 --> 01:11:51.160
Those are very notoriously
hard to prove because placebo

01:11:51.160 --> 01:11:53.655
effect is really a big problem.

01:11:53.655 --> 01:11:55.030
WILLIAM BONVILLIAN:
So that leads

01:11:55.030 --> 01:11:58.660
us right into our
next reading, which

01:11:58.660 --> 01:12:03.100
is this FDA problem and the fact
that we haven't put resources

01:12:03.100 --> 01:12:05.800
on the drug approval process.

01:12:05.800 --> 01:12:08.670
So Chloe, it's yours.

01:12:08.670 --> 01:12:11.880
AUDIENCE: So if
we're starting off

01:12:11.880 --> 01:12:15.730
with tackling that problem
of how do we sort of reform

01:12:15.730 --> 01:12:19.900
and revamp the way in which
we evaluate these products,

01:12:19.900 --> 01:12:23.470
one question for
you guys would be--

01:12:23.470 --> 01:12:25.570
so the meeting
mentioned that one

01:12:25.570 --> 01:12:27.760
of the things you could
attribute this mismatch

01:12:27.760 --> 01:12:32.710
was a mismatch between the
levels of how far both research

01:12:32.710 --> 01:12:35.440
in basic science and applied
science, where they put that.

01:12:35.440 --> 01:12:37.240
They're very mismatched
in terms of one

01:12:37.240 --> 01:12:39.760
of them is just shot ahead and
the other can't even keep up.

01:12:39.760 --> 01:12:46.173
So what are your thoughts on how
or if an agency such as the FDA

01:12:46.173 --> 01:12:47.590
should be responsible
for ensuring

01:12:47.590 --> 01:12:50.440
the development of these
sciences are evenly matched?

01:12:50.440 --> 01:12:53.560
For example, should
the agency bottleneck

01:12:53.560 --> 01:12:56.418
the funding for basic sciences
until applied sciences

01:12:56.418 --> 01:12:56.960
and catch up?

01:12:56.960 --> 01:12:59.620
Or should they aggressively
stimulate opportunities

01:12:59.620 --> 01:13:01.690
on other side?

01:13:01.690 --> 01:13:03.730
AUDIENCE: I suppose
in an ideal scenario

01:13:03.730 --> 01:13:08.200
you just stimulate that's more
funding to research drugs.

01:13:08.200 --> 01:13:11.620
But I understand that there
isn't always money for that.

01:13:11.620 --> 01:13:14.038
AUDIENCE: I forget--
but to that point,

01:13:14.038 --> 01:13:15.080
there is another reading.

01:13:15.080 --> 01:13:16.538
I forget if it was
this one or not.

01:13:16.538 --> 01:13:20.110
But it said, just throwing money
and giving infinite budgets

01:13:20.110 --> 01:13:25.030
isn't always the solution
because, in that case,

01:13:25.030 --> 01:13:27.490
it takes away the
element of good planning

01:13:27.490 --> 01:13:29.138
and strategic planning.

01:13:29.138 --> 01:13:31.430
WILLIAM BONVILLIAN: The end
of innovation organization.

01:13:31.430 --> 01:13:33.347
If you don't have the
innovation organization,

01:13:33.347 --> 01:13:36.742
that's going to enable you to
avoid big gaps in the system.

01:13:36.742 --> 01:13:38.200
You're just not
going to get there.

01:13:38.200 --> 01:13:41.440
So throwing money at a problem
without tackling the innovation

01:13:41.440 --> 01:13:46.280
organization problems
is problematic.

01:13:46.280 --> 01:13:47.572
AUDIENCE: Ideally, yes.

01:13:47.572 --> 01:13:48.530
Money in, money would--

01:13:48.530 --> 01:13:50.720
AUDIENCE: Yeah, assuming that
you can use the money properly.

01:13:50.720 --> 01:13:51.220
Yeah.

01:13:55.675 --> 01:13:57.550
AUDIENCE: One thing that
I was curious about.

01:13:57.550 --> 01:14:00.160
I was confused how
antibiotics can simultaneously

01:14:00.160 --> 01:14:02.620
be working too well
and you can have

01:14:02.620 --> 01:14:05.350
tons of antibiotic-resistant
bacteria, which

01:14:05.350 --> 01:14:08.230
implies that antibiotics
are not working too well.

01:14:08.230 --> 01:14:12.103
So if someone could clarify
that, I would appreciate that.

01:14:12.103 --> 01:14:13.770
WILLIAM BONVILLIAN:
That's yours, Chris.

01:14:13.770 --> 01:14:18.750
AUDIENCE: So I think the problem
is that, say, Pfizer's drug is

01:14:18.750 --> 01:14:19.660
doing really well.

01:14:19.660 --> 01:14:24.330
So they give these
antibiotics to their patients.

01:14:24.330 --> 01:14:26.200
And these patients
are getting cured.

01:14:26.200 --> 01:14:28.893
And so that means, if
they're getting cured

01:14:28.893 --> 01:14:30.810
and they're not really
getting these diseases,

01:14:30.810 --> 01:14:32.790
that means that
drug is not going

01:14:32.790 --> 01:14:34.620
to be really used as much.

01:14:34.620 --> 01:14:37.650
And then at the same time,
because these patients

01:14:37.650 --> 01:14:41.580
have used the drug, there is
antibiotic resistance growing.

01:14:41.580 --> 01:14:44.580
And just because it's
been around for so long,

01:14:44.580 --> 01:14:47.752
it's inevitable
that resistance is

01:14:47.752 --> 01:14:49.710
going to build up to the
point that the drug is

01:14:49.710 --> 01:14:50.970
no longer effective.

01:14:50.970 --> 01:14:55.177
Because it's been
out for 10, 15 years.

01:14:55.177 --> 01:14:56.760
AUDIENCE: But that
resistance can only

01:14:56.760 --> 01:14:59.050
develop if lots of people
are using the drug--

01:14:59.050 --> 01:15:01.467
AUDIENCE: I mean, obviously,
a lot of people have used it.

01:15:01.467 --> 01:15:04.080
And it is, obviously, a
critical mass have used it.

01:15:04.080 --> 01:15:05.050
It's been successful.

01:15:07.620 --> 01:15:09.090
It's a really effective drug.

01:15:09.090 --> 01:15:14.550
So maybe there's not
repeat people in the way

01:15:14.550 --> 01:15:16.930
that other drugs might
have a lot of repeat users.

01:15:16.930 --> 01:15:19.560
Maybe it's treating
a large population,

01:15:19.560 --> 01:15:22.350
but people don't really
get the same kind

01:15:22.350 --> 01:15:25.500
of strain of disease multiple
times, something like that.

01:15:25.500 --> 01:15:27.583
WILLIAM BONVILLIAN: And
Chris, part of the problem

01:15:27.583 --> 01:15:29.160
is that we overprescribe
antibiotics

01:15:29.160 --> 01:15:30.720
to an absurd extent.

01:15:30.720 --> 01:15:33.990
And we're sticking antibiotics
in everything like hand soap.

01:15:33.990 --> 01:15:39.600
And we're virtually guaranteeing
our own Darwinian dilemma.

01:15:39.600 --> 01:15:41.080
AUDIENCE: It seems
to be applying

01:15:41.080 --> 01:15:44.620
the language of this class
in previous lectures.

01:15:44.620 --> 01:15:48.280
We're playing catch-up with
an innovation problem instead

01:15:48.280 --> 01:15:50.350
of purely innovating,
which doesn't

01:15:50.350 --> 01:15:54.520
seem like a very American
way to tackle this problem.

01:15:54.520 --> 01:15:56.230
It's kind of odd
because it's almost

01:15:56.230 --> 01:15:58.540
like we're being outplayed
by nature, which, I mean,

01:15:58.540 --> 01:16:01.767
most of our big successes
over the last 200 or 300 years

01:16:01.767 --> 01:16:03.850
have been us figuring out
how to manipulate nature

01:16:03.850 --> 01:16:04.730
to our advantage.

01:16:04.730 --> 01:16:07.666
So it's kind of an
interesting [INAUDIBLE]..

01:16:07.666 --> 01:16:09.781
AUDIENCE: I left my
American flag at home.

01:16:12.402 --> 01:16:14.110
AUDIENCE: If that's
all we have for that,

01:16:14.110 --> 01:16:18.760
I do have one more question
for the FDA reading,

01:16:18.760 --> 01:16:21.590
more on the standard setting
sorts of things things.

01:16:21.590 --> 01:16:24.220
What do you guys think,
again, are the roles

01:16:24.220 --> 01:16:28.180
and responsibilities
of such an agency that

01:16:28.180 --> 01:16:30.820
sets these standards
to encourage people

01:16:30.820 --> 01:16:33.770
to take risks and
bring the slightly

01:16:33.770 --> 01:16:35.128
riskier drugs to market?

01:16:35.128 --> 01:16:37.420
Because the reading mentioned
that a lot of researchers

01:16:37.420 --> 01:16:39.503
won't even go down that
path because they know how

01:16:39.503 --> 01:16:43.730
arduous and tough [INAUDIBLE].

01:16:43.730 --> 01:16:45.878
So is there something
the FDA could do to--

01:16:45.878 --> 01:16:47.920
AUDIENCE: I like what Bill
said in terms of like,

01:16:47.920 --> 01:16:49.700
OK, it's a very hard process.

01:16:49.700 --> 01:16:51.325
But once you do it,
you're kind of set.

01:16:51.325 --> 01:16:53.858
The only thing I would
question is I would tier it.

01:16:53.858 --> 01:16:55.900
Because there's probably
different kinds of drugs

01:16:55.900 --> 01:16:57.233
that have different specialties.

01:16:57.233 --> 01:16:58.930
And they're probably
something that--

01:16:58.930 --> 01:17:00.347
there's pretty
drugs that I really

01:17:00.347 --> 01:17:01.980
want to get tested
really, really well.

01:17:01.980 --> 01:17:03.910
Or there's some that,
even if I do test them,

01:17:03.910 --> 01:17:07.330
I still don't know and some
drugs that can probably get

01:17:07.330 --> 01:17:08.860
passed faster.

01:17:08.860 --> 01:17:11.560
So I would figure out like
how does this scheme work.

01:17:11.560 --> 01:17:14.908
Look at the data in terms of how
are these drugs being passed,

01:17:14.908 --> 01:17:17.200
how long does it take, which
ones were relatively quick

01:17:17.200 --> 01:17:20.110
and see if I could restructure
the organization so that I

01:17:20.110 --> 01:17:22.920
can optimize for the
stuff that really matters

01:17:22.920 --> 01:17:25.570
and the stuff that doesn't
really matter as much,

01:17:25.570 --> 01:17:27.060
it's not a focus.

01:17:27.060 --> 01:17:30.580
So we're having a linear kind
of everything is the same.

01:17:30.580 --> 01:17:33.880
AUDIENCE: So are you saying
maybe make the funding

01:17:33.880 --> 01:17:37.090
or whatever a function of, say,
quality and the amount of time

01:17:37.090 --> 01:17:40.240
it would take to get passed so
then, if you need a drug that

01:17:40.240 --> 01:17:43.840
maybe would only work for a
few people, you can make it

01:17:43.840 --> 01:17:45.340
so it would be
really high quality.

01:17:45.340 --> 01:17:46.250
Whereas if you have
a drug that needs

01:17:46.250 --> 01:17:49.180
to work for a lot of people
that you need really quickly,

01:17:49.180 --> 01:17:52.420
then you can make
it so that it's

01:17:52.420 --> 01:17:54.440
less robust or for fewer
restraints, et cetera,

01:17:54.440 --> 01:17:55.690
embracing something like that?

01:17:55.690 --> 01:17:57.732
AUDIENCE: Yeah,
something like that.

01:17:57.732 --> 01:17:59.690
Because you also think
about compound interest.

01:17:59.690 --> 01:18:01.357
So say I know that,
if I make this drug,

01:18:01.357 --> 01:18:03.960
I'm going to save the government
like $50 million a year

01:18:03.960 --> 01:18:07.828
or $80 million a year
over four or five years.

01:18:07.828 --> 01:18:10.120
So if it's something that's
going to make a big impact,

01:18:10.120 --> 01:18:12.550
how about we go faster
and we can iterate faster?

01:18:12.550 --> 01:18:15.030
So we have priorities for drugs
that really, really matter.

01:18:15.030 --> 01:18:17.530
I don't like the argument of
saying, oh, not a lot of people

01:18:17.530 --> 01:18:20.020
are going to use it so we're
not going to prioritize it.

01:18:20.020 --> 01:18:21.980
And let's put it in the back
because it's kind of false.

01:18:21.980 --> 01:18:24.147
Or maybe you should create
another organization that

01:18:24.147 --> 01:18:26.050
only focuses on
those kinds of drugs

01:18:26.050 --> 01:18:28.360
and split up the FDA
into one that focuses on

01:18:28.360 --> 01:18:31.010
that so it gets equal review.

01:18:31.010 --> 01:18:33.760
But that's kind of
a same wavelength.

01:18:33.760 --> 01:18:36.220
WILLIAM BONVILLIAN: So
just to kind of summarize

01:18:36.220 --> 01:18:40.870
here from your all good
presentations and good

01:18:40.870 --> 01:18:46.620
questions, the FDA is sitting
on a really critical part

01:18:46.620 --> 01:18:47.440
of the problem.

01:18:47.440 --> 01:18:52.200
So if we could significantly
speed the drug approval process

01:18:52.200 --> 01:18:54.990
and if we could
significantly lower its cost,

01:18:54.990 --> 01:18:58.300
we solve a lot of problems here.

01:18:58.300 --> 01:19:01.680
We can be much less reliant
on a blockbuster drug model.

01:19:01.680 --> 01:19:05.340
So it seems to me that, in
terms of the panoply of fixes

01:19:05.340 --> 01:19:08.850
to this gap in the
innovation system,

01:19:08.850 --> 01:19:12.020
really paying attention
to how to accelerate--

01:19:12.020 --> 01:19:14.070
Martine, as you
were pointing out--

01:19:14.070 --> 01:19:16.140
the review process at FDA.

01:19:16.140 --> 01:19:23.090
And it's very hard to
reduce safety requirements.

01:19:23.090 --> 01:19:25.540
It's just not going to be
acceptable to the public.

01:19:25.540 --> 01:19:30.100
But if there are new ways of
using big data and analytics

01:19:30.100 --> 01:19:34.720
and simulation and
modeling, those potentially

01:19:34.720 --> 01:19:38.680
present very significant
improvements to this process

01:19:38.680 --> 01:19:40.930
here that could really
help tackle this problem.

01:19:40.930 --> 01:19:43.870
So putting some money
on that one I think

01:19:43.870 --> 01:19:45.770
could be really key.

01:19:45.770 --> 01:19:48.490
Then we go back
to NIH, NIH is not

01:19:48.490 --> 01:19:51.870
organized around those kinds
of technology problems.

01:19:51.870 --> 01:19:53.233
So how are we going to do this?

01:19:53.233 --> 01:19:54.650
So we have another
dilemma as soon

01:19:54.650 --> 01:19:57.025
as we arrive at the answer.

01:19:57.025 --> 01:19:57.995
Anything else?

01:20:02.640 --> 01:20:05.360
AUDIENCE: I mean, just as we
transition into Bill's reading

01:20:05.360 --> 01:20:10.580
about this being a legacy sector
or exhibiting a lot of legacy

01:20:10.580 --> 01:20:15.290
features, I'm curious about
what you, Bill, or the class

01:20:15.290 --> 01:20:19.290
thought about the
political viability of,

01:20:19.290 --> 01:20:21.440
I guess, in terms of
Martine's proposal

01:20:21.440 --> 01:20:22.760
toward a tiered approach.

01:20:22.760 --> 01:20:26.090
If we thought it was more
politically viable to do this

01:20:26.090 --> 01:20:31.700
for either therapeutic drugs
or for cure-all interventions,

01:20:31.700 --> 01:20:36.440
there seems, in my very limited
study of the life sciences,

01:20:36.440 --> 01:20:41.000
to be a proclivity towards
the therapeutic drugs

01:20:41.000 --> 01:20:42.590
and interventions
because they're more

01:20:42.590 --> 01:20:44.870
sustainable and profitable.

01:20:44.870 --> 01:20:48.950
So do we think that that
could be a potential market

01:20:48.950 --> 01:20:51.230
opportunity to test
a DARPA-like system

01:20:51.230 --> 01:20:57.980
or to test the sort of
improved speed of acceptance

01:20:57.980 --> 01:20:58.790
of the drug?

01:20:58.790 --> 01:21:02.163
WILLIAM BONVILLIAN: Let me throw
that back to the group here.

01:21:02.163 --> 01:21:03.330
AUDIENCE: I like the point--

01:21:03.330 --> 01:21:06.710
I forgot when we mentioned it
about how drugs were too low.

01:21:06.710 --> 01:21:08.810
So they want to have
recurring revenue.

01:21:08.810 --> 01:21:11.390
But I think, as the
government, you get a lot of,

01:21:11.390 --> 01:21:12.440
you have to pay that.

01:21:12.440 --> 01:21:13.730
So it would be interesting
if the government

01:21:13.730 --> 01:21:15.740
is like, OK, well, we
know, over the lifetime,

01:21:15.740 --> 01:21:17.323
if we don't solve
this now, it's going

01:21:17.323 --> 01:21:20.130
to cost us one million
dollars for this person.

01:21:20.130 --> 01:21:22.420
So you solve it
today, we're going

01:21:22.420 --> 01:21:25.190
to give you $20k, which
is way cheaper for us

01:21:25.190 --> 01:21:26.480
overall in the long term.

01:21:26.480 --> 01:21:30.360
But you're not getting paid
$10 per drug or $100 per drug.

01:21:30.360 --> 01:21:32.720
And so it's kind of a
win-win because it's really

01:21:32.720 --> 01:21:34.250
good revenue for
the company and it

01:21:34.250 --> 01:21:37.760
justifies having a super drug
that really, really works.

01:21:37.760 --> 01:21:40.350
And it gives them enough
money on their balance sheet.

01:21:40.350 --> 01:21:42.200
I don't know if you guys know
how Warren Buffett got rich.

01:21:42.200 --> 01:21:43.610
But he got an insurance company.

01:21:43.610 --> 01:21:45.443
And they give him a lot
of cash so that they

01:21:45.443 --> 01:21:46.808
can invest in other companies.

01:21:46.808 --> 01:21:49.100
And it's really good for
companies having a lot of cash

01:21:49.100 --> 01:21:51.290
on hand.

01:21:51.290 --> 01:21:52.680
AUDIENCE: Who'd have thought?

01:21:52.680 --> 01:21:54.680
AUDIENCE: Well, no, it's
just like a lot of them

01:21:54.680 --> 01:21:57.840
don't have a lot of cash
on hand at any given time.

01:21:57.840 --> 01:22:00.800
So they have their assets
distributed between physical.

01:22:00.800 --> 01:22:03.380
And so it's really good to be
able to move quickly and buy

01:22:03.380 --> 01:22:04.160
all this stuff.

01:22:04.160 --> 01:22:06.770
And it's just not a thing
that happens that easily.

01:22:06.770 --> 01:22:08.870
There's also a lot
of tax benefits.

01:22:08.870 --> 01:22:11.190
That's why people do it.