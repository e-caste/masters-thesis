WEBVTT

00:00:01.640 --> 00:00:04.040
The following content is
provided under a Creative

00:00:04.040 --> 00:00:05.580
Commons license.

00:00:05.580 --> 00:00:07.880
Your support will help
MIT OpenCourseWare

00:00:07.880 --> 00:00:12.270
continue to offer high-quality
educational resources for free.

00:00:12.270 --> 00:00:14.870
To make a donation or
view additional materials

00:00:14.870 --> 00:00:18.830
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:18.830 --> 00:00:21.400
at ocw.mit.edu.

00:00:21.400 --> 00:00:23.150
NANCY KANWISHER: I'll
just be brief today,

00:00:23.150 --> 00:00:28.070
but you can check out some of my
stuff at the website up there.

00:00:28.070 --> 00:00:30.260
If you're confused
by my appearance,

00:00:30.260 --> 00:00:33.710
if you've met me before, yes,
I used to look like that.

00:00:33.710 --> 00:00:37.360
But at a deeper level,
really, I look like this.

00:00:37.360 --> 00:00:41.682
This is me, and you look
like that, too, inside.

00:00:41.682 --> 00:00:43.390
And these are parts
of-- is that showing?

00:00:43.390 --> 00:00:44.187
Yeah.

00:00:44.187 --> 00:00:45.770
These are parts of
my brain that we've

00:00:45.770 --> 00:00:48.890
mapped with functional MRI
that were either discovered

00:00:48.890 --> 00:00:50.805
in my lab, or that my
colleagues discovered,

00:00:50.805 --> 00:00:54.480
and that we then ran-- they're
kinds of scans in my lab.

00:00:54.480 --> 00:00:58.160
These are all regions that do
very specific things and that

00:00:58.160 --> 00:01:04.040
to me, are a big part of the
story of how we are so smart.

00:01:04.040 --> 00:01:06.860
So my interests, at
a very general level,

00:01:06.860 --> 00:01:11.510
are to answer things like
what is the architecture

00:01:11.510 --> 00:01:12.320
of the human mind?

00:01:12.320 --> 00:01:14.162
What are its
fundamental components?

00:01:14.162 --> 00:01:15.620
And there are lots
and lots of ways

00:01:15.620 --> 00:01:17.600
to find those
fundamental components.

00:01:17.600 --> 00:01:20.040
Functional MRI, which is
how we made this picture,

00:01:20.040 --> 00:01:21.960
is just one of a huge number.

00:01:21.960 --> 00:01:24.950
I loved Patrick's comment that
you should find questions, not

00:01:24.950 --> 00:01:25.605
hammers.

00:01:25.605 --> 00:01:28.680
I kind of like my hammer,
I have to confess.

00:01:28.680 --> 00:01:31.070
But questions are
more important.

00:01:31.070 --> 00:01:33.980
And there are lots
of ways to approach

00:01:33.980 --> 00:01:39.740
this question of the basic
architecture of the human mind.

00:01:39.740 --> 00:01:41.990
I also want to know
how this structure,

00:01:41.990 --> 00:01:44.000
which is present in
every normal person--

00:01:44.000 --> 00:01:45.590
I could pop any of
you in the scanner

00:01:45.590 --> 00:01:47.548
and make a picture like
this of your brain, OK,

00:01:47.548 --> 00:01:52.500
it would take a little while,
but wouldn't take that long.

00:01:52.500 --> 00:01:57.110
How does that structure
arise over development?

00:01:57.110 --> 00:01:59.660
How does your genetic
code and your experience

00:01:59.660 --> 00:02:01.730
work together to
wire that up when

00:02:01.730 --> 00:02:04.460
you're an infant and a child?

00:02:04.460 --> 00:02:07.178
How did it evolve
over human evolution?

00:02:10.310 --> 00:02:13.040
This is sort of what's sometimes
called a mesoscale, this really

00:02:13.040 --> 00:02:16.310
macroscopic picture of the major
components of the human mind

00:02:16.310 --> 00:02:17.720
and brain.

00:02:17.720 --> 00:02:20.720
But of course, we also want
to know how each of those bits

00:02:20.720 --> 00:02:21.355
work.

00:02:21.355 --> 00:02:22.730
What are the
representations that

00:02:22.730 --> 00:02:24.230
live in each of those regions?

00:02:24.230 --> 00:02:25.340
And how are they computed?

00:02:25.340 --> 00:02:27.230
And what are the
neural circuits that

00:02:27.230 --> 00:02:30.470
implement those computations?

00:02:30.470 --> 00:02:33.530
And of course, cognition
doesn't happen in just one

00:02:33.530 --> 00:02:35.960
little machine in there.

00:02:35.960 --> 00:02:39.040
It's a product of all of
these bits working together.

00:02:39.040 --> 00:02:41.150
We want to understand how
all of that works, too,

00:02:41.150 --> 00:02:45.230
and how all of that goes
together to make us so smart.

00:02:45.230 --> 00:02:48.510
And that's related to a question
that I'm deeply interested in,

00:02:48.510 --> 00:02:52.490
which is what is so special
about this machine that looks

00:02:52.490 --> 00:02:54.350
a lot like a rodent brain?

00:02:54.350 --> 00:02:57.450
And it's smaller than a whale
brain or a Neanderthal brain,

00:02:57.450 --> 00:02:59.930
so it's not just that
we have more of it.

00:02:59.930 --> 00:03:04.190
What is so special about this
thing that has put all of us

00:03:04.190 --> 00:03:06.320
here, interacting
with each other

00:03:06.320 --> 00:03:07.760
and studying this
thing, something

00:03:07.760 --> 00:03:11.450
that no other brain is doing,
no other species brain?

00:03:11.450 --> 00:03:12.830
So are there special bits?

00:03:12.830 --> 00:03:14.602
Do those bits work differently?

00:03:14.602 --> 00:03:16.060
Are there special
kinds of neurons?

00:03:16.060 --> 00:03:18.530
I don't think so,
some people do.

00:03:18.530 --> 00:03:22.400
What is it about this that
has brought us all right here?

00:03:22.400 --> 00:03:25.460
OK, so that, at a top level,
are some of the questions

00:03:25.460 --> 00:03:27.167
I would most like to answer.

00:03:27.167 --> 00:03:29.000
Not that I know how to
approach any of them,

00:03:29.000 --> 00:03:31.430
but I think it's important to
keep an eye on those goals,

00:03:31.430 --> 00:03:34.910
even when you don't quite see
how you're going to get there.

00:03:34.910 --> 00:03:40.700
My particular focus
in the CBMM Project

00:03:40.700 --> 00:03:42.530
is to look at social
intelligence, which

00:03:42.530 --> 00:03:45.210
is one piece of that puzzle.

00:03:45.210 --> 00:03:47.460
And so, why social intelligence?

00:03:47.460 --> 00:03:50.300
Well, just briefly, I
think social cognition

00:03:50.300 --> 00:03:53.030
is in many ways the crux
of human intelligence.

00:03:53.030 --> 00:03:56.000
OK, and it's a crux in a whole
bunch of different senses.

00:03:56.000 --> 00:03:58.620
One is it's just the source
of how we're so smart.

00:03:58.620 --> 00:04:00.620
Like, if you think about
all the stuff you know,

00:04:00.620 --> 00:04:02.374
OK, do a quick mental inventory.

00:04:02.374 --> 00:04:03.790
OK, what's all the
stuff you know?

00:04:03.790 --> 00:04:05.062
Like, make a little taxonomy.

00:04:05.062 --> 00:04:06.770
There's this kind of
stuff, it's all lots

00:04:06.770 --> 00:04:08.700
of different kinds
of stuff you know.

00:04:08.700 --> 00:04:10.630
OK, now how much of
that stuff that you

00:04:10.630 --> 00:04:13.280
know would you know
if you had never

00:04:13.280 --> 00:04:15.746
interacted with another person?

00:04:15.746 --> 00:04:17.480
A lot of it, you
wouldn't know, right?

00:04:17.480 --> 00:04:20.149
So a lot of the stuff we
know and a lot of the ways

00:04:20.149 --> 00:04:21.890
that we're smart
are things that we

00:04:21.890 --> 00:04:23.850
get from interacting
with other people.

00:04:23.850 --> 00:04:25.820
That's social cognition.

00:04:25.820 --> 00:04:26.930
OK.

00:04:26.930 --> 00:04:29.270
Another sense in
which social cognition

00:04:29.270 --> 00:04:30.980
is the crux of
human intelligence

00:04:30.980 --> 00:04:34.730
is many people think that the
primary driver of the evolution

00:04:34.730 --> 00:04:36.920
of the human brain has
been the requirement

00:04:36.920 --> 00:04:38.910
to interact with
other people who are,

00:04:38.910 --> 00:04:41.425
after all, very
complex entities,

00:04:41.425 --> 00:04:43.550
and to be able to understand
how to work with them,

00:04:43.550 --> 00:04:45.216
and what they're
doing, and what they'll

00:04:45.216 --> 00:04:48.320
do next is very
cognitively demanding.

00:04:48.320 --> 00:04:52.820
And so that may be one of the
major forces that has driven

00:04:52.820 --> 00:04:55.130
the evolution of our brain.

00:04:55.130 --> 00:04:56.930
Another sense in which
social intelligence

00:04:56.930 --> 00:04:59.240
is the crux of
human intelligence

00:04:59.240 --> 00:05:03.160
is that it's just plain a large
percent of human cognition.

00:05:03.160 --> 00:05:09.310
OK, so we do versions of social
cognition much of every day.

00:05:09.310 --> 00:05:12.160
Right now, I'm having
these thoughts in my head.

00:05:12.160 --> 00:05:14.346
God knows what that
looks like neurally.

00:05:14.346 --> 00:05:16.720
I'm translating that into some
noises that are coming out

00:05:16.720 --> 00:05:18.984
of my mouth, you're
hearing those noises,

00:05:18.984 --> 00:05:21.400
and you're getting-- let's
hope-- kind of similar thoughts

00:05:21.400 --> 00:05:22.840
in your head.

00:05:22.840 --> 00:05:24.580
That is a miracle.

00:05:24.580 --> 00:05:28.990
Nobody has the foggiest idea how
that works at a neural level.

00:05:28.990 --> 00:05:32.754
Nobody can even make up
a sketch of a hypothesis

00:05:32.754 --> 00:05:34.420
of a bunch of neural
circuits that might

00:05:34.420 --> 00:05:35.800
be able to make that happen.

00:05:35.800 --> 00:05:37.420
Right?

00:05:37.420 --> 00:05:42.340
That's a fascinating
puzzle, and it's also

00:05:42.340 --> 00:05:44.500
of the essence in
human intelligence.

00:05:44.500 --> 00:05:47.560
And we do it all the time,
not just speaking per se,

00:05:47.560 --> 00:05:50.050
but all the other ways
that we share information

00:05:50.050 --> 00:05:51.470
with each other.

00:05:51.470 --> 00:05:54.070
So one, social
cognition is just what

00:05:54.070 --> 00:05:56.560
we do all day long every day.

00:05:56.560 --> 00:06:00.380
It's also a big part of the
surface area of the cortex.

00:06:00.380 --> 00:06:04.480
So this cartoon here shows--
with some major poetic

00:06:04.480 --> 00:06:05.494
license--

00:06:05.494 --> 00:06:07.660
brain regions that are
involved in different aspects

00:06:07.660 --> 00:06:08.650
of social cognition.

00:06:08.650 --> 00:06:12.820
And it's just a big part of
the cortical area as well.

00:06:12.820 --> 00:06:14.560
OK.

00:06:14.560 --> 00:06:16.930
Another sense in
which social cognition

00:06:16.930 --> 00:06:18.790
is of the essence in
human intelligence

00:06:18.790 --> 00:06:22.060
is that many of the greatest
things that humanity

00:06:22.060 --> 00:06:25.960
has accomplished are products
of people working together.

00:06:25.960 --> 00:06:27.610
So all of that is
the big picture

00:06:27.610 --> 00:06:31.480
on why social cognition is cool,
and important, and fundamental.

00:06:31.480 --> 00:06:34.840
The part of it that we're
focusing on in our thrust

00:06:34.840 --> 00:06:37.180
within this NSF
grant is something

00:06:37.180 --> 00:06:39.160
I call social perception.

00:06:39.160 --> 00:06:41.950
OK, so by social
perception, I mean

00:06:41.950 --> 00:06:45.490
this spectacularly
impressive human ability

00:06:45.490 --> 00:06:48.340
to extract rich,
multidimensional

00:06:48.340 --> 00:06:53.060
social information from a
brief glimpse of a scene.

00:06:53.060 --> 00:06:54.800
From a brief
glimpse at a person,

00:06:54.800 --> 00:06:58.820
you can tell not just who
that person is, you can

00:06:58.820 --> 00:07:02.250
tell what they're trying to do.

00:07:02.250 --> 00:07:04.700
You can tell how they feel.

00:07:04.700 --> 00:07:08.180
You can tell what they're
paying attention to.

00:07:08.180 --> 00:07:12.090
You can tell what they
know and who they like.

00:07:12.090 --> 00:07:13.250
OK?

00:07:13.250 --> 00:07:14.720
And that's just the beginning.

00:07:14.720 --> 00:07:15.219
OK?

00:07:15.219 --> 00:07:18.020
So the work in our
thrust tries to approach

00:07:18.020 --> 00:07:20.210
all of these different
kinds of questions

00:07:20.210 --> 00:07:24.800
that we are calling as part
of our PR of this NSF grant.

00:07:24.800 --> 00:07:26.960
It's kind of an
organizing principle.

00:07:26.960 --> 00:07:30.620
The Turing questions,
these demanding, difficult

00:07:30.620 --> 00:07:33.860
computational problems
of social perception.

00:07:33.860 --> 00:07:34.790
Who is that person?

00:07:34.790 --> 00:07:36.206
What are they
paying attention to?

00:07:36.206 --> 00:07:37.320
What are they feeling?

00:07:37.320 --> 00:07:38.172
What are they like?

00:07:38.172 --> 00:07:39.630
Are they interacting
with somebody?

00:07:39.630 --> 00:07:41.255
What is the nature
of that interaction?

00:07:41.255 --> 00:07:42.190
And so on.

00:07:42.190 --> 00:07:43.340
OK?

00:07:43.340 --> 00:07:47.570
So the general plan
of action in how

00:07:47.570 --> 00:07:50.120
to approach this
in our thrust is

00:07:50.120 --> 00:07:54.140
first to study these abilities
in the computational system

00:07:54.140 --> 00:07:56.420
that's best at them,
namely this one--

00:07:56.420 --> 00:07:58.880
and those out
there, yours, too--

00:07:58.880 --> 00:08:01.310
the human brain.

00:08:01.310 --> 00:08:05.210
And so the roadmap here is
to first do psychophysics,

00:08:05.210 --> 00:08:07.970
characterize simple
behavioral measurements--

00:08:07.970 --> 00:08:10.300
what can people do,
what can't they do--

00:08:10.300 --> 00:08:16.010
from simple stimuli, and
quantify that in detail.

00:08:16.010 --> 00:08:17.390
Ask, how good are we at it?

00:08:17.390 --> 00:08:19.970
Maybe some of these things
that we think we can do, like

00:08:19.970 --> 00:08:22.280
size up somebody's
personality in three seconds

00:08:22.280 --> 00:08:23.450
when we first meet them--

00:08:23.450 --> 00:08:25.565
feels like you can
do that, or at least

00:08:25.565 --> 00:08:27.884
you get a read on them--

00:08:27.884 --> 00:08:29.300
I mean, is that
based on anything?

00:08:29.300 --> 00:08:30.450
Is that just garbage?

00:08:30.450 --> 00:08:31.810
Right?

00:08:31.810 --> 00:08:36.770
Are we actually tapping
into real information there?

00:08:36.770 --> 00:08:39.679
What cues are we using when
we make those high level

00:08:39.679 --> 00:08:41.900
social inferences?

00:08:41.900 --> 00:08:43.669
What is the input
that we get, that we

00:08:43.669 --> 00:08:47.720
use as a basis for analyzing
this particular percept

00:08:47.720 --> 00:08:49.880
or throughout life
that we've used

00:08:49.880 --> 00:08:53.145
to train up our brains
to be able to do this?

00:08:53.145 --> 00:08:55.520
So the second approach is once
we have some kind of sense

00:08:55.520 --> 00:08:58.190
of what are those abilities--
that's sometimes called Marr

00:08:58.190 --> 00:09:02.650
theory level, characterizing
what can we do, right--

00:09:02.650 --> 00:09:05.749
is we can then try to
computationally model this.

00:09:05.749 --> 00:09:07.790
And so there's lots of
different ways to do this,

00:09:07.790 --> 00:09:09.956
and many of the other thrusts
that you'll hear about

00:09:09.956 --> 00:09:12.580
are really tackling
that problem.

00:09:12.580 --> 00:09:14.360
Another thing we can
do is, of course,

00:09:14.360 --> 00:09:17.256
characterize the brain
basis of these abilities,

00:09:17.256 --> 00:09:19.130
and we can do that with
all kinds of methods.

00:09:19.130 --> 00:09:22.730
We're using, in our
thrust, functional MRI,

00:09:22.730 --> 00:09:26.930
intracranial recordings,
something called NIRS.

00:09:26.930 --> 00:09:31.070
This is the ability to make
measurements of blood flow

00:09:31.070 --> 00:09:34.760
changes in very young infants.

00:09:34.760 --> 00:09:36.950
And so we can characterize
these brain systems

00:09:36.950 --> 00:09:38.300
in adults and infants.

00:09:38.300 --> 00:09:41.210
And that gives you a
leg up in understanding

00:09:41.210 --> 00:09:42.890
these other broader
questions about how

00:09:42.890 --> 00:09:46.280
the whole system works in
a number of different ways.

00:09:46.280 --> 00:09:48.650
Just seeing how
the brain carves up

00:09:48.650 --> 00:09:51.380
the problem of social
perception into pieces

00:09:51.380 --> 00:09:53.360
already gives you some
clues about the kinds

00:09:53.360 --> 00:09:56.900
of computations that may go
on in each of those pieces.

00:09:56.900 --> 00:09:57.960
OK?

00:09:57.960 --> 00:09:58.640
OK.

00:09:58.640 --> 00:10:00.654
So that's the overview.

00:10:00.654 --> 00:10:02.320
There's many, many
ways you can do this,

00:10:02.320 --> 00:10:04.050
and of course, people all
over the place are doing this.

00:10:04.050 --> 00:10:06.260
There's nothing all
that unique about it.

00:10:06.260 --> 00:10:09.230
This is just our framework here.

00:10:09.230 --> 00:10:12.050
Some of the specific
projects that are going on

00:10:12.050 --> 00:10:15.410
include some work on face
recognition, which of course,

00:10:15.410 --> 00:10:17.540
a really classic
question that many people

00:10:17.540 --> 00:10:18.950
have been approaching.

00:10:18.950 --> 00:10:23.270
My post-doc, Matt Peterson, here
has done some very lovely work

00:10:23.270 --> 00:10:26.990
where he's shown that, actually,
where you look on a face

00:10:26.990 --> 00:10:28.220
is very systematic.

00:10:28.220 --> 00:10:30.110
You don't just look
anywhere, right?

00:10:30.110 --> 00:10:32.120
When you first make us
saccade into a face,

00:10:32.120 --> 00:10:34.730
somebody appears in your visual
periphery, right, of course,

00:10:34.730 --> 00:10:38.750
all the high-resolution visual
abilities are all right near

00:10:38.750 --> 00:10:40.490
the center of gaze
around the fovea,

00:10:40.490 --> 00:10:43.640
where you have a high density of
photo receptors and a shitload

00:10:43.640 --> 00:10:45.800
of cortex-- to be
technical about it--

00:10:45.800 --> 00:10:47.970
devoted to allocating
center of gaze.

00:10:47.970 --> 00:10:52.310
Right back here, in primary
visual cortex and with

00:10:52.310 --> 00:10:54.170
the first few
retinotopic regions,

00:10:54.170 --> 00:10:57.890
you have 20 square
centimeters-- that's like that--

00:10:57.890 --> 00:11:01.200
of cortex allocated to just the
central two degrees of vision.

00:11:01.200 --> 00:11:01.700
Right?

00:11:01.700 --> 00:11:04.550
So you have a lot of
computational machinery doing

00:11:04.550 --> 00:11:06.140
just that bit right there.

00:11:06.140 --> 00:11:08.120
Well, when a face appears
in your periphery,

00:11:08.120 --> 00:11:10.190
you move that bit of
your cortex, boom,

00:11:10.190 --> 00:11:11.207
right on top of it.

00:11:11.207 --> 00:11:13.040
So you have all that
computational machinery

00:11:13.040 --> 00:11:15.710
to dig in on the face, right?

00:11:15.710 --> 00:11:20.120
OK, so what Matt has shown
is that the particular way

00:11:20.120 --> 00:11:23.390
that you allocate that
computational machinery, namely

00:11:23.390 --> 00:11:25.940
by making an eye movement
to put that stimulus

00:11:25.940 --> 00:11:30.060
right on your fovea, people
do that slightly differently.

00:11:30.060 --> 00:11:32.720
Some people fixate
on a face up here,

00:11:32.720 --> 00:11:35.360
some people fixate
on a face down there,

00:11:35.360 --> 00:11:37.621
and most people fixate
someplace in the middle.

00:11:37.621 --> 00:11:38.120
OK?

00:11:38.120 --> 00:11:39.560
Well, so why is it interesting?

00:11:39.560 --> 00:11:40.970
Here's why it's interesting.

00:11:40.970 --> 00:11:42.830
People do that in
very systematic ways.

00:11:42.830 --> 00:11:44.780
And if you look up
here, you pretty much

00:11:44.780 --> 00:11:45.817
always look up there.

00:11:45.817 --> 00:11:47.900
And if you look down there,
you pretty much always

00:11:47.900 --> 00:11:49.310
look down there.

00:11:49.310 --> 00:11:51.650
And this has computational
consequences.

00:11:51.650 --> 00:11:53.330
If we brought you
guys into the lab

00:11:53.330 --> 00:11:55.664
and ran you on an eye
tracker for 15 minutes,

00:11:55.664 --> 00:11:57.330
we'd find out which
of you look up there

00:11:57.330 --> 00:11:58.705
and which of you
look down there.

00:11:58.705 --> 00:12:01.490
And if we took those of
you who look up here,

00:12:01.490 --> 00:12:04.250
and we presented a face
by flashing it briefly

00:12:04.250 --> 00:12:06.410
while you're fixating
so that the face landed

00:12:06.410 --> 00:12:08.510
in your not-preferred
looking position,

00:12:08.510 --> 00:12:10.520
your accuracy at
recognizing that face

00:12:10.520 --> 00:12:12.799
would be much lower,
and vice versa.

00:12:12.799 --> 00:12:14.840
If you're one of the people
who looks down there,

00:12:14.840 --> 00:12:16.700
and we flash up
a face so that it

00:12:16.700 --> 00:12:18.200
lands right there
on your retina,

00:12:18.200 --> 00:12:20.450
you're much worse
at recognizing it.

00:12:20.450 --> 00:12:23.079
And what that means is that
this fundamental problem

00:12:23.079 --> 00:12:24.620
that you'll hear
about in the course,

00:12:24.620 --> 00:12:26.360
that Tommy has worked
at in many people,

00:12:26.360 --> 00:12:29.900
it's one of the central problems
in vision research of how

00:12:29.900 --> 00:12:32.900
we deal with the many
different ways an object--

00:12:32.900 --> 00:12:35.330
the many different kinds
of images an object

00:12:35.330 --> 00:12:38.630
can make on our
retina by where it

00:12:38.630 --> 00:12:40.100
lands on the
retina, how close it

00:12:40.100 --> 00:12:44.180
is to you, the orientation, the
lighting, all these things that

00:12:44.180 --> 00:12:47.090
create this central
problem in vision

00:12:47.090 --> 00:12:50.690
of the variable ways
an object can look.

00:12:50.690 --> 00:12:53.510
A big part of how we solve
that for face recognition is we

00:12:53.510 --> 00:12:55.670
just move our eyes
to the same place.

00:12:55.670 --> 00:12:58.705
Position and variance
problem solved, mostly.

00:12:58.705 --> 00:13:00.300
OK, it's kind of a
low-tech solution.

00:13:00.300 --> 00:13:02.120
It's a good one.

00:13:02.120 --> 00:13:04.880
OK, anyway, so Matt has been
working on that for a while,

00:13:04.880 --> 00:13:06.830
and so now, most of
that is lab studies.

00:13:06.830 --> 00:13:11.030
Now what he's done is he's
using mobile eye trackers, which

00:13:11.030 --> 00:13:14.224
look like this, and a
GoPro attached to his head,

00:13:14.224 --> 00:13:16.640
because the mobile eye trackers
don't have very good image

00:13:16.640 --> 00:13:17.782
resolution.

00:13:17.782 --> 00:13:19.740
And so he's sending people
around in the world,

00:13:19.740 --> 00:13:21.800
and he's finding that,
first of all, yes, in fact,

00:13:21.800 --> 00:13:23.508
when you're walking
around in the world--

00:13:23.508 --> 00:13:26.125
not just when you're on a
bike bar in a lab, you know,

00:13:26.125 --> 00:13:28.400
with a tracker and a screen--

00:13:28.400 --> 00:13:31.010
the people who look up here
also look up there in the world,

00:13:31.010 --> 00:13:32.242
right?

00:13:32.242 --> 00:13:33.950
So that's just a
reality check that shows

00:13:33.950 --> 00:13:35.390
that our technology is working.

00:13:35.390 --> 00:13:38.960
And now Matt is using this to
ask all kinds of questions.

00:13:38.960 --> 00:13:41.387
For example, social
interactions,

00:13:41.387 --> 00:13:43.220
where do people look
in social interactions?

00:13:43.220 --> 00:13:45.770
Can you tell stuff
about what they

00:13:45.770 --> 00:13:48.200
think about each other based
on where they look on faces,

00:13:48.200 --> 00:13:49.370
right?

00:13:49.370 --> 00:13:50.300
We want to run--

00:13:50.300 --> 00:13:51.110
this is fruity.

00:13:51.110 --> 00:13:52.651
We haven't set it
up yet, but we want

00:13:52.651 --> 00:13:55.730
to run speed dating
experiments in the lab

00:13:55.730 --> 00:13:57.290
with people wearing
eye trackers.

00:13:57.290 --> 00:13:59.437
I bet in the first few
fixation positions,

00:13:59.437 --> 00:14:01.520
you can tell who's going
to want to recontact who.

00:14:01.520 --> 00:14:02.061
I don't know.

00:14:02.061 --> 00:14:03.230
We haven't done that yet.

00:14:03.230 --> 00:14:07.550
OK, that's a little trashy,
but it's kind of interesting.

00:14:07.550 --> 00:14:10.730
Some interesting scientific
questions are a little bit

00:14:10.730 --> 00:14:11.660
trashy, you know.

00:14:11.660 --> 00:14:14.150
Some trashy questions are not
scientifically interesting.

00:14:14.150 --> 00:14:16.870
I think that's one of those
rare that's actually both.

00:14:16.870 --> 00:14:18.050
Anyway.

00:14:18.050 --> 00:14:21.127
We also want to characterize--
a whole other part of this

00:14:21.127 --> 00:14:23.210
is this question that
people have been considering

00:14:23.210 --> 00:14:26.580
for a few decades now of
natural image statistics, right?

00:14:26.580 --> 00:14:29.420
So people have done all this
stuff, collecting images,

00:14:29.420 --> 00:14:31.400
and at first, they did
it really low-tech,

00:14:31.400 --> 00:14:32.535
and then the web appeared.

00:14:32.535 --> 00:14:34.910
And it's like, oh, now there's
a lot of images out there,

00:14:34.910 --> 00:14:36.574
and we can just
collect them easily.

00:14:36.574 --> 00:14:37.740
And let's characterize them.

00:14:37.740 --> 00:14:39.390
What are natural images like?

00:14:39.390 --> 00:14:41.240
So it's a whole
set of math where

00:14:41.240 --> 00:14:43.100
people have looked at
those natural images,

00:14:43.100 --> 00:14:44.475
and characterized
them, and tried

00:14:44.475 --> 00:14:49.430
to ask how the statistical
properties of natural images

00:14:49.430 --> 00:14:51.340
have--

00:14:51.340 --> 00:14:55.160
how we have adjusted our visual
systems to deal with the images

00:14:55.160 --> 00:14:56.600
that we confront.

00:14:56.600 --> 00:14:59.400
And that's a cool and
important area of research.

00:14:59.400 --> 00:15:02.730
But in all of that
work, nobody's

00:15:02.730 --> 00:15:05.190
actually used real
natural images, right?

00:15:05.190 --> 00:15:07.800
The images on the web,
somebody stuck a camera

00:15:07.800 --> 00:15:11.300
and put it there, and
then they threw away

00:15:11.300 --> 00:15:12.966
most of the pictures they took.

00:15:12.966 --> 00:15:14.340
The ones that land
on the web are

00:15:14.340 --> 00:15:17.369
the ones that have
good resolution, where

00:15:17.369 --> 00:15:19.410
people weren't moving in
and out of frame, things

00:15:19.410 --> 00:15:20.240
weren't occluded.

00:15:20.240 --> 00:15:22.410
They're not at all
like the actual images

00:15:22.410 --> 00:15:23.940
that land on your retina.

00:15:23.940 --> 00:15:25.620
So we're collecting
the actual images

00:15:25.620 --> 00:15:26.817
that land on your retina.

00:15:26.817 --> 00:15:28.650
And we're doing it with
mobile eye trackers,

00:15:28.650 --> 00:15:31.140
sending people around in the
world using these nice GoPro

00:15:31.140 --> 00:15:33.480
systems to give us
high resolution.

00:15:33.480 --> 00:15:36.780
And importantly, not only are
we collecting real natural image

00:15:36.780 --> 00:15:39.900
statistics from these
real natural images,

00:15:39.900 --> 00:15:42.810
we know, for each frame,
where the person was looking.

00:15:42.810 --> 00:15:45.360
And that's important for the
reason I mentioned a while ago,

00:15:45.360 --> 00:15:47.640
that most of your
high-resolution information

00:15:47.640 --> 00:15:49.560
is right at the center of gaze.

00:15:49.560 --> 00:15:53.520
And the information out in
the periphery is pretty lousy.

00:15:53.520 --> 00:15:56.190
OK, so that's one project
that I described too long,

00:15:56.190 --> 00:16:00.030
so I'll whip through
the others more briefly.

00:16:00.030 --> 00:16:03.870
We want to know how well people
can read each other's direction

00:16:03.870 --> 00:16:05.140
of attention.

00:16:05.140 --> 00:16:09.300
OK, so when I'm lecturing now,
if you guys get bored and look

00:16:09.300 --> 00:16:12.814
at the clock, I
will see it, right?

00:16:12.814 --> 00:16:14.730
And that's just one of
these things, you know?

00:16:14.730 --> 00:16:17.580
We're very attuned to where
each other are looking,

00:16:17.580 --> 00:16:19.464
and that's very
useful information.

00:16:19.464 --> 00:16:20.880
You meet somebody
at a conference,

00:16:20.880 --> 00:16:23.130
and you see them make a
saccade down to your name tag,

00:16:23.130 --> 00:16:26.190
and it's like, damn it, doesn't
this person remember who I am?

00:16:26.190 --> 00:16:26.870
You know?

00:16:26.870 --> 00:16:29.330
I'm very aware of this because
I'm mildly prosopagnosic.

00:16:29.330 --> 00:16:31.719
So if I've met you before,
and I'm slow to register,

00:16:31.719 --> 00:16:32.760
don't take it personally.

00:16:32.760 --> 00:16:33.600
I'm just lousy.

00:16:33.600 --> 00:16:36.690
It takes me a long
time to encode a face.

00:16:36.690 --> 00:16:40.330
Anyway, we're very attuned at
where each other are looking.

00:16:40.330 --> 00:16:42.960
And so there's been a lot
of work on how precisely

00:16:42.960 --> 00:16:45.780
we can tell whether somebody is
looking right at you versus off

00:16:45.780 --> 00:16:46.800
to the side.

00:16:46.800 --> 00:16:47.580
Try this at lunch.

00:16:47.580 --> 00:16:50.010
When you're in the middle of
a conversation with somebody,

00:16:50.010 --> 00:16:52.800
fixate on just the side of their
face, not way off to the side,

00:16:52.800 --> 00:16:56.400
just like here, and just
do that for a few seconds.

00:16:56.400 --> 00:16:59.160
It's deeply weird.

00:16:59.160 --> 00:17:01.587
The person you're talking to
will detect it immediately,

00:17:01.587 --> 00:17:04.170
will feel uncomfortable, until
they realize what you're doing,

00:17:04.170 --> 00:17:06.869
and then you guys will
have a good laugh.

00:17:06.869 --> 00:17:10.740
And that will show you
how exquisitely precise

00:17:10.740 --> 00:17:12.839
your ability to read
another person's gaze is.

00:17:12.839 --> 00:17:15.000
It's really very
precisely tuned.

00:17:15.000 --> 00:17:15.545
OK.

00:17:15.545 --> 00:17:16.920
So there's a lot
of work on that,

00:17:16.920 --> 00:17:19.859
but there's less
work on how well I

00:17:19.859 --> 00:17:22.817
can tell what exactly you're
looking at if it's not me.

00:17:22.817 --> 00:17:24.900
That is, I can tell if
you're looking at me or off

00:17:24.900 --> 00:17:27.450
to the side, or this
side, or that side.

00:17:27.450 --> 00:17:29.130
But what we're
looking at is how well

00:17:29.130 --> 00:17:32.280
can I tell what object
you're looking at?

00:17:32.280 --> 00:17:35.400
And that's an important
question because many people

00:17:35.400 --> 00:17:40.080
have pointed out that a
central little microcosm, kind

00:17:40.080 --> 00:17:42.390
of a unit of social
interaction, is something

00:17:42.390 --> 00:17:43.880
called joint attention.

00:17:43.880 --> 00:17:47.060
And joint attention is when
you're looking at this thing,

00:17:47.060 --> 00:17:49.500
and I'm looking at it, and
I know you're looking at it,

00:17:49.500 --> 00:17:51.420
and you know I'm looking at it.

00:17:51.420 --> 00:17:53.280
That's a cosmic little thing.

00:17:53.280 --> 00:17:55.290
Like, we can have this
little moment, right?

00:17:55.290 --> 00:17:56.820
Joint attention, OK?

00:17:56.820 --> 00:17:58.410
And people have
argued that that's

00:17:58.410 --> 00:18:01.920
of the essence in children
learning language.

00:18:01.920 --> 00:18:05.460
It's of the essence in all
kinds of social interactions.

00:18:05.460 --> 00:18:08.010
And by most accounts,
no other species

00:18:08.010 --> 00:18:09.510
has it, not even chimps.

00:18:09.510 --> 00:18:10.010
OK?

00:18:10.010 --> 00:18:12.030
I mean, there's still
some debate about this,

00:18:12.030 --> 00:18:14.030
and people niggle and
stuff, but basically, they

00:18:14.030 --> 00:18:16.560
don't have it in anything
like the way we have it.

00:18:16.560 --> 00:18:19.352
So we want to know, what is
the acuity of joint attention?

00:18:19.352 --> 00:18:21.060
OK, so I was supposed
to do that briefly.

00:18:21.060 --> 00:18:22.710
I can't seem to be brief.

00:18:22.710 --> 00:18:24.810
OK.

00:18:24.810 --> 00:18:27.240
So that's a whole project
that's going on with Danny

00:18:27.240 --> 00:18:28.980
Harari and Tao Gao.

00:18:28.980 --> 00:18:30.480
We're also asking
how well people

00:18:30.480 --> 00:18:34.080
can predict the target of
another person's action, right?

00:18:34.080 --> 00:18:36.304
So if I go out to reach
this, at one point-- well,

00:18:36.304 --> 00:18:37.720
there's only one
thing there-- but

00:18:37.720 --> 00:18:39.136
if we had a whole
array of things,

00:18:39.136 --> 00:18:41.070
at one point when I'm
reaching for an object,

00:18:41.070 --> 00:18:43.170
can you extrapolate
my trajectory,

00:18:43.170 --> 00:18:45.120
look at my eye gaze, and
use all of those cues

00:18:45.120 --> 00:18:48.930
to figure out what is
the goal of my action?

00:18:48.930 --> 00:18:52.822
Here's a cool way to look
at how well people can

00:18:52.822 --> 00:18:54.030
predict each other's actions.

00:18:54.030 --> 00:18:56.520
This is work by Maryam
Vaziri-Pashkam, shown here,

00:18:56.520 --> 00:19:00.450
who's a post-doc at Harvard
working with Ken Nakayama, who

00:19:00.450 --> 00:19:03.580
will give a lecture
later in the course.

00:19:03.580 --> 00:19:05.250
And what they're
trying to do is get

00:19:05.250 --> 00:19:07.702
an online read of
how well people can

00:19:07.702 --> 00:19:08.910
predict each other's actions.

00:19:08.910 --> 00:19:11.830
And so obviously, this happens
in all kinds of situations,

00:19:11.830 --> 00:19:13.475
especially in sports, right?

00:19:13.475 --> 00:19:15.690
If you're playing basketball
or ultimate frisbee,

00:19:15.690 --> 00:19:17.940
it's all about predicting
who's going to go where when

00:19:17.940 --> 00:19:21.420
and trying to take that into
account with your actions.

00:19:21.420 --> 00:19:23.130
So they've set
this up in the lab.

00:19:23.130 --> 00:19:25.050
And they have a
piece of glass here,

00:19:25.050 --> 00:19:29.100
and there's two Post-its
on this piece of glass.

00:19:29.100 --> 00:19:32.700
And one person's task is
to reach out and touch

00:19:32.700 --> 00:19:35.350
one of those targets quickly.

00:19:35.350 --> 00:19:38.310
And the other person
who's the goalie

00:19:38.310 --> 00:19:40.110
watches them through
the glass and tries

00:19:40.110 --> 00:19:42.060
to touch that target
as soon as possible

00:19:42.060 --> 00:19:43.410
after the first one does.

00:19:43.410 --> 00:19:44.390
OK?

00:19:44.390 --> 00:19:46.810
And so it's just a
basic little game.

00:19:46.810 --> 00:19:51.500
And so they have little
sensors on each person's finger

00:19:51.500 --> 00:19:53.190
so they can track the
exact trajectories

00:19:53.190 --> 00:19:54.529
and get reaction times.

00:19:54.529 --> 00:19:56.070
They're just behavioral
measurements,

00:19:56.070 --> 00:19:57.450
but they're very cool.

00:19:57.450 --> 00:19:59.070
So what they find
first of all is

00:19:59.070 --> 00:20:00.444
that the goalie,
the person who's

00:20:00.444 --> 00:20:02.730
trying to reach to respond
to the other person,

00:20:02.730 --> 00:20:05.280
can do that extremely
fast, right?

00:20:05.280 --> 00:20:08.820
They launch their hand
to the correct target

00:20:08.820 --> 00:20:11.931
within 150 milliseconds.

00:20:11.931 --> 00:20:14.430
Well, you should immediately
realize that something's fishy.

00:20:14.430 --> 00:20:15.210
You can't do that.

00:20:15.210 --> 00:20:18.600
It takes about 100
milliseconds just to get to V1.

00:20:18.600 --> 00:20:21.300
It takes, I forget how long,
but a few tens of milliseconds

00:20:21.300 --> 00:20:24.620
to send the signal
out from your brain

00:20:24.620 --> 00:20:26.520
out your arm to
initiate the movement.

00:20:26.520 --> 00:20:29.490
So how could you possibly
do all of that in that time?

00:20:29.490 --> 00:20:30.550
Well, you can't.

00:20:30.550 --> 00:20:33.420
And what that means is
that people are actually

00:20:33.420 --> 00:20:37.530
launching the hand
action, the goalie's

00:20:37.530 --> 00:20:39.960
launching the action before
the other person has actually

00:20:39.960 --> 00:20:41.126
started moving their finger.

00:20:41.126 --> 00:20:42.990
They've started
processing it before.

00:20:42.990 --> 00:20:46.620
And the way they've done that
is before this person starts,

00:20:46.620 --> 00:20:49.230
before their hand
moves at all, they've

00:20:49.230 --> 00:20:52.110
subtly changed their body
configuration in ways

00:20:52.110 --> 00:20:54.060
that the other person can read.

00:20:54.060 --> 00:20:55.350
OK?

00:20:55.350 --> 00:20:57.429
Now, on the one hand, OK, duh.

00:20:57.429 --> 00:20:58.470
You're playing this game.

00:20:58.470 --> 00:20:59.940
You learn to exploit cues.

00:20:59.940 --> 00:21:03.300
We're really great at figuring
out cues quickly, and using

00:21:03.300 --> 00:21:05.580
them, and learning to use them.

00:21:05.580 --> 00:21:07.110
But here's the--
one second-- here's

00:21:07.110 --> 00:21:09.540
the cool thing
about this task is

00:21:09.540 --> 00:21:12.870
that this immediate, ultrafast
reaction time happens

00:21:12.870 --> 00:21:15.670
on the very first few trials.

00:21:15.670 --> 00:21:18.480
So the ability that this
task is tapping into

00:21:18.480 --> 00:21:22.470
is not that the goalie can learn
what cues are predictive given

00:21:22.470 --> 00:21:24.250
enough trials and feedback.

00:21:24.250 --> 00:21:26.160
No, they do it
right off the bat.

00:21:26.160 --> 00:21:28.050
This task is tapping
into an ability

00:21:28.050 --> 00:21:30.630
that we all have
already, right now,

00:21:30.630 --> 00:21:35.016
to read each other's actions and
predict each other's behavior.

00:21:35.016 --> 00:21:37.140
And so people with no
instruction and no experience

00:21:37.140 --> 00:21:40.080
whatsoever in this
novel task know

00:21:40.080 --> 00:21:43.410
that this subtle little cue
of the way the body is moving

00:21:43.410 --> 00:21:46.740
a little bit before the person's
finger even starts to move,

00:21:46.740 --> 00:21:48.900
they can tell what
it's predictive of.

00:21:48.900 --> 00:21:54.450
So that's just another way to
characterize people's abilities

00:21:54.450 --> 00:21:56.280
in social perceptions,
so one of some

00:21:56.280 --> 00:21:59.040
of the many different things
that we just see really

00:21:59.040 --> 00:22:01.440
well in other people's actions.

00:22:01.440 --> 00:22:05.510
OK, that's what I
just said, all right.

00:22:05.510 --> 00:22:06.120
All right.

00:22:06.120 --> 00:22:07.536
I'm going to skip
over some stuff.

00:22:07.536 --> 00:22:09.900
We're looking at perception
of emotional expressions.

00:22:09.900 --> 00:22:12.060
Almost the entire
literature is based

00:22:12.060 --> 00:22:16.080
on staged emotional
expressions on faces,

00:22:16.080 --> 00:22:18.360
huge literature with
neuroimaging and behavior,

00:22:18.360 --> 00:22:20.940
and it goes back forever.

00:22:20.940 --> 00:22:24.000
But my colleague Elinor
McKone has pointed out

00:22:24.000 --> 00:22:28.260
that actually, it would
be important to look

00:22:28.260 --> 00:22:29.886
at real emotional
expressions on faces.

00:22:29.886 --> 00:22:31.385
Maybe that's different
behaviorally.

00:22:31.385 --> 00:22:33.600
It turns out it's very
different behaviorally.

00:22:33.600 --> 00:22:37.470
One, you can tell if somebody's
faking an emotional expression

00:22:37.470 --> 00:22:38.580
or if it's a real one.

00:22:38.580 --> 00:22:41.160
Like, OK, which of these is
real fear, and which of these

00:22:41.160 --> 00:22:42.503
is staged fear?

00:22:42.503 --> 00:22:43.390
Duh!

00:22:43.390 --> 00:22:45.450
OK, so one, we're
really attuned to that.

00:22:45.450 --> 00:22:46.970
I think that's
really interesting.

00:22:46.970 --> 00:22:49.590
Just as a social
perceptual ability,

00:22:49.590 --> 00:22:52.110
we spend a lot of time trying
to figure out who's sincere,

00:22:52.110 --> 00:22:53.700
who's genuine, who's
faking something,

00:22:53.700 --> 00:22:54.790
what's for real, right?

00:22:54.790 --> 00:22:55.290
You know?

00:22:55.290 --> 00:22:57.392
There's all kinds
of shades of that.

00:22:57.392 --> 00:22:59.100
And here's one little
piece of it, right?

00:22:59.100 --> 00:23:00.558
So I think that's
very interesting.

00:23:00.558 --> 00:23:03.079
And they've shown that
behaviorally, these phenomenon

00:23:03.079 --> 00:23:03.870
are very different.

00:23:03.870 --> 00:23:05.690
Just one example.

00:23:05.690 --> 00:23:09.300
A prior literature had shown
that people with schizophrenia

00:23:09.300 --> 00:23:12.600
are particularly bad at
reading facial expressions,

00:23:12.600 --> 00:23:17.580
using the standard measures, a
standard stimuli, the Ekman six

00:23:17.580 --> 00:23:20.070
facial expressions.

00:23:20.070 --> 00:23:23.730
These guys replicated that
finding and then showed

00:23:23.730 --> 00:23:26.530
that when you run
the same experiment,

00:23:26.530 --> 00:23:29.830
but using not staged but
real emotional expressions,

00:23:29.830 --> 00:23:32.870
schizophrenics are better
than everyone else.

00:23:32.870 --> 00:23:35.810
OK, so it matters behaviorally,
and it's interesting.

00:23:35.810 --> 00:23:37.440
OK.

00:23:37.440 --> 00:23:40.050
All right.

00:23:40.050 --> 00:23:42.420
Other things that we're doing--

00:23:42.420 --> 00:23:43.050
right.

00:23:43.050 --> 00:23:47.280
Leyla, your TA here, who's done
beautiful work on her thesis

00:23:47.280 --> 00:23:50.740
work with Tommy using
MEG and other methods,

00:23:50.740 --> 00:23:53.710
is now working with
me and Gabriel,

00:23:53.710 --> 00:23:56.170
using some of this
magnificent data

00:23:56.170 --> 00:23:58.780
that Gabriel has collected over
a bunch of years, where he's

00:23:58.780 --> 00:24:02.890
got intracranial recordings
from human brains

00:24:02.890 --> 00:24:04.930
while people watch movies.

00:24:04.930 --> 00:24:06.340
This is so precious.

00:24:06.340 --> 00:24:08.680
These data are
like a dream to me,

00:24:08.680 --> 00:24:10.600
as somebody who's
been using functional

00:24:10.600 --> 00:24:14.260
MRI as my main hammer
for the last 15 years.

00:24:14.260 --> 00:24:17.020
Functional MRI is magnificent,
it's wonderful, it's fun,

00:24:17.020 --> 00:24:19.100
but it has fundamental limits.

00:24:19.100 --> 00:24:23.270
One, it has no time
information worth a damn.

00:24:23.270 --> 00:24:25.720
And the computations
that make up perception,

00:24:25.720 --> 00:24:28.900
including social perception, and
language processing, and most

00:24:28.900 --> 00:24:30.730
of the interesting
aspects of cognition,

00:24:30.730 --> 00:24:33.319
happen on the order of
tens of milliseconds.

00:24:33.319 --> 00:24:34.360
We can't see any of that.

00:24:34.360 --> 00:24:37.000
It's all just squashed
together like a pancake, right,

00:24:37.000 --> 00:24:38.770
with functional MRI.

00:24:38.770 --> 00:24:41.590
With intracranial recordings,
you have exquisite time

00:24:41.590 --> 00:24:44.470
information, and you can see
computations unfold over time.

00:24:44.470 --> 00:24:47.320
That's very precious.

00:24:47.320 --> 00:24:53.170
Second of all, in principle,
with intracranial electrodes,

00:24:53.170 --> 00:24:54.820
you can test causality,
something you

00:24:54.820 --> 00:24:56.470
can't do with functional MRI.

00:24:56.470 --> 00:25:00.680
You can stimulate and ask
what tasks are disrupted.

00:25:00.680 --> 00:25:01.180
All right?

00:25:01.180 --> 00:25:03.580
So there's a huge
number of cool things

00:25:03.580 --> 00:25:06.900
you can do with
intracranial recordings.

00:25:06.900 --> 00:25:08.970
Leyla is looking
at some of the data

00:25:08.970 --> 00:25:11.400
that Gabriel has
been collecting,

00:25:11.400 --> 00:25:14.380
with intracranial recordings
of people watching movies.

00:25:14.380 --> 00:25:18.210
And because these are rich,
complex social stimuli,

00:25:18.210 --> 00:25:20.640
she's going to look
at all kinds of things

00:25:20.640 --> 00:25:23.700
that we can try to
extract from those data.

00:25:23.700 --> 00:25:27.630
Like, can you tell the
identity of the person

00:25:27.630 --> 00:25:29.790
who's on the screen right now?

00:25:29.790 --> 00:25:33.570
Can you tell from their face,
their voice, their body?

00:25:33.570 --> 00:25:35.970
Can you tell what action
they're carrying out?

00:25:35.970 --> 00:25:38.010
Can you tell if the
person on the screen right

00:25:38.010 --> 00:25:39.650
now is a good guy or a bad guy?

00:25:39.650 --> 00:25:41.220
Right?

00:25:41.220 --> 00:25:43.950
Can you tell what kind of social
interactions are going on?

00:25:43.950 --> 00:25:46.170
So we know all of this
stuff, all this information

00:25:46.170 --> 00:25:48.600
is extracted in the brain,
because people are good at it.

00:25:48.600 --> 00:25:51.240
But to get a handle on the
actual neural basis of how

00:25:51.240 --> 00:25:55.190
we carry out those
perceptual processes,

00:25:55.190 --> 00:25:57.060
this will be a really cool tool.

00:25:57.060 --> 00:26:00.150
So that project is
just starting now.

00:26:00.150 --> 00:26:03.870
And in other projects going
on, Lindsey Powell, shown here,

00:26:03.870 --> 00:26:08.670
who's working with Rebecca Saxe,
and Liz Spelke, and others,

00:26:08.670 --> 00:26:10.710
is using this NIRS
method to look

00:26:10.710 --> 00:26:13.860
at blood flow
changes in response

00:26:13.860 --> 00:26:15.720
to neural activity
in infant brains.

00:26:15.720 --> 00:26:18.090
She's looking at some
of those specializations

00:26:18.090 --> 00:26:20.400
that I showed you in my
brain at the beginning

00:26:20.400 --> 00:26:22.740
and asking, which of those
are present in infancy,

00:26:22.740 --> 00:26:25.740
a totally cool question.

00:26:25.740 --> 00:26:29.400
And Ben Deen, and Rebecca Saxe,
and me, and a bunch of others

00:26:29.400 --> 00:26:33.660
are looking at a big chunk of
the human brain that was one

00:26:33.660 --> 00:26:35.280
of my colored patches before.

00:26:35.280 --> 00:26:39.150
This whole dark gray
region here is called

00:26:39.150 --> 00:26:41.760
the superior temporal sulcus.

00:26:41.760 --> 00:26:43.770
This is an inflated
picture of the brain.

00:26:43.770 --> 00:26:45.300
That means--
usually, the cortexes

00:26:45.300 --> 00:26:46.820
are all folded up
inside the head.

00:26:46.820 --> 00:26:48.870
You have to do that
to fit it in there.

00:26:48.870 --> 00:26:50.620
But if you want to
see the whole thing,

00:26:50.620 --> 00:26:52.229
you can mathematically
inflate it.

00:26:52.229 --> 00:26:53.520
So that's what's happened here.

00:26:53.520 --> 00:26:56.040
And the dark bits are the
bits that were inside of folds

00:26:56.040 --> 00:26:57.030
before it was inflated.

00:26:57.030 --> 00:26:58.560
So they're inside
a sulcus, but now

00:26:58.560 --> 00:27:01.540
shown blown out to the surface.

00:27:01.540 --> 00:27:04.350
So this superior temporal
sulcus running down here

00:27:04.350 --> 00:27:07.580
is one of the longest
sulci in the human brain

00:27:07.580 --> 00:27:08.850
and one of the coolest.

00:27:08.850 --> 00:27:12.340
And an awful lot of social
perception goes on right there.

00:27:12.340 --> 00:27:16.290
Ben Deen has a paper in
press and some ongoing work

00:27:16.290 --> 00:27:18.720
where he shows that
lots of different kinds

00:27:18.720 --> 00:27:22.350
of social, cognitive,
and perceptual abilities

00:27:22.350 --> 00:27:26.460
actually inhabit
somewhat distinct regions

00:27:26.460 --> 00:27:28.650
along the superior
temporal sulcus.

00:27:28.650 --> 00:27:30.099
They're not perfectly discrete.

00:27:30.099 --> 00:27:31.890
Nothing is a neat little
oval in the brain.

00:27:31.890 --> 00:27:33.723
Actually, they somewhat
overlap, but there's

00:27:33.723 --> 00:27:35.352
a lot of organization in there.

00:27:35.352 --> 00:27:36.810
And that's cool
because it gives us

00:27:36.810 --> 00:27:39.480
a lever to try to understand
this whole big space

00:27:39.480 --> 00:27:41.420
of cognition.