WEBVTT

00:00:00.000 --> 00:00:02.520
The following content is
provided under a Creative

00:00:02.520 --> 00:00:03.970
Commons license.

00:00:03.970 --> 00:00:06.360
Your support will help
MIT OpenCourseWare

00:00:06.360 --> 00:00:10.660
continue to offer high-quality
educational resources for free.

00:00:10.660 --> 00:00:13.320
To make a donation or
view additional materials

00:00:13.320 --> 00:00:17.160
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:17.160 --> 00:00:18.370
at ocw.mit.edu.

00:00:21.710 --> 00:00:23.960
RUSS TEDRAKE: So welcome back.

00:00:26.600 --> 00:00:29.000
I thought we'd
start today sort of

00:00:29.000 --> 00:00:32.720
with a little bit of
reflection, since we

00:00:32.720 --> 00:00:34.250
have covered a lot of material.

00:00:34.250 --> 00:00:36.230
Even though we've kept
it to simple systems,

00:00:36.230 --> 00:00:38.570
we've actually covered
a lot of material,

00:00:38.570 --> 00:00:41.730
and we're about to blast
off into some new material.

00:00:41.730 --> 00:00:44.750
So I thought, let's
make sure everybody

00:00:44.750 --> 00:00:49.520
knows what we've done,
roughly how it fits together,

00:00:49.520 --> 00:00:51.380
and where we're going, OK?

00:00:51.380 --> 00:00:57.470
So I've been trying to
carry through the course two

00:00:57.470 --> 00:00:59.510
main threads.

00:00:59.510 --> 00:01:01.730
One of them is sort
of the systems thread.

00:01:01.730 --> 00:01:02.997
We start with pendula.

00:01:02.997 --> 00:01:04.580
We're getting to
acrobots, cart-poles.

00:01:04.580 --> 00:01:07.250
We're going to get more and
more interesting systems.

00:01:07.250 --> 00:01:10.580
In parallel, I'm trying to
design this optimal control

00:01:10.580 --> 00:01:12.710
thread which tells
you the way I think

00:01:12.710 --> 00:01:15.680
you should be solving these.

00:01:15.680 --> 00:01:19.340
Along the way, I'm throwing
in lots of puzzle pieces

00:01:19.340 --> 00:01:22.460
about partial feedback,
linearization, energy shaping,

00:01:22.460 --> 00:01:23.420
things like this.

00:01:26.570 --> 00:01:30.660
That's because this is
a hard-thought decision.

00:01:30.660 --> 00:01:33.020
I mean, this is a
research class, really.

00:01:33.020 --> 00:01:36.170
So I'm doing my very best to
teach all this material to you

00:01:36.170 --> 00:01:38.630
as if there's a
textbook on this.

00:01:38.630 --> 00:01:40.950
But in fact,
there's no textbook.

00:01:40.950 --> 00:01:42.470
So what I've decided
to do roughly

00:01:42.470 --> 00:01:47.210
is that, I'm trying to give you
a very clean line of thinking

00:01:47.210 --> 00:01:48.657
through the optimal control.

00:01:48.657 --> 00:01:50.990
But I do want to keep throwing
in what other people do--

00:01:50.990 --> 00:01:53.510
the domain-specific knowledge
about acrobots and cart-poles

00:01:53.510 --> 00:01:55.460
and walking as we get to it.

00:01:55.460 --> 00:01:58.010
Because I think these
puzzle pieces-- ultimately,

00:01:58.010 --> 00:02:00.560
there are things we can't
do with optimal control yet.

00:02:00.560 --> 00:02:03.510
My guess is that ideas from
partial feedback linearization

00:02:03.510 --> 00:02:04.260
are going to help.

00:02:04.260 --> 00:02:06.650
I think ideas from energy
shaping-- these kind of ideas

00:02:06.650 --> 00:02:07.815
are going to work together.

00:02:07.815 --> 00:02:10.190
So even though those aren't
going to connect up perfectly

00:02:10.190 --> 00:02:12.440
in this class, what
I'm hoping to do

00:02:12.440 --> 00:02:14.300
is give you all the
pieces of a puzzle

00:02:14.300 --> 00:02:17.210
that nobody's
actually solved yet,

00:02:17.210 --> 00:02:19.640
give you all the
information I can give you

00:02:19.640 --> 00:02:22.130
about this class of
problems so you can go off

00:02:22.130 --> 00:02:26.838
and write, well, final
projects that are

00:02:26.838 --> 00:02:28.130
cited a hundred thousand times.

00:02:30.810 --> 00:02:31.310
OK.

00:02:31.310 --> 00:02:33.230
So let me just make
sure that's happening.

00:02:33.230 --> 00:02:35.750
So that's a tall order to
sort of carry those threads.

00:02:35.750 --> 00:02:37.250
So let's make sure
that's happening.

00:02:37.250 --> 00:02:39.860
Maybe I'll even use
a whole board for it.

00:02:47.290 --> 00:02:51.040
So I think I've made
no secret of the fact

00:02:51.040 --> 00:02:56.200
that I think optimal control
is a sort of defining way

00:02:56.200 --> 00:03:00.310
to think about control for even
these very complicated systems.

00:03:00.310 --> 00:03:01.053
All right.

00:03:01.053 --> 00:03:02.470
So we've got one
thread that we'll

00:03:02.470 --> 00:03:07.240
continue-- we'll get deeper and
deeper in about optimal control

00:03:07.240 --> 00:03:09.640
methods.

00:03:09.640 --> 00:03:11.920
In particular,
we've already talked

00:03:11.920 --> 00:03:15.520
about sort of two fundamentally
different approaches

00:03:15.520 --> 00:03:16.450
to optimal control.

00:03:16.450 --> 00:03:18.370
We've talked about
optimal control

00:03:18.370 --> 00:03:20.560
based on the
Hamilton-Jacobi-Bellman

00:03:20.560 --> 00:03:27.340
equations, where we talked
about the value function being

00:03:27.340 --> 00:03:31.070
described by a nonlinear
partial differential equation.

00:03:34.300 --> 00:03:39.940
And then we also talked about
Pontryagin's minimum principle,

00:03:39.940 --> 00:03:43.280
which you're probably all
working on right now--

00:03:43.280 --> 00:03:49.150
Pontryagin's minimum principle.

00:03:49.150 --> 00:03:53.500
These were two sort of
analytical optimal control

00:03:53.500 --> 00:03:54.250
approaches, right?

00:04:08.430 --> 00:04:10.860
As such, unfortunately,
we only showed

00:04:10.860 --> 00:04:16.500
you much of anything
on linear systems

00:04:16.500 --> 00:04:19.064
where we can actually solve
those problems analytically.

00:04:22.680 --> 00:04:25.063
What were the big differences?

00:04:25.063 --> 00:04:27.480
Maybe I-- just to motivate
this so you make-- so make sure

00:04:27.480 --> 00:04:28.350
everybody pays attention.

00:04:28.350 --> 00:04:30.850
I should also say a few things
about what I hope you get out

00:04:30.850 --> 00:04:33.720
of the class, and for instance,
what will be on the midterm

00:04:33.720 --> 00:04:35.680
when it comes around.

00:04:35.680 --> 00:04:39.840
So I know that we're
throwing lots of ideas out.

00:04:39.840 --> 00:04:41.468
If there's one
thing that happens,

00:04:41.468 --> 00:04:43.260
one thing that you
should be able to do off

00:04:43.260 --> 00:04:45.750
the top of your
head is think about

00:04:45.750 --> 00:04:48.750
and talk about how these
different tools that we're

00:04:48.750 --> 00:04:51.600
putting out relate to
different problems.

00:04:51.600 --> 00:04:54.810
And for instance, if I
were to give you a problem,

00:04:54.810 --> 00:04:58.483
you could make some reasonable
guess at what kind of-- what

00:04:58.483 --> 00:05:00.150
methods that we've
talked about might be

00:05:00.150 --> 00:05:04.590
most suitable for that problem.

00:05:04.590 --> 00:05:08.070
The details of how you do a
partial feedback linearization,

00:05:08.070 --> 00:05:10.920
I wouldn't expect you to
absorb every piece of that.

00:05:10.920 --> 00:05:12.840
I would guide you through
that on a problem,

00:05:12.840 --> 00:05:15.750
but with the expectation that
you've worked through it once

00:05:15.750 --> 00:05:19.660
on a problem set and sort of
have some ability to do that.

00:05:19.660 --> 00:05:21.660
But if there's one thing
I want you to come away

00:05:21.660 --> 00:05:25.140
from this class with, I
want you to understand

00:05:25.140 --> 00:05:27.750
the suite of tools
we're talking about

00:05:27.750 --> 00:05:30.000
and have a sense for what
you'd apply to what problem.

00:05:32.890 --> 00:05:34.500
So in the
Hamilton-Jacobi-Bellman

00:05:34.500 --> 00:05:37.500
equation, we applied it to--

00:05:37.500 --> 00:05:43.080
we applied that--
which, remember,

00:05:43.080 --> 00:05:56.850
was this partial
differential equation,

00:05:56.850 --> 00:06:00.780
with a hard nonlinearity, which
describes the optimal solution.

00:06:05.100 --> 00:06:07.890
I should put stars on here
to be here careful here.

00:06:07.890 --> 00:06:12.360
The optimal cost-to-go is
described by that equation.

00:06:12.360 --> 00:06:14.430
So one approach
to these things is

00:06:14.430 --> 00:06:16.740
to directly try to
compute solutions

00:06:16.740 --> 00:06:19.590
to this partial
differential equation.

00:06:19.590 --> 00:06:24.750
We did it analytically for the
quadratic regulator problems,

00:06:24.750 --> 00:06:26.615
the linear quadratic regulators.

00:06:42.646 --> 00:06:43.640
Right.

00:06:43.640 --> 00:06:47.930
I didn't actually do it for
the minimum time problem,

00:06:47.930 --> 00:06:53.810
because the minimum
time problem,

00:06:53.810 --> 00:06:58.550
we know that the optimal
solution in J is actually not--

00:06:58.550 --> 00:06:59.990
its gradients are
not well-defined

00:06:59.990 --> 00:07:02.290
across the entire-- for all x.

00:07:02.290 --> 00:07:05.760
That's the only reason
I didn't do it for that.

00:07:05.760 --> 00:07:07.280
But for sort of
smooth problems like

00:07:07.280 --> 00:07:11.510
the linear quadratic regulators,
we could use these methods.

00:07:11.510 --> 00:07:15.770
Pontryagin is a little
bit more general.

00:07:15.770 --> 00:07:19.130
This is the one with
the adjoint equation.

00:07:19.130 --> 00:07:28.250
So you defined the
Hamiltonian is here

00:07:28.250 --> 00:07:32.777
some cost function plus Lagrange
variable, Lagrange multiplier

00:07:32.777 --> 00:07:33.610
times your dynamics.

00:07:39.490 --> 00:07:40.930
Pontryagin was more powerful.

00:07:40.930 --> 00:07:42.670
In some sense, we
solved harder problems.

00:07:42.670 --> 00:07:49.540
We solved, for instance,
the minimum time problem,

00:07:49.540 --> 00:07:51.040
for the double
integrator, at least.

00:07:54.070 --> 00:07:58.180
The problem with it is
just that it was too local.

00:07:58.180 --> 00:08:07.240
The Pontryagin ideas are
based on a gradient statement

00:08:07.240 --> 00:08:08.875
of local optimality.

00:08:25.220 --> 00:08:26.930
So we said along
some trajectory,

00:08:26.930 --> 00:08:30.470
I can verify that if
I change my control

00:08:30.470 --> 00:08:32.299
action a little bit
along this trajectory,

00:08:32.299 --> 00:08:35.980
my cost is only
going to get worse.

00:08:35.980 --> 00:08:38.270
So that's a necessary
condition for optimality.

00:08:38.270 --> 00:08:40.360
That's when we can do
a lot of things with--

00:08:40.360 --> 00:08:44.410
but it's only going to give me
a local optimality statement.

00:08:44.410 --> 00:08:48.760
Are people sort of OK with those
two methods we've been doing?

00:08:59.500 --> 00:09:01.430
OK.

00:09:01.430 --> 00:09:04.660
From the Hamilton-Jacobi
way of thinking,

00:09:04.660 --> 00:09:07.630
we ended up with
our first algorithm.

00:09:29.927 --> 00:09:31.240
Right.

00:09:31.240 --> 00:09:35.580
And we said that you could
discretize the dynamics,

00:09:35.580 --> 00:09:37.590
and in the discrete
dynamics solve

00:09:37.590 --> 00:09:40.980
whatever nonlinear problem
you wanted, pretty much.

00:10:09.700 --> 00:10:10.200
Right.

00:10:10.200 --> 00:10:12.270
And the reason we
could do that is

00:10:12.270 --> 00:10:20.280
because these Bellman equations
have this nice form that--

00:10:20.280 --> 00:10:22.380
there's a nice recursive form.

00:10:22.380 --> 00:10:27.340
It was that J at some x,
n is just the min over u.

00:10:27.340 --> 00:10:31.230
This is now-- maybe I should
be very careful when I write it

00:10:31.230 --> 00:10:34.470
in discrete, because that's
what we talked about it in min

00:10:34.470 --> 00:10:47.770
over actions A, discrete actions
A, S A plus the J of S prime,

00:10:47.770 --> 00:10:52.440
where S prime is what
I get for doing this.

00:11:10.080 --> 00:11:10.580
OK.

00:11:17.650 --> 00:11:20.440
So if you sort of
look at where there's

00:11:20.440 --> 00:11:22.090
white space left
on this board, you

00:11:22.090 --> 00:11:24.130
might be able to
guess what we're

00:11:24.130 --> 00:11:29.050
going to do next, our next
big piece of the puzzle.

00:11:29.050 --> 00:11:31.120
We're going to derive our
first set of algorithms

00:11:31.120 --> 00:11:33.985
now from the sort of
Pontryagin methods.

00:11:36.870 --> 00:11:41.440
And we're going to talk
about some policy search

00:11:41.440 --> 00:11:52.330
methods, the most
important class

00:11:52.330 --> 00:11:55.968
being of trajectory
optimization.

00:12:08.030 --> 00:12:08.530
OK.

00:12:16.220 --> 00:12:20.987
Along the way, we've been sort
of following this systems,

00:12:20.987 --> 00:12:22.570
we're developing
these systems, right?

00:12:26.690 --> 00:12:30.920
In the optimal control, the
analytical optimal control,

00:12:30.920 --> 00:12:33.356
we mostly just thought
about double integrators.

00:12:39.680 --> 00:12:47.945
But those things could have
applied to any LTI system.

00:12:52.250 --> 00:12:54.880
So that's supposed to
be in line with that.

00:12:54.880 --> 00:12:57.550
I'll do my best to not move the
board too many times in this.

00:13:02.020 --> 00:13:09.760
We moved on to sort
of pendulums, pendula.

00:13:09.760 --> 00:13:14.020
And we did the essential things.

00:13:14.020 --> 00:13:16.900
This is where I used to sort
of tell you about dynamics.

00:13:16.900 --> 00:13:19.702
We talked about nonlinear
dynamics, basins of attraction,

00:13:19.702 --> 00:13:20.410
all these things.

00:13:44.480 --> 00:13:46.548
And then we did
acrobots and cart-poles,

00:13:46.548 --> 00:13:48.590
where we talked about a
lot of interesting ideas.

00:13:48.590 --> 00:13:55.340
We talked about
controllability, we

00:13:55.340 --> 00:14:00.200
talked about partial
feedback linearization,

00:14:00.200 --> 00:14:08.510
and we talked about energy
shaping, even tasks-based.

00:14:12.500 --> 00:14:13.580
Lots of ideas in there.

00:14:19.700 --> 00:14:27.200
Those ideas are my attempt
to extract the most general.

00:14:27.200 --> 00:14:33.123
But the main topics of the sort
of acrobot/cart-pole world,

00:14:33.123 --> 00:14:35.540
in acrobots and cart-poles,
people talk about PFL heavily.

00:14:35.540 --> 00:14:36.998
They talk energy
shaping, they talk

00:14:36.998 --> 00:14:38.187
about these kind of things.

00:14:38.187 --> 00:14:39.770
I only presented the
ones that I think

00:14:39.770 --> 00:14:42.410
are going to be
useful in general.

00:14:42.410 --> 00:14:44.870
But to some extent,
right now you

00:14:44.870 --> 00:14:46.940
could think about
these techniques

00:14:46.940 --> 00:14:51.860
as being orthogonal to our
main line of thinking, OK?

00:14:57.680 --> 00:14:59.930
Now, like I said,
this is a puzzle

00:14:59.930 --> 00:15:02.080
that nobody has
the answer to yet.

00:15:02.080 --> 00:15:05.228
So actually, what I want
you to be thinking here is,

00:15:05.228 --> 00:15:06.770
what can we do with
all these things?

00:15:09.570 --> 00:15:13.010
So for instance, I told you that
dynamic programming works well

00:15:13.010 --> 00:15:16.280
for low-dimensional systems.

00:15:16.280 --> 00:15:18.230
Nonlinear systems, no problem.

00:15:18.230 --> 00:15:21.170
Low-dimensional, I can
discretize the space,

00:15:21.170 --> 00:15:23.810
I can just run my algorithm,
bup-bup-bup-bup-bup,

00:15:23.810 --> 00:15:29.670
compute the optimal
cost-to-go optimal policy.

00:15:29.670 --> 00:15:30.170
OK.

00:15:30.170 --> 00:15:33.780
But so maybe there's
obvious things to do.

00:15:33.780 --> 00:15:38.005
And actually, I think there are
obvious things to think about--

00:15:38.005 --> 00:15:40.130
research questions that
you could be thinking about

00:15:40.130 --> 00:15:41.750
for your final projects, right?

00:15:41.750 --> 00:15:44.750
So for instance, you know,
we used partial feedback

00:15:44.750 --> 00:15:48.800
linearization to take--
at least linearize part

00:15:48.800 --> 00:15:51.470
of the dynamics of the system.

00:15:51.470 --> 00:15:53.150
So this is wild
speculation here,

00:15:53.150 --> 00:15:57.260
but let's say I have a
problem that I could then

00:15:57.260 --> 00:16:09.080
describe as x1 dot is A1 x1
plus A2 x2 plus Bu then x2 dot

00:16:09.080 --> 00:16:22.900
equals f of x1, x2, u, where,
let's say, the dimension of x2

00:16:22.900 --> 00:16:26.200
is much, much less
than the dimensions

00:16:26.200 --> 00:16:32.922
of the whole original
system, which is what I get--

00:16:32.922 --> 00:16:35.380
that's the result. That's the
result I would get from doing

00:16:35.380 --> 00:16:37.810
a partial feedback
linearization, where I have,

00:16:37.810 --> 00:16:40.540
let's say, for Little Dog,
and I have five degrees

00:16:40.540 --> 00:16:43.270
of freedom and four
actuators, that I'd

00:16:43.270 --> 00:16:48.310
end up with sort of one very
nonlinear thing and then

00:16:48.310 --> 00:16:51.220
a bunch of very linear dynamics
after doing a partial feedback

00:16:51.220 --> 00:16:52.480
linearization.

00:16:52.480 --> 00:16:56.500
So fantastic research question--

00:16:56.500 --> 00:16:59.350
so could I use that
trick and combine it

00:16:59.350 --> 00:17:02.140
with dynamic
programming, let's say,

00:17:02.140 --> 00:17:05.230
to use dynamic programming
to solve the hard part

00:17:05.230 --> 00:17:09.218
and do some sort of LQR
to solve the easy part?

00:17:09.218 --> 00:17:09.760
I don't know.

00:17:09.760 --> 00:17:10.630
Probably you can.

00:17:10.630 --> 00:17:11.740
I bet you can.

00:17:11.740 --> 00:17:14.593
And I'd be excited to think
about, with any of you,

00:17:14.593 --> 00:17:15.760
you know, what you could do.

00:17:15.760 --> 00:17:18.790
But these are the reasons I'm
saying things like PFL, right?

00:17:18.790 --> 00:17:24.490
So imagine doing PFL
plus dynamic programming.

00:17:24.490 --> 00:17:28.480
I'd bet you could do
higher-dimensional optimization

00:17:28.480 --> 00:17:31.450
if you could exploit
tricks like that.

00:17:31.450 --> 00:17:35.200
So that'd be a fantastic
sort of research question

00:17:35.200 --> 00:17:39.490
to think about for your project.

00:17:44.920 --> 00:17:49.350
Are people sort of OK
with how this is going?

00:17:49.350 --> 00:17:50.095
Yeah?

00:17:50.095 --> 00:17:53.350
AUDIENCE: Are any of those
[INAUDIBLE] dimension that

00:17:53.350 --> 00:17:56.150
[INAUDIBLE] convergence or--

00:17:56.150 --> 00:17:59.310
RUSS TEDRAKE: Good, OK.

00:17:59.310 --> 00:18:02.280
So they're not explicitly--
these are not explicitly

00:18:02.280 --> 00:18:05.560
targeted to solving
optimal control problem.

00:18:05.560 --> 00:18:08.370
So proof of convergence, we
have to define what we mean.

00:18:08.370 --> 00:18:11.640
I mean, PFL,
certifiably, provides

00:18:11.640 --> 00:18:14.370
this sort of a dynamics.

00:18:14.370 --> 00:18:16.230
The energy shaping,
under some conditions,

00:18:16.230 --> 00:18:22.290
we showed we could regulate
the energy of our systems.

00:18:22.290 --> 00:18:27.450
So there's-- each of these
have their own sort of proofs

00:18:27.450 --> 00:18:28.655
and task space.

00:18:28.655 --> 00:18:30.030
But most of them
are not directly

00:18:30.030 --> 00:18:32.795
aimed at proving that you've
obtained some optimal policy.

00:18:32.795 --> 00:18:35.645
AUDIENCE: If you
obtain a kind of policy

00:18:35.645 --> 00:18:37.545
which would [INAUDIBLE] goal.

00:18:37.545 --> 00:18:40.650
If you have a specific
state that you want to be

00:18:40.650 --> 00:18:46.318
in [INAUDIBLE] to get to that,
maybe not optimally but--

00:18:46.318 --> 00:18:47.110
RUSS TEDRAKE: Good.

00:18:47.110 --> 00:18:48.735
So in the energy
shaping I talked about

00:18:48.735 --> 00:18:50.192
for the cart-pole--

00:18:50.192 --> 00:18:52.150
the energy shaping plus
PFL that I talked about

00:18:52.150 --> 00:18:57.250
for the cart-pole and swing-up,
there's a citation in the notes

00:18:57.250 --> 00:19:01.450
of a guy that proved that for
a set of parameters-- well,

00:19:01.450 --> 00:19:03.282
I'm being a little flippant--

00:19:03.282 --> 00:19:04.990
there's a little--
there's a regime where

00:19:04.990 --> 00:19:06.400
that's guaranteed to work.

00:19:06.400 --> 00:19:09.190
But the general proof that
you'd like to have is not there.

00:19:09.190 --> 00:19:12.010
For the acrobot, I know about
even less proof to that.

00:19:12.010 --> 00:19:14.290
There is one
particular controller

00:19:14.290 --> 00:19:18.770
that we implemented that someone
who took the class implemented

00:19:18.770 --> 00:19:19.270
before.

00:19:19.270 --> 00:19:21.953
And it does have
a Lyapunov proof

00:19:21.953 --> 00:19:23.120
saying it'll get to the top.

00:19:23.120 --> 00:19:25.090
But it sort of works by going--

00:19:25.090 --> 00:19:25.960
this is an acrobots.

00:19:25.960 --> 00:19:27.160
It's going ee-ee-ee-ee.

00:19:27.160 --> 00:19:28.490
It's like really unattractive.

00:19:28.490 --> 00:19:30.272
So it does something
really stupid.

00:19:30.272 --> 00:19:32.230
You wouldn't want to run
it on your real robot,

00:19:32.230 --> 00:19:34.600
probably, unless
you're very patient.

00:19:34.600 --> 00:19:37.255
But it has a proof
to get to the top.

00:19:37.255 --> 00:19:39.130
So these are the trade-offs
that people make.

00:19:44.000 --> 00:19:45.130
OK.

00:19:45.130 --> 00:19:46.040
Right.

00:19:46.040 --> 00:19:47.090
So I hope that sort of--

00:19:50.263 --> 00:19:51.430
I hope that was worth doing.

00:19:51.430 --> 00:19:55.090
I just wanted to quickly make
sure we're all calibrated.

00:19:55.090 --> 00:19:57.175
So let's talk a
minute now about--

00:20:00.827 --> 00:20:02.410
so I said that for
the dynamic program

00:20:02.410 --> 00:20:03.952
we showed it working
on the pendulum.

00:20:03.952 --> 00:20:07.540
I put a big asterisk
saying that there's

00:20:07.540 --> 00:20:09.850
discretization errors present.

00:20:09.850 --> 00:20:13.090
So even for the pendulum,
it'll solve it lightning fast.

00:20:13.090 --> 00:20:15.670
But it's solving the
discretized system, not

00:20:15.670 --> 00:20:16.930
the continuous system.

00:20:16.930 --> 00:20:19.270
And the optimal
policy you get out

00:20:19.270 --> 00:20:21.070
could be different
than the optimal policy

00:20:21.070 --> 00:20:23.560
for the continuous system.

00:20:23.560 --> 00:20:24.550
OK.

00:20:24.550 --> 00:20:26.080
So can you do
dynamic programming

00:20:26.080 --> 00:20:29.080
for the acrobot and cart-pole?

00:20:29.080 --> 00:20:31.940
That's an obvious question.

00:20:31.940 --> 00:20:33.430
So the answer is yes.

00:20:33.430 --> 00:20:36.640
People have done it.

00:20:36.640 --> 00:20:39.250
My code on the
acrobot and cart-pole

00:20:39.250 --> 00:20:40.690
runs in a few seconds.

00:20:40.690 --> 00:20:44.170
It's not a problem
of dimensionality.

00:20:44.170 --> 00:20:46.630
But the results are not--

00:20:46.630 --> 00:20:52.290
of my code-- are not
satisfying because of exactly

00:20:52.290 --> 00:20:54.430
the asterisks I put
on the pendulum.

00:20:54.430 --> 00:20:58.900
So let's just sort of
evaluate dynamic programming

00:20:58.900 --> 00:20:59.650
as we go forward.

00:21:20.470 --> 00:21:22.860
So absolutely, the
acrobot and the cart-pole

00:21:22.860 --> 00:21:32.260
both have four-dimensional state
space, one-dimensional action

00:21:32.260 --> 00:21:32.760
space.

00:21:42.620 --> 00:21:44.600
Easily discretized these days.

00:21:48.190 --> 00:21:51.620
That's still
low-dimensional enough

00:21:51.620 --> 00:21:55.010
that I can actually
bin up the space.

00:21:55.010 --> 00:21:55.800
That wasn't true.

00:21:55.800 --> 00:21:58.820
When people weer doing it in
the '80s, but it's true today.

00:21:58.820 --> 00:21:59.320
OK.

00:22:03.740 --> 00:22:11.450
The only real problem
with it is that there's

00:22:11.450 --> 00:22:12.440
discretization error.

00:22:24.380 --> 00:22:33.170
And essentially, the
discretized dynamics

00:22:33.170 --> 00:22:46.490
can be a poor representation
of the continuous dynamics.

00:22:50.190 --> 00:22:52.760
If you spend a lot of
time with the acrobot,

00:22:52.760 --> 00:22:55.860
you find actually the
acrobot's dynamics are pretty--

00:22:55.860 --> 00:22:57.780
are sort of wicked
in a lot of ways.

00:22:57.780 --> 00:23:01.970
So actually, spending a lot
more time about it recently--

00:23:04.880 --> 00:23:07.148
I mean, even just
sort of making sure

00:23:07.148 --> 00:23:08.690
that energy is
conserved when you put

00:23:08.690 --> 00:23:10.813
no torque into your system--

00:23:10.813 --> 00:23:12.980
this is the basic absolute
thing you do to make sure

00:23:12.980 --> 00:23:16.310
you got your
equations of motion--

00:23:16.310 --> 00:23:19.490
the acrobot, you have to put
your integration tolerances up

00:23:19.490 --> 00:23:22.460
the wazoo to make sure
you conserve energy.

00:23:22.460 --> 00:23:24.850
I mean, sort of
[INAUDIBLE] resolution,

00:23:24.850 --> 00:23:27.350
the relative tolerance in the
ODE solver in Matlab had to be

00:23:27.350 --> 00:23:29.570
something like negative--

00:23:29.570 --> 00:23:31.070
1 to the negative
ninth or something

00:23:31.070 --> 00:23:34.670
to make this thing
integrate and look

00:23:34.670 --> 00:23:37.280
like it had a flat line and
energy as it's just swinging

00:23:37.280 --> 00:23:39.980
around with zero torque.

00:23:39.980 --> 00:23:44.090
As a consequence, when
you discretize it,

00:23:44.090 --> 00:23:45.710
and you run your
optimal control which

00:23:45.710 --> 00:23:51.080
converges nicely on the
discretized system, the same--

00:23:51.080 --> 00:23:52.850
you can't discretize
it with sort of 10

00:23:52.850 --> 00:23:56.240
to the negative ninth precision.

00:23:56.240 --> 00:23:58.790
And you'll find that your
discretized system doesn't

00:23:58.790 --> 00:24:00.170
conserve energy, for instance.

00:24:00.170 --> 00:24:03.125
So that's what's one of
the major shortcomings.

00:24:29.360 --> 00:24:30.500
OK.

00:24:30.500 --> 00:24:33.607
And so for that reason I'm
going to move on in our--

00:24:33.607 --> 00:24:35.690
when we're going to talk
about the optimal control

00:24:35.690 --> 00:24:37.070
for the acrobot
and the cart-pole,

00:24:37.070 --> 00:24:39.028
we're actually going to
use some other methods.

00:24:39.028 --> 00:24:41.465
But I don't want to
move on without seeding

00:24:41.465 --> 00:24:43.340
the idea that there are
good ways-- there are

00:24:43.340 --> 00:24:45.080
ways to fix this, potentially.

00:24:47.850 --> 00:24:49.492
So for instance--

00:24:49.492 --> 00:24:51.200
I mean, I think there's
lots of good work

00:24:51.200 --> 00:24:54.440
to be done in sort of the
dynamic programming world.

00:24:54.440 --> 00:25:11.270
I think there are ideas
from discrete mechanics

00:25:11.270 --> 00:25:22.490
and from finite element methods,
where people have thought

00:25:22.490 --> 00:25:25.820
a lot about the consequences
of discretizing PDEs and trying

00:25:25.820 --> 00:25:28.180
to, for instance, conserve
quantities like energy.

00:25:31.380 --> 00:25:36.560
My guess is if someone had
some excitement or experience

00:25:36.560 --> 00:25:38.108
with these sort of
methods, I'd bet

00:25:38.108 --> 00:25:39.650
the next time I
teach the class I can

00:25:39.650 --> 00:25:42.440
say it works for the acrobot.

00:25:42.440 --> 00:25:47.240
So this would be a great
final project, yeah?

00:25:47.240 --> 00:25:48.567
And publication.

00:25:53.930 --> 00:25:57.590
Just do a smarter discretization
of the dynamics, and then

00:25:57.590 --> 00:25:58.580
sort of--

00:25:58.580 --> 00:26:00.500
so the discrete mechanics
philosophy is that

00:26:00.500 --> 00:26:09.470
if you've taken your Lagrangian,
and you've turned it into x dot

00:26:09.470 --> 00:26:14.540
equals f of x, u and then you
discretize, then you've done--

00:26:14.540 --> 00:26:15.770
you've already--

00:26:15.770 --> 00:26:16.500
it's too late.

00:26:16.500 --> 00:26:19.970
You've already killed the
beauty of the Lagrangian.

00:26:19.970 --> 00:26:28.310
And the discrete
mechanics point of view

00:26:28.310 --> 00:26:30.440
is you should discretize
the Lagrangian,

00:26:30.440 --> 00:26:36.860
do discretization up here,
and then carry that down

00:26:36.860 --> 00:26:38.420
to your equations of motion.

00:26:38.420 --> 00:26:41.000
And these sort of discrete
mechanics principles

00:26:41.000 --> 00:26:42.530
tend to have much
better properties

00:26:42.530 --> 00:26:47.265
and energy conservation
and stuff like that.

00:26:47.265 --> 00:26:49.640
We might get to it in our
trajectory optimization family,

00:26:49.640 --> 00:26:52.790
but there's a line
of work now called

00:26:52.790 --> 00:27:08.990
discrete mechanics and
optimal control that's

00:27:08.990 --> 00:27:14.840
been done by Marsden and
all at Caltech that I

00:27:14.840 --> 00:27:16.380
think that's my
best lead right now

00:27:16.380 --> 00:27:17.630
and how to fix these problems.

00:27:28.990 --> 00:27:29.490
OK.

00:27:29.490 --> 00:27:32.032
There's another idea out there
for how to fix these problems.

00:27:35.980 --> 00:27:39.040
If you judge your problem is
just that your discretization

00:27:39.040 --> 00:28:03.970
is bad, another big idea sort of
is variable resolution methods,

00:28:03.970 --> 00:28:05.470
which says, let's
stick to our guns,

00:28:05.470 --> 00:28:06.820
discretization is
going to work as long

00:28:06.820 --> 00:28:08.230
as I have enough resolution.

00:28:08.230 --> 00:28:10.180
And because of
computational limitations,

00:28:10.180 --> 00:28:12.180
I'm just going to make
sure I put the resolution

00:28:12.180 --> 00:28:14.410
in the right places.

00:28:14.410 --> 00:28:20.500
So if you discretize the
pendulum or something

00:28:20.500 --> 00:28:35.290
like this, when you do
your optimal control

00:28:35.290 --> 00:28:37.390
solution on this,
and you find out,

00:28:37.390 --> 00:28:41.410
for instance, that when you're
transitioning from this point--

00:28:41.410 --> 00:28:43.480
this way, energy
is not conserved.

00:28:43.480 --> 00:28:45.700
Or the value function
at these corners

00:28:45.700 --> 00:28:48.178
are very, very different.

00:28:48.178 --> 00:28:50.470
So it looks like there's
something more going on there,

00:28:50.470 --> 00:28:55.320
then let's just add more
resolution there, until--

00:28:55.320 --> 00:29:00.460
as much as necessary, sort
of, to capture the dynamics.

00:29:00.460 --> 00:29:09.921
There's a nice line of work
in this by Munos and Moore,

00:29:09.921 --> 00:29:11.800
the same people I
listed for doing

00:29:11.800 --> 00:29:13.870
the barycentric interpolation.

00:29:13.870 --> 00:29:17.800
They talked about variable
resolution DP methods.

00:29:17.800 --> 00:29:19.990
I think Woody thinks
that this is our--

00:29:19.990 --> 00:29:22.810
this is the way to
get value iteration

00:29:22.810 --> 00:29:26.890
to work on at least the minimum
time problem for the pendulum

00:29:26.890 --> 00:29:28.750
and for the brick--

00:29:28.750 --> 00:29:31.750
that if you use the right
splitting criteria--

00:29:31.750 --> 00:29:34.630
and that's the big question,
I think, in this work is,

00:29:34.630 --> 00:29:36.730
what's the right
splitting criteria--

00:29:41.650 --> 00:29:44.260
then you can actually
maybe make serious progress

00:29:44.260 --> 00:29:45.010
on these problems.

00:29:57.770 --> 00:29:58.270
OK.

00:29:58.270 --> 00:30:01.090
So I've given you
a line of thinking

00:30:01.090 --> 00:30:04.660
about one class of algorithms
dynamic programming.

00:30:04.660 --> 00:30:07.988
We showed how they could apply
to the pendulums and decided

00:30:07.988 --> 00:30:10.030
to not show how they don't
quite work beautifully

00:30:10.030 --> 00:30:11.860
for the acrobot/cart-pole.

00:30:11.860 --> 00:30:15.250
If I build an algorithm
that took overnight to run,

00:30:15.250 --> 00:30:16.360
then I think it works.

00:30:16.360 --> 00:30:19.220
But they don't run sort of
in real-time in the class,

00:30:19.220 --> 00:30:23.552
so let's leave it as
future work to make better

00:30:23.552 --> 00:30:25.510
to stay with programming
algorithms for pendula

00:30:25.510 --> 00:30:27.280
and acrobots.

00:30:27.280 --> 00:30:28.990
And I'm very, very
serious about this.

00:30:28.990 --> 00:30:31.790
These are not killer problems.

00:30:31.790 --> 00:30:35.140
These are problems that--

00:30:35.140 --> 00:30:37.870
I mean, these tools sort of
that you see in the class,

00:30:37.870 --> 00:30:41.350
I think, just really haven't
been put together before.

00:30:41.350 --> 00:30:45.430
I think that we're
lining up all the tools

00:30:45.430 --> 00:30:47.440
to solve these basic problems.

00:30:47.440 --> 00:30:49.600
I wish they were
all solved already.

00:30:49.600 --> 00:30:51.940
We've just got too many
problems and not enough time.

00:30:51.940 --> 00:30:57.160
But I mean, you could solve this
problem in your final project

00:30:57.160 --> 00:31:00.010
and make serious
contributions to the field.

00:31:00.010 --> 00:31:03.730
This is the state
that the field is in.

00:31:03.730 --> 00:31:04.630
OK, good.

00:31:13.820 --> 00:31:14.992
So change the world.

00:31:14.992 --> 00:31:16.700
Do that for your final
projects, ideally.

00:31:21.420 --> 00:31:23.780
That's where we've come from.

00:31:23.780 --> 00:31:26.700
Let's start thinking
about-- let me just bite off

00:31:26.700 --> 00:31:28.800
today the next big chunk, OK?

00:31:31.470 --> 00:31:33.570
You're going to
finish this class

00:31:33.570 --> 00:31:38.223
with sort of a Chinese menu of
tools that hopefully will help

00:31:38.223 --> 00:31:39.390
you solve all your problems.

00:32:03.610 --> 00:32:04.110
OK.

00:32:04.110 --> 00:32:07.560
So analytically and
computationally,

00:32:07.560 --> 00:32:09.390
there are two major
approaches to solving

00:32:09.390 --> 00:32:10.682
these optimal control problems.

00:32:21.630 --> 00:32:24.057
Let's even just say
computational optimal--

00:32:24.057 --> 00:32:25.140
numerical optimal control.

00:32:37.340 --> 00:32:45.220
The first one, like I said, is
you're trying to solve a PDE--

00:32:54.420 --> 00:32:56.100
Partial Differential Equation.

00:32:56.100 --> 00:32:59.440
The particular name is the
Hamilton-Jacobi-Bellman

00:32:59.440 --> 00:32:59.940
equation.

00:33:06.580 --> 00:33:07.990
But there is a second approach.

00:33:13.310 --> 00:33:20.460
The second approach is policy
search, direct policy search.

00:33:28.720 --> 00:33:34.090
Very much still is governed
by the partial differential

00:33:34.090 --> 00:33:36.910
equations of optimality.

00:33:36.910 --> 00:33:41.300
But the solution
technique is different.

00:33:41.300 --> 00:33:42.040
Here's the idea.

00:34:00.770 --> 00:34:03.702
Let's design not directly the--

00:34:03.702 --> 00:34:05.410
I mean, we've designed
our cost function.

00:34:05.410 --> 00:34:08.260
We have our cost function,
we have our dynamics.

00:34:08.260 --> 00:34:12.010
Let's not-- let's design a
family of control systems

00:34:12.010 --> 00:34:14.590
with a bunch of parameters, OK?

00:34:14.590 --> 00:34:20.703
So the policy search
methods define some class

00:34:20.703 --> 00:34:22.120
of feedback policies
that you care

00:34:22.120 --> 00:34:28.254
about that are parameterized
by some vector alpha.

00:34:55.880 --> 00:34:59.510
We define a class of
feedback policies.

00:34:59.510 --> 00:35:04.710
And then using the same exact
formulations we used before,

00:35:04.710 --> 00:35:12.620
where we used J to represent
the long-term cost of taking

00:35:12.620 --> 00:35:16.610
and starting with some initial
condition at some time,

00:35:16.610 --> 00:35:17.390
which could be--

00:35:32.005 --> 00:35:33.380
this is what I
wrote down before.

00:35:36.150 --> 00:35:38.270
Now I'm going to be
even more specific

00:35:38.270 --> 00:35:44.470
and say, let's make
J of alpha x0, t.

00:35:44.470 --> 00:35:46.820
I'm going to say it's a
function of the parameters.

00:35:46.820 --> 00:35:53.480
And I'm going to
say that u is now

00:35:53.480 --> 00:35:57.320
the cost of evaluating my
control system with parameters

00:35:57.320 --> 00:35:58.130
alpha.

00:35:58.130 --> 00:35:59.630
So it's a little
abstract right now,

00:35:59.630 --> 00:36:01.850
but let's make it concrete.

00:36:01.850 --> 00:36:04.360
So here's a couple of potential
parameterizations, right?

00:36:04.360 --> 00:36:07.250
So we talked about
the linear family

00:36:07.250 --> 00:36:13.760
of feedback policies,
linear feedback

00:36:13.760 --> 00:36:16.730
control with some
big matrix K. Well,

00:36:16.730 --> 00:36:20.030
that's a perfectly acceptable
policy parameterization.

00:36:20.030 --> 00:36:22.910
If I want to search over the
class of feedback policies

00:36:22.910 --> 00:36:24.830
that are linear
feedback policies,

00:36:24.830 --> 00:36:29.730
then I could call that
pi of alpha x of t.

00:36:29.730 --> 00:36:34.790
It just happens that that
control policy is alpha 1,

00:36:34.790 --> 00:36:41.840
alpha 2, alpha n times x.

00:36:45.120 --> 00:36:47.745
It's a perfectly reasonable
class of control policies.

00:37:18.760 --> 00:37:20.710
Actually, just to
throw it out there,

00:37:20.710 --> 00:37:23.920
it's probably a bad
choice, actually.

00:37:23.920 --> 00:37:28.510
Because I think people know
that even sort of LQR problems

00:37:28.510 --> 00:37:31.305
are not convex in
this parameterization.

00:37:31.305 --> 00:37:33.430
I haven't told you how
we're going to solve it yet,

00:37:33.430 --> 00:37:34.847
but let me just
throw out the fact

00:37:34.847 --> 00:37:38.020
that I think most sort
of serious control people

00:37:38.020 --> 00:37:40.330
wouldn't use this as a
representation to search over,

00:37:40.330 --> 00:37:44.080
because it turns out the
relationship to performance

00:37:44.080 --> 00:37:46.120
based on these parameters
is complicated.

00:37:46.120 --> 00:37:47.350
Maybe unnecessarily so.

00:37:50.152 --> 00:37:54.640
A much-- a very common
parameterization

00:37:54.640 --> 00:37:59.410
is sort of an open
loop control tape,

00:37:59.410 --> 00:38:10.720
I'll call it, where
in the simplest form,

00:38:10.720 --> 00:38:31.960
let's say u is just is that
a reasonable way to write it?

00:38:36.340 --> 00:38:39.880
And every time, I just--

00:38:39.880 --> 00:38:42.130
this would be a zero-order hold.

00:38:42.130 --> 00:38:44.800
And at any time, I just
find the closest sort

00:38:44.800 --> 00:38:48.070
of point in my control tape.

00:38:48.070 --> 00:38:51.490
And I'll put-- so I've
got alpha at time 1,

00:38:51.490 --> 00:38:54.130
I've got alpha at time 2, alpha
at time 3 just in the tape.

00:38:54.130 --> 00:38:57.400
And I just-- as I run my
policy, I ignore state, and just

00:38:57.400 --> 00:39:00.220
play out an open-loop tape.

00:39:00.220 --> 00:39:05.080
That's a perfectly valid
policy representation.

00:39:05.080 --> 00:39:09.355
Maybe a better one would be
something based on splines.

00:39:16.088 --> 00:39:18.130
Or even just a smoother
interpolation, maybe that

00:39:18.130 --> 00:39:21.040
could be better.

00:39:21.040 --> 00:39:25.970
People use things
like neural networks

00:39:25.970 --> 00:39:28.069
as policy representations.

00:39:32.470 --> 00:39:35.200
There's a lot of work on things
like radial basis functions.

00:39:43.840 --> 00:39:47.680
And in general, a lot of sort
of kernel methods in machine

00:39:47.680 --> 00:39:54.885
learning you can use sort of--

00:39:54.885 --> 00:39:56.260
the point of this
line is you can

00:39:56.260 --> 00:40:02.842
use general machine learning
function approximators.

00:40:17.120 --> 00:40:21.100
And those tend to be reasonable
policy representations, where

00:40:21.100 --> 00:40:22.843
maybe the weights in
the neural network,

00:40:22.843 --> 00:40:24.760
even if you don't know
what these things are--

00:40:24.760 --> 00:40:26.230
I'm actually going to do a
little bit of an introduction

00:40:26.230 --> 00:40:29.200
to function approximators once
we start using them heavily

00:40:29.200 --> 00:40:29.770
in class.

00:40:29.770 --> 00:40:33.108
But just from seeing the words,
even if you've never used one,

00:40:33.108 --> 00:40:34.900
you probably have a
sense that these things

00:40:34.900 --> 00:40:38.440
are sort of ways to
represent functions

00:40:38.440 --> 00:40:40.810
with a lot of parameters.

00:40:40.810 --> 00:40:45.940
And those are perfectly
good candidates.

00:40:45.940 --> 00:40:49.000
So the key idea
here is, if we're

00:40:49.000 --> 00:40:51.010
willing to parameterize
our control

00:40:51.010 --> 00:40:56.470
system with a class
of some parameters,

00:40:56.470 --> 00:41:01.750
some finite parameters, then
I can turn my optimal control

00:41:01.750 --> 00:41:05.620
problem into a simple
parameter search.

00:41:05.620 --> 00:41:09.820
In general now, if
I want to minimize--

00:41:26.490 --> 00:41:30.454
the problem is to
minimize over alpha,

00:41:30.454 --> 00:41:37.030
let's say J alpha from the
x0 I care about at time 0.

00:41:37.030 --> 00:41:41.860
I could describe J
through those equations,

00:41:41.860 --> 00:41:45.700
through some Matlab function,
let's say, and just say, find

00:41:45.700 --> 00:41:47.860
the minimum of this function.

00:41:47.860 --> 00:41:52.250
You can do it with sort
of fmin or various--

00:41:52.250 --> 00:41:55.330
any old tools from
nonlinear optimization.

00:42:28.410 --> 00:42:29.494
Seem reasonable?

00:42:32.168 --> 00:42:34.710
It's important to make sure we
understand why it's different,

00:42:34.710 --> 00:42:35.210
OK?

00:42:35.210 --> 00:42:37.950
So-- do I still have
this up on the board?

00:42:49.950 --> 00:42:53.253
AUDIENCE: Are these [INAUDIBLE]
approximators [INAUDIBLE]

00:42:53.253 --> 00:42:56.575
x as input and so y
is output [INAUDIBLE]??

00:43:00.190 --> 00:43:01.690
RUSS TEDRAKE:
Potentially x and time

00:43:01.690 --> 00:43:03.970
as an input and u as an output.

00:43:03.970 --> 00:43:06.040
You're trying to-- the
function approximators

00:43:06.040 --> 00:43:09.450
represent this function, right?

00:43:15.220 --> 00:43:19.180
They're mapping which depends
on parameters alpha from x and t

00:43:19.180 --> 00:43:20.680
in the general case to u.

00:43:29.670 --> 00:43:33.390
in many ways, this is
a very naive approach.

00:43:33.390 --> 00:43:36.750
The dynamic programming view
of the world is very beautiful.

00:43:36.750 --> 00:43:41.850
We turned our complicated
long-term optimization

00:43:41.850 --> 00:43:46.170
of this function into
a recursive form,

00:43:46.170 --> 00:43:48.060
where at each step
I only had to think

00:43:48.060 --> 00:43:51.150
about my instantaneous
control action.

00:43:51.150 --> 00:43:57.480
I did a min over u for that one
step, and that was end to end,

00:43:57.480 --> 00:44:01.050
if I could solve my value
function, then that was enough.

00:44:01.050 --> 00:44:05.640
I could use my value function to
turn my long-term optimization

00:44:05.640 --> 00:44:08.040
into a short-term
optimization, min over u.

00:44:11.580 --> 00:44:13.525
Tell me if I need to
say things differently.

00:44:16.380 --> 00:44:19.788
In many ways, this
is the dumb approach.

00:44:19.788 --> 00:44:22.330
We're not-- we're throwing away
the structure in the problem.

00:44:22.330 --> 00:44:27.360
We're just going to directly
search over parameters.

00:44:27.360 --> 00:44:31.080
The saving grace is
that I don't have to--

00:44:31.080 --> 00:44:33.450
the value function can
turn out to be a hard thing

00:44:33.450 --> 00:44:36.330
to represent, especially if--
with dynamic programming,

00:44:36.330 --> 00:44:40.110
I can't represented in
10 dimensions, let's say.

00:44:40.110 --> 00:44:43.020
So this dumb
approach can actually

00:44:43.020 --> 00:44:44.490
work in more
complicated systems.

00:44:47.470 --> 00:44:53.027
The only problem is it doesn't
guarantee global optimality.

00:45:39.290 --> 00:45:42.080
Like I said, in some ways
it's a very naive approach.

00:45:42.080 --> 00:45:46.298
It tends to scale better-- it's
not as sensitive explicitly

00:45:46.298 --> 00:45:47.840
to the dimensionality
of the problem.

00:46:01.100 --> 00:46:02.600
There's another
nice thing about it,

00:46:02.600 --> 00:46:09.920
which there's no explicit
need for discretization, which

00:46:09.920 --> 00:46:13.100
I told you was a big problem
in the dynamic programming

00:46:13.100 --> 00:46:15.680
thing-- except for there's
discretization potentially

00:46:15.680 --> 00:46:20.050
in the ODE sort of integrator.

00:46:26.960 --> 00:46:28.670
And that can make--

00:46:28.670 --> 00:46:31.049
we do know how to make
that arbitrarily accurate.

00:47:00.530 --> 00:47:04.931
The only real killer of these
methods is that they don't--

00:47:04.931 --> 00:47:07.040
they're very subject
to local minima.

00:47:07.040 --> 00:47:07.790
Yeah, please.

00:47:07.790 --> 00:47:09.980
AUDIENCE: This
function approximation,

00:47:09.980 --> 00:47:12.390
isn't it like discretization
of your state space?

00:47:12.390 --> 00:47:12.890
[INAUDIBLE]

00:47:12.890 --> 00:47:14.710
RUSS TEDRAKE: Not necessarily.

00:47:14.710 --> 00:47:17.140
AUDIENCE: I mean,
but you essentially--

00:47:17.140 --> 00:47:19.410
you don't have full control
[INAUDIBLE] available

00:47:19.410 --> 00:47:20.392
[INAUDIBLE].

00:47:23.042 --> 00:47:24.500
RUSS TEDRAKE: It's
a good question.

00:47:24.500 --> 00:47:28.270
So take the linear
feedback example.

00:47:28.270 --> 00:47:30.370
If I have a problem
that I know the--

00:47:30.370 --> 00:47:32.950
if I take an LQR problem and
I solve it with policy search,

00:47:32.950 --> 00:47:35.290
and I know the feedback
policy should exist

00:47:35.290 --> 00:47:37.270
in the class of linear
[INAUDIBLE] things,

00:47:37.270 --> 00:47:41.050
then I haven't lost anything
by doing an approximation.

00:47:41.050 --> 00:47:43.900
And in general,
these things are--

00:47:43.900 --> 00:47:45.700
so radial basic functions
have the feeling

00:47:45.700 --> 00:47:47.830
of similar to discretization.

00:47:47.830 --> 00:47:50.620
But some of them are much
smoother and much more

00:47:50.620 --> 00:47:53.290
continuous than these
hard discretizations.

00:47:53.290 --> 00:47:54.950
And the way that
you evaluate them,

00:47:54.950 --> 00:47:59.200
which is what's essential, is
you're still going to find--

00:47:59.200 --> 00:48:01.528
so if I evaluate the
system by literally

00:48:01.528 --> 00:48:03.820
taking my parameters of my
neural network, radial basis

00:48:03.820 --> 00:48:06.850
function, whatever,
running this function

00:48:06.850 --> 00:48:09.490
without any
discretization, then it'll

00:48:09.490 --> 00:48:11.585
give me an accurate
measurement of this function.

00:48:11.585 --> 00:48:13.210
Discretization comes
into the-- doesn't

00:48:13.210 --> 00:48:15.850
come into the evaluation
of the function.

00:48:15.850 --> 00:48:18.490
In dynamic programming,
it's fundamental.

00:48:18.490 --> 00:48:19.760
Discretization is right there.

00:48:19.760 --> 00:48:24.585
We always operate directly
under discretized system.

00:48:24.585 --> 00:48:26.710
So I do think these things
are much closer to being

00:48:26.710 --> 00:48:30.673
continuous solvers.

00:48:30.673 --> 00:48:32.090
You might say
another disadvantage

00:48:32.090 --> 00:48:37.670
is that it doesn't exploit
the recursion that we

00:48:37.670 --> 00:48:44.233
know to exist in the problem.

00:48:44.233 --> 00:48:45.650
So it sort of feels
like we should

00:48:45.650 --> 00:48:48.115
be able to use that
trick more generally.

00:48:48.115 --> 00:48:49.490
And a lot of times,
these methods

00:48:49.490 --> 00:48:51.990
are going to be the very naive
things which throw them away.

00:48:54.390 --> 00:48:58.027
AUDIENCE: You said DP requires
the discretized space?

00:49:00.830 --> 00:49:01.610
RUSS TEDRAKE: Yep.

00:49:01.610 --> 00:49:03.020
That's what I said.

00:49:03.020 --> 00:49:05.530
Do you disagree?

00:49:05.530 --> 00:49:07.470
AUDIENCE: [INAUDIBLE]
can be [INAUDIBLE]..

00:49:12.330 --> 00:49:14.790
RUSS TEDRAKE: Well, then I
would call that an approximate

00:49:14.790 --> 00:49:17.922
dynamic programming method,
which is-- these are the--

00:49:17.922 --> 00:49:19.380
it depends where
you draw the line.

00:49:19.380 --> 00:49:22.530
I'm going to talk about those
in the reinforcement learning

00:49:22.530 --> 00:49:23.892
part of the course.

00:49:23.892 --> 00:49:25.350
But the thing that
I think people--

00:49:25.350 --> 00:49:28.710
I think that we talked about,
which has guaranteed results

00:49:28.710 --> 00:49:30.690
for the discrete
system, which is sort

00:49:30.690 --> 00:49:33.270
of really dynamic
programming, discretization

00:49:33.270 --> 00:49:34.685
is exactly fundamental.

00:49:34.685 --> 00:49:36.560
So Alborz is pointing
out that actually there

00:49:36.560 --> 00:49:38.340
are people that use
function approximators

00:49:38.340 --> 00:49:39.540
in dynamic programming
algorithms.

00:49:39.540 --> 00:49:41.623
And we're going to talk
about those in the future.

00:49:41.623 --> 00:49:43.322
But they tend to be approximate.

00:49:43.322 --> 00:49:45.780
A lot of times, they have weaker
guarantees of convergence.

00:49:45.780 --> 00:49:47.572
But we'll talk about
those as they come up.

00:49:53.020 --> 00:49:55.600
OK, good.

00:49:55.600 --> 00:49:57.430
So now we have a
very simple problem.

00:49:57.430 --> 00:49:59.650
We've taken our
optimal control problem

00:49:59.650 --> 00:50:03.730
that we've thrown all
kinds of work into.

00:50:03.730 --> 00:50:05.420
And we've talked
about the recursion,

00:50:05.420 --> 00:50:07.090
we've talked about
the Bellman equation.

00:50:07.090 --> 00:50:09.070
And now we just said,
OK, might as well just

00:50:09.070 --> 00:50:10.750
think of it, that--

00:50:10.750 --> 00:50:13.540
if I run my robot with
three different parameters,

00:50:13.540 --> 00:50:16.180
I'm going to get three
different scores.

00:50:16.180 --> 00:50:19.000
If I literally take my acrobot
and I make the parameters

00:50:19.000 --> 00:50:27.670
all 1, then I'm going
to get some score

00:50:27.670 --> 00:50:29.950
for running that policy.

00:50:29.950 --> 00:50:32.950
If I change my parameters
so the third parameter is 2,

00:50:32.950 --> 00:50:34.145
I'll get a different score.

00:50:34.145 --> 00:50:35.770
And I'll get a
different score if I run

00:50:35.770 --> 00:50:37.020
a different set of parameters.

00:50:37.020 --> 00:50:39.730
I'm just going to run my trial
for, let's say, for 10 seconds

00:50:39.730 --> 00:50:41.450
with different
sets of parameters.

00:50:41.450 --> 00:50:46.540
And this is going to give
me some landscape, which

00:50:46.540 --> 00:50:48.740
is J of alpha.

00:50:48.740 --> 00:50:50.590
Now typically in
these problems, I'm

00:50:50.590 --> 00:50:53.290
going to be thinking
about optimizing it

00:50:53.290 --> 00:50:55.012
from a particular
initial condition.

00:50:55.012 --> 00:50:56.220
We can talk about later how--

00:50:56.220 --> 00:50:58.220
if you want to get around that.

00:50:58.220 --> 00:51:03.580
But this is just some
function J of alpha, right?

00:51:03.580 --> 00:51:06.550
So how do we
optimize J of alpha?

00:51:06.550 --> 00:51:09.400
Well, there's lots of good ways,
from nonlinear programming,

00:51:09.400 --> 00:51:12.340
from nonlinear optimization.

00:51:12.340 --> 00:51:16.240
What are some good ways to
find the minimum of J of alpha?

00:51:20.540 --> 00:51:23.460
Guess a lot of alphas,
that's one approach.

00:51:23.460 --> 00:51:24.700
Pick the smallest one.

00:51:24.700 --> 00:51:25.750
OK.

00:51:25.750 --> 00:51:27.880
AUDIENCE: You can
form J in a way which

00:51:27.880 --> 00:51:30.895
is, you can take [INAUDIBLE]
dynamics smooth then we

00:51:30.895 --> 00:51:32.060
can solve [INAUDIBLE].

00:51:32.060 --> 00:51:33.200
RUSS TEDRAKE: OK, good.

00:51:33.200 --> 00:51:37.520
So let's say I have
an initial guess at J,

00:51:37.520 --> 00:51:43.440
and I can actually compute
the derivative of J.

00:51:43.440 --> 00:51:45.900
Which I can always do, because
I could do it numerically

00:51:45.900 --> 00:51:48.870
if I wanted to, right?

00:51:48.870 --> 00:51:52.260
I can just evaluate it a bunch
of times to do it if I had to.

00:51:52.260 --> 00:51:55.800
But if I can compute dJ
d alpha, then that'll

00:51:55.800 --> 00:51:59.310
tell me that slope.

00:51:59.310 --> 00:52:03.900
And I could, for instance, do
gradient descent on that slope.

00:52:03.900 --> 00:52:06.390
I could do alpha--

00:52:06.390 --> 00:52:08.820
my second alpha that
I'm going to try

00:52:08.820 --> 00:52:11.160
is going to be my first alpha.

00:52:11.160 --> 00:52:15.990
I try minus some movement in
the direction of the gradient.

00:52:23.840 --> 00:52:29.330
I could take this,
estimate the gradient,

00:52:29.330 --> 00:52:33.590
and then take a motion that
moves me down the gradient,

00:52:33.590 --> 00:52:38.230
make a new update, move down
the gradient, make a new update.

00:52:38.230 --> 00:52:40.670
And eventually I'll
get to the minimum

00:52:40.670 --> 00:52:42.490
where the gradient
is equal to 0.

00:52:42.490 --> 00:52:44.240
How many people have
used gradient descent

00:52:44.240 --> 00:52:46.754
before in something?

00:52:46.754 --> 00:52:49.700
OK, good.

00:52:49.700 --> 00:52:54.590
So nobody actually does
that, I don't think, anymore.

00:52:54.590 --> 00:52:55.755
Because we have sort of--

00:52:55.755 --> 00:52:57.380
I mean, that's
absolutely the right way

00:52:57.380 --> 00:53:00.200
to think about things, and
gradient methods are critical.

00:53:00.200 --> 00:53:08.870
But you optimization theory
has gotten pretty good.

00:53:08.870 --> 00:53:11.960
So there's another way to do it.

00:53:11.960 --> 00:53:14.108
Let's say I had--

00:53:14.108 --> 00:53:16.679
I couldn't just-- I not only
compute the first derivative,

00:53:16.679 --> 00:53:18.846
but let's say I could compute
the second derivative.

00:53:39.770 --> 00:53:42.332
My initial guess here, that
could be the first derivative.

00:53:49.900 --> 00:53:51.833
And it could be the
second derivative.

00:53:55.780 --> 00:53:58.890
Then what could I do?

00:53:58.890 --> 00:54:00.550
AUDIENCE: Fit a parabola to it?

00:54:00.550 --> 00:54:01.390
RUSS TEDRAKE: Fit
a parabola to it?

00:54:01.390 --> 00:54:02.090
I didn't quite
hear what you said.

00:54:02.090 --> 00:54:02.947
Is that what you said, too?

00:54:02.947 --> 00:54:04.072
AUDIENCE: Steepest descent.

00:54:06.328 --> 00:54:07.370
RUSS TEDRAKE: Absolutely.

00:54:07.370 --> 00:54:10.370
Let's fit a quadratic
bowl to it, right?

00:54:10.370 --> 00:54:12.140
And actually, the
problem I did right now,

00:54:12.140 --> 00:54:14.223
probably the quadratic
bowl is a pretty good match

00:54:14.223 --> 00:54:18.140
to the real optimization.

00:54:18.140 --> 00:54:21.910
And why not move directly
to this point and then fix--

00:54:21.910 --> 00:54:26.355
find a new quadratic bowl and
move directly to that point.

00:54:26.355 --> 00:54:27.980
So this would be a
second-order method.

00:54:37.840 --> 00:54:38.420
OK.

00:54:38.420 --> 00:54:45.050
And so Newton-- a lot of people
call it the Newton method.

00:54:50.770 --> 00:54:53.360
Turns out it works just as well
in high-dimensional systems.

00:54:53.360 --> 00:54:55.510
If I have a bunch
of alphas, I can

00:54:55.510 --> 00:54:57.940
do these second-order methods.

00:54:57.940 --> 00:55:03.280
And doing this, in
general, is what

00:55:03.280 --> 00:55:05.564
is called sequential
quadratic programming.

00:55:21.226 --> 00:55:23.980
Yeah.

00:55:23.980 --> 00:55:25.750
And they tend to converge--

00:55:25.750 --> 00:55:27.880
there's an additional
cost, potentially,

00:55:27.880 --> 00:55:30.320
of computing that
second derivative.

00:55:30.320 --> 00:55:32.858
But you can do it by
remembering the past--

00:55:32.858 --> 00:55:34.525
the same way you can
remember your-- you

00:55:34.525 --> 00:55:37.480
can estimate your gradient by
remembering a couple of samples

00:55:37.480 --> 00:55:39.340
and just doing a
numerical gradient.

00:55:39.340 --> 00:55:40.990
You can remember a
couple of samples

00:55:40.990 --> 00:55:44.950
and compute the-- estimate
the second derivative.

00:55:44.950 --> 00:55:51.635
So I'd say probably the most
common method used right now--

00:55:51.635 --> 00:55:52.510
how could I say that?

00:55:52.510 --> 00:55:54.310
But one of the
very common methods

00:55:54.310 --> 00:55:59.350
is to try to compute these
analytically, because--

00:55:59.350 --> 00:56:01.840
I'll show you a good
way to compute those.

00:56:01.840 --> 00:56:03.400
And then these,
which could be put

00:56:03.400 --> 00:56:06.010
could be potentially
more trouble to compute,

00:56:06.010 --> 00:56:08.770
we'll just use sort of a
numerical secant method

00:56:08.770 --> 00:56:11.800
to collect our
second-order terms,

00:56:11.800 --> 00:56:15.940
and then use sequential
quadratic programming.

00:56:15.940 --> 00:56:19.210
The thing that makes sequential
quadratic programming

00:56:19.210 --> 00:56:23.170
better than sort of the
naive gradient descent

00:56:23.170 --> 00:56:24.550
is that it's faster.

00:56:24.550 --> 00:56:27.640
But the real thing is that
optimization theory is just

00:56:27.640 --> 00:56:28.880
this beautiful thing.

00:56:28.880 --> 00:56:35.410
Now I can take constraints
into account very simply.

00:56:35.410 --> 00:56:38.320
So let's say I have--

00:56:38.320 --> 00:56:41.260
this is sort of a crash
course in optimization theory.

00:56:41.260 --> 00:56:45.615
But I think you can say in a few
minutes most of the key ideas.

00:56:53.500 --> 00:56:55.390
I mean, to be fair,
most of the lectures

00:56:55.390 --> 00:56:59.110
we've had so far, you
could take an entire course

00:56:59.110 --> 00:57:00.880
on each one of those lectures.

00:57:00.880 --> 00:57:03.160
So pick your favorite,
take another course.

00:57:03.160 --> 00:57:05.467
But, you know, I think that's--

00:57:05.467 --> 00:57:07.300
I think it's useful to
have the courses that

00:57:07.300 --> 00:57:09.342
go over a lot of topics,
and that's what this is.

00:57:11.830 --> 00:57:14.500
So what happens if
I now have, if I

00:57:14.500 --> 00:57:21.640
want to minimize over
alpha J alpha subject

00:57:21.640 --> 00:57:25.530
to some constraint, let's say--

00:57:25.530 --> 00:57:26.530
I'll just call it--

00:57:26.530 --> 00:57:27.905
I'm running out
of letters here--

00:57:30.200 --> 00:57:31.840
A of x equals 0.

00:57:34.570 --> 00:57:38.650
We know how to formulate those
with Lagrange multipliers.

00:57:38.650 --> 00:57:41.560
But in general,
finding equality,

00:57:41.560 --> 00:57:44.050
solving for equalities,
that's just root finding.

00:57:44.050 --> 00:57:49.840
That's actually no more
difficult than finding

00:57:49.840 --> 00:57:51.340
minimals.

00:57:51.340 --> 00:57:55.270
I can use the same
Newton method to find--

00:57:55.270 --> 00:57:56.200
to do root finding.

00:58:00.250 --> 00:58:04.965
So if I have some constraint,
let's say, alpha--

00:58:04.965 --> 00:58:06.340
oh, that was a
really bad choice.

00:58:06.340 --> 00:58:10.750
Let's call this something
other than A. Let's just

00:58:10.750 --> 00:58:14.920
call it f of alpha, just
so I keep my dimensions

00:58:14.920 --> 00:58:16.480
in the same direction here.

00:58:22.760 --> 00:58:23.260
OK.

00:58:23.260 --> 00:58:24.052
If I want to find--

00:58:24.052 --> 00:58:25.930
I'd better make it go through 0.

00:58:31.210 --> 00:58:33.220
If I want to find the
zeros of that solution,

00:58:33.220 --> 00:58:36.490
I can use the same exact
gradient updates, right?

00:58:36.490 --> 00:58:39.940
I can define a zero
crossing if I have

00:58:39.940 --> 00:58:42.625
an initial guess at the system.

00:58:42.625 --> 00:58:46.570
I take the linearization, its'
going to give me a new guess

00:58:46.570 --> 00:58:47.637
for the zero point.

00:58:47.637 --> 00:58:49.720
I take the derivative
there, that'll get me close.

00:58:49.720 --> 00:58:51.470
That's the Newton
method for root finding.

00:59:01.580 --> 00:59:02.080
OK.

00:59:02.080 --> 00:59:06.460
So by knowing the gradients,
you could sort of simultaneously

00:59:06.460 --> 00:59:12.370
do minimization and root
finding to satisfy constraints.

00:59:12.370 --> 00:59:18.730
Long story short, if
you have a problem that

00:59:18.730 --> 00:59:24.130
has the form minimize
alpha subject--

00:59:24.130 --> 00:59:25.608
some function J of alpha--

00:59:25.608 --> 00:59:28.150
it's potentially nonlinear, but
you could take its gradients,

00:59:28.150 --> 00:59:29.680
let's say--

00:59:29.680 --> 00:59:38.050
subject to linear constraints,
equality constraints, or even

00:59:38.050 --> 00:59:45.840
inequality constraints, you
can just hand that these days

00:59:45.840 --> 00:59:47.385
to some nice solver--

00:59:57.360 --> 01:00:01.330
some sequential quadratic
programming solver.

01:00:01.330 --> 01:00:04.690
The one we use these days
in lab is called SNOPT--

01:00:07.930 --> 01:00:10.480
Sparse Nonlinear Optimization
Package something,

01:00:10.480 --> 01:00:12.140
I don't know.

01:00:12.140 --> 01:00:12.640
OK.

01:00:15.610 --> 01:00:18.550
So you could start solving
optimal control problems

01:00:18.550 --> 01:00:24.190
by literally saying, OK, if I
run this-- just telling it J,

01:00:24.190 --> 01:00:26.080
telling it the gradients
of J if you can.

01:00:26.080 --> 01:00:27.140
That'll make it faster.

01:00:27.140 --> 01:00:29.440
Even if you didn't, you
could just say, here's J,

01:00:29.440 --> 01:00:32.170
find me the minimum of
J. You hand it to SNOPT,

01:00:32.170 --> 01:00:35.530
it'll go ahead and
do a lot of work

01:00:35.530 --> 01:00:37.390
and come up with
the best J, which

01:00:37.390 --> 01:00:40.870
is going to be some minima
of this cost function.

01:00:40.870 --> 01:00:45.470
There's no guarantee that
it won't find this one.

01:00:45.470 --> 01:00:47.170
It's subject to local minima.

01:00:47.170 --> 01:00:51.610
But sequential quadratic
programming methods

01:00:51.610 --> 01:00:53.770
tend to be better
than gradient methods

01:00:53.770 --> 01:00:56.690
in avoiding local minima,
because, for instance,

01:00:56.690 --> 01:00:59.530
if I'm here and I estimate
the quadratic bowl, if I just

01:00:59.530 --> 01:01:01.780
take bigger steps,
then I tend to jump

01:01:01.780 --> 01:01:05.260
over some small local minima
that a gradient method might

01:01:05.260 --> 01:01:06.430
get caught in.

01:01:06.430 --> 01:01:09.910
So just experimentally,
people know

01:01:09.910 --> 01:01:13.253
a lot about how it works
on quadratic programs

01:01:13.253 --> 01:01:15.670
if they're actually-- if the
system is actually quadratic.

01:01:15.670 --> 01:01:17.950
If it's a nonlinear system
that you're approximating

01:01:17.950 --> 01:01:21.770
as quadratic programs, then
they sort of wave their hands,

01:01:21.770 --> 01:01:23.720
but it works really
well in practice.

01:01:23.720 --> 01:01:24.490
Yeah, OK?

01:01:27.040 --> 01:01:29.740
So we have a new way of solving
optimal control problems.

01:01:29.740 --> 01:01:32.853
Just write the function down in
a function that SNOPT can call.

01:01:32.853 --> 01:01:34.270
Give it a set of
parameters alpha,

01:01:34.270 --> 01:01:38.200
it'll churn away and find alpha.

01:01:38.200 --> 01:01:40.660
All that's left for
us to do in this class

01:01:40.660 --> 01:01:42.700
is figure out the best
way to hand it to SNOPT.

01:01:46.400 --> 01:01:48.920
We want to make SNOPT's
computation as effective

01:01:48.920 --> 01:01:49.520
as possible.

01:01:55.365 --> 01:01:57.240
And there's a lot of
different ways to do it.

01:02:13.060 --> 01:02:16.350
So the first way is literally
parameterize your control

01:02:16.350 --> 01:02:18.570
system, called SNOPT.

01:02:18.570 --> 01:02:21.420
But let's at least be smart
about computing the gradients.

01:02:21.420 --> 01:02:25.230
Let's avoid asking
our nonlinear solver

01:02:25.230 --> 01:02:28.350
to compute the gradients
for us numerically,

01:02:28.350 --> 01:02:31.620
because we can give you those
analytically, exploiting

01:02:31.620 --> 01:02:35.200
the structure in the
additive equations,

01:02:35.200 --> 01:02:38.850
the additive cost optimal
control equations.

01:02:38.850 --> 01:02:41.670
And as it turns out, it's a
direct and clear descendent

01:02:41.670 --> 01:02:46.510
from the Pontryagin
minimum principle, OK?

01:02:46.510 --> 01:02:48.600
So I'm going to show
you lots of examples

01:02:48.600 --> 01:02:51.120
of these things
working on Thursday.

01:02:51.120 --> 01:02:54.960
But I thought today,
let's just make

01:02:54.960 --> 01:02:59.580
sure that the basic idea of what
we're doing here comes through,

01:02:59.580 --> 01:03:03.420
this policy search, and show you
how to compute those gradients.

01:03:13.170 --> 01:03:15.730
In fact, let me just tell
you the result first.

01:03:15.730 --> 01:03:17.940
I think that works sometimes.

01:03:17.940 --> 01:03:24.060
OK, so given J--

01:03:33.680 --> 01:03:37.420
I'll just leave off that end
condition for now, the terminal

01:03:37.420 --> 01:03:38.365
condition.

01:03:51.440 --> 01:04:05.330
The goal is to compute
partial J x0 partial alpha.

01:04:05.330 --> 01:04:07.940
My claim is I can compute
that very efficiently

01:04:07.940 --> 01:04:10.880
by integrating the
system forward from 0

01:04:10.880 --> 01:04:15.290
to t backward from t to 0,
and then I'll get my gradient.

01:05:11.880 --> 01:05:13.110
OK.

01:05:13.110 --> 01:05:14.490
It integrates the
system forward,

01:05:14.490 --> 01:05:17.040
just like you would do it,
run any old simulation.

01:05:17.040 --> 01:05:20.325
But while you do it, keep
track of a few key variables.

01:05:57.430 --> 01:06:00.220
Similarly, g of x.

01:07:05.600 --> 01:07:06.100
It's.

01:07:56.750 --> 01:08:00.730
Anybody recognize that equation?

01:08:00.730 --> 01:08:02.750
It's written a little
bit different form, but.

01:08:09.666 --> 01:08:10.817
AUDIENCE: Filter equation?

01:08:10.817 --> 01:08:12.150
RUSS TEDRAKE: It's not a filter.

01:08:12.150 --> 01:08:15.240
Well, it could be interpreted as
a filter of something probably,

01:08:15.240 --> 01:08:15.740
but.

01:08:18.680 --> 01:08:22.340
It's an equation
we've seen before.

01:08:22.340 --> 01:08:23.330
AUDIENCE: Adjoint.

01:08:23.330 --> 01:08:26.010
RUSS TEDRAKE: It's the adjoint
equation from the Pontryagin.

01:08:26.010 --> 01:08:26.510
OK.

01:08:44.420 --> 01:08:44.920
OK.

01:08:47.770 --> 01:08:48.819
Then the gradients--

01:09:29.130 --> 01:09:29.729
OK.

01:09:29.729 --> 01:09:31.604
So I'm done writing for
a second, let's talk.

01:09:36.500 --> 01:09:40.760
Do you remember the story
from the Pontryagin?

01:09:44.210 --> 01:09:47.540
The derivation sketch
I did, we said that we

01:09:47.540 --> 01:09:48.770
had some functional, right?

01:09:48.770 --> 01:09:52.730
It was that if we change
our control actions,

01:09:52.730 --> 01:09:54.980
we want to make sure that
changing our control actions

01:09:54.980 --> 01:09:58.150
at all doesn't increase the--

01:09:58.150 --> 01:10:01.260
doesn't change the
constrained minimization of J

01:10:01.260 --> 01:10:04.850
subject to the constraints
of the dynamics.

01:10:04.850 --> 01:10:09.440
y, in that derivation turned out
to be the Lagrange multipliers

01:10:09.440 --> 01:10:12.780
that enforced the constraint.

01:10:12.780 --> 01:10:14.220
OK.

01:10:14.220 --> 01:10:17.700
What they did was
they put the system--

01:10:17.700 --> 01:10:21.060
by making sure that this
equation was satisfied

01:10:21.060 --> 01:10:24.240
and this equation
was satisfied, we

01:10:24.240 --> 01:10:26.970
made sure that we were
at a stationary point,

01:10:26.970 --> 01:10:32.160
at a minima of our functional,
our constrained functional,

01:10:32.160 --> 01:10:34.875
of our Lagrange
multiplier equation.

01:10:37.560 --> 01:10:38.610
OK.

01:10:38.610 --> 01:10:41.400
It's exactly the same
reason we're doing it here.

01:10:41.400 --> 01:10:47.250
We now have a functional which
depends on J. This functional

01:10:47.250 --> 01:10:49.080
J, the Lagrange
multiplier functional.

01:10:49.080 --> 01:10:50.622
And the derivations
are in the notes.

01:10:50.622 --> 01:10:52.200
I won't do it again.

01:10:52.200 --> 01:10:54.890
By going backwards, by
going-- integrating forward,

01:10:54.890 --> 01:10:57.810
we ensure that this
constraint is satisfied.

01:10:57.810 --> 01:10:59.390
By integrating
backwards, we solve

01:10:59.390 --> 01:11:01.170
for the Lagrange multiplier.

01:11:01.170 --> 01:11:03.870
What we're left
with is we can now,

01:11:03.870 --> 01:11:06.930
since the gradient with respect
to Lagrange multipliers is 0,

01:11:06.930 --> 01:11:09.960
the gradient with respect to
the state equations are 0,

01:11:09.960 --> 01:11:12.120
the only thing left is
the gradient with respect

01:11:12.120 --> 01:11:15.870
to the parameters alpha.

01:11:15.870 --> 01:11:19.210
And it turns out to be this
sort of very simple equation.

01:11:19.210 --> 01:11:22.620
So it's this beautiful
thing right that actually--

01:11:22.620 --> 01:11:24.357
I hope this is--

01:11:24.357 --> 01:11:26.190
it's a lot to write on
the board real quick,

01:11:26.190 --> 01:11:29.460
but it's actually a pretty
straightforward algorithm

01:11:29.460 --> 01:11:32.010
for computing the
gradients, efficiently

01:11:32.010 --> 01:11:35.400
computing the gradients
partial J partial alpha.

01:11:35.400 --> 01:11:38.310
All I have to do is
simulate the system forward,

01:11:38.310 --> 01:11:41.370
simulate this gradient
equation backwards,

01:11:41.370 --> 01:11:45.820
and I'm left with a
direct function alpha, OK?

01:11:50.200 --> 01:11:53.560
How many people have worked
with neural networks before?

01:11:53.560 --> 01:11:56.320
Yeah?

01:11:56.320 --> 01:11:57.970
OK.

01:11:57.970 --> 01:12:00.290
Well, this is the
back propagation.

01:12:00.290 --> 01:12:02.960
This is the back propagation
algorithm for neural networks.

01:12:02.960 --> 01:12:05.140
Turns out to be
exactly the same.

01:12:05.140 --> 01:12:07.030
This is the continuous
time form of it.

01:12:07.030 --> 01:12:09.170
People have worked
on it and back

01:12:09.170 --> 01:12:11.920
prop through time for
recurrent neural networks.

01:12:11.920 --> 01:12:15.603
But the exact way-- the
reason the back propagation--

01:12:15.603 --> 01:12:17.770
so there was this revolution
in the mid '80s about--

01:12:17.770 --> 01:12:19.510
that basically
suddenly, everybody

01:12:19.510 --> 01:12:23.320
said neural networks
will solve any problem.

01:12:23.320 --> 01:12:26.182
some People still
say that today.

01:12:26.182 --> 01:12:27.640
The thing-- the
only thing, really,

01:12:27.640 --> 01:12:31.480
that happened, I think,
from my point of view,

01:12:31.480 --> 01:12:33.940
is that somebody came up
with an efficient algorithm

01:12:33.940 --> 01:12:39.250
for computing the gradients
of the neural network weights

01:12:39.250 --> 01:12:42.190
as a function of the
input/output data.

01:12:42.190 --> 01:12:45.152
It's exactly this idea that you
can march the system forward

01:12:45.152 --> 01:12:46.360
and then integrate backwards.

01:12:46.360 --> 01:12:48.310
In that case through
a big neural network,

01:12:48.310 --> 01:12:51.820
you had to integrate
these equations backwards.

01:12:51.820 --> 01:12:54.640
Being able to compute
those gradients faster

01:12:54.640 --> 01:12:56.260
was enough that
the world started

01:12:56.260 --> 01:12:58.390
saying neural networks
are going to match

01:12:58.390 --> 01:13:01.050
the computational
intelligence of the brain

01:13:01.050 --> 01:13:05.240
and solve AI and
all these things.

01:13:05.240 --> 01:13:07.330
So it's a little dry, maybe.

01:13:07.330 --> 01:13:09.430
But this is potentially
very enabling

01:13:09.430 --> 01:13:11.590
to be able to compute
gradients efficiently.

01:13:14.197 --> 01:13:16.030
It could change what
problems you can solve.

01:13:18.750 --> 01:13:19.360
OK.

01:13:19.360 --> 01:13:22.480
Are people OK with the big
picture of where things are?

01:13:22.480 --> 01:13:23.830
Yeah?

01:13:23.830 --> 01:13:24.560
Good.

01:13:24.560 --> 01:13:28.030
So on Thursday, I'm
going to show you,

01:13:28.030 --> 01:13:30.970
now that we know how to compute
the gradients efficiently,

01:13:30.970 --> 01:13:32.950
I'm going to show
you this put to work,

01:13:32.950 --> 01:13:35.500
the intuition of sort
of changing a policy,

01:13:35.500 --> 01:13:38.080
searching in policy space
to solve problems like

01:13:38.080 --> 01:13:43.120
the acrobot/cart-pole,
and some simpler examples.

01:13:43.120 --> 01:13:46.810
And the dumb idea
is, let's just make

01:13:46.810 --> 01:13:49.060
it a straight,
nonlinear optimization

01:13:49.060 --> 01:13:50.620
problem over alpha.

01:13:50.620 --> 01:13:52.780
And I'll try to help
you compare and contrast

01:13:52.780 --> 01:13:56.800
the way that works compared
to the dynamic programming.

01:13:56.800 --> 01:13:58.560
See you then.