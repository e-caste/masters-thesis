WEBVTT

00:00:00.000 --> 00:00:02.430
The following content is
provided under a Creative

00:00:02.430 --> 00:00:03.730
Commons license.

00:00:03.730 --> 00:00:06.060
Your support will help
MIT OpenCourseWare

00:00:06.060 --> 00:00:10.090
continue to offer high-quality
educational resources for free.

00:00:10.090 --> 00:00:12.690
To make a donation or to
view additional materials

00:00:12.690 --> 00:00:16.560
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.560 --> 00:00:17.744
at ocw.mit.edu.

00:00:25.750 --> 00:00:28.410
BO MADSEN: Continuous
process improvement--

00:00:28.410 --> 00:00:30.160
we're going to need
some improvement here.

00:00:30.160 --> 00:00:34.330
Can we agree on that, or
did it flow seamlessly?

00:00:34.330 --> 00:00:37.510
You're happy?

00:00:37.510 --> 00:00:41.080
Maybe it feels like something
you're already used to so hard

00:00:41.080 --> 00:00:43.450
to see the difference.

00:00:43.450 --> 00:00:46.960
So at the end of
this, you should

00:00:46.960 --> 00:00:52.360
recognize the PDSA or PDCA--

00:00:52.360 --> 00:00:54.860
Plan-Do-Study-Act
some of your notes.

00:00:54.860 --> 00:00:56.710
I think say, Plan-Do-Check-Act.

00:00:59.370 --> 00:01:01.630
It really, it is the same.

00:01:01.630 --> 00:01:04.440
We just like the study
better than the checking.

00:01:04.440 --> 00:01:06.870
And because you need to see--

00:01:06.870 --> 00:01:10.000
follow up on what your
changes they actually mean.

00:01:10.000 --> 00:01:11.460
We'll get to that.

00:01:11.460 --> 00:01:13.650
A bit about A3
thinking-- and there's

00:01:13.650 --> 00:01:16.200
a lot more about that tomorrow.

00:01:16.200 --> 00:01:23.190
But it is an effective
improvement process approaches.

00:01:23.190 --> 00:01:27.510
And you should be able to use
a framework, continuous process

00:01:27.510 --> 00:01:30.660
improvement framework for
bettering your system.

00:01:30.660 --> 00:01:33.240
You should be able to
apply the value stream

00:01:33.240 --> 00:01:36.240
mapping did a little bit
about that yesterday.

00:01:36.240 --> 00:01:38.520
I know it was short, and
you'll do some more now,

00:01:38.520 --> 00:01:43.290
so it should help you get that
concept more under the skin.

00:01:43.290 --> 00:01:46.660
And then we'll do some root
cause analysis as well.

00:01:46.660 --> 00:01:50.610
And we talked about the
five whys yesterday.

00:01:50.610 --> 00:01:52.620
We'll get into that more now.

00:01:52.620 --> 00:01:56.160
So what is it this
Plan-Do-Study-Act?

00:01:56.160 --> 00:02:01.620
Well, it's something that we
use because for improvement.

00:02:01.620 --> 00:02:05.250
And you use it as a
problem-solving tool.

00:02:05.250 --> 00:02:07.590
And you use it as something
that will give you

00:02:07.590 --> 00:02:12.180
an overview of what you're doing
now, how you plan your changes,

00:02:12.180 --> 00:02:14.880
and then actually
doing those changes,

00:02:14.880 --> 00:02:18.080
and remembering to
follow up on it.

00:02:18.080 --> 00:02:21.930
It's also so that we try to
solve problems in the same way.

00:02:21.930 --> 00:02:25.590
Because that way, it's
easier to integrate work

00:02:25.590 --> 00:02:26.830
in the organization.

00:02:26.830 --> 00:02:30.390
And instead of working in silos,
you can work across everybody.

00:02:30.390 --> 00:02:32.560
It's using the same methodology.

00:02:32.560 --> 00:02:37.260
The A3 thinking is built
on the same as well.

00:02:37.260 --> 00:02:42.510
So A3 thinking-- collaborative
problem-solving approach--

00:02:42.510 --> 00:02:46.170
and it gives us a
logical approach

00:02:46.170 --> 00:02:49.540
to how to solve problems.

00:02:49.540 --> 00:02:53.250
It tells you something
about where are we now?

00:02:53.250 --> 00:02:56.100
What is the strategy
of our organization?

00:02:56.100 --> 00:02:58.620
Where is it that we want to go?

00:02:58.620 --> 00:03:00.600
And how do we plan to go there?

00:03:03.760 --> 00:03:06.850
Do you know what A3 stands for?

00:03:06.850 --> 00:03:07.790
AUDIENCE: Paper size.

00:03:07.790 --> 00:03:08.998
BO MADSEN: It's a paper size.

00:03:08.998 --> 00:03:11.940
Yeah, exactly--
you know A4 paper?

00:03:11.940 --> 00:03:14.360
So in Europe, we don't
use the letter form.

00:03:14.360 --> 00:03:17.570
We have something called
A4, double-size A4,

00:03:17.570 --> 00:03:21.560
it's double-size
letter is an A3.

00:03:21.560 --> 00:03:27.620
So A3 thinking is your plan
for improving something

00:03:27.620 --> 00:03:29.900
that fits within an A3 size.

00:03:29.900 --> 00:03:33.530
So it forces you
to be very concise.

00:03:33.530 --> 00:03:38.090
You can't go on rambling about
this, that, or the other.

00:03:38.090 --> 00:03:40.610
Because there's
simply no room for it.

00:03:40.610 --> 00:03:44.160
And it does fit
within that size--

00:03:44.160 --> 00:03:46.380
takes a little bit
of practice, maybe.

00:03:46.380 --> 00:03:47.460
But it does.

00:03:47.460 --> 00:03:52.870
And again, what is
so important about it

00:03:52.870 --> 00:03:57.690
is is well, if everybody in
your organization is using this,

00:03:57.690 --> 00:03:58.920
you can collaborate.

00:03:58.920 --> 00:04:01.140
Because that your partners--

00:04:01.140 --> 00:04:03.750
they are thinking
the same way as you

00:04:03.750 --> 00:04:08.120
are, which is really important.

00:04:08.120 --> 00:04:11.810
If you think about it, how
it is now in many places,

00:04:11.810 --> 00:04:14.810
people-- they solve
problems totally different.

00:04:14.810 --> 00:04:20.060
Some departments they have a
chair, who's maybe a dictator.

00:04:20.060 --> 00:04:23.540
This is a problem, this
is how you'll fix it.

00:04:23.540 --> 00:04:25.250
Others say OK, let's sit down.

00:04:25.250 --> 00:04:26.810
Let's think about
how we can do this.

00:04:26.810 --> 00:04:29.192
And you brainstorm,
and maybe you

00:04:29.192 --> 00:04:31.400
come up with who does what,
or maybe you just come up

00:04:31.400 --> 00:04:33.775
with a lot of ideas that are
sitting there and collecting

00:04:33.775 --> 00:04:35.510
dust.

00:04:35.510 --> 00:04:37.280
But this gives you
really a platform

00:04:37.280 --> 00:04:39.410
to do it the same way--

00:04:39.410 --> 00:04:42.080
everybody, which is nice.

00:04:42.080 --> 00:04:49.610
And part of that in this A3
thinking or your plan here is

00:04:49.610 --> 00:04:52.130
the Plan-Do-Study-Act.

00:04:52.130 --> 00:04:58.580
It is a piece of how you solve
problems and improve processes.

00:04:58.580 --> 00:05:01.110
But it's only a piece of it.

00:05:01.110 --> 00:05:06.820
It is not the
answer-all questions.

00:05:06.820 --> 00:05:08.570
So don't take it as such.

00:05:08.570 --> 00:05:15.580
So for the continuous process
improvement, the framework

00:05:15.580 --> 00:05:17.350
here, there are
a number of steps

00:05:17.350 --> 00:05:22.510
we will get through them
as we go along here.

00:05:22.510 --> 00:05:26.970
But first, do we
perceive the problem?

00:05:26.970 --> 00:05:30.050
Do we understand
what the problem is?

00:05:30.050 --> 00:05:33.510
That's important before you
start improving anything,

00:05:33.510 --> 00:05:35.040
you know what they say.

00:05:35.040 --> 00:05:41.880
So all improvement is a change,
not all change is improvement.

00:05:41.880 --> 00:05:45.020
So you need to find out
what your problem is

00:05:45.020 --> 00:05:47.450
to improve the right thing.

00:05:47.450 --> 00:05:53.210
So you need to grasp
the current situation.

00:05:53.210 --> 00:05:55.360
How do you do that?

00:05:55.360 --> 00:05:59.802
How is it we find out what
the current situation is?

00:05:59.802 --> 00:06:01.712
AUDIENCE: [INTERPOSING VOICES]

00:06:01.712 --> 00:06:02.670
BO MADSEN: You observe.

00:06:02.670 --> 00:06:03.833
Where do you observe?

00:06:03.833 --> 00:06:04.500
AUDIENCE: Gemba.

00:06:04.500 --> 00:06:06.840
BO MADSEN: In Gemba--

00:06:06.840 --> 00:06:10.200
where the actual people
do the actual work

00:06:10.200 --> 00:06:12.090
in the actual place.

00:06:12.090 --> 00:06:14.970
There you go--
the three actuals.

00:06:14.970 --> 00:06:17.290
Value stream
mapping-- so I said,

00:06:17.290 --> 00:06:18.720
we did a little bit yesterday.

00:06:18.720 --> 00:06:21.090
So we need to find out
what our value streams are.

00:06:21.090 --> 00:06:24.600
Have we mapped the
end-to-end processes here--

00:06:24.600 --> 00:06:26.370
the information flow?

00:06:26.370 --> 00:06:28.230
Do we know that right now?

00:06:28.230 --> 00:06:31.410
After our little
simulation exercise here?

00:06:31.410 --> 00:06:33.300
We have an idea about it.

00:06:33.300 --> 00:06:36.450
My perspective sitting
over at table three here

00:06:36.450 --> 00:06:39.090
was that the information
flow was maybe

00:06:39.090 --> 00:06:44.110
what we had the most difficulty
with finding out where--

00:06:44.110 --> 00:06:45.240
how that is connected.

00:06:45.240 --> 00:06:48.810
I don't know how-- what
was your experience here?

00:06:48.810 --> 00:06:52.290
Was it the physical
flow of location?

00:06:52.290 --> 00:06:54.160
Or was it more information flow?

00:06:54.160 --> 00:06:55.530
AUDIENCE: Information flow.

00:06:55.530 --> 00:06:57.030
BO MADSEN: Yeah,
so maybe that would

00:06:57.030 --> 00:06:59.580
be valuable to find
out about that.

00:06:59.580 --> 00:07:03.420
And then, you add
on the process data.

00:07:03.420 --> 00:07:05.700
Also, like we talked
about yesterday,

00:07:05.700 --> 00:07:08.340
add on things that will give
you valuable information.

00:07:08.340 --> 00:07:12.390
But don't clutter it with all
information under the sun.

00:07:12.390 --> 00:07:13.890
Because it ain't
going to be useful,

00:07:13.890 --> 00:07:16.182
and you won't have space for
it if you do it on your A3

00:07:16.182 --> 00:07:17.220
as well.

00:07:17.220 --> 00:07:20.400
So you need to think about what
metrics represent the system

00:07:20.400 --> 00:07:21.630
performance--

00:07:21.630 --> 00:07:25.800
wait time, throughput time,
financial performance.

00:07:25.800 --> 00:07:29.610
So not so much
talking from here--

00:07:29.610 --> 00:07:32.790
15-minute exercise.

00:07:32.790 --> 00:07:38.880
Develop your process map
as it looks right now,

00:07:38.880 --> 00:07:41.460
not the anticipated
future state.

00:07:41.460 --> 00:07:44.580
But what does it
look like right now?

00:07:44.580 --> 00:07:47.460
Write your process
steps on your Post-its.

00:07:47.460 --> 00:07:50.130
You have the easels that
you can put them up on.

00:07:50.130 --> 00:07:52.530
And you can connect them.

00:07:52.530 --> 00:07:58.680
And just before you
start, add the decisions--

00:07:58.680 --> 00:08:02.730
the waits, the holds,
and the inventories.

00:08:02.730 --> 00:08:03.960
Are there pileups?

00:08:03.960 --> 00:08:05.560
And look at this one.

00:08:05.560 --> 00:08:06.810
That's how you can look at it.

00:08:06.810 --> 00:08:11.790
Inventory or awaiting--
triangles, task, rectangles,

00:08:11.790 --> 00:08:12.330
burst--

00:08:12.330 --> 00:08:13.740
if there are issues--

00:08:13.740 --> 00:08:18.580
diamonds, decision points.

00:08:18.580 --> 00:08:19.650
Try to do that.

00:08:19.650 --> 00:08:22.350
You have 15 minutes
so quarter past 11.

00:08:22.350 --> 00:08:25.110
HUGH MCMANUS: So this exercise
is just like yesterday.

00:08:25.110 --> 00:08:29.670
You should be writing
at kind of the exam

00:08:29.670 --> 00:08:36.210
or whatever the single sticky
per process level on these.

00:08:36.210 --> 00:08:41.250
Do them first then the
inventory and decisions.

00:08:41.250 --> 00:08:44.070
And when you're quite satisfied
with all that on the stickies

00:08:44.070 --> 00:08:47.460
and you have [INAUDIBLE]
then tie them together

00:08:47.460 --> 00:08:49.170
with the matches.

00:08:49.170 --> 00:08:54.892
[INTERPOSING VOICES]

00:08:54.892 --> 00:08:58.380
SPEAKER 1: The only reason
it would go in a discharge

00:08:58.380 --> 00:09:00.162
is if they've already
been to the lab.

00:09:00.162 --> 00:09:01.620
I guess put that
there too, though.

00:09:01.620 --> 00:09:03.240
Because it's an option.

00:09:03.240 --> 00:09:05.052
SPEAKER 2: So make it
a little different--

00:09:05.052 --> 00:09:06.510
SPEAKER 3: Just
make these in pink.

00:09:06.510 --> 00:09:09.240
SPEAKER 2: This has
to come back here.

00:09:09.240 --> 00:09:11.010
SPEAKER 3: Right,
But then failed

00:09:11.010 --> 00:09:12.577
has to go back there too.

00:09:12.577 --> 00:09:14.910
SPEAKER 4: I think we need
another decision point here--

00:09:14.910 --> 00:09:16.540
if previous tests.

00:09:16.540 --> 00:09:18.082
So if there was a
failed test then it

00:09:18.082 --> 00:09:21.357
would have to go back to here
because of [? positive ?] test.

00:09:21.357 --> 00:09:22.440
And they've already been--

00:09:22.440 --> 00:09:22.950
SPEAKER 5: You can go like--

00:09:22.950 --> 00:09:24.492
SPEAKER 4: they go
back to discharge.

00:09:24.492 --> 00:09:26.310
SPEAKER 5: We can go
test results here.

00:09:26.310 --> 00:09:31.140
HUGH MCMANUS: OK, So
everybody's gotten pretty close.

00:09:31.140 --> 00:09:33.930
They're still tweaking some
stuff and realizing that when

00:09:33.930 --> 00:09:36.900
you try to map out this process,
although it seems fairly

00:09:36.900 --> 00:09:38.880
simple, it isn't.

00:09:38.880 --> 00:09:41.130
It's kind of
complicated, and it's

00:09:41.130 --> 00:09:43.350
complicated a couple of
different dimensions.

00:09:43.350 --> 00:09:46.110
What I'd like to start
with is just to have--

00:09:46.110 --> 00:09:49.403
why don't we start with you
folks briefing your map, just

00:09:49.403 --> 00:09:50.820
real quick because
everybody knows

00:09:50.820 --> 00:09:53.700
the process they've got the
same one, just brief how

00:09:53.700 --> 00:09:55.080
you mapped it.

00:09:55.080 --> 00:09:57.342
If you could do that.

00:09:57.342 --> 00:09:58.290
SPEAKER 6: Go ahead.

00:09:58.290 --> 00:10:01.140
SPEAKER 1: OK.

00:10:01.140 --> 00:10:02.910
So we put our three
big decision points

00:10:02.910 --> 00:10:06.960
made by triage, the MD, and
lab as these green diamonds.

00:10:06.960 --> 00:10:08.730
And then instead of
having a waiting room,

00:10:08.730 --> 00:10:11.310
we treated all of
the wait times with

00:10:11.310 --> 00:10:14.250
these upside-down triangles.

00:10:14.250 --> 00:10:15.510
HUGH MCMANUS: So that's nice.

00:10:15.510 --> 00:10:16.875
It's functional.

00:10:16.875 --> 00:10:18.750
There's a couple--
there's one thing that you

00:10:18.750 --> 00:10:21.240
sort of abstracted, which is
that issue of everything going

00:10:21.240 --> 00:10:24.690
back to the waiting room, which
you distributed, which is fine.

00:10:24.690 --> 00:10:26.020
You have to make that decision.

00:10:26.020 --> 00:10:28.208
But you've sort of
abstracted that.

00:10:28.208 --> 00:10:30.000
And the other thing,
of course, is the fact

00:10:30.000 --> 00:10:32.730
that there's a dependency.

00:10:32.730 --> 00:10:37.230
The lab results often affect
what the MD has to decide.

00:10:37.230 --> 00:10:39.100
So there's an
additional complication,

00:10:39.100 --> 00:10:41.310
which isn't captured at
this level of detail.

00:10:41.310 --> 00:10:42.630
You could capture it.

00:10:42.630 --> 00:10:47.590
But it would essentially be
more detail on the decision.

00:10:47.590 --> 00:10:49.470
[INTERPOSING VOICES]

00:10:51.330 --> 00:10:53.780
HUGH MCMANUS: We're
just multiple decisions

00:10:53.780 --> 00:10:54.780
that the MD has to make.

00:10:54.780 --> 00:10:56.370
Has this patient been seen?

00:10:56.370 --> 00:10:59.097
Did they fail their
lab tests, et cetera.

00:10:59.097 --> 00:11:00.930
Did they get a positive
result, because that

00:11:00.930 --> 00:11:02.370
affects where things go.

00:11:02.370 --> 00:11:04.110
That's cool, so
now let's have you

00:11:04.110 --> 00:11:09.351
folks just by way of contrast,
tell us your strategy

00:11:09.351 --> 00:11:14.222
for plotting out the
value [INAUDIBLE]..

00:11:14.222 --> 00:11:15.930
SPEAKER 7: So we have
the different tasks

00:11:15.930 --> 00:11:17.347
that people have
to do, which were

00:11:17.347 --> 00:11:21.770
all in green, so scheduling,
registration, triage,

00:11:21.770 --> 00:11:22.780
et cetera.

00:11:22.780 --> 00:11:24.570
But what we
represented the waiting

00:11:24.570 --> 00:11:26.910
room as a physical location.

00:11:26.910 --> 00:11:28.920
So it was like a mix
between that spaghetti

00:11:28.920 --> 00:11:31.336
chart and the downstream map--

00:11:31.336 --> 00:11:33.751
so basically in between
every single task

00:11:33.751 --> 00:11:35.860
they have to go back
to the waiting room.

00:11:35.860 --> 00:11:38.610
And so we are also
didn't quite finish,

00:11:38.610 --> 00:11:42.210
but we try to have
the dependency.

00:11:42.210 --> 00:11:44.220
If the test result
is negative, you

00:11:44.220 --> 00:11:46.380
go back to the waiting
room, and then discharge.

00:11:46.380 --> 00:11:49.080
If positive, then
something else [INAUDIBLE]..

00:11:49.080 --> 00:11:53.280
And then the MD has to decide
based on the previous test,

00:11:53.280 --> 00:11:54.060
what to do.

00:11:56.920 --> 00:11:59.742
AUDIENCE: They also start
with times [INAUDIBLE]..

00:11:59.742 --> 00:12:01.950
HUGH MCMANUS: That's kind
of our next step, actually,

00:12:01.950 --> 00:12:04.185
so they're ahead of
the game as usual.

00:12:04.185 --> 00:12:05.310
This table is good at that.

00:12:05.310 --> 00:12:07.140
So you guys can
finish up your traces.

00:12:07.140 --> 00:12:09.240
But here, they're taking
a more physical approach.

00:12:09.240 --> 00:12:11.220
And the maps capture
different things.

00:12:11.220 --> 00:12:14.547
This, it's sort of hard to
see the flows and decisions.

00:12:14.547 --> 00:12:17.130
Because everything's going back
and forth to the waiting room.

00:12:17.130 --> 00:12:20.100
So it provides a sort of
a visual confusion factor.

00:12:20.100 --> 00:12:22.918
But maybe, the issue
is that everything's

00:12:22.918 --> 00:12:24.210
going back to the waiting room.

00:12:24.210 --> 00:12:25.890
Maybe that's like
an issue that we

00:12:25.890 --> 00:12:28.830
need to deal with, because
that is obviously, confusing.

00:12:28.830 --> 00:12:31.770
It also has an awful lot
of waste of motion in there

00:12:31.770 --> 00:12:35.430
with the poor patient and
the potential for confusion

00:12:35.430 --> 00:12:37.090
that that engenders.

00:12:37.090 --> 00:12:39.540
And I can see your strategy
although you didn't finish

00:12:39.540 --> 00:12:42.870
that there's actually
individual paths here, which

00:12:42.870 --> 00:12:44.670
are going to get more
complicated as we get

00:12:44.670 --> 00:12:46.830
the failed diagnostics,
where maybe you could use

00:12:46.830 --> 00:12:51.790
a different color to trace
the extra ones [? too. ?]

00:12:51.790 --> 00:12:54.840
So you can follow it,
but it's a bit torturous,

00:12:54.840 --> 00:12:58.080
but it does capture certainly
the chaos of the system

00:12:58.080 --> 00:12:59.040
quite nicely.

00:12:59.040 --> 00:13:04.122
So why don't we finish here
and see what you guys have?

00:13:04.122 --> 00:13:05.580
You want to say
something about it?

00:13:05.580 --> 00:13:08.520
[INTERPOSING VOICES]

00:13:08.520 --> 00:13:11.460
SPEAKER 8: We have each of
the stations in the blue.

00:13:11.460 --> 00:13:13.390
I think the main
source of chaos for us

00:13:13.390 --> 00:13:17.550
was what happens with the
exam process and the decisions

00:13:17.550 --> 00:13:18.050
afterward.

00:13:18.050 --> 00:13:20.370
So that was our main
point of contention

00:13:20.370 --> 00:13:22.170
at the end of this
process is where

00:13:22.170 --> 00:13:25.230
do we put all these
negative-positive failed test

00:13:25.230 --> 00:13:26.130
outcomes?

00:13:26.130 --> 00:13:27.720
And how do they
eventually link back

00:13:27.720 --> 00:13:29.732
to the patient-to-start process.

00:13:29.732 --> 00:13:32.190
HUGH MCMANUS: And got some
color going there to sort of try

00:13:32.190 --> 00:13:33.240
to chase that around.

00:13:36.332 --> 00:13:38.790
AUDIENCE: These are all value
stream maps from the patient.

00:13:38.790 --> 00:13:40.483
But we don't have
the information for--

00:13:40.483 --> 00:13:42.900
HUGH MCMANUS: Right, there's
some other [INAUDIBLE] there.

00:13:42.900 --> 00:13:44.580
AUDIENCE: There's charts
and paperwork flying around.

00:13:44.580 --> 00:13:45.060
HUGH MCMANUS: That's right.

00:13:45.060 --> 00:13:47.477
And we did say we were following
the patient value stream.

00:13:47.477 --> 00:13:51.388
But there are some other value
streams up there-- the charts,

00:13:51.388 --> 00:13:53.430
the paperwork, which we
actually could use pretty

00:13:53.430 --> 00:13:56.160
much the same map to chase.

00:13:56.160 --> 00:14:00.480
But they also have their own
chart room and record room

00:14:00.480 --> 00:14:02.610
and to some extent,
their own processes.

00:14:02.610 --> 00:14:07.320
They don't follow exactly
the same path as the patient.

00:14:07.320 --> 00:14:08.220
So this is good.

00:14:08.220 --> 00:14:12.420
So why don't we continue
with our exercise.

00:14:12.420 --> 00:14:15.810
BO MADSEN: Yes, so
remember, yesterday we

00:14:15.810 --> 00:14:19.140
talked about different times.

00:14:19.140 --> 00:14:21.720
We talked about cycle time--

00:14:21.720 --> 00:14:25.890
the time from the beginning
to the end of the process.

00:14:25.890 --> 00:14:28.050
The touch time--
where the actual work

00:14:28.050 --> 00:14:32.340
is being done, where you
exclude the wait times.

00:14:32.340 --> 00:14:37.240
And then again, value added
non-value added time--

00:14:37.240 --> 00:14:41.780
so we talk about some
different types of time.

00:14:41.780 --> 00:14:45.130
And obviously, it is the value
added time that we really want,

00:14:45.130 --> 00:14:48.640
and we prefer to get
rid of the rest of it.

00:14:48.640 --> 00:14:52.450
So then there is also--

00:14:52.450 --> 00:14:54.680
when we get to the
capacity things as well,

00:14:54.680 --> 00:14:56.920
you need to think
about failed tests.

00:14:56.920 --> 00:14:58.630
This is not 100% right.

00:14:58.630 --> 00:15:00.940
You have a certain
amount of your test

00:15:00.940 --> 00:15:03.790
that just they're neither
positive nor negative.

00:15:03.790 --> 00:15:05.530
They're just failed.

00:15:05.530 --> 00:15:07.390
Hospital systems for us--

00:15:07.390 --> 00:15:13.220
what I have in my face
every day is potassium.

00:15:13.220 --> 00:15:14.900
Do you experience
the same things?

00:15:14.900 --> 00:15:16.160
You get high potassium.

00:15:16.160 --> 00:15:17.270
Everybody gets scared.

00:15:17.270 --> 00:15:19.430
Because it is dangerous.

00:15:19.430 --> 00:15:21.200
You need redraws.

00:15:21.200 --> 00:15:24.300
And we used to be around 20%.

00:15:24.300 --> 00:15:27.950
And now, I think we're down
to 7% through leaning it out.

00:15:27.950 --> 00:15:30.800
But 7% is still a lot.

00:15:30.800 --> 00:15:33.260
Because like you said,
what does everybody

00:15:33.260 --> 00:15:34.910
do when they come
to the hospital?

00:15:34.910 --> 00:15:36.840
They get lab tests.

00:15:36.840 --> 00:15:39.600
So we have probably a
couple of patients every day

00:15:39.600 --> 00:15:43.200
referred to the emergency
department for hyperkalemia

00:15:43.200 --> 00:15:45.270
that we redraw.

00:15:45.270 --> 00:15:47.410
And then it's negative-- normal.

00:15:47.410 --> 00:15:48.790
So that's expensive.

00:15:48.790 --> 00:15:50.700
HUGH MCMANUS: So why don't we--

00:15:50.700 --> 00:15:54.150
because this group seems to
have caught the basic issue,

00:15:54.150 --> 00:15:56.100
and some of them have
already jumped ahead--

00:15:56.100 --> 00:16:02.050
and what we want to do is add
some time and reliability data

00:16:02.050 --> 00:16:03.960
to our map.

00:16:03.960 --> 00:16:08.100
The tricky thing is, of
course, every patient

00:16:08.100 --> 00:16:10.350
is different based
on the dice, right?

00:16:10.350 --> 00:16:14.640
So we have to pick some kind of
unit of analysis-- an average,

00:16:14.640 --> 00:16:16.448
a median, something.

00:16:16.448 --> 00:16:17.740
BO MADSEN: A min and max maybe.

00:16:17.740 --> 00:16:19.740
HUGH MCMANUS: A
min and max, right.

00:16:19.740 --> 00:16:22.740
So we need to decide what
our unit of analysis is

00:16:22.740 --> 00:16:23.670
and be consistent.

00:16:23.670 --> 00:16:25.710
It almost doesn't
matter what it is.

00:16:25.710 --> 00:16:27.400
Over long experience
with these things,

00:16:27.400 --> 00:16:31.110
I found that doing
a min-max average

00:16:31.110 --> 00:16:33.588
is easily enough detail.

00:16:33.588 --> 00:16:35.880
When you start putting min-max
average on all of these,

00:16:35.880 --> 00:16:38.297
you suddenly realize, I got a
whole bunch of numbers here.

00:16:38.297 --> 00:16:40.170
And it's enough to
tell most of the story.

00:16:40.170 --> 00:16:42.090
So we don't need a deep
statistical analysis

00:16:42.090 --> 00:16:42.930
of these numbers.

00:16:42.930 --> 00:16:46.560
But we need to decide
what our unit of analysis

00:16:46.560 --> 00:16:48.630
is, put the times up.

00:16:48.630 --> 00:16:51.180
And the times can pretty
much be the hourglass.

00:16:51.180 --> 00:16:53.730
If there's a little bit of
non-value-added touch-time,

00:16:53.730 --> 00:16:56.400
if there's a little bit of
futzing time or confusion time

00:16:56.400 --> 00:17:01.500
or waiting for supplies time,
you can add that, as well.

00:17:01.500 --> 00:17:03.570
And put those times
on our processes.

00:17:03.570 --> 00:17:09.480
And then the percentages of
different decision outcomes,

00:17:09.480 --> 00:17:11.160
again, need to be estimated.

00:17:11.160 --> 00:17:13.839
Some of those are
based on the dice.

00:17:13.839 --> 00:17:15.839
So you sort of have the
numbers in front of you.

00:17:15.839 --> 00:17:17.317
Some of them aren't so much.

00:17:17.317 --> 00:17:18.650
When do they go to the hospital?

00:17:18.650 --> 00:17:20.220
Well, when the
right-colored head shows up.

00:17:20.220 --> 00:17:21.137
When does that happen?

00:17:21.137 --> 00:17:22.140
You don't know.

00:17:22.140 --> 00:17:23.609
You just have to
kind of estimate

00:17:23.609 --> 00:17:26.490
based on your experience, OK?

00:17:26.490 --> 00:17:27.970
So not too complicated.

00:17:27.970 --> 00:17:31.740
Let's take another 10-ish
minutes to finish our maps

00:17:31.740 --> 00:17:34.000
and annotate them.

00:17:34.000 --> 00:17:35.633
EARLL MURMAN: I love that.

00:17:35.633 --> 00:17:37.800
AUDIENCE: So we're doing a
weighted average to our--

00:17:37.800 --> 00:17:38.592
EARLL MURMAN: Yeah.

00:17:38.592 --> 00:17:43.290
AUDIENCE: Yeah, so if there
are two patients waiting,

00:17:43.290 --> 00:17:45.650
one will be waiting
for this much.

00:17:45.650 --> 00:17:48.600
And the second will be
waiting for two units of this.

00:17:48.600 --> 00:17:49.850
EARLL MURMAN: Excellent, yeah.

00:17:49.850 --> 00:17:50.912
AUDIENCE: Yeah.

00:17:50.912 --> 00:17:53.470
And if there's a third
patient, the third patient

00:17:53.470 --> 00:17:55.020
will wait for three
units of this.

00:17:55.020 --> 00:17:55.560
EARLL MURMAN: Yeah, OK.

00:17:55.560 --> 00:17:57.518
But we have to kind of
average when we roll it.

00:17:57.518 --> 00:18:00.648
So on average, how many patients
do you think were waiting?

00:18:00.648 --> 00:18:03.747
So treatment time is
three times the dice roll.

00:18:03.747 --> 00:18:04.830
AUDIENCE: Yes, 40 seconds.

00:18:04.830 --> 00:18:08.760
EARLL MURMAN: OK, of which only
1/3 is value-added time and 2/3

00:18:08.760 --> 00:18:09.990
is waste.

00:18:09.990 --> 00:18:11.640
The average time a
patient is in here

00:18:11.640 --> 00:18:16.200
is 80 times 3, which is
240, which is 240 seconds.

00:18:16.200 --> 00:18:18.618
AUDIENCE: OK, so
should we just put 240?

00:18:18.618 --> 00:18:19.410
EARLL MURMAN: 240--

00:18:19.410 --> 00:18:20.190
AUDIENCE: Yeah, you can do that.

00:18:20.190 --> 00:18:22.460
EARLL MURMAN: --of
which 80 is value-added.

00:18:22.460 --> 00:18:25.950
AUDIENCE: So how about we put
average time and value-added?

00:18:25.950 --> 00:18:27.330
EARLL MURMAN: Yeah, OK.

00:18:27.330 --> 00:18:28.180
AUDIENCE: OK.

00:18:28.180 --> 00:18:29.970
HUGH MCMANUS: There's
basically two ways

00:18:29.970 --> 00:18:34.410
you could tackle the challenge
of collecting data in the sim.

00:18:34.410 --> 00:18:35.865
And I think different
teams did it

00:18:35.865 --> 00:18:37.740
different ways, which
is an interesting thing

00:18:37.740 --> 00:18:38.448
about this group.

00:18:38.448 --> 00:18:40.380
It's a fairly
sophisticated group.

00:18:40.380 --> 00:18:42.780
I think that people
have grasped the issue

00:18:42.780 --> 00:18:45.330
and made different decisions
about how to tackle it.

00:18:45.330 --> 00:18:48.570
You could go in, and
you could say, well, OK.

00:18:48.570 --> 00:18:50.370
If I rolled an infinite
number of dice,

00:18:50.370 --> 00:18:53.520
what would be the
statistically likely outcome?

00:18:53.520 --> 00:18:55.620
What would be my
weighted average time?

00:18:58.590 --> 00:19:02.310
What would be my weighted
average of different outcomes

00:19:02.310 --> 00:19:03.610
through the system?

00:19:03.610 --> 00:19:05.137
So you could do it that way.

00:19:05.137 --> 00:19:06.720
And that's something
in the real world

00:19:06.720 --> 00:19:10.410
you could do if you had profound
knowledge of the system,

00:19:10.410 --> 00:19:14.010
if you just knew that 30%
of this kind of patient

00:19:14.010 --> 00:19:15.300
went this way.

00:19:15.300 --> 00:19:20.580
Or other approach is you
could use data, right?

00:19:20.580 --> 00:19:21.750
We have data.

00:19:21.750 --> 00:19:24.150
So you can just
count them, right?

00:19:24.150 --> 00:19:25.710
Which ones went where?

00:19:25.710 --> 00:19:27.090
How many dots do we have to do?

00:19:27.090 --> 00:19:28.230
How much rework was there?

00:19:28.230 --> 00:19:33.450
The problem with that is
that it's small n, right?

00:19:33.450 --> 00:19:35.910
It's not going to give
you the same answer

00:19:35.910 --> 00:19:40.650
as the statistical study unless
you have a really large sample.

00:19:40.650 --> 00:19:46.230
Now, is that your world?

00:19:46.230 --> 00:19:48.140
Pretty much, right?

00:19:48.140 --> 00:19:51.840
In fact, medical studies tend to
not really converge unless they

00:19:51.840 --> 00:19:54.900
have really large samples.

00:19:54.900 --> 00:19:56.130
But this is real.

00:19:56.130 --> 00:19:58.510
This is the reality
on the ground.

00:19:58.510 --> 00:19:59.550
Which one do you trust?

00:19:59.550 --> 00:20:00.960
Which one do you believe?

00:20:00.960 --> 00:20:03.060
You have to choose, right?

00:20:03.060 --> 00:20:04.350
There's no absolute answer.

00:20:04.350 --> 00:20:07.710
BO MADSEN: It depends on
what system you are in.

00:20:07.710 --> 00:20:11.070
So BI would probably have the
most advanced medical records

00:20:11.070 --> 00:20:12.660
in this country.

00:20:12.660 --> 00:20:14.730
So we can pull everything out.

00:20:14.730 --> 00:20:18.780
And we can go 10 years back,
50,000 or 55,000 visits

00:20:18.780 --> 00:20:21.120
in the emergency
department per year.

00:20:21.120 --> 00:20:23.820
And we could just
pull all of that out.

00:20:23.820 --> 00:20:26.340
It's fairly easy, but that's
because we have good people.

00:20:26.340 --> 00:20:28.380
But that's not the
reality everywhere.

00:20:28.380 --> 00:20:30.300
So I worked with Iceland
and with Denmark.

00:20:30.300 --> 00:20:33.390
And, well, they have
fairly sophisticated

00:20:33.390 --> 00:20:35.230
electronic medical records.

00:20:35.230 --> 00:20:36.810
But a lot of it
is still on paper.

00:20:36.810 --> 00:20:39.690
And you just need to go
and look at the paper.

00:20:39.690 --> 00:20:43.260
And at BI, our record
has limitations, too.

00:20:43.260 --> 00:20:45.600
Let's just say we
want to study sepsis.

00:20:45.600 --> 00:20:48.810
We want to study the antibiotics
that these patients got.

00:20:48.810 --> 00:20:52.500
I can electronically see what
got pulled out of the Pyxis.

00:20:52.500 --> 00:20:54.600
You may be familiar
with the Pyxis--

00:20:54.600 --> 00:20:55.860
locked cabinet.

00:20:55.860 --> 00:20:58.140
You punch in the patient's
medical record number

00:20:58.140 --> 00:21:00.000
and what you want to pull out.

00:21:00.000 --> 00:21:04.560
But I need to look at the paper
to see what the nurse gave

00:21:04.560 --> 00:21:06.570
because one thing is
that they pulled out

00:21:06.570 --> 00:21:10.560
4.5 grams of x, y, or z.

00:21:10.560 --> 00:21:14.820
But if they only gave 3
grams, that information

00:21:14.820 --> 00:21:17.880
is only available
on paper as it is.

00:21:17.880 --> 00:21:21.567
All right, so, yes,
you can go either way.

00:21:21.567 --> 00:21:22.650
HUGH MCMANUS: And that's--

00:21:22.650 --> 00:21:27.000
BO MADSEN: Here, with the
numbers that we added on,

00:21:27.000 --> 00:21:29.970
we had it a little bit fudged
because, well, when you

00:21:29.970 --> 00:21:32.400
handle stuff, it takes time.

00:21:32.400 --> 00:21:35.700
15 seconds for just handling
the patient to the waiting

00:21:35.700 --> 00:21:37.320
room, passing on the message.

00:21:37.320 --> 00:21:39.970
New patient takes time.

00:21:39.970 --> 00:21:43.830
There is a range of how long
the different steps take,

00:21:43.830 --> 00:21:47.630
and the weighted
average plus the fudge.

00:21:47.630 --> 00:21:51.810
OK, so it's hopefully
pretty similar to what

00:21:51.810 --> 00:21:54.000
the different groups found.

00:21:54.000 --> 00:21:55.650
Maybe?

00:21:55.650 --> 00:21:56.342
Take a look.

00:21:56.342 --> 00:21:58.800
HUGH MCMANUS: Yeah, did you do
something kind of innovative

00:21:58.800 --> 00:21:59.700
here instead of--

00:22:02.290 --> 00:22:05.820
AUDIENCE: We calculated
the actual waiting

00:22:05.820 --> 00:22:09.180
time for the patient in MD.

00:22:09.180 --> 00:22:14.810
So the process time-- so
if it's 1 or 2 on a roll,

00:22:14.810 --> 00:22:18.400
then it's, what's their
probability of 30 seconds?

00:22:18.400 --> 00:22:21.667
And if it's 3 to 4, it's,
what's their probability of--

00:22:21.667 --> 00:22:22.500
[INTERPOSING VOICES]

00:22:22.500 --> 00:22:26.010
And then I calculated all
of them and summed them up.

00:22:26.010 --> 00:22:30.850
So for one patient,
the [INAUDIBLE] average

00:22:30.850 --> 00:22:33.082
time is 80 seconds.

00:22:33.082 --> 00:22:34.290
HUGH MCMANUS: 80 seconds, OK.

00:22:34.290 --> 00:22:34.670
All right.

00:22:34.670 --> 00:22:35.010
So--

00:22:35.010 --> 00:22:37.100
EARLL MURMAN: But then there's
another important step--

00:22:37.100 --> 00:22:37.530
HUGH MCMANUS: Yeah.

00:22:37.530 --> 00:22:37.860
AUDIENCE: Yeah.

00:22:37.860 --> 00:22:39.300
EARLL MURMAN: --is that
she's got patients waiting.

00:22:39.300 --> 00:22:40.545
HUGH MCMANUS: Oh, OK.

00:22:40.545 --> 00:22:43.530
AUDIENCE: Yeah, so if
one patient is waiting,

00:22:43.530 --> 00:22:47.326
and he probably will wait for
the [INAUDIBLE] time that's

00:22:47.326 --> 00:22:48.180
80 seconds.

00:22:48.180 --> 00:22:50.040
And if two patients
are waiting--

00:22:50.040 --> 00:22:54.570
so this is 80 seconds-- this
one will be 160 seconds.

00:22:54.570 --> 00:22:56.070
HUGH MCMANUS: OK,
there's an issue.

00:22:56.070 --> 00:23:00.420
I noticed that we didn't
even try [LAUGHS] to estimate

00:23:00.420 --> 00:23:01.990
the waiting times, right?

00:23:01.990 --> 00:23:04.260
So she's gotten extra
sophisticated and said,

00:23:04.260 --> 00:23:07.500
the 80 is actually, we tacked
on 15 seconds for paperwork.

00:23:07.500 --> 00:23:10.110
And so we're agreeing
on that exactly.

00:23:10.110 --> 00:23:11.970
What she's doing,
which is very clever--

00:23:11.970 --> 00:23:15.370
and this, you probably
do need to do database.

00:23:15.370 --> 00:23:18.030
How many patients did you
have waiting typically?

00:23:18.030 --> 00:23:19.050
So yep.

00:23:19.050 --> 00:23:22.440
EARLL MURMAN: So she estimated
that she has two patients

00:23:22.440 --> 00:23:23.295
on average waiting.

00:23:23.295 --> 00:23:24.060
HUGH MCMANUS: Waiting, OK.

00:23:24.060 --> 00:23:24.550
That's right.

00:23:24.550 --> 00:23:25.395
EARLL MURMAN: So the
actual time in the MD

00:23:25.395 --> 00:23:27.395
was three times the
actual treatment.

00:23:27.395 --> 00:23:28.530
HUGH MCMANUS: Right, right.

00:23:28.530 --> 00:23:29.010
So if we have--

00:23:29.010 --> 00:23:29.760
BO MADSEN: So 240.

00:23:29.760 --> 00:23:30.872
HUGH MCMANUS: Yep, yeah.

00:23:30.872 --> 00:23:31.830
So that's great, right?

00:23:31.830 --> 00:23:34.470
That's going deeper than
we did in our example.

00:23:34.470 --> 00:23:36.420
And that's right.

00:23:36.420 --> 00:23:40.020
Any time you have inventory
in front of a process, yeah,

00:23:40.020 --> 00:23:41.280
it's going to have to--

00:23:41.280 --> 00:23:43.110
something called
Little's law, which

00:23:43.110 --> 00:23:45.270
we'll talk about next time.

00:23:45.270 --> 00:23:47.520
You're going to have
to wait essentially

00:23:47.520 --> 00:23:51.580
that number of cycles to
get through the process.

00:23:51.580 --> 00:23:55.380
So if there's two patients
waiting and one in exam,

00:23:55.380 --> 00:23:57.600
it's going to, on
average, take three cycles

00:23:57.600 --> 00:24:00.180
to clear a patient
through there.

00:24:00.180 --> 00:24:01.560
So that's very good.

00:24:01.560 --> 00:24:02.060
OK.

00:24:02.060 --> 00:24:05.430
BO MADSEN: And then
if you look at your

00:24:05.430 --> 00:24:08.220
how long time things
[? they ?] take,

00:24:08.220 --> 00:24:11.580
you should also get a sense of
what the rate-limiting steps

00:24:11.580 --> 00:24:12.150
are here.

00:24:14.910 --> 00:24:18.120
What would you say?

00:24:18.120 --> 00:24:19.560
[LAUGHTER]

00:24:19.560 --> 00:24:23.230
When you look at it,
who's the limiting step?

00:24:23.230 --> 00:24:24.837
AUDIENCE: MD and the lab.

00:24:24.837 --> 00:24:25.920
BO MADSEN: MD and the lab.

00:24:25.920 --> 00:24:26.545
AUDIENCE: Yeah.

00:24:26.545 --> 00:24:30.570
BO MADSEN: What's the difference
between the MD and the lab?

00:24:30.570 --> 00:24:32.327
The MD is--

00:24:32.327 --> 00:24:32.910
AUDIENCE: One.

00:24:32.910 --> 00:24:33.910
BO MADSEN: --one person.

00:24:33.910 --> 00:24:35.700
And the lab can do,
how much at a time?

00:24:35.700 --> 00:24:36.076
AUDIENCE: Three.

00:24:36.076 --> 00:24:36.452
AUDIENCE: Potentially.

00:24:36.452 --> 00:24:38.560
BO MADSEN: Three with a
little bit of good luck,

00:24:38.560 --> 00:24:43.250
right, because they can do three
different things at a time.

00:24:43.250 --> 00:24:47.940
But if you look at the times
of the lab, well, 45 to 205.

00:24:47.940 --> 00:24:49.380
The same for the lab.

00:24:49.380 --> 00:24:51.570
But the MD is really
only one and can only

00:24:51.570 --> 00:24:57.920
be in one place
at a time, so OK.

00:24:57.920 --> 00:25:00.630
And then there's some rework.

00:25:00.630 --> 00:25:02.630
HUGH MCMANUS: And that,
too, we have essentially

00:25:02.630 --> 00:25:03.547
the same issue, right?

00:25:03.547 --> 00:25:08.630
People can look at the
dice and guesstimate.

00:25:08.630 --> 00:25:11.360
Or they can look at
their data and figure out

00:25:11.360 --> 00:25:13.910
what the rework rates are.

00:25:13.910 --> 00:25:17.510
The thing that
actually you can't

00:25:17.510 --> 00:25:20.810
do there is that some of that
depends on the patient color,

00:25:20.810 --> 00:25:22.238
which you don't know, right?

00:25:22.238 --> 00:25:23.780
There's an externality
there that you

00:25:23.780 --> 00:25:25.370
don't have any control over.

00:25:25.370 --> 00:25:28.115
And if that's true, all you can
do is look at your data, right?

00:25:28.115 --> 00:25:29.990
You don't know what the
big world looks like.

00:25:29.990 --> 00:25:32.720
You only know what
your data looks like.

00:25:32.720 --> 00:25:37.670
So based on that, you should
have something on this order.

00:25:37.670 --> 00:25:42.650
Something on the order of half
of the tests don't go so well.

00:25:42.650 --> 00:25:46.025
So that's another
major detractor.

00:25:46.025 --> 00:25:50.190
BO MADSEN: All right, so
diagnosing root causes.

00:25:50.190 --> 00:25:53.130
You need to find out,
what are the causes here?

00:25:53.130 --> 00:25:54.660
What's the effect?

00:25:54.660 --> 00:25:55.860
What's the cause?

00:25:55.860 --> 00:26:00.240
It's nice to separate those
out because the root causes,

00:26:00.240 --> 00:26:03.060
if you can find an
effect of those,

00:26:03.060 --> 00:26:05.730
you have a better chance
of improving your system.

00:26:05.730 --> 00:26:10.290
We haven't talked
much about workaround.

00:26:10.290 --> 00:26:15.360
But it's very prominent
in the medical field.

00:26:15.360 --> 00:26:18.570
So the medical field and
the engineering field,

00:26:18.570 --> 00:26:20.940
I think that we have some
of the same attributes.

00:26:20.940 --> 00:26:23.180
It is that we fix
problems, right?

00:26:23.180 --> 00:26:26.010
We see a problem, we fix it.

00:26:26.010 --> 00:26:28.630
So I have a problem at
work, I just fix it.

00:26:28.630 --> 00:26:31.830
I don't go back and say, all
right, why is it that it takes

00:26:31.830 --> 00:26:36.260
15 minutes to do
a lumbar puncture?

00:26:36.260 --> 00:26:38.550
It's not that it's
the 11 minutes

00:26:38.550 --> 00:26:42.470
that it takes to find the
stuff and get everything ready.

00:26:42.470 --> 00:26:44.240
I just go ahead, and I do it.

00:26:44.240 --> 00:26:47.570
Or if it's a new resident, I'll
help them and collect the stuff

00:26:47.570 --> 00:26:51.620
for them, instead of
saying, OK, we need kits.

00:26:51.620 --> 00:26:54.350
We need the stuff to be
available in the area

00:26:54.350 --> 00:26:57.152
where we use it because
that's a long process.

00:26:57.152 --> 00:26:58.610
It involves our
nursing leadership,

00:26:58.610 --> 00:27:01.460
physician leadership,
and restocking guys.

00:27:01.460 --> 00:27:04.530
And it's someone else's
area of responsibility.

00:27:04.530 --> 00:27:07.590
And they're going to be upset
if I say this is all wrong.

00:27:07.590 --> 00:27:11.440
And so we just do workarounds.

00:27:11.440 --> 00:27:13.030
That's not a good
way of doing it.

00:27:13.030 --> 00:27:17.960
You can analyze the root-cause
analysis in different ways--

00:27:17.960 --> 00:27:21.610
the 5 Whys we talked about
with the Jefferson Monument.

00:27:21.610 --> 00:27:22.700
It's very interesting.

00:27:22.700 --> 00:27:24.940
It's really useful.

00:27:24.940 --> 00:27:26.860
If you think about
a medical system

00:27:26.860 --> 00:27:31.750
and say, we do too many
joint replacements,

00:27:31.750 --> 00:27:33.850
why do we do too many
joint replacements?

00:27:33.850 --> 00:27:35.440
Well, because the
joints are worn.

00:27:35.440 --> 00:27:38.220
Why are the joints worn?

00:27:38.220 --> 00:27:39.510
Chime in here.

00:27:39.510 --> 00:27:41.700
Why do people get joint
replacements in the US?

00:27:41.700 --> 00:27:42.450
AUDIENCE: Obesity.

00:27:42.450 --> 00:27:44.010
BO MADSEN: Yes, obesity.

00:27:44.010 --> 00:27:45.300
Why are people obese?

00:27:45.300 --> 00:27:46.758
AUDIENCE: McDonald's [INAUDIBLE]

00:27:46.758 --> 00:27:48.220
[LAUGHTER]

00:27:48.220 --> 00:27:49.010
BO MADSEN: No, no.

00:27:49.010 --> 00:27:53.110
And again, these things
are being answered

00:27:53.110 --> 00:27:54.610
in a personal manner, right?

00:27:54.610 --> 00:27:56.290
So you can end up
with different things.

00:27:56.290 --> 00:27:58.105
But I think you're right on.

00:27:58.105 --> 00:28:02.780
Pre-processed food is cheaper
than making your own food,

00:28:02.780 --> 00:28:03.670
right?

00:28:03.670 --> 00:28:05.930
And then it gets
into, who earns what?

00:28:05.930 --> 00:28:07.240
So you do, why?

00:28:07.240 --> 00:28:09.670
Pre-processed food is
cheaper than the other.

00:28:09.670 --> 00:28:10.930
Why is it?

00:28:10.930 --> 00:28:13.270
Because we put
garbage in the food.

00:28:13.270 --> 00:28:14.530
And why is that?

00:28:14.530 --> 00:28:15.490
Blah, blah, blah.

00:28:15.490 --> 00:28:19.300
OK, so 5 Whys really work.

00:28:19.300 --> 00:28:21.320
And it works on many
different things.

00:28:21.320 --> 00:28:24.730
It's not only the Jefferson
Monument, which is nice, too.

00:28:24.730 --> 00:28:26.470
We can do capacity analysis.

00:28:26.470 --> 00:28:29.170
We looked at that yesterday.

00:28:29.170 --> 00:28:31.870
Remember, how much
time is available?

00:28:31.870 --> 00:28:34.530
What is our cycle time--

00:28:34.530 --> 00:28:41.760
again, limited by the slowest
steps in this process.

00:28:41.760 --> 00:28:43.410
All right, so
tomorrow you're going

00:28:43.410 --> 00:28:46.680
to look at cause-and-effect
diagrams and some Pareto

00:28:46.680 --> 00:28:47.940
charts, too.

00:28:47.940 --> 00:28:49.830
This we're just going to stop.

00:28:49.830 --> 00:28:54.650
And pitfalls, they can
be answered differently.

00:28:54.650 --> 00:28:58.540
Some are based on
values and on opinions.

00:28:58.540 --> 00:29:01.770
If there's too much
difference, then maybe

00:29:01.770 --> 00:29:03.570
you need a more
sophisticated tool

00:29:03.570 --> 00:29:06.050
for that particular problem.

00:29:06.050 --> 00:29:10.170
But in general, it's going to
work well on many problems.

00:29:10.170 --> 00:29:11.370
Good place to start.

00:29:11.370 --> 00:29:15.670
Yeah, it's difficult to identify
all the possible causes.

00:29:15.670 --> 00:29:20.365
If you have input that's
higher than your capacity,

00:29:20.365 --> 00:29:21.990
then you're going to
have a bottleneck.

00:29:21.990 --> 00:29:24.630
And then you're just going
to have a build-up of things

00:29:24.630 --> 00:29:26.420
that are waiting.

00:29:26.420 --> 00:29:29.460
Example from Denmark--
pardon me again--

00:29:29.460 --> 00:29:31.820
so there is a plan that
says, for instance,

00:29:31.820 --> 00:29:33.920
pancreatic cancer
patients, they should

00:29:33.920 --> 00:29:36.050
be able to have
surgery within, I

00:29:36.050 --> 00:29:38.570
don't remember if it's
two or four weeks.

00:29:38.570 --> 00:29:40.190
One would hope
that it's tomorrow.

00:29:40.190 --> 00:29:41.750
But it's two or four weeks.

00:29:41.750 --> 00:29:45.840
Nonetheless, they don't have
the capacity to do that.

00:29:45.840 --> 00:29:47.930
And then you have a
build-up of patients.

00:29:47.930 --> 00:29:50.720
And some of them, they get
surgery two months later,

00:29:50.720 --> 00:29:52.250
maybe three months later.

00:29:52.250 --> 00:29:54.110
Others, what happened to them?

00:29:54.110 --> 00:29:55.770
Well, when it's
cancer, you know what?

00:29:55.770 --> 00:29:58.040
It becomes inoperable, right?

00:29:58.040 --> 00:30:01.630
And then they drop off the list.

00:30:01.630 --> 00:30:05.980
So when capacity and
supply is mismatched,

00:30:05.980 --> 00:30:07.720
you're going to have a build-up.

00:30:07.720 --> 00:30:13.540
Theoretical capacity, so
this is a very cool field.

00:30:13.540 --> 00:30:15.410
You'll have more
about that tomorrow.

00:30:15.410 --> 00:30:19.960
So maximum capacity is, well,
the maximum sustainable flow

00:30:19.960 --> 00:30:20.620
rate.

00:30:20.620 --> 00:30:23.878
Any activity, we like
to think about 100%.

00:30:23.878 --> 00:30:26.170
Hugh is going to tell you
tomorrow that that's actually

00:30:26.170 --> 00:30:28.330
not really attainable.

00:30:28.330 --> 00:30:34.288
And it's not an attractive goal
because it will not function.

00:30:34.288 --> 00:30:36.580
It will lead to longer wait
times and things like that.

00:30:36.580 --> 00:30:39.400
Effective capacity
takes into account

00:30:39.400 --> 00:30:43.840
the errors, the
distracters, the reworks,

00:30:43.840 --> 00:30:45.880
what you can actually achieve.

00:30:45.880 --> 00:30:47.930
And we can look at that.

00:30:47.930 --> 00:30:50.230
So if you can see
five patients per hour

00:30:50.230 --> 00:30:53.860
but you have an
error rate of 20%,

00:30:53.860 --> 00:30:56.140
then in reality
you're only going

00:30:56.140 --> 00:30:59.270
to see four patients
per hour, right?

00:30:59.270 --> 00:31:04.370
OK, so that's your effective
capacity, not your maximum.

00:31:04.370 --> 00:31:05.480
All right, let's see.

00:31:05.480 --> 00:31:07.040
We can look at this one here.

00:31:07.040 --> 00:31:10.310
Capacity calculation, time
available-- we know that.

00:31:10.310 --> 00:31:14.300
And then the cycle time, the
time per unit, time per round,

00:31:14.300 --> 00:31:16.370
the number of resources
that you have.

00:31:16.370 --> 00:31:18.980
But you're not always
available, are you?

00:31:18.980 --> 00:31:21.170
You're not available
100% of the time.

00:31:21.170 --> 00:31:22.550
People, they go to eat.

00:31:22.550 --> 00:31:24.710
They have bathroom breaks.

00:31:24.710 --> 00:31:26.390
In Europe, they smoke.

00:31:26.390 --> 00:31:29.780
And some places, that is being
taken out of your work time

00:31:29.780 --> 00:31:30.350
now.

00:31:30.350 --> 00:31:31.340
I'm not kidding.

00:31:31.340 --> 00:31:32.870
But that's a new concept.

00:31:32.870 --> 00:31:35.320
It never used to be.

00:31:35.320 --> 00:31:37.080
So I think smoking
will go down with that.

00:31:37.080 --> 00:31:38.310
I think it's an excellent step.

00:31:38.310 --> 00:31:38.580
[LAUGHTER]

00:31:38.580 --> 00:31:40.020
No, I mean-- and
I'm not kidding.

00:31:40.020 --> 00:31:43.470
[LAUGHS] The actual touch time,
where you're doing something

00:31:43.470 --> 00:31:45.390
that is useful for the patient.

00:31:45.390 --> 00:31:49.410
And then the number of repeats,
the failed test or the,

00:31:49.410 --> 00:31:52.620
I had a positive test, I
need to go back to the MD,

00:31:52.620 --> 00:31:54.490
as in our simulation here.

00:31:54.490 --> 00:31:56.050
So you put that
in your equation.

00:31:56.050 --> 00:31:58.013
And then you get
your real capacity.

00:31:58.013 --> 00:31:59.430
The green ones are
the good stuff.

00:31:59.430 --> 00:32:01.440
And the red ones
are the detractors.

00:32:01.440 --> 00:32:05.345
So this is basic concepts.

00:32:05.345 --> 00:32:07.220
People, if you go back
to your organizations,

00:32:07.220 --> 00:32:09.500
they might be confused by
the words that you're using.

00:32:09.500 --> 00:32:13.080
But if you talk about
this as a concept,

00:32:13.080 --> 00:32:17.550
then you should all
be on the same page.

00:32:17.550 --> 00:32:22.430
So now we have 10 minutes
to do a root-cause analysis

00:32:22.430 --> 00:32:25.380
for your clinic operation here.

00:32:25.380 --> 00:32:28.460
So identify causes
that can be remedied

00:32:28.460 --> 00:32:32.900
using lean principles and tools
that you heard about yesterday.

00:32:32.900 --> 00:32:34.910
Try to put it on your easel.

00:32:34.910 --> 00:32:37.600
And let's talk about it.

00:32:37.600 --> 00:32:40.100
HUGH MCMANUS: So think a little
bit more about what's wrong.

00:32:40.100 --> 00:32:43.850
You can finish up
your value stream map.

00:32:43.850 --> 00:32:48.170
Rather than do a separate
easel chart display,

00:32:48.170 --> 00:32:53.450
why don't you go ahead and
put your suspected root causes

00:32:53.450 --> 00:32:55.460
right there on the
chart, you know?

00:32:55.460 --> 00:32:59.698
Is this the problem,
chaos in the waiting room?

00:32:59.698 --> 00:33:01.490
I don't know whether
that's the root cause.

00:33:01.490 --> 00:33:06.410
That may actually be a symptom.

00:33:06.410 --> 00:33:08.300
But we'll put that
right on the chart.

00:33:08.300 --> 00:33:12.350
So we'll finish the morning
with an annotated chart

00:33:12.350 --> 00:33:14.150
of the things that
you want to fix.

00:33:14.150 --> 00:33:16.808
And after lunch, we're going
to proceed to fix them.

00:33:16.808 --> 00:33:18.350
EARLL MURMAN: So it
sounds like we've

00:33:18.350 --> 00:33:21.140
identified two major problems.

00:33:21.140 --> 00:33:22.570
We have the bottleneck here.

00:33:22.570 --> 00:33:25.490
And there's a solution
to get the [INAUDIBLE]..

00:33:25.490 --> 00:33:27.350
And then the
failing [INAUDIBLE],,

00:33:27.350 --> 00:33:29.155
we got to find some
solution for that.

00:33:29.155 --> 00:33:29.780
AUDIENCE: Yeah.

00:33:29.780 --> 00:33:32.340
EARLL MURMAN: And then those
are the two main long poles

00:33:32.340 --> 00:33:32.840
in the tent.

00:33:32.840 --> 00:33:35.450
And then next level
down is stream-lining

00:33:35.450 --> 00:33:41.660
the ordering system
and this, just,

00:33:41.660 --> 00:33:43.305
flow through the waiting room.

00:33:43.305 --> 00:33:45.440
AUDIENCE: Also
optimizing the order

00:33:45.440 --> 00:33:48.410
that we get patients from
the MD to the diagnostics

00:33:48.410 --> 00:33:50.090
so that I can run
a couple at a time.

00:33:50.090 --> 00:33:50.960
AUDIENCE: So we're doing that.

00:33:50.960 --> 00:33:51.390
AUDIENCE: Yeah, because--

00:33:51.390 --> 00:33:52.070
EARLL MURMAN: Oh, OK.

00:33:52.070 --> 00:33:54.410
So we actually want to have
this distributed waiting room

00:33:54.410 --> 00:33:54.993
type of thing?

00:33:54.993 --> 00:33:56.902
AUDIENCE: No, that is
just so she doesn't--

00:33:56.902 --> 00:33:59.360
like, she has to pick which
order she sees the patients in.

00:33:59.360 --> 00:34:01.130
AUDIENCE: Right, if I'm
treating a gray patient

00:34:01.130 --> 00:34:03.170
and she's got a gray patient
and blue patient that she's

00:34:03.170 --> 00:34:04.640
trying to decide
who to treat next,

00:34:04.640 --> 00:34:06.840
pick the blue one so that I
can run it at the same time.

00:34:06.840 --> 00:34:07.010
EARLL MURMAN: Ah, wow.

00:34:07.010 --> 00:34:07.880
So this is a visual control.

00:34:07.880 --> 00:34:08.505
AUDIENCE: Yeah.

00:34:08.505 --> 00:34:09.290
EARLL MURMAN: OK.

00:34:09.290 --> 00:34:10.380
OK, cool.

00:34:10.380 --> 00:34:14.360
HUGH MCMANUS: Let's talk
about the conclusions

00:34:14.360 --> 00:34:17.210
you guys came to on your
root-cause exercises.

00:34:17.210 --> 00:34:19.670
If we could just go
around and just tell me

00:34:19.670 --> 00:34:23.540
two things that you think
are the biggest problems

00:34:23.540 --> 00:34:29.719
with your processes from
a root-cause perspective.

00:34:29.719 --> 00:34:30.919
Let's start back here.

00:34:30.919 --> 00:34:33.620
AUDIENCE: So our main
problem was the bottleneck

00:34:33.620 --> 00:34:34.471
in the exam room.

00:34:34.471 --> 00:34:35.179
HUGH MCMANUS: OK.

00:34:35.179 --> 00:34:37.670
AUDIENCE: So when it boiled
down to the root causes,

00:34:37.670 --> 00:34:41.989
we thought it was due to
triage failure, potentially

00:34:41.989 --> 00:34:44.210
due to inadequate
training here in triage--

00:34:44.210 --> 00:34:45.110
HUGH MCMANUS: OK.

00:34:45.110 --> 00:34:47.600
AUDIENCE: --as well
as test failure

00:34:47.600 --> 00:34:52.370
due to equipment issues, for
example lack of maintenance,

00:34:52.370 --> 00:34:55.850
more training required,
and a protocol

00:34:55.850 --> 00:35:00.750
that just would make the
process less efficient.

00:35:00.750 --> 00:35:01.760
HUGH MCMANUS: Right.

00:35:01.760 --> 00:35:06.860
So the rework issue
from diagnostics

00:35:06.860 --> 00:35:08.690
is easy to understand.

00:35:08.690 --> 00:35:12.200
What was the issue with triage?

00:35:12.200 --> 00:35:14.630
AUDIENCE: So we
potentially were thinking

00:35:14.630 --> 00:35:18.170
that we could start
cross-training staff

00:35:18.170 --> 00:35:21.320
between registration and
triage because this might just

00:35:21.320 --> 00:35:23.255
be a step that we
don't need necessarily.

00:35:23.255 --> 00:35:24.160
HUGH MCMANUS: OK,
so you think there's

00:35:24.160 --> 00:35:25.310
some inefficiency there.

00:35:25.310 --> 00:35:27.020
AUDIENCE: Well, in
triage, the doctor

00:35:27.020 --> 00:35:29.840
was seeing levels of care
that were either too easy,

00:35:29.840 --> 00:35:32.750
they could have been managed
by triage to either discharged

00:35:32.750 --> 00:35:35.630
to home or sent to the hospital
without ever seeing the doctor.

00:35:35.630 --> 00:35:38.360
So he could have seen fewer
patients if triage was--

00:35:38.360 --> 00:35:43.160
HUGH MCMANUS: OK, so triage
was feeding unnecessary work

00:35:43.160 --> 00:35:44.700
to the doctor.

00:35:44.700 --> 00:35:46.160
OK.

00:35:46.160 --> 00:35:47.600
You folks?

00:35:47.600 --> 00:35:50.390
What's your top two?

00:35:50.390 --> 00:35:55.340
AUDIENCE: We think one of them
is too much patient movement,

00:35:55.340 --> 00:35:58.090
having them shuttle back and
forth to the waiting room.

00:35:58.090 --> 00:36:03.140
It created a lot of
confusion for all areas

00:36:03.140 --> 00:36:06.810
in that we didn't know where
they were supposed to go next.

00:36:06.810 --> 00:36:09.900
So that kind of covered
actually a couple of them.

00:36:09.900 --> 00:36:14.610
We also have the inefficient
registration triage system

00:36:14.610 --> 00:36:18.460
and also the [INAUDIBLE]
information flow,

00:36:18.460 --> 00:36:22.020
where the chart was getting
separated from the patient

00:36:22.020 --> 00:36:26.470
and going to the chartroom
in between each time.

00:36:26.470 --> 00:36:29.615
And really one way
to solve that would

00:36:29.615 --> 00:36:31.705
be keep the chart
with the patient

00:36:31.705 --> 00:36:33.190
as they move through the system.

00:36:33.190 --> 00:36:35.470
HUGH MCMANUS: So
you focused more

00:36:35.470 --> 00:36:38.080
on the detractors
for the bottleneck,

00:36:38.080 --> 00:36:41.860
while you guys are focusing
more on the overall process

00:36:41.860 --> 00:36:45.690
issues of the confusion of
having the patient moving.

00:36:45.690 --> 00:36:47.050
These are both valid.

00:36:47.050 --> 00:36:51.240
It's interesting that folks
are getting kind of different--

00:36:51.240 --> 00:36:52.930
so who wants to
speak for this table?

00:36:52.930 --> 00:36:55.027
AUDIENCE: So we also
agreed with them,

00:36:55.027 --> 00:36:56.360
so I won't reiterate that point.

00:36:56.360 --> 00:36:57.818
But one minor thing
that we noticed

00:36:57.818 --> 00:36:59.901
is we had a lot of unused
capacity in diagnostics.

00:36:59.901 --> 00:37:00.610
HUGH MCMANUS: OK.

00:37:00.610 --> 00:37:02.690
AUDIENCE: And we had a
backup with the physician.

00:37:02.690 --> 00:37:04.340
And the physician
didn't have a method

00:37:04.340 --> 00:37:05.923
of choosing which
patient to see next.

00:37:05.923 --> 00:37:11.660
So we set up a signal system
whereby any unused device

00:37:11.660 --> 00:37:14.363
would be set in front of
the eyes of the physician

00:37:14.363 --> 00:37:16.530
so that she could pick the
right patient to see next

00:37:16.530 --> 00:37:18.363
instead of running back
over to diagnostics.

00:37:18.363 --> 00:37:19.370
HUGH MCMANUS: Yeah, OK.

00:37:19.370 --> 00:37:20.410
AUDIENCE: [INAUDIBLE]

00:37:20.410 --> 00:37:25.370
HUGH MCMANUS: So looking at
the outflow from the physician,

00:37:25.370 --> 00:37:28.070
making sure that patients didn't
have to wait on the other end,

00:37:28.070 --> 00:37:28.890
as well.

00:37:28.890 --> 00:37:29.390
Yeah?

00:37:29.390 --> 00:37:31.900
EARLL MURMAN: That's a
really good instance of pull.

00:37:31.900 --> 00:37:33.020
HUGH MCMANUS: Yes, yep.

00:37:33.020 --> 00:37:37.340
EARLL MURMAN: OK, you can see
what the diagnostics could use.

00:37:37.340 --> 00:37:39.780
And they really have
something set up almost

00:37:39.780 --> 00:37:40.655
like a [? combine. ?]

00:37:40.655 --> 00:37:43.280
HUGH MCMANUS: It's almost like
a [? pull ?] [? combine, ?] yep,

00:37:43.280 --> 00:37:45.920
that, yeah, the patient is
pulled into diagnostic based

00:37:45.920 --> 00:37:48.250
on the availability.