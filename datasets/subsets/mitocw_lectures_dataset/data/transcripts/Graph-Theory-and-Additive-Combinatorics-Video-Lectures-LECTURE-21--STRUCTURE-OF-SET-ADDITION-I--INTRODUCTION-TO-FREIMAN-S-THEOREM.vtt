WEBVTT

00:00:17.963 --> 00:00:19.380
YUFEI ZHAO: All
right, today we're

00:00:19.380 --> 00:00:22.850
going to start a new topic
an additive combinatorics.

00:00:22.850 --> 00:00:25.260
And this is a
fairly central topic

00:00:25.260 --> 00:00:28.740
having to do with the
structure of set addition.

00:00:43.480 --> 00:00:44.980
So the main players
that we're going

00:00:44.980 --> 00:00:49.810
to be seeing in this
chapter have to do with,

00:00:49.810 --> 00:00:56.410
if you start with a subset
of some obedient group

00:00:56.410 --> 00:00:59.980
under addition--

00:00:59.980 --> 00:01:01.150
not necessarily finite.

00:01:01.150 --> 00:01:03.580
So the obedient
group that I'm going

00:01:03.580 --> 00:01:06.580
to keep in mind, the ones
that will come up generally

00:01:06.580 --> 00:01:11.410
are integers, z mod n or
the finite field model.

00:01:15.260 --> 00:01:20.750
We're going to be looking at
objects such as a sum set, so

00:01:20.750 --> 00:01:26.000
a plus b, meaning the set of
elements that can be written

00:01:26.000 --> 00:01:29.180
as a sum, where you
take one element

00:01:29.180 --> 00:01:34.510
from a and another from b.

00:01:34.510 --> 00:01:39.340
Likewise, you can also have
a minus b defined similarly,

00:01:39.340 --> 00:01:41.080
now taking a minus b.

00:01:45.550 --> 00:01:48.430
We can iterate this operation.

00:01:48.430 --> 00:01:54.760
So kA, so 2A, 3A,
4A, for instance,

00:01:54.760 --> 00:02:05.520
means I add A to
itself k times, not

00:02:05.520 --> 00:02:11.330
to be confused with a dilation,
which we'll denote by k dot A.

00:02:11.330 --> 00:02:16.370
So this is notation for
multiplying every element of A

00:02:16.370 --> 00:02:17.540
by the number k.

00:02:24.360 --> 00:02:28.120
So given a subset of integers
I can do these operations

00:02:28.120 --> 00:02:29.200
to the set.

00:02:29.200 --> 00:02:32.230
And I want to ask, how
does the size of the set

00:02:32.230 --> 00:02:37.750
change when I do
these operations?

00:02:37.750 --> 00:02:43.120
For example, what is the
largest or the smallest?

00:02:43.120 --> 00:02:59.590
So how large or small can A plus
A be for a given set size, A?

00:02:59.590 --> 00:03:04.070
So if I allow you
to use 10 elements,

00:03:04.070 --> 00:03:07.290
how can you make A plus
A as big as possible?

00:03:07.290 --> 00:03:10.160
And how can you make it
as small as possible?

00:03:10.160 --> 00:03:12.500
So this is not a hard question.

00:03:12.500 --> 00:03:14.280
How can you make it
as big as possible?

00:03:18.700 --> 00:03:21.080
So what's the
maximum size A plus A

00:03:21.080 --> 00:03:24.430
can be as a function of A?

00:03:24.430 --> 00:03:27.120
Well, I'm looking
at pairwise sums,

00:03:27.120 --> 00:03:30.020
so if there are no collisions
between different pairwise

00:03:30.020 --> 00:03:32.720
sums, this is as
large as possible.

00:03:32.720 --> 00:03:36.200
And then it's not hard to see
that the maximum possible is

00:03:36.200 --> 00:03:38.790
the size of A plus 1, choose 2.

00:03:41.370 --> 00:03:52.200
So since at most,
this many pairs

00:03:52.200 --> 00:03:56.475
and space possible if
all sums are distinct.

00:04:00.610 --> 00:04:07.280
So for example, in integers,
you can take 1, 2, 2 squared,

00:04:07.280 --> 00:04:07.780
and so on.

00:04:11.126 --> 00:04:15.040
So that will give you the span.

00:04:15.040 --> 00:04:17.480
The minimum possible
is also not too hard.

00:04:20.910 --> 00:04:23.230
We're allowed to work in
a general obedient group.

00:04:23.230 --> 00:04:29.770
So in that case, the minimum
could be just the size of A.

00:04:29.770 --> 00:04:32.860
The size is always at
least the size of A.

00:04:32.860 --> 00:04:39.080
And this is tight
if A is a subgroup.

00:04:39.080 --> 00:04:42.780
If you have a subgroup, then
it's closed under addition.

00:04:42.780 --> 00:04:48.030
So the set does not
expand under addition.

00:04:48.030 --> 00:04:52.520
In the integers, you don't
have any finite subgroups.

00:04:52.520 --> 00:04:55.940
So if I give you k integers,
what's the smallest,

00:04:55.940 --> 00:04:57.564
the sum set can be?

00:04:57.564 --> 00:04:58.670
AUDIENCE: 2k minus 1.

00:04:58.670 --> 00:04:59.920
YUFEI ZHAO: 2k minus 1, right?

00:04:59.920 --> 00:05:02.628
So the example is when you
have an arithmetic progression.

00:05:02.628 --> 00:05:07.750
So in integers, the
minimum is 2k minus 1.

00:05:10.440 --> 00:05:18.360
And it's achieved for an
arithmetic progression.

00:05:18.360 --> 00:05:21.810
So let me just give you the
one-line proof why you always

00:05:21.810 --> 00:05:24.000
have at least this
many elements,

00:05:24.000 --> 00:05:31.530
is if A has elements
sorted like this,

00:05:31.530 --> 00:05:40.020
then the following elements
are distinct in the sum set.

00:05:40.020 --> 00:05:41.940
So you start with
A plus A. And then

00:05:41.940 --> 00:05:47.850
you move A1 plus A2, A1 plus
A3, and so on, to A1 plus Ak.

00:05:47.850 --> 00:05:49.815
And then you move the
first element forward.

00:05:56.310 --> 00:06:04.810
OK, so here you already see
2k minus 1 distinct elements

00:06:04.810 --> 00:06:10.420
in A plus A.

00:06:10.420 --> 00:06:13.060
OK, so these are
fairly simple examples,

00:06:13.060 --> 00:06:14.350
fairly simple questions.

00:06:14.350 --> 00:06:18.280
So now let's get to some more
interesting questions, which

00:06:18.280 --> 00:06:22.840
is, what can you say
about a set if you know

00:06:22.840 --> 00:06:25.390
that it has small doubling?

00:06:25.390 --> 00:06:28.030
If it doesn't
expand by very much,

00:06:28.030 --> 00:06:30.510
what can you tell
me about the set?

00:06:30.510 --> 00:06:33.330
And for that, let me define the
notion of a doubling constant.

00:06:38.960 --> 00:06:43.670
So the doubling
constant of A is defined

00:06:43.670 --> 00:06:45.980
to be the number
which we often denote

00:06:45.980 --> 00:06:54.730
by k, the number obtained by
dividing the size of A plus A

00:06:54.730 --> 00:06:59.075
by the size of A. And we
would like to understand--

00:06:59.075 --> 00:07:01.340
and this is the
main question that's

00:07:01.340 --> 00:07:07.160
addressed in the
upcoming lectures is,

00:07:07.160 --> 00:07:22.405
what is the structure of a set
with bounded doubling constant?

00:07:29.960 --> 00:07:33.070
So for instance,
think of k as fixed.

00:07:35.960 --> 00:07:37.400
Let's say k is 100.

00:07:37.400 --> 00:07:41.730
If you know a set has doubling
constant, at most, 100,

00:07:41.730 --> 00:07:45.570
what can you tell me about
the structure of the set?

00:07:45.570 --> 00:07:47.310
So that's the main question.

00:07:47.310 --> 00:07:50.370
Let me show you in a second
a few examples of sets

00:07:50.370 --> 00:07:53.600
the have bounded
doubling constant.

00:07:53.600 --> 00:07:56.280
So that's easy to check
that those examples indeed

00:07:56.280 --> 00:07:58.570
have bounded doubling constant.

00:07:58.570 --> 00:08:00.330
And what this
question amounts to

00:08:00.330 --> 00:08:04.250
is what is often known
as an inverse question.

00:08:04.250 --> 00:08:10.320
So it's an inverse
problem that asks

00:08:10.320 --> 00:08:13.070
you to describe in reverse--

00:08:13.070 --> 00:08:15.750
so it's easy to check
in the upcoming examples

00:08:15.750 --> 00:08:20.600
that all of those examples
have bounded doubling constant.

00:08:20.600 --> 00:08:22.500
And what we want to
say is, in reverse,

00:08:22.500 --> 00:08:25.740
that if a set has bounded
doubling constant,

00:08:25.740 --> 00:08:31.160
then it must in some sense
look like one of our examples.

00:08:31.160 --> 00:08:32.820
It's the harder
inverse question.

00:08:35.530 --> 00:08:37.929
OK, so let me give you
some examples of sets

00:08:37.929 --> 00:08:39.744
with small doubling constant.

00:08:49.650 --> 00:08:51.900
One example we
already saw earlier

00:08:51.900 --> 00:08:56.600
is that if you have an
arithmetic progression.

00:08:56.600 --> 00:08:58.400
If you have an
arithmetic progression,

00:08:58.400 --> 00:09:01.430
then the size of
A plus A is always

00:09:01.430 --> 00:09:06.085
2 times the size of A minus 1.

00:09:06.085 --> 00:09:11.340
So the doubling constantly
is always, at most, 2.

00:09:11.340 --> 00:09:12.460
That's pretty small.

00:09:12.460 --> 00:09:16.580
That's as small as you can get
in arithmetic progressions is

00:09:16.580 --> 00:09:17.330
in the integers.

00:09:20.460 --> 00:09:23.370
But if you start with an
arithmetic progression

00:09:23.370 --> 00:09:27.810
and now I take just a
subset of the elements

00:09:27.810 --> 00:09:33.580
of this progression,
so if I take AP,

00:09:33.580 --> 00:09:38.650
and if I cross out a few
elements, just a small number

00:09:38.650 --> 00:09:41.350
of elements from this
progression, or even

00:09:41.350 --> 00:09:44.320
cross out most, but
keeping a constant fraction

00:09:44.320 --> 00:09:48.850
of elements still
remaining, I claim

00:09:48.850 --> 00:09:52.200
that's still a pretty good set.

00:09:52.200 --> 00:10:01.290
So if A can be
embedded inside an AP

00:10:01.290 --> 00:10:06.690
such that the AP has size
no more a constant factor

00:10:06.690 --> 00:10:15.880
and more than that of A,
then the size of A plus A is,

00:10:15.880 --> 00:10:16.700
at most--

00:10:16.700 --> 00:10:22.240
so we bound it by the size of P
plus P, which is, at most, 2P.

00:10:25.160 --> 00:10:30.250
So the doubling constant
of A is, at most, 2C.

00:10:30.250 --> 00:10:35.960
So if you have a set which is
at least 1/10 fraction of an AP,

00:10:35.960 --> 00:10:40.630
then you are doubling
constant at most, 20, bounded.

00:10:40.630 --> 00:10:42.920
So this is another
class of examples.

00:10:42.920 --> 00:10:45.950
So it's kind of a
modification, some alteration

00:10:45.950 --> 00:10:48.827
of the arithmetic progression.

00:10:52.170 --> 00:10:56.220
Another more substantial
generalization of APs

00:10:56.220 --> 00:11:01.790
is that of a two-dimensional
arithmetic progression.

00:11:01.790 --> 00:11:03.600
So you think of an
arithmetic progression

00:11:03.600 --> 00:11:08.420
as equally spaced
points on a line.

00:11:08.420 --> 00:11:16.600
But you can extend this
in multiple dimensions,

00:11:16.600 --> 00:11:18.710
so like a grid.

00:11:18.710 --> 00:11:21.560
So this is a two-dimensional
arithmetic progression,

00:11:21.560 --> 00:11:24.330
but I still want to work
inside the integers.

00:11:24.330 --> 00:11:30.080
So what we are going to
do is project this picture

00:11:30.080 --> 00:11:31.025
onto the integers.

00:11:33.880 --> 00:11:36.700
So that's a two-dimensional
arithmetic progression.

00:11:36.700 --> 00:11:45.240
And specifically, we
have a set of the form,

00:11:45.240 --> 00:11:52.300
so x0 is the starting
point, plus l1 of x1--

00:11:52.300 --> 00:11:57.830
l1 times x1, and l2
2 times x2, where

00:11:57.830 --> 00:12:04.070
the little l's are
integers, non-negative

00:12:04.070 --> 00:12:19.140
integers up to big L.

00:12:19.140 --> 00:12:23.110
So that's a two-dimensional
arithmetic progression.

00:12:23.110 --> 00:12:28.740
So the picture that you can have
in mind is, on the number line,

00:12:28.740 --> 00:12:35.470
we can get, write
down first an AP

00:12:35.470 --> 00:12:40.490
and then a few more
points like that so

00:12:40.490 --> 00:12:42.980
that you can have a
two-dimensional arithmetic

00:12:42.980 --> 00:12:43.911
progression.

00:12:48.630 --> 00:12:53.910
We say that this set, this
two-dimensional arithmetic

00:12:53.910 --> 00:13:05.635
progression is proper if
all terms are distinct.

00:13:12.570 --> 00:13:17.356
And if that's the case,
then I can write A plus A

00:13:17.356 --> 00:13:19.290
in a very similar format.

00:13:19.290 --> 00:13:26.780
So A plus A contains elements
still of the same form,

00:13:26.780 --> 00:13:32.420
but now the indices
go up to 2L minus 1.

00:13:39.120 --> 00:13:43.130
So you see that A plus A
has size, at most, 4 times

00:13:43.130 --> 00:13:47.600
the original set, A. Also easy
to see from this blue picture

00:13:47.600 --> 00:13:48.360
up there--

00:13:48.360 --> 00:13:49.880
you expand that grid.

00:13:49.880 --> 00:13:52.300
It goes to, at most,
4 times the size.

00:13:52.300 --> 00:13:53.055
Yes?

00:13:53.055 --> 00:13:56.520
AUDIENCE: [INAUDIBLE]

00:13:56.520 --> 00:13:58.840
YUFEI ZHAO: So the
question is, should it be?

00:13:58.840 --> 00:14:04.430
AUDIENCE: [INAUDIBLE]

00:14:04.430 --> 00:14:05.600
YUFEI ZHAO: 2x0?

00:14:05.600 --> 00:14:08.480
AUDIENCE: [INAUDIBLE]

00:14:08.480 --> 00:14:09.710
YUFEI ZHAO: What do you mean?

00:14:09.710 --> 00:14:11.485
AUDIENCE: 2x0 plus l1 x0 plus 1?

00:14:11.485 --> 00:14:13.360
YUFEI ZHAO: Ah, thank
you, so 2x0, thank you.

00:14:13.360 --> 00:14:15.220
Yeah, 2x0, great.

00:14:18.070 --> 00:14:21.400
OK, so that's the size.

00:14:21.400 --> 00:14:24.130
And of course, you can
generalize this example

00:14:24.130 --> 00:14:27.220
of a fairly straightforward
way to d dimensional arithmetic

00:14:27.220 --> 00:14:28.150
progressions.

00:14:28.150 --> 00:14:30.010
And we call those
things generalized

00:14:30.010 --> 00:14:33.200
arithmetic progressions.

00:14:33.200 --> 00:14:46.270
So a Generalized
Arithmetic Progression,

00:14:46.270 --> 00:14:50.250
which we will abbreviate
by the letters GAP,

00:14:50.250 --> 00:14:56.440
is a set of numbers
of the form as above,

00:14:56.440 --> 00:15:09.720
except now you have d different
directions and indices,

00:15:09.720 --> 00:15:12.270
are also straightforward
generalizations

00:15:12.270 --> 00:15:14.440
of what was earlier.

00:15:14.440 --> 00:15:17.340
So this is the notion of
a generalized arithmetic

00:15:17.340 --> 00:15:18.070
progression.

00:15:18.070 --> 00:15:20.220
So think about projection
of a d dimensional grid

00:15:20.220 --> 00:15:20.970
onto the integers.

00:15:23.640 --> 00:15:30.650
And for GAPs, we
say that it's proper

00:15:30.650 --> 00:15:32.015
if all the terms are distinct.

00:15:38.940 --> 00:15:47.310
We call d the
dimension of the GAP.

00:15:47.310 --> 00:15:51.150
And for a GAP, whether
it's proper or not,

00:15:51.150 --> 00:15:56.925
we call the size to be the
product of the lengths.

00:16:01.550 --> 00:16:05.290
And this is potentially larger.

00:16:05.290 --> 00:16:12.220
So this is larger than the
number of distinct elements

00:16:12.220 --> 00:16:15.790
if it's not proper.

00:16:15.790 --> 00:16:18.040
So when I refer to
the size of a GAP--

00:16:18.040 --> 00:16:20.260
so I view the GAP more
than just as a set,

00:16:20.260 --> 00:16:22.570
but also with the data
of the initial point

00:16:22.570 --> 00:16:24.050
and the directions.

00:16:24.050 --> 00:16:25.570
If I talk about the
size, I'm always

00:16:25.570 --> 00:16:27.630
referring to this
quantity over here.

00:16:32.360 --> 00:16:33.790
Great.

00:16:33.790 --> 00:16:39.910
So you see, if you take a GAP
or a fraction of a GAP, then,

00:16:39.910 --> 00:16:43.420
as with earlier examples,
you have small doubling.

00:16:45.930 --> 00:16:59.310
So if P is a proper
GAP, of dimension d,

00:16:59.310 --> 00:17:05.370
then P plus P is,
at most, 2 raised

00:17:05.370 --> 00:17:11.400
to power d times the size
of P. And furthermore,

00:17:11.400 --> 00:17:22.319
if A is an arbitrary subset of
P and such that A has size--

00:17:22.319 --> 00:17:25.400
such that the GAP
has size, at most,

00:17:25.400 --> 00:17:28.250
a constant fraction
bigger than that of A,

00:17:28.250 --> 00:17:32.430
then A has small
doubling as well.

00:17:45.120 --> 00:17:47.600
So all of these are
examples of constructions

00:17:47.600 --> 00:17:51.230
of sets where, for some
fixed constant, the doubling

00:17:51.230 --> 00:17:56.900
constant, we can
find a family of sets

00:17:56.900 --> 00:17:59.760
with doubling constant
bounded by that number.

00:18:02.646 --> 00:18:07.150
And the natural question though
is, are these all the examples?

00:18:07.150 --> 00:18:10.810
So have we missed
some important family

00:18:10.810 --> 00:18:14.700
of constructions not covered
by any of these examples?

00:18:14.700 --> 00:18:16.450
And so that's the kind
of inverse question

00:18:16.450 --> 00:18:17.717
I was referring to earlier.

00:18:17.717 --> 00:18:20.050
So all of these examples,
easy to check that they indeed

00:18:20.050 --> 00:18:21.258
have small doubling constant.

00:18:23.680 --> 00:18:24.990
Can you go in reverse?

00:18:24.990 --> 00:18:27.880
So can you ask the
inverse question,

00:18:27.880 --> 00:18:30.100
if a set has small
doubling constant,

00:18:30.100 --> 00:18:34.610
must it look like, in some
sense, one of these sets?

00:18:34.610 --> 00:18:38.770
It turns out this is not
such an easy problem.

00:18:38.770 --> 00:18:45.130
And there is a central result
in additive combinatorics known

00:18:45.130 --> 00:18:51.310
as Freiman's theorem which
gives a positive answer

00:18:51.310 --> 00:18:53.850
to that question.

00:18:53.850 --> 00:18:58.300
So Freiman's theorem is now
considered a central result

00:18:58.300 --> 00:19:00.040
in additive combinatorics.

00:19:00.040 --> 00:19:02.230
And it completely
describes, in some sense,

00:19:02.230 --> 00:19:05.380
the sets that have
small doubling.

00:19:05.380 --> 00:19:07.730
And let me write
down the statement.

00:19:07.730 --> 00:19:20.500
So if A is a subset of Z
and has bounded doubling,

00:19:20.500 --> 00:19:40.310
then A is contained in a GAP
of bounded dimension and size

00:19:40.310 --> 00:19:46.160
bounded by some constant
times the size of the set.

00:19:52.710 --> 00:19:54.085
This is a really
important result

00:19:54.085 --> 00:19:55.730
in additive combinatorics.

00:19:59.170 --> 00:20:04.480
The title of this chapter,
"Structure of Set Addition,"

00:20:04.480 --> 00:20:06.970
Freiman's theorem tells us
something about the structure

00:20:06.970 --> 00:20:09.220
of a set with small doubling.

00:20:11.740 --> 00:20:14.020
The next few lecturers
are going to be occupied

00:20:14.020 --> 00:20:15.550
with proving this theorem.

00:20:15.550 --> 00:20:18.090
So this theorem will have--

00:20:18.090 --> 00:20:20.290
its proof is involved and
probably the most involved

00:20:20.290 --> 00:20:22.330
proof that we have
in this course.

00:20:22.330 --> 00:20:25.570
And the proof will take
the next several lectures.

00:20:25.570 --> 00:20:27.610
And we'll see a lot of
different ingredients,

00:20:27.610 --> 00:20:29.377
a lot of really nice tools.

00:20:29.377 --> 00:20:31.210
Fourier analysis will
come up at some point,

00:20:31.210 --> 00:20:34.630
but also other tools like the
geometry of numbers and also

00:20:34.630 --> 00:20:37.935
some more classical additive
combinatorics ideas.

00:20:37.935 --> 00:20:39.310
But before starting
on a proof, I

00:20:39.310 --> 00:20:42.940
want to offer a few remarks
and historical remarks to just

00:20:42.940 --> 00:20:46.280
give you some more context
about Freiman's theorem,

00:20:46.280 --> 00:20:47.905
but first, a few
mathematical comments.

00:20:50.980 --> 00:20:53.290
In this conclusions
of Freiman's theorem,

00:20:53.290 --> 00:20:55.150
I didn't mention properness.

00:20:55.150 --> 00:20:57.220
And that's mostly a
matter of convenience.

00:20:57.220 --> 00:21:01.150
So you can, in fact, make
the conclusion proper

00:21:01.150 --> 00:21:05.200
as well at the cost of
increasing the number somewhat,

00:21:05.200 --> 00:21:08.110
but still constants
depending only on k--

00:21:11.890 --> 00:21:21.540
can guarantee
properness as well.

00:21:26.130 --> 00:21:31.240
So there is an extra step
involved which we'll not cover,

00:21:31.240 --> 00:21:32.670
because it's not
entirely trivial,

00:21:32.670 --> 00:21:33.795
but it's also not too hard.

00:21:37.260 --> 00:21:41.160
Freiman's original proof,
so it's named after Freiman.

00:21:41.160 --> 00:21:43.310
So he proved that in the '60s.

00:21:43.310 --> 00:21:46.320
But at that time, the proof
was considered rather obscure.

00:21:46.320 --> 00:21:50.220
It actually did not get the
attention and the recognition

00:21:50.220 --> 00:21:52.740
that it deserved
until much later.

00:21:52.740 --> 00:21:55.530
So this was kind of a forgotten
result, a forgotten proof

00:21:55.530 --> 00:22:00.700
for a very long time until
quite a bit later when Ruzsa--

00:22:00.700 --> 00:22:03.150
Ruzsa's name will come up
many times in this chapter.

00:22:03.150 --> 00:22:06.290
Ruzsa came and gave a different
proof of Freiman's theorem,

00:22:06.290 --> 00:22:07.915
and significantly
cleaned up the proof,

00:22:07.915 --> 00:22:09.750
and offered many new ideas.

00:22:09.750 --> 00:22:12.390
So much of what we'll
see today are results

00:22:12.390 --> 00:22:14.190
that we now attribute to Ruzsa.

00:22:14.190 --> 00:22:16.570
And theorem sometimes
is also called

00:22:16.570 --> 00:22:17.930
the Freiman-Ruzsa theorem.

00:22:25.650 --> 00:22:27.740
But this result was
really brought into--

00:22:30.360 --> 00:22:33.520
brought as a highlight
of additive combinatorics

00:22:33.520 --> 00:22:36.540
in the work of Gowers
when he proved,

00:22:36.540 --> 00:22:40.000
that gave his new proof
of Szemerédi's theorem,

00:22:40.000 --> 00:22:41.620
giving much better bounds.

00:22:41.620 --> 00:22:46.630
So he had to use quite a bit of
serious additive combinatorics.

00:22:46.630 --> 00:22:50.410
And many of the ideas that
went into Gowers' proof

00:22:50.410 --> 00:22:53.290
of Szemerédi's theorem came
from this line of work,

00:22:53.290 --> 00:22:55.170
Freiman and Ruzsa.

00:22:55.170 --> 00:22:58.780
So and their work was, again,
brought into prominence

00:22:58.780 --> 00:23:02.050
as a result of Gowers'
Fields-Medal-winning work

00:23:02.050 --> 00:23:03.580
on Szemerédi's theorem.

00:23:06.590 --> 00:23:08.610
So this is some of the history.

00:23:08.610 --> 00:23:10.720
And now Freiman's
theorem is considered

00:23:10.720 --> 00:23:13.118
a central result in the area.

00:23:13.118 --> 00:23:14.660
You can see, it's
a beautiful result.

00:23:14.660 --> 00:23:17.730
And it's also quite
a deep result.

00:23:17.730 --> 00:23:20.060
Let me mention a few
things about bounds.

00:23:20.060 --> 00:23:25.380
So what do we know about
this d of k and f of k?

00:23:25.380 --> 00:23:27.400
But first, an example--

00:23:27.400 --> 00:23:32.460
so if the set A is dissociated
in the sense of having

00:23:32.460 --> 00:23:40.460
no arithmetic structure,
no coincidental sums

00:23:40.460 --> 00:23:44.960
colliding, so for example,
if a of this form,

00:23:44.960 --> 00:23:47.360
then you see that--

00:23:47.360 --> 00:23:51.800
also and we saw the size of A
plus A, so A plus 1 choose 2.

00:23:51.800 --> 00:23:57.790
So in this case, the
doubling constant

00:23:57.790 --> 00:24:03.385
is the size of A plus 1
divided by 2, so roughly

00:24:03.385 --> 00:24:07.260
on the same order
as the size of A.

00:24:07.260 --> 00:24:11.010
But what do you need to
take in Freiman's theorem

00:24:11.010 --> 00:24:13.820
for d and for f?

00:24:13.820 --> 00:24:17.140
So how can I embed this A
in generalized arithmetic

00:24:17.140 --> 00:24:19.366
progression?

00:24:19.366 --> 00:24:23.990
See, there is not a
great way to do it.

00:24:23.990 --> 00:24:26.005
So I want to keep
the size small.

00:24:26.005 --> 00:24:27.660
There is not a
great way to do it.

00:24:27.660 --> 00:24:31.700
So one way to do it is
to use one direction

00:24:31.700 --> 00:24:35.170
for each of these elements.

00:24:35.170 --> 00:24:39.857
So contained in GAP--

00:24:39.857 --> 00:24:41.440
now of course, there
is always a trade

00:24:41.440 --> 00:24:43.447
off between dimension and size.

00:24:43.447 --> 00:24:44.530
But usually, not a great--

00:24:44.530 --> 00:24:46.820
I mean, it's not such
an important trade off.

00:24:46.820 --> 00:24:49.780
So but certainly it's
contained in the GAP

00:24:49.780 --> 00:24:55.180
of dimension size of
A minus 1 and size

00:24:55.180 --> 00:25:00.370
2 to the size of A minus 1,
by thinking about A as a cube.

00:25:03.380 --> 00:25:06.330
And so you convince yourself
that you basically cannot do

00:25:06.330 --> 00:25:06.830
much better.

00:25:10.400 --> 00:25:24.710
So the best possible bound
that we can hope to prove

00:25:24.710 --> 00:25:33.820
is of the form d being,
at most, linear in k,

00:25:33.820 --> 00:25:38.420
and f being, at most,
exponential in k.

00:25:41.680 --> 00:25:43.510
So you see already,
the bounds, that you

00:25:43.510 --> 00:25:45.130
have to lose some things.

00:25:45.130 --> 00:25:45.710
Yes?

00:25:45.710 --> 00:25:47.710
AUDIENCE: Why can't we
just make the dimension 1

00:25:47.710 --> 00:25:50.295
and just let our arithmetic
progression be 1 through 2

00:25:50.295 --> 00:25:51.647
to the sine of A minus 1?

00:25:51.647 --> 00:25:53.730
YUFEI ZHAO: OK, great, so
that's a great question.

00:25:53.730 --> 00:25:56.600
So why can't we just
make dimension 1

00:25:56.600 --> 00:25:59.000
and have the entire
thing be as part

00:25:59.000 --> 00:26:01.170
of a single linear
arithmetic progression?

00:26:01.170 --> 00:26:04.490
So you can do that, but then
I can cook up other examples

00:26:04.490 --> 00:26:08.110
where I blow up this cube.

00:26:08.110 --> 00:26:10.080
So I ask you to think
about how to do that.

00:26:10.080 --> 00:26:12.150
So you can try to
blow up this cube

00:26:12.150 --> 00:26:14.960
so that you really
do need the dimension

00:26:14.960 --> 00:26:21.492
to not be constant, so exercise.

00:26:21.492 --> 00:26:24.730
So the best result is
not quite this claim.

00:26:24.730 --> 00:26:26.080
So this is still open.

00:26:26.080 --> 00:26:32.110
So the best result so far is
due to Tom Sanders, whose name

00:26:32.110 --> 00:26:34.720
came up earlier, as he has
basically the best bound

00:26:34.720 --> 00:26:35.752
on Roth's theorem.

00:26:35.752 --> 00:26:37.210
And you know, many
of these results

00:26:37.210 --> 00:26:40.160
are all related to each other.

00:26:40.160 --> 00:26:51.860
So Sanders has-- so he showed
that Freiman's theorem is

00:26:51.860 --> 00:27:00.090
true with d being,
so basically k,

00:27:00.090 --> 00:27:04.600
but you lose a poly log factor.

00:27:04.600 --> 00:27:07.610
I think the big O is maybe
3, or 4, something like that,

00:27:07.610 --> 00:27:09.390
so not substantial.

00:27:09.390 --> 00:27:14.670
And then f of k is also
basically exponential,

00:27:14.670 --> 00:27:16.880
but you lose a poly log
factor in the exponent.

00:27:21.870 --> 00:27:25.020
Just a minor note about
how to read this notation--

00:27:25.020 --> 00:27:28.500
so I mean, it's written
slightly sloppily as log k

00:27:28.500 --> 00:27:29.880
raised to big O of 1.

00:27:29.880 --> 00:27:33.750
You should think k as
constant, but somewhat big,

00:27:33.750 --> 00:27:37.200
because if k were 2,
this notation actually

00:27:37.200 --> 00:27:38.560
doesn't make sense.

00:27:38.560 --> 00:27:41.883
So just think of
chaos, as at least 3

00:27:41.883 --> 00:27:43.050
when you read that notation.

00:27:45.750 --> 00:27:49.550
All right, so we will
prove Freiman's theorem.

00:27:49.550 --> 00:27:51.580
So this bound will
show a worse bound.

00:27:51.580 --> 00:27:53.737
It actually will be basically
exponentially worse,

00:27:53.737 --> 00:27:54.820
but it will be a constant.

00:27:54.820 --> 00:27:57.370
So it will be just
a function of k.

00:27:57.370 --> 00:28:00.800
And that will take us the
next several lectures.

00:28:00.800 --> 00:28:05.260
So we'll begin by developing
some tools that are,

00:28:05.260 --> 00:28:07.070
I think, of interest
individually.

00:28:07.070 --> 00:28:09.308
And they can all be
used for other things.

00:28:09.308 --> 00:28:10.850
So we'll develop
some tools that will

00:28:10.850 --> 00:28:15.380
help us to show, eventually
lead us to Freiman's theorem.

00:28:15.380 --> 00:28:18.020
And I'll try to structure
this proof in such a way

00:28:18.020 --> 00:28:21.110
that there are several
goal posts that

00:28:21.110 --> 00:28:22.580
are also interesting.

00:28:22.580 --> 00:28:25.960
So in particular, just as what
we did with Roth's theorem,

00:28:25.960 --> 00:28:28.640
we'll begin by
proving a finite field

00:28:28.640 --> 00:28:32.270
analog of Freiman's theorem.

00:28:32.270 --> 00:28:36.860
So what would that mean,
a finite field analog?

00:28:36.860 --> 00:28:39.810
So what would a problem like
this mean in F2 to the n?

00:28:52.680 --> 00:29:00.140
So in F2 to the n, so this
is a finite field analog.

00:29:00.140 --> 00:29:05.060
If A plus A is small--

00:29:10.005 --> 00:29:13.400
so I'm not trying to
ask an inverse question.

00:29:13.400 --> 00:29:17.050
But what are examples of
sets in F2 to the n that

00:29:17.050 --> 00:29:20.345
have small doubling?

00:29:20.345 --> 00:29:21.728
AUDIENCE: 2 to the n.

00:29:21.728 --> 00:29:25.167
YUFEI ZHAO: So 2 to the n, so
you can take the entire space.

00:29:25.167 --> 00:29:27.000
Any other examples that
have small doubling?

00:29:33.503 --> 00:29:34.920
AUDIENCE: You can
take a subspace.

00:29:34.920 --> 00:29:36.712
YUFEI ZHAO: Exactly,
I can take a subspace.

00:29:36.712 --> 00:29:38.780
So a subspace, well,
it doesn't grow.

00:29:38.780 --> 00:29:43.460
So A plus A is the same
as A. All right, so

00:29:43.460 --> 00:29:47.960
and also, as before, you can
take a subset of a subspace.

00:29:47.960 --> 00:29:50.480
So then the analog
of Freiman's theorem

00:29:50.480 --> 00:30:06.950
will say that A is contained
in a subspace of size, at most,

00:30:06.950 --> 00:30:13.930
a constant times the size of A.

00:30:13.930 --> 00:30:18.950
So this is the analog of
Freiman's theorem in F2.

00:30:18.950 --> 00:30:22.040
And so we'll see, so
this will be much easier

00:30:22.040 --> 00:30:24.040
than the general result
about Freiman's theorem,

00:30:24.040 --> 00:30:26.190
but it will involve
a subset of F2.

00:30:26.190 --> 00:30:28.060
And we'll see this
theorem first.

00:30:28.060 --> 00:30:30.760
So we'll prove
that next lecture.

00:30:30.760 --> 00:30:33.400
Of course, this is much
easier in many ways,

00:30:33.400 --> 00:30:35.470
because here, unlike
before, I don't even

00:30:35.470 --> 00:30:37.700
have to think about
what subspace to take.

00:30:37.700 --> 00:30:43.900
I can just take the subspace
generated by the elements of A.

00:30:43.900 --> 00:30:49.084
All right, Any questions so far?

00:30:49.084 --> 00:30:49.584
Yes?

00:30:49.584 --> 00:30:52.853
AUDIENCE: Is the f of k
here still exponential in k?

00:30:52.853 --> 00:30:54.770
YUFEI ZHAO: OK, so the
question, is the f of k

00:30:54.770 --> 00:30:56.910
here still exponential in k?

00:30:56.910 --> 00:30:58.870
So the answer is, yes.

00:30:58.870 --> 00:31:01.560
And the construction is if
you take A to be a basis.

00:31:05.790 --> 00:31:10.020
OK, so let's start with some
techniques and some proofs.

00:31:23.830 --> 00:31:27.900
So in this chapter, many
things are named after Ruzsa.

00:31:27.900 --> 00:31:30.960
And at some point, it
becomes slightly confusing

00:31:30.960 --> 00:31:33.353
which ones are not
named after Ruzsa.

00:31:33.353 --> 00:31:35.270
But the first thing will
be named after Ruzsa.

00:31:35.270 --> 00:31:37.341
So it's a Ruzsa
Triangle Inequality.

00:31:45.197 --> 00:31:48.520
All right, the Ruzsa
Triangle Inequality

00:31:48.520 --> 00:31:52.390
tells us that, if A, B, and C--

00:31:52.390 --> 00:31:54.500
so unless otherwise
I tell you so,

00:31:54.500 --> 00:31:57.310
and I'll try to remind you
each time, but basically,

00:31:57.310 --> 00:32:01.240
we're always going to
be looking finite sets

00:32:01.240 --> 00:32:09.940
in an arbitrary obedient group
always with an under addition--

00:32:09.940 --> 00:32:15.790
then one has the inequality on
their sizes of different sets.

00:32:22.750 --> 00:32:25.520
The size of A times
the size of B minus C

00:32:25.520 --> 00:32:28.800
is upper bounded by the size of
A minus B times the size of A

00:32:28.800 --> 00:32:36.500
minus C. So that's the
Ruzsa Triangle Inequality.

00:32:36.500 --> 00:32:39.490
Let me show you the proof.

00:32:39.490 --> 00:32:51.300
We will construct an injection
from A cross B minus C

00:32:51.300 --> 00:32:57.420
to A minus B cross A
minus C. Of course,

00:32:57.420 --> 00:32:59.620
if you can exhibit
such an injection,

00:32:59.620 --> 00:33:03.170
then you prove the
desired inequality.

00:33:03.170 --> 00:33:11.640
To obtain this injection, we
start with an element a, d.

00:33:11.640 --> 00:33:17.400
And for this a, d, so
for each d, let me pick--

00:33:20.410 --> 00:33:24.850
so if d is an
element of B minus C,

00:33:24.850 --> 00:33:30.450
let us pick arbitrarily but
stick with those choices

00:33:30.450 --> 00:33:41.550
a b of d in the set B and
a c of d in the set C such

00:33:41.550 --> 00:33:47.180
that d equals to b
of d minus c of d.

00:33:47.180 --> 00:33:51.660
So because d is
the set B minus C,

00:33:51.660 --> 00:33:54.720
it can be represented as a
difference from one element

00:33:54.720 --> 00:33:55.340
from each set.

00:33:55.340 --> 00:33:58.210
So it may be represented
in many ways.

00:33:58.210 --> 00:34:00.740
But from the start, you
pick a way to represent it.

00:34:00.740 --> 00:34:02.290
And you stick with that choice.

00:34:02.290 --> 00:34:05.598
And you label that
function b of d and c of d.

00:34:08.670 --> 00:34:21.570
Now I map a, d to the element
a minus b of d and a minus

00:34:21.570 --> 00:34:22.170
c of d.

00:34:28.070 --> 00:34:30.230
So this is a map.

00:34:30.230 --> 00:34:32.104
I want to show that
it is injective.

00:34:35.830 --> 00:34:37.296
Why is it injective?

00:34:41.760 --> 00:34:43.650
Well, to show
something is injective,

00:34:43.650 --> 00:34:46.080
I just need to show that
I can recover where I came

00:34:46.080 --> 00:34:49.810
from if I tell you the image.

00:34:49.810 --> 00:34:54.850
So I can recover a and d
from these two numbers.

00:34:54.850 --> 00:34:58.930
So if-- sorry, new board.

00:35:05.040 --> 00:35:07.470
OK, so well you
basically can think

00:35:07.470 --> 00:35:12.320
about how you can recover a
and d from the image elements.

00:35:21.540 --> 00:35:24.140
So if the image--

00:35:24.140 --> 00:35:27.440
so I label that map phi.

00:35:27.440 --> 00:35:28.790
So that's phi up there.

00:35:28.790 --> 00:35:42.520
So if the image is given,
then I can recover d.

00:35:42.520 --> 00:35:44.380
So how can we recover
the element d?

00:35:50.810 --> 00:35:53.090
So you subtract
these two numbers.

00:35:53.090 --> 00:35:55.860
So d is minus x.

00:35:55.860 --> 00:35:58.940
And once you recover d,
you can also then take

00:35:58.940 --> 00:36:00.230
a look at the first element.

00:36:00.230 --> 00:36:01.680
And you can recover a.

00:36:06.030 --> 00:36:06.980
So now you know d.

00:36:06.980 --> 00:36:10.490
I can now recover a.

00:36:10.490 --> 00:36:13.420
OK, so then this is-- you can
check this is an injection.

00:36:13.420 --> 00:36:19.269
And that proves the Ruzsa
Triangle Inequality.

00:36:19.269 --> 00:36:24.468
OK, so it's short,
but it's tricky.

00:36:24.468 --> 00:36:26.380
It's tricky.

00:36:26.380 --> 00:36:29.320
OK, so why is this called
Ruzsa's Triangle Inequality?

00:36:29.320 --> 00:36:31.770
Where is the triangle in this?

00:36:31.770 --> 00:36:36.090
The reason that it's given
that name is that you can write

00:36:36.090 --> 00:36:38.360
the inequality as follows.

00:36:38.360 --> 00:36:45.070
Suppose we use rho A, B to
denote this quantity obtained

00:36:45.070 --> 00:36:49.630
by taking the log of the
size of A minus B divided

00:36:49.630 --> 00:36:52.510
by the square root
of the product

00:36:52.510 --> 00:36:59.470
of their individual
sizes, then the inequality

00:36:59.470 --> 00:37:05.860
says that the rho
of B, C is, at most,

00:37:05.860 --> 00:37:13.100
rho of A, B plus rho of A, C,
which looks like a triangle

00:37:13.100 --> 00:37:14.590
inequality.

00:37:14.590 --> 00:37:16.910
So that's why it's called
Ruzsa's Triangle Inequality,

00:37:16.910 --> 00:37:17.720
because this is--

00:37:17.720 --> 00:37:20.660
don't take it too seriously,
because this is not a distance.

00:37:24.960 --> 00:37:30.560
So rho of A, A is
not equal to 0.

00:37:30.560 --> 00:37:33.540
But it certainly has the form
of a triangle inequality, hence

00:37:33.540 --> 00:37:34.040
the name.

00:37:37.560 --> 00:37:39.780
How should you think of
Ruzsa's triangle inequality?

00:37:39.780 --> 00:37:40.900
So in this chapter,
there's going

00:37:40.900 --> 00:37:42.480
to be a lot of symbol
pushing around.

00:37:42.480 --> 00:37:45.310
And it's easy to get lost and
buried in all of these symbols.

00:37:45.310 --> 00:37:48.390
And I want to tell
you about how you

00:37:48.390 --> 00:37:52.430
might think about what's the
point of Ruzsa's Triangle

00:37:52.430 --> 00:37:52.930
Inequality.

00:37:52.930 --> 00:37:55.120
How would you use it?

00:37:55.120 --> 00:38:02.230
And the idea is that if you
have a set with small doubling,

00:38:02.230 --> 00:38:04.780
we want to use Ruzsa's
triangle inequality

00:38:04.780 --> 00:38:08.998
and other tools to control
its further doublings.

00:38:11.810 --> 00:38:14.760
So in particular, if--

00:38:14.760 --> 00:38:19.790
so I'll say, applications.

00:38:19.790 --> 00:38:27.755
So suppose you knew
that 2A minus 2A

00:38:27.755 --> 00:38:31.040
is size, at most, k
times A. So this is

00:38:31.040 --> 00:38:34.790
a stronger hypothesis than
just A has small doublings.

00:38:34.790 --> 00:38:37.400
Even if you iterate
it several times,

00:38:37.400 --> 00:38:42.156
you still have size, at
most, constant times A.

00:38:42.156 --> 00:38:45.250
I would like to start
from this hypothesis

00:38:45.250 --> 00:38:49.120
and control further
iterations, further subsets

00:38:49.120 --> 00:38:51.700
of A. And Ruzsa's
Triangle Inequality

00:38:51.700 --> 00:39:00.820
allows us to do it, because
by the Ruzsa's Triangle

00:39:00.820 --> 00:39:09.630
Inequality, setting B
and C to be 2A minus A,

00:39:09.630 --> 00:39:18.330
we find that 3A minus 3A is,
at most, 2A minus 2A squared

00:39:18.330 --> 00:39:22.950
over A, the size of
A. So plug it in.

00:39:22.950 --> 00:39:25.680
This is what you get.

00:39:25.680 --> 00:39:29.810
So if the size of 2A plus 2A is,
at most, k times the size of A,

00:39:29.810 --> 00:39:35.500
then the size of
3A times 3A is--

00:39:35.500 --> 00:39:38.550
blows up by a factor,
at most, k squared.

00:39:38.550 --> 00:39:40.650
So it controls
further doublings.

00:39:40.650 --> 00:39:42.368
And of course, we can iterate.

00:39:46.220 --> 00:39:53.180
If we know set B and
C to be 3A minus 2A,

00:39:53.180 --> 00:39:57.890
then what we get is 5A
minus 5A is, at most,

00:39:57.890 --> 00:40:02.930
a size of 3A minus 3A square
divided by the size of A.

00:40:02.930 --> 00:40:08.760
And so now you have a bound
which is k to the 4 times A.

00:40:08.760 --> 00:40:11.464
And you can continue.

00:40:11.464 --> 00:40:12.922
You can continue.

00:40:15.672 --> 00:40:17.880
OK, so this is all a
consequence of Ruzsa's triangle.

00:40:17.880 --> 00:40:19.920
So starting with
this hypothesis,

00:40:19.920 --> 00:40:25.160
now I get to control all
the further doublings,

00:40:25.160 --> 00:40:26.850
the further subset iterations.

00:40:26.850 --> 00:40:29.620
I call them doublings, but
they're no longer doubles,

00:40:29.620 --> 00:40:32.580
but further subsets.

00:40:32.580 --> 00:40:34.650
But this is a stronger
hypothesis than the one

00:40:34.650 --> 00:40:37.790
that we start with
in Freiman's theorem,

00:40:37.790 --> 00:40:42.300
because if you have that,
then this 2A minus 2A

00:40:42.300 --> 00:40:45.640
is at least as large
as the size of 2A.

00:40:45.640 --> 00:40:50.350
So can we start with
just doubling constant

00:40:50.350 --> 00:40:55.410
and then obtain bounds
on the iterations?

00:40:55.410 --> 00:40:56.960
| it turns out you can.

00:40:56.960 --> 00:41:00.270
It will require another theorem.

00:41:07.130 --> 00:41:10.753
So this theorem is called
Plunnecke inequality.

00:41:14.070 --> 00:41:16.790
But actually, these
days, in literature,

00:41:16.790 --> 00:41:21.560
it's often referred to as
Plunnecke-Ruzsa inequality.

00:41:21.560 --> 00:41:23.330
So Plunnecke
initially proved it.

00:41:23.330 --> 00:41:25.130
But nobody understood his proof.

00:41:25.130 --> 00:41:26.718
And Ruzsa gave a better proof.

00:41:26.718 --> 00:41:29.010
And actually, recently, there
was an even better proof.

00:41:29.010 --> 00:41:31.688
And that's the one
I will show you.

00:41:31.688 --> 00:41:34.680
So Plunnecke-Ruzsa
inequality tells us

00:41:34.680 --> 00:41:45.680
that if A is subset of
some obedient group,

00:41:45.680 --> 00:41:54.340
and has doubling
constant, at most, k,

00:41:54.340 --> 00:42:03.930
then for all non-negative
integers m and n,

00:42:03.930 --> 00:42:10.440
the size of mA minus
nA is, at most,

00:42:10.440 --> 00:42:17.230
k to the m plus n
times the size of A.

00:42:17.230 --> 00:42:22.490
So if you have bounded doubling,
then the further iterations,

00:42:22.490 --> 00:42:27.520
the further subset iterations
are also controlling size.

00:42:27.520 --> 00:42:31.480
I want you to think of
polynomial transformations in k

00:42:31.480 --> 00:42:33.320
as negligible.

00:42:33.320 --> 00:42:36.340
So don't worry about that
we're raising things here.

00:42:36.340 --> 00:42:37.210
k is constant.

00:42:37.210 --> 00:42:39.640
You should think of
m and n as constant.

00:42:39.640 --> 00:42:42.015
So I'm changing k to
some other constant.

00:42:42.015 --> 00:42:44.210
And in fact, I'm only
changing it by a polynomial.

00:42:44.210 --> 00:42:46.150
So this is, like,
almost no change at all.

00:42:50.810 --> 00:42:52.600
So this is tricky.

00:42:52.600 --> 00:42:56.210
So we'll do it
after a short break.

00:42:56.210 --> 00:42:59.150
All right, let's prove
Plunnecke's inequality,

00:42:59.150 --> 00:43:00.290
Plunnecke-Ruzsa inequality.

00:43:00.290 --> 00:43:05.770
So the history of
Plunnecke's inequality

00:43:05.770 --> 00:43:08.160
has some similarities
with Freiman's theorem.

00:43:08.160 --> 00:43:09.760
So Plunnecke
initially proved it,

00:43:09.760 --> 00:43:13.390
but his proof was
hard to understand

00:43:13.390 --> 00:43:16.330
and was sort of left not
understood for a long time

00:43:16.330 --> 00:43:20.230
until others like
Plun and Ruzsa came in

00:43:20.230 --> 00:43:22.690
and really simplified the proof.

00:43:22.690 --> 00:43:26.320
But even then, the
proof was not so easy.

00:43:26.320 --> 00:43:30.260
And if I were teaching this
course about 10 years ago,

00:43:30.260 --> 00:43:32.440
I would have just skipped
this proof, maybe sketched

00:43:32.440 --> 00:43:34.398
some ideas, but I would
have skipped the proof.

00:43:34.398 --> 00:43:36.595
And the proof, actually,
it's a beautiful proof,

00:43:36.595 --> 00:43:38.860
but it uses some
serious graph theory.

00:43:38.860 --> 00:43:41.658
It uses Menger's
theorem about flows.

00:43:41.658 --> 00:43:42.700
You construct some graph.

00:43:42.700 --> 00:43:45.132
And then you try to
understand its flows.

00:43:45.132 --> 00:43:46.090
It's very pretty stuff.

00:43:46.090 --> 00:43:50.170
And I do encourage
you to look it up.

00:43:50.170 --> 00:43:53.560
And then about eight
years ago, Petridis

00:43:53.560 --> 00:44:03.290
found a proof, so a
proof by Petridis,

00:44:03.290 --> 00:44:06.450
who was a PhD student that
Tim Gowers at the time.

00:44:06.450 --> 00:44:10.200
And that was surprisingly
short, and beautiful,

00:44:10.200 --> 00:44:13.650
and kind of surprised everyone
that such a short proof exists,

00:44:13.650 --> 00:44:16.200
given that this theorem
sat in that state

00:44:16.200 --> 00:44:17.450
for such a long time.

00:44:17.450 --> 00:44:20.340
And it's a pretty
central step in the proof

00:44:20.340 --> 00:44:23.500
of Freiman's theorem.

00:44:23.500 --> 00:44:27.600
We'll prove Plunnecke-Ruzsa
via a slightly more general

00:44:27.600 --> 00:44:28.690
statement.

00:44:28.690 --> 00:44:32.393
So you see, it generalizes
the earlier statement.

00:44:32.393 --> 00:44:33.810
Instead of having
one set, it will

00:44:33.810 --> 00:44:36.930
be convenient to have
two different sets.

00:44:36.930 --> 00:44:46.500
So let A and B be subsets of
some obedient group, as usual.

00:44:50.350 --> 00:44:59.490
If size of A plus B is, at
most, k times the size of A,

00:44:59.490 --> 00:45:08.490
then mB minus nB
has size, at most,

00:45:08.490 --> 00:45:13.650
k to the m plus n
times the size of A

00:45:13.650 --> 00:45:19.028
for all non-negative
integers m and n.

00:45:19.028 --> 00:45:21.070
So instead of having one
set, so I have two sets,

00:45:21.070 --> 00:45:24.580
A and B. Of course, then you
derive the earlier statement

00:45:24.580 --> 00:45:27.040
setting A and B to equal.

00:45:27.040 --> 00:45:29.314
So we'll prove this
more general statement.

00:45:34.640 --> 00:45:37.400
The proof uses a key lemma.

00:45:40.390 --> 00:45:54.330
And the key lemma says that if
a subset x of A is non-empty

00:45:54.330 --> 00:45:55.430
and--

00:45:55.430 --> 00:46:05.720
so if x is a
non-empty subset of A

00:46:05.720 --> 00:46:21.500
that minimizes the ratio x
plus B divided by size of x,

00:46:21.500 --> 00:46:32.160
and let k prime be this
ratio, this minimum ratio,

00:46:32.160 --> 00:46:40.780
then so the conclusion
says that x plus B plus C

00:46:40.780 --> 00:46:48.200
has size, at most, k prime times
the size of x plus C for all

00:46:48.200 --> 00:46:53.230
sets C.

00:46:53.230 --> 00:46:54.510
So that's the statement.

00:46:54.510 --> 00:46:57.576
I'll explain how you should
think about the statement.

00:47:00.770 --> 00:47:05.420
These ratios which you
see in both hypotheses,

00:47:05.420 --> 00:47:10.210
how you should think about them
is that there is this graph.

00:47:10.210 --> 00:47:14.840
Let's say it's the group
bipartite graph with the group

00:47:14.840 --> 00:47:17.070
elements on both sides.

00:47:17.070 --> 00:47:22.430
And the graph has edges,
the bipartite graph,

00:47:22.430 --> 00:47:30.500
where the edges are from
each vertex a drawn edge

00:47:30.500 --> 00:47:35.400
for each element of
B. So I expand by B.

00:47:35.400 --> 00:47:37.920
So if you have
this graph and you

00:47:37.920 --> 00:47:45.280
start with some A on the left,
then its neighbors on the right

00:47:45.280 --> 00:47:56.910
will be A plus B. And
those ratios up there

00:47:56.910 --> 00:47:59.790
are the expansion ratios.

00:47:59.790 --> 00:48:05.975
so quantities like this,
they are expansion ratios.

00:48:08.520 --> 00:48:11.070
You start with some
set on the left

00:48:11.070 --> 00:48:13.890
and see by a what fraction
does it expand if you

00:48:13.890 --> 00:48:16.730
look at the neighborhood.

00:48:16.730 --> 00:48:20.010
So let's read the
statement of the key lemma.

00:48:20.010 --> 00:48:23.630
It says, if you have a set x--

00:48:23.630 --> 00:48:25.420
I look, so I have
a set A. And I'm

00:48:25.420 --> 00:48:31.420
choosing a subset of A that
minimizes the expansion ratio,

00:48:31.420 --> 00:48:33.260
so choose a
non-empty subset that

00:48:33.260 --> 00:48:36.080
minimizes the expansion ratio.

00:48:36.080 --> 00:48:41.950
And if this minimum expense
ratio is k prime, then,

00:48:41.950 --> 00:48:53.550
so x minimizes expansion ratio
and expense ratios k prime,

00:48:53.550 --> 00:49:04.660
then x plus C also has expansion
ratio, at most, k prime

00:49:04.660 --> 00:49:05.160
as well.

00:49:08.560 --> 00:49:09.771
So that's the statement.

00:49:12.480 --> 00:49:15.060
I mentioned earlier that the
previous proofs of this theorem

00:49:15.060 --> 00:49:18.750
went through some graph
theory and Menger's theorem,

00:49:18.750 --> 00:49:20.530
that type of graph theory.

00:49:20.530 --> 00:49:23.695
You can kind of see
where it might come in.

00:49:23.695 --> 00:49:24.820
We're not going to do that.

00:49:24.820 --> 00:49:26.100
We're going to stick with
additive combinatorics.

00:49:26.100 --> 00:49:28.620
We're going to stick
with playing with sums,

00:49:28.620 --> 00:49:30.870
playing with additive
combinatorics.

00:49:30.870 --> 00:49:34.390
So let's see how we can
prove the statement up there,

00:49:34.390 --> 00:49:35.620
so using the key lemma.

00:49:39.960 --> 00:49:50.580
So assuming key lemma, so
let's prove the statement,

00:49:50.580 --> 00:49:52.610
the theorem up there.

00:49:52.610 --> 00:50:01.520
So take a non-empty
subset x of A--

00:50:01.520 --> 00:50:12.640
sorry, so x subset of A that
minimizes the ratio x plus B

00:50:12.640 --> 00:50:16.600
divided by x.

00:50:16.600 --> 00:50:20.140
And let k prime be
this minimum ratio.

00:50:25.710 --> 00:50:30.390
Note that k prime
is, at most, k,

00:50:30.390 --> 00:50:33.810
because if you plug in x
equals the k, you get--

00:50:33.810 --> 00:50:36.980
if you plug in x
equals to A, you get k.

00:50:36.980 --> 00:50:40.870
But I'm choosing x to
be possibly even lower.

00:50:40.870 --> 00:50:42.510
So k prime is, at most, k.

00:50:50.738 --> 00:51:03.980
Now, applying the lemma, so
applying the key lemma with C

00:51:03.980 --> 00:51:14.294
equals to B, we find that
x plus 2B, so C, plug in B,

00:51:14.294 --> 00:51:23.780
x plus 2B has size, at most,
k times size of x plus B.

00:51:23.780 --> 00:51:28.490
But the size of x plus B is,
at most, k times the size of A.

00:51:28.490 --> 00:51:35.430
So we get k squared, so k
times the size of x, at most, k

00:51:35.430 --> 00:51:37.860
squared x.

00:51:37.860 --> 00:51:41.430
So we're already in good shape.

00:51:41.430 --> 00:51:44.220
If you iterate
expansion twice-- so

00:51:44.220 --> 00:51:46.170
I imagine there
is several chains

00:51:46.170 --> 00:51:47.976
of these bipartite graphs.

00:51:47.976 --> 00:51:50.250
If you iterate this
expansion twice,

00:51:50.250 --> 00:51:52.410
you still do not
blow up by too much.

00:51:54.970 --> 00:51:58.610
So we can iterate further,
so apply the lemma

00:51:58.610 --> 00:52:05.460
with C being now 2B, and
then later 3B, and so on.

00:52:05.460 --> 00:52:13.530
So you find that x
plus nB has size,

00:52:13.530 --> 00:52:18.320
at most, k raised to power
n times the size of x

00:52:18.320 --> 00:52:21.430
for all non-negative
integers, n.

00:52:30.930 --> 00:52:32.600
What do we want to control?

00:52:32.600 --> 00:52:39.810
So we want to prove a bound
on the size of mB minus nB.

00:52:39.810 --> 00:52:43.721
Take a look at the statement
of Ruzsa Triangle Inequality.

00:52:50.790 --> 00:52:53.970
Applying Ruzsa
Triangle Inequality,

00:52:53.970 --> 00:53:02.800
we find that if we want
to control mB minus nB,

00:53:02.800 --> 00:53:13.390
we can upper bound it by x
plus mB x plus nB divided

00:53:13.390 --> 00:53:15.370
by the size of x.

00:53:18.160 --> 00:53:22.630
Because each of these two
factors in the numerator

00:53:22.630 --> 00:53:26.080
are small expansions
of x, now we

00:53:26.080 --> 00:53:30.430
can upper bound the whole
expression by k to the m

00:53:30.430 --> 00:53:35.790
plus n times the size of x.

00:53:35.790 --> 00:53:43.950
And because x is a subset of A,
we can do one more upper bound

00:53:43.950 --> 00:53:46.410
and obtain the bound
that we are looking for.

00:53:51.400 --> 00:53:53.020
OK, so that proves
the key lemma.

00:53:56.764 --> 00:53:57.700
It's OK?

00:53:57.700 --> 00:53:59.580
AUDIENCE: [INAUDIBLE]

00:53:59.580 --> 00:54:02.170
YUFEI ZHAO: Sorry, that
proves the theorem,

00:54:02.170 --> 00:54:03.587
assuming the key lemma.

00:54:03.587 --> 00:54:05.170
Thank you, that's
what I meant to say.

00:54:05.170 --> 00:54:06.680
Yeah, so that
proves the theorem,

00:54:06.680 --> 00:54:07.638
assuming the key lemma.

00:54:07.638 --> 00:54:10.170
So now we do prove
the key lemma.

00:54:10.170 --> 00:54:12.010
Great, we need to
prove the key lemma.

00:54:12.010 --> 00:54:15.000
And so Petridis' proof
of the key lemma,

00:54:15.000 --> 00:54:19.300
it's quite surprising, in
that it uses induction.

00:54:19.300 --> 00:54:21.430
And basically, we have
not used induction

00:54:21.430 --> 00:54:24.460
in this course ever
since the first or maybe

00:54:24.460 --> 00:54:27.430
the second lecture,
and for good reason.

00:54:27.430 --> 00:54:29.518
So everything in this
course is fairly analytic.

00:54:29.518 --> 00:54:31.060
You know, you have
these Roth bounds.

00:54:31.060 --> 00:54:36.010
And putting one extra vertex
often doesn't really help.

00:54:36.010 --> 00:54:54.257
OK, so here, we're going to use
induction on the size of C. OK,

00:54:54.257 --> 00:54:56.590
I just want to emphasize again
that the use of induction

00:54:56.590 --> 00:54:59.190
here was surprising.

00:54:59.190 --> 00:55:02.320
So if the base case--

00:55:02.320 --> 00:55:05.290
always check the base case--

00:55:05.290 --> 00:55:10.780
when C is 1, then plus
C is a translation.

00:55:15.070 --> 00:55:18.630
So this shifts the set over.

00:55:18.630 --> 00:55:27.070
And so you can see that if
you do plus C and minus 1,

00:55:27.070 --> 00:55:33.040
you raise the plus C. And the
conclusion follows basically

00:55:33.040 --> 00:55:35.830
from the hypothesis.

00:55:35.830 --> 00:55:40.840
So in this case,
x plus B plus C is

00:55:40.840 --> 00:55:49.990
equal to x plus B, which is, at
most, k prime times the size x,

00:55:49.990 --> 00:55:52.990
by definition of--

00:55:52.990 --> 00:55:56.890
so this actually is
equal to the size of k.

00:56:03.030 --> 00:56:04.120
The base case is easy.

00:56:06.642 --> 00:56:07.850
Now we do the induction step.

00:56:13.660 --> 00:56:20.080
So let's assume that the
size of C is bigger than 1

00:56:20.080 --> 00:56:25.510
and C is C prime plus an
additional element, which

00:56:25.510 --> 00:56:26.380
we'll call gamma.

00:56:29.680 --> 00:56:35.410
So let's see this
expression, x plus B plus C,

00:56:35.410 --> 00:56:39.760
by separating it according
to if its contribution came

00:56:39.760 --> 00:56:44.870
from C prime or not.

00:56:44.870 --> 00:56:47.460
The contributions that
came from C prime,

00:56:47.460 --> 00:56:49.760
I can write it like that.

00:56:52.973 --> 00:56:54.890
And then there are other
contributions, namely

00:56:54.890 --> 00:56:56.980
those that came from
this extra element.

00:57:04.480 --> 00:57:08.960
But I may have some
redundancies in doing this.

00:57:08.960 --> 00:57:11.760
So I may have some redundancies
coming from the fact

00:57:11.760 --> 00:57:14.430
that some of the
elements in this set

00:57:14.430 --> 00:57:18.100
might have already
appeared earlier.

00:57:18.100 --> 00:57:27.300
So let me take
out those elements

00:57:27.300 --> 00:57:37.230
by taking out elements where
it already appeared earlier.

00:57:37.230 --> 00:57:42.330
So this means I'm
looking at the set z

00:57:42.330 --> 00:57:51.150
being elements of x such that
x plus B plus gamma is already

00:57:51.150 --> 00:57:56.940
a subset of x plus
B plus C prime.

00:57:59.570 --> 00:58:02.600
So the stuff in yellow,
I can safely discard,

00:58:02.600 --> 00:58:04.330
because it already
appeared earlier.

00:58:11.490 --> 00:58:16.250
So because of the
definition of z,

00:58:16.250 --> 00:58:24.020
we see that z plus
B plus gamma appears

00:58:24.020 --> 00:58:27.950
in x plus B plus C prime.

00:58:27.950 --> 00:58:31.940
So that union is valid.

00:58:31.940 --> 00:58:34.790
Now, z is a subset of x.

00:58:39.500 --> 00:58:48.410
So the expansion ratio
for z is at least k prime,

00:58:48.410 --> 00:58:52.695
because we chose x to
minimize this expansion ratio.

00:59:07.530 --> 00:59:13.830
We would like to understand
how big x plus B plus C.

00:59:13.830 --> 00:59:19.310
So let's evaluate the
cardinality of that expression

00:59:19.310 --> 00:59:21.260
up there.

00:59:21.260 --> 00:59:23.790
The cardinality
I can upper bound

00:59:23.790 --> 00:59:27.960
by the union of these sum of
the sizes of the components.

00:59:39.420 --> 00:59:45.100
So up there, so I just do a
union bound on that expression

00:59:45.100 --> 00:59:45.600
up there.

00:59:50.490 --> 00:59:53.310
And now you see z
is a subset of x.

00:59:53.310 --> 00:59:56.400
So I can split this
expression up even further.

01:00:09.657 --> 01:00:15.930
All right, now let's use
the induction hypothesis.

01:00:15.930 --> 01:00:17.700
So we have some
expression involving

01:00:17.700 --> 01:00:21.790
x plus B plus C prime.

01:00:21.790 --> 01:00:28.170
So now we apply induction
hypothesis over here

01:00:28.170 --> 01:00:32.260
to this expression
that has plus C prime.

01:00:32.260 --> 01:00:34.510
And we obtain an
upper bound which

01:00:34.510 --> 01:00:38.650
is k prime x plus C prime.

01:00:43.370 --> 01:00:45.510
And the two expressions
on the right,

01:00:45.510 --> 01:00:50.850
well, one of them here
is, by definition,

01:00:50.850 --> 01:00:56.610
coming from the
expansion ratio of x.

01:00:56.610 --> 01:01:00.300
And then the other, we
gave a bound just now.

01:01:12.060 --> 01:01:13.770
OK, so we're almost there.

01:01:13.770 --> 01:01:17.520
So we are trying to upper bound
the size of this quantity.

01:01:17.520 --> 01:01:22.690
So we decomposed it into pieces
according to its contribution

01:01:22.690 --> 01:01:24.240
coming from this extra element.

01:01:24.240 --> 01:01:28.770
And we analyzed these
pieces individually.

01:01:28.770 --> 01:01:32.630
But now I want to understand
the right-hand side,

01:01:32.630 --> 01:01:37.750
so x plus C. So let's try to
understand the right-hand side.

01:01:41.140 --> 01:01:46.510
See, the x plus C, I can
likewise write it as earlier

01:01:46.510 --> 01:01:52.510
by decomposing it into
contributions from C prime

01:01:52.510 --> 01:01:54.460
and those from
the extra element.

01:02:01.490 --> 01:02:06.670
And as earlier, we can take out
contributions that were already

01:02:06.670 --> 01:02:13.820
appearing earlier, which we
now recall W plus gamma, where

01:02:13.820 --> 01:02:24.970
W is the set of elements in
x, such that x plus gamma

01:02:24.970 --> 01:02:30.100
is already contained
in x plus C prime.

01:02:30.100 --> 01:02:33.988
So this part was already
included earlier.

01:02:33.988 --> 01:02:35.530
We don't need to
include it any more.

01:02:39.234 --> 01:02:43.480
A couple of observations that
were different from earlier--

01:02:43.480 --> 01:02:46.890
now this union I claim
and say disjoined union.

01:02:52.518 --> 01:02:55.250
So this union is
a disjoined union.

01:02:55.250 --> 01:02:58.270
So there is actually
no more overlaps.

01:03:02.780 --> 01:03:07.730
And furthermore, W is contained
in the set z from earlier.

01:03:17.410 --> 01:03:18.778
Any questions?

01:03:24.634 --> 01:03:30.990
All right, therefore,
the size of x plus C

01:03:30.990 --> 01:03:35.550
is equal to, because this
is a disjoined union, x

01:03:35.550 --> 01:03:46.590
plus C prime plus the size
of x minus the size of W,

01:03:46.590 --> 01:03:51.030
and which is--

01:03:51.030 --> 01:03:54.700
so W, because W
is contained in z,

01:03:54.700 --> 01:04:01.510
is x plus C prime plus the
size of x minus the size of z.

01:04:07.160 --> 01:04:09.240
Now you compare these
two expressions.

01:04:12.660 --> 01:04:13.920
And that proves the key lemma.

01:04:21.255 --> 01:04:23.211
OK?

01:04:23.211 --> 01:04:24.300
That's it.

01:04:24.300 --> 01:04:24.800
Yeah?

01:04:24.800 --> 01:04:26.425
AUDIENCE: Can you
explain one more time

01:04:26.425 --> 01:04:27.620
why it's a disjoined union?

01:04:27.620 --> 01:04:30.453
YUFEI ZHAO: OK, great, so why
is this a disjoined union?

01:04:30.453 --> 01:04:34.500
Now, I have the set here.

01:04:34.500 --> 01:04:40.200
So I'm looking at
this x plus gamma.

01:04:43.760 --> 01:04:46.790
So think about, let's
say, gamma equals to 0.

01:04:46.790 --> 01:04:51.910
So we translate, think
about if gamma equals to 0.

01:04:51.910 --> 01:05:00.890
So I include x, but if some
element of x was already here,

01:05:00.890 --> 01:05:03.340
I take it out.

01:05:03.340 --> 01:05:09.400
So here is x plus C prime.

01:05:09.400 --> 01:05:13.270
And let's say this set is x.

01:05:13.270 --> 01:05:16.850
This W then would there
be their intersection.

01:05:16.850 --> 01:05:20.520
So now x minus W
is just this set.

01:05:20.520 --> 01:05:22.448
So it's a disjoined union.

01:05:22.448 --> 01:05:24.740
So the points are, here,
you're adding single elements,

01:05:24.740 --> 01:05:26.282
where there, you're
adding some sets.

01:05:26.282 --> 01:05:30.350
So you cannot necessarily take
a whole partition, necessarily.

01:05:30.350 --> 01:05:31.560
But here it's OK.

01:05:36.500 --> 01:05:40.410
It's tricky.

01:05:40.410 --> 01:05:41.288
Yeah, it's tricky.

01:05:41.288 --> 01:05:43.580
And you know, this took a
long time for people to find.

01:05:43.580 --> 01:05:48.090
It was found about
eight years ago.

01:05:48.090 --> 01:05:51.930
And yeah, it was surprising
when this proof was discovered.

01:05:51.930 --> 01:05:54.090
People did not expect
that this proof existed.

01:05:59.270 --> 01:06:00.990
And it's also
tricky to get right.

01:06:00.990 --> 01:06:02.900
So the details-- I do it slowly.

01:06:02.900 --> 01:06:05.060
But the execution,
like, the order

01:06:05.060 --> 01:06:07.850
that you take the
minimalities is important.

01:06:07.850 --> 01:06:11.760
It's easy to mess up this proof.

01:06:11.760 --> 01:06:13.190
OK, any questions?

01:06:15.880 --> 01:06:20.290
Let me show you, just as
an aside, an application

01:06:20.290 --> 01:06:23.520
of this key lemma.

01:06:23.520 --> 01:06:26.460
So earlier we saw Ruzsa's
Triangle Inequality.

01:06:26.460 --> 01:06:30.000
And you may wonder, what if
you replace the minus signs

01:06:30.000 --> 01:06:31.620
in the theorem by plus signs?

01:06:34.530 --> 01:06:36.370
I mean, if you replace
the right-hand side,

01:06:36.370 --> 01:06:38.800
the two pluses by minuses,
the same proof works.

01:06:41.340 --> 01:06:44.650
But if you replace all the minus
signs by plus signs, you see,

01:06:44.650 --> 01:06:47.860
the proof doesn't work anymore.

01:06:47.860 --> 01:06:50.280
Just give yourself a moment
to convince yourself that.

01:06:50.280 --> 01:06:53.305
If you just replace all the
minus signs by plus signs,

01:06:53.305 --> 01:06:55.180
it doesn't work anymore,
but it's still true.

01:06:59.540 --> 01:07:01.070
So this is more of an aside.

01:07:01.070 --> 01:07:02.290
We will not use it.

01:07:02.290 --> 01:07:03.320
But it's nice.

01:07:03.320 --> 01:07:04.190
It's fun.

01:07:04.190 --> 01:07:13.610
So we have the inequality A B
plus C bounded by A plus B A

01:07:13.610 --> 01:07:17.477
plus C.

01:07:17.477 --> 01:07:19.200
So hopefully you've
convince yourself

01:07:19.200 --> 01:07:21.540
that if you follow our notes
with the previous proof,

01:07:21.540 --> 01:07:23.520
you are you're not
going to get it.

01:07:23.520 --> 01:07:26.340
You're not going to
prove this this way.

01:07:26.340 --> 01:07:27.010
It's still true.

01:07:27.010 --> 01:07:28.140
So how can we prove it?

01:07:28.140 --> 01:07:31.050
So we are going to
use the key lemma.

01:07:31.050 --> 01:07:38.970
So first, the statement
is trivial if A is empty.

01:07:38.970 --> 01:07:40.470
So let's assume
that's not the case.

01:07:43.290 --> 01:07:53.870
Let x be a subset
of A that minimizes

01:07:53.870 --> 01:08:02.330
the expression or the
expansion ratio x plus B

01:08:02.330 --> 01:08:07.490
divided by x as
in the key lemma.

01:08:07.490 --> 01:08:15.220
So let k denote the
quantity A plus B over A,

01:08:15.220 --> 01:08:21.680
so the expansion ratio
for A, and k prime

01:08:21.680 --> 01:08:25.720
be the expansion ratio for x.

01:08:25.720 --> 01:08:29.420
So the quantities
came up earlier.

01:08:29.420 --> 01:08:36.560
k prime is, at most, value of
k, because of our choice of x.

01:08:36.560 --> 01:08:47.069
So the key lemma
gives x B plus C--

01:08:47.069 --> 01:08:50.120
OK, and this, it's really
amazing what's happening.

01:08:50.120 --> 01:08:55.100
It seems like we're just going
to throw in some extra stuff.

01:08:55.100 --> 01:08:57.890
So I'm going to upper
bound it by x plus B

01:08:57.890 --> 01:09:01.870
plus C. I'm just going to
throw in some extra stuff.

01:09:01.870 --> 01:09:07.540
And then by the lemma, I can
upper bound this expression

01:09:07.540 --> 01:09:15.540
by k prime times the
size of x plus C.

01:09:15.540 --> 01:09:18.359
So that's what the
lemma gives you.

01:09:18.359 --> 01:09:22.200
And because x is
a subset of A, we

01:09:22.200 --> 01:09:31.220
can upper bound it by the size
of A plus C. And now k prime

01:09:31.220 --> 01:09:34.380
is, at most, the size of k.

01:09:34.380 --> 01:09:36.520
k prime is, at most, k.

01:09:36.520 --> 01:09:38.529
So you have that.

01:09:38.529 --> 01:09:40.444
But now look at what
the definition of k is.

01:09:48.139 --> 01:09:49.115
And that's it.

01:09:55.480 --> 01:09:58.300
So that's how you
can prove this harder

01:09:58.300 --> 01:10:03.800
version of Ruzsa's Triangle
Inequality, Yes, question?

01:10:03.800 --> 01:10:06.110
AUDIENCE: Are there
equality cases for this?

01:10:06.110 --> 01:10:07.860
YUFEI ZHAO: All right,
question, are there

01:10:07.860 --> 01:10:09.130
equality cases for this?

01:10:09.130 --> 01:10:11.640
Yes, so I mean, if
you're in a subgroup,

01:10:11.640 --> 01:10:14.850
then all things are
equal, although,

01:10:14.850 --> 01:10:18.480
if A, B, and C are
all the same subgroup

01:10:18.480 --> 01:10:20.310
of some finite obedient group.

01:10:20.310 --> 01:10:22.615
AUDIENCE: What if you're
working in the integers?

01:10:22.615 --> 01:10:23.580
YUFEI ZHAO: Great,
yeah, so the question

01:10:23.580 --> 01:10:25.205
is, what if you're
working in integers?

01:10:27.980 --> 01:10:29.010
That's a good question.

01:10:29.010 --> 01:10:31.550
I mean, you can suddenly
get expansion ratio of two

01:10:31.550 --> 01:10:33.340
if you have--

01:10:33.340 --> 01:10:33.840
no, OK.

01:10:36.650 --> 01:10:39.090
Right, yeah, so that's
a good question.

01:10:39.090 --> 01:10:41.430
Can you get equality cases?

01:10:41.430 --> 01:10:50.310
If you set A, B, and C to be
sets of very different sizes,

01:10:50.310 --> 01:10:51.600
AP is a very different set.

01:10:51.600 --> 01:10:51.860
Yes?

01:10:51.860 --> 01:10:54.193
AUDIENCE: If you set B being
true for the single element

01:10:54.193 --> 01:10:58.305
and B and C to just be sets
that have full extension

01:10:58.305 --> 01:10:59.670
so that B plus C is not [? B. ?]

01:10:59.670 --> 01:11:01.280
YUFEI ZHAO: Great,
yeah, so you take

01:11:01.280 --> 01:11:04.670
A to be a
single-element set, then

01:11:04.670 --> 01:11:07.790
it could be that B plus C
is the same as the size of B

01:11:07.790 --> 01:11:11.973
times the size of C if B and C
have no additive interactions.

01:11:16.603 --> 01:11:17.530
Yeah?

01:11:17.530 --> 01:11:19.113
AUDIENCE: Are there
other known proofs

01:11:19.113 --> 01:11:21.002
of this that are less involved?

01:11:21.002 --> 01:11:23.210
YUFEI ZHAO: OK, are there
other known proofs of this?

01:11:23.210 --> 01:11:24.020
I don't know.

01:11:24.020 --> 01:11:25.625
I'm not aware of other proofs.

01:11:25.625 --> 01:11:27.540
It would be nice to
find a different proof.

01:11:31.570 --> 01:11:33.768
More questions?

01:11:33.768 --> 01:11:34.268
Yeah?

01:11:34.268 --> 01:11:36.260
AUDIENCE: How did
come up with this?

01:11:36.260 --> 01:11:37.968
YUFEI ZHAO: How did
he come up with this?

01:11:37.968 --> 01:11:39.680
You know, Petridis
did a very long PhD.

01:11:39.680 --> 01:11:42.520
He spent, I think, seven
or eight years in his PhD.

01:11:42.520 --> 01:11:44.270
And he eventually came
up with this proof.

01:11:46.568 --> 01:11:48.610
So he must have thought
a lot about this problem.

01:11:53.417 --> 01:11:55.000
But the already
proofs are still nice.

01:11:55.000 --> 01:11:57.280
The earlier proofs, I think
they are worth looking at.

01:11:57.280 --> 01:12:00.700
They are looking at
expansion ratios in graphs.

01:12:00.700 --> 01:12:03.690
So you take a sequence of
graphs, multi-partite graphs.

01:12:03.690 --> 01:12:05.310
And you think about expansion.

01:12:05.310 --> 01:12:06.960
And you think about flows.

01:12:06.960 --> 01:12:12.310
It's, again, not easy at
all, but maybe more motivated

01:12:12.310 --> 01:12:16.960
if you're used to think about
expansions and flows in graphs.

01:12:16.960 --> 01:12:21.440
And this one really distills
the core ideas of that proof,

01:12:21.440 --> 01:12:25.040
but looks something you can
teach in half a lecture,

01:12:25.040 --> 01:12:28.332
whereas before this
proof came about,

01:12:28.332 --> 01:12:30.290
I could have taught the
proof, but most likely,

01:12:30.290 --> 01:12:31.546
I would have just skipped it.

01:12:35.830 --> 01:12:40.180
To just give you a sense of
what's coming up ahead, so

01:12:40.180 --> 01:12:45.070
going forward, the first thing
we'll do in the next lecture

01:12:45.070 --> 01:12:46.240
is we'll show--

01:12:46.240 --> 01:12:50.890
we'll see the proof of
the Freiman's theorem

01:12:50.890 --> 01:12:55.750
in the finite field
setting, so in F2 to the n.

01:12:55.750 --> 01:12:58.645
There is one more thing, one
more very quick lemma called

01:12:58.645 --> 01:13:00.520
the covering lemma,
Ruzsa are Covering Lemma,

01:13:00.520 --> 01:13:01.522
that I will tell you.

01:13:01.522 --> 01:13:02.980
And then once we
have that, then we

01:13:02.980 --> 01:13:07.620
can prove Freiman's theorem
in the finite field setting.

01:13:07.620 --> 01:13:09.540
But then moving on
to the integers,

01:13:09.540 --> 01:13:16.330
we'll need to understand how
to think about the integers.

01:13:16.330 --> 01:13:21.150
Well, if you start with a
subset of integers, they could,

01:13:21.150 --> 01:13:23.130
even if you have a small
number of elements,

01:13:23.130 --> 01:13:25.970
they could be spread out,
really, all over the place.

01:13:25.970 --> 01:13:28.950
But because you only care
about the additive structure

01:13:28.950 --> 01:13:32.400
within the integers,
you can try to model

01:13:32.400 --> 01:13:34.650
that very spread-out
set of integers

01:13:34.650 --> 01:13:36.722
to something that
is very compact.

01:13:36.722 --> 01:13:38.430
So there is something
called the modeling

01:13:38.430 --> 01:13:42.638
lemma, Ruzsa's Modeling Lemma,
that we'll see next time.

01:13:42.638 --> 01:13:44.430
And that will play a
pretty important role.

01:13:47.760 --> 01:13:49.920
Before finishing
off, I also want

01:13:49.920 --> 01:13:54.150
to mention that Freiman in his
work, so he had this result.

01:13:54.150 --> 01:13:58.290
And he also wrote a book I think
called The Structural Theory

01:13:58.290 --> 01:14:01.980
of Set Addition, or
something like that, that

01:14:01.980 --> 01:14:04.350
emphasized this connection.

01:14:04.350 --> 01:14:07.200
He tried to draw this
analogy sort of comparing

01:14:07.200 --> 01:14:12.390
additive combinatorics to
geometry in the sense of cline,

01:14:12.390 --> 01:14:14.625
where in order to
understand sets,

01:14:14.625 --> 01:14:15.750
you don't think about sets.

01:14:15.750 --> 01:14:17.910
You think about
maps between sets,

01:14:17.910 --> 01:14:20.940
which was kind of an
obscure idea at the time.

01:14:20.940 --> 01:14:23.120
But we'll see next
lecture that this actually

01:14:23.120 --> 01:14:25.650
is a very powerful, it's
a very influential idea

01:14:25.650 --> 01:14:28.620
to really think about
a sets of integers

01:14:28.620 --> 01:14:30.410
under transformations
that only preserve

01:14:30.410 --> 01:14:32.800
their additive structure.

01:14:32.800 --> 01:14:35.210
So we'll see this next time.