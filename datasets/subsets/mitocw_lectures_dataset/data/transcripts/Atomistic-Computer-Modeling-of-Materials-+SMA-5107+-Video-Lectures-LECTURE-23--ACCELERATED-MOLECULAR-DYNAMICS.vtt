WEBVTT

00:00:01.410 --> 00:00:03.030
PROFESSOR: One more
lecture from me.

00:00:03.030 --> 00:00:06.030
And so remember that on
Thursday we'll be here.

00:00:06.030 --> 00:00:10.020
And Chris Wolverton from Ford
will be lecturing, straight

00:00:10.020 --> 00:00:11.310
live direct from Ford.

00:00:11.310 --> 00:00:13.500
And so you better have
good questions for him

00:00:13.500 --> 00:00:15.130
because he only
lectures about an hour.

00:00:15.130 --> 00:00:16.620
And so we usually--

00:00:16.620 --> 00:00:18.720
in the past, we've had
quite some good discussion

00:00:18.720 --> 00:00:22.660
afterwards, but that's
going to depend on you.

00:00:22.660 --> 00:00:25.960
So what I'm going to do
today is a variety of topics,

00:00:25.960 --> 00:00:29.040
but they all have to do with the
same idea of bigger and faster

00:00:29.040 --> 00:00:29.760
and better--

00:00:29.760 --> 00:00:33.150
not necessarily better.

00:00:33.150 --> 00:00:40.810
So when you deal with
atoms, both because

00:00:40.810 --> 00:00:44.630
of the size and the
time, if you go away,

00:00:44.630 --> 00:00:47.050
especially if you go away
from periodic systems,

00:00:47.050 --> 00:00:51.910
you always run into this problem
that it's too small [INAUDIBLE]

00:00:51.910 --> 00:00:55.530
system, that the
simulation is too short.

00:00:55.530 --> 00:00:58.080
I always like to quote
Professor Marzari on this.

00:00:58.080 --> 00:01:02.580
When people come to
him with nano problems,

00:01:02.580 --> 00:01:07.030
he always says, nano is just
a little too big for us.

00:01:07.030 --> 00:01:09.030
And so I think that's
telling you something

00:01:09.030 --> 00:01:12.850
about the state of what we do.

00:01:12.850 --> 00:01:17.670
So you've actually seen
certain solutions already

00:01:17.670 --> 00:01:20.920
to the sort of size
and time problem.

00:01:20.920 --> 00:01:22.260
Maybe they were fairly obvious.

00:01:22.260 --> 00:01:26.130
But if you think of the time
problem, what I've already

00:01:26.130 --> 00:01:30.790
showed you is how to essentially
coarse grain that away, which

00:01:30.790 --> 00:01:35.000
is it's one thing to coarse
grain over time and space.

00:01:35.000 --> 00:01:37.000
It's another thing, and
it's actually easier

00:01:37.000 --> 00:01:40.330
to almost remove it by,
integrating in a way.

00:01:40.330 --> 00:01:43.000
And when you essentially
integrate time away completely,

00:01:43.000 --> 00:01:45.003
you end up with thermodynamics.

00:01:45.003 --> 00:01:45.920
I mean, thin about it.

00:01:45.920 --> 00:01:49.040
That's what integration over
the partition function is.

00:01:49.040 --> 00:01:52.850
You're essentially assuming
the system has had enough time

00:01:52.850 --> 00:01:56.060
to sample all its
excitations, so we essentially

00:01:56.060 --> 00:01:57.735
integrate over that ensemble.

00:01:57.735 --> 00:01:59.360
You integrate over
all the excitations,

00:01:59.360 --> 00:02:01.760
and you end up with the
thermodynamic functions.

00:02:01.760 --> 00:02:04.580
And the examples that I showed
you with the cluster expansion

00:02:04.580 --> 00:02:06.570
were essentially
examples like that.

00:02:06.570 --> 00:02:09.740
So that part, I would say,
for crystalline systems

00:02:09.740 --> 00:02:11.150
is a solved problem.

00:02:11.150 --> 00:02:12.803
It's not a trivial solution.

00:02:12.803 --> 00:02:14.720
It's still a lot of work,
but it's essentially

00:02:14.720 --> 00:02:17.750
a solved problem.

00:02:17.750 --> 00:02:22.040
I would say most of
the spatial problem

00:02:22.040 --> 00:02:23.870
is solved if you're
going to deal

00:02:23.870 --> 00:02:27.380
with static properties,
static properties and things

00:02:27.380 --> 00:02:30.840
such as elastic behavior.

00:02:30.840 --> 00:02:33.110
You essentially coarse
grain fairly easily

00:02:33.110 --> 00:02:36.710
and end up with
continuum theory.

00:02:36.710 --> 00:02:40.760
The real problem lies in
what sort of happens in

00:02:40.760 --> 00:02:43.640
between here.

00:02:43.640 --> 00:02:48.950
When you want to keep some level
of detail that's not continuum

00:02:48.950 --> 00:02:52.820
or in the time max
is not thermodynamic,

00:02:52.820 --> 00:02:55.550
but you can afford to
stay all the way down

00:02:55.550 --> 00:02:58.860
at the atomistic scale and
the scale of the electrons,

00:02:58.860 --> 00:03:03.768
that's where I think the
real challenge exists.

00:03:03.768 --> 00:03:05.560
And I'll tell you a
little more about that.

00:03:08.045 --> 00:03:09.545
That's when you
break your computer.

00:03:13.008 --> 00:03:15.050
So first, I'm going to
tell you there's obviously

00:03:15.050 --> 00:03:20.600
the brute force approaches,
which is just throw

00:03:20.600 --> 00:03:23.180
more computer power at it.

00:03:23.180 --> 00:03:25.100
And these days the
way you do that is not

00:03:25.100 --> 00:03:26.390
buying faster computers.

00:03:26.390 --> 00:03:28.410
You buy more of them.

00:03:28.410 --> 00:03:31.910
So you have to parallelize.

00:03:31.910 --> 00:03:36.750
Parallelization over space is
obviously the most obvious one.

00:03:36.750 --> 00:03:42.530
If you have a really big system,
you can divide it in chunks.

00:03:42.530 --> 00:03:44.793
OK, you know?

00:03:44.793 --> 00:03:46.710
You'd probably do it a
little more systematic,

00:03:46.710 --> 00:03:49.170
but you can divide
it in chunks and give

00:03:49.170 --> 00:03:56.040
each chunk of atoms to a CPU,
CPU1, CPU2, CPU3, et cetera.

00:03:59.240 --> 00:04:03.800
Of course, that implies that
the coupling between regions

00:04:03.800 --> 00:04:05.210
is not too severe.

00:04:05.210 --> 00:04:07.845
Because when you calculate--

00:04:07.845 --> 00:04:09.470
let's say you're
doing electrodynamics.

00:04:09.470 --> 00:04:13.910
When you calculate forces on
the atoms in the region of CPU1,

00:04:13.910 --> 00:04:17.560
the atoms that live
in the boundary layer

00:04:17.560 --> 00:04:24.870
obviously see forces coming
from atoms in the other regions.

00:04:24.870 --> 00:04:28.280
So how efficient this method
is will depend very much

00:04:28.280 --> 00:04:31.430
on how well you can divide
the sort of spatial origin

00:04:31.430 --> 00:04:32.942
of the forces and the energy.

00:04:32.942 --> 00:04:34.400
So you can already
see that this is

00:04:34.400 --> 00:04:37.430
going to be easier when you do
it with pair potentials, say.

00:04:37.430 --> 00:04:40.910
With pair potentials,
you can directly assign,

00:04:40.910 --> 00:04:42.440
when you have the
force on an atom,

00:04:42.440 --> 00:04:45.320
the component coming
from other atoms.

00:04:45.320 --> 00:04:47.220
You can say the force
on this atom comes--

00:04:47.220 --> 00:04:49.220
I have a piece coming
from the potential

00:04:49.220 --> 00:04:52.643
with that atom, the potential
with that atom, et cetera.

00:04:52.643 --> 00:04:54.560
You'll see that in the
standard approximation,

00:04:54.560 --> 00:04:56.018
for example, the
quantum mechanics,

00:04:56.018 --> 00:04:58.410
this is virtually impossible.

00:04:58.410 --> 00:05:02.750
When we work with
block states, those

00:05:02.750 --> 00:05:07.280
are, by definition, extended
over the whole system, OK?

00:05:07.280 --> 00:05:12.510
So you can't partition
them over pieces of space.

00:05:12.510 --> 00:05:16.760
So to do this sort of
divide and conquer approach

00:05:16.760 --> 00:05:20.000
with quantum mechanics,
you have to go

00:05:20.000 --> 00:05:23.210
to alternative approaches.

00:05:23.210 --> 00:05:27.920
People invest a lot of time
now in just real space grids.

00:05:27.920 --> 00:05:29.720
In theory, the
Schrodinger equation

00:05:29.720 --> 00:05:32.840
is a partial
differential equation.

00:05:32.840 --> 00:05:34.880
Like any other partial
differential equation,

00:05:34.880 --> 00:05:37.820
you should be able to solve
it on a real space grid.

00:05:37.820 --> 00:05:39.890
There's all kinds of
complications that arise,

00:05:39.890 --> 00:05:42.348
but people are doing a lot--
there's a lot of work actually

00:05:42.348 --> 00:05:44.130
being done on that.

00:05:44.130 --> 00:05:47.880
The other is to go to
localized basis sets.

00:05:47.880 --> 00:05:51.990
And you know, maximally
localized Wannier functions

00:05:51.990 --> 00:05:52.920
fall in that category.

00:05:52.920 --> 00:05:54.712
And Professor Marzari
is an expert on that,

00:05:54.712 --> 00:05:58.290
almost essentially invented--

00:05:58.290 --> 00:06:00.190
tight binding approaches.

00:06:00.190 --> 00:06:02.730
So you'll see a lot of work
being done on real space

00:06:02.730 --> 00:06:06.450
methods, which is, in
essence, directed largely

00:06:06.450 --> 00:06:08.670
towards this sort of divide
and conquer approach.

00:06:08.670 --> 00:06:11.200
If you can go a real space
in quantum mechanics,

00:06:11.200 --> 00:06:15.150
you can divide space up.

00:06:15.150 --> 00:06:18.960
So space is maybe, in
the end, not the biggest

00:06:18.960 --> 00:06:21.450
problem we have to deal with.

00:06:21.450 --> 00:06:23.910
Time is a much harder one.

00:06:23.910 --> 00:06:27.520
Because how do you
parallelize over time?

00:06:27.520 --> 00:06:30.600
Time is, by nature, sequential.

00:06:30.600 --> 00:06:34.500
So it's really hard
to do something

00:06:34.500 --> 00:06:38.950
that's in the future when you
don't know the present yet.

00:06:38.950 --> 00:06:40.265
But you'll see in a second--

00:06:40.265 --> 00:06:42.390
well, not in a second, a
little more than a second,

00:06:42.390 --> 00:06:43.440
but later in the lecture.

00:06:43.440 --> 00:06:46.225
There are some approaches
to paralyzing time,

00:06:46.225 --> 00:06:47.850
but they're all, I
would say, much more

00:06:47.850 --> 00:06:52.380
limited in scope
than the methods

00:06:52.380 --> 00:06:53.700
for parallelizing over space.

00:06:56.920 --> 00:06:59.430
So you see time will
be the big problem.

00:06:59.430 --> 00:07:03.015
Time is easy to deal with when
it's either short or very long.

00:07:03.015 --> 00:07:05.640
Because when it's very long, you
essentially integrate it away.

00:07:05.640 --> 00:07:08.900
But in between is where
it tends to get harder.

00:07:12.810 --> 00:07:16.160
So let me give you sort
of a couple of examples

00:07:16.160 --> 00:07:19.440
of ideas that have
been kicked around

00:07:19.440 --> 00:07:22.132
for coarse-graining space.

00:07:22.132 --> 00:07:24.090
And then I'll say a little
more about the time.

00:07:24.090 --> 00:07:27.960
And with time comes
temperature problem.

00:07:27.960 --> 00:07:32.920
So you could imagine, if you
do an impurity calculation--

00:07:32.920 --> 00:07:35.910
so you take a sort of crystal
of these bluish atoms,

00:07:35.910 --> 00:07:38.547
and you stick a big red atom in.

00:07:38.547 --> 00:07:40.380
You want to calculate
the energy [INAUDIBLE]

00:07:40.380 --> 00:07:41.850
with quantum mechanics.

00:07:41.850 --> 00:07:46.350
Well, those shells around the
red atom kind of relax a lot.

00:07:46.350 --> 00:07:49.110
And then as you
sort of go further,

00:07:49.110 --> 00:07:51.330
this is largely an
elastic problem.

00:07:51.330 --> 00:07:54.900
You've put a ball in a
hole that's too small,

00:07:54.900 --> 00:07:58.560
and sort of the system
relaxes around it.

00:07:58.560 --> 00:08:01.440
We tend to sort of brute
force that typically.

00:08:01.440 --> 00:08:04.153
We do quantum mechanics on
bigger and bigger units cells.

00:08:04.153 --> 00:08:05.820
But it's actually
remarkable if you ever

00:08:05.820 --> 00:08:09.450
plot the displacements.

00:08:09.450 --> 00:08:12.960
You will find that these systems
behave remarkably elastically

00:08:12.960 --> 00:08:15.810
in very close shells
to the defect already.

00:08:15.810 --> 00:08:18.450
Often, from the
second, third neighbor,

00:08:18.450 --> 00:08:20.340
if you were to apply
elasticity theory,

00:08:20.340 --> 00:08:21.720
you'd still get it right.

00:08:21.720 --> 00:08:25.410
It's amazing how applicable
elasticity theory

00:08:25.410 --> 00:08:27.900
is at the atomistic level.

00:08:27.900 --> 00:08:30.690
So that gave people the
idea that really when

00:08:30.690 --> 00:08:37.740
they do calculations with broken
symmetry, so around defects,

00:08:37.740 --> 00:08:40.169
maybe you really don't
need all the atoms that we

00:08:40.169 --> 00:08:43.570
tend to put in calculations.

00:08:43.570 --> 00:08:46.290
So the idea that's
been kicked around

00:08:46.290 --> 00:08:52.380
is that let's say that this
is a piece of your simulation

00:08:52.380 --> 00:08:56.010
that's far away from whatever
perturbation you're looking at.

00:08:56.010 --> 00:08:57.180
Maybe it's a grain boundary.

00:08:57.180 --> 00:08:58.650
Maybe it's a dislocation moving.

00:08:58.650 --> 00:09:01.980
Maybe you just
did nuclear fusion

00:09:01.980 --> 00:09:03.990
somewhere in the material.

00:09:03.990 --> 00:09:08.730
But far away, you believe
that the system acts almost

00:09:08.730 --> 00:09:09.900
in a continuum mode.

00:09:09.900 --> 00:09:12.030
And so the idea is
that, what if I kept

00:09:12.030 --> 00:09:13.590
track only of these red atoms?

00:09:17.420 --> 00:09:21.620
Let's say I'm looking at energy
of an elastic displacement

00:09:21.620 --> 00:09:23.600
or even not elastic.

00:09:23.600 --> 00:09:25.940
If I knew how these
four items moved,

00:09:25.940 --> 00:09:29.630
I could probably know something
about how the other atoms move,

00:09:29.630 --> 00:09:30.500
OK?

00:09:30.500 --> 00:09:33.980
So I could interpolate,
say, their displacement

00:09:33.980 --> 00:09:37.840
from the displacement
of the corner atoms.

00:09:37.840 --> 00:09:40.640
So one thing you
can do is say, well,

00:09:40.640 --> 00:09:43.060
if I know how
these atoms move, I

00:09:43.060 --> 00:09:46.840
assume that the energy
of the atoms in between

00:09:46.840 --> 00:09:49.960
is essentially the same as an
energy of a sort of macroscopic

00:09:49.960 --> 00:09:53.770
solid that I deform
with that displacement.

00:09:53.770 --> 00:09:54.980
You can do things in between.

00:09:54.980 --> 00:09:56.770
You can actually
sort of calculate

00:09:56.770 --> 00:10:00.430
the energy of that unit
cell as it's displaced.

00:10:00.430 --> 00:10:04.540
But the whole idea
that essentially you

00:10:04.540 --> 00:10:08.470
start keeping only track of
a limited number of atoms.

00:10:08.470 --> 00:10:11.150
And you can think
of these as nodes.

00:10:11.150 --> 00:10:12.890
So these are called nodal atoms.

00:10:12.890 --> 00:10:15.820
And what happens to all
the atoms you removed--

00:10:15.820 --> 00:10:18.310
you essentially get
by interpolation.

00:10:18.310 --> 00:10:21.340
And once you're happy with
using elasticity theory,

00:10:21.340 --> 00:10:22.840
then essentially
you know the energy

00:10:22.840 --> 00:10:27.850
of that cube, how that changes
as you change the four corners.

00:10:27.850 --> 00:10:31.300
Typically, people use triangles
because people will tend

00:10:31.300 --> 00:10:32.830
to use triangular measures.

00:10:32.830 --> 00:10:37.725
But I wanted to give the
example with a square

00:10:37.725 --> 00:10:38.920
since it's a little simpler.

00:10:43.270 --> 00:10:48.120
So this is essentially the idea
of the quasi continuum method.

00:10:48.120 --> 00:10:52.600
Let's say out here you
have some perturbation,

00:10:52.600 --> 00:10:55.480
something you want to study
at the atomistic level.

00:10:55.480 --> 00:11:00.410
As you go farther and farther
away, you want to coarse grain

00:11:00.410 --> 00:11:01.490
more and more.

00:11:01.490 --> 00:11:05.200
So essentially, you want to
keep less and less nodal atoms

00:11:05.200 --> 00:11:06.820
and get more and
more information

00:11:06.820 --> 00:11:08.960
simply by interpolation.

00:11:08.960 --> 00:11:12.280
So you could say this is coarse
graining at the level of one

00:11:12.280 --> 00:11:16.060
out of four when you're here.

00:11:16.060 --> 00:11:18.200
And then you have a
few regions of that.

00:11:18.200 --> 00:11:22.590
And then you coarse
grain at a higher level.

00:11:22.590 --> 00:11:24.630
So you keep, say, I should
have removed-- sorry,

00:11:24.630 --> 00:11:26.130
these should not be red.

00:11:26.130 --> 00:11:28.230
These should be blue, sorry.

00:11:28.230 --> 00:11:30.480
So you only keep
these four atoms,

00:11:30.480 --> 00:11:32.490
and you sort of
assume that that solid

00:11:32.490 --> 00:11:36.210
undergoes a homogeneous
deformation within that box.

00:11:38.730 --> 00:11:41.640
What you see is that
somewhere in this limit

00:11:41.640 --> 00:11:43.650
you're going to end up
with a finite element

00:11:43.650 --> 00:11:47.670
approaches, where essentially
you do continuum theory.

00:11:47.670 --> 00:11:50.430
And you essentially
say that, if I

00:11:50.430 --> 00:11:55.890
know some displacements of
elements, of the corner points,

00:11:55.890 --> 00:11:59.820
the vertices of elements, I know
how to that element deforms.

00:11:59.820 --> 00:12:03.750
So what you have is essentially
a sort of continuous transition

00:12:03.750 --> 00:12:07.050
here in coarse graining
from our atomistic behavior

00:12:07.050 --> 00:12:08.933
to a finite element approach.

00:12:08.933 --> 00:12:10.350
And people have
put that together.

00:12:10.350 --> 00:12:13.530
And this is called a
quasi-continuum approach.

00:12:13.530 --> 00:12:17.850
This is sort of a
pictorial version of it.

00:12:17.850 --> 00:12:21.010
Let's say this is some boundary
where you do something.

00:12:21.010 --> 00:12:22.740
You have very fine resolution.

00:12:22.740 --> 00:12:25.050
You could say the nodes of
your finite element niche

00:12:25.050 --> 00:12:26.307
are the atoms.

00:12:26.307 --> 00:12:28.140
And then as you go
farther and farther away,

00:12:28.140 --> 00:12:29.550
you coarse grain more and more.

00:12:29.550 --> 00:12:33.078
And you keep less
and less information.

00:12:33.078 --> 00:12:34.620
I'll give you a
reference at the end,

00:12:34.620 --> 00:12:38.010
but the people
who developed this

00:12:38.010 --> 00:12:40.020
were essentially a
fairly small group

00:12:40.020 --> 00:12:43.230
of people, Shenoi,
Tadmor, and Rob Phillips,

00:12:43.230 --> 00:12:45.000
and Michael Ortiz at Caltech.

00:12:45.000 --> 00:12:47.520
And there's some excellent
review papers about this

00:12:47.520 --> 00:12:49.740
if you'd like to
read more about this.

00:12:54.010 --> 00:12:56.920
It's now been fairly
well-implemented,

00:12:56.920 --> 00:13:02.795
these kind of approaches, mainly
with empirical energy methods.

00:13:02.795 --> 00:13:05.170
People have tried to implement
it with quantum mechanics.

00:13:05.170 --> 00:13:06.753
And some people have
actually done it,

00:13:06.753 --> 00:13:09.700
but it's not all that
effective really.

00:13:09.700 --> 00:13:13.780
It's extremely hard to
couple the atomistic region

00:13:13.780 --> 00:13:16.060
where you do quantum
mechanics to a sort

00:13:16.060 --> 00:13:19.450
of more coarse grained region.

00:13:19.450 --> 00:13:22.583
But with potentials and with
things like embedded atom

00:13:22.583 --> 00:13:24.250
method, people have
coupled these things

00:13:24.250 --> 00:13:25.990
fairly well together.

00:13:25.990 --> 00:13:28.690
This is, for example,
a grain boundary--

00:13:28.690 --> 00:13:31.900
sorry, a crack impinging
on a grain boundary.

00:13:31.900 --> 00:13:34.400
See, this is a symmetric
grain boundary.

00:13:34.400 --> 00:13:36.310
And you have the crack
in the middle there.

00:13:36.310 --> 00:13:39.610
It comes in, hits
the grain boundary,

00:13:39.610 --> 00:13:43.510
and essentially deflects
in the grain boundary.

00:13:43.510 --> 00:13:48.070
So that's a simulation
done with quasi-continuum.

00:13:48.070 --> 00:13:51.310
You know, if you want to
think about it, what it really

00:13:51.310 --> 00:13:54.010
does for you
quasi-continuum, is that it's

00:13:54.010 --> 00:13:57.550
a way of getting the
boundary conditions right

00:13:57.550 --> 00:14:00.310
on your atomistic simulation.

00:14:00.310 --> 00:14:03.310
By slowly integrating
it, essentially

00:14:03.310 --> 00:14:08.440
with a continuum theory, you,
first of all, have adaptive--

00:14:08.440 --> 00:14:12.910
your boundary conditions or
your atomistic simulation

00:14:12.910 --> 00:14:15.460
change during the simulation.

00:14:15.460 --> 00:14:18.010
And because you have a
better embedding theory,

00:14:18.010 --> 00:14:20.200
you have a better
continuum theory,

00:14:20.200 --> 00:14:21.580
they're sort of
more appropriate.

00:14:21.580 --> 00:14:23.800
And especially in
mechanical problems,

00:14:23.800 --> 00:14:27.670
that is very important to have
the right elastic boundary

00:14:27.670 --> 00:14:28.698
conditions.

00:14:35.540 --> 00:14:39.100
So let me sort of
position this for you

00:14:39.100 --> 00:14:41.230
to show you where
we have the solution

00:14:41.230 --> 00:14:44.763
and where we still have
significant problems.

00:14:44.763 --> 00:14:46.180
You know, I would
essentially say,

00:14:46.180 --> 00:14:48.970
when we work purely at
the microscopic scale,

00:14:48.970 --> 00:14:52.960
we have most things
under control.

00:14:52.960 --> 00:14:55.810
We know well how to deal
with the energetics.

00:14:55.810 --> 00:14:58.162
We fairly well how to
deal with the dynamics.

00:14:58.162 --> 00:14:59.620
Because for pretty
much everything,

00:14:59.620 --> 00:15:02.980
except things like hydrogen, you
can use Newtonian dynamics even

00:15:02.980 --> 00:15:04.720
on the atomistic scale.

00:15:04.720 --> 00:15:06.220
You could argue we
don't really know

00:15:06.220 --> 00:15:08.200
how to deal well with
electron dynamics,

00:15:08.200 --> 00:15:10.210
but that's another problem.

00:15:10.210 --> 00:15:13.510
If you're willing to go all
the way to the continuum scale,

00:15:13.510 --> 00:15:17.210
we also know the equations
that describe matter.

00:15:17.210 --> 00:15:20.818
It's essentially
thermodynamics and elasticity.

00:15:20.818 --> 00:15:22.360
And you could think
of thermodynamics

00:15:22.360 --> 00:15:25.240
as the integrator of those.

00:15:25.240 --> 00:15:28.390
It's when we live at this
inhomogeneous coarse grain

00:15:28.390 --> 00:15:30.560
scale that we're
really in trouble.

00:15:30.560 --> 00:15:32.720
And I'll give you an example.

00:15:32.720 --> 00:15:35.140
Think of temperature.

00:15:35.140 --> 00:15:39.370
In continuum theory,
temperature is a field.

00:15:39.370 --> 00:15:42.160
In a microscopic
simulation, it's

00:15:42.160 --> 00:15:45.220
kinetic energy of the atoms.

00:15:45.220 --> 00:15:47.110
You can already see
a problem appear.

00:15:47.110 --> 00:15:50.800
Essentially, as you
inhomogeneously coarse grain

00:15:50.800 --> 00:15:53.590
around that atomistic
region, that temperature

00:15:53.590 --> 00:15:57.760
has to evolve from being
the kinetic energy of motion

00:15:57.760 --> 00:15:59.290
to a field.

00:15:59.290 --> 00:16:03.148
And it's [INAUDIBLE] tricky to
know what you do in between.

00:16:03.148 --> 00:16:05.440
I mean, I know how to deal
with temperature as a field.

00:16:05.440 --> 00:16:07.273
I know how to deal with
this kinetic energy.

00:16:07.273 --> 00:16:08.380
But what is it in between?

00:16:08.380 --> 00:16:11.290
What is it when you say a
factor of 10 coarse grain,

00:16:11.290 --> 00:16:14.220
so you've removed
every 10th atom?

00:16:14.220 --> 00:16:16.720
And I'm going to go a little
deeper in some of these things,

00:16:16.720 --> 00:16:18.460
but those are some
of the problems.

00:16:18.460 --> 00:16:23.380
We also don't know what the
dynamics here is at this scale.

00:16:23.380 --> 00:16:26.760
Because think of how do
you dissipate energy.

00:16:26.760 --> 00:16:30.870
How do you dissipate energy
in a microscopic system?

00:16:30.870 --> 00:16:35.790
You dissipate it, essentially,
by non-harmonic vibrations.

00:16:35.790 --> 00:16:37.770
That's how you dissipate energy.

00:16:37.770 --> 00:16:40.350
How do you dissipate it here?

00:16:40.350 --> 00:16:44.260
Actually, you don't unless
you put it inexplicitly.

00:16:44.260 --> 00:16:47.650
And in perfectly
elasticity theory,

00:16:47.650 --> 00:16:50.380
you don't have dissipation.

00:16:50.380 --> 00:16:54.220
So again, energy
dissipation is a big deal

00:16:54.220 --> 00:16:57.370
in inhomogeneously
coarse-grained systems.

00:16:57.370 --> 00:17:00.940
Because the mechanism by which
it happens at the atomistic

00:17:00.940 --> 00:17:03.894
and at the continuum
scale is different.

00:17:08.349 --> 00:17:13.510
So quasi-continuum approaches
have been extremely successful

00:17:13.510 --> 00:17:16.720
for elastic static
properties and even

00:17:16.720 --> 00:17:20.440
nonlinear elastic problems.

00:17:20.440 --> 00:17:22.540
It's when people try
to put temperature

00:17:22.540 --> 00:17:26.000
and dynamics in that life
gets a lot more complicated.

00:17:26.000 --> 00:17:27.880
So there are essentially
two approaches that

00:17:27.880 --> 00:17:29.890
have been suggested and tried.

00:17:29.890 --> 00:17:32.680
And both sort of
seem reasonable,

00:17:32.680 --> 00:17:35.110
but have significant failures.

00:17:35.110 --> 00:17:36.610
One is to simply--

00:17:36.610 --> 00:17:39.700
let's say, how would you
do molecular dynamics

00:17:39.700 --> 00:17:41.650
on a coarse grain
system like this?

00:17:41.650 --> 00:17:45.640
Well, remember, you've
removed these atoms.

00:17:45.640 --> 00:17:49.020
You could lump their
mass into the nodes.

00:17:49.020 --> 00:17:52.280
So essentially, the nodes of
your mesh now become heavier.

00:17:52.280 --> 00:17:56.118
And then you do MD on those.

00:17:56.118 --> 00:17:57.660
The problem with
that is that, as you

00:17:57.660 --> 00:17:58.910
coarse grain more
and more, you get

00:17:58.910 --> 00:18:00.160
the heavier and heavier nodes.

00:18:00.160 --> 00:18:02.150
And after a while, they
don't move anymore.

00:18:02.150 --> 00:18:05.020
Because if they have
the same temperature,

00:18:05.020 --> 00:18:07.990
mv squared average over
2 is the temperature.

00:18:07.990 --> 00:18:13.300
So at the same temperature,
the v becomes very small.

00:18:13.300 --> 00:18:16.270
The other one is a sort
of often used approach

00:18:16.270 --> 00:18:20.320
to use static optimizations.

00:18:20.320 --> 00:18:24.580
But rather than say get all
the positions of these atoms--

00:18:24.580 --> 00:18:26.620
rather than get them
from the energy,

00:18:26.620 --> 00:18:30.130
get them from minimizing
the free energy.

00:18:30.130 --> 00:18:34.210
Say, the force would
be now the gradient

00:18:34.210 --> 00:18:36.940
of something like
the free energy

00:18:36.940 --> 00:18:39.250
rather than the
gradient of the energy.

00:18:39.250 --> 00:18:42.560
So you have some amount of
temperature effects in there

00:18:42.560 --> 00:18:45.580
then, but you don't
truly have dynamics.

00:18:50.290 --> 00:18:52.960
So one thing this would do
for you, for example, is you'd

00:18:52.960 --> 00:18:55.660
get the right bond length
and lattice parameters.

00:19:06.030 --> 00:19:07.140
OK.

00:19:07.140 --> 00:19:11.290
I want to show you some other
ideas that have been out there.

00:19:11.290 --> 00:19:14.580
This is one that I've
worked on for a short while.

00:19:14.580 --> 00:19:17.782
But the generic idea has
really being out there

00:19:17.782 --> 00:19:18.990
in the community a long time.

00:19:18.990 --> 00:19:21.120
And it's very similar
to what we've done

00:19:21.120 --> 00:19:23.950
in the coarse graining of time.

00:19:23.950 --> 00:19:27.120
The idea is essentially think
of three atoms on a chain,

00:19:27.120 --> 00:19:29.196
1, 2, 3 there.

00:19:29.196 --> 00:19:33.210
What if you want to remove
atom 2, and so coarse grain

00:19:33.210 --> 00:19:35.670
and only keep 1
and 3 as the nodes?

00:19:35.670 --> 00:19:39.607
The question really is,
what should your potential--

00:19:39.607 --> 00:19:41.190
let's say you do
this with potentials.

00:19:41.190 --> 00:19:42.898
Don't even worry about
quantum mechanics.

00:19:42.898 --> 00:19:44.780
What should your
potential between 1 and 3

00:19:44.780 --> 00:19:50.310
be, so that they behave the
same way as if 2 were there?

00:19:50.310 --> 00:19:52.450
So you're going to
take 2 out, but you

00:19:52.450 --> 00:19:55.420
want to set up a
potential between 1 and 3

00:19:55.420 --> 00:19:57.890
that acts like if 2 were there.

00:19:57.890 --> 00:20:00.910
Well, you can get the solution
again from thermodynamics,

00:20:00.910 --> 00:20:04.660
essentially requiring
that the partition

00:20:04.660 --> 00:20:07.570
function for the
motion of 1 and 3

00:20:07.570 --> 00:20:10.570
is the same with
or without 2 there.

00:20:10.570 --> 00:20:13.220
And that's essentially
what's written out here.

00:20:13.220 --> 00:20:16.180
If you think of q's and
p's for the coordinates,

00:20:16.180 --> 00:20:19.790
remember q's are spatial
coordinates. p's are

00:20:19.790 --> 00:20:22.750
velocities,
essentially the moment.

00:20:22.750 --> 00:20:24.250
Essentially, what
you're saying is

00:20:24.250 --> 00:20:27.670
that the free energy
of the Hamiltonian

00:20:27.670 --> 00:20:29.630
with only q1 and q3--

00:20:29.630 --> 00:20:32.830
so now, you keep only the
positions of 1 and 3--

00:20:32.830 --> 00:20:37.390
is obtained by integrating
away the coordinates of 2.

00:20:37.390 --> 00:20:39.190
So you integrate
over the position

00:20:39.190 --> 00:20:41.440
and over the momentum of 2.

00:20:41.440 --> 00:20:43.660
And if the motions
are classical,

00:20:43.660 --> 00:20:46.300
then the integration over
the momentum is trivial.

00:20:46.300 --> 00:20:48.560
You always get the same
factors from momentum.

00:20:48.560 --> 00:20:52.910
So it's really the integration
over the coordinates.

00:20:52.910 --> 00:20:56.710
And so if you integrate
this away, then

00:20:56.710 --> 00:21:01.840
formally this integral has no
q2 dependence by definition.

00:21:01.840 --> 00:21:06.100
You've essentially integrated
over all possible displacements

00:21:06.100 --> 00:21:11.050
of 2 to get the interaction
between 1 and 3.

00:21:11.050 --> 00:21:16.848
And so that then defines a
potential just between 1 and 3.

00:21:16.848 --> 00:21:18.640
Now, there's all kinds
of practical issues.

00:21:18.640 --> 00:21:20.980
You can really only
do this effectively

00:21:20.980 --> 00:21:25.932
if you have interactions
that are spatially limited.

00:21:25.932 --> 00:21:27.640
Because, otherwise,
you really don't know

00:21:27.640 --> 00:21:29.300
what you all have to integrate.

00:21:29.300 --> 00:21:32.890
So this works great with
pair potentials then.

00:21:32.890 --> 00:21:36.320
So you know, what does
this physically mean?

00:21:36.320 --> 00:21:41.080
It really means that, if
you, say, displace atom three

00:21:41.080 --> 00:21:44.920
and you look at the force
that it produces on atom 1,

00:21:44.920 --> 00:21:47.560
that you're looking at
the kind of screening

00:21:47.560 --> 00:21:49.810
by atom 2 is included.

00:21:49.810 --> 00:21:51.760
In the real system, atom
2 would sort of maybe

00:21:51.760 --> 00:21:53.980
screen that displacement
away somewhat.

00:21:53.980 --> 00:21:55.210
And that's not included.

00:21:55.210 --> 00:21:56.920
And people have
done this before,

00:21:56.920 --> 00:21:59.560
looking at interactions of--
when you look at interactions

00:21:59.560 --> 00:22:02.912
of ions and fluids,
the way to look

00:22:02.912 --> 00:22:04.370
at the interaction
between two ions

00:22:04.370 --> 00:22:07.397
is by integrating over the
possible displacement of all

00:22:07.397 --> 00:22:08.480
the other ones in between.

00:22:08.480 --> 00:22:10.820
And that's how you
end up with screening.

00:22:10.820 --> 00:22:13.700
So this is sort of the
screening equivalent

00:22:13.700 --> 00:22:15.065
in displacement fields.

00:22:21.300 --> 00:22:25.080
And what you get at is very
much what you'd expected.

00:22:25.080 --> 00:22:27.150
This is the potentials
for different levels

00:22:27.150 --> 00:22:29.990
of coarse graining in
normalized distances.

00:22:29.990 --> 00:22:35.370
So if the length of the bond
length is in units of 1,

00:22:35.370 --> 00:22:37.410
so this would be the
normal potential.

00:22:37.410 --> 00:22:40.530
If you coarse grain one level,
so you remove every other atom,

00:22:40.530 --> 00:22:42.030
you actually end
up with a potential

00:22:42.030 --> 00:22:44.280
that's twice the bond length.

00:22:44.280 --> 00:22:48.450
Because, remember, now
you have atom 1, 2, 3.

00:22:48.450 --> 00:22:50.670
You've removed 2, so
the equilibrium distance

00:22:50.670 --> 00:22:53.962
between 1 and 3 is about
2 times the bond length.

00:22:53.962 --> 00:22:55.920
And you keep on coarse
graining, and you end up

00:22:55.920 --> 00:22:58.560
with a potential that's 4
times the bond length, 8

00:22:58.560 --> 00:23:00.470
times the bond length.

00:23:00.470 --> 00:23:00.970
OK.

00:23:05.500 --> 00:23:12.430
It turns out that special
coarse graining always

00:23:12.430 --> 00:23:15.190
tends to cause some
kind of time quartering.

00:23:15.190 --> 00:23:16.900
That's a much more
difficult issue.

00:23:16.900 --> 00:23:19.510
I don't want to say much.

00:23:19.510 --> 00:23:23.770
In 1D, it's easy to
remove atoms and add up.

00:23:23.770 --> 00:23:26.410
So when you remove atom
2 that's between 1 and 3,

00:23:26.410 --> 00:23:28.990
essentially that defines a
potential between 1 and 3.

00:23:28.990 --> 00:23:32.140
In 2D, it's a little harder
how you partition bonds,

00:23:32.140 --> 00:23:35.710
but you can do all kinds of
bond moving approximations.

00:23:35.710 --> 00:23:37.900
This is a simple one
in a triangular lattice

00:23:37.900 --> 00:23:44.250
where, if you have a
triangle, you essentially

00:23:44.250 --> 00:23:48.260
want to remove these guys here.

00:23:48.260 --> 00:23:50.040
And so you can
define some scheme

00:23:50.040 --> 00:23:59.230
by which you sort of collapse
the bonds onto these sides.

00:23:59.230 --> 00:24:01.300
You can also define
other schemes.

00:24:01.300 --> 00:24:04.840
So here's an example of an
inhomogeneously coarse-grained

00:24:04.840 --> 00:24:08.840
system in 2D where, in this
case, it's fine at the edges

00:24:08.840 --> 00:24:10.090
and it's coarse in the middle.

00:24:18.000 --> 00:24:19.850
OK.

00:24:19.850 --> 00:24:22.500
There are essentially two
major problems with almost

00:24:22.500 --> 00:24:24.090
any coarse-graining scheme.

00:24:24.090 --> 00:24:30.640
And the first one is the
worst, is that whenever

00:24:30.640 --> 00:24:32.050
you go from a--

00:24:32.050 --> 00:24:34.810
let's say you're
atomistic out here.

00:24:34.810 --> 00:24:39.070
Here, you've coarse-grained
level 4, coarse-grained

00:24:39.070 --> 00:24:42.250
another factor of 4.

00:24:42.250 --> 00:24:45.700
You cannot sustain
short wavelength phonons

00:24:45.700 --> 00:24:47.410
in the coarse regions.

00:24:47.410 --> 00:24:49.750
Let's say you have a
phonon come in here

00:24:49.750 --> 00:24:55.090
that's, say, has a
wavelength like this.

00:25:02.120 --> 00:25:07.200
Since here you only
have these nodes,

00:25:07.200 --> 00:25:11.100
this is essentially the minimum
wavelength you can have.

00:25:11.100 --> 00:25:12.420
It's the minimum bond distance.

00:25:12.420 --> 00:25:18.710
So at every interface
between a fine region

00:25:18.710 --> 00:25:20.930
and of coarser
region, what happens

00:25:20.930 --> 00:25:22.520
is that there's a
series of phonons.

00:25:22.520 --> 00:25:26.540
The ones that have a wavelength
that's too short get reflected

00:25:26.540 --> 00:25:32.405
back because they cannot
go into the coarser region.

00:25:32.405 --> 00:25:34.280
And ultimately, you hit
the continuum region,

00:25:34.280 --> 00:25:36.750
and you can't have any phonons.

00:25:36.750 --> 00:25:40.410
Because there they should all
be dissipated as temperature.

00:25:40.410 --> 00:25:43.340
So what does that cause?

00:25:43.340 --> 00:25:47.900
Well, if you look at
dynamical processes,

00:25:47.900 --> 00:25:50.300
let's say you have a fine
region in which you have

00:25:50.300 --> 00:25:55.380
some reaction that dissipates
energy or that creates energy,

00:25:55.380 --> 00:25:57.980
the way that that
energy has to get out

00:25:57.980 --> 00:26:00.770
is by phonon transmission.

00:26:00.770 --> 00:26:02.270
You have to send
lattice vibrations

00:26:02.270 --> 00:26:04.200
out which, through
their n harmonicity,

00:26:04.200 --> 00:26:07.040
have to get
dissipated somewhere.

00:26:07.040 --> 00:26:10.610
And so any time
you block phonons,

00:26:10.610 --> 00:26:14.030
you're essentially reducing
the thermal conductivity

00:26:14.030 --> 00:26:16.258
of the system.

00:26:16.258 --> 00:26:18.800
So this coarse graining gives
you lower thermal conductivity.

00:26:18.800 --> 00:26:21.332
And I'll show you some
examples in a second.

00:26:21.332 --> 00:26:22.790
But you know, it
does worse things.

00:26:22.790 --> 00:26:25.910
It's essentially
elastically confining, also,

00:26:25.910 --> 00:26:29.670
your system somewhat, but
only in a dynamical sense.

00:26:29.670 --> 00:26:33.230
So it's like you're
having, for certain,

00:26:33.230 --> 00:26:35.880
dynamical nodes,
a small unit cell.

00:26:35.880 --> 00:26:38.360
And so that means
that they reflect back

00:26:38.360 --> 00:26:41.390
of the coarse
graining interface.

00:26:41.390 --> 00:26:44.390
And they hit your
region of action

00:26:44.390 --> 00:26:46.550
fairly quickly as soon as
they're reflected back.

00:26:50.180 --> 00:26:55.640
So it's exactly the same
as putting your dynamics

00:26:55.640 --> 00:26:59.120
in a very small box except
that the size of the box

00:26:59.120 --> 00:27:00.830
that the system
fields is different

00:27:00.830 --> 00:27:03.140
for different wavelengths.

00:27:03.140 --> 00:27:06.080
So a certain amount of
elastic behavior gets

00:27:06.080 --> 00:27:09.630
reflected back fairly quickly.

00:27:09.630 --> 00:27:12.430
So the phonon transmission
problem is a serious one.

00:27:18.750 --> 00:27:21.420
And the phonon
transmission one is usually

00:27:21.420 --> 00:27:23.280
recognized very well.

00:27:23.280 --> 00:27:25.380
There's one that's not
as well recognized,

00:27:25.380 --> 00:27:28.020
but is probably in
the long-term just as

00:27:28.020 --> 00:27:31.590
severe, is any time
you remove degrees

00:27:31.590 --> 00:27:34.283
of freedom you remove entropy.

00:27:34.283 --> 00:27:35.700
Because the entropy
is essentially

00:27:35.700 --> 00:27:38.670
a count of your
degrees of freedom.

00:27:38.670 --> 00:27:40.290
You may not worry about that.

00:27:40.290 --> 00:27:43.470
But the problem is that,
if you do dynamics,

00:27:43.470 --> 00:27:47.460
your system will equilibrate
along certain derivatives

00:27:47.460 --> 00:27:48.570
of the entropy.

00:27:48.570 --> 00:27:49.740
And you'll get them wrong.

00:27:49.740 --> 00:27:51.240
If you get the
entropy wrong, you'll

00:27:51.240 --> 00:27:52.530
get its derivatives wrong.

00:27:52.530 --> 00:27:55.950
And some of the ones
that you may worry about

00:27:55.950 --> 00:27:58.830
are heat capacity,
which is the temperature

00:27:58.830 --> 00:28:02.208
derivative of the entropy,
but also this one, which

00:28:02.208 --> 00:28:03.750
you may worry a lot
more about if you

00:28:03.750 --> 00:28:07.080
do mechanical behavior, thermal
expansion, which is the volume

00:28:07.080 --> 00:28:09.540
derivative of the entropy.

00:28:09.540 --> 00:28:11.040
Remember your Maxwell relations?

00:28:11.040 --> 00:28:15.760
The sdv is essentially
dv dt up to some factors.

00:28:15.760 --> 00:28:17.820
So how the entropy
changed with volume

00:28:17.820 --> 00:28:20.580
determines the
thermal expansion.

00:28:20.580 --> 00:28:23.670
And that's why, if you
actually look back,

00:28:23.670 --> 00:28:27.430
the slide I showed
you, when we define

00:28:27.430 --> 00:28:31.340
the effective potential
between atoms 1 and 3,

00:28:31.340 --> 00:28:33.420
there's actually a potential.

00:28:33.420 --> 00:28:37.800
And then there's a part
that doesn't contain

00:28:37.800 --> 00:28:40.440
the coordinates of 1 and 3.

00:28:40.440 --> 00:28:45.450
And it's essentially the entropy
you've lost by removing node 2.

00:28:45.450 --> 00:28:50.960
You have to actually keep
that entropy in the system

00:28:50.960 --> 00:28:55.030
if you want to get the total
thermodynamic qualities right.

00:28:55.030 --> 00:28:59.410
It's sort of like you
see that this is obvious

00:28:59.410 --> 00:29:01.900
if you take the complete
limit of removing all nodes

00:29:01.900 --> 00:29:02.830
or going to 1 node.

00:29:02.830 --> 00:29:06.510
Then you end up with
continuum behavior.

00:29:06.510 --> 00:29:09.750
And the degrees of freedom
of continuing behavior

00:29:09.750 --> 00:29:11.340
are not the entropy.

00:29:11.340 --> 00:29:14.850
You've actually removed
all the dynamic motion

00:29:14.850 --> 00:29:16.570
when you go through
continuum theory.

00:29:16.570 --> 00:29:19.230
So unless you've kept track
of the degrees of freedom

00:29:19.230 --> 00:29:21.780
and the entropy
that they include,

00:29:21.780 --> 00:29:24.390
you've lost all your
information about that.

00:29:28.970 --> 00:29:32.590
So when you do something
like this here,

00:29:32.590 --> 00:29:35.890
these will actually, if
you define the potentials

00:29:35.890 --> 00:29:39.370
at a given temperature, because
the renormalization potential

00:29:39.370 --> 00:29:42.560
depends on temperature--

00:29:42.560 --> 00:29:44.510
if you define this at
a given temperature

00:29:44.510 --> 00:29:46.970
and you run this at
any other temperature,

00:29:46.970 --> 00:29:50.240
these regions will have
different thermal expansions.

00:29:50.240 --> 00:29:52.768
And so you'll build up
internal strain in your system

00:29:52.768 --> 00:29:53.560
without knowing it.

00:29:58.590 --> 00:30:01.000
I get a new color scheme.

00:30:01.000 --> 00:30:02.650
There we go.

00:30:02.650 --> 00:30:07.230
So if you take a simple
pair potential model,

00:30:07.230 --> 00:30:09.900
these coarse graining
schemes work pretty well.

00:30:09.900 --> 00:30:11.610
Here's essentially
a static property

00:30:11.610 --> 00:30:13.152
even though it has
temperature in it,

00:30:13.152 --> 00:30:18.780
but this is the strain in that
2D system versus the stress.

00:30:18.780 --> 00:30:22.960
And the black curve
underlying this

00:30:22.960 --> 00:30:26.770
is the full system,
so no coarse graining.

00:30:26.770 --> 00:30:29.950
And the red curve is that coarse
grain system that I showed you.

00:30:29.950 --> 00:30:32.950
And you'll see even in the
non-linear part does this

00:30:32.950 --> 00:30:33.790
very well.

00:30:33.790 --> 00:30:35.125
And it makes sense, you know.

00:30:35.125 --> 00:30:39.580
This kind of mechanical
behavior, strain versus stress,

00:30:39.580 --> 00:30:42.070
is largely dominated
by the potentials

00:30:42.070 --> 00:30:43.600
in this kind of solid system.

00:30:43.600 --> 00:30:46.850
There's very little dynamical
factors that play a role in it.

00:30:46.850 --> 00:30:50.230
So as long as you normalize
the potentials right,

00:30:50.230 --> 00:30:54.400
you will get the stress-strain
relation right even

00:30:54.400 --> 00:30:56.170
in the non-linear regime.

00:30:56.170 --> 00:30:57.520
So that's not a big surprise.

00:31:00.530 --> 00:31:02.960
If you keep track of
the entropy right,

00:31:02.960 --> 00:31:06.830
you'll get things like
the heat capacities right.

00:31:06.830 --> 00:31:10.850
This is the ratio
between the heat capacity

00:31:10.850 --> 00:31:14.240
in the non-homogeneous system,
which is the coarse grain

00:31:14.240 --> 00:31:17.150
system, divided by the
exact result, you could say,

00:31:17.150 --> 00:31:18.860
the heat capacity
in the homogeneous.

00:31:18.860 --> 00:31:21.500
It essentially
oscillates around one

00:31:21.500 --> 00:31:23.190
as a function of temperature.

00:31:23.190 --> 00:31:25.790
So by construction you
pretty much have that right.

00:31:30.090 --> 00:31:33.030
So here gets more interesting.

00:31:33.030 --> 00:31:36.180
If you look at heat
conduction through

00:31:36.180 --> 00:31:38.650
a coarse grained interface--

00:31:38.650 --> 00:31:40.950
so let's say you're
fine at this side.

00:31:40.950 --> 00:31:42.480
Let's say these are atoms.

00:31:42.480 --> 00:31:47.820
And here we've removed a bunch
of nodes with coarse grains.

00:31:47.820 --> 00:31:50.940
And so you look at the heat
conduction through this.

00:31:50.940 --> 00:31:52.540
So you set up a
temperature gradient

00:31:52.540 --> 00:31:55.600
and essentially look at the
heat flux when you do dynamics.

00:31:55.600 --> 00:32:03.450
So what this is showing
here is the heat conduction

00:32:03.450 --> 00:32:07.260
in the non-homogeneous system
divided by the heat conduction

00:32:07.260 --> 00:32:08.850
in the homogeneous system.

00:32:08.850 --> 00:32:11.490
And this is pretty much
always lower than 1.

00:32:11.490 --> 00:32:14.670
So the non-homogeneous system
has less heat conduction.

00:32:14.670 --> 00:32:18.950
And the reason is you scatter
phonons on this interface.

00:32:18.950 --> 00:32:20.710
So here there is
a certain amount

00:32:20.710 --> 00:32:22.910
of phonons that
get reflected back.

00:32:22.910 --> 00:32:25.090
But it's interesting.

00:32:25.090 --> 00:32:26.860
If you show this
here as a function

00:32:26.860 --> 00:32:30.920
of the length of the
homogeneous system,

00:32:30.920 --> 00:32:35.030
you do better and better
as this system gets bigger.

00:32:35.030 --> 00:32:37.550
And that makes sense because
then the interface becomes

00:32:37.550 --> 00:32:39.230
less and less important.

00:32:39.230 --> 00:32:42.560
But, you know, look
at the size here.

00:32:42.560 --> 00:32:44.630
To get up to sort
of about 1, you

00:32:44.630 --> 00:32:51.640
need about 1,500 atoms in
the homogeneous region.

00:32:51.640 --> 00:32:56.110
So this is a major problem
with full phonons in general.

00:32:56.110 --> 00:33:01.180
I think of any atomistic level
phenomena phonons are probably

00:33:01.180 --> 00:33:05.032
the ones that have the
largest length scale.

00:33:05.032 --> 00:33:07.240
The phonon mean free
[INAUDIBLE] at a low temperature

00:33:07.240 --> 00:33:09.520
is enormous.

00:33:09.520 --> 00:33:11.500
It's thousands of atoms far.

00:33:11.500 --> 00:33:15.040
That means that phonons
are usually the first thing

00:33:15.040 --> 00:33:18.015
to see something far away.

00:33:18.015 --> 00:33:20.140
They're the first thing to
see finite size effects.

00:33:20.140 --> 00:33:22.480
They're the first to see
scattering of interfaces.

00:33:22.480 --> 00:33:25.570
Because the reason is
that a lot of systems

00:33:25.570 --> 00:33:28.830
behave at low temperature
fairly harmonic.

00:33:28.830 --> 00:33:30.420
That means that
these phonons just

00:33:30.420 --> 00:33:31.860
travel and travel and travel.

00:33:31.860 --> 00:33:33.870
And their probability
of being scattered

00:33:33.870 --> 00:33:36.340
is pretty low because it's
only as they start becoming

00:33:36.340 --> 00:33:39.180
enharmonic that they scatter.

00:33:39.180 --> 00:33:41.077
Of course, they could
scatter off disorder.

00:33:41.077 --> 00:33:42.660
So if you have the
disordered systems,

00:33:42.660 --> 00:33:44.340
the mean free pattern
is a lot lower.

00:33:44.340 --> 00:33:48.030
But phonons you often
see hundreds of angstrom

00:33:48.030 --> 00:33:49.887
far, essentially.

00:34:00.160 --> 00:34:04.790
OK, here's the same result
as a function of temperature.

00:34:04.790 --> 00:34:10.030
So the heat capacity versus the
normalized temperature, this

00:34:10.030 --> 00:34:12.429
is the real system.

00:34:12.429 --> 00:34:15.520
So this is a fully
atomistic level system.

00:34:15.520 --> 00:34:19.570
And this, in red here,
is the partially coarse

00:34:19.570 --> 00:34:21.800
grained system, in this
case with two interfaces.

00:34:21.800 --> 00:34:24.175
Now, what you see is the coarse
grained system always has

00:34:24.175 --> 00:34:27.100
lower heat conductance.

00:34:27.100 --> 00:34:29.560
They tend to come a
little closer together

00:34:29.560 --> 00:34:30.995
at higher temperature.

00:34:30.995 --> 00:34:32.620
And the reason is at
higher temperature

00:34:32.620 --> 00:34:34.510
you have more enharmonicity.

00:34:34.510 --> 00:34:38.210
So the phonons have a
shorter mean free path.

00:34:38.210 --> 00:34:42.130
So they tend to
homogenizer easier

00:34:42.130 --> 00:34:45.040
and don't see the
interfaces as much.

00:34:51.540 --> 00:34:53.199
OK, let me skip this.

00:34:53.199 --> 00:34:55.080
OK.

00:34:55.080 --> 00:34:59.850
So that's some of the efforts
going on in coarse graining

00:34:59.850 --> 00:35:00.675
over space.

00:35:05.260 --> 00:35:08.950
I think if there's
an area in which you

00:35:08.950 --> 00:35:12.490
want to work and have high
impact, this is probably one.

00:35:12.490 --> 00:35:14.140
I haven't seen a
single good idea

00:35:14.140 --> 00:35:16.257
in this field in
the last 10 years.

00:35:16.257 --> 00:35:17.840
I probably shouldn't
say this on tape,

00:35:17.840 --> 00:35:20.920
but, you know, this
is a field where

00:35:20.920 --> 00:35:22.510
progress is desperately needed.

00:35:22.510 --> 00:35:25.630
And it's a really,
really hard problem.

00:35:25.630 --> 00:35:28.010
Because you're essentially
asking the question,

00:35:28.010 --> 00:35:31.120
what is the dynamics of
partially coarse-grained

00:35:31.120 --> 00:35:32.920
systems?

00:35:32.920 --> 00:35:36.310
And the reason it's
so hard is that it's

00:35:36.310 --> 00:35:38.740
a mixture of sort of
Newtonian mechanics, which

00:35:38.740 --> 00:35:43.900
is energy conserving,
and dissipated dynamics.

00:35:43.900 --> 00:35:45.520
And you have to
sort of-- and that

00:35:45.520 --> 00:35:47.500
how you mix those
essentially depends

00:35:47.500 --> 00:35:50.550
on the frequency of your motion.

00:35:50.550 --> 00:35:52.500
And that's why this is
such a hard problem.

00:35:52.500 --> 00:35:55.530
People have tried
things with boundaries

00:35:55.530 --> 00:35:59.130
that have complex
impedances, where

00:35:59.130 --> 00:36:01.755
essentially your transmission
through the boundary

00:36:01.755 --> 00:36:04.120
is frequency dependent.

00:36:04.120 --> 00:36:05.590
And you can see,
with that one, you

00:36:05.590 --> 00:36:10.130
can definitely sort of tailor
better what the phonons do.

00:36:10.130 --> 00:36:12.800
Because, now, you have a
much more complex interface

00:36:12.800 --> 00:36:15.052
literally to control.

00:36:15.052 --> 00:36:17.510
The problem is that some of
these things you can make work,

00:36:17.510 --> 00:36:20.690
but they get so complicated
to implement that they're not

00:36:20.690 --> 00:36:22.160
necessarily very practical.

00:36:22.160 --> 00:36:25.760
Other people do things with
large overlapping regions.

00:36:25.760 --> 00:36:28.430
You could say one way
to solve this problem is

00:36:28.430 --> 00:36:31.070
to not have these
sharp boundaries

00:36:31.070 --> 00:36:34.100
between different levels
of coarse graining,

00:36:34.100 --> 00:36:38.030
but overlap the two regions
and slowly force them

00:36:38.030 --> 00:36:39.000
in the overlap region.

00:36:39.000 --> 00:36:40.940
The solution, say, to
the displacements fields

00:36:40.940 --> 00:36:41.510
are the same.

00:36:44.520 --> 00:36:45.610
OK.

00:36:45.610 --> 00:36:50.740
The next thing I want to talk
about is accelerating time.

00:36:50.740 --> 00:36:53.010
I said without Einstein,
but I think Einstein only

00:36:53.010 --> 00:36:54.060
could slow down time.

00:36:54.060 --> 00:36:54.930
Is isn't that right?

00:36:54.930 --> 00:36:56.510
I'm not sure we
can accelerate, no?

00:36:56.510 --> 00:36:59.310
I don't know.

00:36:59.310 --> 00:37:03.180
I don't know my theory of
relativity too well anymore.

00:37:03.180 --> 00:37:06.390
I think I don't have to
convince you-- you've done MD--

00:37:06.390 --> 00:37:10.135
why you need to speed
up time sometimes.

00:37:10.135 --> 00:37:11.760
Most of what I'm
going to say comes out

00:37:11.760 --> 00:37:14.670
of this review
article by Art Voter,

00:37:14.670 --> 00:37:19.440
who's probably been the guy to
work on accelerated MD methods.

00:37:19.440 --> 00:37:21.540
And I'll give you the
references again at the end.

00:37:21.540 --> 00:37:22.957
This is a great
review if you want

00:37:22.957 --> 00:37:27.700
to read about this
because there's

00:37:27.700 --> 00:37:30.310
some really clever stuff
in here that I think,

00:37:30.310 --> 00:37:32.860
even if you don't want
to do accelerated MD,

00:37:32.860 --> 00:37:37.580
that you could use
for other things.

00:37:37.580 --> 00:37:40.780
So first of all,
what's the problem?

00:37:40.780 --> 00:37:44.140
The problem is obviously
that, in most systems that

00:37:44.140 --> 00:37:48.850
are fairly dense, you have
well-defined minimum phase

00:37:48.850 --> 00:37:49.630
space.

00:37:49.630 --> 00:37:52.790
And often the barriers
between them are pretty high.

00:37:52.790 --> 00:37:55.690
So you sample the
transitions between them

00:37:55.690 --> 00:37:57.760
at a very low rate.

00:37:57.760 --> 00:38:00.590
The rate is essentially
proportional to the exponential

00:38:00.590 --> 00:38:02.590
of the activation barrier
between the minimum.

00:38:02.590 --> 00:38:04.548
And like I said, in a
lot of condensed systems,

00:38:04.548 --> 00:38:07.720
those activation
barriers are quite high

00:38:07.720 --> 00:38:11.365
and lead to timescales that
you can't quite sample.

00:38:16.430 --> 00:38:19.870
So I'm going to talk briefly
about three different methods

00:38:19.870 --> 00:38:23.050
to speed up time
parallel replica

00:38:23.050 --> 00:38:26.450
dynamics, hyperdynamics,
and temperature accelerated

00:38:26.450 --> 00:38:26.950
dynamics.

00:38:30.180 --> 00:38:31.110
OK.

00:38:31.110 --> 00:38:34.110
Let me sort of quickly
review what you would do

00:38:34.110 --> 00:38:36.190
with transition state theory.

00:38:36.190 --> 00:38:39.750
So if you knew the transitions
that a system had to make, like

00:38:39.750 --> 00:38:43.170
in, say, a simple
molecular reaction,

00:38:43.170 --> 00:38:45.300
then you really don't
need to do a simulation.

00:38:45.300 --> 00:38:50.220
Because if the activation
barrier, this quantity and you

00:38:50.220 --> 00:38:53.910
have some idea of the frequency
with which the system tries

00:38:53.910 --> 00:38:58.110
to cross that barrier, you
can do transition state theory

00:38:58.110 --> 00:39:02.100
and essentially say that
the crossing rate is going

00:39:02.100 --> 00:39:05.160
to be something like
the attempt rate,

00:39:05.160 --> 00:39:09.150
nu, times the success rate,
which is this Boltzmann factor.

00:39:09.150 --> 00:39:12.047
And the chemists among
you and chemical engineers

00:39:12.047 --> 00:39:14.130
know there's all kinds of
approximations in there.

00:39:14.130 --> 00:39:16.530
But none of them are
particularly severe for most

00:39:16.530 --> 00:39:17.370
things to study.

00:39:17.370 --> 00:39:21.390
Like, one approximation just
assumes you don't cross back.

00:39:21.390 --> 00:39:23.610
Often, when you sit at
the transition state,

00:39:23.610 --> 00:39:25.110
you're essentially
assuming that you

00:39:25.110 --> 00:39:27.240
fall over and don't cross back.

00:39:27.240 --> 00:39:29.460
The other approximation
is that this

00:39:29.460 --> 00:39:32.580
assumes that the
transitions are infrequent

00:39:32.580 --> 00:39:34.950
compared to the
vibrations in the minimum.

00:39:34.950 --> 00:39:38.580
So you assume that when the
system goes from here to here

00:39:38.580 --> 00:39:41.340
it's sort of equilibrates
here, vibrates

00:39:41.340 --> 00:39:45.240
around until it makes
the next transition.

00:39:45.240 --> 00:39:47.040
And the reason you
need to do that

00:39:47.040 --> 00:39:51.130
is that you need to equilibrate
first in every potential well

00:39:51.130 --> 00:39:52.380
before you go to the next one.

00:39:52.380 --> 00:39:54.660
Because, otherwise, you
have dynamical memory left

00:39:54.660 --> 00:39:57.450
from the previous transition,
which would essentially

00:39:57.450 --> 00:40:00.870
change your statistic, would
make your statistical mechanics

00:40:00.870 --> 00:40:03.540
approach invalid.

00:40:03.540 --> 00:40:08.545
But usually those are
easy to deal with.

00:40:08.545 --> 00:40:09.420
It's sort of obvious.

00:40:09.420 --> 00:40:12.180
Because if you think about
it, if the system crosses very

00:40:12.180 --> 00:40:15.090
rapidly compared to
the time it vibrates,

00:40:15.090 --> 00:40:16.638
then you just do
molecular dynamics

00:40:16.638 --> 00:40:18.430
because then you have
very fast transition.

00:40:18.430 --> 00:40:20.470
So who cares about
transition state theory?

00:40:26.710 --> 00:40:27.820
OK.

00:40:27.820 --> 00:40:30.490
So the parallel replica
method is really

00:40:30.490 --> 00:40:35.440
kind of elegant in
its triviality almost.

00:40:35.440 --> 00:40:40.120
If you think of what is time,
time is waiting for events

00:40:40.120 --> 00:40:41.930
to happen.

00:40:41.930 --> 00:40:44.877
And if you think of a
really trivial example,

00:40:44.877 --> 00:40:46.960
let's say the system wants
to move from this state

00:40:46.960 --> 00:40:48.220
to that state.

00:40:48.220 --> 00:40:50.230
You're just sitting there.

00:40:50.230 --> 00:40:51.640
The atoms are vibrating around.

00:40:51.640 --> 00:40:54.580
And you're waiting for
a system to transition.

00:40:54.580 --> 00:40:57.920
Why not wait on many
processors at a time?

00:40:57.920 --> 00:41:00.310
So the idea is you
run this simulation

00:41:00.310 --> 00:41:02.680
on a bunch of processors.

00:41:02.680 --> 00:41:05.080
And if you run on,
say, 100, you could

00:41:05.080 --> 00:41:07.930
say that's kind of like
waiting 100 times the time you

00:41:07.930 --> 00:41:09.790
wait on one processor.

00:41:09.790 --> 00:41:15.100
And then let's say it
happens on one processor.

00:41:15.100 --> 00:41:16.840
The system transitions.

00:41:16.840 --> 00:41:19.930
Then you essentially add up
all the time all the systems

00:41:19.930 --> 00:41:22.660
have waited, and that's
your total waiting time.

00:41:22.660 --> 00:41:25.240
And in a statistical sense,
that's actually right.

00:41:25.240 --> 00:41:27.550
If you do queuing theory
and things like that,

00:41:27.550 --> 00:41:29.520
you'll find that
this is the solution.

00:41:29.520 --> 00:41:31.270
It's actually easy to
see if you turn this

00:41:31.270 --> 00:41:33.460
all into probabilities
for transfer.

00:41:33.460 --> 00:41:37.750
Essentially, you could say,
when you do it 100 times,

00:41:37.750 --> 00:41:40.360
you've 100 times
attempted or given

00:41:40.360 --> 00:41:44.290
the system chances in a given
time to make a transition.

00:41:44.290 --> 00:41:48.790
So you add up all the time,
and then you just restart.

00:41:48.790 --> 00:41:52.270
So you put the system
in the next state.

00:41:52.270 --> 00:41:54.453
And you again run
all those replicas.

00:41:54.453 --> 00:41:56.620
You have to introduce a
little bit of randomization,

00:41:56.620 --> 00:41:57.250
of course.

00:41:57.250 --> 00:42:00.130
You don't want these to follow
exactly the same trajectory

00:42:00.130 --> 00:42:01.420
through phase space.

00:42:01.420 --> 00:42:05.530
So there's a certain amount
of randomization that goes on.

00:42:05.530 --> 00:42:10.510
So essentially, this
is linear time scaling.

00:42:10.510 --> 00:42:13.810
Overall, you pretty much--
if you have n processors,

00:42:13.810 --> 00:42:16.840
time is accelerated by a
factor of n you could say.

00:42:16.840 --> 00:42:19.390
It's a little less
because there's overhead.

00:42:19.390 --> 00:42:23.050
You have to, first of all,
do the non-trivial thing,

00:42:23.050 --> 00:42:25.300
which is detect the transition.

00:42:25.300 --> 00:42:28.570
When you think about it, this
is kind of not that trivial.

00:42:28.570 --> 00:42:30.160
You're doing your MD simulation.

00:42:30.160 --> 00:42:33.970
And you've got to sort
of ask your system, oh,

00:42:33.970 --> 00:42:35.800
has something happened?

00:42:35.800 --> 00:42:39.040
And maybe it's, like, an
atom diffusing, whatever.

00:42:39.040 --> 00:42:41.590
So you've got to do quite a
bit of work to sort of check

00:42:41.590 --> 00:42:43.007
whether a transition
that happens.

00:42:43.007 --> 00:42:44.500
So you've got overhead there.

00:42:44.500 --> 00:42:49.600
And then you have overhead when
you sort of copy the transition

00:42:49.600 --> 00:42:52.180
state into all the other ones.

00:42:52.180 --> 00:42:54.500
You have to do a little
bit of randomization here.

00:42:54.500 --> 00:42:59.170
So typically you may restart
with an actual Boltzmann

00:42:59.170 --> 00:43:00.760
distribution of
velocities and so.

00:43:00.760 --> 00:43:02.488
But you have to initialize that.

00:43:02.488 --> 00:43:04.280
You have to run that
for a very short time.

00:43:04.280 --> 00:43:06.100
And so you have a bit
of overhead there.

00:43:06.100 --> 00:43:10.690
So you'll get a little
less than end scaling.

00:43:10.690 --> 00:43:12.640
But it's not bad.

00:43:12.640 --> 00:43:14.050
It's not great either.

00:43:14.050 --> 00:43:16.150
But like I said, with
1,000 processors,

00:43:16.150 --> 00:43:19.360
you can go from nanoseconds
to microseconds.

00:43:19.360 --> 00:43:22.270
So yeah, that's not bad.

00:43:22.270 --> 00:43:23.830
I mean, you can see
that you're never

00:43:23.830 --> 00:43:27.730
going to make it to seconds
because of the linear scaling.

00:43:27.730 --> 00:43:33.650
But it is a sort of intermediate
timescale that can be useful.

00:43:33.650 --> 00:43:34.910
Here's an example.

00:43:34.910 --> 00:43:39.700
This is planarization
of silver on silver.

00:43:39.700 --> 00:43:43.930
And this comes straight
out of Art Voter's article.

00:43:43.930 --> 00:43:46.780
So essentially, this is a
1, 1, 1 layer of silver.

00:43:46.780 --> 00:43:49.060
That's the white atoms.

00:43:49.060 --> 00:43:51.800
And then on top of
that is a first layer,

00:43:51.800 --> 00:43:53.110
which is the blue atoms.

00:43:53.110 --> 00:43:55.430
And then the yellow atoms
is another layer on top.

00:43:55.430 --> 00:43:57.430
OK, so you're
seeing three layers.

00:43:57.430 --> 00:44:03.340
And so this study tracks
how the system planarizes

00:44:03.340 --> 00:44:05.030
to lower its surface energy.

00:44:05.030 --> 00:44:07.510
So the top atoms should
sort of come down

00:44:07.510 --> 00:44:10.250
and form all one island.

00:44:10.250 --> 00:44:13.910
And so this is perfect
for accelerated MD.

00:44:13.910 --> 00:44:16.670
I mean, researchers know
why they pick problems

00:44:16.670 --> 00:44:18.950
because they can solve them.

00:44:18.950 --> 00:44:22.510
Because this is a set
of discrete events.

00:44:22.510 --> 00:44:25.580
You know, atoms diffuse and
maybe even collectively.

00:44:25.580 --> 00:44:27.770
You see, the nice thing
about MD is that you're not

00:44:27.770 --> 00:44:30.590
imposing the kinetic mechanism.

00:44:30.590 --> 00:44:33.410
But it's still a set
of discrete events.

00:44:33.410 --> 00:44:35.810
So atoms may help a
little-- you can see it

00:44:35.810 --> 00:44:37.970
in the first few slides
there-- and ultimately

00:44:37.970 --> 00:44:39.020
sort of planarize.

00:44:39.020 --> 00:44:45.050
People got all the way
up to 1 microsecond.

00:44:45.050 --> 00:44:47.600
Although it was done
with empirical potential.

00:44:47.600 --> 00:44:51.260
And according to Art Voter,
this took only about five days

00:44:51.260 --> 00:44:52.580
on 32 Pentiums.

00:44:52.580 --> 00:44:53.390
And these are old.

00:44:53.390 --> 00:44:55.015
I mean, these are 1
gigahertz Pentiums,

00:44:55.015 --> 00:44:58.030
so probably do it in
maybe one to two days now.

00:45:02.120 --> 00:45:06.260
I think you can already
see, if I go back,

00:45:06.260 --> 00:45:07.790
when this will not work.

00:45:10.700 --> 00:45:14.720
This will not work if the
overhead becomes excessive.

00:45:14.720 --> 00:45:17.030
And how is it going
to become excessive--

00:45:17.030 --> 00:45:22.840
if you start getting
a lot of transitions.

00:45:22.840 --> 00:45:25.180
If only after a little
bit of simulation

00:45:25.180 --> 00:45:27.190
you get a transition,
then your overhead

00:45:27.190 --> 00:45:29.035
starts to weigh heavily.

00:45:29.035 --> 00:45:30.410
And when is that
going to happen?

00:45:30.410 --> 00:45:32.368
Well, it's going to
happen, of course, when you

00:45:32.368 --> 00:45:33.580
have low activation barriers.

00:45:33.580 --> 00:45:35.050
But there's another
problem which

00:45:35.050 --> 00:45:36.910
is a little more
severe, if you make

00:45:36.910 --> 00:45:39.570
your system bigger and bigger.

00:45:39.570 --> 00:45:42.590
See the probability-- let's
say you have a system that's

00:45:42.590 --> 00:45:43.790
sort of locally identical.

00:45:43.790 --> 00:45:46.540
If you make it
bigger and bigger,

00:45:46.540 --> 00:45:49.100
the probability that
a transition occurs--

00:45:49.100 --> 00:45:50.600
let's say an atom diffuses--

00:45:50.600 --> 00:45:53.150
is proportional to
the system size.

00:45:53.150 --> 00:45:56.010
The probability that
an event happens

00:45:56.010 --> 00:45:57.900
is proportional to
the system size.

00:45:57.900 --> 00:45:59.870
So as you make the
system bigger and bigger,

00:45:59.870 --> 00:46:03.080
this essentially becomes
less and less efficient

00:46:03.080 --> 00:46:05.790
because you get more
and more transitions.

00:46:05.790 --> 00:46:07.850
And that's something you'll
see in other versions

00:46:07.850 --> 00:46:10.180
of accelerated MD as well.

00:46:12.820 --> 00:46:13.960
OK.

00:46:13.960 --> 00:46:16.990
Hyperdynamics, I like
the word very much,

00:46:16.990 --> 00:46:19.300
but I'm not going to
say much about it.

00:46:19.300 --> 00:46:22.150
Hyperdynamics is really
a class of methods

00:46:22.150 --> 00:46:25.900
that is getting very popular
not just in accelerating MD now.

00:46:25.900 --> 00:46:29.770
But the whole idea of
modifying the potential surface

00:46:29.770 --> 00:46:31.960
is getting sort of
very popular also

00:46:31.960 --> 00:46:34.840
for pure optimization methods.

00:46:34.840 --> 00:46:42.000
If you think that this is the
surface of the original system,

00:46:42.000 --> 00:46:45.210
this is the energy
surface, your problem

00:46:45.210 --> 00:46:46.650
is that these
wells are too deep.

00:46:46.650 --> 00:46:49.170
Well, solve the problem
by lifting them up.

00:46:49.170 --> 00:46:51.780
So if you can define
a potential that

00:46:51.780 --> 00:46:58.170
tracks the original
potential in most of space,

00:46:58.170 --> 00:47:02.480
especially the activated
pieces, but then lifts up

00:47:02.480 --> 00:47:08.813
the minima of the well,
if your system moves

00:47:08.813 --> 00:47:10.730
on the red potential,
it's going to transition

00:47:10.730 --> 00:47:15.170
a lot faster because the
activation barrier goes down

00:47:15.170 --> 00:47:17.000
a lot.

00:47:17.000 --> 00:47:21.050
And you can actually run
the system on the red curve

00:47:21.050 --> 00:47:23.720
and correct for the
transition rate.

00:47:23.720 --> 00:47:27.340
Because, see, the cool
thing is that once

00:47:27.340 --> 00:47:31.600
the MD finds the transitions--

00:47:31.600 --> 00:47:34.650
so MD is going back
and forth here.

00:47:34.650 --> 00:47:36.490
But once it's found
the transition,

00:47:36.490 --> 00:47:38.740
you could calculate back
what the real barrier

00:47:38.740 --> 00:47:41.560
should have been.

00:47:41.560 --> 00:47:43.630
So you know at what
rate the system should

00:47:43.630 --> 00:47:45.950
have transitioned.

00:47:45.950 --> 00:47:49.010
So boosting the potential
surface with this boost

00:47:49.010 --> 00:47:50.780
potential-- that's
this difference here,

00:47:50.780 --> 00:47:52.280
boosting it up--

00:47:52.280 --> 00:47:57.860
is essentially accelerating
the escape from the minimum.

00:47:57.860 --> 00:48:01.520
And you can correct back by
this Boltzmann factor, which

00:48:01.520 --> 00:48:07.790
is essentially comes from
the ratio of the proper rate

00:48:07.790 --> 00:48:10.838
to the rate that you actually
had in your MD simulation.

00:48:10.838 --> 00:48:12.380
There's all kinds
of tricks involved.

00:48:12.380 --> 00:48:15.950
This is a simplified
version of it.

00:48:15.950 --> 00:48:17.450
There's a lot of
questions about how

00:48:17.450 --> 00:48:20.300
you define that boost surface.

00:48:20.300 --> 00:48:23.850
For example, do you want to
keep the same frequencies?

00:48:23.850 --> 00:48:27.320
So then you'd like to keep
the curvature the same.

00:48:27.320 --> 00:48:30.110
Because then you keep the
same attempt frequencies,

00:48:30.110 --> 00:48:32.450
but you're only
changing the success

00:48:32.450 --> 00:48:34.107
rate of crossing the barrier.

00:48:34.107 --> 00:48:35.690
That's a very elegant
way of doing it.

00:48:35.690 --> 00:48:38.930
And people have ways
that they can do this.

00:48:38.930 --> 00:48:45.180
So doing this in
practice often means

00:48:45.180 --> 00:48:49.290
calculating derivatives
of potential surfaces,

00:48:49.290 --> 00:48:53.640
in many cases even Hessians, so
matrices of second derivatives.

00:48:53.640 --> 00:48:56.460
And that's easy to do
when you have potentials.

00:48:56.460 --> 00:48:58.975
It's a lot harder to do when
you're doing quantum mechanics.

00:48:58.975 --> 00:49:00.600
And so it's, again,
one of these things

00:49:00.600 --> 00:49:04.770
that is usually only done
with empirical potentials.

00:49:04.770 --> 00:49:07.170
Actually, I don't know of any
implementation with quantum

00:49:07.170 --> 00:49:09.810
mechanics, but it may
be something I've just

00:49:09.810 --> 00:49:12.720
missed in the literature.

00:49:12.720 --> 00:49:15.270
This is used for sort of
other schemes as well.

00:49:15.270 --> 00:49:19.200
If you for a second don't
care about dynamics,

00:49:19.200 --> 00:49:22.800
there are now schemes out there
to use this for optimization.

00:49:22.800 --> 00:49:25.077
If you think of
global optimization

00:49:25.077 --> 00:49:26.910
of a system is a big
problem because there's

00:49:26.910 --> 00:49:29.490
all kinds of local wells,
well, what you can do

00:49:29.490 --> 00:49:33.860
is, if you fall in a
well, you essentially

00:49:33.860 --> 00:49:35.030
start filling up the well.

00:49:39.570 --> 00:49:41.370
It's sort of like water
filling up the well

00:49:41.370 --> 00:49:44.100
until you fall out
into the next well.

00:49:44.100 --> 00:49:44.850
OK.

00:49:44.850 --> 00:49:49.720
And then you start
filling up that well

00:49:49.720 --> 00:49:51.100
until you fall in next well.

00:49:51.100 --> 00:49:53.500
And it's sort of like
water cascading down

00:49:53.500 --> 00:49:54.850
an energy surface.

00:49:54.850 --> 00:49:57.200
And it's a way to do
global optimization

00:49:57.200 --> 00:49:59.610
in a landscape of many minima.

00:49:59.610 --> 00:50:01.120
I think this method
was developed

00:50:01.120 --> 00:50:03.596
by people at Princeton.

00:50:09.660 --> 00:50:12.060
So that's sort of in the
category of hyperdynamics.

00:50:14.727 --> 00:50:16.310
The one that's
actually very practical

00:50:16.310 --> 00:50:20.360
is the next one, which is
temperature accelerated

00:50:20.360 --> 00:50:26.760
dynamics, which is, again,
a sort of obvious idea.

00:50:26.760 --> 00:50:29.600
If stuff runs too slow
at low temperature,

00:50:29.600 --> 00:50:30.850
run it at higher temperatures.

00:50:30.850 --> 00:50:33.300
It'll go faster.

00:50:33.300 --> 00:50:36.180
That's actually something
people have often done in MD

00:50:36.180 --> 00:50:38.700
without much justification.

00:50:38.700 --> 00:50:41.490
What Art Voter's group
did in Los Alamos

00:50:41.490 --> 00:50:43.380
is essentially give
this a justification

00:50:43.380 --> 00:50:46.770
and show how you can
correct for that temperature

00:50:46.770 --> 00:50:49.630
difference between where
you would like the result

00:50:49.630 --> 00:50:51.780
and where you're
actually simulating.

00:50:51.780 --> 00:50:55.360
And so the idea of
TAD, as it's called,

00:50:55.360 --> 00:51:00.570
is to use the high temperature
to find the transitions,

00:51:00.570 --> 00:51:03.300
but then execute them
with the proper rate

00:51:03.300 --> 00:51:05.947
of the low temperature.

00:51:05.947 --> 00:51:07.780
So essentially, you run
at high temperature.

00:51:07.780 --> 00:51:11.770
So you fairly quickly scan
the potential surface.

00:51:11.770 --> 00:51:14.520
And that tells you what
the transitions are.

00:51:14.520 --> 00:51:16.830
And then you go back
to the low temperature,

00:51:16.830 --> 00:51:18.970
and you do a sort of
statistical mechanics,

00:51:18.970 --> 00:51:20.940
a kind of kinetic
Monte Carlo scheme

00:51:20.940 --> 00:51:25.650
or a transition state
theory approach and execute

00:51:25.650 --> 00:51:26.950
the transitions.

00:51:26.950 --> 00:51:29.907
So I'll show you an example.

00:51:29.907 --> 00:51:31.740
The idea is that you
run at high temperature

00:51:31.740 --> 00:51:33.660
until a transition occurs.

00:51:33.660 --> 00:51:35.790
Once you find the
transition, it's

00:51:35.790 --> 00:51:40.290
a trivial matter of finding
the activation barrier.

00:51:40.290 --> 00:51:42.960
Then you reverse the
transition, and you run again

00:51:42.960 --> 00:51:44.070
at high temperature.

00:51:44.070 --> 00:51:47.430
And the idea is that you get
this catalog of transitions.

00:51:47.430 --> 00:51:49.860
So you get this catalog
of possible transitions.

00:51:49.860 --> 00:51:52.780
Now, why do you need
more than one, you say?

00:51:52.780 --> 00:51:56.370
Well, the reason is that the
one you find at high temperature

00:51:56.370 --> 00:51:57.930
may not be the one
that actually gets

00:51:57.930 --> 00:51:59.850
executed at low temperature.

00:51:59.850 --> 00:52:02.310
If they have different
activation barriers,

00:52:02.310 --> 00:52:04.845
then their rates may
cross with temperature.

00:52:09.300 --> 00:52:10.830
Here's an example.

00:52:10.830 --> 00:52:17.130
If I show the crossing
rate versus 1 over t,

00:52:17.130 --> 00:52:19.860
let's say you run
at high temperature.

00:52:19.860 --> 00:52:23.770
If these behave Arrhenius,
then their crossing rate,

00:52:23.770 --> 00:52:26.550
which is 1 over the
time you have to wait,

00:52:26.550 --> 00:52:29.340
goes like 1 over t.

00:52:29.340 --> 00:52:32.820
You may find one that
has a high crossing rate

00:52:32.820 --> 00:52:38.420
at high temperature and this
one that has a lower crossing

00:52:38.420 --> 00:52:40.340
rate at high temperature.

00:52:40.340 --> 00:52:43.070
But if they have a different
activation barrier,

00:52:43.070 --> 00:52:45.440
they'll extrapolate differently
to lower temperature.

00:52:45.440 --> 00:52:49.820
But what you see
at low temperature,

00:52:49.820 --> 00:52:52.310
the one with the high
rate at high temperature

00:52:52.310 --> 00:52:55.690
has the lower rate
at low temperature.

00:52:55.690 --> 00:52:58.270
So because transitions have
different activation barriers,

00:52:58.270 --> 00:53:02.950
they may not be in the same
order, so the same frequency,

00:53:02.950 --> 00:53:05.620
the same rate at
different temperatures.

00:53:05.620 --> 00:53:07.930
And that's why you
need a catalog of them.

00:53:07.930 --> 00:53:16.140
You essentially need
a window of rates,

00:53:16.140 --> 00:53:19.230
of transmission rates, that
give you a certain certainty

00:53:19.230 --> 00:53:24.090
that at the lower temperature
you found the lowest one.

00:53:24.090 --> 00:53:27.060
And you can kind of do back
of the envelope calculations.

00:53:27.060 --> 00:53:31.950
If you make some assumptions
about the range in which

00:53:31.950 --> 00:53:34.800
your EAs, your activation
barrier, can vary,

00:53:34.800 --> 00:53:37.140
then you have the range of
slopes of these Arrhenius

00:53:37.140 --> 00:53:38.460
walls.

00:53:38.460 --> 00:53:40.500
So that can tell you a
little bit about how long

00:53:40.500 --> 00:53:44.520
you should be running
at the high temperature

00:53:44.520 --> 00:53:47.700
to make sure you found
all the transitions

00:53:47.700 --> 00:53:50.010
or are likely to have found
all the transitions that

00:53:50.010 --> 00:53:52.590
get executed at the
low temperature.

00:53:52.590 --> 00:53:54.510
So does everyone see the idea?

00:53:54.510 --> 00:53:58.920
You're essentially
using molecular dynamics

00:53:58.920 --> 00:54:02.350
as a way of finding transitions.

00:54:02.350 --> 00:54:04.350
And that's the hard problem
in any kinetic from.

00:54:04.350 --> 00:54:05.700
It's finding the transitions.

00:54:05.700 --> 00:54:08.490
Once you find them, you can
calculate their activation

00:54:08.490 --> 00:54:09.270
barrier.

00:54:09.270 --> 00:54:13.710
And you can execute them with
standard rate constant theory.

00:54:13.710 --> 00:54:14.700
But it's finding them.

00:54:14.700 --> 00:54:18.780
And MD, because it's unbiased,
is great at doing that.

00:54:26.270 --> 00:54:28.810
OK.

00:54:28.810 --> 00:54:32.200
So the approximations of the
method are fairly obvious.

00:54:32.200 --> 00:54:37.480
To do this extrapolation, you
assume harmonic transition

00:54:37.480 --> 00:54:38.330
state theory.

00:54:38.330 --> 00:54:40.780
So you essentially assume that
you have a simple Arrhenius

00:54:40.780 --> 00:54:43.180
extrapolation
between temperature,

00:54:43.180 --> 00:54:47.200
so that the exponential
factor is constant.

00:54:47.200 --> 00:54:50.230
And like I said before,
you have to make sure

00:54:50.230 --> 00:54:53.852
that you found all
the mechanisms,

00:54:53.852 --> 00:54:56.060
that you found enough
mechanisms at high temperature,

00:54:56.060 --> 00:55:00.370
so you definitely have the
fastest one at low temperature.

00:55:04.510 --> 00:55:05.500
OK.

00:55:05.500 --> 00:55:09.340
And here's another application
out of Art Voter's work.

00:55:09.340 --> 00:55:12.970
This is copper on
copper deposition.

00:55:12.970 --> 00:55:16.240
So they literally, I think,
add atoms to a surface

00:55:16.240 --> 00:55:18.910
and then equilibrate them.

00:55:18.910 --> 00:55:24.020
And they run-- so they do
direct MD for 2 picoseconds.

00:55:24.020 --> 00:55:28.120
That's how the deposit
the atom, but then run

00:55:28.120 --> 00:55:34.210
0.3 seconds of
intervening time with TAD.

00:55:34.210 --> 00:55:36.370
Now, you may think, 0.3
seconds, that's a lot.

00:55:36.370 --> 00:55:38.470
Well, it's not
because you're really

00:55:38.470 --> 00:55:40.780
doing transition state theory.

00:55:40.780 --> 00:55:46.900
If I have barriers of 1 electron
volt, then pretty much at room

00:55:46.900 --> 00:55:49.450
temperature 1
electron volt, that

00:55:49.450 --> 00:55:52.160
tends to give you rates
around 1 per second.

00:55:52.160 --> 00:55:53.718
That's kind of the time scale.

00:55:53.718 --> 00:55:55.510
So if you have barriers
of 1 electron volt,

00:55:55.510 --> 00:55:57.280
then every time
you execute a step,

00:55:57.280 --> 00:56:00.110
you're 1 second
further on average.

00:56:00.110 --> 00:56:03.940
So the 0.3 seconds, that
is not that impressive.

00:56:03.940 --> 00:56:06.250
You know, I can do 1,000
seconds with one step

00:56:06.250 --> 00:56:09.310
just by having a system at a
very high activation barrier.

00:56:13.790 --> 00:56:15.860
OK.

00:56:15.860 --> 00:56:19.190
You can look at the different
events in the simulation.

00:56:19.190 --> 00:56:23.090
And one of the nice things
is, because you're doing MD,

00:56:23.090 --> 00:56:25.490
your system is unbiased.

00:56:25.490 --> 00:56:28.130
And one thing we've
learned more and more

00:56:28.130 --> 00:56:33.800
by doing MD on surfaces is that
the diffusive processes are not

00:56:33.800 --> 00:56:36.380
at all the way people
thought they were.

00:56:36.380 --> 00:56:39.080
People think of atoms
hopping by themselves.

00:56:39.080 --> 00:56:41.720
But because surfaces
have so much open space,

00:56:41.720 --> 00:56:43.310
have such a low
symmetry, you see

00:56:43.310 --> 00:56:45.590
a lot of collective behavior.

00:56:45.590 --> 00:56:48.110
For example, here's one.

00:56:48.110 --> 00:56:54.470
This blue atom here
pushes in the surface,

00:56:54.470 --> 00:57:01.070
pushing that orange atom or
kind of-- what is it-- brown.

00:57:01.070 --> 00:57:03.470
And that pushes
then these two out.

00:57:03.470 --> 00:57:06.650
And that's all one
collective event.

00:57:06.650 --> 00:57:08.780
So these are not things
you would easily guess at.

00:57:11.555 --> 00:57:13.180
Here's another
collective event of sort

00:57:13.180 --> 00:57:18.820
of a kind of roll of atoms
three at a time at a step edge,

00:57:18.820 --> 00:57:20.320
essentially kind of moving down.

00:57:26.300 --> 00:57:28.190
OK.

00:57:28.190 --> 00:57:37.250
So you typically need MD
methods whenever you don't know

00:57:37.250 --> 00:57:39.770
or you're not absolutely
sure what the transmission

00:57:39.770 --> 00:57:41.720
mechanisms are.

00:57:41.720 --> 00:57:44.390
If you know what the
transmission mechanisms are,

00:57:44.390 --> 00:57:48.530
then it tends to be much more
efficient to do Monte Carlo.

00:57:48.530 --> 00:57:50.360
You can set up
kinetic Monte Carlo

00:57:50.360 --> 00:57:56.750
schemes that execute transitions
with the right transfer rate.

00:57:56.750 --> 00:57:59.480
It's just that you have to know
what those transitions are.

00:57:59.480 --> 00:58:03.020
So you've already done Monte
Carlo on lattice models,

00:58:03.020 --> 00:58:05.810
but we saw it as
a sampling method.

00:58:05.810 --> 00:58:08.490
You could also, now, see
it as a kinetic method.

00:58:08.490 --> 00:58:12.140
Let's say you have
a lattice of atoms.

00:58:12.140 --> 00:58:14.430
Let's make it easier
even, atoms and vacancies.

00:58:17.620 --> 00:58:20.950
So we've shown you how
to do the thermodynamics.

00:58:20.950 --> 00:58:24.310
Well, let's say you
want to study diffusion.

00:58:24.310 --> 00:58:27.910
If you know microscopically
how this atom would migrate

00:58:27.910 --> 00:58:31.220
to there, through which
path it would do that,

00:58:31.220 --> 00:58:34.340
then you just calculate
the energy along that path.

00:58:34.340 --> 00:58:38.260
And you can now do
a Monte Carlo where

00:58:38.260 --> 00:58:41.410
the way you travel
through phase space

00:58:41.410 --> 00:58:43.840
is by a real kinetic mechanism.

00:58:43.840 --> 00:58:44.740
OK.

00:58:44.740 --> 00:58:48.100
So you could now take
your exchange rate,

00:58:48.100 --> 00:58:50.582
dependent not only on
the energy of the initial

00:58:50.582 --> 00:58:52.540
and the final state,
which is the way we did it

00:58:52.540 --> 00:58:54.880
in a Metropolis
algorithm, but also

00:58:54.880 --> 00:58:57.160
have a prefactor
now that's kinetic.

00:58:57.160 --> 00:58:59.890
So that has a frequency
times an activation barrier.

00:58:59.890 --> 00:59:02.560
And that's essentially
kinetic Monte Carlo.

00:59:02.560 --> 00:59:03.430
OK.

00:59:03.430 --> 00:59:05.200
But you see, kinetic
Monte Carlo implies

00:59:05.200 --> 00:59:10.510
that you know what
your possible migration

00:59:10.510 --> 00:59:12.610
mechanisms are between states.

00:59:12.610 --> 00:59:16.990
And usually you know that
reasonably well in things

00:59:16.990 --> 00:59:18.130
like crystalline solids.

00:59:18.130 --> 00:59:20.890
So there kinetic Monte
Carlo is very applicable.

00:59:20.890 --> 00:59:23.200
People also use it on
surfaces even though it

00:59:23.200 --> 00:59:25.462
gets a little more dicey there.

00:59:25.462 --> 00:59:26.920
But once, of course,
you go to sort

00:59:26.920 --> 00:59:29.560
of very disordered
systems, it really

00:59:29.560 --> 00:59:32.240
gets way out of hand what
the kinetic mechanisms are.

00:59:32.240 --> 00:59:35.920
And this wouldn't work anymore.

00:59:35.920 --> 00:59:38.550
So I was going to show you
one example to sort of end up.

00:59:38.550 --> 00:59:40.838
And on the continuity,
I was going

00:59:40.838 --> 00:59:43.380
to take the same example that
we did for the phase stability.

00:59:43.380 --> 00:59:46.290
If you remember this when
we talked about the cluster

00:59:46.290 --> 00:59:48.600
expansion, we looked
at the phase diagram

00:59:48.600 --> 00:59:53.340
of lithium and lithium vacancies
and lithium cobalt oxide.

00:59:53.340 --> 00:59:56.910
So remember the issue is
that, if you take lithium out,

00:59:56.910 --> 00:59:58.500
you create vacancies there.

00:59:58.500 --> 01:00:01.050
And the issue was how
did they organize.

01:00:01.050 --> 01:00:03.630
And I showed you how to
use a cluster expansion

01:00:03.630 --> 01:00:06.810
to do the phase diagram,
the thermodynamics of that.

01:00:06.810 --> 01:00:09.860
Let's say you want to
worry about the kinetics.

01:00:09.860 --> 01:00:12.972
So essentially, how fast can
you get that lithium in and out?

01:00:12.972 --> 01:00:14.430
So you essentially
want a diffusion

01:00:14.430 --> 01:00:17.160
constant in that material.

01:00:17.160 --> 01:00:21.800
Well, this is fairly well-suited
for kinetic Monte Carlo rather

01:00:21.800 --> 01:00:22.800
than molecular dynamics.

01:00:22.800 --> 01:00:26.340
First of all, the
rates are fairly slow.

01:00:26.340 --> 01:00:29.480
So doing anything with
transition state theory

01:00:29.480 --> 01:00:32.020
is going to help you a lot.

01:00:32.020 --> 01:00:37.380
And you have transitions
between well-defined positions.

01:00:37.380 --> 01:00:39.510
The atoms go from
one well-defined site

01:00:39.510 --> 01:00:40.380
to another site.

01:00:44.920 --> 01:00:51.850
So if you had dilute
diffusion, you

01:00:51.850 --> 01:00:54.110
could just use
random walk theory.

01:00:54.110 --> 01:00:57.370
So in that case, diffusion
is sort of trivial.

01:00:57.370 --> 01:01:00.730
All you need is an activation
barrier and a prefactor.

01:01:00.730 --> 01:01:01.720
All the rest you know.

01:01:01.720 --> 01:01:03.520
You have the lattice
constant, which

01:01:03.520 --> 01:01:04.990
is actually the jump linked.

01:01:04.990 --> 01:01:07.180
And you have the geometric
correlation factor.

01:01:07.180 --> 01:01:08.920
These are all known.

01:01:08.920 --> 01:01:12.010
The things in green you
would have to calculate.

01:01:12.010 --> 01:01:14.080
But let's do calculation.

01:01:14.080 --> 01:01:17.770
Random walks only apply when
you have dilute diffusion.

01:01:17.770 --> 01:01:20.530
What I mean with
dilute diffusion--

01:01:20.530 --> 01:01:23.950
it's when the carrier of
diffusion is very dilute,

01:01:23.950 --> 01:01:28.070
so it doesn't
interact with itself.

01:01:28.070 --> 01:01:30.190
So if you have a
substitutional diffusion

01:01:30.190 --> 01:01:32.540
with very dilute
vacancy concentration,

01:01:32.540 --> 01:01:35.283
then this would apply.

01:01:35.283 --> 01:01:36.700
The problem, of
course, that we're

01:01:36.700 --> 01:01:38.658
going to look at the
lithium cobalt [INAUDIBLE]

01:01:38.658 --> 01:01:40.210
is by definition not dilute.

01:01:40.210 --> 01:01:41.680
You essentially
can go all the way

01:01:41.680 --> 01:01:46.150
from all lithium on the site
to all vacancies on the site.

01:01:46.150 --> 01:01:49.162
So you go to very
non-dilute regimes.

01:01:49.162 --> 01:01:51.370
If you want to do that, you
need to actually simulate

01:01:51.370 --> 01:01:53.950
the diffusion-- and you may
have even done that in the MD

01:01:53.950 --> 01:01:55.420
homework--

01:01:55.420 --> 01:01:58.240
by doing some kinetic
model and then tracking

01:01:58.240 --> 01:02:00.400
the root mean
square displacement.

01:02:00.400 --> 01:02:03.947
This is sort of a simple
form for the self-diffusion.

01:02:03.947 --> 01:02:05.530
The chemical diffusion
constant, which

01:02:05.530 --> 01:02:08.110
is the one you would use
in macroscopic theories,

01:02:08.110 --> 01:02:12.040
is the self-diffusion times
the thermodynamic factor.

01:02:12.040 --> 01:02:15.575
But the thermodynamic factor
is essentially the derivative

01:02:15.575 --> 01:02:17.450
of the chemical potential
of the composition,

01:02:17.450 --> 01:02:21.108
so that you already have from
the thermodynamic calculation.

01:02:25.500 --> 01:02:27.072
OK.

01:02:27.072 --> 01:02:29.280
So I have a few more slides
here that I already used,

01:02:29.280 --> 01:02:31.260
so I'm going to
[INAUDIBLE] through them.

01:02:31.260 --> 01:02:33.180
You remember how we
did the thermodynamics?

01:02:33.180 --> 01:02:35.370
We built a lattice model.

01:02:35.370 --> 01:02:37.560
We calculate a lot of
lithium vacancy arrangement,

01:02:37.560 --> 01:02:40.020
build a cluster expansion,
and do Monte Carlo on that.

01:02:40.020 --> 01:02:43.820
And that gives you
the phase diagram.

01:02:43.820 --> 01:02:45.620
Let me skip that since
we did that already.

01:02:45.620 --> 01:02:46.820
Those are the interactions.

01:02:46.820 --> 01:02:49.550
OK.

01:02:49.550 --> 01:02:51.380
How would you do
kinetic Monte Carlo?

01:02:51.380 --> 01:02:53.180
I sort of also mentioned that.

01:02:53.180 --> 01:02:58.100
You would now execute all the
exchanges in the Monte Carlo

01:02:58.100 --> 01:03:00.230
that look like
diffusive processes.

01:03:00.230 --> 01:03:04.170
And you would execute
them with the proper rate.

01:03:04.170 --> 01:03:07.650
So you would have an
activation barrier in there.

01:03:10.640 --> 01:03:12.040
OK.

01:03:12.040 --> 01:03:13.520
I think I said all this.

01:03:13.520 --> 01:03:15.220
OK.

01:03:15.220 --> 01:03:20.180
So here's an example
of how that works out.

01:03:20.180 --> 01:03:22.670
If you calculate barriers
in lithium cobalt oxide

01:03:22.670 --> 01:03:24.830
and you then do a kinetic
Monte Carlo simulation,

01:03:24.830 --> 01:03:27.680
you keep track of the root
mean square displacement.

01:03:27.680 --> 01:03:30.500
You get the macroscopic
diffusivity.

01:03:30.500 --> 01:03:34.940
And as you see, it varies
by orders of magnitude.

01:03:34.940 --> 01:03:38.940
It's 10 to the minus 7 here
centimeters squared per second.

01:03:38.940 --> 01:03:42.173
And it's 10 to
the minus 13 here.

01:03:42.173 --> 01:03:43.840
You can already see
that you would never

01:03:43.840 --> 01:03:48.820
get to all these time scales
with a simple dynamics model.

01:03:54.920 --> 01:03:56.690
OK.

01:03:56.690 --> 01:04:00.830
How you get
activation barriers--

01:04:00.830 --> 01:04:02.270
typically, we get
this with what's

01:04:02.270 --> 01:04:06.590
called a nudge
elastic band model.

01:04:06.590 --> 01:04:10.980
You know, what's the issue in
finding activation barrier?

01:04:10.980 --> 01:04:12.800
Well, you know
the initial state,

01:04:12.800 --> 01:04:14.600
and you know the final state.

01:04:14.600 --> 01:04:16.760
This is not necessarily
the state of an atom.

01:04:16.760 --> 01:04:20.330
You really should think of these
as two states in phase space.

01:04:20.330 --> 01:04:23.030
Now, for simplicity,
you can think, well,

01:04:23.030 --> 01:04:26.090
only one atom moves, is
different, between those two

01:04:26.090 --> 01:04:26.810
states.

01:04:26.810 --> 01:04:28.520
But in reality, more
stuff is different.

01:04:28.520 --> 01:04:30.950
Because if the atom has
moved, the other atoms

01:04:30.950 --> 01:04:32.930
may have relaxed around it.

01:04:32.930 --> 01:04:36.300
So these are really
states in phase space.

01:04:36.300 --> 01:04:40.220
So what you have to find
is the path between the two

01:04:40.220 --> 01:04:44.240
with the lowest energy
maximum along that path.

01:04:44.240 --> 01:04:46.820
That's essentially
the activated state.

01:04:46.820 --> 01:04:48.950
And a very practical
way to find is

01:04:48.950 --> 01:04:51.290
what's called a nudged
elastic band model, which

01:04:51.290 --> 01:04:56.270
is essentially that you do
a simulation on many systems

01:04:56.270 --> 01:04:57.890
at a time.

01:04:57.890 --> 01:05:01.280
And all the systems live
at intermediate states

01:05:01.280 --> 01:05:04.970
between the final state
and the initial state.

01:05:04.970 --> 01:05:08.570
And the way you keep them
there is interesting.

01:05:08.570 --> 01:05:13.310
Rather than optimizing the
energy of each system, what

01:05:13.310 --> 01:05:17.060
you optimize is the
sum of their energies,

01:05:17.060 --> 01:05:20.120
the sum of their
Hamiltonian values,

01:05:20.120 --> 01:05:25.460
plus some spring constant,
basically plus some energy

01:05:25.460 --> 01:05:29.660
penalty, which is associated
with the difference in

01:05:29.660 --> 01:05:31.980
coordinates between
the two systems.

01:05:31.980 --> 01:05:34.880
And what that tends
to do is actually,

01:05:34.880 --> 01:05:38.090
since this is a quadratic in
the difference in corniness,

01:05:38.090 --> 01:05:42.730
it tends to spread out
the systems along the path

01:05:42.730 --> 01:05:44.027
between the two states.

01:05:44.027 --> 01:05:44.860
I mean, think of it.

01:05:44.860 --> 01:05:49.090
If I got rid of this,
so if I set k to 0,

01:05:49.090 --> 01:05:52.030
then I'm going to minimize this.

01:05:52.030 --> 01:05:54.968
So they're all going
to go down here.

01:05:54.968 --> 01:05:57.010
But what do you actually
do is you hold one here.

01:05:57.010 --> 01:05:59.170
You hold one there.

01:05:59.170 --> 01:06:02.020
And then because of the
harmonic potential between them,

01:06:02.020 --> 01:06:04.430
you tend to end up with
systems that live in between.

01:06:04.430 --> 01:06:08.710
So it's a very elegant way
of finding minimum energy

01:06:08.710 --> 01:06:11.050
paths between states.

01:06:11.050 --> 01:06:12.640
It's called the
elastic band method

01:06:12.640 --> 01:06:14.310
or the nudged
elastic band method.

01:06:14.310 --> 01:06:18.730
And there's a whole bunch
of variants of it as well.

01:06:18.730 --> 01:06:20.630
It's the perfect
parallelization.

01:06:20.630 --> 01:06:21.505
You may have noticed.

01:06:24.280 --> 01:06:26.270
If you want to do,
say, 10 replicas--

01:06:26.270 --> 01:06:28.360
so you want to do 10
points along the path--

01:06:28.360 --> 01:06:30.280
you run on 10 processors.

01:06:30.280 --> 01:06:32.650
Because it's the same
system, they pretty much

01:06:32.650 --> 01:06:35.590
run about the same
amount of time.

01:06:35.590 --> 01:06:37.760
They never have to
talk to each other.

01:06:37.760 --> 01:06:40.510
They have to talk to each other
on extremely rare occasion

01:06:40.510 --> 01:06:42.030
when they exchange coordinates.

01:06:42.030 --> 01:06:43.180
That's it.

01:06:43.180 --> 01:06:45.360
So it's a perfect
parallelization tool.

01:06:49.850 --> 01:06:54.110
If you do that in lithium cobalt
oxide, you have a complication.

01:06:54.110 --> 01:06:56.600
Just to show you how the data
for that kinetic Monte Carlo

01:06:56.600 --> 01:07:03.740
simulation was derived, the
yellow is the lithium here.

01:07:03.740 --> 01:07:07.130
These are oxygens,
the big red balls.

01:07:07.130 --> 01:07:09.680
The way you can diffuse
from this side to that side

01:07:09.680 --> 01:07:11.330
is straight through
the oxygen bond.

01:07:11.330 --> 01:07:14.780
And if you do that,
this is obtained

01:07:14.780 --> 01:07:16.080
by elastic band method.

01:07:16.080 --> 01:07:17.970
So these are the replicas.

01:07:17.970 --> 01:07:19.640
So this is initial stage.

01:07:19.640 --> 01:07:22.100
This is the final state.

01:07:22.100 --> 01:07:29.530
And so you get an activation
barrier of about 0.85.

01:07:29.530 --> 01:07:34.360
So it's very nice how you
get these activation curves.

01:07:34.360 --> 01:07:36.980
But the problem is that there's
two paths in this material.

01:07:36.980 --> 01:07:40.330
So already you're starting to
run into a particular problem

01:07:40.330 --> 01:07:42.010
of kinetic Monte Carlo.

01:07:42.010 --> 01:07:44.300
Let's say you thought
that was the path.

01:07:44.300 --> 01:07:48.610
Well, you'd be very wrong
because there's another path.

01:07:48.610 --> 01:07:50.680
And that's one when the
outcome actually, rather

01:07:50.680 --> 01:07:52.840
than going straight
through this bond,

01:07:52.840 --> 01:07:57.820
it takes a curve into this
tetrahedron and comes back out.

01:07:57.820 --> 01:08:00.700
And that's actually a path,
if you do elastic band, that

01:08:00.700 --> 01:08:02.360
is so much lower.

01:08:02.360 --> 01:08:05.590
It's only about 200
millielectron volts.

01:08:05.590 --> 01:08:07.780
And it sort of shows
the real problem

01:08:07.780 --> 01:08:11.650
you can run into that, when
you do kinetic Monte Carlo,

01:08:11.650 --> 01:08:16.149
you have to assume what your
paths are for transitions.

01:08:16.149 --> 01:08:19.029
And if you don't get them right,
you can be seriously wrong.

01:08:19.029 --> 01:08:20.740
And that's one of the
nice things of MD,

01:08:20.740 --> 01:08:21.580
that it's unbiased.

01:08:21.580 --> 01:08:24.710
So it would find
these things for you.

01:08:24.710 --> 01:08:26.678
But these are actually
the only two paths.

01:08:26.678 --> 01:08:28.720
And of course, because of
the activation barrier,

01:08:28.720 --> 01:08:30.319
this is so much lower.

01:08:30.319 --> 01:08:32.770
This is pretty much the one
that gets executed almost

01:08:32.770 --> 01:08:34.100
all the time.

01:08:34.100 --> 01:08:37.135
The difference between 0.2
electron volts and 0.8 electron

01:08:37.135 --> 01:08:40.060
volts at room
temperature is amazing.

01:08:40.060 --> 01:08:44.870
It's, I think, 5, 6 orders of
magnitude in rate constant.

01:08:44.870 --> 01:08:48.220
You just have to calculate the
exponential of each of these.

01:08:51.300 --> 01:08:53.790
One of the problems you have
whenever you have two rate

01:08:53.790 --> 01:08:58.500
constants is that, when
you do your Monte Carlo,

01:08:58.500 --> 01:09:01.819
you can only scale
the fastest one away.

01:09:01.819 --> 01:09:03.800
So you have essentially
one scale factor

01:09:03.800 --> 01:09:06.090
in the time of your
Monte Carlo simulation.

01:09:06.090 --> 01:09:09.890
So when you do multiple
time scales, when

01:09:09.890 --> 01:09:11.390
you have multiple
time scales, it

01:09:11.390 --> 01:09:15.990
gets very inefficient to
do kinetic Monte Carlo.

01:09:15.990 --> 01:09:16.770
But this works.

01:09:16.770 --> 01:09:20.010
You can get diffusion constants.

01:09:20.010 --> 01:09:24.340
This is with
elastic band method.

01:09:24.340 --> 01:09:27.300
This is the activation barrier
for that low energy mechanism

01:09:27.300 --> 01:09:29.319
as a function of
lithium concentration,

01:09:29.319 --> 01:09:31.779
so very dependent
on concentration.

01:09:31.779 --> 01:09:34.050
So you can do your
kinetic Monte Carlo.

01:09:34.050 --> 01:09:36.569
And then you have these,
and you can go all the way

01:09:36.569 --> 01:09:38.520
to macroscopic stimulation.

01:09:38.520 --> 01:09:40.109
Then you can solve
a fixed equation

01:09:40.109 --> 01:09:44.340
and actually look at diffusion
on the scale of microns.

01:09:44.340 --> 01:09:47.399
So it's a fairly simplistic
way of course graining.

01:09:50.399 --> 01:09:51.240
OK.

01:09:51.240 --> 01:09:54.330
So I'm going to end just
giving you some reference.

01:09:54.330 --> 01:09:57.150
If you want to read more about
the quasi-continuum method,

01:09:57.150 --> 01:10:00.420
there's these great papers
by Miller and Tadmor.

01:10:00.420 --> 01:10:02.010
These are actually
somewhat similar,

01:10:02.010 --> 01:10:05.123
but the 202 version
is an update.

01:10:05.123 --> 01:10:06.540
These are not the
original papers,

01:10:06.540 --> 01:10:09.270
but they're actually
sometimes more pedagogical

01:10:09.270 --> 01:10:10.855
than the original papers.

01:10:10.855 --> 01:10:12.480
But you'll find the
references in there

01:10:12.480 --> 01:10:14.550
to the original papers.

01:10:14.550 --> 01:10:20.370
The problem of sort of dynamics
at that scale is my own work.

01:10:20.370 --> 01:10:24.120
The accelerated MD, there's a
series of papers by Art Voter.

01:10:24.120 --> 01:10:27.090
But this annual review
of materials research

01:10:27.090 --> 01:10:30.540
is, I think, a great review
if you want to read about it.

01:10:30.540 --> 01:10:34.800
And the lithium cobalt
application is in a few papers,

01:10:34.800 --> 01:10:36.150
but it's quite elaborate.

01:10:36.150 --> 01:10:37.860
The whole idea of
kinetic Monte Carlo

01:10:37.860 --> 01:10:40.060
and parameterizing
activation barriers

01:10:40.060 --> 01:10:43.390
is quite elaborately
discussed in this paper.

01:10:43.390 --> 01:10:46.360
So I think we're done a
little early, but that's fine.

01:10:46.360 --> 01:10:47.610
So I'm going to end here.

01:10:47.610 --> 01:10:52.490
And I'll see you on Thursday
for the lecture from Ford.