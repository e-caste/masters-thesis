WEBVTT

00:00:00.000 --> 00:00:03.860
GERBRAND CEDER: So what I
want to do today is finish up

00:00:03.860 --> 00:00:10.850
Monte Carlo simulation and go
into a little more advanced

00:00:10.850 --> 00:00:13.250
things in Monte Carlo
simulation and then

00:00:13.250 --> 00:00:16.100
also go into free
energy integrations

00:00:16.100 --> 00:00:17.860
and other
coarse-graining methods

00:00:17.860 --> 00:00:20.210
so when direct
simulation won't work.

00:00:25.700 --> 00:00:28.070
If you remember, I
introduced Monte Carlo

00:00:28.070 --> 00:00:30.230
simulation as a way
of importance sampling

00:00:30.230 --> 00:00:32.607
and contrasted it
against simple sampling.

00:00:32.607 --> 00:00:34.190
What I want to show
you today, there's

00:00:34.190 --> 00:00:37.100
actually quite a few things in
between that, in some cases,

00:00:37.100 --> 00:00:38.270
can be practical.

00:00:38.270 --> 00:00:40.520
Remember the idea
of simple sampling

00:00:40.520 --> 00:00:44.270
is that you sample
randomly and then

00:00:44.270 --> 00:00:47.120
you weigh with a
probability that's

00:00:47.120 --> 00:00:50.180
correct relatively,
where the states have

00:00:50.180 --> 00:00:53.120
their correct relative
probability to one another.

00:00:53.120 --> 00:00:56.150
Importance sampling is sampling
with the correct probability

00:00:56.150 --> 00:01:01.010
and then just averaging
the quantity you sample,

00:01:01.010 --> 00:01:04.980
but you can actually sample
with things in between.

00:01:04.980 --> 00:01:09.920
So here you're sampling with
a probability proportional

00:01:09.920 --> 00:01:14.150
to that exponential
of that Hamiltonian.

00:01:14.150 --> 00:01:16.160
Here you're sampling
with no Hamiltonian

00:01:16.160 --> 00:01:19.550
and therefore, you have to
correct the probability later.

00:01:19.550 --> 00:01:23.210
You can sample with any
Hamiltonian H0, which is not

00:01:23.210 --> 00:01:25.520
the true Hamiltonian
of your system,

00:01:25.520 --> 00:01:28.380
and then correct for it
in the probabilities.

00:01:28.380 --> 00:01:35.550
So if you sample with H0,
then the states you sample

00:01:35.550 --> 00:01:37.920
have to be corrected with
the relative probability

00:01:37.920 --> 00:01:41.270
of that state, the
relative probability

00:01:41.270 --> 00:01:44.220
that you would get with the
correct Hamiltonian versus what

00:01:44.220 --> 00:01:47.670
you get with the Hamiltonian
which you decided to sample.

00:01:47.670 --> 00:01:48.600
OK?

00:01:48.600 --> 00:01:50.880
So this is the Hamiltonian
which we decided to pick,

00:01:50.880 --> 00:01:53.230
the states that
go in your sample,

00:01:53.230 --> 00:01:55.420
and then this is the
probability correction.

00:01:55.420 --> 00:01:55.920
Sorry.

00:02:02.350 --> 00:02:04.630
And so whenever you
sample with what's

00:02:04.630 --> 00:02:07.150
not the proper Hamiltonian
of your system,

00:02:07.150 --> 00:02:08.965
people call it
non-Boltzmann sampling.

00:02:15.290 --> 00:02:18.860
Why would you want to do
non-Boltzmann sampling?

00:02:18.860 --> 00:02:24.810
Well, it can be relevant if
the particular quantity you're

00:02:24.810 --> 00:02:28.290
after in your system
is essentially not

00:02:28.290 --> 00:02:31.410
determined by the relevant
thermodynamics states.

00:02:31.410 --> 00:02:35.340
Remember, I introduced
this by say,

00:02:35.340 --> 00:02:39.030
what if you're looking
at, say, average energy

00:02:39.030 --> 00:02:41.705
or average volume or
average magnetization,

00:02:41.705 --> 00:02:43.080
then what you
really need to know

00:02:43.080 --> 00:02:46.500
is what's the
energy of the states

00:02:46.500 --> 00:02:49.470
that the system spent
most of its time in?

00:02:49.470 --> 00:02:52.740
But what if a system
spends only a small amount

00:02:52.740 --> 00:02:54.720
of its time in certain
states, but those

00:02:54.720 --> 00:02:57.780
have the relevant property
that you want to sample?

00:02:57.780 --> 00:03:03.840
For example, let's say that
this is a phase space, this

00:03:03.840 --> 00:03:04.920
[INAUDIBLE].

00:03:04.920 --> 00:03:06.990
So with importance
sampling, you'd

00:03:06.990 --> 00:03:09.170
be drawn towards these states.

00:03:09.170 --> 00:03:09.870
OK?

00:03:09.870 --> 00:03:12.270
I don't know, maybe
the ones that live here

00:03:12.270 --> 00:03:14.760
are optically
active or something

00:03:14.760 --> 00:03:16.770
like that and the other
ones aren't and you

00:03:16.770 --> 00:03:19.410
want to somehow get
a lot of information

00:03:19.410 --> 00:03:21.630
of the optical activity
of the material,

00:03:21.630 --> 00:03:24.570
you may want to build a
Hamiltonian that drives you

00:03:24.570 --> 00:03:26.540
towards these states.

00:03:26.540 --> 00:03:27.210
OK?

00:03:27.210 --> 00:03:30.240
And as long as you then correct
for the proper probability,

00:03:30.240 --> 00:03:32.610
you'll get a proper ensemble.

00:03:32.610 --> 00:03:35.970
It's one that's just much
more efficiently biased

00:03:35.970 --> 00:03:38.700
towards the regional phase
space where you want to get.

00:03:38.700 --> 00:03:41.440
So that's
non-Boltzmann sampling.

00:03:41.440 --> 00:03:45.810
Another obvious way is you can
use it to sample phase space

00:03:45.810 --> 00:03:48.250
more efficiently.

00:03:48.250 --> 00:03:56.280
If you had a phase base
with a lot of local minima,

00:03:56.280 --> 00:04:01.260
you may want to define
a new Hamiltonian that

00:04:01.260 --> 00:04:02.070
looks like this.

00:04:07.120 --> 00:04:09.550
And this is especially relevant
if your Monte Carlo has

00:04:09.550 --> 00:04:11.290
some form of dynamics in it.

00:04:11.290 --> 00:04:14.230
So in the blue Hamiltonian,
the true Hamiltonian,

00:04:14.230 --> 00:04:16.540
it may be very hard to
get out of this minimum

00:04:16.540 --> 00:04:18.190
into the next one.

00:04:18.190 --> 00:04:20.649
Whereas if you raise
the potential well,

00:04:20.649 --> 00:04:23.320
OK, in the red
Hamiltonian it's going

00:04:23.320 --> 00:04:26.140
to be much easier
to get out of it.

00:04:26.140 --> 00:04:26.680
OK?

00:04:26.680 --> 00:04:30.280
So essentially your
flattening your phase space

00:04:30.280 --> 00:04:31.870
with the new
Hamiltonian, so it's

00:04:31.870 --> 00:04:34.570
going to be much easier
to get out of local minima

00:04:34.570 --> 00:04:37.640
and then you can correct
for that probability.

00:04:37.640 --> 00:04:42.280
There's a lot of algorithms
these days built on this idea,

00:04:42.280 --> 00:04:44.860
not just in Monte
Carlo, but there

00:04:44.860 --> 00:04:46.815
are molecular dynamic
schemes, there

00:04:46.815 --> 00:04:48.190
are all kinds of
schemes that are

00:04:48.190 --> 00:04:52.420
built on this idea of lifting
up the potential wells

00:04:52.420 --> 00:04:55.060
and then correcting the
relative probability

00:04:55.060 --> 00:04:57.610
or the relative
vibrational frequency

00:04:57.610 --> 00:05:00.700
or the relative time you
spend in each potential well.

00:05:07.060 --> 00:05:09.380
OK.

00:05:09.380 --> 00:05:11.840
You can also do
non-Metropolis Monte Carlo.

00:05:11.840 --> 00:05:14.330
This gets even a
little more odd.

00:05:14.330 --> 00:05:21.200
Remember that we defined an
acceptable Metropolis as one

00:05:21.200 --> 00:05:25.280
where the a priori
probabilities were equal.

00:05:28.150 --> 00:05:30.160
So basically in
the Markov chain,

00:05:30.160 --> 00:05:33.940
the rate at which I pick
the i state from the j one

00:05:33.940 --> 00:05:37.982
as a potential next step in
the Markov chain is symmetric.

00:05:37.982 --> 00:05:39.940
It's the same as the rate
at which I pick the j

00:05:39.940 --> 00:05:41.365
state from the i state.

00:05:41.365 --> 00:05:44.290
j to i and i to j is the same.

00:05:44.290 --> 00:05:46.970
You don't necessarily
have to do that.

00:05:46.970 --> 00:05:50.040
You can actually
make these rates--

00:05:50.040 --> 00:05:52.300
so these are the picking
rates, the rates at which I

00:05:52.300 --> 00:05:56.890
try one state from the other,
non-symmetric, and even more,

00:05:56.890 --> 00:06:01.030
you can make them dependent
on the Hamiltonian.

00:06:01.030 --> 00:06:02.560
And why would you
want to do that?

00:06:02.560 --> 00:06:04.300
I'll show you an
example in a second.

00:06:04.300 --> 00:06:07.570
It's a way of forcing systems
downhill in energy space

00:06:07.570 --> 00:06:09.740
much faster.

00:06:09.740 --> 00:06:14.110
So as long as you're correct in
your detailed balance argument,

00:06:14.110 --> 00:06:15.250
you'll be OK.

00:06:15.250 --> 00:06:18.670
So the important thing is
the detailed balance criteria

00:06:18.670 --> 00:06:21.730
because the detailed balance
criteria is the one that

00:06:21.730 --> 00:06:26.033
ultimately ensures that
you sample phase space

00:06:26.033 --> 00:06:27.700
or that you weigh
states and phase space

00:06:27.700 --> 00:06:29.620
with the correct probability.

00:06:29.620 --> 00:06:31.790
And so as long as
you correct here--

00:06:31.790 --> 00:06:37.270
so if you changed
the W0, you can still

00:06:37.270 --> 00:06:40.480
get satisfied detail balanced
by essentially changing

00:06:40.480 --> 00:06:42.760
what the acceptance rates are.

00:06:42.760 --> 00:06:46.420
PI to J and PJ to I. You
can write out what they are.

00:06:46.420 --> 00:06:50.440
Essentially the
ratio of PIJ to PJI

00:06:50.440 --> 00:06:55.330
is the factor we had
before, but now you

00:06:55.330 --> 00:06:58.540
correct by the relative
weight, which we

00:06:58.540 --> 00:07:00.050
did the picking of the states.

00:07:00.050 --> 00:07:00.550
OK?

00:07:00.550 --> 00:07:04.227
So in the end it's a
fairly trivial correction.

00:07:09.840 --> 00:07:13.380
I haven't seen too many examples
of this, but one is this one.

00:07:13.380 --> 00:07:15.720
It's force-bias
Monte Carlo, which

00:07:15.720 --> 00:07:18.157
almost looks like a
hybrid between Monte

00:07:18.157 --> 00:07:19.365
Carlo and molecular dynamics.

00:07:23.993 --> 00:07:26.660
You know, I've given you several
times this example of a liquid.

00:07:26.660 --> 00:07:30.190
How would you sample a liquid?

00:07:30.190 --> 00:07:32.980
In Monte Carlo, you just could
pick random displacements

00:07:32.980 --> 00:07:34.435
of an atom within a given range.

00:07:38.020 --> 00:07:41.500
One way to actually drive
the system to low energy

00:07:41.500 --> 00:07:45.430
faster is not take a random
displacement of the atoms,

00:07:45.430 --> 00:07:49.260
but take one that's biased
along the force on that atom.

00:07:49.260 --> 00:07:50.950
If you move an atom
down with force,

00:07:50.950 --> 00:07:54.370
you're obviously going to
lower the energy mathematically

00:07:54.370 --> 00:07:57.400
because the force is the
gradient of the energy.

00:07:57.400 --> 00:08:03.150
So you could take a
displacement factor

00:08:03.150 --> 00:08:06.930
that has a random component and
that has some component that

00:08:06.930 --> 00:08:09.720
depends on the force.

00:08:09.720 --> 00:08:14.060
Actually if you
only do this, that's

00:08:14.060 --> 00:08:18.492
actually how a lot of static
relaxation schemes work.

00:08:18.492 --> 00:08:20.200
For example, in density
functional theory

00:08:20.200 --> 00:08:21.980
you calculate the
forces on atoms

00:08:21.980 --> 00:08:25.160
and then you relax them assuming
a certain spring constant

00:08:25.160 --> 00:08:26.930
typically.

00:08:26.930 --> 00:08:29.720
But because you still
have a random element,

00:08:29.720 --> 00:08:34.130
this is probably somewhat better
described as mixed dynamics

00:08:34.130 --> 00:08:36.027
Monte Carlo methods.

00:08:36.027 --> 00:08:37.860
And if you would like
to read more about it,

00:08:37.860 --> 00:08:39.527
I think this was one
of the first papers

00:08:39.527 --> 00:08:41.600
that kind of introduced them.

00:08:46.100 --> 00:08:49.700
So what I want to do is a
couple more case studies

00:08:49.700 --> 00:08:53.060
and then show you some
of the complications that

00:08:53.060 --> 00:08:56.450
can arise when you do difficult
systems with Monte Carlo

00:08:56.450 --> 00:08:59.750
and see how we solve
them, and that'll lead us

00:08:59.750 --> 00:09:02.660
into free energy integration.

00:09:02.660 --> 00:09:05.990
So this is sort of
a classic paper on--

00:09:05.990 --> 00:09:09.530
it's from 1985-- using
Monte Carlo to study surface

00:09:09.530 --> 00:09:12.140
segregation in copper nickel.

00:09:12.140 --> 00:09:14.872
It uses the embedded atom
method as a potential so,

00:09:14.872 --> 00:09:16.580
one of the reasons I
picked it because it

00:09:16.580 --> 00:09:19.950
integrates a lot of the
things you've seen in class.

00:09:19.950 --> 00:09:23.660
So the idea was to take
random copper nickel alloys

00:09:23.660 --> 00:09:26.540
and see which element
segregates to the surface

00:09:26.540 --> 00:09:30.227
and then see how the segregation
pattern away from the surface

00:09:30.227 --> 00:09:32.060
is, because there's
been a lot of discussion

00:09:32.060 --> 00:09:36.570
about that in the literature,
especially around that time.

00:09:36.570 --> 00:09:40.520
So what they do is they set up,
just like you would probably,

00:09:40.520 --> 00:09:43.190
supercells.

00:09:43.190 --> 00:09:52.700
So I think they either
had 24 or 24 or 48 layers,

00:09:52.700 --> 00:09:55.070
and then with a certain width.

00:09:55.070 --> 00:09:56.990
So here's your supercell.

00:09:59.870 --> 00:10:04.560
Again, you can define your
Hamiltonian multiple ways.

00:10:04.560 --> 00:10:08.090
You could just seed the system
with a particular concentration

00:10:08.090 --> 00:10:11.030
and then you have to decide
which kind of Monte Carlo

00:10:11.030 --> 00:10:13.580
moves to allow.

00:10:13.580 --> 00:10:16.980
A copper nickel form
[INAUDIBLE] solid solutions.

00:10:16.980 --> 00:10:18.590
So what kind of
moves would you do

00:10:18.590 --> 00:10:23.620
to equilibrate the system if
you had to set this up yourself?

00:10:30.770 --> 00:10:34.240
So again, essentially you
would seed the system, probably

00:10:34.240 --> 00:10:41.500
with some concentration
of copper and nickel

00:10:41.500 --> 00:10:43.740
except that there's
a lot more atoms.

00:10:43.740 --> 00:10:46.830
So how would you do a
Monte Carlo on this?

00:10:46.830 --> 00:10:49.550
Remember that you're going
to have an embedded atom

00:10:49.550 --> 00:10:51.440
Hamiltonian
essentially, so it's one

00:10:51.440 --> 00:10:53.680
that you can fairly
rapidly evaluate.

00:10:53.680 --> 00:10:56.630
So in the end, it's a very
simple energy function.

00:10:56.630 --> 00:10:59.450
It's a bunch of
pairwise sums and then

00:10:59.450 --> 00:11:02.550
you just stick the result in
a function and you're done.

00:11:02.550 --> 00:11:04.460
It's not like quantum mechanics.

00:11:04.460 --> 00:11:07.395
You have, essentially, a
Hamiltonian you can abuse,

00:11:07.395 --> 00:11:09.890
so it's important to realize.

00:11:09.890 --> 00:11:11.580
So how would you do
Monte Carlo on this?

00:11:18.262 --> 00:11:19.220
This is the one thing--

00:11:19.220 --> 00:11:21.980
Monte Carlo is about
choosing your perturbations,

00:11:21.980 --> 00:11:25.710
the rest is automatic
after that essentially.

00:11:25.710 --> 00:11:29.213
It's just doing
it a lot of times.

00:11:29.213 --> 00:11:30.880
So how would you
equilibrate the system?

00:11:36.208 --> 00:11:38.750
It's too early in the morning,
you're all still equilibrated.

00:11:44.140 --> 00:11:47.320
So first of all, you need
to segregate some species

00:11:47.320 --> 00:11:49.730
to the surface assuming
there will be segregation.

00:11:49.730 --> 00:11:51.980
So how do you do that?

00:11:51.980 --> 00:11:55.810
Again, you could
do diffusive hops.

00:11:55.810 --> 00:12:00.590
Diffusive like hops, so do
canonical like interchanges.

00:12:00.590 --> 00:12:03.400
You could interchange
them nearby

00:12:03.400 --> 00:12:05.770
or you could interchange
them far away.

00:12:05.770 --> 00:12:07.990
I got to stick to
my colors here.

00:12:07.990 --> 00:12:11.920
So you could interchange
positions of copper and nickel,

00:12:11.920 --> 00:12:14.170
but again, the slightly
faster way to do it

00:12:14.170 --> 00:12:17.030
is to do it grand canonically,
to define actually

00:12:17.030 --> 00:12:25.780
a Hamiltonian that's the energy
minus mu copper, n copper

00:12:25.780 --> 00:12:31.130
minus from mu nickel, n nickel.

00:12:31.130 --> 00:12:31.940
OK?

00:12:31.940 --> 00:12:35.150
And since you're actually
going to be interchanging

00:12:35.150 --> 00:12:40.520
the identity of atoms,
n copper and n nickel

00:12:40.520 --> 00:12:42.320
are not independent variables.

00:12:42.320 --> 00:12:46.650
You keep total number
of atoms constant.

00:12:46.650 --> 00:12:52.410
So you can actually write this
as E minus mu copper minus mu

00:12:52.410 --> 00:12:57.830
nickle times n copper,
since any change of a nickel

00:12:57.830 --> 00:13:00.140
is compensated by
a change of copper.

00:13:00.140 --> 00:13:02.990
So we have essentially only one
controlling chemical potential,

00:13:02.990 --> 00:13:06.140
which is the difference of
the two species chemical

00:13:06.140 --> 00:13:07.170
potentials.

00:13:07.170 --> 00:13:08.090
OK.

00:13:08.090 --> 00:13:09.058
Yes, sir?

00:13:09.058 --> 00:13:11.498
AUDIENCE: If a [INAUDIBLE]
in a specific ratio, nickel

00:13:11.498 --> 00:13:14.015
or copper, [INAUDIBLE] very
long to find the correct value

00:13:14.015 --> 00:13:15.131
of [INAUDIBLE]?

00:13:19.280 --> 00:13:21.240
GERBRAND CEDER: Yes.

00:13:21.240 --> 00:13:23.490
AUDIENCE: [INAUDIBLE]

00:13:23.490 --> 00:13:24.570
GERBRAND CEDER: Yes.

00:13:24.570 --> 00:13:30.920
Yes, so you're controlling the
external chemical potential,

00:13:30.920 --> 00:13:32.770
so you don't control
the composition.

00:13:32.770 --> 00:13:33.270
True.

00:13:36.135 --> 00:13:39.900
What people sometimes
do is that--

00:13:39.900 --> 00:13:45.150
what's of interest to you is the
bulk chemical potential, that's

00:13:45.150 --> 00:13:47.250
the source for the surface.

00:13:47.250 --> 00:13:49.500
You first do bulk
simulations and then

00:13:49.500 --> 00:13:52.710
you roughly know what
chemical potential corresponds

00:13:52.710 --> 00:13:57.540
to what compositions, because
it's actually a little tricky.

00:13:57.540 --> 00:14:00.990
While energetically often,
the center of the system

00:14:00.990 --> 00:14:02.610
does not influence
the surface much

00:14:02.610 --> 00:14:05.220
so you think you
have convergence.

00:14:05.220 --> 00:14:07.620
You still deplete
it as a reservoir

00:14:07.620 --> 00:14:09.870
as you segregate one
species to the surface,

00:14:09.870 --> 00:14:11.370
so that's sometimes
why you actually

00:14:11.370 --> 00:14:13.230
need more bulk in the system.

00:14:13.230 --> 00:14:15.480
But yes, what you say is true.

00:14:15.480 --> 00:14:17.730
If you're only interested
in one composition

00:14:17.730 --> 00:14:20.540
it can be better to
stick there with that.

00:14:20.540 --> 00:14:21.120
OK.

00:14:21.120 --> 00:14:22.875
But let's say you do
these exchange moves.

00:14:26.000 --> 00:14:27.380
Do you do it on a lattice?

00:14:27.380 --> 00:14:30.233
Do you do it in sort
of a continuous space?

00:14:30.233 --> 00:14:31.400
I mean, how would you do it?

00:14:34.630 --> 00:14:35.870
This is an FCC solid.

00:14:35.870 --> 00:14:38.540
This is an FCC solid solution.

00:14:38.540 --> 00:14:42.585
So you could if you want to do
it on a lattice, but would you?

00:14:42.585 --> 00:14:44.210
So you know what I
mean with a lattice?

00:14:44.210 --> 00:14:46.910
You have pre-defined positions
where the atoms can sit.

00:14:54.512 --> 00:14:56.220
Somebody has to be
able to say something.

00:14:56.220 --> 00:14:59.200
I'm just going to stand here.

00:14:59.200 --> 00:15:02.512
And it's not good because
you're being taped for OCW,

00:15:02.512 --> 00:15:03.970
so they're going
to think these MIT

00:15:03.970 --> 00:15:05.230
students have nothing to say.

00:15:08.830 --> 00:15:10.600
Somebody in Western
Africa sees this

00:15:10.600 --> 00:15:12.650
they're going to go
like, why did they

00:15:12.650 --> 00:15:13.940
let these people in at MIT?

00:15:17.930 --> 00:15:19.883
So what else would you add?

00:15:19.883 --> 00:15:21.800
First of all, if you do
it on a fixed lattice,

00:15:21.800 --> 00:15:23.990
think of what you end up
with thermodynamically?

00:15:23.990 --> 00:15:25.970
What have you sampled?

00:15:25.970 --> 00:15:27.470
If you're on a fixed
lattice, you've

00:15:27.470 --> 00:15:31.850
sampled the configurational
entropy, essentially

00:15:31.850 --> 00:15:34.010
the possible distributions
of copper and nickel

00:15:34.010 --> 00:15:36.770
on these fixed lattice sites.

00:15:36.770 --> 00:15:39.140
But if one atom is
bigger than the other,

00:15:39.140 --> 00:15:43.130
for example, then they don't
sit on a fixed lattice,

00:15:43.130 --> 00:15:46.520
then atoms will relax away
from lattice positions.

00:15:46.520 --> 00:15:49.760
You will also not sample
vibrational excitation

00:15:49.760 --> 00:15:52.790
because you never go away
from your lattice position.

00:15:52.790 --> 00:15:56.140
So you could add
small displacements

00:15:56.140 --> 00:15:57.560
to the perturbations.

00:15:57.560 --> 00:15:59.410
So remember, you
do the sort of big

00:15:59.410 --> 00:16:02.350
into the chemical interchange
as you interchange copper

00:16:02.350 --> 00:16:05.200
to nickel, but then
to that you could add

00:16:05.200 --> 00:16:08.590
small displacements of the atoms
so you not sample deviations

00:16:08.590 --> 00:16:10.780
from their
equilibrium positions.

00:16:10.780 --> 00:16:12.430
And if you're done
them, then you'll

00:16:12.430 --> 00:16:16.360
have both configurational
and vibrational entropy.

00:16:16.360 --> 00:16:21.440
So remember that by the
possible perturbations

00:16:21.440 --> 00:16:24.740
you pick for your system,
you are essentially defining

00:16:24.740 --> 00:16:27.220
the phase space you sample.

00:16:27.220 --> 00:16:30.920
So you're defining this phase
space you integrate over

00:16:30.920 --> 00:16:34.570
and that's essentially telling
you what forms of entropy

00:16:34.570 --> 00:16:37.950
you allow in your system.

00:16:37.950 --> 00:16:40.710
Because, you know, what forms
of entropy is the same as what

00:16:40.710 --> 00:16:45.090
forms of disorder or excitations
I allow in your system.

00:16:45.090 --> 00:16:45.900
OK?

00:16:45.900 --> 00:16:48.960
So the cool thing
about it is that you

00:16:48.960 --> 00:16:52.025
can look at the effects of both,
and I'll show that in a bit.

00:16:52.025 --> 00:16:53.400
You could actually
say, first I'm

00:16:53.400 --> 00:16:56.285
going to do it on
a rigid lattice

00:16:56.285 --> 00:16:57.660
and I'll see the
result, and then

00:16:57.660 --> 00:17:01.212
I'll also include displacement
away from the rigid lattice

00:17:01.212 --> 00:17:02.670
and you can look
at the difference,

00:17:02.670 --> 00:17:04.829
and that's essentially
telling you

00:17:04.829 --> 00:17:07.680
what the effect of
vibrational excitations

00:17:07.680 --> 00:17:11.069
are on your thermodynamics.

00:17:11.069 --> 00:17:25.079
OK, so here's the result.
You know this was 1985?

00:17:25.079 --> 00:17:27.660
You'd be amazed how
easy this is to do now

00:17:27.660 --> 00:17:29.850
if you wanted to do
something like this yourself.

00:17:29.850 --> 00:17:33.270
With a Hamiltonian-like embedded
atom it really goes very fast

00:17:33.270 --> 00:17:36.580
and you could equilibrate
systems like this in no time.

00:17:36.580 --> 00:17:38.070
But here's the
result. So this is

00:17:38.070 --> 00:17:42.690
a function of the bulk
concentration of copper.

00:17:42.690 --> 00:17:45.870
This is the amount of
copper in the first

00:17:45.870 --> 00:17:47.380
and second and third layer.

00:17:47.380 --> 00:17:49.570
So the green curve
is the first layer.

00:17:49.570 --> 00:17:53.230
So clearly, copper segregates
to the surface in this material.

00:17:53.230 --> 00:17:58.050
So as you can see, even
for 20% copper in the bulk

00:17:58.050 --> 00:18:01.440
you have an almost perfect
copper layer on the surface.

00:18:01.440 --> 00:18:04.830
I think this was
actually a 111 surface.

00:18:04.830 --> 00:18:07.665
Copper in the second layer,
interestingly, is depleted.

00:18:11.960 --> 00:18:16.070
So it's actually below the
average bulk concentration.

00:18:16.070 --> 00:18:18.350
And then copper
in the third layer

00:18:18.350 --> 00:18:22.890
essentially starts tracking
the bulk concentration.

00:18:22.890 --> 00:18:29.750
So why do you think the
copper in the second layer

00:18:29.750 --> 00:18:30.530
is depleted?

00:18:37.130 --> 00:18:40.490
Because first of all, why
does copper go to the surface?

00:18:40.490 --> 00:18:45.277
It has a lower surface energy,
so this is not rocket science.

00:18:45.277 --> 00:18:47.610
Most of the time the thing
with the lower surface energy

00:18:47.610 --> 00:18:50.040
goes to the surface.

00:18:50.040 --> 00:18:50.940
OK?

00:18:50.940 --> 00:18:53.460
But why is depleted
in the second layer?

00:18:53.460 --> 00:18:55.440
Because I sort of
think, well, this

00:18:55.440 --> 00:18:56.790
is the lower surface energy.

00:18:56.790 --> 00:18:59.820
Even in the second layer
it's not perfectly bonded,

00:18:59.820 --> 00:19:03.300
so maybe it still wants to
enhance its concentration there

00:19:03.300 --> 00:19:05.290
but actually depletes it.

00:19:05.290 --> 00:19:10.600
This is not atypical, it's very
common surface concentration.

00:19:13.780 --> 00:19:16.150
It's actually because copper
and nickel in this system

00:19:16.150 --> 00:19:18.360
have an ordering interaction.

00:19:18.360 --> 00:19:24.260
So it's the fact that the first
layer is almost pure copper,

00:19:24.260 --> 00:19:27.050
but the second layer,
for chemical reasons,

00:19:27.050 --> 00:19:29.500
really wants to be nickel.

00:19:29.500 --> 00:19:30.430
OK?

00:19:30.430 --> 00:19:31.960
And this is a pure
surface effect.

00:19:31.960 --> 00:19:33.970
Copper and nickel in
the bulk are actually

00:19:33.970 --> 00:19:36.130
at low temperature
phase separating,

00:19:36.130 --> 00:19:38.080
but in the surface
because of strain effects

00:19:38.080 --> 00:19:40.180
they form an
ordering interaction.

00:19:40.180 --> 00:19:42.370
And so the second layer
wants to be nickel

00:19:42.370 --> 00:19:44.980
because the first layer
is so much copper.

00:19:44.980 --> 00:19:49.060
And so you often see this
in compound forming systems

00:19:49.060 --> 00:19:52.840
that you have
damped oscillations

00:19:52.840 --> 00:19:55.240
in the concentration
away from the surface.

00:20:05.070 --> 00:20:07.445
OK.

00:20:07.445 --> 00:20:09.570
So I want to show you one
example of something that

00:20:09.570 --> 00:20:12.630
gets much more
complicated, and you'll

00:20:12.630 --> 00:20:16.620
see how you start running into
problems with Monte Carlo.

00:20:16.620 --> 00:20:20.460
So I've shown you a little
bit how you would detect phase

00:20:20.460 --> 00:20:22.230
transitions in Monte Carlo.

00:20:22.230 --> 00:20:24.270
You'd look at things
like the heat capacity

00:20:24.270 --> 00:20:26.730
especially, particularly
powerful for detecting

00:20:26.730 --> 00:20:28.350
second order transitions.

00:20:28.350 --> 00:20:32.280
For first order transitions,
you look at discontinuities

00:20:32.280 --> 00:20:34.950
in things like
the energy, things

00:20:34.950 --> 00:20:37.650
like the relation between mu
and see chemical potential

00:20:37.650 --> 00:20:40.650
and concentration, and
you'll pick that up.

00:20:40.650 --> 00:20:43.770
The problem you'll face is
often that Monte Carlo systems,

00:20:43.770 --> 00:20:48.660
just like real systems, often
face significant hysteresis.

00:20:48.660 --> 00:20:52.770
So here's an example from
quite a few years ago

00:20:52.770 --> 00:20:55.470
of a fairly complicated
lattice model Hamiltonian.

00:20:55.470 --> 00:20:57.750
This, again, was
on an FCC lattice.

00:20:57.750 --> 00:20:59.820
This is the palladium
vanadium system, OK?

00:20:59.820 --> 00:21:00.450
Phase diagram.

00:21:00.450 --> 00:21:04.440
This is palladium on this
side, this side is vanadium,

00:21:04.440 --> 00:21:08.220
and this is a lattice model
with a bunch of interactions

00:21:08.220 --> 00:21:09.420
in the Hamiltonian.

00:21:09.420 --> 00:21:12.150
A nearest neighbor pair,
second neighbor pair,

00:21:12.150 --> 00:21:13.680
third neighbor pair, and so on.

00:21:13.680 --> 00:21:18.130
Four body interactions, four
body here, three body here.

00:21:18.130 --> 00:21:19.800
It's a fairly
complicated Hamiltonian

00:21:19.800 --> 00:21:22.860
that tends to give you
a lot of local minima

00:21:22.860 --> 00:21:24.660
and how would you get
this phase diagram?

00:21:24.660 --> 00:21:26.670
Well, what would you do?

00:21:26.670 --> 00:21:30.960
Again, to equilibrate faster you
wouldn't keep the concentration

00:21:30.960 --> 00:21:33.420
fixed, you would scan
the chemical potential

00:21:33.420 --> 00:21:38.380
and evolve in concentration
from one end to the other.

00:21:38.380 --> 00:21:38.880
OK?

00:21:38.880 --> 00:21:40.630
Let me actually do
that on the next slide.

00:21:45.412 --> 00:21:46.870
So you have some
chemical potential

00:21:46.870 --> 00:21:50.080
that gives you the difference
in palladium and vanadium

00:21:50.080 --> 00:21:51.610
amounts or the concentration.

00:21:55.160 --> 00:21:55.970
OK.

00:21:55.970 --> 00:21:58.190
And so you would
plot something like--

00:22:01.395 --> 00:22:03.420
so you would have a
driving chemical potential

00:22:03.420 --> 00:22:04.920
and you would plot
the average spin,

00:22:04.920 --> 00:22:06.587
we'd say is a
concentration of vanadium.

00:22:11.660 --> 00:22:14.040
And let's say you scan
at this temperature,

00:22:14.040 --> 00:22:15.800
so what would you see?

00:22:15.800 --> 00:22:18.890
If you start here, you would
go through a solid solution

00:22:18.890 --> 00:22:20.150
regime.

00:22:20.150 --> 00:22:24.350
So you would see your
concentration go up when

00:22:24.350 --> 00:22:28.070
you hit the two phase region.

00:22:28.070 --> 00:22:28.570
OK?

00:22:28.570 --> 00:22:30.278
The chemical potential
is constant there,

00:22:30.278 --> 00:22:32.530
so that means at that
chemical potential you

00:22:32.530 --> 00:22:36.170
have a discontinuity
in the concentration,

00:22:36.170 --> 00:22:37.400
so this would go straight up.

00:22:40.120 --> 00:22:42.240
Then you would go in
a single phase region.

00:22:45.580 --> 00:22:46.360
OK?

00:22:46.360 --> 00:22:49.180
So in a single phase region,
the chemical potential

00:22:49.180 --> 00:22:51.860
changes rapidly
with concentration.

00:22:51.860 --> 00:22:56.090
So there, you actually
tend to be kind of flat.

00:22:56.090 --> 00:22:58.130
It's not quite
flat, but it tends

00:22:58.130 --> 00:23:01.280
to just be sloped a lot less.

00:23:01.280 --> 00:23:04.460
Then you would, again, go
in to a two phase region.

00:23:04.460 --> 00:23:08.420
So you would,
again, form a step.

00:23:08.420 --> 00:23:12.332
You would go into
a single phase.

00:23:12.332 --> 00:23:15.100
So we basically see
this kind of behavior,

00:23:15.100 --> 00:23:18.010
and where you have
these discontinuities

00:23:18.010 --> 00:23:21.730
in concentration, you would
know that there's a first order

00:23:21.730 --> 00:23:23.650
transition.

00:23:23.650 --> 00:23:26.440
You could also plot the
energy, and the energy

00:23:26.440 --> 00:23:28.480
is discontinuous as well.

00:23:28.480 --> 00:23:31.570
The internal energy system is
discontinuous at a first order

00:23:31.570 --> 00:23:33.680
transition.

00:23:33.680 --> 00:23:36.610
You don't necessarily see
things in the heat capacity.

00:23:36.610 --> 00:23:37.940
Now what happens in reality?

00:23:40.490 --> 00:23:44.350
If you think about it,
if you come from this end

00:23:44.350 --> 00:23:46.450
so you have a
solid solution, you

00:23:46.450 --> 00:23:47.950
go through two phase
region, and you

00:23:47.950 --> 00:23:49.810
have to form this
compound, which

00:23:49.810 --> 00:23:51.580
is called nickel [INAUDIBLE].

00:23:51.580 --> 00:23:55.070
So often in Monte Carlo,
just like in a real system,

00:23:55.070 --> 00:23:56.770
you have nucleation problems.

00:23:56.770 --> 00:24:00.010
If you have to form a phase
or an arrangement that's

00:24:00.010 --> 00:24:03.340
extremely different from the
host from which it forms,

00:24:03.340 --> 00:24:05.950
it will often just not
nucleate, and well, what happens

00:24:05.950 --> 00:24:08.980
is that you will overshoot.

00:24:08.980 --> 00:24:13.690
So you will actually push the
disordered phase way too far

00:24:13.690 --> 00:24:16.330
out of equilibrium and
then at some point,

00:24:16.330 --> 00:24:19.060
you will be so far
out of equilibrium

00:24:19.060 --> 00:24:22.450
that you literally shoot
into the ordered phase.

00:24:22.450 --> 00:24:25.630
And then what happens
when you come back?

00:24:25.630 --> 00:24:27.270
You have hysteresis
the other way.

00:24:29.880 --> 00:24:32.520
So you'll overshoot the order
phase sometimes and disorder,

00:24:32.520 --> 00:24:34.900
although disordering is
a little easier to do.

00:24:34.900 --> 00:24:37.860
So just like in real systems at
strong first order conditions

00:24:37.860 --> 00:24:44.060
you'll see a lot of hysteresis,
and it's often very hard

00:24:44.060 --> 00:24:46.950
to get rid of.

00:24:46.950 --> 00:24:48.950
I think some of you may
have noticed that if you

00:24:48.950 --> 00:24:51.560
did the molecular dynamics lab.

00:24:51.560 --> 00:24:56.270
Seeing first order transitions
in a molecular dynamics lab,

00:24:56.270 --> 00:24:58.830
you also are often
plagued with hysteresis.

00:24:58.830 --> 00:25:01.940
I mean, if you study
melting, for example,

00:25:01.940 --> 00:25:03.830
it's very asymmetrical
hysteresis.

00:25:03.830 --> 00:25:07.280
If you heat up a solid,
it's pretty easy to melt it.

00:25:07.280 --> 00:25:10.370
If you cool down a liquid,
it's about impossible

00:25:10.370 --> 00:25:13.670
to nucleate the solid
unless you force it.

00:25:13.670 --> 00:25:17.360
So there you have enormous
amounts of hysteresis.

00:25:17.360 --> 00:25:22.370
So the point of this is that
to study strong first order

00:25:22.370 --> 00:25:25.070
transitions,
sometimes the best way

00:25:25.070 --> 00:25:28.940
to find their transition
temperatures or concentrations

00:25:28.940 --> 00:25:31.370
is not by direct simulation.

00:25:31.370 --> 00:25:33.880
Essentially, what
you need to do is go

00:25:33.880 --> 00:25:35.130
through a thermodynamic route.

00:25:35.130 --> 00:25:39.718
Try to extract free energies
and find where they cross,

00:25:39.718 --> 00:25:41.510
because first order
transitions are defined

00:25:41.510 --> 00:25:45.830
by where free energies of
the two phases intersect,

00:25:45.830 --> 00:25:48.650
and that's by far the most
accurate way of detecting

00:25:48.650 --> 00:25:50.870
phase transitions.

00:25:50.870 --> 00:25:53.930
There's a real problem
here is that, how

00:25:53.930 --> 00:25:55.130
do you get free energy?

00:26:00.320 --> 00:26:03.920
The fundamental difference
between free energy and energy

00:26:03.920 --> 00:26:06.920
is that energy is
an average quantity

00:26:06.920 --> 00:26:08.930
and free energy is not.

00:26:08.930 --> 00:26:11.660
See, energy is the
average of something

00:26:11.660 --> 00:26:15.200
that is defined in the
microscopic states.

00:26:15.200 --> 00:26:17.660
For every microscopic
state I go through,

00:26:17.660 --> 00:26:21.087
I can define an energy, and
then the internal energy,

00:26:21.087 --> 00:26:22.670
the thermodynamic
energy of the system

00:26:22.670 --> 00:26:25.370
is just the average
of that quantity.

00:26:25.370 --> 00:26:27.590
For free energy or entropy--

00:26:27.590 --> 00:26:30.980
which are essentially the same
because if I know the entropy,

00:26:30.980 --> 00:26:33.080
I know the free energy--

00:26:33.080 --> 00:26:36.350
it is not the average of
a quantity that's defined

00:26:36.350 --> 00:26:38.235
in the microscopic state.

00:26:38.235 --> 00:26:38.735
You know?

00:26:38.735 --> 00:26:41.600
If you put the atoms
in a fixed position

00:26:41.600 --> 00:26:46.940
somewhere with some velocity,
that's a microscopic state.

00:26:46.940 --> 00:26:48.980
You cannot define
the entropy of that.

00:26:48.980 --> 00:26:52.310
The entropy is a property
of the ensemble as a whole,

00:26:52.310 --> 00:26:54.660
not of a given
macroscopic state.

00:26:54.660 --> 00:26:59.120
So entropy and free energy
cannot be obtained as averages.

00:26:59.120 --> 00:27:01.730
They're actually integrals.

00:27:01.730 --> 00:27:07.730
You can see that the entropy
is a sum over all phase

00:27:07.730 --> 00:27:12.340
space of this quantity,
P log P. You can write

00:27:12.340 --> 00:27:17.850
the free energy same way as an
integrated quantity over all

00:27:17.850 --> 00:27:21.570
of phase space of this quantity.

00:27:21.570 --> 00:27:24.540
If you rewrite it, you
sort of see it better.

00:27:24.540 --> 00:27:26.820
You are averaging something.

00:27:26.820 --> 00:27:29.700
If you look at this, you
are averaging something

00:27:29.700 --> 00:27:31.230
because you have a
probability here,

00:27:31.230 --> 00:27:34.000
but what's the quantity
you're averaging?

00:27:34.000 --> 00:27:36.670
It's essentially the
free energy itself.

00:27:36.670 --> 00:27:40.460
So it's a quantity that's
flat in phase space.

00:27:40.460 --> 00:27:41.250
OK?

00:27:41.250 --> 00:27:46.020
So that makes it extremely
difficult to sample.

00:27:46.020 --> 00:27:49.095
Actually this is not a
mathematical problem,

00:27:49.095 --> 00:27:50.220
this is a physical problem.

00:27:50.220 --> 00:27:52.920
It's just the same as
what happens in nature.

00:27:52.920 --> 00:27:55.530
You can measure energy,
you can measure volume,

00:27:55.530 --> 00:27:57.120
you cannot measure free energy.

00:27:57.120 --> 00:28:00.900
There are no free energy
meters because it's

00:28:00.900 --> 00:28:04.230
an extensive quantity
that that is determined

00:28:04.230 --> 00:28:05.650
by the whole ensemble.

00:28:05.650 --> 00:28:08.642
You only really get free
energies ever indirectly.

00:28:08.642 --> 00:28:10.100
You can get free
energy difference,

00:28:10.100 --> 00:28:13.320
but you get free energy
by integrating lower order

00:28:13.320 --> 00:28:14.040
quantities.

00:28:21.400 --> 00:28:27.430
OK, so you can write
it as an average

00:28:27.430 --> 00:28:30.130
but it's a little misleading.

00:28:30.130 --> 00:28:35.620
You can actually write it as
the average of this thing here.

00:28:35.620 --> 00:28:39.710
If you can calculate
the exponential

00:28:39.710 --> 00:28:42.303
of beta the Hamiltonian and
average that over phase space--

00:28:42.303 --> 00:28:43.970
and notice I didn't
make an error there.

00:28:43.970 --> 00:28:45.980
I did not drop a minus sign.

00:28:45.980 --> 00:28:48.320
It's the exponential
of the positive beta

00:28:48.320 --> 00:28:50.000
times the Hamiltonian.

00:28:50.000 --> 00:28:51.650
If you can average
that quantity,

00:28:51.650 --> 00:28:54.770
you can show that you can
actually have the free energy.

00:28:54.770 --> 00:28:56.390
And the proof is
given here, it's

00:28:56.390 --> 00:28:59.870
sort of an almost trivial proof.

00:28:59.870 --> 00:29:03.050
But you see that's
kind of problematic.

00:29:03.050 --> 00:29:06.110
The Hamiltonian is an
extensive quantity,

00:29:06.110 --> 00:29:09.420
so it scales with the
size of the system.

00:29:09.420 --> 00:29:13.790
So you're taking the exponential
of something that's extensive,

00:29:13.790 --> 00:29:15.477
so that gets very big.

00:29:15.477 --> 00:29:17.810
So first of all, you can only
do this for finite systems

00:29:17.810 --> 00:29:20.480
and for systems that are
really, really small.

00:29:20.480 --> 00:29:23.810
Because otherwise,
essentially, that quantity,

00:29:23.810 --> 00:29:26.660
the exponential of beta the
Hamiltonian, the difference

00:29:26.660 --> 00:29:31.670
between two states
becomes excessively large

00:29:31.670 --> 00:29:34.490
as your system size gets
bigger because that quantity

00:29:34.490 --> 00:29:37.250
in the exponential is extensive.

00:29:37.250 --> 00:29:38.010
OK?

00:29:38.010 --> 00:29:41.570
You see, if I'm calculating the
Hamiltonian difference, say,

00:29:41.570 --> 00:29:45.800
between two phases, the
Hamiltonian value goes in there

00:29:45.800 --> 00:29:47.570
as the extensive quantity.

00:29:47.570 --> 00:29:49.670
It's not the normalized one.

00:29:49.670 --> 00:29:53.160
It's not the one, say, per unit
cell or something like that.

00:29:53.160 --> 00:29:56.120
So that energy
difference is infinite

00:29:56.120 --> 00:29:58.370
in the extensive limit, OK?

00:29:58.370 --> 00:30:03.020
So even if two phases only are
one joule a part per molecule,

00:30:03.020 --> 00:30:05.450
per mol set, one joule per mol.

00:30:05.450 --> 00:30:09.040
In the extensive limit, they're
still an infinite energy apart.

00:30:09.040 --> 00:30:10.040
OK?

00:30:10.040 --> 00:30:15.250
So you can't practically
actually sample that, so

00:30:15.250 --> 00:30:17.080
how do people get free energies?

00:30:17.080 --> 00:30:21.790
Well, there are
hundreds of papers

00:30:21.790 --> 00:30:23.943
on free energy
integration and the reason

00:30:23.943 --> 00:30:25.360
that there's
hundreds of papers is

00:30:25.360 --> 00:30:28.990
that it's such a difficult thing
and everybody claims to have

00:30:28.990 --> 00:30:32.810
the magic potion to do it.

00:30:32.810 --> 00:30:35.590
The first thing to realize
is that you almost never need

00:30:35.590 --> 00:30:38.170
free energy, you always
need free energy differences

00:30:38.170 --> 00:30:41.290
between two things, and
that's a powerful statement

00:30:41.290 --> 00:30:44.098
because that's a lot
easier to do as you'll see.

00:30:44.098 --> 00:30:45.640
The second thing is
that you probably

00:30:45.640 --> 00:30:49.240
shouldn't believe half of
what you read in papers.

00:30:49.240 --> 00:30:51.340
I used to track that
field and everybody said,

00:30:51.340 --> 00:30:55.390
oh, I have a great method
to get free energies out

00:30:55.390 --> 00:30:58.090
of a single simulation, because
that's sort of the problem.

00:30:58.090 --> 00:31:00.490
You'll see in a second that
the way we get free energy

00:31:00.490 --> 00:31:02.513
is that we have
to do Monte Carlo

00:31:02.513 --> 00:31:04.930
at a lot of different points
to get the free energy at one

00:31:04.930 --> 00:31:07.060
point.

00:31:07.060 --> 00:31:09.190
There's tons of papers
that write that you

00:31:09.190 --> 00:31:10.730
can do it with one simulation.

00:31:10.730 --> 00:31:13.450
Well, either implicitly
they do a lot of simulations

00:31:13.450 --> 00:31:16.570
within that one and
just call it one,

00:31:16.570 --> 00:31:19.060
or you can do it
in limited cases

00:31:19.060 --> 00:31:23.090
if you know a lot about the
form of your phase space.

00:31:23.090 --> 00:31:26.080
So if you have extremely
simple Hamiltonians--

00:31:26.080 --> 00:31:30.680
if I give you a nearest neighbor
Ising model, the magnetic model

00:31:30.680 --> 00:31:32.830
which is the nearest
neighbor interaction,

00:31:32.830 --> 00:31:35.680
essentially the
amount of excitations

00:31:35.680 --> 00:31:38.470
out of the low energy
states there is very finite.

00:31:38.470 --> 00:31:40.450
Like I said, you could
flip one isolate, spin,

00:31:40.450 --> 00:31:42.700
you get a times j.

00:31:42.700 --> 00:31:44.822
So you could almost
numerically start writing out

00:31:44.822 --> 00:31:46.030
what the free energy becomes.

00:31:46.030 --> 00:31:50.925
So in very simple models, if
you know the form of the phase

00:31:50.925 --> 00:31:53.980
space, you can actually get
towards free energy models.

00:31:53.980 --> 00:31:57.280
In general, it's pretty
much an unsolved problem.

00:31:57.280 --> 00:31:58.900
And the way we
practically get it

00:31:58.900 --> 00:32:01.490
is with three types of methods.

00:32:01.490 --> 00:32:05.010
One is free energy integration,
and I put lambda integration

00:32:05.010 --> 00:32:05.510
under there.

00:32:05.510 --> 00:32:08.970
I'll show in a
second what it is.

00:32:08.970 --> 00:32:11.130
And the second one is
overlapping distribution

00:32:11.130 --> 00:32:14.070
methods, which is slightly
less important, especially

00:32:14.070 --> 00:32:15.480
for solids.

00:32:15.480 --> 00:32:20.940
So it's really only 2 previous
others, which I used to cover

00:32:20.940 --> 00:32:22.650
and I don't even do anymore now.

00:32:22.650 --> 00:32:23.640
OK.

00:32:23.640 --> 00:32:25.770
Let me first show you
overlapping distribution

00:32:25.770 --> 00:32:30.180
methods, which I'm less familiar
with because I never use it,

00:32:30.180 --> 00:32:33.580
but the idea of it
is quite simple.

00:32:33.580 --> 00:32:36.660
So if you want to know the free
energy difference between two

00:32:36.660 --> 00:32:39.300
states, remember that
the free energy is KT

00:32:39.300 --> 00:32:41.730
log the partition function q.

00:32:41.730 --> 00:32:45.120
So the delta, the
difference is the log

00:32:45.120 --> 00:32:48.020
of the ratio of the
partition function, OK?

00:32:48.020 --> 00:32:49.340
You are with us?

00:32:49.340 --> 00:32:51.010
So you can write
out what that is.

00:32:51.010 --> 00:32:54.750
The partition
function is the sum

00:32:54.750 --> 00:32:57.020
over all the states
of the exponential

00:32:57.020 --> 00:32:59.760
of minus beta the Hamiltonian.

00:32:59.760 --> 00:33:02.220
If I multiply this
by 1-- and I'm

00:33:02.220 --> 00:33:04.980
going to multiply
this by 1, then I'm

00:33:04.980 --> 00:33:11.190
going to write 1 as the
exponential of beta H1.

00:33:11.190 --> 00:33:12.040
Sorry.

00:33:12.040 --> 00:33:13.260
Got to be consistent here.

00:33:13.260 --> 00:33:20.460
H1 nu times exponential
minus beta H1.

00:33:20.460 --> 00:33:23.400
OK, so that's one.

00:33:23.400 --> 00:33:26.550
So then I can collect the
terms here, and what I get

00:33:26.550 --> 00:33:29.100
is that I get I still
sum over all the states.

00:33:29.100 --> 00:33:33.180
I get the exponential,
the Hamiltonian difference

00:33:33.180 --> 00:33:37.050
to n1 weighted by
the probability

00:33:37.050 --> 00:33:41.100
of this state in the
ensemble of Hamiltonian one.

00:33:41.100 --> 00:33:43.830
This is essentially
the probability

00:33:43.830 --> 00:33:46.800
of that state is the
exponential minus beta H

00:33:46.800 --> 00:33:51.000
over the partition function
taken with Hamiltonian 1.

00:33:51.000 --> 00:33:52.740
So what have I written here?

00:33:52.740 --> 00:33:56.340
The exponential of the
probability of that state

00:33:56.340 --> 00:34:01.540
weighted in Hamiltonian
1 of this quantity.

00:34:01.540 --> 00:34:03.960
So essentially,
what I'm averaging

00:34:03.960 --> 00:34:07.650
is the exponential of minus
beta the Hamiltonian difference

00:34:07.650 --> 00:34:10.469
between state two and
one, but I average it

00:34:10.469 --> 00:34:13.800
in the ensemble of one and
that gives me the free energy

00:34:13.800 --> 00:34:15.960
difference.

00:34:15.960 --> 00:34:22.130
The reason that's called
overlapping distribution

00:34:22.130 --> 00:34:24.250
methods is that--

00:34:24.250 --> 00:34:27.100
let me show you
that in a second--

00:34:27.100 --> 00:34:30.670
you're trying to say
something about state two,

00:34:30.670 --> 00:34:34.570
but you're sampling in
the ensemble of one.

00:34:34.570 --> 00:34:38.980
So the only way this
is ever going to work

00:34:38.980 --> 00:34:43.300
is if one and 2 are not too far
apart so that the states that

00:34:43.300 --> 00:34:47.920
are relevant for two are also
sampled to some extent when

00:34:47.920 --> 00:34:50.739
you're in one, and that's
why it's called overlapping

00:34:50.739 --> 00:34:51.980
distribution method.

00:34:51.980 --> 00:34:57.280
So if I sample in
one, essentially

00:34:57.280 --> 00:34:58.330
let's look at the energy.

00:34:58.330 --> 00:35:02.875
I sample energy states around
the average with some spread,

00:35:02.875 --> 00:35:05.170
spread could be
the heat capacity.

00:35:05.170 --> 00:35:06.940
If I'm in two I
do the same thing

00:35:06.940 --> 00:35:09.870
around the average
energy of two.

00:35:09.870 --> 00:35:11.580
And essentially
what I'm doing is

00:35:11.580 --> 00:35:15.900
I'm integrating things
for ensemble two

00:35:15.900 --> 00:35:20.690
just by the way I walk
through ensemble one.

00:35:20.690 --> 00:35:25.040
And so it's a relatively
elegant way of doing it,

00:35:25.040 --> 00:35:28.670
and the key aspect is that the
states in the two ensembles

00:35:28.670 --> 00:35:29.270
are the same.

00:35:32.210 --> 00:35:35.440
The ensembles are the same,
so the accessible states

00:35:35.440 --> 00:35:38.390
are the same, it's just that
you weigh them differently.

00:35:38.390 --> 00:35:42.220
So this is almost just like
non-Boltzmann sampling.

00:35:42.220 --> 00:35:45.250
I Boltzmann sample
for ensemble one,

00:35:45.250 --> 00:35:47.350
but you could say I
non-Boltzmann sample

00:35:47.350 --> 00:35:50.920
for ensemble two and I correct
the probability and this is

00:35:50.920 --> 00:35:52.240
how I get the free energy.

00:35:55.180 --> 00:35:57.430
So you can already see when
this is not going to work.

00:35:57.430 --> 00:36:00.910
This is not going to work when
your states are too far apart.

00:36:04.680 --> 00:36:06.810
OK.

00:36:06.810 --> 00:36:10.200
By far the most
used method to get

00:36:10.200 --> 00:36:12.630
free energy is sort of a
trivial one in some sense,

00:36:12.630 --> 00:36:16.100
it's free energy integration.

00:36:16.100 --> 00:36:19.120
But it's the one
that always works

00:36:19.120 --> 00:36:20.790
if you put enough
time in it and it

00:36:20.790 --> 00:36:23.520
starts from this
kind of trivial idea

00:36:23.520 --> 00:36:26.820
that the difference
in a quantity

00:36:26.820 --> 00:36:30.000
is the integral of the
differential, which this is why

00:36:30.000 --> 00:36:33.100
you come to MIT to learn this.

00:36:33.100 --> 00:36:39.330
So if I can actually
sample this,

00:36:39.330 --> 00:36:41.070
I may be able to
get at the quantity

00:36:41.070 --> 00:36:43.380
simply by integrating that.

00:36:43.380 --> 00:36:44.650
And why is that important?

00:36:44.650 --> 00:36:48.000
Because if A is a free
energy or an entropy,

00:36:48.000 --> 00:36:52.110
the derivatives of free
energies and entropies

00:36:52.110 --> 00:36:54.090
are things that can be
sampled because they

00:36:54.090 --> 00:36:57.000
tend to be either
averages or fluctuations.

00:36:57.000 --> 00:36:59.580
For example, for
the entropy, you

00:36:59.580 --> 00:37:02.950
wanted the entropy
difference between two states

00:37:02.950 --> 00:37:05.082
so you integrate the
derivative of the entropy.

00:37:05.082 --> 00:37:06.540
Well, the derivative
of the entropy

00:37:06.540 --> 00:37:09.600
is the heat capacity
and the heat capacity

00:37:09.600 --> 00:37:11.430
you can get from Monte Carlo.

00:37:11.430 --> 00:37:14.430
The heat capacity is essentially
the fluctuation of the energy.

00:37:22.250 --> 00:37:25.780
So if you want to know the
entropy at a given temperature,

00:37:25.780 --> 00:37:28.900
you start from some
reference temperature

00:37:28.900 --> 00:37:32.200
where you know the entropy or
you just fix it to some value

00:37:32.200 --> 00:37:34.960
if you want to reference
everything to the same thing

00:37:34.960 --> 00:37:38.560
and you integrate
the heat capacity.

00:37:38.560 --> 00:37:40.480
What do you take as
reference states?

00:37:40.480 --> 00:37:42.878
Well, again, you could just
integrate between two states

00:37:42.878 --> 00:37:44.170
and get the entropy difference.

00:37:44.170 --> 00:37:47.350
Often you start from 0.

00:37:47.350 --> 00:37:50.920
If you start from 0
temperature in models

00:37:50.920 --> 00:37:53.440
with discrete degrees of
freedoms like the Ising

00:37:53.440 --> 00:37:56.800
model, the spin model, the
entropy is 0 at 0 Kelvin

00:37:56.800 --> 00:37:59.230
so that's an easy
integration state.

00:37:59.230 --> 00:38:02.710
In some cases, you can also
find the entropy at infinity

00:38:02.710 --> 00:38:05.390
because in infinity, your
phase space is random,

00:38:05.390 --> 00:38:07.390
the probability
distribution is flat,

00:38:07.390 --> 00:38:11.170
and so sometimes you can get
analytically the entropy there.

00:38:11.170 --> 00:38:13.510
So these are all proper
reference states.

00:38:22.040 --> 00:38:23.650
So here's an example.

00:38:23.650 --> 00:38:28.690
This is, again, our very simple
2D square magnetic Ising model.

00:38:28.690 --> 00:38:31.160
You would essentially
integrate C over T,

00:38:31.160 --> 00:38:36.040
so you'd essentially integrate
under this curve from 0 up.

00:38:36.040 --> 00:38:37.990
The way you practically
do it is that you

00:38:37.990 --> 00:38:42.010
wouldn't start from 0,
because the reason is you're

00:38:42.010 --> 00:38:43.370
integrating.

00:38:43.370 --> 00:38:52.860
So you're integrating C
over T and that integral,

00:38:52.860 --> 00:38:56.700
in reality of course,
converges as T goes to 0.

00:38:56.700 --> 00:38:59.100
But numerically, it will
never in your simulation

00:38:59.100 --> 00:39:03.360
because T goes to 0
and you force T to 0

00:39:03.360 --> 00:39:04.260
in your simulation.

00:39:04.260 --> 00:39:07.920
That's a well defined
number, but the heat capacity

00:39:07.920 --> 00:39:12.150
will not go to 0 just
because of numerical noise.

00:39:12.150 --> 00:39:13.590
In reality, it
should be really 0,

00:39:13.590 --> 00:39:17.070
but what will actually
happen is that because

00:39:17.070 --> 00:39:19.110
of some minor noise
and fluctuations,

00:39:19.110 --> 00:39:21.300
we will get non-zero
heat capacity.

00:39:21.300 --> 00:39:24.510
So you divide by a number
that gets exceedingly small

00:39:24.510 --> 00:39:26.910
as you go to 0, and so
you're integral will blow up

00:39:26.910 --> 00:39:28.330
numerically.

00:39:28.330 --> 00:39:31.770
So what you typically do is
you look at your heat capacity

00:39:31.770 --> 00:39:36.810
and say, well, below 0.5
or 0.75 I essentially

00:39:36.810 --> 00:39:38.460
have no heat capacity.

00:39:38.460 --> 00:39:40.860
That means all the
way from 0 to there

00:39:40.860 --> 00:39:43.830
I have essentially no
entropy, and you just

00:39:43.830 --> 00:39:47.400
start integrating
from 0.5 or 0.75.

00:39:47.400 --> 00:39:49.470
If you want to be
more accurate, there

00:39:49.470 --> 00:39:54.990
are ways of analytically
writing the heat capacity from 0

00:39:54.990 --> 00:39:57.330
to low temperature by
things like low temperature

00:39:57.330 --> 00:39:59.070
expansions.

00:39:59.070 --> 00:40:01.410
Essentially from
here to about here,

00:40:01.410 --> 00:40:04.800
all that would ever happen
is single spin flips.

00:40:04.800 --> 00:40:07.320
So you'd have this
ferromagnet sitting there,

00:40:07.320 --> 00:40:09.900
once in a while one spin would
go, [FAST-SOUNDING WHISTLE]..

00:40:09.900 --> 00:40:11.520
So they're single
excitation so you

00:40:11.520 --> 00:40:14.290
can write out what the partition
function pretty much looks

00:40:14.290 --> 00:40:14.790
like.

00:40:14.790 --> 00:40:19.320
It's the groundstate energy plus
just the first excited states.

00:40:19.320 --> 00:40:21.450
So you can write
out analytically

00:40:21.450 --> 00:40:24.490
what the entropy
is up to that point

00:40:24.490 --> 00:40:25.740
and then integrate from there.

00:40:33.260 --> 00:40:37.760
Practically you can integrate a
whole bunch of other variables.

00:40:37.760 --> 00:40:40.190
The one that if you
integrate from infinity

00:40:40.190 --> 00:40:45.140
that's very practical is to use
the Gibbs-Helmholtz relation.

00:40:45.140 --> 00:40:46.820
Gibbs-Helmholtz
relation essentially

00:40:46.820 --> 00:40:49.790
tells you that
the average energy

00:40:49.790 --> 00:40:52.580
is the derivative of
the free energy over T

00:40:52.580 --> 00:40:56.840
with respect to 1 over T. This
is actually a generic relation.

00:40:56.840 --> 00:41:02.140
If you think here the
average of any Hamiltonian

00:41:02.140 --> 00:41:09.350
is actually the derivative of
its corresponding free energy

00:41:09.350 --> 00:41:14.600
over T with respect to 1 over T.

00:41:14.600 --> 00:41:15.470
OK.

00:41:15.470 --> 00:41:19.432
So if you do this in
a canonical system,

00:41:19.432 --> 00:41:21.140
then you're Hamiltonian's
like the energy

00:41:21.140 --> 00:41:24.300
minus mu times
some concentration.

00:41:24.300 --> 00:41:27.470
So then that's the average
quantity you would get here.

00:41:27.470 --> 00:41:28.520
Why is this useful?

00:41:28.520 --> 00:41:32.300
Because essentially now you're
integrating in 1 over T,

00:41:32.300 --> 00:41:36.020
so in beta, and that
quantity is 0 when

00:41:36.020 --> 00:41:37.470
you're at infinite temperature.

00:41:37.470 --> 00:41:39.660
So beta is 0 and
T equals infinity.

00:41:39.660 --> 00:41:44.150
So now this is an easy way
to integrate from infinity.

00:41:44.150 --> 00:41:46.160
Why do you want
integrate from infinity?

00:41:46.160 --> 00:41:48.830
Like I said before, sometimes
that infinite temperature,

00:41:48.830 --> 00:41:50.510
you know the free
energy analytically,

00:41:50.510 --> 00:41:54.260
because everything is totally
random and so something that's

00:41:54.260 --> 00:41:56.420
a useful integration state.

00:41:56.420 --> 00:41:58.250
Another one that's
quite practical

00:41:58.250 --> 00:42:02.698
is simply integrating
in composition,

00:42:02.698 --> 00:42:04.740
and that's why I sort of
shown this on this phase

00:42:04.740 --> 00:42:09.450
because it shows the three
major ways of integration.

00:42:09.450 --> 00:42:11.750
If you come from
low temperature,

00:42:11.750 --> 00:42:13.430
you integrate the heat capacity.

00:42:13.430 --> 00:42:15.110
If you come from
high temperature,

00:42:15.110 --> 00:42:17.180
you use the
Gibbs-Helmholtz relation

00:42:17.180 --> 00:42:20.610
to integrate the average
Hamiltonian, so the energy

00:42:20.610 --> 00:42:22.280
most cases.

00:42:22.280 --> 00:42:26.760
If you come from the sides, you
integrate in composition space.

00:42:26.760 --> 00:42:29.750
So you integrate
essentially sigma d mu,

00:42:29.750 --> 00:42:32.825
and the reason is
that the composition--

00:42:32.825 --> 00:42:36.430
let me write in regular
thermodynamic variables--

00:42:36.430 --> 00:42:39.670
is essentially derivative
of free energy with respect

00:42:39.670 --> 00:42:41.810
to the chemical potential.

00:42:41.810 --> 00:42:43.632
So when you integrate that--

00:42:43.632 --> 00:42:46.090
I've written composition here
as the average spin in a spin

00:42:46.090 --> 00:42:52.240
model, so you integrate Cd
mu, and that gives you dF

00:42:52.240 --> 00:42:56.020
and so that's essentially
what this here is.

00:42:56.020 --> 00:42:59.080
Why can you integrate
from the sides?

00:42:59.080 --> 00:43:01.180
Well, if you have pure 1--

00:43:01.180 --> 00:43:05.020
so you call this A or
B. If you have pure A,

00:43:05.020 --> 00:43:07.630
you know the free
energy in many cases

00:43:07.630 --> 00:43:11.490
because if you have a model with
only configuration entropy when

00:43:11.490 --> 00:43:13.240
you have pure A, you
have no configuration

00:43:13.240 --> 00:43:16.700
entropy so the free energy
there is just the energy.

00:43:16.700 --> 00:43:17.200
OK?

00:43:17.200 --> 00:43:21.190
So in some sense, if you
think of this phase diagram

00:43:21.190 --> 00:43:23.530
as this line going to
infinity, you essentially

00:43:23.530 --> 00:43:29.840
know the thermodynamic
properties at all four edges

00:43:29.840 --> 00:43:32.630
and then you can integrate.

00:43:32.630 --> 00:43:36.440
This is by far the most accurate
way of determining first order

00:43:36.440 --> 00:43:38.480
transitions, by far.

00:43:38.480 --> 00:43:40.340
The reason is that
you can get the answer

00:43:40.340 --> 00:43:42.590
as accurately as you want it.

00:43:42.590 --> 00:43:45.290
So you have to integrate
now along a path, that's

00:43:45.290 --> 00:43:47.130
the painful thing.

00:43:47.130 --> 00:43:50.150
So if I like the
free energy here,

00:43:50.150 --> 00:43:51.680
I don't have to
just simulate here,

00:43:51.680 --> 00:43:55.715
I have to simulate pretty
much all the way up from here.

00:43:55.715 --> 00:43:57.840
So rather than simulating
at one set of conditions,

00:43:57.840 --> 00:44:00.490
I got to simulate
along a whole path.

00:44:00.490 --> 00:44:01.890
But the nice thing is that--

00:44:01.890 --> 00:44:04.830
so where does your
error come from?

00:44:04.830 --> 00:44:08.000
It comes from things
you all control.

00:44:08.000 --> 00:44:10.710
You know, how long I've
sampled at each state

00:44:10.710 --> 00:44:13.350
to get the quantity I'm
integrating, like heat capacity

00:44:13.350 --> 00:44:13.860
or energies.

00:44:13.860 --> 00:44:14.790
You can control that.

00:44:14.790 --> 00:44:17.220
If you want it better,
you sample longer.

00:44:17.220 --> 00:44:19.560
How many steps I take
along the integration path,

00:44:19.560 --> 00:44:22.140
so now you're numerically
integrating along a part.

00:44:22.140 --> 00:44:24.880
If I want that more
accurate, I take more steps.

00:44:24.880 --> 00:44:28.350
So while it looks difficult,
you have all the properties

00:44:28.350 --> 00:44:29.013
under control.

00:44:29.013 --> 00:44:30.430
So that's the nice
thing, that you

00:44:30.430 --> 00:44:33.080
know how to make it better
if you don't like the answer.

00:44:35.772 --> 00:44:37.230
The only thing to
keep in mind when

00:44:37.230 --> 00:44:40.260
you free energy integration,
that you have to iterate

00:44:40.260 --> 00:44:42.660
through equilibrium states.

00:44:42.660 --> 00:44:44.640
These thermodynamic
relations do not

00:44:44.640 --> 00:44:48.520
hold when you're away
from equilibrium states.

00:44:48.520 --> 00:44:52.350
So if you integrate
through transitions,

00:44:52.350 --> 00:44:57.060
then you want to be absolutely
sure that that transition is

00:44:57.060 --> 00:45:00.070
occurring in equilibrium,
and that's often the problem,

00:45:00.070 --> 00:45:02.640
and that's why we combine
all these schemes.

00:45:02.640 --> 00:45:07.440
Like if I want to get,
say, this phase boundary,

00:45:07.440 --> 00:45:12.270
I would probably integrate
one phase up from here to here

00:45:12.270 --> 00:45:16.140
and then I would integrate
either the solid solution

00:45:16.140 --> 00:45:19.860
from the side or from
infinity to that point.

00:45:19.860 --> 00:45:20.940
OK?

00:45:20.940 --> 00:45:24.840
So I would never try to get the
solid solution by integrating

00:45:24.840 --> 00:45:27.510
from the ordered phase
through the transition

00:45:27.510 --> 00:45:29.550
into the solid solution
because I get way

00:45:29.550 --> 00:45:32.340
too much error from
non-equilibrium phenomena

00:45:32.340 --> 00:45:35.140
at the transition.

00:45:35.140 --> 00:45:35.640
OK.

00:45:43.940 --> 00:45:48.860
Then we come to the last form of
free energy integration, which

00:45:48.860 --> 00:45:52.070
is a form of
thermodynamic integration

00:45:52.070 --> 00:45:54.590
that has a bit of a science
fiction component to it.

00:45:57.870 --> 00:45:58.620
Come on.

00:45:58.620 --> 00:45:59.800
OK.

00:45:59.800 --> 00:46:02.790
Anyway, I think I've
said all these things.

00:46:02.790 --> 00:46:05.100
What the advantages
and disadvantages are,

00:46:05.100 --> 00:46:08.880
thermodynamic integration.

00:46:08.880 --> 00:46:14.030
You can actually do something
a little more fancy or esoteric

00:46:14.030 --> 00:46:15.720
in thermodynamic
integration, which

00:46:15.720 --> 00:46:19.660
tends to go by the name
of lambda integration.

00:46:19.660 --> 00:46:24.700
What I showed you before was you
were integrating with respect

00:46:24.700 --> 00:46:26.710
to derivatives of
physical parameters,

00:46:26.710 --> 00:46:29.380
like temperature
or concentration

00:46:29.380 --> 00:46:32.380
or 1 over temperature.

00:46:32.380 --> 00:46:34.540
You can actually
integrate with respect

00:46:34.540 --> 00:46:36.190
to nonphysical parameters.

00:46:36.190 --> 00:46:39.250
For example, I may want
to get the free energy

00:46:39.250 --> 00:46:42.420
difference between
systems that have

00:46:42.420 --> 00:46:46.230
two different Hamiltonians.

00:46:46.230 --> 00:46:47.190
What would that mean?

00:46:47.190 --> 00:46:48.930
Maybe I want to know
how to free energy

00:46:48.930 --> 00:46:52.350
change if I turn on a certain
interaction in the Hamiltonian.

00:46:52.350 --> 00:46:55.342
Like maybe I want to know, I
turn on Coulombic interactions

00:46:55.342 --> 00:46:57.300
and I want to know, how
does this really affect

00:46:57.300 --> 00:46:59.620
the free energy of my system?

00:46:59.620 --> 00:47:02.003
Maybe I want to add a particle.

00:47:02.003 --> 00:47:04.170
You could think of actually
changing the temperature

00:47:04.170 --> 00:47:05.907
as a way of changing
your Hamiltonian,

00:47:05.907 --> 00:47:07.740
because the thing you
put in the exponential

00:47:07.740 --> 00:47:11.430
is beta times Hamiltonian, so
it's really kind of one unit.

00:47:11.430 --> 00:47:13.230
It's when you
change that product

00:47:13.230 --> 00:47:16.950
that you're changing something
to the probability density.

00:47:16.950 --> 00:47:20.710
I'll show you some cool
examples of this in a second,

00:47:20.710 --> 00:47:23.620
but let me show
you how it works.

00:47:23.620 --> 00:47:27.060
So now you're going to integrate
along a path of lambda that

00:47:27.060 --> 00:47:30.990
essentially describes how
you go from Hamiltonian 1

00:47:30.990 --> 00:47:33.270
to Hamiltonian 2.

00:47:33.270 --> 00:47:35.700
And Hamiltonian 2 could be
totally different physics,

00:47:35.700 --> 00:47:38.380
it could be different
chemistry, whatever.

00:47:38.380 --> 00:47:40.680
So I'm going to
write the Hamiltonian

00:47:40.680 --> 00:47:45.630
as a linear combination of the
Hamiltonians of 1 and 2, OK?

00:47:45.630 --> 00:47:48.570
So now you see, as
lambda goes from 0 to 1,

00:47:48.570 --> 00:47:50.910
if I'm 0 I have
Hamiltonian 1, if I'm

00:47:50.910 --> 00:47:52.630
one I have Hamiltonian 2.

00:47:52.630 --> 00:47:53.130
OK?

00:47:53.130 --> 00:47:54.750
So the integral
0 to 1 for lambda

00:47:54.750 --> 00:47:58.368
defines the past one
which I integrate.

00:47:58.368 --> 00:47:59.910
So what I want to
know is essentially

00:47:59.910 --> 00:48:03.047
the free energy between
lambda is 1 and 0--

00:48:03.047 --> 00:48:05.130
but I'll get the free
energy along the whole path,

00:48:05.130 --> 00:48:07.660
as you'll see in a second.

00:48:07.660 --> 00:48:09.090
You can see how
you can get that.

00:48:09.090 --> 00:48:12.240
If you look at the derivative
of the free energy with respect

00:48:12.240 --> 00:48:16.170
to lambda, well, the
free energy is the log

00:48:16.170 --> 00:48:17.890
of the partition function.

00:48:17.890 --> 00:48:19.920
So if I take the
derivative of that,

00:48:19.920 --> 00:48:21.867
you can sort of
do the math here.

00:48:21.867 --> 00:48:23.700
If I take a derivative
of these exponentials

00:48:23.700 --> 00:48:25.920
I get the exponential
back, so that's

00:48:25.920 --> 00:48:28.200
going to give me a
partition function.

00:48:28.200 --> 00:48:30.330
Because remember, if I
take derivative of the log

00:48:30.330 --> 00:48:32.130
I get 1 over this thing.

00:48:32.130 --> 00:48:33.990
So you know, I get log z.

00:48:33.990 --> 00:48:36.660
When you take the derivative of
that, I'm going to get 1 over z

00:48:36.660 --> 00:48:39.420
and then times d, z,
d, whatever I'm taking

00:48:39.420 --> 00:48:42.540
the derivative of with respect.

00:48:42.540 --> 00:48:45.310
So that gives me that
partition function here.

00:48:45.310 --> 00:48:48.120
And then I take the derivative
of what's inside the log

00:48:48.120 --> 00:48:49.530
and that gives me this.

00:48:49.530 --> 00:48:53.700
And essentially what
shows up is the derivative

00:48:53.700 --> 00:48:56.190
of the Hamiltonian
with respect to lambda,

00:48:56.190 --> 00:48:57.450
and this is actually classic.

00:48:57.450 --> 00:48:58.320
This always happens.

00:48:58.320 --> 00:49:01.650
If you take any derivative
of the partition function,

00:49:01.650 --> 00:49:04.290
you essentially always end
up with a weighted derivative

00:49:04.290 --> 00:49:05.850
of the Hamiltonian.

00:49:05.850 --> 00:49:08.790
And so what you see is
this is the probability,

00:49:08.790 --> 00:49:12.090
this exponential weighted
by q is the probability.

00:49:12.090 --> 00:49:16.820
So essentially what this
free energy derivative is,

00:49:16.820 --> 00:49:20.120
it's the average of the
derivative of the Hamiltonian

00:49:20.120 --> 00:49:21.770
with respect to lambda.

00:49:21.770 --> 00:49:22.310
OK?

00:49:22.310 --> 00:49:27.330
This is actually quite generic
in statistical mechanics.

00:49:27.330 --> 00:49:32.930
So the quantity that you need
to integrate is this derivative.

00:49:32.930 --> 00:49:35.600
Now if we've linearized
our Hamiltonian,

00:49:35.600 --> 00:49:38.570
that derivative is just
Hamiltonian difference.

00:49:38.570 --> 00:49:39.140
OK?

00:49:39.140 --> 00:49:42.690
But this is actually
more generically true.

00:49:42.690 --> 00:49:44.720
But if you linearize
it, all you need to do

00:49:44.720 --> 00:49:47.038
is average the
Hamiltonian difference.

00:50:01.690 --> 00:50:04.270
So I'm going to show
you an example which

00:50:04.270 --> 00:50:08.210
I got out of this paper,
which is hidden here by--

00:50:08.210 --> 00:50:09.210
kind of move this thing.

00:50:09.210 --> 00:50:09.878
There we go.

00:50:13.677 --> 00:50:15.260
And this was a study
where they wanted

00:50:15.260 --> 00:50:20.270
to look at the effects
of a water dipole

00:50:20.270 --> 00:50:22.620
on the free energy of water.

00:50:22.620 --> 00:50:26.077
And so the reason you have a
dipole in water is, of course,

00:50:26.077 --> 00:50:26.660
you have H2O--

00:50:29.210 --> 00:50:31.280
how does this work again?

00:50:31.280 --> 00:50:35.220
So the hydrogens are
slightly positively charged

00:50:35.220 --> 00:50:39.260
and so this is then minus
2 times that quantity.

00:50:39.260 --> 00:50:44.250
And so because of that, you of
course, have a dipole which--

00:50:44.250 --> 00:50:47.090
does a dipole point from
positive to negative

00:50:47.090 --> 00:50:50.785
or, yeah, from negative
to positive dipoles?

00:50:50.785 --> 00:50:51.410
Well, whatever.

00:50:51.410 --> 00:50:53.660
We'll define it this way.

00:50:53.660 --> 00:50:59.330
So you have a dipole moment
and in a simple simulation,

00:50:59.330 --> 00:51:03.410
you can essentially
just represent the water

00:51:03.410 --> 00:51:05.510
by its dipole, nothing else.

00:51:05.510 --> 00:51:07.140
No atoms, no molecules.

00:51:07.140 --> 00:51:09.950
So you want to look at
the dipole interactions

00:51:09.950 --> 00:51:11.030
between water.

00:51:11.030 --> 00:51:13.910
Now if you want to look at
how does the free energies

00:51:13.910 --> 00:51:17.790
change with the strength of
that dipole, for example,

00:51:17.790 --> 00:51:22.910
you could write dipolar strength
in terms of some parameter

00:51:22.910 --> 00:51:25.290
lambda, and that's
what I've done here.

00:51:25.290 --> 00:51:28.460
So the positive and the
negative charge in the dipole

00:51:28.460 --> 00:51:31.392
depend on the parameter
lambda, and so essentially

00:51:31.392 --> 00:51:33.350
what I'm going to do is
look at the free energy

00:51:33.350 --> 00:51:34.460
as a function of lambda.

00:51:37.160 --> 00:51:40.400
And let me show
you how it works.

00:51:40.400 --> 00:51:43.400
The green line here, there's a
few too many lines on this plot

00:51:43.400 --> 00:51:44.240
unfortunately.

00:51:44.240 --> 00:51:45.605
This is the exact result--

00:51:49.770 --> 00:51:52.350
and actually, this
was well parameterized

00:51:52.350 --> 00:51:55.230
because at 0 and 1 you
should get the same answer

00:51:55.230 --> 00:51:59.180
because when lambda is 1, the
dipole is the same as at 0,

00:51:59.180 --> 00:52:01.950
it's just inverted the
plus n minus charge.

00:52:01.950 --> 00:52:03.420
OK?

00:52:03.420 --> 00:52:08.100
So the purple line is what they
got with lambda integrations

00:52:08.100 --> 00:52:09.750
paper, so it does pretty well.

00:52:09.750 --> 00:52:12.432
I mean it's this
line here, sorry.

00:52:12.432 --> 00:52:14.640
But what you see is there's
of course a bit of error.

00:52:14.640 --> 00:52:18.360
This point should be the
same as that point, OK?

00:52:18.360 --> 00:52:22.650
And so you clearly see that
they accumulated some error

00:52:22.650 --> 00:52:24.810
along the integration path.

00:52:24.810 --> 00:52:28.320
And if you're really
hard core computational

00:52:28.320 --> 00:52:31.973
and you think this is
fun, this is one way

00:52:31.973 --> 00:52:34.140
you can check your integration
errors is essentially

00:52:34.140 --> 00:52:38.170
do a circular integration
in your phase space.

00:52:38.170 --> 00:52:44.160
So not only go from Hamil
state 1 to 2, but come back

00:52:44.160 --> 00:52:45.690
and you essentially
have some idea

00:52:45.690 --> 00:52:48.180
of the error you've accumulated
along the integration path.

00:52:53.970 --> 00:52:57.600
This one, the next one
I like as an example.

00:52:57.600 --> 00:53:01.620
This is starting to get
very close to alchemy.

00:53:01.620 --> 00:53:04.980
You know, in the old days people
tried to turn lead into gold.

00:53:04.980 --> 00:53:07.530
This is getting pretty close.

00:53:07.530 --> 00:53:10.540
You can look at
three energy changes

00:53:10.540 --> 00:53:14.880
literally by changing chemistry.

00:53:14.880 --> 00:53:16.590
I know nothing about
organic chemistry,

00:53:16.590 --> 00:53:19.320
but I think that ring
there is called the phenyl

00:53:19.320 --> 00:53:21.690
and so you can put different
groups on the phenyl

00:53:21.690 --> 00:53:24.360
and if you put chlorine
on it, it's chlorophenyl.

00:53:24.360 --> 00:53:27.480
If you pull a methyl
group on its methylphenyl,

00:53:27.480 --> 00:53:29.760
and if you put a cyan
group it's cyanophenyl.

00:53:29.760 --> 00:53:35.670
So there's clearly some
logic in chemical names.

00:53:35.670 --> 00:53:38.880
But for example, you
could write a Hamiltonian

00:53:38.880 --> 00:53:43.225
that slowly changes one of
these species into another one.

00:53:43.225 --> 00:53:44.850
And what does that
mean, slowly change?

00:53:44.850 --> 00:53:46.830
That means that you
mix the interaction.

00:53:46.830 --> 00:53:48.630
Let's say you did
this with potential,

00:53:48.630 --> 00:53:52.170
you would essentially write
a potential from that group.

00:53:52.170 --> 00:53:55.950
Potential that comes from this
group here that you attach

00:53:55.950 --> 00:53:58.225
has a weighted average of--

00:53:58.225 --> 00:53:59.850
let's say we go from,
like we did here,

00:53:59.850 --> 00:54:02.730
methylphenyl to chlorophenyl.

00:54:02.730 --> 00:54:06.030
So you would weigh the potential
with the parameter lambda

00:54:06.030 --> 00:54:07.860
and integrate in
that space and you'd

00:54:07.860 --> 00:54:10.320
get the free energy
difference between these two

00:54:10.320 --> 00:54:11.605
groups attached.

00:54:17.660 --> 00:54:19.780
OK.

00:54:19.780 --> 00:54:25.870
So here's my take
on Monte Carlo.

00:54:25.870 --> 00:54:30.532
What I really like about it,
it's conceptually simple.

00:54:30.532 --> 00:54:31.990
Of all the simulation
methods, it's

00:54:31.990 --> 00:54:37.630
probably the one that has
the least amount of frills.

00:54:37.630 --> 00:54:43.510
It tends to be very
easy to implement.

00:54:43.510 --> 00:54:46.820
And maybe the most
important thing,

00:54:46.820 --> 00:54:49.930
it's as accurate
as your Hamiltonian

00:54:49.930 --> 00:54:53.320
can be so you can push
the sampling as far as you

00:54:53.320 --> 00:54:54.200
want it to be.

00:54:54.200 --> 00:54:57.400
So the sampling part can be done
as accurately as you have time

00:54:57.400 --> 00:54:58.210
for, essentially.

00:54:58.210 --> 00:54:59.957
Time and money for.

00:54:59.957 --> 00:55:01.540
Which is not always
true about models.

00:55:01.540 --> 00:55:05.290
If I set up a potential
model, I can't necessarily

00:55:05.290 --> 00:55:08.110
improve that infinitely
better to model

00:55:08.110 --> 00:55:09.520
the energetics of my system.

00:55:09.520 --> 00:55:13.030
But at least with Monte
Carlo, the sampling part, so

00:55:13.030 --> 00:55:17.320
the finite temperature part can
be done with as little error

00:55:17.320 --> 00:55:20.440
as you'd like it to be.

00:55:20.440 --> 00:55:22.630
I think there's
sort of two or three

00:55:22.630 --> 00:55:28.850
major disadvantages is that
it's not a dynamical method,

00:55:28.850 --> 00:55:31.090
so it doesn't give you
any kinetic information

00:55:31.090 --> 00:55:33.623
like molecular dynamics does.

00:55:33.623 --> 00:55:35.290
Sometimes that's an
advantage because it

00:55:35.290 --> 00:55:38.170
means you don't need
a kinetic mechanism

00:55:38.170 --> 00:55:41.770
to study how the system goes
through it's phase space.

00:55:41.770 --> 00:55:45.400
But the second one is the
major hit most of the time.

00:55:45.400 --> 00:55:48.130
It's an extremely
wasteful method

00:55:48.130 --> 00:55:50.710
in terms of energy evaluations.

00:55:50.710 --> 00:55:53.530
You do a lot of kind of
random excursions in phase

00:55:53.530 --> 00:55:56.960
space and every time you
need to get the energy,

00:55:56.960 --> 00:56:00.430
and so that's why it's
really great to implement it

00:56:00.430 --> 00:56:02.050
with fast energy methods.

00:56:02.050 --> 00:56:04.827
You know, [INAUDIBLE] small
Hamiltonian G. That's just

00:56:04.827 --> 00:56:06.910
adding a few numbers and
multiplying a few numbers

00:56:06.910 --> 00:56:08.620
and you got the energy, bam!

00:56:08.620 --> 00:56:10.690
Or something like
potential models

00:56:10.690 --> 00:56:14.440
if you do it in a continuous
space or embedded atom

00:56:14.440 --> 00:56:16.840
works great with those methods.

00:56:16.840 --> 00:56:19.840
It's essentially impossible
to implement it with quantum

00:56:19.840 --> 00:56:21.670
mechanics directly, you know?

00:56:21.670 --> 00:56:24.200
I mean, that embedded.

00:56:24.200 --> 00:56:25.900
The method, the
copper nickel one

00:56:25.900 --> 00:56:28.420
I showed you did millions
of energy evaluations

00:56:28.420 --> 00:56:30.520
to equilibrate the system.

00:56:30.520 --> 00:56:33.120
So can you imagine you're
going to millions of direct DFT

00:56:33.120 --> 00:56:34.740
calculations?

00:56:34.740 --> 00:56:35.640
No.

00:56:35.640 --> 00:56:38.010
So that the fact that
you need typically

00:56:38.010 --> 00:56:42.430
a fast energy method is
sort of a limitation.

00:56:42.430 --> 00:56:45.150
The stochastic nature of
it can be a limitation.

00:56:45.150 --> 00:56:49.710
It's less and less so, but
when you run two Monte Carlo

00:56:49.710 --> 00:56:53.380
simulations you don't
get the same answer,

00:56:53.380 --> 00:56:57.060
so because of that,
there is noise in data.

00:56:57.060 --> 00:57:00.780
It's a lot harder to write
methods on top of it,

00:57:00.780 --> 00:57:03.020
in some sense, drivers for it.

00:57:03.020 --> 00:57:06.570
If you do DFT, if
you converge, you

00:57:06.570 --> 00:57:08.790
get the same answer every time.

00:57:08.790 --> 00:57:10.220
So it's not stochastic.

00:57:10.220 --> 00:57:14.790
So you can now develop
algorithms that use that input

00:57:14.790 --> 00:57:15.840
and do stuff with it.

00:57:15.840 --> 00:57:18.510
It's a lot harder to work
with stochastic input,

00:57:18.510 --> 00:57:22.830
let me tell you, because you
kind of have to average noise

00:57:22.830 --> 00:57:24.570
away.

00:57:24.570 --> 00:57:26.900
And I think the fourth one--
you know, I should update.

00:57:26.900 --> 00:57:29.730
This is becoming less
and less an issue.

00:57:29.730 --> 00:57:33.540
It used to be, but as computers
get faster it's really,

00:57:33.540 --> 00:57:35.760
I would say we can
get free energy when

00:57:35.760 --> 00:57:39.870
we want it, especially on
models with discrete degrees

00:57:39.870 --> 00:57:40.388
of freedom.

00:57:40.388 --> 00:57:42.680
Models with continuous degree
of freedom you can do it.

00:57:42.680 --> 00:57:46.320
There's still more work, but
it's not much of a disadvantage

00:57:46.320 --> 00:57:49.065
anymore.

00:57:49.065 --> 00:57:53.260
OK, I've gone through
the references Before.

00:57:53.260 --> 00:57:54.070
OK.

00:57:54.070 --> 00:57:55.785
So what I want to
start maybe now--

00:57:55.785 --> 00:57:57.160
and I'm probably
not going to get

00:57:57.160 --> 00:58:05.800
this finished-- is start to talk
about coarse-graining methods.

00:58:05.800 --> 00:58:07.750
And why do you need
coarse-graining methods?

00:58:07.750 --> 00:58:13.500
it's essentially a nice follow
up on what we just discussed.

00:58:13.500 --> 00:58:18.990
Monte Carlo allows you to get
full phase space sampling,

00:58:18.990 --> 00:58:22.740
but you cannot do it on an
accurate Hamiltonian like

00:58:22.740 --> 00:58:25.930
density functional theory.

00:58:25.930 --> 00:58:30.780
So what if you actually need
highly accurate energetics

00:58:30.780 --> 00:58:32.760
and you need to sample
phase space well?

00:58:32.760 --> 00:58:35.520
Then you're in trouble
because the two

00:58:35.520 --> 00:58:38.880
are very hard to combine.

00:58:38.880 --> 00:58:41.250
Sampling phase
space, well, means

00:58:41.250 --> 00:58:44.520
a lot of energy evaluations
and a lot of energy evaluations

00:58:44.520 --> 00:58:47.700
precludes using a very
highly accurate Hamiltonian,

00:58:47.700 --> 00:58:50.880
but there are problems for
which you need both anyway.

00:58:50.880 --> 00:58:54.270
And then you sort of need to
go to coarse-graining methods.

00:58:54.270 --> 00:58:56.100
And the idea in
coarse-graining methods

00:58:56.100 --> 00:59:01.290
is that you try to either remove
spatial degrees of freedom

00:59:01.290 --> 00:59:03.690
or temporal degrees of
freedom or your system

00:59:03.690 --> 00:59:06.510
very systematically so
that your model becomes

00:59:06.510 --> 00:59:11.470
simpler and simpler, giving up
as little accuracy as possible.

00:59:11.470 --> 00:59:11.970
OK?

00:59:11.970 --> 00:59:16.110
So accumulating as little
error on the way as possible.

00:59:16.110 --> 00:59:19.090
I'll talk first about
temporal coarse-graining

00:59:19.090 --> 00:59:21.373
since it's easier, but if
we have time in the end

00:59:21.373 --> 00:59:23.790
I may say a little about spatial
coarse-graining, which is

00:59:23.790 --> 00:59:26.310
a much more difficult problem.

00:59:29.790 --> 00:59:32.750
OK, let me skip this.

00:59:32.750 --> 00:59:33.931
OK.

00:59:33.931 --> 00:59:35.473
Well, actually let
me show it to you.

00:59:39.560 --> 00:59:41.060
Something wrong
with the color here.

00:59:45.160 --> 00:59:49.510
Here's an example of why
you need coarse-graining.

00:59:49.510 --> 00:59:51.550
This is the copper,
aluminum phase diagram.

00:59:54.310 --> 00:59:56.890
All the stable
phases in here are

00:59:56.890 --> 01:00:00.250
in many cases within something
like 5 to 10 milli electron

01:00:00.250 --> 01:00:03.250
volt of several other phases.

01:00:03.250 --> 01:00:06.250
So that means that
to actually know

01:00:06.250 --> 01:00:08.470
that these are the stables
facing that system,

01:00:08.470 --> 01:00:11.480
you need highly
accurate energetics.

01:00:11.480 --> 01:00:14.880
You can't afford more than a
few million electoral votes

01:00:14.880 --> 01:00:15.990
to an error.

01:00:15.990 --> 01:00:17.940
That's a very small error.

01:00:17.940 --> 01:00:22.010
So an election volt is
about 100 kilojoules,

01:00:22.010 --> 01:00:25.770
so a million electron
volt is about 100 joules.

01:00:25.770 --> 01:00:26.840
All right.

01:00:26.840 --> 01:00:27.822
Yeah.

01:00:27.822 --> 01:00:29.530
So I don't know what
that in calories is,

01:00:29.530 --> 01:00:33.620
but anyway, so highly
accurate energetics

01:00:33.620 --> 01:00:36.700
and then to get the
temperature behavior

01:00:36.700 --> 01:00:38.510
you need to sample
phase space because you

01:00:38.510 --> 01:00:41.360
need to get the entropy
and the excitations.

01:00:46.100 --> 01:00:49.860
For some problems like
these, essentially we

01:00:49.860 --> 01:00:51.630
figured out how to do this.

01:00:51.630 --> 01:00:54.650
It's still hard work, but
essentially the road map

01:00:54.650 --> 01:00:56.750
is laid out.

01:00:56.750 --> 01:01:01.580
The idea is that you
successively integrate over

01:01:01.580 --> 01:01:04.160
slower and slower timescales.

01:01:04.160 --> 01:01:07.520
So you look at what
excursions, what excitations

01:01:07.520 --> 01:01:11.090
occur in the system, first at
the really fast time scales

01:01:11.090 --> 01:01:15.110
and then you try to either
variationally remove them

01:01:15.110 --> 01:01:16.670
or you try to
integrate over them,

01:01:16.670 --> 01:01:18.140
and those two are
different things.

01:01:18.140 --> 01:01:21.843
If you variationally
remove a degree of freedom,

01:01:21.843 --> 01:01:23.510
then you're really
finding, essentially,

01:01:23.510 --> 01:01:27.290
what gives you the lowest energy
for that degree of freedom.

01:01:27.290 --> 01:01:29.990
If you integrate
over the excursions

01:01:29.990 --> 01:01:32.330
of that degree of freedom,
then essentially you

01:01:32.330 --> 01:01:34.430
capture its full
entropic component,

01:01:34.430 --> 01:01:36.680
and I'll come back to the
distinction between the two.

01:01:36.680 --> 01:01:39.170
But let's take, for
example, a simple binary

01:01:39.170 --> 01:01:42.170
solid, like that aluminum
copper I showed you.

01:01:42.170 --> 01:01:45.690
What are the excitations
in that system?

01:01:45.690 --> 01:01:49.670
Well, it's a metal so at the
highest level there's probably

01:01:49.670 --> 01:01:51.920
electronic excitations.

01:01:51.920 --> 01:01:56.810
If the Fermi level of the
system cuts through a band

01:01:56.810 --> 01:01:59.810
so you have density of
states at the Fermi level,

01:01:59.810 --> 01:02:02.860
then electrons can get excited
across the Fermi level.

01:02:02.860 --> 01:02:03.360
OK?

01:02:03.360 --> 01:02:05.900
So that's a form of entropy
right there already.

01:02:05.900 --> 01:02:07.610
Most of the time we
don't worry about it.

01:02:07.610 --> 01:02:10.190
That's one that we
variationally remove.

01:02:10.190 --> 01:02:13.310
You do the FT and you find
the lowest energy state.

01:02:13.310 --> 01:02:15.080
You don't say, I'm
going to integrate

01:02:15.080 --> 01:02:17.150
over all the accessible
electronic states.

01:02:17.150 --> 01:02:20.610
You find the lowest one.

01:02:20.610 --> 01:02:23.293
Then you have
vibrational excitations.

01:02:23.293 --> 01:02:24.710
These are ones you
can get around.

01:02:24.710 --> 01:02:28.935
They're essentially present in
every material by definition.

01:02:28.935 --> 01:02:31.800
These live on timescale
10 to the minus 11,

01:02:31.800 --> 01:02:35.970
10 to the minus 12, 10
to the minus 13 seconds.

01:02:35.970 --> 01:02:40.050
And then typically the slower
one is configurational ones.

01:02:40.050 --> 01:02:45.690
If you have just A and B that
they interchange positions,

01:02:45.690 --> 01:02:47.175
they start giving you disorder.

01:02:51.240 --> 01:02:54.390
Again, the reason you can
sort of do this problem easily

01:02:54.390 --> 01:02:57.240
is that this would be
the perfect Monte Carlo

01:02:57.240 --> 01:03:00.420
problem, just like in
that copper nickel example

01:03:00.420 --> 01:03:01.650
segregation.

01:03:01.650 --> 01:03:03.600
If you could do fast
energy evaluations,

01:03:03.600 --> 01:03:05.340
you would just do
small displacements

01:03:05.340 --> 01:03:07.410
to capture the
vibrations and then

01:03:07.410 --> 01:03:09.900
you would do big
exchanges to capture

01:03:09.900 --> 01:03:11.640
the configurational excitations.

01:03:11.640 --> 01:03:13.110
But because you
need the accuracy,

01:03:13.110 --> 01:03:16.973
you'd almost need to do
it on a DFT Hamiltonian.

01:03:16.973 --> 01:03:18.390
You could say the
vibrational ones

01:03:18.390 --> 01:03:21.990
you could capture very well
with molecular dynamics.

01:03:21.990 --> 01:03:25.530
You just track the
displacements of the atoms.

01:03:25.530 --> 01:03:28.770
Think about it, the
sort of slower phonons

01:03:28.770 --> 01:03:32.020
go on a timescale of
maybe 10 to the minus 11.

01:03:32.020 --> 01:03:32.910
So what is that?

01:03:32.910 --> 01:03:35.040
That's 10 picoseconds.

01:03:35.040 --> 01:03:38.130
So if you simulate 100
picoseconds in nanoseconds,

01:03:38.130 --> 01:03:40.230
you're going to start
fairly allegorically

01:03:40.230 --> 01:03:41.410
sampling the vibration.

01:03:41.410 --> 01:03:44.190
So you'd have a
pretty good result

01:03:44.190 --> 01:03:46.230
for vibrational free
energy, but you'd never

01:03:46.230 --> 01:03:48.598
get down to the
configurational timescale.

01:03:52.190 --> 01:03:53.600
So how do you
solve that problem?

01:03:59.990 --> 01:04:04.760
Again, the idea is
that we integrate over

01:04:04.760 --> 01:04:07.490
the fast degrees
of freedom and try

01:04:07.490 --> 01:04:10.460
to define a
Hamiltonian that's only

01:04:10.460 --> 01:04:13.740
defined in the phase space of
the slow degrees of freedom.

01:04:13.740 --> 01:04:14.240
OK?

01:04:14.240 --> 01:04:18.350
And the question is how
accurate can we do this?

01:04:18.350 --> 01:04:21.050
So I'm going to focus
on this alloy problem

01:04:21.050 --> 01:04:22.500
just so that we keep our focus.

01:04:22.500 --> 01:04:27.140
So what I want to get to is a
Hamiltonian that has integrated

01:04:27.140 --> 01:04:31.400
away the electronic excitations,
the vibrational excitations,

01:04:31.400 --> 01:04:34.280
and therefore that just
lives in the phase space

01:04:34.280 --> 01:04:36.320
of the substitutional
excitations, which

01:04:36.320 --> 01:04:37.760
is a much smaller phase space.

01:04:44.790 --> 01:04:47.170
OK.

01:04:47.170 --> 01:04:48.490
Let me show you the math.

01:04:51.190 --> 01:04:56.873
If you think of a
crystal of A and B atoms,

01:04:56.873 --> 01:04:58.790
they may live on a
lattice, but of course they

01:04:58.790 --> 01:05:00.430
can be displaced
from the lattice

01:05:00.430 --> 01:05:03.520
just through static
relaxation but also

01:05:03.520 --> 01:05:05.410
through vibrational excursions.

01:05:05.410 --> 01:05:10.090
So normally you could
define that system

01:05:10.090 --> 01:05:12.220
just by coordinate vectors.

01:05:12.220 --> 01:05:15.050
If I have n atoms, I need
n coordinate vectors.

01:05:15.050 --> 01:05:17.980
I'm going to change the way
I characterize that system

01:05:17.980 --> 01:05:21.110
by first, a lattice index.

01:05:21.110 --> 01:05:22.780
So this is a topological index.

01:05:22.780 --> 01:05:26.660
This is essentially if I
have a crystalline material,

01:05:26.660 --> 01:05:28.900
I could start indexing
the possible sites

01:05:28.900 --> 01:05:30.680
in that material.

01:05:30.680 --> 01:05:35.770
So I will be the index of
these possible lattice sites

01:05:35.770 --> 01:05:39.490
and delta r will be the
displacement from these lattice

01:05:39.490 --> 01:05:40.080
sites.

01:05:40.080 --> 01:05:40.870
OK?

01:05:40.870 --> 01:05:45.280
So do you agree that the
combination of these two

01:05:45.280 --> 01:05:48.220
is essentially the same as
having a full coordinate?

01:05:48.220 --> 01:05:49.510
OK.

01:05:49.510 --> 01:05:58.040
Now the set of indices i I'm
going to represent essentially

01:05:58.040 --> 01:06:00.030
by a lattice model.

01:06:00.030 --> 01:06:04.040
So the set of indices i is
essentially saying at each

01:06:04.040 --> 01:06:07.220
lattice point or around
there-- because the atom

01:06:07.220 --> 01:06:10.040
doesn't exactly have to sit
there, but around there--

01:06:10.040 --> 01:06:12.380
is it an A or a B there?

01:06:12.380 --> 01:06:13.880
So the variables
to describe that

01:06:13.880 --> 01:06:17.180
are the same variables as a
spin model or lattice model,

01:06:17.180 --> 01:06:19.160
it's a binary problem now.

01:06:19.160 --> 01:06:19.940
OK?

01:06:19.940 --> 01:06:24.380
So the question is,
at I is it A or B?

01:06:24.380 --> 01:06:27.200
But again, I don't need to
specify that the atom exactly

01:06:27.200 --> 01:06:31.460
sits at A or B. That I specify
by the displacements, the delta

01:06:31.460 --> 01:06:33.530
r's, OK?

01:06:33.530 --> 01:06:35.810
So what I've done is
I've separated variables

01:06:35.810 --> 01:06:39.920
that give me the configurational
topology from the variables

01:06:39.920 --> 01:06:43.910
that gives me the excursions
away from the ideal lattice

01:06:43.910 --> 01:06:44.410
site.

01:06:49.840 --> 01:06:51.270
And now you see where I'm going.

01:06:51.270 --> 01:06:55.500
I'm going to integrate
over the excursions

01:06:55.500 --> 01:06:58.050
and then retain
something that only

01:06:58.050 --> 01:07:00.780
exists in the space of the
configurational degrees

01:07:00.780 --> 01:07:01.860
of freedom.

01:07:01.860 --> 01:07:04.090
OK, here we go.

01:07:04.090 --> 01:07:07.660
So the partition function
is the sum over all states.

01:07:07.660 --> 01:07:09.310
So again, the sum
over all states

01:07:09.310 --> 01:07:12.540
you would have normally be
the sum over all vectors.

01:07:12.540 --> 01:07:16.230
I'm going to write that as the
sum over configurational states

01:07:16.230 --> 01:07:19.690
and then the sum over all
displacement states, which

01:07:19.690 --> 01:07:20.910
have called nu.

01:07:20.910 --> 01:07:31.520
So nu is the set of delta
ri, and so the energy

01:07:31.520 --> 01:07:33.890
depends on both variables.

01:07:33.890 --> 01:07:35.290
OK?

01:07:35.290 --> 01:07:38.770
Now what I'm going to do is
I'm going to essentially assume

01:07:38.770 --> 01:07:40.780
I can do this integration.

01:07:40.780 --> 01:07:43.310
We'll talk in a second
about how you can do that.

01:07:43.310 --> 01:07:46.510
So I'm only going to do the
sum over the displacement,

01:07:46.510 --> 01:07:49.880
but for a given
configurational state.

01:07:49.880 --> 01:07:51.650
So what does that
practically mean?

01:07:51.650 --> 01:07:56.030
That means that I'm integrating
the phase space of a fixed

01:07:56.030 --> 01:07:59.500
topology, but allowing the
atoms to sort of vibrate

01:07:59.500 --> 01:08:02.770
around their average positions.

01:08:02.770 --> 01:08:04.510
That's essentially
what I'm doing.

01:08:04.510 --> 01:08:07.120
So essentially I'm
capturing, in that integral,

01:08:07.120 --> 01:08:09.610
the vibrational free
energy component

01:08:09.610 --> 01:08:13.570
for a given configuration.

01:08:13.570 --> 01:08:16.970
And so I'm going to define.

01:08:16.970 --> 01:08:20.203
So this is that integral
we talked about.

01:08:20.203 --> 01:08:22.120
So I'm going to give
that a free energy, which

01:08:22.120 --> 01:08:24.050
is just the logarithm of that.

01:08:24.050 --> 01:08:29.300
And then just if I
substitute that in here,

01:08:29.300 --> 01:08:35.069
you see that what I
end up with is this

01:08:35.069 --> 01:08:36.450
and this is kind of important.

01:08:36.450 --> 01:08:37.270
What do I have?

01:08:37.270 --> 01:08:41.130
I have the partition
function of a lattice model.

01:08:41.130 --> 01:08:44.160
I have a partition
function that only

01:08:44.160 --> 01:08:46.770
sums over different
topologies, it only

01:08:46.770 --> 01:08:52.670
sums over different
configurational states, OK?

01:08:52.670 --> 01:08:55.370
So I've reduced the phase space.

01:08:55.370 --> 01:08:57.189
I'm not summing over
vibrational states.

01:08:57.189 --> 01:08:58.609
Remember, I've integrated them.

01:08:58.609 --> 01:09:00.713
But what is the
quantity I'm summing?

01:09:00.713 --> 01:09:01.880
This is the important thing.

01:09:01.880 --> 01:09:04.729
The quantity I'm summing
is not the energy,

01:09:04.729 --> 01:09:08.420
it's the free energy of
the vibrations essentially.

01:09:08.420 --> 01:09:09.740
OK?

01:09:09.740 --> 01:09:14.300
So as you coarse-grain
in time, your Hamiltonian

01:09:14.300 --> 01:09:17.450
at the slower timescale is
essentially the free energy

01:09:17.450 --> 01:09:19.640
of the faster timescale.

01:09:19.640 --> 01:09:20.720
OK?

01:09:20.720 --> 01:09:21.290
Why?

01:09:21.290 --> 01:09:23.359
Because you
successively integrate.

01:09:23.359 --> 01:09:27.350
So in essence, if I sum
over lattice model stage

01:09:27.350 --> 01:09:30.260
and I put A's and B's on
different lattice positions,

01:09:30.260 --> 01:09:32.630
what this is telling you
is that the quantity--

01:09:32.630 --> 01:09:35.600
that's my Hamiltonian-- is
not the energy of that state.

01:09:35.600 --> 01:09:39.210
It's the vibrational free
energy of that state.

01:09:39.210 --> 01:09:42.140
So if I take that
as my Hamiltonian

01:09:42.140 --> 01:09:44.960
and then I do this
partition function,

01:09:44.960 --> 01:09:47.359
I will essentially
have an exact result.

01:09:47.359 --> 01:09:51.260
I will have the exact partition
function of the system.

01:09:51.260 --> 01:09:52.310
OK?

01:09:52.310 --> 01:09:54.590
And that's pretty amazing
because I've really

01:09:54.590 --> 01:09:58.460
sort of separated the timescale,
integrate over them separately,

01:09:58.460 --> 01:10:01.730
but I get what's
essentially still--

01:10:01.730 --> 01:10:05.840
it's an almost exact
result, because let's say

01:10:05.840 --> 01:10:07.590
I'm going to do it this way.

01:10:07.590 --> 01:10:09.530
So let's say on this
I do Monte Carlo now.

01:10:12.260 --> 01:10:15.170
There is a small assumption
that I've made in all of this.

01:10:18.530 --> 01:10:20.360
Think of the physical
picture here.

01:10:23.390 --> 01:10:25.970
Essentially what I'm
saying is that I got

01:10:25.970 --> 01:10:28.160
these A's and B's sitting on--

01:10:28.160 --> 01:10:30.018
you can't call them
exactly lattice site,

01:10:30.018 --> 01:10:32.060
but they're associated
with a given lattice site.

01:10:32.060 --> 01:10:35.090
They may be displaced from it,
and they sort of vibrate around

01:10:35.090 --> 01:10:37.640
and I integrate that
those vibrations to get

01:10:37.640 --> 01:10:38.870
the vibrational free energy.

01:10:38.870 --> 01:10:42.320
And then once in a while
they hop, exchange,

01:10:42.320 --> 01:10:46.490
and if I sample that that
gives me the free energy coming

01:10:46.490 --> 01:10:49.200
from that slower timescale.

01:10:49.200 --> 01:10:51.240
There's one assumption
I've made in all of this.

01:10:54.700 --> 01:10:59.070
It's sort of a subtle
one, but I've essentially

01:10:59.070 --> 01:11:03.460
assumed that the time
scales are uncoupled,

01:11:03.460 --> 01:11:05.572
and here you have to be
careful with what I say.

01:11:05.572 --> 01:11:07.030
I say the timescales
are uncoupled.

01:11:07.030 --> 01:11:09.070
I don't mean the
energetics is uncoupled.

01:11:09.070 --> 01:11:12.790
Obviously the
vibrational free energy

01:11:12.790 --> 01:11:14.510
depends on the configuration.

01:11:14.510 --> 01:11:16.390
If I arrange the
atoms differently

01:11:16.390 --> 01:11:18.250
over the lattice sites, I get
a different vibrational free

01:11:18.250 --> 01:11:18.750
energy.

01:11:18.750 --> 01:11:20.020
That's not the problem.

01:11:20.020 --> 01:11:25.100
I've assumed that you
can define a free energy.

01:11:25.100 --> 01:11:25.880
OK?

01:11:25.880 --> 01:11:28.050
That this thing exists.

01:11:28.050 --> 01:11:30.290
So what does that
physically mean?

01:11:30.290 --> 01:11:35.870
What I assume is that for a
given lattice model state,

01:11:35.870 --> 01:11:37.640
the system actually
waits long enough

01:11:37.640 --> 01:11:39.740
before it goes to the next one.

01:11:39.740 --> 01:11:42.920
If it actually only did
one vibration and bam,

01:11:42.920 --> 01:11:45.860
it goes to the other one,
then the system is not

01:11:45.860 --> 01:11:47.353
ergodic in its vibration.

01:11:47.353 --> 01:11:48.770
And what that means
is essentially

01:11:48.770 --> 01:11:50.390
it doesn't sample
all its vibrations

01:11:50.390 --> 01:11:53.490
before it goes
onto the next one.

01:11:53.490 --> 01:11:57.420
So it's the fact that I can
separate the excitation that

01:11:57.420 --> 01:11:59.070
really allows me to do this.

01:11:59.070 --> 01:12:04.110
Now in most materials, this
is no problem whatsoever.

01:12:04.110 --> 01:12:08.160
So vibrations, again, these are
timescale 10 to minus 11, 10

01:12:08.160 --> 01:12:12.090
to the minus 13 kind of range.

01:12:12.090 --> 01:12:14.610
The exchanges between
atoms on lattices

01:12:14.610 --> 01:12:17.130
depends on the
diffusion constant,

01:12:17.130 --> 01:12:20.310
but you're going
to be hard pressed

01:12:20.310 --> 01:12:22.950
to find any solid where
that happens faster

01:12:22.950 --> 01:12:26.950
than of a rate of, say, 10 to
the 4 per second, for example.

01:12:26.950 --> 01:12:28.590
10 to the 4, 10 to
the 5 per second.

01:12:28.590 --> 01:12:30.765
That's really fast diffusion.

01:12:30.765 --> 01:12:32.640
That gives you diffusion
constants of like 10

01:12:32.640 --> 01:12:35.400
to the minus 7, 10 to minus
8, which are very high.

01:12:35.400 --> 01:12:37.550
Extremely high.

01:12:37.550 --> 01:12:40.110
So at room temperature,
for a lot of--

01:12:40.110 --> 01:12:44.980
say for metals, this is well
below one hop per second.

01:12:44.980 --> 01:12:49.230
Fast conductors you start to
get to a few hops per second

01:12:49.230 --> 01:12:50.130
at room temperature.

01:12:50.130 --> 01:12:51.505
Then of course,
if you go higher,

01:12:51.505 --> 01:12:53.560
temperature goes faster,
but almost always are

01:12:53.560 --> 01:12:57.050
these timescales
extremely well separated.

01:12:57.050 --> 01:13:00.720
Places where they might not
be like fast proton motion.

01:13:00.720 --> 01:13:02.760
They might not be
very well separated

01:13:02.760 --> 01:13:04.500
and then this stuff breaks down.

01:13:04.500 --> 01:13:07.050
But remember, if they move
that fast, you should just

01:13:07.050 --> 01:13:10.050
do molecular dynamics because
then it's within the range.

01:13:10.050 --> 01:13:13.080
It's well within the scope
of molecular dynamics,

01:13:13.080 --> 01:13:17.380
and that's the perfect
approach at that point.

01:13:17.380 --> 01:13:17.880
OK.

01:13:42.680 --> 01:13:49.160
OK, let me do one more
thing and then we'll stop.

01:13:49.160 --> 01:13:51.680
There's a variety of
approximations you can do.

01:13:55.810 --> 01:13:59.140
Remember that your Hamiltonian
in your lattice model

01:13:59.140 --> 01:14:03.580
should be the free energy of
the higher order states, which

01:14:03.580 --> 01:14:07.000
are essentially the vibrational
and the electronic excitations

01:14:07.000 --> 01:14:09.640
that you've removed.

01:14:09.640 --> 01:14:13.600
Now in some cases
people say, I don't

01:14:13.600 --> 01:14:16.960
want to do all that
work of integrating

01:14:16.960 --> 01:14:18.850
over the electronic
states and integrating

01:14:18.850 --> 01:14:20.230
over the vibrational states.

01:14:20.230 --> 01:14:22.060
I'm going to
variationally remove

01:14:22.060 --> 01:14:25.030
them, which means I'm
going to find the lowest

01:14:25.030 --> 01:14:28.630
energy electronic states and
the lowest energy displacement

01:14:28.630 --> 01:14:30.770
state, delta ri state.

01:14:30.770 --> 01:14:31.390
OK?

01:14:31.390 --> 01:14:33.310
So I do that
practically while you

01:14:33.310 --> 01:14:35.350
take an arrangement
of atoms and you just

01:14:35.350 --> 01:14:38.830
relax them both the electronic
states and the positions

01:14:38.830 --> 01:14:43.220
to the minimum energy, and
that gives you some E value.

01:14:43.220 --> 01:14:44.960
So what it essentially
is is if you

01:14:44.960 --> 01:14:48.410
think of the F as the free
energy of an ensemble,

01:14:48.410 --> 01:14:52.820
the E you take is the lowest
energy value in that ensemble.

01:14:52.820 --> 01:14:55.280
So if you do that and then
you stick that in Monte Carlo,

01:14:55.280 --> 01:14:56.600
what do you have?

01:14:56.600 --> 01:14:58.610
You have proper
energetics and you only

01:14:58.610 --> 01:15:00.980
have configurational
entropy because rather

01:15:00.980 --> 01:15:03.560
than integrating all the
vibrations and the electronics

01:15:03.560 --> 01:15:08.950
states, you've taken the minimal
state out of that sub-ensemble.

01:15:08.950 --> 01:15:10.630
You'll integrate
over-- that means

01:15:10.630 --> 01:15:14.140
essentially your system
hasn't sampled excursions

01:15:14.140 --> 01:15:15.880
for those variables,
so you don't have

01:15:15.880 --> 01:15:17.960
entropy from those variables.

01:15:17.960 --> 01:15:20.270
OK?

01:15:20.270 --> 01:15:22.580
And then you can do all
kinds of approximation.

01:15:22.580 --> 01:15:25.940
You can say, well, I don't
care about the vibrations.

01:15:25.940 --> 01:15:27.650
I think that's too much work.

01:15:27.650 --> 01:15:29.743
I'm going to just get
the electronic entropy.

01:15:29.743 --> 01:15:31.910
And one of the reasons
electronic entropy and metals

01:15:31.910 --> 01:15:34.580
is easy, any time you
have delocalized states,

01:15:34.580 --> 01:15:36.028
you can write as
a simple integral

01:15:36.028 --> 01:15:37.820
over the density of
states, which you often

01:15:37.820 --> 01:15:40.470
have [INAUDIBLE] density
functional theory.

01:15:40.470 --> 01:15:43.040
So if you say I'm going
to take the minimal energy

01:15:43.040 --> 01:15:44.762
and the electronic
entropy, well then

01:15:44.762 --> 01:15:46.220
after you've done
your Monte Carlo,

01:15:46.220 --> 01:15:50.270
you have configurational
entropy and electronic entropy.

01:15:50.270 --> 01:15:54.230
And then if you want
to go all the way,

01:15:54.230 --> 01:15:56.653
rather than minimizing the
energy you integrate over

01:15:56.653 --> 01:15:58.070
to displacement,
then you're going

01:15:58.070 --> 01:16:00.910
to get the vibrational
entropy component as well.

01:16:07.180 --> 01:16:08.420
OK.

01:16:08.420 --> 01:16:10.420
I'm going to stop here
because the rest is going

01:16:10.420 --> 01:16:11.860
to take us a little too long.

01:16:11.860 --> 01:16:16.240
And so I'll pick some
of this up again.

01:16:16.240 --> 01:16:18.640
It's unfortunately almost
two weeks away from now,

01:16:18.640 --> 01:16:22.420
I think, because like I said,
so Tuesday's no lecture.

01:16:22.420 --> 01:16:25.592
Thursday-- oh, wait
Thursday's you, no?

01:16:25.592 --> 01:16:28.050
Yeah, so actually Thursday's
a lecture by Professor Marzari

01:16:28.050 --> 01:16:31.650
and then it's the next Tuesday's
the lab and then Thursday

01:16:31.650 --> 01:16:34.085
after that I pick
this up again and then

01:16:34.085 --> 01:16:35.460
I think we're in
May or something

01:16:35.460 --> 01:16:37.740
and we're almost over.

01:16:37.740 --> 01:16:40.530
Anyway, so have a good--

01:16:40.530 --> 01:16:42.030
what is this holiday again?

01:16:42.030 --> 01:16:42.770
[INAUDIBLE] Day?

01:16:42.770 --> 01:16:44.060
No?

01:16:44.060 --> 01:16:44.970
[INAUDIBLE] Day?

01:16:44.970 --> 01:16:45.540
OK.

01:16:45.540 --> 01:16:47.510
Watch the marathon.