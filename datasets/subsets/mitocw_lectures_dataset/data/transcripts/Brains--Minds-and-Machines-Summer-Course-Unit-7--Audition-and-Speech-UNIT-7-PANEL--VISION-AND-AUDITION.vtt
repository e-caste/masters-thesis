WEBVTT

00:00:01.680 --> 00:00:04.080
The following content is
provided under a Creative

00:00:04.080 --> 00:00:05.620
Commons license.

00:00:05.620 --> 00:00:07.920
Your support will help
MIT OpenCourseWare

00:00:07.920 --> 00:00:12.280
continue to offer high-quality
educational resources for free.

00:00:12.280 --> 00:00:14.910
To make a donation or
view additional materials

00:00:14.910 --> 00:00:18.760
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:18.760 --> 00:00:19.680
at ocw.MIT.edu.

00:00:23.030 --> 00:00:25.790
ALEX KELL: So, let's talk about
the historical arcs of vision

00:00:25.790 --> 00:00:27.410
and auditory sciences.

00:00:27.410 --> 00:00:29.930
In the mid 20th century,
auditory psychophysics was,

00:00:29.930 --> 00:00:33.049
like, a pretty robust
and diverse field.

00:00:33.049 --> 00:00:35.090
But currently there are
very few auditory faculty

00:00:35.090 --> 00:00:38.270
in psychology departments,
whereas, like, vision faculty

00:00:38.270 --> 00:00:40.457
are the cornerstone of
basically every psychology

00:00:40.457 --> 00:00:41.540
department in the country.

00:00:44.450 --> 00:00:46.619
In a similar vein,
automated speech recognition

00:00:46.619 --> 00:00:48.410
is this big fruitful
field, but there's not

00:00:48.410 --> 00:00:50.630
much kind of broader
automated sound recognition.

00:00:50.630 --> 00:00:53.054
In contrast, computer
vision is this huge field.

00:00:53.054 --> 00:00:54.845
So, I'm just kind of
wondering historically

00:00:54.845 --> 00:00:56.511
and sociologically,
how did we get here?

00:00:58.137 --> 00:01:00.220
JOSH TENENBAUM: You probably
talk about this more.

00:01:00.220 --> 00:01:03.240
JOSH MCDERMOTT: Sure, yeah.

00:01:03.240 --> 00:01:07.740
I'm happy to tell
you my take on this.

00:01:07.740 --> 00:01:09.150
Yes, so it's--

00:01:09.150 --> 00:01:11.520
I think there are really
interesting case studies

00:01:11.520 --> 00:01:13.830
in the history of science.

00:01:13.830 --> 00:01:19.350
If you go back to the
'50s, psychoacoustics

00:01:19.350 --> 00:01:22.280
was sort of a centerpiece
of psychology.

00:01:22.280 --> 00:01:24.470
And if you looked around
at, like, you know,

00:01:24.470 --> 00:01:28.170
the top universities, they
all had really good people

00:01:28.170 --> 00:01:29.250
studying hearing.

00:01:29.250 --> 00:01:32.640
And even some of the names that
you know, like Green and Swets,

00:01:32.640 --> 00:01:35.430
you know, the guys that invented
signal detection theory, pretty

00:01:35.430 --> 00:01:36.200
much.

00:01:36.200 --> 00:01:38.060
They were psychoacousticians.

00:01:38.060 --> 00:01:40.000
People often forget that.

00:01:40.000 --> 00:01:41.460
But they literally
wrote the book

00:01:41.460 --> 00:01:42.585
on signal detection theory.

00:01:44.514 --> 00:01:45.930
JOSH TENENBAUM:
When people talked

00:01:45.930 --> 00:01:48.596
about separating signal from the
noise, they meant actual noise.

00:01:51.240 --> 00:01:55.380
JOSH MCDERMOTT: Yeah, and there
was this famous psychoacoustics

00:01:55.380 --> 00:01:59.150
lab at Harvard that everybody
kind of passed through.

00:01:59.150 --> 00:02:02.580
So back then, what
constituted psychology

00:02:02.580 --> 00:02:04.080
was something pretty different.

00:02:04.080 --> 00:02:06.205
And it was really kind of
closely related to things

00:02:06.205 --> 00:02:07.690
like signal detection theory.

00:02:07.690 --> 00:02:10.620
And it was pretty low level
by the standards of today.

00:02:10.620 --> 00:02:14.580
And what happened over time is
that hearing kind of gradually

00:02:14.580 --> 00:02:18.360
drifted out of
psychology departments

00:02:18.360 --> 00:02:21.370
and vision became more
and more prominent.

00:02:21.370 --> 00:02:23.580
I think the reason for
this is that there's

00:02:23.580 --> 00:02:25.890
one really important-- there
are several forces here,

00:02:25.890 --> 00:02:30.480
but one really important factor
is that hearing impairment

00:02:30.480 --> 00:02:34.650
is something that really
involves abnormal functioning

00:02:34.650 --> 00:02:36.430
at the level of the cochlea.

00:02:36.430 --> 00:02:38.160
So the actual signal
processing that's

00:02:38.160 --> 00:02:39.826
being done at the
cochlea really changes

00:02:39.826 --> 00:02:41.610
when people start to
lose their hearing.

00:02:41.610 --> 00:02:44.040
And so there's always
been pretty strong

00:02:44.040 --> 00:02:47.006
impetus coming, in
part, from the NIH

00:02:47.006 --> 00:02:48.630
to try to understand
hearing impairment

00:02:48.630 --> 00:02:49.950
and to know how to treat that.

00:02:49.950 --> 00:02:54.840
And knowing what
happens at the front end

00:02:54.840 --> 00:02:56.550
of the auditory
system really has been

00:02:56.550 --> 00:02:58.400
critical to making that work.

00:02:58.400 --> 00:03:01.220
In contrast, most
vision impairments

00:03:01.220 --> 00:03:03.450
are optical in nature, and
you fix them with glasses.

00:03:03.450 --> 00:03:03.630
Right?

00:03:03.630 --> 00:03:05.010
So it's not like
studying vision is really

00:03:05.010 --> 00:03:07.140
going to help you understand
visual impairment.

00:03:07.140 --> 00:03:09.056
And so there was never
really that same thing.

00:03:09.056 --> 00:03:11.799
And so, when psychology
sort of gradually

00:03:11.799 --> 00:03:13.590
got more and more
cognitive, vision science

00:03:13.590 --> 00:03:14.515
went along with it.

00:03:14.515 --> 00:03:16.140
That really didn't
happen with hearing.

00:03:16.140 --> 00:03:18.240
And I think part of that
was the clinical impetus

00:03:18.240 --> 00:03:20.769
to try to continue to
understand the periphery.

00:03:20.769 --> 00:03:22.560
The auditory periphery
was also just harder

00:03:22.560 --> 00:03:24.990
to work out, because it's a
mechanical device, the cochlea.

00:03:24.990 --> 00:03:26.940
And so you can't just
stick an electrode into it

00:03:26.940 --> 00:03:27.773
and characterize it.

00:03:27.773 --> 00:03:30.330
It's actually really
technically challenging

00:03:30.330 --> 00:03:32.260
to work out what's happening.

00:03:32.260 --> 00:03:35.560
And so that just kept people
busy for a very long time.

00:03:35.560 --> 00:03:38.094
But as psychology was
sort of advancing,

00:03:38.094 --> 00:03:40.260
what people in hearing
science were studying kind of

00:03:40.260 --> 00:03:41.700
ceased to really be
what psychologists

00:03:41.700 --> 00:03:42.360
found interesting.

00:03:42.360 --> 00:03:44.943
And so the field kind of dropped
out of psychology departments

00:03:44.943 --> 00:03:46.715
and moved into speech
and hearing science

00:03:46.715 --> 00:03:48.090
departments, which
were typically

00:03:48.090 --> 00:03:50.380
at bigger state schools.

00:03:50.380 --> 00:03:54.780
And they never really got
on the cognitive bandwagon

00:03:54.780 --> 00:03:57.930
in the same way that
everybody in vision did.

00:03:57.930 --> 00:03:59.790
And then what ends up
happening in science

00:03:59.790 --> 00:04:02.686
is there's this interesting
phenomenon where people

00:04:02.686 --> 00:04:04.560
get trained in fields
where there are already

00:04:04.560 --> 00:04:05.820
lots of scientists.

00:04:05.820 --> 00:04:07.887
So if you're a grad student,
you need an advisor,

00:04:07.887 --> 00:04:09.720
and so you often end
up working on something

00:04:09.720 --> 00:04:10.759
that your advisor does.

00:04:10.759 --> 00:04:13.050
And so if there's some field
that is under-represented,

00:04:13.050 --> 00:04:16.019
it typically gets
more under-represented

00:04:16.019 --> 00:04:17.860
as time goes on.

00:04:17.860 --> 00:04:20.500
And so that's sort
of been the case.

00:04:20.500 --> 00:04:23.049
You know, if you want to
study, you know, olfaction,

00:04:23.049 --> 00:04:24.090
it's a great idea, right?

00:04:24.090 --> 00:04:25.230
But how are you going to do it?

00:04:25.230 --> 00:04:26.938
You've got to find
somebody to work with.

00:04:28.337 --> 00:04:30.420
There's not many places
you can go to get trained.

00:04:30.420 --> 00:04:32.711
And the same has been true
for hearing for a long time.

00:04:32.711 --> 00:04:35.037
So that's my take
on that part of it.

00:04:35.037 --> 00:04:37.370
Hynek, do you have anything
to say on the computational?

00:04:37.370 --> 00:04:39.150
HYNEK HERMANSKY:
No, I don't know.

00:04:39.150 --> 00:04:42.450
I'm thinking, if it
is something that also

00:04:42.450 --> 00:04:43.980
evolved with tools available.

00:04:43.980 --> 00:04:48.030
Because in the old days it was
easier to generate the sounds

00:04:48.030 --> 00:04:49.710
than to generate images.

00:04:49.710 --> 00:04:53.600
On the computer now,
it's much easier, right?

00:04:53.600 --> 00:04:57.690
So vision and visual
research became sexier.

00:04:57.690 --> 00:05:02.030
So I teach auditory
perception to engineers.

00:05:02.030 --> 00:05:04.110
Also I teach a little
bit of visual perception.

00:05:04.110 --> 00:05:05.610
And I notice that
they are much more

00:05:05.610 --> 00:05:10.090
interested in visual perception,
especially the various effects.

00:05:10.090 --> 00:05:14.140
And, you know, because
somehow you can see it better.

00:05:14.140 --> 00:05:16.590
And the other thing
is, of course, funding.

00:05:16.590 --> 00:05:21.900
I mean, you know, the hearing
research's main applications

00:05:21.900 --> 00:05:24.390
are, as you said,
hearing prostheses.

00:05:24.390 --> 00:05:26.576
These people don't
have much money, right?

00:05:26.576 --> 00:05:30.180
The speech recognition, we
didn't get much of the benefits

00:05:30.180 --> 00:05:33.960
yet from hearing
research, unfortunately.

00:05:33.960 --> 00:05:39.440
So I wonder if this is
not also a little bit--

00:05:39.440 --> 00:05:42.210
JOSH TENENBAUM: Can I add one?

00:05:42.210 --> 00:05:44.580
So, maybe-- this is sort of
things you guys also gesture

00:05:44.580 --> 00:05:46.495
towards, but I think in both--

00:05:46.495 --> 00:05:48.870
to go back towards similarities
and not just differences.

00:05:48.870 --> 00:05:51.900
Maybe that's what
will be my theme.

00:05:51.900 --> 00:05:54.480
In both vision and
hearing or audition,

00:05:54.480 --> 00:05:56.610
there's, I think, a strong
bias towards the aspects

00:05:56.610 --> 00:05:59.390
of the problem that fit
with the rest of cognition.

00:05:59.390 --> 00:06:01.269
And often that's mediated
by language, right?

00:06:01.269 --> 00:06:03.060
So there's been a lot
of interest in vision

00:06:03.060 --> 00:06:05.624
on object recognition, parts
of vision that ultimately

00:06:05.624 --> 00:06:07.040
lead into something
like attaching

00:06:07.040 --> 00:06:09.770
a word to a part of
an image or a scene.

00:06:09.770 --> 00:06:11.600
And there's a lot of
other parts of vision,

00:06:11.600 --> 00:06:13.558
like certain kinds of
scene understanding, that

00:06:13.558 --> 00:06:16.910
have been way understudied
until recently also, right?

00:06:16.910 --> 00:06:19.759
And it does seem like
the parts of hearing that

00:06:19.759 --> 00:06:21.050
have been the focus are speech.

00:06:21.050 --> 00:06:22.880
I mean, there are
lots of people in--

00:06:22.880 --> 00:06:25.220
it's maybe not as much as
vision or object recognition,

00:06:25.220 --> 00:06:27.860
but certainly there's a lot of
mainline cognitive psychology

00:06:27.860 --> 00:06:31.009
who studied things like
categorization of basic speech

00:06:31.009 --> 00:06:33.050
elements and things that
just start to bleed very

00:06:33.050 --> 00:06:36.210
quickly into psycholinguistics.

00:06:36.210 --> 00:06:36.710
Right?

00:06:36.710 --> 00:06:38.814
Whereas, the parts of hearing--

00:06:38.814 --> 00:06:40.730
at least that's been
where a lot of the focus.

00:06:40.730 --> 00:06:41.660
But the parts of
hearing that are

00:06:41.660 --> 00:06:43.190
more about auditory
scene analysis

00:06:43.190 --> 00:06:45.680
in general, like sound
textures or physical events

00:06:45.680 --> 00:06:47.450
or all the richness
of the world that we

00:06:47.450 --> 00:06:50.870
might get through sound,
has been super understudied.

00:06:50.870 --> 00:06:53.120
Right?

00:06:53.120 --> 00:06:55.700
But echoing something Josh
said also or implicitly is,

00:06:55.700 --> 00:06:58.575
just because it
might be understudied

00:06:58.575 --> 00:07:00.200
and you need to find
an advisor doesn't

00:07:00.200 --> 00:07:01.590
mean you shouldn't work on it.

00:07:01.590 --> 00:07:03.440
So if you have any
interested in this,

00:07:03.440 --> 00:07:04.815
and there's even
one person, say,

00:07:04.815 --> 00:07:07.315
who's doing some good work on
it, you should work with them.

00:07:07.315 --> 00:07:08.576
And it's a great opportunity.

00:07:08.576 --> 00:07:10.617
JOSH MCDERMOTT: If I could
follow up and just say

00:07:10.617 --> 00:07:13.982
that my sense of this is,
if you can bear with it

00:07:13.982 --> 00:07:16.190
and figure out a way to make
it work, in the long run

00:07:16.190 --> 00:07:17.620
it's actually a
great place to be.

00:07:17.620 --> 00:07:19.953
It's a lot of fun to work in
an area that's not crowded.

00:07:25.700 --> 00:07:27.410
ALEX KELL: All right.

00:07:27.410 --> 00:07:30.894
Obviously, a large-- to kind
of transition, a large emphasis

00:07:30.894 --> 00:07:32.810
of the summer school is
on potential symbiosis

00:07:32.810 --> 00:07:37.950
between, like, machine and,
like, engineering and science.

00:07:37.950 --> 00:07:42.440
And so, what have been the most
kind of fruitful interactions

00:07:42.440 --> 00:07:45.289
between machine perception,
either vision or hearing,

00:07:45.289 --> 00:07:47.330
over the years, and are
there any kind of lessons

00:07:47.330 --> 00:07:48.539
that we can learn in general?

00:07:48.539 --> 00:07:50.913
HYNEK HERMANSKY: You know, I
went a little bit backwards,

00:07:50.913 --> 00:07:51.860
quite frankly.

00:07:51.860 --> 00:07:55.400
I'm trained as an engineer,
and I was paid always

00:07:55.400 --> 00:07:57.260
to build better machines.

00:07:57.260 --> 00:07:59.630
And in the process of
building better machines,

00:07:59.630 --> 00:08:03.140
you discover that, almost
unknowingly, we were emulating

00:08:03.140 --> 00:08:04.490
some properties of hearing.

00:08:04.490 --> 00:08:07.760
So then I, of course,
started to be interested,

00:08:07.760 --> 00:08:10.340
and I wanted to get more of it.

00:08:10.340 --> 00:08:12.570
So that's how I got into that.

00:08:12.570 --> 00:08:16.130
But I have to admit
that in my field,

00:08:16.130 --> 00:08:17.780
we are a little
bit looked down at.

00:08:17.780 --> 00:08:19.860
[INTERPOSING VOICES]

00:08:19.860 --> 00:08:23.150
HYNEK HERMANSKY: Because
mainly not all that much,

00:08:23.150 --> 00:08:26.180
because engineers are such that
[INAUDIBLE] that if something

00:08:26.180 --> 00:08:30.350
works, they like it and they
don't much want to know why,

00:08:30.350 --> 00:08:30.850
you know?

00:08:30.850 --> 00:08:33.409
Or at least they don't
talk much about it.

00:08:33.409 --> 00:08:37.429
So it's interesting when
I'm in engineering meetings,

00:08:37.429 --> 00:08:41.090
they look at me as this strange
kid who works also on hearing.

00:08:41.090 --> 00:08:43.747
And when I'm in an
environment like this,

00:08:43.747 --> 00:08:45.455
people look at me like
a speech engineer.

00:08:45.455 --> 00:08:50.180
But, I mean, I don't even
feel either in some ways.

00:08:50.180 --> 00:08:53.510
But what I was wondering
when Josh was talking about,

00:08:53.510 --> 00:08:57.350
is there anybody in this
world who works on both?

00:08:57.350 --> 00:08:58.760
Because, you know,
that, I think,

00:08:58.760 --> 00:09:01.250
is much more needed
than anything else.

00:09:01.250 --> 00:09:03.920
I mean, somebody
who is interested

00:09:03.920 --> 00:09:07.400
in both audio and
visual processing

00:09:07.400 --> 00:09:10.339
and is capable of making this--

00:09:10.339 --> 00:09:12.505
JOSH TENENBAUM: So not both
science and engineering,

00:09:12.505 --> 00:09:13.940
but both vision and audition.

00:09:13.940 --> 00:09:15.315
HYNEK HERMANSKY:
Yes, that's what

00:09:15.315 --> 00:09:18.290
I mean, vision and audition,
with a real goal of trying

00:09:18.290 --> 00:09:21.530
to understand both and trying
to find the similarities.

00:09:21.530 --> 00:09:24.710
Because, personally,
I got some inspiration

00:09:24.710 --> 00:09:31.730
from visual research, even
when I work with audio.

00:09:31.730 --> 00:09:33.510
But I don't see
much of it anymore.

00:09:33.510 --> 00:09:36.230
And there are some basic
questions which I would like

00:09:36.230 --> 00:09:38.680
to ask-- and maybe I
should have sent it in--

00:09:38.680 --> 00:09:41.750
which is like, I
don't even know which

00:09:41.750 --> 00:09:45.520
most are the similar and
different in audio and vision.

00:09:45.520 --> 00:09:48.680
Should I look at time?

00:09:48.680 --> 00:09:50.780
Should I look at modulations?

00:09:50.780 --> 00:09:53.150
Should I look at
the frequencies?

00:09:53.150 --> 00:09:55.920
Should I look at the
spatial resolution?

00:09:55.920 --> 00:09:56.930
And so on and so on.

00:09:56.930 --> 00:10:00.300
So I don't know if somebody
can help me with this.

00:10:00.300 --> 00:10:03.560
I would be very happy
to go home knowing that.

00:10:03.560 --> 00:10:07.070
I mean, sometimes I suspect
that spatial resolution

00:10:07.070 --> 00:10:10.550
and frequency resolution
in hearing are similar.

00:10:10.550 --> 00:10:12.980
I'm thinking about
modulations in speech.

00:10:12.980 --> 00:10:14.740
Josh talked a lot about it.

00:10:14.740 --> 00:10:17.390
But there must be a
modulation in vision also.

00:10:17.390 --> 00:10:20.120
But, of course, we never
studied much of the vision

00:10:20.120 --> 00:10:21.680
of the moving pictures.

00:10:21.680 --> 00:10:25.100
A lot of vision
research was fixed.

00:10:25.100 --> 00:10:27.800
Basically, the images, right?

00:10:27.800 --> 00:10:30.260
It was a little bit
like, in speech, we

00:10:30.260 --> 00:10:32.490
used to study vowels.

00:10:32.490 --> 00:10:34.720
We don't do it anymore,
because the area of speech

00:10:34.720 --> 00:10:36.720
is something very,
very different.

00:10:36.720 --> 00:10:38.980
The same thing is
in image processing.

00:10:38.980 --> 00:10:41.540
I think that now it's getting
more and more, because, again,

00:10:41.540 --> 00:10:45.080
I mean I'm going back to
availability of the machines.

00:10:45.080 --> 00:10:49.970
You can do some work on
moving images and on video

00:10:49.970 --> 00:10:51.580
and so on and so on.

00:10:51.580 --> 00:10:53.870
But I don't know how much
of that is happening.

00:10:53.870 --> 00:10:57.020
And so my question is really,
are there any similarities,

00:10:57.020 --> 00:10:58.700
and on which level they are?

00:10:58.700 --> 00:11:03.230
[INAUDIBLE] There is a time,
there is a spatial frequency,

00:11:03.230 --> 00:11:05.140
there is a carrier
frequency, there

00:11:05.140 --> 00:11:07.800
are modulations in speech.

00:11:07.800 --> 00:11:08.660
I don't know.

00:11:08.660 --> 00:11:10.220
I mean, I would
like to know this.

00:11:10.220 --> 00:11:12.560
I mean, that's something
somebody can help me.

00:11:16.230 --> 00:11:17.270
DAN YAMINS: Oh, I was--

00:11:17.270 --> 00:11:19.269
I had-- I think those are
interesting questions,

00:11:19.269 --> 00:11:20.120
but I actually--

00:11:20.120 --> 00:11:22.180
I'm sure I don't have the
answers at this point.

00:11:22.180 --> 00:11:24.741
But I was going to say
something a little--

00:11:24.741 --> 00:11:26.990
you know, going back to the
original general question,

00:11:26.990 --> 00:11:28.390
which is, again,
you know, this sort

00:11:28.390 --> 00:11:29.890
of thinking about it from
a historical point of view

00:11:29.890 --> 00:11:31.000
I think is helpful.

00:11:31.000 --> 00:11:35.110
In the long run, I think what's
happened over the past 50

00:11:35.110 --> 00:11:37.960
years is that biological
inspiration has been very

00:11:37.960 --> 00:11:42.640
helpful at injecting ideas
into the engineering realm that

00:11:42.640 --> 00:11:44.090
end up being very powerful.

00:11:44.090 --> 00:11:44.590
Right?

00:11:44.590 --> 00:11:47.920
I mean, I think we're seeing
kind of the arc of that right

00:11:47.920 --> 00:11:49.690
now in a very strong way.

00:11:49.690 --> 00:11:53.770
I mean, you know, in terms
of vision and audition,

00:11:53.770 --> 00:11:57.460
the sort of algorithms
that are most dominant

00:11:57.460 --> 00:12:00.567
are ones that were strongly
biologically inspired.

00:12:00.567 --> 00:12:02.650
And there had been a
historical arc over, I think,

00:12:02.650 --> 00:12:05.110
a period of decades, where,
first the algorithms were sort

00:12:05.110 --> 00:12:08.680
of biologically inspired
back in the '50s and '60s,

00:12:08.680 --> 00:12:10.900
and then they were not
biologically inspired

00:12:10.900 --> 00:12:11.410
for a while.

00:12:11.410 --> 00:12:14.170
Like, the biology stuff
didn't seem to be panning out.

00:12:14.170 --> 00:12:19.240
That was sort of the dark ages
of, kind of, neural networks.

00:12:19.240 --> 00:12:21.400
And then more recently
that has begun to change.

00:12:21.400 --> 00:12:23.230
And, again, biologically
inspired ideas

00:12:23.230 --> 00:12:27.850
seem to be very powerful,
for creating, you know,

00:12:27.850 --> 00:12:29.170
algorithmic approaches.

00:12:29.170 --> 00:12:31.600
But the arc is a
very long one, right?

00:12:31.600 --> 00:12:34.030
And so it's not like, you
know, you discover something

00:12:34.030 --> 00:12:35.740
in the lab and then
the next day you

00:12:35.740 --> 00:12:37.510
would go implement
it in your algorithm

00:12:37.510 --> 00:12:40.240
and suddenly you get 20%
improvement on some task.

00:12:40.240 --> 00:12:40.740
All right?

00:12:40.740 --> 00:12:41.950
That's not realistic.

00:12:41.950 --> 00:12:42.910
OK?

00:12:42.910 --> 00:12:45.070
But if you're willing
to have the patience

00:12:45.070 --> 00:12:48.830
to wait for a while, and sort of
see ideas sort of slowly percol

00:12:48.830 --> 00:12:50.420
up, I think they can
be very powerful.

00:12:50.420 --> 00:12:52.794
Now, the other direction is
really also very interesting,

00:12:52.794 --> 00:12:55.907
like using the algorithms to
understand neuroscience, right?

00:12:55.907 --> 00:12:58.240
That's one where you can get
a lot of bang for your buck

00:12:58.240 --> 00:12:59.500
quickly, right?

00:12:59.500 --> 00:13:02.931
And it's sort of like-- it's
like that's a short-term high,

00:13:02.931 --> 00:13:03.430
right?

00:13:03.430 --> 00:13:06.220
Because what happens is that
you take this machine that you

00:13:06.220 --> 00:13:08.440
didn't understand and you
apply it to this problem

00:13:08.440 --> 00:13:09.630
that you were worried
about and that

00:13:09.630 --> 00:13:11.350
is sort of scientifically
interesting,

00:13:11.350 --> 00:13:13.640
and suddenly you get 20%
improvement overnight.

00:13:13.640 --> 00:13:14.140
Right?

00:13:14.140 --> 00:13:16.090
That is feasible in
that direction, e.g.,

00:13:16.090 --> 00:13:19.320
taking advances from
the computational side

00:13:19.320 --> 00:13:21.550
or on the algorithmic
side and applying them

00:13:21.550 --> 00:13:23.380
to understanding
data in neuroscience.

00:13:23.380 --> 00:13:26.140
That does seem to have
been borne out, but only

00:13:26.140 --> 00:13:27.130
much more recently.

00:13:27.130 --> 00:13:30.550
So, there wasn't much of
that at all for many decades.

00:13:30.550 --> 00:13:32.720
But more recently that
has begun to happen.

00:13:32.720 --> 00:13:35.350
And so I think that there
is a really interesting

00:13:35.350 --> 00:13:38.800
open question right now as to
which thing, which direction,

00:13:38.800 --> 00:13:40.297
is more live.

00:13:40.297 --> 00:13:42.130
Which one is leading
at this point, I think,

00:13:42.130 --> 00:13:43.060
is a really
interesting question.

00:13:43.060 --> 00:13:43.990
Maybe neither of
them is leading.

00:13:43.990 --> 00:13:46.446
But I think that certainly on
the everyday, on-the-ground

00:13:46.446 --> 00:13:48.820
experience, as somebody who
is trying to do some of both,

00:13:48.820 --> 00:13:51.190
it feels like the algorithms
are leading the biology.

00:13:51.190 --> 00:13:51.690
OK?

00:13:51.690 --> 00:13:53.731
Are leading the neuroscience,
to me, in the sense

00:13:53.731 --> 00:13:57.619
that I feel like, in
the short run at least,

00:13:57.619 --> 00:14:00.160
things are going to come out of
the community of people doing

00:14:00.160 --> 00:14:02.493
algorithms development that
are going to help understand

00:14:02.493 --> 00:14:04.957
neuroscience data
before specific things

00:14:04.957 --> 00:14:07.290
are going to come out of the
neuroscience community that

00:14:07.290 --> 00:14:08.560
are going to help make
better algorithms,

00:14:08.560 --> 00:14:09.820
like in the short run.

00:14:09.820 --> 00:14:10.330
OK?

00:14:10.330 --> 00:14:12.204
Again, I think the long
run can be different.

00:14:12.204 --> 00:14:15.340
And I think that's a really
deep open research program

00:14:15.340 --> 00:14:18.640
question, is which tasks are
the ones that you should choose

00:14:18.640 --> 00:14:21.270
such that learning about
them from a neuroscience

00:14:21.270 --> 00:14:23.770
and psychology point of
view will help, in the five-

00:14:23.770 --> 00:14:25.487
to 10-year run, make
better algorithms.

00:14:25.487 --> 00:14:27.070
And if you can choose
those correctly,

00:14:27.070 --> 00:14:29.180
I think you really have
done something valuable.

00:14:29.180 --> 00:14:31.154
But I think that's really hard.

00:14:31.154 --> 00:14:31.820
ALEX KELL: Yeah.

00:14:31.820 --> 00:14:32.550
I want to push back.

00:14:32.550 --> 00:14:34.591
I like how you said how
the engineering is really

00:14:34.591 --> 00:14:37.150
helping the science right
now, but the science--

00:14:37.150 --> 00:14:40.240
the seed that science
planted in the engineering.

00:14:40.240 --> 00:14:43.000
Like, what you're talking
about is just CNNs, basically.

00:14:43.000 --> 00:14:43.930
DAN YAMINS: Well, I
think not entirely,

00:14:43.930 --> 00:14:45.190
because I think that
there are some ideas

00:14:45.190 --> 00:14:46.330
in recurrent neural networks.

00:14:46.330 --> 00:14:46.780
ALEX KELL: OK, sure.

00:14:46.780 --> 00:14:47.863
Neural networks generally.

00:14:47.863 --> 00:14:51.177
But the point is the ideas
that were kind of inspired

00:14:51.177 --> 00:14:53.260
from that have been around
for decades and decades

00:14:53.260 --> 00:14:53.760
and decades.

00:14:53.760 --> 00:14:56.410
Are there other kinds
of key examples besides,

00:14:56.410 --> 00:15:00.475
like, the operations that
you throw into a CNN?

00:15:00.475 --> 00:15:02.080
The idea of convolution
and the idea

00:15:02.080 --> 00:15:04.371
of layered computation--
these are obviously very, very

00:15:04.371 --> 00:15:07.390
important ideas, but, like, what
are kind of other contributions

00:15:07.390 --> 00:15:09.480
that science has given
engineering besides--?

00:15:09.480 --> 00:15:11.420
DAN YAMINS: Well,
Green and Swets.

00:15:11.420 --> 00:15:12.190
I mean, the thing
that he mentioned

00:15:12.190 --> 00:15:14.130
earlier about Green and Swets
is another great example.

00:15:14.130 --> 00:15:14.530
ALEX KELL: Yeah.

00:15:14.530 --> 00:15:15.321
DAN YAMINS: Right.?

00:15:15.321 --> 00:15:17.730
Psychophysics helped understand
signal detection theory.

00:15:17.730 --> 00:15:20.304
But that's much older, but
that's a very clear example.

00:15:20.304 --> 00:15:21.970
HYNEK HERMANSKY:
Signal detection theory

00:15:21.970 --> 00:15:23.510
didn't come from
Green and Swets.

00:15:23.510 --> 00:15:26.469
It came from Second World War.

00:15:26.469 --> 00:15:28.510
DAN YAMINS: I was just
thinking of all the work--

00:15:28.510 --> 00:15:30.850
HYNEK HERMANSKY: They did
very good work obviously,

00:15:30.850 --> 00:15:33.160
and they indeed were
auditory people.

00:15:33.160 --> 00:15:34.900
DAN YAMINS: And
they were actually--

00:15:34.900 --> 00:15:36.670
they were doing a
lot of work during--

00:15:36.670 --> 00:15:37.460
government--

00:15:37.460 --> 00:15:38.320
JOSH MCDERMOTT: They
formalized a lot of stuff.

00:15:38.320 --> 00:15:39.370
DAN YAMINS: Yeah,
and they did a lot--

00:15:39.370 --> 00:15:40.859
HYNEK HERMANSKY: Yeah, I don't
want to take anything away

00:15:40.859 --> 00:15:41.500
from them.

00:15:41.500 --> 00:15:42.130
DAN YAMINS: But, you
know, it's interesting.

00:15:42.130 --> 00:15:43.600
There's this great paper
that Green and Swets have

00:15:43.600 --> 00:15:44.570
where they talked about their--

00:15:44.570 --> 00:15:45.760
HYNEK HERMANSKY:
--was engineering.

00:15:45.760 --> 00:15:48.070
DAN YAMINS: They talked about
their military work, right?

00:15:48.070 --> 00:15:49.700
And they did-- they actually
worked for the military,

00:15:49.700 --> 00:15:51.220
just, like, determining
which type of plane

00:15:51.220 --> 00:15:53.290
was the one that they
were going to be facing.

00:15:53.290 --> 00:15:55.230
And so, yeah, I agree
that came out of that.

00:15:55.230 --> 00:15:57.396
HYNEK HERMANSKY: If I want
to still-- if I can still

00:15:57.396 --> 00:16:00.740
spend a little bit of time on
engineering versus science,

00:16:00.740 --> 00:16:02.260
we also are missing
one big thing,

00:16:02.260 --> 00:16:04.000
which is, like, Bell Labs.

00:16:04.000 --> 00:16:08.890
Bell Labs was the organization
which paid people for doing--

00:16:08.890 --> 00:16:09.670
having fun.

00:16:09.670 --> 00:16:11.470
Doing really good research.

00:16:11.470 --> 00:16:13.790
There was no question
that, at the time,

00:16:13.790 --> 00:16:16.630
Bell Labs were about
speech and about audio.

00:16:16.630 --> 00:16:19.180
So there was-- a lot of
things were justified.

00:16:19.180 --> 00:16:22.240
And even, like, Bela
Julesz and these people--

00:16:22.240 --> 00:16:24.310
they pretended they are
working on perception

00:16:24.310 --> 00:16:26.860
because the company
wanted to make more

00:16:26.860 --> 00:16:28.550
money on the telephone calls.

00:16:28.550 --> 00:16:29.331
This has gone.

00:16:29.331 --> 00:16:29.830
Right?

00:16:29.830 --> 00:16:30.330
Both.

00:16:30.330 --> 00:16:32.530
Speech is gone.

00:16:32.530 --> 00:16:33.490
Bell Labs is gone.

00:16:33.490 --> 00:16:35.780
And maybe image is high--

00:16:35.780 --> 00:16:38.410
image processing is in,
because the government

00:16:38.410 --> 00:16:42.070
is interested in finding
various things from the images

00:16:42.070 --> 00:16:43.520
and so on and so on.

00:16:43.520 --> 00:16:47.890
So, a lot of that is funding.

00:16:47.890 --> 00:16:49.960
Since you mentioned
neural networks,

00:16:49.960 --> 00:16:52.330
it never stops
amazing me that people

00:16:52.330 --> 00:16:55.600
would call artificial
neural networks anything

00:16:55.600 --> 00:16:57.130
similar to biology.

00:16:57.130 --> 00:17:00.580
I mean, the only thing which
I see similar there maybe

00:17:00.580 --> 00:17:03.056
are now these layered networks
and that sort of things.

00:17:03.056 --> 00:17:05.680
ALEX KELL: I think a lot of the
concepts were inspired by that.

00:17:05.680 --> 00:17:06.970
I don't think it was,
like, directly-- like,

00:17:06.970 --> 00:17:09.053
I don't think anyone takes
it as a super serious--

00:17:09.053 --> 00:17:12.310
HYNEK HERMANSKY: But there
I still have maybe one point

00:17:12.310 --> 00:17:13.119
to make.

00:17:13.119 --> 00:17:15.310
Most of the ideas
which are now being

00:17:15.310 --> 00:17:19.130
explored in neural
networks are also very old.

00:17:19.130 --> 00:17:21.849
The only thing is that we
didn't have the hardware.

00:17:21.849 --> 00:17:24.940
We didn't have the means,
basically, of doing so.

00:17:24.940 --> 00:17:28.119
So technology really
supported this,

00:17:28.119 --> 00:17:30.370
and suddenly,
yeah, it's working.

00:17:30.370 --> 00:17:33.850
But to some people it's not even
surprising that it's working.

00:17:33.850 --> 00:17:35.020
They say, of course.

00:17:35.020 --> 00:17:36.400
They say, we couldn't do it.

00:17:36.400 --> 00:17:38.358
DAN YAMINS: I think what
was surprising to them

00:17:38.358 --> 00:17:39.850
was that it didn't
work for so long

00:17:39.850 --> 00:17:42.261
and that people were very
disappointed and upset

00:17:42.261 --> 00:17:42.760
about that.

00:17:42.760 --> 00:17:44.310
And then, you know--

00:17:44.310 --> 00:17:46.480
but I agree that basically
there's all these, like--

00:17:46.480 --> 00:17:48.640
all the ideas are these
40-year-old or 50-year-old

00:17:48.640 --> 00:17:50.710
ideas that people
had thought of,

00:17:50.710 --> 00:17:52.990
typically many of them
coming out of the psychology

00:17:52.990 --> 00:17:56.230
and neuroscience community
a long time ago but just

00:17:56.230 --> 00:17:57.630
couldn't do anything about it.

00:17:57.630 --> 00:18:02.317
And so that takes a long time
to bear fruit, it feels like.

00:18:02.317 --> 00:18:04.900
GABRIEL KREIMAN: So I have more
questions rather than answers,

00:18:04.900 --> 00:18:08.170
but to try to get back to
a question about vision

00:18:08.170 --> 00:18:10.930
and hearing and how
we can synergistically

00:18:10.930 --> 00:18:13.790
interact between the two.

00:18:13.790 --> 00:18:17.620
First, I wanted to lay out a
couple of biases and almost

00:18:17.620 --> 00:18:22.600
religious beliefs I have on the
notion that cortex is cortex,

00:18:22.600 --> 00:18:24.640
meaning that there's
a six-layer structure,

00:18:24.640 --> 00:18:27.100
that there are some patterns
of connectivity that have been

00:18:27.100 --> 00:18:29.170
described both in the vision--

00:18:29.170 --> 00:18:31.740
visual cortex as well
as auditory cortex.

00:18:31.740 --> 00:18:33.400
They are remarkably
similar, and we

00:18:33.400 --> 00:18:37.060
have to work with the same
type of hardware in both cases.

00:18:37.060 --> 00:18:40.420
The type of plasticity learning
rules that have been described

00:18:40.420 --> 00:18:41.930
are very similar in both cases.

00:18:41.930 --> 00:18:43.750
So there's a huge
amount of similarity

00:18:43.750 --> 00:18:45.640
to the biological level.

00:18:45.640 --> 00:18:47.230
We use a lot of
the same vocabulary

00:18:47.230 --> 00:18:49.732
in terms of describing problems
about invariants and so on.

00:18:49.732 --> 00:18:51.190
And yet, at the
same time, I wanted

00:18:51.190 --> 00:18:53.560
to raise a few
questions, particularly

00:18:53.560 --> 00:18:56.010
to demonstrate my ignorance
in terms of the auditory world

00:18:56.010 --> 00:18:59.890
and get answers from
these two experts here.

00:18:59.890 --> 00:19:03.280
I cannot help but feel
that maybe there's a nasty

00:19:03.280 --> 00:19:06.760
possibility that there are
differences between the two,

00:19:06.760 --> 00:19:10.905
in particular the role of
timing has been somewhat

00:19:10.905 --> 00:19:13.210
under-explored in
the visual domain.

00:19:13.210 --> 00:19:15.670
We have done some work on
this, some other people have.

00:19:15.670 --> 00:19:18.550
But it seems that timing plays
a much more fundamental role

00:19:18.550 --> 00:19:20.350
in the auditory domain.

00:19:20.350 --> 00:19:23.650
Perhaps the most extreme
example is sound localization,

00:19:23.650 --> 00:19:25.270
where we need to
take into account

00:19:25.270 --> 00:19:28.340
micro-second differences
in the arrival of signals

00:19:28.340 --> 00:19:29.590
within the two ears.

00:19:29.590 --> 00:19:33.930
I don't know anything even close
to that in the visual domain.

00:19:33.930 --> 00:19:35.680
So that's one
example where I think

00:19:35.680 --> 00:19:38.890
we have to say that there
is a fundamental difference.

00:19:38.890 --> 00:19:42.100
Now thinking more about sort
of the recognition questions

00:19:42.100 --> 00:19:46.150
that many of us are
interested in, I think,

00:19:46.150 --> 00:19:48.430
again, timing seems to
play a fundamental role

00:19:48.430 --> 00:19:49.580
in the auditory domain.

00:19:49.580 --> 00:19:54.420
But I would love to hear
from these two experts here.

00:19:54.420 --> 00:19:57.430
I easily come up with
questions about what

00:19:57.430 --> 00:19:59.500
is an object in the
auditory domain that's

00:19:59.500 --> 00:20:02.825
sort of defined in a
somewhat heuristic way

00:20:02.825 --> 00:20:03.700
in the visual domain?

00:20:03.700 --> 00:20:06.310
But we all sort of agree
on what objects are.

00:20:06.310 --> 00:20:07.810
And I don't know
what the equivalent

00:20:07.810 --> 00:20:10.630
is in the auditory domain.

00:20:10.630 --> 00:20:13.180
And how much attention
should we pay to the fact

00:20:13.180 --> 00:20:15.640
that the temporal
evolution of signals

00:20:15.640 --> 00:20:18.610
is a fundamental aspect in
the auditory world, which

00:20:18.610 --> 00:20:19.917
we don't really--

00:20:19.917 --> 00:20:22.000
by and large, we don't
really think about too much

00:20:22.000 --> 00:20:24.340
in the visual domain.

00:20:24.340 --> 00:20:27.340
With that said, I do
hope that at the end

00:20:27.340 --> 00:20:30.640
we will find similar fundamental
principles and algorithms,

00:20:30.640 --> 00:20:32.850
because, as I said,
cortex is cortex.

00:20:35.112 --> 00:20:36.570
JOSH MCDERMOTT: I
can speak to some

00:20:36.570 --> 00:20:37.778
of those issues a little bit.

00:20:39.999 --> 00:20:41.040
Look, I think it can be--

00:20:41.040 --> 00:20:44.370
I mean, it's an interesting
and fun and, I think,

00:20:44.370 --> 00:20:46.950
often useful exercise
to try to map, kind of,

00:20:46.950 --> 00:20:49.900
concepts from one
modality onto another.

00:20:49.900 --> 00:20:52.627
But, again, at the end of the
day, the purpose of perception

00:20:52.627 --> 00:20:54.210
is just to figure
out what's out there

00:20:54.210 --> 00:20:56.275
in the world, and
the information

00:20:56.275 --> 00:20:57.900
that you get from
different modalities,

00:20:57.900 --> 00:20:59.190
I think in some cases
it just tells you

00:20:59.190 --> 00:21:00.780
about different kinds of things.

00:21:00.780 --> 00:21:04.830
So sound is usually created
when something happens, right?

00:21:04.830 --> 00:21:07.530
It's not quite-- it's not
quite the same thing as there

00:21:07.530 --> 00:21:10.304
being an object there off
of which light reflects.

00:21:10.304 --> 00:21:11.970
I mean, sometimes
there's, in some sense

00:21:11.970 --> 00:21:12.840
which there's an object there.

00:21:12.840 --> 00:21:13.715
Like a person, right?

00:21:13.715 --> 00:21:15.840
Persons producing sound.

00:21:15.840 --> 00:21:17.509
But, oftentimes, the
sound is produced

00:21:17.509 --> 00:21:19.800
by an interaction between a
couple of different things.

00:21:19.800 --> 00:21:23.850
So, really, the question
is sort of what happened,

00:21:23.850 --> 00:21:26.170
as much as what's there.

00:21:26.170 --> 00:21:29.760
And so, you could probably
try to find things that are

00:21:29.760 --> 00:21:32.040
analogous to objects, but it's--

00:21:32.040 --> 00:21:34.470
in my mind it may just not
be exactly the right question

00:21:34.470 --> 00:21:36.372
to be asking about the sound.

00:21:36.372 --> 00:21:38.330
JOSH TENENBAUM: Can I
just comment on that one?

00:21:38.330 --> 00:21:39.400
Yeah, I mean, I
think, again, this

00:21:39.400 --> 00:21:42.270
is a place where Gabriel and I
have somewhat different biases,

00:21:42.270 --> 00:21:44.160
although, again, it's all open.

00:21:44.160 --> 00:21:46.555
But an object to me
is not a visual thing

00:21:46.555 --> 00:21:47.430
or an auditory thing.

00:21:47.430 --> 00:21:48.630
An object is a
physical thing, right?

00:21:48.630 --> 00:21:51.270
So those of you who saw Liz
Spelke's lectures on this, this

00:21:51.270 --> 00:21:54.082
is very inspiring to me that
from very early on infants

00:21:54.082 --> 00:21:56.040
have a concept of an
object, which is basically

00:21:56.040 --> 00:21:59.370
a thing in the world that can
move on its own or be moved.

00:21:59.370 --> 00:22:02.421
And the same principles apply
in vision but also haptics.

00:22:02.421 --> 00:22:04.170
And, you know, it's
true that the main way

00:22:04.170 --> 00:22:06.660
we perceive objects is
not through audition,

00:22:06.660 --> 00:22:09.060
but we can certainly
perceive things about objects

00:22:09.060 --> 00:22:13.210
from sound and often just,
echoing what Josh said,

00:22:13.210 --> 00:22:19.710
it's the events or the
interactions between objects

00:22:19.710 --> 00:22:22.440
that make sounds.

00:22:22.440 --> 00:22:25.170
They make the--
physically cause sounds.

00:22:25.170 --> 00:22:27.519
And so it's often what we're
learning from sound is--

00:22:27.519 --> 00:22:29.310
GABRIEL KREIMAN: But
maybe if I could ask--

00:22:29.310 --> 00:22:32.590
I don't disagree with your
definition of objects,

00:22:32.590 --> 00:22:34.182
a la Spelke and so on.

00:22:34.182 --> 00:22:35.640
But I guess in the
auditory domain,

00:22:35.640 --> 00:22:38.740
if I think about
speech, you know,

00:22:38.740 --> 00:22:39.990
are we talking about phonemes?

00:22:39.990 --> 00:22:41.580
Are we talking about words?

00:22:41.580 --> 00:22:44.947
I mean, if we talk about
Lady Gaga or Vivaldi,

00:22:44.947 --> 00:22:46.780
are we talking about a
whole piece of music,

00:22:46.780 --> 00:22:48.242
a measure, a tone, a frequency?

00:22:48.242 --> 00:22:49.200
These are things that--

00:22:49.200 --> 00:22:50.205
JOSH TENENBAUM:
So, structure, sort

00:22:50.205 --> 00:22:51.385
of structure more generally.

00:22:51.385 --> 00:22:53.343
GABRIEL KREIMAN: What's
the unit of computation

00:22:53.343 --> 00:22:55.350
that we should think
about algorithmically?

00:22:55.350 --> 00:22:58.290
In the same way that Dan
and us and many others

00:22:58.290 --> 00:23:01.170
think about algorithms that
will eventually have labels

00:23:01.170 --> 00:23:03.060
and objects, for example.

00:23:03.060 --> 00:23:05.140
I mean, what are those
fundamental units?

00:23:05.140 --> 00:23:08.255
And maybe the answer
is all of them, but--

00:23:08.255 --> 00:23:10.380
JOSH TENENBAUM: Well, speech
is really interesting,

00:23:10.380 --> 00:23:12.410
because from one
point of view, you

00:23:12.410 --> 00:23:15.600
could think of it
as, like, what--

00:23:15.600 --> 00:23:18.150
it's basically, like--
it's an artifact, right?

00:23:18.150 --> 00:23:20.970
Speech is a thing that's created
through biological and cultural

00:23:20.970 --> 00:23:23.940
evolution, manipulating a
system to kind of create

00:23:23.940 --> 00:23:25.860
these artificial event
categories, which

00:23:25.860 --> 00:23:28.424
we can call phonemes and
words and sentences and so on.

00:23:28.424 --> 00:23:30.090
And, you know, surely
there was audition

00:23:30.090 --> 00:23:31.470
before there was speech, right?

00:23:31.470 --> 00:23:33.720
So, it seems like it's
building on a system that's

00:23:33.720 --> 00:23:36.750
going to detect a more
basic notion of events,

00:23:36.750 --> 00:23:39.900
physical interactions, or things
like babbling brooks or fires

00:23:39.900 --> 00:23:41.400
or breezes.

00:23:41.400 --> 00:23:44.010
And then animal communication.

00:23:44.010 --> 00:23:47.661
And it hacks that, basically,
both on the production side

00:23:47.661 --> 00:23:48.660
and the perception side.

00:23:48.660 --> 00:23:51.330
So it's very interesting to
ask what's the structure?

00:23:51.330 --> 00:23:54.090
What's the right way to describe
the structure in speech?

00:23:54.090 --> 00:23:56.650
It probably seems most analogous
to something like gesture,

00:23:56.650 --> 00:23:57.150
you know?

00:23:57.150 --> 00:23:59.149
That's a way to hack the
visual system to create

00:23:59.149 --> 00:24:00.490
these events visually.

00:24:00.490 --> 00:24:02.910
Salient changes in
motion, whether for just

00:24:02.910 --> 00:24:05.220
non-verbal communication or
something in sign language.

00:24:05.220 --> 00:24:06.470
It's super interesting, right?

00:24:06.470 --> 00:24:07.470
But it's, again--

00:24:07.470 --> 00:24:10.150
I wouldn't say-- the analog--
speech isn't a set of objects.

00:24:10.150 --> 00:24:12.090
It's a set of
structured events, which

00:24:12.090 --> 00:24:16.080
have been created to be
perceivable by a system which

00:24:16.080 --> 00:24:18.700
was evolutionarily
much more ancient one,

00:24:18.700 --> 00:24:22.596
perceiving object
interactions and events.

00:24:22.596 --> 00:24:24.720
JOSH MCDERMOTT: But I also
think it's a case that--

00:24:24.720 --> 00:24:28.180
yeah, there's a lot of
focus on objects and vision,

00:24:28.180 --> 00:24:31.500
but it's certainly the case
that vision is richer than just

00:24:31.500 --> 00:24:32.670
being about objects, right?

00:24:32.670 --> 00:24:34.230
I mean, you have--

00:24:34.230 --> 00:24:35.580
there-- right?

00:24:35.580 --> 00:24:36.750
I mean, there's--

00:24:36.750 --> 00:24:39.900
I think in some sense,
the fact that you

00:24:39.900 --> 00:24:41.790
are posing the question,
it's a reflection

00:24:41.790 --> 00:24:45.220
of where a lot of work
has been concentrated on.

00:24:45.220 --> 00:24:47.820
But, yeah, there's obviously--
you know, you have scenes,

00:24:47.820 --> 00:24:50.180
there's stuff, not
just things, right?

00:24:50.180 --> 00:24:51.614
And the same is
true in audition.

00:24:51.614 --> 00:24:54.030
And the difference is just
that there isn't really as much

00:24:54.030 --> 00:24:58.120
of a focus on, like, things,
only because those are not--

00:24:58.120 --> 00:25:00.120
GABRIEL KREIMAN: Here's
the fundamental question

00:25:00.120 --> 00:25:02.790
I'm trying to raise, as well
as the question about timing.

00:25:02.790 --> 00:25:05.520
In the visual domain,
let's get away from objects

00:25:05.520 --> 00:25:07.969
and think about action
recognition, for example.

00:25:07.969 --> 00:25:09.510
And that's one domain
where you would

00:25:09.510 --> 00:25:12.420
think that, well, you have
to start thinking about time.

00:25:12.420 --> 00:25:14.760
It's actually extremely
challenging to come up with

00:25:14.760 --> 00:25:17.280
good stimuli that you
cannot recognize--

00:25:17.280 --> 00:25:20.520
where you cannot infer
actions from single frames.

00:25:20.520 --> 00:25:22.874
And I would argue, but--

00:25:22.874 --> 00:25:24.540
JOSH TENENBAUM: Let's
talk about events.

00:25:24.540 --> 00:25:26.592
GABRIEL KREIMAN: But let
me say one more thing.

00:25:26.592 --> 00:25:28.050
But please correct
me if I'm wrong.

00:25:28.050 --> 00:25:29.400
I would argue that in
the auditory domain,

00:25:29.400 --> 00:25:30.360
it's the opposite.

00:25:30.360 --> 00:25:32.295
It's very hard to come up with
things that you can recognize

00:25:32.295 --> 00:25:33.170
from a single incident.

00:25:33.170 --> 00:25:33.590
JOSH MCDERMOTT: Sure.

00:25:33.590 --> 00:25:35.210
GABRIEL KREIMAN: You need time.

00:25:35.210 --> 00:25:39.350
Time is inherent to the basic
definition of everything.

00:25:39.350 --> 00:25:42.170
In the visual domain--

00:25:42.170 --> 00:25:44.330
again, we've thought
about time and what

00:25:44.330 --> 00:25:46.090
happens if you present
parts of objects

00:25:46.090 --> 00:25:47.600
asynchronously, for example.

00:25:47.600 --> 00:25:50.290
And you can disrupt object
recognition or action

00:25:50.290 --> 00:25:52.190
recognition in that way.

00:25:52.190 --> 00:25:53.720
But it's sort of--

00:25:53.720 --> 00:25:57.680
again, you can do a lot without
time or without thinking

00:25:57.680 --> 00:25:59.260
too seriously about time.

00:25:59.260 --> 00:26:01.132
Then maybe, I don't know--

00:26:01.132 --> 00:26:03.340
time is probably not one of
your main preoccupations,

00:26:03.340 --> 00:26:07.310
I suspect, in the visual domain.

00:26:07.310 --> 00:26:09.290
HYNEK HERMANSKY: I'm
not sure, because one

00:26:09.290 --> 00:26:12.800
of the big things which
always strikes me in vision

00:26:12.800 --> 00:26:15.260
is the saccade and
the fact that we

00:26:15.260 --> 00:26:18.950
are moving eyes, and the
fact that it's possible even

00:26:18.950 --> 00:26:21.290
to lose the vision,
basically, if you really

00:26:21.290 --> 00:26:24.900
fix the things on the
retina, and so on and so on.

00:26:24.900 --> 00:26:28.010
So vision probably
figured out different ways

00:26:28.010 --> 00:26:30.980
of introducing time
into perception,

00:26:30.980 --> 00:26:34.070
basically moving eyes
and maybe in sounds.

00:26:34.070 --> 00:26:37.430
Indeed, it's happening more,
like, already out there.

00:26:37.430 --> 00:26:41.900
But, you know, I had one
joint project actually

00:26:41.900 --> 00:26:45.500
where we tried to work on
audio-visual recognition.

00:26:45.500 --> 00:26:50.270
And it was the project about
recognizing unexpected things.

00:26:50.270 --> 00:26:52.700
And that was a big pain
initially, because,

00:26:52.700 --> 00:26:55.610
of course, vision people
thinking one way or auditory

00:26:55.610 --> 00:26:57.540
people thinking another way.

00:26:57.540 --> 00:27:01.820
But eventually we ended up with
the time and with the surprises

00:27:01.820 --> 00:27:04.900
and with the unexpected
and with the priors.

00:27:04.900 --> 00:27:06.920
And there's been a
lot of similarities

00:27:06.920 --> 00:27:11.400
between audio and
visual world, you know?

00:27:11.400 --> 00:27:13.760
So that's why I was maybe
saying in the beginning,

00:27:13.760 --> 00:27:15.410
people should be
more encouraged--

00:27:15.410 --> 00:27:17.340
now I'm looking
at the students--

00:27:17.340 --> 00:27:18.280
to look at both.

00:27:18.280 --> 00:27:20.860
I mean, don't just say
I'm a visual person

00:27:20.860 --> 00:27:23.540
and I just want to know a little
bit about speech or something.

00:27:23.540 --> 00:27:24.039
No.

00:27:24.039 --> 00:27:26.830
I mean, these things
are very interesting.

00:27:26.830 --> 00:27:29.020
And, of course I mean
in auditory world,

00:27:29.020 --> 00:27:31.760
there are problems that are
very similar to visual problems.

00:27:31.760 --> 00:27:35.100
And in the visual world there
are very similar problems

00:27:35.100 --> 00:27:36.750
to auditory work.

00:27:36.750 --> 00:27:40.370
You just take a speech
and take a writing, right?

00:27:40.370 --> 00:27:43.700
And be it handwriting or
being even printed things.

00:27:43.700 --> 00:27:46.580
I mean, these things
communicate messages,

00:27:46.580 --> 00:27:49.340
communicate information,
in a very similar way.

00:27:49.340 --> 00:27:52.370
So, I would just say I
got a little bit excited

00:27:52.370 --> 00:27:54.200
because I finished my coffee.

00:27:54.200 --> 00:27:57.530
But I would just say, let's
look for the similarities rather

00:27:57.530 --> 00:28:01.860
than differences, and let's
be very serious about it.

00:28:01.860 --> 00:28:04.880
Like, sort of say, oh,
finally I found something.

00:28:04.880 --> 00:28:07.190
Like, for instance, I give
you one little example.

00:28:07.190 --> 00:28:10.130
We had a big problem with
a perceptual constancy

00:28:10.130 --> 00:28:12.980
when you get linear
distortions in the signal.

00:28:12.980 --> 00:28:16.000
And I just accidentally read
some paper by David Marr

00:28:16.000 --> 00:28:18.450
at the time, and I
didn't understand it.

00:28:18.450 --> 00:28:21.570
I have to say I actually missed
[INAUDIBLE] a little bit.

00:28:21.570 --> 00:28:23.630
But still, it was a
great inspiration.

00:28:23.630 --> 00:28:26.360
And I came up with
an algorithm which

00:28:26.360 --> 00:28:28.120
ended up to be a very good one.

00:28:28.120 --> 00:28:29.120
Well, at the time.

00:28:29.120 --> 00:28:31.030
I mean, I was being
beaten many times.

00:28:31.030 --> 00:28:33.570
But, you know, let's just
look for the similarities.

00:28:33.570 --> 00:28:36.380
That's what I'm
somehow, maybe arguing.

00:28:36.380 --> 00:28:38.420
And that was also
my quest-- like,

00:28:38.420 --> 00:28:41.850
I don't even know what
is similar and different

00:28:41.850 --> 00:28:44.420
in auditory and visual signals.

00:28:44.420 --> 00:28:47.390
So, find-- certainly maybe--

00:28:47.390 --> 00:28:49.600
on a certain level, it
must be the same, right?

00:28:49.600 --> 00:28:51.590
The cortex is
very, very similar.

00:28:51.590 --> 00:28:54.770
So I believe that,
indeed, at the end

00:28:54.770 --> 00:28:58.310
we are getting information
into our brain, which

00:28:58.310 --> 00:29:02.270
is being used for figuring out
what's happening in the world.

00:29:02.270 --> 00:29:04.940
And there are these big
differences at the beginning.

00:29:04.940 --> 00:29:06.680
I mean, the senses
are so different.

00:29:06.680 --> 00:29:10.554
JOSH TENENBAUM: Could I
nominate one sort of thing

00:29:10.554 --> 00:29:12.470
that could be very
interesting to study that's

00:29:12.470 --> 00:29:14.510
very basic in both vision
and audition, of where

00:29:14.510 --> 00:29:15.551
there are some analogies?

00:29:15.551 --> 00:29:17.180
Which is certain
kinds of basic events

00:29:17.180 --> 00:29:19.460
that involve physical
interaction between objects.

00:29:19.460 --> 00:29:21.510
Like, I'll try to
make one right here.

00:29:21.510 --> 00:29:22.010
Right?

00:29:22.010 --> 00:29:22.510
OK.

00:29:22.510 --> 00:29:25.130
So there was a visual event,
and it has a low level

00:29:25.130 --> 00:29:26.420
signal-- a motion signal.

00:29:26.420 --> 00:29:28.380
There was some motion over here.

00:29:28.380 --> 00:29:31.696
Then there was some other motion
that, in a sense, was caused.

00:29:31.696 --> 00:29:33.320
There was some sound
that went with it.

00:29:33.320 --> 00:29:35.150
There was the sound of the
thing sliding on the table

00:29:35.150 --> 00:29:36.560
and then the sound
of the collision.

00:29:36.560 --> 00:29:38.000
We have all sorts of other
things like that, Right?

00:29:38.000 --> 00:29:39.770
Like, I can drop
this object here,

00:29:39.770 --> 00:29:41.780
and it makes a certain sound.

00:29:41.780 --> 00:29:45.590
And so there's very salient,
low levelly detectable,

00:29:45.590 --> 00:29:47.780
both auditory and
visual signals that have

00:29:47.780 --> 00:29:49.137
a common cause in the world.

00:29:49.137 --> 00:29:50.220
One thing hitting another.

00:29:50.220 --> 00:29:51.740
It's also the kind
of thing which--

00:29:51.740 --> 00:29:53.150
I don't know if Liz mentioned
this in her lecture.

00:29:53.150 --> 00:29:54.500
I mentioned this a little bit.

00:29:54.500 --> 00:29:56.930
Even very young infants,
even two-month-olds,

00:29:56.930 --> 00:29:58.760
understand something
about this contact

00:29:58.760 --> 00:30:01.654
causality, that one object can
cause another object to move.

00:30:01.654 --> 00:30:03.570
It's the sort of thing
that Shimon has shown--

00:30:03.570 --> 00:30:05.030
Shimon Ullman has shown.

00:30:05.030 --> 00:30:06.590
You can, in a very
basic way, use

00:30:06.590 --> 00:30:10.580
this to pick out primitive
agents, like hands as movers.

00:30:10.580 --> 00:30:14.630
So this is one
basic kind of event

00:30:14.630 --> 00:30:17.810
that has interesting parallels
between vision and audition,

00:30:17.810 --> 00:30:19.580
because there's a
basic thing happening

00:30:19.580 --> 00:30:21.740
in the world, an exertion
of force between one

00:30:21.740 --> 00:30:25.190
moving object when it comes
into contact with another thing.

00:30:25.190 --> 00:30:28.910
And it creates some
simultaneously detectable

00:30:28.910 --> 00:30:30.990
events with analogous
kinds of structure.

00:30:30.990 --> 00:30:33.290
I think a very basic
question is, you know,

00:30:33.290 --> 00:30:35.490
if we were to look at the
cortical representation

00:30:35.490 --> 00:30:38.751
of a visual collision event
and the auditory side of that,

00:30:38.751 --> 00:30:39.250
you know?

00:30:39.250 --> 00:30:40.330
How do those work together?

00:30:40.330 --> 00:30:41.610
What are similarities
or differences

00:30:41.610 --> 00:30:43.734
in the representation and
computation of those kind

00:30:43.734 --> 00:30:45.180
of very basic events?

00:30:48.230 --> 00:30:50.980
HYNEK HERMANSKY: If I still
may, obvious thing to use

00:30:50.980 --> 00:30:56.850
is use vision to transcribe the
human communication by speech.

00:30:56.850 --> 00:31:00.240
If somebody wants a lot of
money from Amazon or Microsoft

00:31:00.240 --> 00:31:04.110
or Google or government,
you know, work on that.

00:31:04.110 --> 00:31:07.200
Because there is a clear
visual channel, which is being

00:31:07.200 --> 00:31:09.617
used very heavily, you know?

00:31:09.617 --> 00:31:10.200
Not only that.

00:31:10.200 --> 00:31:13.350
I move the hands and
that sort of thing.

00:31:13.350 --> 00:31:16.140
If somebody can help there,
I mean, that would be great.

00:31:16.140 --> 00:31:18.969
And it's actually a relatively
very straightforward problem.

00:31:18.969 --> 00:31:19.885
I'm not saying simple.

00:31:19.885 --> 00:31:21.300
But it's well defined.

00:31:21.300 --> 00:31:23.310
Because there is
a message, which

00:31:23.310 --> 00:31:27.780
is being conveyed in a
communication by speech.

00:31:27.780 --> 00:31:28.890
And it's being used.

00:31:28.890 --> 00:31:30.570
I mean, lips are
definitely moving,

00:31:30.570 --> 00:31:32.610
unless you are working
with a machine.

00:31:32.610 --> 00:31:35.440
And hands are moving unless you
are a really calm person, which

00:31:35.440 --> 00:31:36.450
none of us is.

00:31:36.450 --> 00:31:38.940
And so this is one--

00:31:38.940 --> 00:31:40.971
JOSH TENENBAUM: Just basic
speech communication.

00:31:40.971 --> 00:31:42.804
HYNEK HERMANSKY: Basic
speech communication,

00:31:42.804 --> 00:31:44.690
as Martin [INAUDIBLE] is saying.

00:31:44.690 --> 00:31:47.317
That would be great, really.

00:31:47.317 --> 00:31:49.650
JOSH MCDERMOTT: I mean, it's
also worth saying, I think,

00:31:49.650 --> 00:31:51.904
you know, most of perception
is multimodal, right?

00:31:51.904 --> 00:31:53.820
And you can certainly
come up with these cases

00:31:53.820 --> 00:31:59.864
where you rely on sound and
have basically no information

00:31:59.864 --> 00:32:01.280
from vision and
vice versa, right?

00:32:01.280 --> 00:32:02.724
But most of the
time, you get both

00:32:02.724 --> 00:32:04.640
and you don't even really
think about the fact

00:32:04.640 --> 00:32:06.020
that you have two modalities.

00:32:06.020 --> 00:32:08.686
You're just, you know-- you want
to know what to grab or whether

00:32:08.686 --> 00:32:11.860
to run or whether it's safe
to cross the street and, you

00:32:11.860 --> 00:32:12.480
know--

00:32:12.480 --> 00:32:14.021
HYNEK HERMANSKY: Of
course, the thing

00:32:14.021 --> 00:32:17.315
is that you can switch off one
modality without much damage.

00:32:17.315 --> 00:32:20.160
That's OK, because in
most of the perception

00:32:20.160 --> 00:32:21.520
this is always the case.

00:32:21.520 --> 00:32:24.185
You don't need all the
channels of communication.

00:32:24.185 --> 00:32:25.390
You only need some.

00:32:25.390 --> 00:32:28.160
But if you want to have
a perfect communication,

00:32:28.160 --> 00:32:30.240
then you would like to use it.

00:32:30.240 --> 00:32:36.225
But I absolutely agree that
the world is audiovisual.

00:32:36.225 --> 00:32:37.600
JOSH TENENBAUM:
This is a comment

00:32:37.600 --> 00:32:39.460
I was going to add to our
discussion list, which I shared

00:32:39.460 --> 00:32:40.650
with Alex but
maybe not the rest,

00:32:40.650 --> 00:32:42.775
is I think it's a really
interesting question, what

00:32:42.775 --> 00:32:44.620
can be understood
about the similarities

00:32:44.620 --> 00:32:47.080
and differences in each of
these perceptual modalities

00:32:47.080 --> 00:32:49.390
by studying
multimodal perception?

00:32:49.390 --> 00:32:52.240
And to put out a kind
of a bold hypothesis,

00:32:52.240 --> 00:32:55.900
I think that, for reasons that
you guys were just saying,

00:32:55.900 --> 00:32:58.532
because natural perception
is inherently multimodal.

00:32:58.532 --> 00:32:59.740
And it's not just these ones.

00:32:59.740 --> 00:33:01.119
It also involves
touch and so on.

00:33:01.119 --> 00:33:03.160
I think that's going to
impose strong constraints

00:33:03.160 --> 00:33:05.830
on the representations
and computations in both

00:33:05.830 --> 00:33:07.292
how vision and audition work.

00:33:07.292 --> 00:33:09.250
The fact that they have
to be able to interface

00:33:09.250 --> 00:33:11.380
with a common system,
what, you know,

00:33:11.380 --> 00:33:14.686
I would think of as a kind of
physical object events system.

00:33:14.686 --> 00:33:16.060
But, however you
want to describe

00:33:16.060 --> 00:33:19.450
it, the fact of multimodal
perception's pervasiveness,

00:33:19.450 --> 00:33:21.970
the fact that you can switch
on or off sense modalities

00:33:21.970 --> 00:33:24.520
and still do something, but
that you can really just

00:33:24.520 --> 00:33:26.470
so fluently, naturally
bring them together

00:33:26.470 --> 00:33:29.980
into a shared understanding
of the world, that's something

00:33:29.980 --> 00:33:31.640
we can't ignore, I would say.

00:33:31.640 --> 00:33:36.510
GABRIEL KREIMAN: Why are people
so sure that in everyday life,

00:33:36.510 --> 00:33:40.460
most things are multimodal?

00:33:40.460 --> 00:33:42.570
I'm not really sure
how to quantify that.

00:33:42.570 --> 00:33:44.892
But is there any
quantification of this?

00:33:44.892 --> 00:33:47.100
JOSH MCDERMOTT: No, I don't
know of a quantification.

00:33:47.100 --> 00:33:53.930
All I mean is that, most of the
time, I mean, you're listening

00:33:53.930 --> 00:33:55.490
and you're looking
and you're doing

00:33:55.490 --> 00:33:57.100
everything you can to figure
out what happened, right?

00:33:57.100 --> 00:33:58.430
I mean, it's like,
you know, you want

00:33:58.430 --> 00:34:00.138
to know if there's
traffic coming, right?

00:34:00.138 --> 00:34:01.850
I mean, there's noise
that the cars make.

00:34:01.850 --> 00:34:03.445
You also look, you know?

00:34:03.445 --> 00:34:04.320
You do both of those.

00:34:04.320 --> 00:34:05.986
And you probably don't
even really think

00:34:05.986 --> 00:34:07.400
about which of
them you're doing.

00:34:07.400 --> 00:34:07.610
GABRIEL KREIMAN: No.

00:34:07.610 --> 00:34:09.609
I'm not talking about the
most of the time part.

00:34:09.609 --> 00:34:12.690
Yes, that's a very good example
of multimodal experience.

00:34:12.690 --> 00:34:14.360
I can cite lots
of other examples

00:34:14.360 --> 00:34:17.150
where I'm running and
listening to music

00:34:17.150 --> 00:34:20.360
and they're
completely decoupled.

00:34:20.360 --> 00:34:21.610
Or I'm working on my computer.

00:34:21.610 --> 00:34:23.318
JOSH TENENBAUM: You
don't listen to music

00:34:23.318 --> 00:34:24.469
when you're driving, right?

00:34:24.469 --> 00:34:25.550
GABRIEL KREIMAN: I do, but--

00:34:25.550 --> 00:34:25.980
GABRIEL KREIMAN: No, but no.

00:34:25.980 --> 00:34:27.860
But, I mean, not in
the way that, like--

00:34:27.860 --> 00:34:29.580
sure, you listen to
music, obviously.

00:34:29.580 --> 00:34:30.780
You listen to music
when we're driving,

00:34:30.780 --> 00:34:32.955
but we try-- it's sort of
important that it doesn't

00:34:32.955 --> 00:34:34.080
drown out all other sounds.

00:34:34.080 --> 00:34:36.454
GABRIEL KREIMAN: I'm just
wondering to what extent this--

00:34:36.454 --> 00:34:37.582
JOSH TENENBAUM: Ok, fine.

00:34:37.582 --> 00:34:39.290
ALEX KELL: And how
much of that is, like,

00:34:39.290 --> 00:34:41.351
kind of the particular,
like, the modern-- like,

00:34:41.351 --> 00:34:43.850
in the contemporary world you
can actually decorrelate these

00:34:43.850 --> 00:34:45.830
things in a way that in the
natural world you can't.

00:34:45.830 --> 00:34:47.455
Like, if you are a
monkey, these things

00:34:47.455 --> 00:34:49.900
would probably be a lot
more correlated than you are

00:34:49.900 --> 00:34:52.719
as a human in the 21st century.

00:34:52.719 --> 00:34:55.610
Like, there would be a
[INAUDIBLE] physical world

00:34:55.610 --> 00:34:57.950
causing the input to both
your modalities in a way

00:34:57.950 --> 00:35:00.279
that you can break now, right?

00:35:00.279 --> 00:35:01.070
Like, I don't know.

00:35:01.070 --> 00:35:02.060
That feels--

00:35:02.060 --> 00:35:03.476
GABRIEL KREIMAN:
You may be right.

00:35:03.476 --> 00:35:05.461
I haven't really thought
deeply about this.

00:35:05.461 --> 00:35:06.500
[INTERPOSING VOICES]

00:35:06.500 --> 00:35:07.490
GABRIEL KREIMAN:
I'm not [INAUDIBLE]

00:35:07.490 --> 00:35:07.770
JOSH MCDERMOTT: It would
be interesting to compute

00:35:07.770 --> 00:35:08.820
some statistics of this.

00:35:08.820 --> 00:35:10.861
GABRIEL KREIMAN: I'm not
disputing the usefulness

00:35:10.861 --> 00:35:11.960
of multimodal perception.

00:35:11.960 --> 00:35:13.460
I think it's fantastic.

00:35:13.460 --> 00:35:14.870
I'm just wondering.

00:35:14.870 --> 00:35:18.006
I think vision can do very
well without the other auditory

00:35:18.006 --> 00:35:18.740
world.

00:35:18.740 --> 00:35:20.240
And vice versa.

00:35:20.240 --> 00:35:22.823
DAN YAMINS: We could just close
our eyes right now, all of us,

00:35:22.823 --> 00:35:24.852
and we'd have a fine
panel for a while.

00:35:24.852 --> 00:35:26.810
JOSH TENENBAUM: But many
of the social dynamics

00:35:26.810 --> 00:35:29.590
would be invisible, literally.

00:35:29.590 --> 00:35:31.340
JOSH MCDERMOTT: No, I
think you'd probably

00:35:31.340 --> 00:35:32.381
get a lot of reciprocity.

00:35:32.381 --> 00:35:33.470
It's an open question.

00:35:33.470 --> 00:35:35.810
JOSH TENENBAUM: You'd get
some, but, like, there's

00:35:35.810 --> 00:35:38.660
a difference.

00:35:38.660 --> 00:35:40.620
Have you ever listened
to a radio talk show?

00:35:40.620 --> 00:35:43.226
Sometimes these days the shows
are broadcast on TV and also--

00:35:43.226 --> 00:35:45.350
and it's, like, when you
watch you're like, oh my--

00:35:45.350 --> 00:35:46.430
like, you have a
totally different view

00:35:46.430 --> 00:35:47.030
of what's going on.

00:35:47.030 --> 00:35:48.840
Or, like, if you're
there in the studio.

00:35:48.840 --> 00:35:51.256
I mean, I totally agree that
these are all open questions,

00:35:51.256 --> 00:35:53.480
and it would be nice
to actually quantify,

00:35:53.480 --> 00:35:56.150
for example, what to me is this
often subjective experience.

00:35:56.150 --> 00:35:59.249
Like, sometimes if the
sound is, you know--

00:35:59.249 --> 00:35:59.790
I don't know.

00:35:59.790 --> 00:36:01.248
You turn off the
sound on something

00:36:01.248 --> 00:36:03.800
where you're used to
having the sound, it

00:36:03.800 --> 00:36:05.366
changes your experience, right?

00:36:05.366 --> 00:36:06.740
Or you turn on
the sound in a way

00:36:06.740 --> 00:36:08.840
that you had previously
watched something, right?

00:36:08.840 --> 00:36:11.006
Like, you could do experiments
where you show people

00:36:11.006 --> 00:36:13.515
a movie without the sound and
then you turn on the sound.

00:36:13.515 --> 00:36:15.431
You know, in some ways
transform what they see

00:36:15.431 --> 00:36:16.306
and in some ways not.

00:36:16.306 --> 00:36:18.880
So, maybe the right thing to
say is more data is needed.

00:36:18.880 --> 00:36:21.770
DAN YAMINS: But don't you guys
think, though, that, like,

00:36:21.770 --> 00:36:24.224
even independent of multimodal,
there's still actually

00:36:24.224 --> 00:36:25.640
a lot of even more
basic questions

00:36:25.640 --> 00:36:27.514
to be asked about
similarity and differences?

00:36:27.514 --> 00:36:28.882
Like, I mean, just from a very--

00:36:28.882 --> 00:36:31.340
from my point of view since
that's the only one I'm usually

00:36:31.340 --> 00:36:32.840
able to take, like,
you took a bunch

00:36:32.840 --> 00:36:34.700
of convolutional
neural networks and you

00:36:34.700 --> 00:36:36.824
train some of them on vision
tasks and some of them

00:36:36.824 --> 00:36:37.960
on audition tasks, right?

00:36:37.960 --> 00:36:39.140
And you figured out
which architectures

00:36:39.140 --> 00:36:40.310
are good for audition
tasks and which

00:36:40.310 --> 00:36:41.510
are good for vision tasks.

00:36:41.510 --> 00:36:43.340
See if the architectures
are the same,

00:36:43.340 --> 00:36:45.620
and if indeed the architectures
are fairly similar,

00:36:45.620 --> 00:36:47.204
then, like, looking
at the differences

00:36:47.204 --> 00:36:48.911
between the features
at different levels.

00:36:48.911 --> 00:36:50.810
I mean, I know that
that's a very narrow way

00:36:50.810 --> 00:36:52.300
to interpret the
question, but it's one.

00:36:52.300 --> 00:36:54.050
And there's probably
a lot that can be--

00:36:54.050 --> 00:36:55.220
JOSH TENENBAUM: You guys
have been doing that.

00:36:55.220 --> 00:36:57.020
What have you learned
from doing that?

00:36:57.020 --> 00:36:57.840
ALEX KELL: We haven't
done it that exhaustively.

00:36:57.840 --> 00:36:59.150
DAN YAMINS: We haven't
done it that exhaustively.

00:36:59.150 --> 00:37:00.858
But suffice it to say
that the hints are,

00:37:00.858 --> 00:37:02.360
I think, very interesting.

00:37:02.360 --> 00:37:04.610
Like, you begin to
see places where

00:37:04.610 --> 00:37:07.400
there are clear similarities and
clear differences and asking,

00:37:07.400 --> 00:37:09.350
like, where did the
divergence occur?

00:37:09.350 --> 00:37:12.080
Are there any underlying
principles about what layers

00:37:12.080 --> 00:37:14.420
or what levels in the
model those divergences

00:37:14.420 --> 00:37:15.500
start to occur?

00:37:15.500 --> 00:37:17.083
Can you see similarities
at all layers

00:37:17.083 --> 00:37:18.770
or do you start to
see sort of a kind

00:37:18.770 --> 00:37:20.371
of a clear branching point?

00:37:20.371 --> 00:37:20.870
Right?

00:37:20.870 --> 00:37:22.800
Moreover, like what about
lower layers, right?

00:37:22.800 --> 00:37:24.860
I mean, you start to
actually see differences

00:37:24.860 --> 00:37:28.400
in sort of frequency content in
auditory data and differences

00:37:28.400 --> 00:37:29.840
between that and
visual data that

00:37:29.840 --> 00:37:31.970
seem to emerge very
naturally from the underlying

00:37:31.970 --> 00:37:33.097
similarities.

00:37:33.097 --> 00:37:35.430
You know, underlying differences
between the statistics.

00:37:35.430 --> 00:37:37.310
But still, downstream
from there,

00:37:37.310 --> 00:37:40.264
there are some deep similarities
about extraction of objects

00:37:40.264 --> 00:37:41.180
of some kind or other.

00:37:41.180 --> 00:37:43.230
You know, auditory
objects, potentially.

00:37:43.230 --> 00:37:45.022
And so I think that's
a very narrow way

00:37:45.022 --> 00:37:45.980
of posing the question.

00:37:45.980 --> 00:37:48.521
And I don't say that everybody
should pose it that way by any

00:37:48.521 --> 00:37:49.130
means.

00:37:49.130 --> 00:37:51.770
But I just think that before we
get to multimodal interaction,

00:37:51.770 --> 00:37:53.520
which is interesting,
I think there's just

00:37:53.520 --> 00:37:56.690
this huge space of
clear, very concrete ways

00:37:56.690 --> 00:37:59.060
to ask the question of
similarities and differences

00:37:59.060 --> 00:37:59.720
that are--

00:37:59.720 --> 00:38:00.860
like, almost no matter
what you'll find,

00:38:00.860 --> 00:38:02.300
you'll find something
interesting.

00:38:02.300 --> 00:38:03.740
JOSH TENENBAUM: You're saying
if we enlarge the discussion

00:38:03.740 --> 00:38:04.880
from just talking
about vision audition

00:38:04.880 --> 00:38:06.920
to other parts of
cognition, then we'll

00:38:06.920 --> 00:38:09.530
see more of the similarities
between these sense modalities,

00:38:09.530 --> 00:38:11.655
because they will be the
differences that stand out

00:38:11.655 --> 00:38:13.720
in relief with respect
to the rest of cognition.

00:38:13.720 --> 00:38:17.030
Yeah, I mean, I think that's
a valuable thing to do,

00:38:17.030 --> 00:38:19.020
and it connects to what
these guys were saying,

00:38:19.020 --> 00:38:21.197
which is that there's
a sense in which this--

00:38:21.197 --> 00:38:23.780
you know, something like these
deep convolutional architecture

00:38:23.780 --> 00:38:27.740
seem like really good ways to
do pattern recognition, right?

00:38:27.740 --> 00:38:30.590
This is what I would see as
the common theme between where

00:38:30.590 --> 00:38:34.776
a lot of the successes happened
in vision and in audition.

00:38:34.776 --> 00:38:37.400
And I don't think-- and, again,
everybody here has heard me say

00:38:37.400 --> 00:38:38.358
this a bunch of times--

00:38:38.358 --> 00:38:40.430
I think that pattern
recognition does not

00:38:40.430 --> 00:38:42.440
exhaust, by any
means, intelligence

00:38:42.440 --> 00:38:43.340
or even perception.

00:38:43.340 --> 00:38:46.260
Like, I think even within
vision and audition,

00:38:46.260 --> 00:38:49.550
there's a lot we do that
goes beyond, at least

00:38:49.550 --> 00:38:51.729
on the surface, you
know, pattern recognition

00:38:51.729 --> 00:38:52.520
and classification.

00:38:52.520 --> 00:38:54.410
It's something more like
building a generative model.

00:38:54.410 --> 00:38:55.410
Maybe this is a good time to--

00:38:55.410 --> 00:38:57.243
that's another theme
you wanted to bring in.

00:38:57.243 --> 00:38:59.390
But, you know,
something about building

00:38:59.390 --> 00:39:02.360
a rich model of the world and
its physical interactions.

00:39:02.360 --> 00:39:03.990
And, to me, you
know, and, again,

00:39:03.990 --> 00:39:06.680
something Dan and I have talked
a lot about it and I think

00:39:06.680 --> 00:39:07.367
it's--

00:39:07.367 --> 00:39:09.200
you know, you've heard
some of this from me,

00:39:09.200 --> 00:39:12.200
and Dan has got some really
awesome work in a similar vein

00:39:12.200 --> 00:39:14.300
of trying to understand
how, basically,

00:39:14.300 --> 00:39:15.899
deep pattern
recognizers-- to me,

00:39:15.899 --> 00:39:18.440
that's another way we could call
deep convolutional pattern--

00:39:18.440 --> 00:39:21.667
or just deep invariant
pattern recognizers,

00:39:21.667 --> 00:39:23.750
where the invariance is
over space or time windows

00:39:23.750 --> 00:39:26.390
or whatever it is that
deep convolutional--

00:39:26.390 --> 00:39:28.850
you know, these are
obviously important tools.

00:39:28.850 --> 00:39:30.620
They obviously have
some connection

00:39:30.620 --> 00:39:32.720
to not just the six
layer cortex architecture

00:39:32.720 --> 00:39:35.810
but these multiple-- you
know, the things that goes on

00:39:35.810 --> 00:39:37.700
in, like, the ventral
stream, for example.

00:39:37.700 --> 00:39:39.450
I don't know, the
auditory system as well.

00:39:39.450 --> 00:39:41.720
But it's going on from one
cortical area to a next.

00:39:41.720 --> 00:39:43.370
A hierarchy of processing.

00:39:43.370 --> 00:39:47.000
That seems to be a way that
cortex has been arranged

00:39:47.000 --> 00:39:50.630
in these two sense modalities
in particular to do

00:39:50.630 --> 00:39:53.180
a really powerful kind
of pattern recognition.

00:39:53.180 --> 00:39:55.610
And then I think there's
the question of, OK,

00:39:55.610 --> 00:40:00.037
how does pattern recognition fit
together with model building?

00:40:00.037 --> 00:40:02.120
And, you know, I think in
other areas of cognition

00:40:02.120 --> 00:40:04.570
you see a similar kind
of interchange, right?

00:40:04.570 --> 00:40:07.580
It might be-- like, this has
come up a little bit in action

00:40:07.580 --> 00:40:09.560
planning-- like,
model-based planning

00:40:09.560 --> 00:40:11.660
versus more model-free
reinforcement learning.

00:40:11.660 --> 00:40:13.160
And those are,
again, a place where

00:40:13.160 --> 00:40:15.118
there might be two
different systems that might

00:40:15.118 --> 00:40:16.370
interact in some kind of way.

00:40:16.370 --> 00:40:18.911
I think pattern recognition
also is useful all over--

00:40:18.911 --> 00:40:20.660
you know, where cognition
starts to become

00:40:20.660 --> 00:40:22.410
different from
perception, for example.

00:40:22.410 --> 00:40:24.170
There's so many ways, but
things like when you have a goal

00:40:24.170 --> 00:40:26.600
and you're trying to solve
a problem, do something.

00:40:26.600 --> 00:40:30.050
Pattern recognition is often
useful in guiding problem

00:40:30.050 --> 00:40:31.790
solving, right?

00:40:31.790 --> 00:40:35.690
But it's not the same
as a plan, right?

00:40:35.690 --> 00:40:37.190
So, I don't know
if this is starting

00:40:37.190 --> 00:40:41.060
to answer your question, but I
think this idea of intelligence

00:40:41.060 --> 00:40:43.030
more generally as
something like--

00:40:43.030 --> 00:40:45.500
I mean, the way Laura put it
for learning, the same idea,

00:40:45.500 --> 00:40:49.160
she put it as, like, goal
directed or goal constrained--

00:40:49.160 --> 00:40:50.420
how did she put it?--

00:40:50.420 --> 00:40:52.550
problem solving or
something like that, right?

00:40:52.550 --> 00:40:55.820
That's a good way to-- if
you need one general purpose

00:40:55.820 --> 00:40:59.930
definition of cognition,
that's a good way to put it.

00:40:59.930 --> 00:41:02.900
And then, on the other hand,
there's pattern recognition.

00:41:02.900 --> 00:41:05.840
And so you could ask, well, how
does pattern recognition more

00:41:05.840 --> 00:41:08.180
generally work and
what have we learned

00:41:08.180 --> 00:41:11.240
about how it works in the
cortex or computationally

00:41:11.240 --> 00:41:13.790
from studying the commonalities
between these two sense

00:41:13.790 --> 00:41:14.829
modalities?

00:41:14.829 --> 00:41:16.370
And then how does
pattern recognition

00:41:16.370 --> 00:41:18.650
play into a larger
system that is basically

00:41:18.650 --> 00:41:21.230
trying to have goals,
build models of the world,

00:41:21.230 --> 00:41:24.770
use those goals to guide its
action plans on those models?

00:41:24.770 --> 00:41:27.530
ALEX KELL: On the public of
convolutional neural networks

00:41:27.530 --> 00:41:31.809
and deep learning, like,
they are reaching, like,

00:41:31.809 --> 00:41:33.350
kind of impressive
successes and they

00:41:33.350 --> 00:41:35.490
might eliminate some
similarities and differences

00:41:35.490 --> 00:41:37.480
between the modalities.

00:41:37.480 --> 00:41:40.090
But, in both cases,
the learning algorithm

00:41:40.090 --> 00:41:41.720
is extremely non-biological.

00:41:41.720 --> 00:41:43.930
And I was wondering
if any of you guys--

00:41:43.930 --> 00:41:45.650
like, infants
don't need millions

00:41:45.650 --> 00:41:51.242
of examples of label data
to learn what words are.

00:41:51.242 --> 00:41:52.700
So I was wondering
if you guys have

00:41:52.700 --> 00:41:56.340
any kind of thoughts on how
to make that algorithm more

00:41:56.340 --> 00:41:57.257
biologically possible?

00:41:57.257 --> 00:41:59.298
DAN YAMINS: I would go to
what Josh said earlier,

00:41:59.298 --> 00:42:01.185
which is you look at
those real physically

00:42:01.185 --> 00:42:02.060
embodied environment.

00:42:02.060 --> 00:42:05.850
You look for those low level
cues that can be used to, like,

00:42:05.850 --> 00:42:08.414
be a proxy for the higher
level information, right?

00:42:08.414 --> 00:42:09.830
And then what you
really want is--

00:42:09.830 --> 00:42:11.080
ALEX KELL: Can you be
a little more specific?

00:42:11.080 --> 00:42:11.510
What do you mean?

00:42:11.510 --> 00:42:12.500
DAN YAMINS: Well,
do you want to be--

00:42:12.500 --> 00:42:14.625
JOSH TENENBAUM: I mean,
some people have heard this

00:42:14.625 --> 00:42:16.190
from Tommy and
others here about,

00:42:16.190 --> 00:42:18.590
like, sort of kinds of
natural supervision, right?

00:42:18.590 --> 00:42:20.840
I mean, several people have
talked about this, right?

00:42:20.840 --> 00:42:22.131
Is that what you're getting at?

00:42:22.131 --> 00:42:24.590
The idea that, often,
just tracking things

00:42:24.590 --> 00:42:26.240
as they move in
the world gives you

00:42:26.240 --> 00:42:28.115
a lot of extra
effectively labeled data.

00:42:28.115 --> 00:42:30.490
You're getting lots of different
views of this microphone

00:42:30.490 --> 00:42:33.350
now, or whatever, for walking
around the stage or all

00:42:33.350 --> 00:42:35.720
of our faces as we're rotating.

00:42:35.720 --> 00:42:38.780
So, when you pointed to the
biological implausibility

00:42:38.780 --> 00:42:41.240
of the standard way of
training deep networks,

00:42:41.240 --> 00:42:43.130
I think a lot of
people are realizing--

00:42:43.130 --> 00:42:45.560
and this was the main idea
behind Tommy's conversion

00:42:45.560 --> 00:42:47.900
to now be a strong prophet
for people learning instead

00:42:47.900 --> 00:42:50.510
of being a critic, right?--
was that, the issue

00:42:50.510 --> 00:42:52.520
of needing lots of
labeled training, that's

00:42:52.520 --> 00:42:53.870
not the biggest issue.

00:42:53.870 --> 00:42:55.680
There's other issues,
like backpropagation

00:42:55.680 --> 00:42:58.970
as a mechanism of actually
propagating error gradients all

00:42:58.970 --> 00:43:00.890
the way down to a deep network.

00:43:00.890 --> 00:43:02.635
I think that
troubles more people.

00:43:02.635 --> 00:43:04.760
DAN YAMINS: I have quite
the opposite view on that.

00:43:04.760 --> 00:43:05.551
JOSH TENENBAUM: OK.

00:43:05.551 --> 00:43:07.790
DAN YAMINS: Yes.

00:43:07.790 --> 00:43:10.850
I agree that it's true that
the specific biological

00:43:10.850 --> 00:43:14.300
plausibility of a specific deep
learning, like backpropagation

00:43:14.300 --> 00:43:16.280
algorithm is probably suspect.

00:43:16.280 --> 00:43:18.210
But I suspect that
by the same token,

00:43:18.210 --> 00:43:20.570
there are somewhat
inexact versions that

00:43:20.570 --> 00:43:22.640
are biologically plausible
or more plausible

00:43:22.640 --> 00:43:24.380
anyway that could
work pretty well.

00:43:24.380 --> 00:43:26.042
I think that's less like--

00:43:26.042 --> 00:43:27.000
let me put it this way.

00:43:27.000 --> 00:43:28.010
I think that's a
flashy question.

00:43:28.010 --> 00:43:29.540
I think if you actually
end up solving that

00:43:29.540 --> 00:43:30.770
both from an algorithm
point of view

00:43:30.770 --> 00:43:33.186
and maybe, more importantly,
seeing how that's implemented

00:43:33.186 --> 00:43:37.176
in a kind of real
neural circumstance,

00:43:37.176 --> 00:43:38.300
you'll win the Nobel Prize.

00:43:38.300 --> 00:43:41.192
But, I mean, I think that--

00:43:41.192 --> 00:43:43.400
I feel like that's something
that will happen, right?

00:43:43.400 --> 00:43:45.500
I think that there
is a bigger question

00:43:45.500 --> 00:43:48.650
out there, which is, you know--

00:43:48.650 --> 00:43:50.720
I do think that from an
algorithmic point of view

00:43:50.720 --> 00:43:52.820
which things that people
don't yet know how to do,

00:43:52.820 --> 00:43:55.850
how to replace, like, millions
of heavily semantic training

00:43:55.850 --> 00:43:58.525
examples with those
other things, right?

00:43:58.525 --> 00:44:01.025
Like, the things that you just
mentioned a moment ago, like,

00:44:01.025 --> 00:44:02.260
the extra data.

00:44:02.260 --> 00:44:04.010
Like, it hasn't actually
been demonstrated

00:44:04.010 --> 00:44:04.926
how to really do that.

00:44:04.926 --> 00:44:08.750
And I feel like the details of
getting that right will tell us

00:44:08.750 --> 00:44:11.942
a lot about the signals that
babies and others are paying

00:44:11.942 --> 00:44:14.150
attention to in a way that's
really conceptually very

00:44:14.150 --> 00:44:17.470
interesting and, I think, not
so obvious at this point how

00:44:17.470 --> 00:44:18.010
that's--

00:44:18.010 --> 00:44:19.280
I think it'll happen
too, but it will

00:44:19.280 --> 00:44:21.500
be conceptually interesting
when it does in a way

00:44:21.500 --> 00:44:21.980
that I think that--

00:44:21.980 --> 00:44:22.950
JOSH TENENBAUM: Both
are pretty interesting.

00:44:22.950 --> 00:44:23.180
DAN YAMINS: Yeah.

00:44:23.180 --> 00:44:24.164
JOSH TENENBAUM:
Some people are more

00:44:24.164 --> 00:44:25.148
worried about one or the other.

00:44:25.148 --> 00:44:25.640
But, yeah.

00:44:25.640 --> 00:44:26.220
DAN YAMINS: Exactly.

00:44:26.220 --> 00:44:28.520
And, personally, I would
say that, from an algorithm

00:44:28.520 --> 00:44:30.170
point of view, I'm more
interested in that second one,

00:44:30.170 --> 00:44:32.960
because I think that will be
a place where the biology will

00:44:32.960 --> 00:44:34.711
help us teach how to
do better algorithms.

00:44:34.711 --> 00:44:37.001
JOSH TENENBAUM: Learning
about the biological mechanism

00:44:37.001 --> 00:44:38.966
backpropagation seems
less likely to transform

00:44:38.966 --> 00:44:39.590
our algorithms.

00:44:39.590 --> 00:44:42.320
Although, again, if you ask
Andrew Sax-- he's one person.

00:44:42.320 --> 00:44:43.400
He's been here.

00:44:43.400 --> 00:44:45.830
He's think-- that's the
question he most wants to solve,

00:44:45.830 --> 00:44:47.272
and he's a very smart person.

00:44:47.272 --> 00:44:48.980
And I think he has
some thoughts on that.

00:44:48.980 --> 00:44:53.194
But I-- my sympathies
are also with you there.

00:44:53.194 --> 00:44:55.610
I think there are other things
besides those that are both

00:44:55.610 --> 00:44:58.430
biologically and cognitively
implausible that need work,

00:44:58.430 --> 00:45:01.230
too, so those-- but those are
two of the main ones that--

00:45:01.230 --> 00:45:03.355
HYNEK HERMANSKY: I think
you are touching something

00:45:03.355 --> 00:45:06.230
very interesting, and one of
the major problems with machine

00:45:06.230 --> 00:45:08.160
learning in general,
as I see it,

00:45:08.160 --> 00:45:12.030
which is like use of transcribed
or untranscribed data.

00:45:12.030 --> 00:45:14.640
And I think that this is one
direction, which actually,

00:45:14.640 --> 00:45:17.660
specifically in the speech,
it's a big, big, big problem

00:45:17.660 --> 00:45:21.220
because, of course,
data is expensive, so--

00:45:21.220 --> 00:45:22.910
unless you are Google.

00:45:22.910 --> 00:45:26.210
But even there, you will want
to have it transcribe data.

00:45:26.210 --> 00:45:29.185
You want to know what is inside,
and clearly, this is not what--

00:45:29.185 --> 00:45:31.310
JOSH TENENBAUM: You guys
have this thing in speech.

00:45:31.310 --> 00:45:33.410
I think this is I'd like to
talk more about this because you

00:45:33.410 --> 00:45:35.450
guys have this thing,
particularly at Hopkins,

00:45:35.450 --> 00:45:37.824
in speech that you call zero
resource speech recognition.

00:45:37.824 --> 00:45:39.202
HYNEK HERMANSKY: Right, that's--

00:45:39.202 --> 00:45:41.660
JOSH TENENBAUM: And I think
this is a version of this idea,

00:45:41.660 --> 00:45:44.840
but it's one of the places where
studying not just neuroscience.

00:45:44.840 --> 00:45:46.970
But cognition and what
young children do,

00:45:46.970 --> 00:45:48.830
the ability to get so
much from so little

00:45:48.830 --> 00:45:50.450
is a place where we
really have a lot

00:45:50.450 --> 00:45:52.533
to learn on the engineering
side from the science.

00:45:52.533 --> 00:45:54.590
HYNEK HERMANSKY: Yes,
I mean, [INAUDIBLE]

00:45:54.590 --> 00:45:57.210
that I could speak about it
a little bit more in depth.

00:45:57.210 --> 00:46:00.240
But definitely, this is the
direction I'm thinking about,

00:46:00.240 --> 00:46:02.420
which is like what do you
do if you don't know what

00:46:02.420 --> 00:46:05.140
is in the signal, but you
know there is a structure,

00:46:05.140 --> 00:46:08.270
and you know that there
is information you need.

00:46:08.270 --> 00:46:10.220
And you have to start
from the very scratch,

00:46:10.220 --> 00:46:13.910
figure out where information
is, how is it coded,

00:46:13.910 --> 00:46:16.910
and then use it in the machine.

00:46:16.910 --> 00:46:19.110
And I think it's
a general problem

00:46:19.110 --> 00:46:21.519
in the same thing as in region.

00:46:21.519 --> 00:46:23.060
JOSH TENENBAUM:
Maybe-- you're asking

00:46:23.060 --> 00:46:24.226
several different questions.

00:46:24.226 --> 00:46:25.280
I mean, I don't know if--

00:46:25.280 --> 00:46:26.420
have people in the
summer school talked

00:46:26.420 --> 00:46:28.250
about these instabilities
It's an interesting question.

00:46:28.250 --> 00:46:30.530
People are very much
divided on what they say.

00:46:30.530 --> 00:46:32.880
And I do think that
generative models are going

00:46:32.880 --> 00:46:34.130
to come out differently there.

00:46:34.130 --> 00:46:37.370
But, again, I don't want to
say generative models are

00:46:37.370 --> 00:46:41.390
better than discriminatively
trained pattern recognizers.

00:46:41.390 --> 00:46:43.130
I think, particularly
for perception

00:46:43.130 --> 00:46:45.296
and a lot of other areas,
what we need to understand

00:46:45.296 --> 00:46:46.790
is how to combine
the best of both.

00:46:46.790 --> 00:46:49.892
So in an audience where people
are just neural networks,

00:46:49.892 --> 00:46:51.350
rah, rah, rah, rah,
rah, and that's

00:46:51.350 --> 00:46:53.540
all there is, then I'm going to
be arguing for the other side.

00:46:53.540 --> 00:46:55.490
But that's not that I
think they are better.

00:46:55.490 --> 00:46:57.980
I think they have complementary
strengths and weaknesses.

00:46:57.980 --> 00:46:58.760
This might be one.

00:46:58.760 --> 00:47:02.300
I think pretty much any pattern
classifier, whether it's

00:47:02.300 --> 00:47:04.040
a neural network
or something else,

00:47:04.040 --> 00:47:06.980
will probably be susceptible
to these kind of pathologies

00:47:06.980 --> 00:47:10.340
where you can basically hack up
a stimulus that's arbitrarily

00:47:10.340 --> 00:47:15.410
different from an actual
member of the class that

00:47:15.410 --> 00:47:16.190
gets classified.

00:47:16.190 --> 00:47:17.900
Basically, if
you're trying to put

00:47:17.900 --> 00:47:21.256
a separating surface between
two or n finite classes--

00:47:21.256 --> 00:47:23.630
I was trying to see how to
formulate this mathematically.

00:47:23.630 --> 00:47:25.644
I think you can basically
show that it's not

00:47:25.644 --> 00:47:26.810
specific to neural networks.

00:47:26.810 --> 00:47:28.893
It should be true for any
kind of discriminatively

00:47:28.893 --> 00:47:30.110
trained pattern classifier.

00:47:30.110 --> 00:47:31.670
I think generative
models have other sorts

00:47:31.670 --> 00:47:32.930
of illusions and pathologies.

00:47:32.930 --> 00:47:34.620
But they're definitely
going to be--

00:47:34.620 --> 00:47:36.620
my sense is they're going
to be some of the ways

00:47:36.620 --> 00:47:38.720
that any pattern
classifier is susceptible,

00:47:38.720 --> 00:47:40.210
that generative models
won't be susceptible to.

00:47:40.210 --> 00:47:42.626
And there will be others that
they will be susceptible to.

00:47:42.626 --> 00:47:44.820
But it's sort of an
orthogonal issue.

00:47:44.820 --> 00:47:47.660
But I think the illusions
that generative models are

00:47:47.660 --> 00:47:51.350
susceptible to,
are generally going

00:47:51.350 --> 00:47:53.700
to have, like, interesting,
rational interpretations.

00:47:53.700 --> 00:47:54.930
It's going to tell
you something.

00:47:54.930 --> 00:47:57.020
They're less likely to be
susceptible to just completely

00:47:57.020 --> 00:47:59.061
bizarre pathologies that
we look at and are like,

00:47:59.061 --> 00:48:01.384
I don't understand
why it's seeing that.

00:48:01.384 --> 00:48:03.800
On the other hand, they're
going to have other things that

00:48:03.800 --> 00:48:04.550
will frustrate us.

00:48:04.550 --> 00:48:06.230
And my inference
algorithm is stuck.

00:48:06.230 --> 00:48:09.320
I don't understand why my
Markov chain isn't converging.

00:48:09.320 --> 00:48:12.230
If that's the only way
you're going to do inference,

00:48:12.230 --> 00:48:14.690
you'll be very frustrated by
the dynamics of inference.

00:48:14.690 --> 00:48:16.273
And that's where,
hopefully, some kind

00:48:16.273 --> 00:48:19.040
of pattern recognition system
will come to the rescue.

00:48:19.040 --> 00:48:21.410
And if we just look at
anecdotal experience,

00:48:21.410 --> 00:48:23.737
both in speech and vision,
there are certain kinds

00:48:23.737 --> 00:48:25.820
of cases where, like, you
know, in a passing rock,

00:48:25.820 --> 00:48:28.520
you suddenly see a
face, or a noise.

00:48:28.520 --> 00:48:30.560
Or in a tree people
will see Jesus's face

00:48:30.560 --> 00:48:32.990
on arbitrary parts
of the visual world.

00:48:32.990 --> 00:48:34.640
And also sometimes in sound.

00:48:34.640 --> 00:48:36.290
You hear something.

00:48:36.290 --> 00:48:42.420
So this idea of seeing signal in
noise, we know humans do that.

00:48:42.420 --> 00:48:45.200
But, for example, there are
ways to get deep confidence

00:48:45.200 --> 00:48:47.417
in vision to see--

00:48:47.417 --> 00:48:49.250
you can start off with
an arbitrary texture.

00:48:49.250 --> 00:48:50.460
Have you seen this stuff?

00:48:50.460 --> 00:48:53.140
And massage it to look like--

00:48:53.140 --> 00:48:55.380
like you can start off with
a texture of green bars

00:48:55.380 --> 00:48:57.289
and make it look like
a dog to the network,

00:48:57.289 --> 00:48:58.830
and it doesn't look
like a dog to us.

00:48:58.830 --> 00:49:01.290
And we're never going to see
a dog in a periodic pattern

00:49:01.290 --> 00:49:03.260
of green and polka dotted bars.

00:49:03.260 --> 00:49:03.570
JOSH MCDERMOTT:
But the reason you

00:49:03.570 --> 00:49:05.135
can do that is because
perfect access to the network.

00:49:05.135 --> 00:49:05.500
Right?

00:49:05.500 --> 00:49:07.320
And if you had perfect access
to visual stimuli [INAUDIBLE]..

00:49:07.320 --> 00:49:07.420
JOSH TENENBAUM: Sure.

00:49:07.420 --> 00:49:07.470
Sure.

00:49:07.470 --> 00:49:08.928
But I'm just saying--
these don't--

00:49:08.928 --> 00:49:09.890
well, I don't think so.

00:49:09.890 --> 00:49:10.260
DAN YAMINS: Of
course there's going

00:49:10.260 --> 00:49:11.730
to be visual illusions
in every case.

00:49:11.730 --> 00:49:12.780
The question is
whether or not they're

00:49:12.780 --> 00:49:13.830
going to make sense to humans--

00:49:13.830 --> 00:49:14.100
JOSH TENENBAUM: Right.

00:49:14.100 --> 00:49:15.390
And I think some of them--

00:49:15.390 --> 00:49:16.980
ALEX KELL: --as a test of
whether or not that model--

00:49:16.980 --> 00:49:17.930
JOSH TENENBAUM: If you
learned something from that.

00:49:17.930 --> 00:49:19.020
DAN YAMINS: --is a real model.

00:49:19.020 --> 00:49:20.395
JOSH TENENBAUM:
Just to be clear,

00:49:20.395 --> 00:49:22.650
the ones that the convnets
are susceptible to that say

00:49:22.650 --> 00:49:24.384
a generative model
or a human isn't--

00:49:24.384 --> 00:49:26.550
they're not signs that
they're fundamentally broken.

00:49:26.550 --> 00:49:29.310
Rather they're signs of any
discriminatively trained

00:49:29.310 --> 00:49:30.150
pattern recognizer.

00:49:30.150 --> 00:49:32.890
I would predict, whether
it's good or bad,

00:49:32.890 --> 00:49:35.610
it's signs of the limitations
of pattern recognition.

00:49:35.610 --> 00:49:38.550
DAN YAMINS: Or signs of the
limitation of the type of tasks

00:49:38.550 --> 00:49:43.050
that are being used of which
the recognition is being done.

00:49:43.050 --> 00:49:45.600
If you replaced something like
categorization with something

00:49:45.600 --> 00:49:51.030
like the ability to predict
geometric and physical

00:49:51.030 --> 00:49:53.910
interactions x period
of time in the future,

00:49:53.910 --> 00:49:56.980
maybe you'd end up with
quite different illusions.

00:49:56.980 --> 00:49:57.480
Right?

00:49:57.480 --> 00:49:59.605
There's something very
brittle about categorization

00:49:59.605 --> 00:50:02.720
that could lead to, sort of
null space as being very broad.

00:50:02.720 --> 00:50:03.720
JOSH TENENBAUM: Exactly.

00:50:03.720 --> 00:50:04.290
That's what I mean.

00:50:04.290 --> 00:50:06.498
By pattern recognition, I
mean pattern classification

00:50:06.498 --> 00:50:08.280
in particular.

00:50:08.280 --> 00:50:09.727
Not prediction but
classification.

00:50:09.727 --> 00:50:10.477
DAN YAMINS: Right.

00:50:10.477 --> 00:50:13.650
But I don't think it's yet known
whether the existence of these,

00:50:13.650 --> 00:50:17.790
sort of fooling images or this
kind of weird allusions, e.g.

00:50:17.790 --> 00:50:19.650
the models are bad
or do not pick out

00:50:19.650 --> 00:50:21.204
the correct resolutions.

00:50:21.204 --> 00:50:22.120
I don't know whether--

00:50:22.120 --> 00:50:23.280
people are not totally
sure whether that's

00:50:23.280 --> 00:50:24.989
like, the networks
need to have feedback,

00:50:24.989 --> 00:50:27.071
and that will be what you
really need to solve it.

00:50:27.071 --> 00:50:28.860
It's at that broad
level of mechanism.

00:50:28.860 --> 00:50:30.937
Or is it like,
the task is wrong?

00:50:30.937 --> 00:50:32.520
So it's sort of a
little bit less bad.

00:50:32.520 --> 00:50:35.400
Or maybe like Josh said, it's
like the easiest thing would

00:50:35.400 --> 00:50:37.060
be, well, actually
if you just did this

00:50:37.060 --> 00:50:39.150
with the neural system, you'd
find exactly the same thing.

00:50:39.150 --> 00:50:41.270
But we don't have access to
it, so we're not finding it.

00:50:41.270 --> 00:50:41.790
Right?

00:50:41.790 --> 00:50:45.850
And so I think it's not
totally clear where it is yet.

00:50:45.850 --> 00:50:46.350
Right?

00:50:46.350 --> 00:50:49.080
It's a great question, but I
feel like the answers are murky

00:50:49.080 --> 00:50:50.234
right now.

00:50:50.234 --> 00:50:50.900
ALEX KELL: Yeah.

00:50:50.900 --> 00:50:51.990
OK.

00:50:51.990 --> 00:50:56.200
On the topic of feedback, I
wanted to kind of move over--

00:50:56.200 --> 00:50:58.980
and Gabriel talked about
feedback during his talk.

00:50:58.980 --> 00:51:01.272
And there's really
heavy kind of feedback

00:51:01.272 --> 00:51:02.730
in both of these
modalities, where,

00:51:02.730 --> 00:51:04.800
like, in hearing as
Josh talked about,

00:51:04.800 --> 00:51:06.930
it goes all the
way back to, it can

00:51:06.930 --> 00:51:09.690
alter the mechanics
of the cochlea,

00:51:09.690 --> 00:51:11.082
of the basilar membrane.

00:51:11.082 --> 00:51:12.040
That's pretty shocking.

00:51:12.040 --> 00:51:13.300
That's pretty interesting.

00:51:13.300 --> 00:51:15.017
So what is the role--

00:51:15.017 --> 00:51:17.100
Gabriel talked about a
couple of specific examples

00:51:17.100 --> 00:51:21.160
where feedback would
actually be useful.

00:51:21.160 --> 00:51:23.219
Can you say something
more broadly about,

00:51:23.219 --> 00:51:25.260
in general when is feedback
useful across the two

00:51:25.260 --> 00:51:25.750
modalities?

00:51:25.750 --> 00:51:27.791
Do we think they are kind
of specific instances--

00:51:27.791 --> 00:51:29.680
can we talk about specific
instances in each?

00:51:29.680 --> 00:51:31.554
GABRIEL KREIMAN: Throughout
the visual system

00:51:31.554 --> 00:51:36.600
there is feedback essentially
all over except for the retina.

00:51:36.600 --> 00:51:38.540
Throughout the
auditory cortex, again

00:51:38.540 --> 00:51:43.580
this feedback and recurrent
connections all over.

00:51:48.030 --> 00:51:52.620
We've been interested in
a couple of specific apps

00:51:52.620 --> 00:51:56.000
in situations where feedback
may be playing a role.

00:51:56.000 --> 00:51:58.650
This includes visual search.

00:51:58.650 --> 00:52:02.550
This includes
pattern completion,

00:52:02.550 --> 00:52:04.890
feature-based attention.

00:52:04.890 --> 00:52:07.410
I believe, and hopefully
Josh will expand on this

00:52:07.410 --> 00:52:09.570
that these are problems
that at least at a very

00:52:09.570 --> 00:52:12.420
superficial level also exist
in the auditory domain,

00:52:12.420 --> 00:52:15.900
and where it's tempting to
think that feedback will also

00:52:15.900 --> 00:52:18.670
play a role.

00:52:18.670 --> 00:52:20.970
More generally, you
can mathematically

00:52:20.970 --> 00:52:24.000
demonstrate that any
network with feedback

00:52:24.000 --> 00:52:26.130
can be transformed into
a feed-forward network

00:52:26.130 --> 00:52:31.350
just by decomposing
time into more layers.

00:52:31.350 --> 00:52:39.000
So I think ultimately,
feedback in the cortex

00:52:39.000 --> 00:52:41.550
may have a lot to do with, how
many layers can you actually

00:52:41.550 --> 00:52:47.230
fit into a system
the size of the head

00:52:47.230 --> 00:52:50.087
that it has to go through--
interesting places

00:52:50.087 --> 00:52:50.670
at some point.

00:52:50.670 --> 00:52:53.050
And there are sort of
physical limitations

00:52:53.050 --> 00:52:57.674
to that more than fundamental
computational ones.

00:52:57.674 --> 00:52:59.340
At the heart of this
is the question of,

00:52:59.340 --> 00:53:01.359
how many recurrent
computations do you need?

00:53:01.359 --> 00:53:03.900
How much feedback you actually
need, how many recurrent loops

00:53:03.900 --> 00:53:04.870
you need.

00:53:04.870 --> 00:53:07.326
If that involves only
two or three loops,

00:53:07.326 --> 00:53:08.700
I think it's easy
to convert that

00:53:08.700 --> 00:53:11.830
into a feed forward network
that will do the same job.

00:53:11.830 --> 00:53:14.640
If that involves hundreds
of iterations and loops,

00:53:14.640 --> 00:53:17.860
it's harder to think about
a biological system that

00:53:17.860 --> 00:53:19.620
will accomplish that.

00:53:19.620 --> 00:53:21.480
But at least at the
very superficial level,

00:53:21.480 --> 00:53:22.396
I would imagine that--

00:53:22.396 --> 00:53:25.837
JOSH TENENBAUM: Can I ask
a very focused version

00:53:25.837 --> 00:53:27.420
of the same question,
or try to, which

00:53:27.420 --> 00:53:30.110
is, what is the computational
role of feedback

00:53:30.110 --> 00:53:31.770
in vision and audition?

00:53:31.770 --> 00:53:33.630
Like when we talk
about feedback,

00:53:33.630 --> 00:53:36.180
maybe we mean something
like top-down connections

00:53:36.180 --> 00:53:39.781
in the brain or something
like recurrent processing.

00:53:39.781 --> 00:53:42.030
Just from a computational
point of view of the problem

00:53:42.030 --> 00:53:43.405
we're trying to
solve, what do we

00:53:43.405 --> 00:53:45.170
think its roles are
in each of those?

00:53:45.170 --> 00:53:45.750
GABRIEL KREIMAN:
So more and more,

00:53:45.750 --> 00:53:47.550
I think that's the wrong
kind of question to ask.

00:53:47.550 --> 00:53:48.000
If I ask you--

00:53:48.000 --> 00:53:48.630
JOSH TENENBAUM: Why?

00:53:48.630 --> 00:53:51.171
GABRIEL KREIMAN: What's the role
of feed-forward connections?

00:53:51.171 --> 00:53:52.850
JOSH TENENBAUM:
Pattern recognition.

00:53:52.850 --> 00:53:53.665
GABRIEL KREIMAN:
There is no role

00:53:53.665 --> 00:53:54.870
of feed-forward connections.

00:53:54.870 --> 00:53:55.010
JOSH TENENBAUM: No.

00:53:55.010 --> 00:53:55.830
On the contrary.

00:53:55.830 --> 00:53:56.872
Tommy has a theory of it.

00:53:56.872 --> 00:53:58.288
You know, you have
another theory.

00:53:58.288 --> 00:53:59.760
Something like
very quickly trying

00:53:59.760 --> 00:54:01.800
to find invariant features--

00:54:01.800 --> 00:54:04.289
trying to very quickly
find invariant features

00:54:04.289 --> 00:54:05.580
of certain classes of patterns.

00:54:05.580 --> 00:54:06.540
That's a hypothesis.

00:54:06.540 --> 00:54:08.114
It's pretty well supported.

00:54:08.114 --> 00:54:09.780
GABRIEL KREIMAN:
There's a lot of things

00:54:09.780 --> 00:54:10.770
that happen with feed-forward.

00:54:10.770 --> 00:54:12.728
HYNEK HERMANSKY: If you
want a feed so that you

00:54:12.728 --> 00:54:15.140
can make things better
somehow, I mean, you

00:54:15.140 --> 00:54:17.280
need a measure of
goodness first.

00:54:17.280 --> 00:54:19.290
I mean, otherwise I
mean, how to build--

00:54:19.290 --> 00:54:21.720
I agree with you
that you can make

00:54:21.720 --> 00:54:25.440
a very deep structure which will
function as a feedback thing.

00:54:25.440 --> 00:54:27.450
But always what
worries me the most,

00:54:27.450 --> 00:54:30.570
and in general a number
of cognitive problems,

00:54:30.570 --> 00:54:36.870
is, how do I provide my machine
with some mechanism which

00:54:36.870 --> 00:54:40.230
tells the machine that
output is good or not?

00:54:40.230 --> 00:54:43.830
If the output is bad, if my
image is making no sense,

00:54:43.830 --> 00:54:47.520
there is no dog but it's a kind
of weird mix of green things

00:54:47.520 --> 00:54:50.290
and it's telling me it's
a dog, I need feedback.

00:54:50.290 --> 00:54:52.410
That's the point I need
the feedback, I believe.

00:54:52.410 --> 00:54:53.600
And I need to fix things.

00:54:53.600 --> 00:54:56.280
Josh is talking about
tuning the cochlea.

00:54:56.280 --> 00:54:59.880
Yeah, of course that means
that sharpening the tuning

00:54:59.880 --> 00:55:00.540
is possible.

00:55:00.540 --> 00:55:02.880
But in communication,
I mean, if things

00:55:02.880 --> 00:55:05.190
are noisy I go ahead
and close the door.

00:55:05.190 --> 00:55:06.740
There's the feedback to me.

00:55:06.740 --> 00:55:09.240
But I know, as a
human being, I know

00:55:09.240 --> 00:55:11.550
information is not
getting through,

00:55:11.550 --> 00:55:12.960
and I do something about it.

00:55:12.960 --> 00:55:13.880
And this is what we--

00:55:13.880 --> 00:55:14.160
JOSH TENENBAUM:
That's great You just

00:55:14.160 --> 00:55:16.372
gave two good examples
of, I think, just

00:55:16.372 --> 00:55:18.330
to generalize those,
right, or just to say them

00:55:18.330 --> 00:55:19.260
in more general terms.

00:55:19.260 --> 00:55:21.839
One role of feedback that
people have hypothesized

00:55:21.839 --> 00:55:23.880
is like in the context of
something like analysis

00:55:23.880 --> 00:55:24.467
by synthesis.

00:55:24.467 --> 00:55:26.550
If you have a high level
model of what's going on,

00:55:26.550 --> 00:55:27.970
and you want to see, does
that really make sense?

00:55:27.970 --> 00:55:29.860
Does that really explain
my low level data?

00:55:29.860 --> 00:55:32.400
Let me try it out and see that.

00:55:32.400 --> 00:55:34.527
Another is, basically
saying, the role

00:55:34.527 --> 00:55:37.110
of the feed-forward connections
is a kind of invariant pattern

00:55:37.110 --> 00:55:40.290
recognizer, and tuning
those, tuning the filters,

00:55:40.290 --> 00:55:44.340
tuning the patterns to
context or in particular

00:55:44.340 --> 00:55:48.000
in a contextual way to
make the features more

00:55:48.000 --> 00:55:49.860
diagnostic in this
particular context.

00:55:49.860 --> 00:55:51.210
Those are two ideas.

00:55:51.210 --> 00:55:51.810
And they are probably others.

00:55:51.810 --> 00:55:54.018
HYNEK HERMANSKY: Yeah, you
gave the wonderful example

00:55:54.018 --> 00:55:55.860
with analysis by synthesis.

00:55:55.860 --> 00:55:59.490
But even there, we
need an error measure.

00:55:59.490 --> 00:56:01.410
And I'm not saying
that least mean

00:56:01.410 --> 00:56:03.830
squared error between
what I generate

00:56:03.830 --> 00:56:05.700
and what I see is the right one.

00:56:05.700 --> 00:56:06.380
JOSH TENENBAUM: So
you think feedback

00:56:06.380 --> 00:56:08.160
if it helps tune
the error measure.

00:56:08.160 --> 00:56:09.670
HYNEK HERMANSKY: Well, no.

00:56:09.670 --> 00:56:11.160
It's a chicken and egg problem.

00:56:11.160 --> 00:56:13.920
I think I need the error
measure first, before I even

00:56:13.920 --> 00:56:15.557
start using the feedback.

00:56:15.557 --> 00:56:17.640
Because, you know, feedback,
we can talk about it.

00:56:17.640 --> 00:56:19.590
But if you want to
implement it, you

00:56:19.590 --> 00:56:22.680
have to figure out, what
is the error measure

00:56:22.680 --> 00:56:23.985
or what is the criteria?

00:56:23.985 --> 00:56:28.422
And that I recognize my output
is bad or not good enough.

00:56:28.422 --> 00:56:29.880
Obviously it will
a little bit bad.

00:56:29.880 --> 00:56:30.379
Right?

00:56:30.379 --> 00:56:33.000
I am not good enough and I
have to do something about it.

00:56:33.000 --> 00:56:36.600
Once I know it, I know
what to do, I think.

00:56:36.600 --> 00:56:39.559
Well maybe not me, but
my students, whatever.

00:56:39.559 --> 00:56:41.850
This is one of the big problems
in which we are working

00:56:41.850 --> 00:56:43.890
on actually-- figuring
out, how can I

00:56:43.890 --> 00:56:46.590
tell that output from my
neural net or something

00:56:46.590 --> 00:56:49.630
is good or bad?

00:56:49.630 --> 00:56:52.014
And so far I don't
have any answer.

00:56:55.929 --> 00:56:58.470
JOSH TENENBAUM: But I think it's
neat that those two or three

00:56:58.470 --> 00:56:59.594
different kinds of things--

00:56:59.594 --> 00:57:02.880
they are totally parallel
in vision and audition.

00:57:02.880 --> 00:57:04.890
They're useful for
both, engineering-wise,

00:57:04.890 --> 00:57:07.890
and people have long proposed
them both in psychology

00:57:07.890 --> 00:57:09.084
and neuroscience.

00:57:09.084 --> 00:57:10.500
GABRIEL KREIMAN:
Generally I think

00:57:10.500 --> 00:57:12.458
there's a lot to be done
in this area, I think.

00:57:12.458 --> 00:57:15.957
And the notion of adding--

00:57:15.957 --> 00:57:17.540
I mean, a lot of
what's been happening

00:57:17.540 --> 00:57:19.623
in commercial networks is
sort of tweaks and hacks

00:57:19.623 --> 00:57:20.370
here and there.

00:57:20.370 --> 00:57:22.290
If there are fundamental
principles that

00:57:22.290 --> 00:57:25.140
come from studying recurrent
connections and feedback

00:57:25.140 --> 00:57:27.252
from the auditory domain,
from the visual domain,

00:57:27.252 --> 00:57:29.460
those are the sort of things
that, as Dan was saying,

00:57:29.460 --> 00:57:33.940
could potentially sort of lead
to major jumps in performance

00:57:33.940 --> 00:57:36.660
or in our conceptual
understanding of what

00:57:36.660 --> 00:57:38.470
these networks are doing.

00:57:38.470 --> 00:57:41.010
I think it's a very rich
area of exploration,

00:57:41.010 --> 00:57:45.920
both in vision and
the auditory world.

00:57:45.920 --> 00:57:49.632
ALEX KELL: And wanted to
ask Josh one more thing--

00:57:49.632 --> 00:57:50.840
the common constraints thing.

00:57:50.840 --> 00:57:52.150
You were kind of saying like,
it seems like there would

00:57:52.150 --> 00:57:53.983
be common constraints
and there are probably

00:57:53.983 --> 00:57:56.390
consequences of those.

00:57:56.390 --> 00:57:58.250
What are some kind of
specific consequences

00:57:58.250 --> 00:57:59.499
that you think would come out?

00:57:59.499 --> 00:58:02.810
Like, how can we
think about this?

00:58:02.810 --> 00:58:05.120
To the extent that there
is kind of a shared system,

00:58:05.120 --> 00:58:06.590
what does it mean?

00:58:11.500 --> 00:58:13.140
JOSH TENENBAUM:
Well-- so again, I

00:58:13.140 --> 00:58:15.330
can only, as several of
the other speakers said,

00:58:15.330 --> 00:58:18.720
only give my very, very
personal, subjectively

00:58:18.720 --> 00:58:19.710
biased view.

00:58:19.710 --> 00:58:22.290
But I think the brain
has a way to think

00:58:22.290 --> 00:58:23.874
about the physical
world to represent,

00:58:23.874 --> 00:58:25.164
to perceive the physical world.

00:58:25.164 --> 00:58:27.540
And it's really like a
physics engine in your head.

00:58:27.540 --> 00:58:28.987
And that the different--

00:58:28.987 --> 00:58:30.570
it's like analysis
by synthesis that's

00:58:30.570 --> 00:58:33.000
a familiar idea probably
best developed classically

00:58:33.000 --> 00:58:36.780
in speech, but in a way
that's almost independent

00:58:36.780 --> 00:58:37.690
of sense modality.

00:58:37.690 --> 00:58:39.800
I think we have different
sensory modalities,

00:58:39.800 --> 00:58:41.550
and they're all just
different projections

00:58:41.550 --> 00:58:44.730
of an underlying physical
representation of the world.

00:58:44.730 --> 00:58:47.340
I think that, whether
it's understanding

00:58:47.340 --> 00:58:50.820
simple kinds of events as I
was trying to illustrate here,

00:58:50.820 --> 00:58:53.310
or many other kinds of
things, I think, basically,

00:58:53.310 --> 00:58:55.740
at some one, one of
the key outputs of all

00:58:55.740 --> 00:58:58.860
of these different
sensory processing

00:58:58.860 --> 00:59:01.350
pipelines has to be
a shared system that

00:59:01.350 --> 00:59:03.450
represents the world
in three dimensions

00:59:03.450 --> 00:59:07.410
with physical objects that
have physical reality--

00:59:07.410 --> 00:59:11.000
properties like mass
or surface properties

00:59:11.000 --> 00:59:13.730
that produce friction when it
comes to motion-- roughness.

00:59:13.730 --> 00:59:14.230
Right.

00:59:14.230 --> 00:59:19.440
There's some way to think about
the forces, whether the force

00:59:19.440 --> 00:59:20.860
that one object
exerts on another,

00:59:20.860 --> 00:59:24.300
or the force that an object
presents in resisting,

00:59:24.300 --> 00:59:28.110
when I reach for it, either the
rigidity that resists my grasp

00:59:28.110 --> 00:59:30.418
and that [INAUDIBLE] with it.

00:59:30.418 --> 00:59:32.000
Or the weight of
the object that that

00:59:32.000 --> 00:59:34.630
requires me to exert
some weight to do that.

00:59:34.630 --> 00:59:36.720
So I think there
has to be a shared

00:59:36.720 --> 00:59:40.050
representation that bridges
perception to action.

00:59:40.050 --> 00:59:42.480
And that it's a
physical representation,

00:59:42.480 --> 00:59:44.910
and that it has to bridge--
it's the same representations

00:59:44.910 --> 00:59:47.160
that's going to bridge the
different sense modalities.

00:59:47.160 --> 00:59:49.077
DAN YAMINS: Yeah, but
to make [INAUDIBLE]..

00:59:49.077 --> 00:59:50.160
JOSH TENENBAUM: More what?

00:59:50.160 --> 00:59:52.080
DAN YAMINS: More
brain meat-oriented,

00:59:52.080 --> 00:59:53.840
I think that there's
a version of that

00:59:53.840 --> 00:59:56.310
that could be a constraint
that is so strong that you have

00:59:56.310 --> 00:59:58.260
to have a special
brain area that's

00:59:58.260 --> 00:59:59.850
used as the
clearinghouse for doing

00:59:59.850 --> 01:00:00.610
that common representation.

01:00:00.610 --> 01:00:01.530
JOSH TENENBAUM: I'm
certainly not saying that.

01:00:01.530 --> 01:00:01.770
DAN YAMINS: OK.

01:00:01.770 --> 01:00:01.950
Right.

01:00:01.950 --> 01:00:03.116
No, I didn't think you were.

01:00:03.116 --> 01:00:04.659
But that would be
a concrete result.

01:00:04.659 --> 01:00:06.450
Another concrete result
is like effectively

01:00:06.450 --> 01:00:11.640
that the individual modality
structures are constrained

01:00:11.640 --> 01:00:13.350
in such a way that
they have an API that

01:00:13.350 --> 01:00:16.290
has access to information
from the other modality,

01:00:16.290 --> 01:00:19.620
so that message passing is
efficient, among other things.

01:00:19.620 --> 01:00:20.120
Right?

01:00:20.120 --> 01:00:21.600
And I think that they
can talk to each other.

01:00:21.600 --> 01:00:22.680
JOSH TENENBAUM: I think
it's often not direct.

01:00:22.680 --> 01:00:25.290
I think some of it might be,
but a lot of it is going to be--

01:00:25.290 --> 01:00:27.706
it's not like vision talking
to audition, but each of them

01:00:27.706 --> 01:00:29.870
talking to physics.

01:00:29.870 --> 01:00:30.620
DAN YAMINS: Right.

01:00:30.620 --> 01:00:31.485
Right.

01:00:31.485 --> 01:00:33.360
JOSH TENENBAUM: It's
very hard for a lot of--

01:00:33.360 --> 01:00:33.845
DAN YAMINS: Right.

01:00:33.845 --> 01:00:34.870
And that's a third--

01:00:34.870 --> 01:00:35.260
JOSH TENENBAUM: Mid-level
vision and mid-level audition

01:00:35.260 --> 01:00:36.300
are hard to talk to each other.

01:00:36.300 --> 01:00:36.430
DAN YAMINS: Right.

01:00:36.430 --> 01:00:38.010
And a third possibility is
is that it's actually not

01:00:38.010 --> 01:00:40.301
really so much of-- it that
there's no particular brain

01:00:40.301 --> 01:00:42.900
area, and they're not exactly
talking to each other API

01:00:42.900 --> 01:00:43.659
directly.

01:00:43.659 --> 01:00:46.200
It's just that there is a common
constraint in the world that

01:00:46.200 --> 01:00:49.170
forces them to have
similar structure

01:00:49.170 --> 01:00:52.350
or sort of aligned structure
for representing the things that

01:00:52.350 --> 01:00:54.799
are caused by the same
underlying phenomenon.

01:00:54.799 --> 01:00:57.090
And that's like the weakest
of the types of constraints

01:00:57.090 --> 01:00:57.923
that you might have.

01:00:57.923 --> 01:00:58.590
Right?

01:00:58.590 --> 01:01:01.110
The first one is very strong.

01:01:01.110 --> 01:01:03.610
JOSH TENENBAUM: But it's not
it's not vague or content-less.

01:01:03.610 --> 01:01:05.520
So, Nancy Kanwisher
and Jason Fisher

01:01:05.520 --> 01:01:06.960
have a particular hypothesis.

01:01:06.960 --> 01:01:08.910
They've been doing some
preliminary studies

01:01:08.910 --> 01:01:11.118
on the kind of intuitive
physics engine in the brain.

01:01:11.118 --> 01:01:13.320
And they could point to
a network of brain areas,

01:01:13.320 --> 01:01:15.390
some premotor, some parietal.

01:01:15.390 --> 01:01:16.900
You know, it's possible.

01:01:16.900 --> 01:01:17.400
Who knows.

01:01:17.400 --> 01:01:18.275
It's very early days.

01:01:18.275 --> 01:01:20.820
But this might be
a candidate way

01:01:20.820 --> 01:01:24.900
into a view of
brain systems that

01:01:24.900 --> 01:01:26.140
might be this physics engine.

01:01:26.140 --> 01:01:26.590
DAN YAMINS: Right.

01:01:26.590 --> 01:01:27.000
But you are--

01:01:27.000 --> 01:01:28.705
JOSH TENENBAUM: Also
ventral stream area.

01:01:28.705 --> 01:01:30.455
DAN YAMINS: [INAUDIBLE]
be something like,

01:01:30.455 --> 01:01:33.330
if you optimized network's
set of parameters

01:01:33.330 --> 01:01:37.190
to do the joint physics
prediction interaction task,

01:01:37.190 --> 01:01:39.440
you'll get a different result
than if you sort of just

01:01:39.440 --> 01:01:41.340
did each modality separately.

01:01:41.340 --> 01:01:44.010
And that would be a better--
that new different thing would

01:01:44.010 --> 01:01:47.010
be a better match to the
actual neural response patterns

01:01:47.010 --> 01:01:47.870
in interesting--

01:01:47.870 --> 01:01:48.150
JOSH TENENBAUM: Yeah.

01:01:48.150 --> 01:01:49.410
I think would make really
cool thing to explore.

01:01:49.410 --> 01:01:50.880
DAN YAMINS: And that's, I think
the concrete way with cache

01:01:50.880 --> 01:01:51.040
out.

01:01:51.040 --> 01:01:52.350
And that certainly
seems possible.

01:01:52.350 --> 01:01:52.920
JOSH TENENBAUM: And
it might be, you know,

01:01:52.920 --> 01:01:55.450
a lot of things which
are traditionally called

01:01:55.450 --> 01:01:57.510
association cortex, right.

01:01:57.510 --> 01:01:59.940
This is an old idea and I'm
not enough of a neuroscientist

01:01:59.940 --> 01:02:02.139
to know, but a
cartoon history is,

01:02:02.139 --> 01:02:04.680
there are lots of parts of the
brain that nobody could figure

01:02:04.680 --> 01:02:06.680
what they were doing
because they didn't respond

01:02:06.680 --> 01:02:09.570
in an obvious selective way to
one particular sense modality.

01:02:09.570 --> 01:02:12.700
It wasn't exactly obvious
what the deficit was.

01:02:12.700 --> 01:02:16.280
And so they can be called
the association cortex.

01:02:16.280 --> 01:02:19.650
That connects to the study
of cross-modal association

01:02:19.650 --> 01:02:22.575
and association to semantics,
and this idea of association.

01:02:22.575 --> 01:02:24.450
It's this thing you say
when you don't really

01:02:24.450 --> 01:02:25.350
know what's going on.

01:02:25.350 --> 01:02:28.170
But it's quite possible
that big chunks

01:02:28.170 --> 01:02:30.660
of the brain we're
calling association cortex

01:02:30.660 --> 01:02:33.150
are actually doing
something like this.

01:02:33.150 --> 01:02:36.540
They're this convergence
zone for a shared

01:02:36.540 --> 01:02:38.850
physical representation
across different perceptional

01:02:38.850 --> 01:02:42.200
modalities and bridging
to action plan.

01:02:42.200 --> 01:02:45.450
And a big open
challenge is that we

01:02:45.450 --> 01:02:49.050
can have what feels to
us like a deep debate

01:02:49.050 --> 01:02:51.784
that we can think of as like the
central problem in neuroscience

01:02:51.784 --> 01:02:53.950
of, how do we combine
whatever you want to call it--

01:02:53.950 --> 01:02:55.741
I don't know, generative
and discriminative

01:02:55.741 --> 01:02:59.580
or model-based analysis
by synthesis and pattern

01:02:59.580 --> 01:03:00.600
recognition synthesis.

01:03:00.600 --> 01:03:02.413
But actually there's
a lot of parts

01:03:02.413 --> 01:03:04.750
of the brain that have to
do with reward and goals.

01:03:04.750 --> 01:03:05.790
And again, I thought
Laura's talk was

01:03:05.790 --> 01:03:07.440
a really good
illustration of this,

01:03:07.440 --> 01:03:09.602
understanding perception
is representing

01:03:09.602 --> 01:03:11.810
what's out there in the
world, but that's clearly got

01:03:11.810 --> 01:03:13.730
to be influenced by your goal.

01:03:13.730 --> 01:03:17.360
And what is certainly
a big problem

01:03:17.360 --> 01:03:20.160
is the relation between those.

01:03:20.160 --> 01:03:23.264
It says something that most of
us who are studying perception

01:03:23.264 --> 01:03:24.930
don't think we need
to worry about that.

01:03:24.930 --> 01:03:27.140
But I think we should,
particularly those of us,

01:03:27.140 --> 01:03:28.680
again, echoing what Laura said--

01:03:28.680 --> 01:03:30.650
if we're studying
learning, we definitely,

01:03:30.650 --> 01:03:34.014
I think, need to think
about that more than we do.

01:03:34.014 --> 01:03:35.930
HYNEK HERMANSKY: It may
not be exactly related

01:03:35.930 --> 01:03:38.070
to what you are asking,
but I don't know.

01:03:38.070 --> 01:03:39.800
I believe that we are
carrying the model

01:03:39.800 --> 01:03:43.160
of the world in our brain,
and we are constantly

01:03:43.160 --> 01:03:48.380
evaluating the fit of what we
expect to what we are seeing.

01:03:48.380 --> 01:03:52.190
And as long as we are seeing
or hearing what we expect,

01:03:52.190 --> 01:03:53.810
we don't work very
hard, basically,

01:03:53.810 --> 01:03:55.490
because the model is there.

01:03:55.490 --> 01:03:57.480
You know what I'm going to say.

01:03:57.480 --> 01:03:59.040
I'm not saying anything special.

01:03:59.040 --> 01:04:01.790
I look reasonable
and so on and so on.

01:04:01.790 --> 01:04:06.210
And when the model of the world
is for some reason violated,

01:04:06.210 --> 01:04:09.770
that may be one way how
to induce the feedback,

01:04:09.770 --> 01:04:12.140
because then suddenly I
know I should do something

01:04:12.140 --> 01:04:13.700
about my perception.

01:04:13.700 --> 01:04:15.380
Or I may just give up and say--

01:04:15.380 --> 01:04:18.260
or I become very,
very interested.

01:04:18.260 --> 01:04:20.730
But I think this is a
model of the world priors

01:04:20.730 --> 01:04:23.025
which we all carry with us.

01:04:23.025 --> 01:04:26.180
It's extremely
important and it helps

01:04:26.180 --> 01:04:28.280
us to move through the world.

01:04:28.280 --> 01:04:31.600
That's my feeling.

01:04:31.600 --> 01:04:34.850
In speech we have a somehow
interesting situation

01:04:34.850 --> 01:04:36.640
that we can actually predict--

01:04:36.640 --> 01:04:39.740
say we are interested in
estimating probabilities

01:04:39.740 --> 01:04:41.120
of the speech sounds.

01:04:41.120 --> 01:04:43.940
But we can also predict them
from the language model.

01:04:43.940 --> 01:04:45.710
Our language model
is learned typically

01:04:45.710 --> 01:04:49.205
very differently
from a lot of texts,

01:04:49.205 --> 01:04:50.910
and it's a lot of things.

01:04:50.910 --> 01:04:54.020
And so we had quite
a bit of success

01:04:54.020 --> 01:04:57.190
in trying to determine
if the world recognizes

01:04:57.190 --> 01:05:01.150
if it's working well or not, by
comparing what they recognize

01:05:01.150 --> 01:05:04.190
and expect and what it sees.

01:05:04.190 --> 01:05:08.180
And as long as these things
go together well, it's fine.

01:05:08.180 --> 01:05:12.050
If there is a problem
between these two,

01:05:12.050 --> 01:05:14.080
we have to start working.

01:05:14.080 --> 01:05:15.830
JOSH TENENBAUM: I
think, you know, physics

01:05:15.830 --> 01:05:19.609
is a source of beautiful
math and ideas.

01:05:19.609 --> 01:05:21.650
I think it's an interesting
thing to think about,

01:05:21.650 --> 01:05:24.620
maybe some tuning of
some low level mechanisms

01:05:24.620 --> 01:05:26.180
and in both sensory
modalities might

01:05:26.180 --> 01:05:27.960
be well thought of that way.

01:05:27.960 --> 01:05:28.490
Right.

01:05:28.490 --> 01:05:29.990
But I think it is
dangerous to apply

01:05:29.990 --> 01:05:31.100
too much of the
physicist's approach

01:05:31.100 --> 01:05:32.141
to the system as a whole.

01:05:32.141 --> 01:05:36.350
This idea that we're going to
explain deep stuff about how

01:05:36.350 --> 01:05:39.710
the brain works as some kind of
emergent phenomenon, something

01:05:39.710 --> 01:05:42.320
that just happened to work
that way because of physics.

01:05:42.320 --> 01:05:43.811
This is an engineered system.

01:05:43.811 --> 01:05:44.310
Right.

01:05:44.310 --> 01:05:46.109
Evolution engineered brains.

01:05:46.109 --> 01:05:47.150
It's a very complicated--

01:05:47.150 --> 01:05:49.640
I mean, we have had a version
of this discussion before.

01:05:49.640 --> 01:05:51.634
But I think it's
something that a lot of us

01:05:51.634 --> 01:05:52.550
here are committed to.

01:05:52.550 --> 01:05:53.383
Maybe not all of us.

01:05:53.383 --> 01:05:58.040
But the way I see it is, this is
a reverse engineering science.

01:05:58.040 --> 01:05:59.780
And the brain isn't an accident.

01:05:59.780 --> 01:06:00.720
It didn't just happen.

01:06:00.720 --> 01:06:04.340
There were lots of forces
over many different timescales

01:06:04.340 --> 01:06:06.870
acting to shape it to have
the function that it does.

01:06:06.870 --> 01:06:10.430
So if it is the case that there
are some basic mechanisms,

01:06:10.430 --> 01:06:15.200
say maybe at the synaptic
level that could be described

01:06:15.200 --> 01:06:17.350
that way, it's not an accident.

01:06:17.350 --> 01:06:19.520
They were [INAUDIBLE].

01:06:19.520 --> 01:06:23.210
I would call that, you know,
biology using the physics

01:06:23.210 --> 01:06:24.500
to solve a problem.

01:06:24.500 --> 01:06:27.590
And again there's a long history
of connecting free energy type

01:06:27.590 --> 01:06:30.770
approaches to various
elegant statistical inference

01:06:30.770 --> 01:06:31.600
frameworks.

01:06:31.600 --> 01:06:34.370
And it could be very
sensible to say, yes,

01:06:34.370 --> 01:06:36.380
at some levels you could
describe that low level

01:06:36.380 --> 01:06:40.815
sensory adaptation as doing that
kind of just physical resonance

01:06:40.815 --> 01:06:41.315
process.

01:06:41.315 --> 01:06:43.770
Or nonequilibrium stat
mech could describe that.

01:06:43.770 --> 01:06:47.030
But the reason why
nature has basically

01:06:47.030 --> 01:06:49.156
put that physics
interface in there

01:06:49.156 --> 01:06:50.780
is because it's
actually a way to solve

01:06:50.780 --> 01:06:53.585
a certain kind of adaptive
statistical inference problem.

01:06:53.585 --> 01:06:54.460
ALEX KELL: All right.

01:06:54.460 --> 01:06:54.610
Cool.

01:06:54.610 --> 01:06:55.526
Let's thank our panel.

01:06:55.526 --> 01:06:58.410
[APPLAUSE]