WEBVTT

00:00:01.640 --> 00:00:04.040
The following content is
provided under a Creative

00:00:04.040 --> 00:00:05.580
Commons license.

00:00:05.580 --> 00:00:07.880
Your support will help
MIT OpenCourseWare

00:00:07.880 --> 00:00:12.270
continue to offer high-quality
educational resources for free.

00:00:12.270 --> 00:00:14.870
To make a donation or
view additional materials

00:00:14.870 --> 00:00:18.830
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:18.830 --> 00:00:20.000
at ocw.mit.edu.

00:00:22.552 --> 00:00:24.010
TONY PRESCOTT:
Great pleasure to be

00:00:24.010 --> 00:00:26.790
in Woods Hole, my
first visit here,

00:00:26.790 --> 00:00:29.390
had a wonderful swim
in the sea yesterday.

00:00:29.390 --> 00:00:33.790
Sheffield Robotics is across
both universities in Sheffield.

00:00:33.790 --> 00:00:36.130
And it's been
founded since 2011,

00:00:36.130 --> 00:00:39.490
but we've really been doing
robotics since the 1980s.

00:00:39.490 --> 00:00:41.950
And I joined them in 1989.

00:00:41.950 --> 00:00:45.570
And we do pretty much every
different kind of robotics,

00:00:45.570 --> 00:00:47.740
but I'm going to talk
about biomimetics.

00:00:47.740 --> 00:00:50.650
I also do what you might
call cognitive robotics.

00:00:50.650 --> 00:00:53.000
And I collaborate with
Giorgio Metta on that,

00:00:53.000 --> 00:00:54.760
but since he's
speaking too, I'm going

00:00:54.760 --> 00:00:57.430
to focus on the more
animal-like robots

00:00:57.430 --> 00:00:59.680
that we've been developing.

00:00:59.680 --> 00:01:02.890
So this is one of
our latest projects.

00:01:02.890 --> 00:01:08.260
This is a small,
autonomous, mobile robot,

00:01:08.260 --> 00:01:10.330
which is a commercial
platform, which

00:01:10.330 --> 00:01:13.840
will be available in the
UK, I think, next January.

00:01:13.840 --> 00:01:16.570
And there will hopefully
be a developer program

00:01:16.570 --> 00:01:19.330
for people that are
interested in helping

00:01:19.330 --> 00:01:23.270
to develop the intelligence
for this robot.

00:01:23.270 --> 00:01:27.310
So this is at a conference we
had in Barcelona last month.

00:01:27.310 --> 00:01:31.000
And you can see that
it's a robot pet.

00:01:31.000 --> 00:01:34.720
And we've been
focusing on giving it

00:01:34.720 --> 00:01:38.650
some effective
communication abilities,

00:01:38.650 --> 00:01:40.870
responding
particularly to touch.

00:01:40.870 --> 00:01:44.990
You can see that it's
orienting to stimuli.

00:01:44.990 --> 00:01:46.135
It has stereo vision.

00:01:46.135 --> 00:01:47.470
It has stereo sound.

00:01:47.470 --> 00:01:51.490
And it can orient
to visual stimuli

00:01:51.490 --> 00:01:53.400
and also to auditory stimuli.

00:01:53.400 --> 00:01:55.640
Here we're showing it
a picture of itself

00:01:55.640 --> 00:01:57.730
on this magazine cover.

00:01:57.730 --> 00:02:01.550
And the goal is to
demonstrate that we can,

00:02:01.550 --> 00:02:05.320
in a commercial robot that
will cost less than $1,000,

00:02:05.320 --> 00:02:08.770
considerably less, some
of the principles of how

00:02:08.770 --> 00:02:12.140
the brain generates behavior.

00:02:12.140 --> 00:02:14.500
So this robot is called MiRo.

00:02:14.500 --> 00:02:19.360
It is based on some high-level
principles abstracted

00:02:19.360 --> 00:02:22.450
from what we know about how
mammalian brains control

00:02:22.450 --> 00:02:26.200
behavior, so it's a
relatively complex robot, 13

00:02:26.200 --> 00:02:29.440
degrees of freedom, 3 arm
processes corresponding

00:02:29.440 --> 00:02:31.360
to different
levels, if you like,

00:02:31.360 --> 00:02:35.810
of the neuroaxis, the
central nervous system.

00:02:35.810 --> 00:02:41.380
So once you start out with some
general ideas, and questions,

00:02:41.380 --> 00:02:44.260
and issues about
how we might learn

00:02:44.260 --> 00:02:47.890
from the biology in the
brain, how to develop robots,

00:02:47.890 --> 00:02:51.730
and how we might use robots to
help us understand the brain.

00:02:51.730 --> 00:02:54.880
And a central question
I think that robotics

00:02:54.880 --> 00:02:58.170
can help us answer, and I
think that's a core question

00:02:58.170 --> 00:03:01.510
in neuroscience, is what
you might call the problem

00:03:01.510 --> 00:03:02.980
of behavioral integration.

00:03:02.980 --> 00:03:05.650
And the neuroscientist
Ernest Barrington

00:03:05.650 --> 00:03:07.090
summarized this quite nicely.

00:03:07.090 --> 00:03:10.120
He said, "the phenomenon
so characteristic of living

00:03:10.120 --> 00:03:13.660
organisms, so very difficult
to analyze, the fact

00:03:13.660 --> 00:03:16.840
that they behave as wholes
rather than as the sum

00:03:16.840 --> 00:03:18.700
of their constituent parts.

00:03:18.700 --> 00:03:21.090
Their behavior
shows integration,

00:03:21.090 --> 00:03:23.820
a process unifying the
actions of an organism

00:03:23.820 --> 00:03:27.140
into patterns that involve
the whole individual."

00:03:27.140 --> 00:03:29.500
And this picture of a squirrel
over here I think nicely

00:03:29.500 --> 00:03:30.260
demonstrates this.

00:03:30.260 --> 00:03:32.980
So of course this squirrel
is leaping from one branch

00:03:32.980 --> 00:03:34.030
to the next.

00:03:34.030 --> 00:03:36.370
And you can see that
every part of his body

00:03:36.370 --> 00:03:39.640
is coordinated and
organized for this action,

00:03:39.640 --> 00:03:42.430
so you can see that his
eyes looking straight ahead,

00:03:42.430 --> 00:03:44.830
his whiskers-- and I'll talk
a lot more about whiskers--

00:03:44.830 --> 00:03:46.250
pointing forward.

00:03:46.250 --> 00:03:49.930
His arms and his
feet are all ready

00:03:49.930 --> 00:03:53.140
and they're there ready
to catch his fall.

00:03:53.140 --> 00:03:55.840
Even his tail is
angled and positioned

00:03:55.840 --> 00:03:57.670
to help him fly through the air.

00:03:57.670 --> 00:04:00.820
So it's the coordination of the
different parts of the body,

00:04:00.820 --> 00:04:03.130
and the multiple degrees
of freedom of the body,

00:04:03.130 --> 00:04:07.060
and the sensory systems in space
and in time, which, I think,

00:04:07.060 --> 00:04:11.170
is a critical problem
for biological control

00:04:11.170 --> 00:04:14.200
and also a problem for robots,
which we're still struggling

00:04:14.200 --> 00:04:16.290
to address with our robots.

00:04:16.290 --> 00:04:19.209
And I want to give you two
very general principles

00:04:19.209 --> 00:04:23.870
for thinking about how
brains solve this problem.

00:04:23.870 --> 00:04:27.700
So many of you will have
come across Rodney Brooks,

00:04:27.700 --> 00:04:29.710
yes, from MIT.

00:04:29.710 --> 00:04:32.020
And he's famous
for, in robotics,

00:04:32.020 --> 00:04:36.340
the notion of layered control,
which he called subsumption.

00:04:36.340 --> 00:04:39.370
And I think the
ideas that he brought

00:04:39.370 --> 00:04:41.740
into robotics really
changed how people thought

00:04:41.740 --> 00:04:44.020
about robots in the 1980s.

00:04:44.020 --> 00:04:49.060
But if we go back to the
1880s, John Hughlings Jackson,

00:04:49.060 --> 00:04:52.950
who was a British neurologist,
proposed a similar idea,

00:04:52.950 --> 00:04:56.270
but with respect to
the nervous system.

00:04:56.270 --> 00:05:01.030
So in the 1880s, people
thought about the higher areas

00:05:01.030 --> 00:05:04.510
of the brain,
particularly the cortex,

00:05:04.510 --> 00:05:08.710
as being about higher thought,
and reasoning, and language,

00:05:08.710 --> 00:05:11.460
and not so much about
perception and action.

00:05:11.460 --> 00:05:14.500
And Hughlings Jackson, I think,
was revolutionary in his day

00:05:14.500 --> 00:05:17.770
in saying, that the highest
motor senses represent over

00:05:17.770 --> 00:05:20.110
again in more complex
combinations what

00:05:20.110 --> 00:05:22.072
the middle motor
centers represent.

00:05:22.072 --> 00:05:24.530
In other words, he was saying
that, the whole of the brain,

00:05:24.530 --> 00:05:27.470
all the way up, is about
coordinating perception

00:05:27.470 --> 00:05:28.490
with action.

00:05:28.490 --> 00:05:31.460
And he described it in many
senses as a layered system.

00:05:31.460 --> 00:05:33.080
He talked about how
you could take off

00:05:33.080 --> 00:05:37.190
the top layers of the system
and the competences of the lower

00:05:37.190 --> 00:05:39.440
layers remained intact,
which, of course, is

00:05:39.440 --> 00:05:41.930
very much the idea of
Rodney Brooks subsumption

00:05:41.930 --> 00:05:43.580
architecture.

00:05:43.580 --> 00:05:47.660
And some old studies, they
did transection in animals

00:05:47.660 --> 00:05:49.805
like cats and rats--
demonstrate this nicely.

00:05:49.805 --> 00:05:53.120
So if you take a cat or a
rat, particularly a rat,

00:05:53.120 --> 00:05:56.245
and you remove, in fact,
all of the cerebral cortex,

00:05:56.245 --> 00:06:00.530
so if you make a slice here
that takes away cortex,

00:06:00.530 --> 00:06:03.110
you get an animal that
actually, to all appearances,

00:06:03.110 --> 00:06:04.280
looks fairly normal.

00:06:04.280 --> 00:06:06.660
It does motivated
behavioral sequences,

00:06:06.660 --> 00:06:07.737
so it will get hungry.

00:06:07.737 --> 00:06:08.820
And it will look for food.

00:06:08.820 --> 00:06:10.220
And it will eat.

00:06:10.220 --> 00:06:12.200
If there's an
appropriate mate nearby,

00:06:12.200 --> 00:06:16.220
it will look to have
a sexual relationship.

00:06:16.220 --> 00:06:21.050
And it will fail in some
challenges such as learning,

00:06:21.050 --> 00:06:25.000
and perhaps also in dexterous
control, but in many ways,

00:06:25.000 --> 00:06:26.910
it will look normal.

00:06:26.910 --> 00:06:31.910
If you slice below the
other part of the forebrain,

00:06:31.910 --> 00:06:34.610
the thalamus and
the hypothalamus,

00:06:34.610 --> 00:06:37.100
you remove these areas, then
you remove this capacity

00:06:37.100 --> 00:06:41.270
for motivated behavior, but you
leave intact midbrain systems

00:06:41.270 --> 00:06:43.820
that can still generate
individual actions.

00:06:43.820 --> 00:06:46.460
And if you remove
parts of the midbrain,

00:06:46.460 --> 00:06:48.710
you leave intact, still,
component movements,

00:06:48.710 --> 00:06:51.890
so for example, animals
that can run on a treadmill.

00:06:51.890 --> 00:06:57.800
So we are, with our MiRo
robot, loosely recapitulating

00:06:57.800 --> 00:07:01.070
this architecture, so we
have three processors.

00:07:01.070 --> 00:07:03.720
And the idea with this robot,
it's actually a part work,

00:07:03.720 --> 00:07:04.760
so you build it up.

00:07:04.760 --> 00:07:07.790
You get a magazine every week
with a new part for the robot.

00:07:07.790 --> 00:07:10.580
And you build, essentially,
a spinal robot first.

00:07:10.580 --> 00:07:12.620
And then you add a
midbrain processor.

00:07:12.620 --> 00:07:15.500
Eventually you add a
cortical processor,

00:07:15.500 --> 00:07:18.470
which gives with it some
learning capacities,

00:07:18.470 --> 00:07:22.280
some pattern recognition,
some navigation, so that's

00:07:22.280 --> 00:07:24.800
one principle, layered
architecture, which

00:07:24.800 --> 00:07:29.360
seems to work both for biology,
and perhaps in robotics.

00:07:29.360 --> 00:07:32.600
So second principle,
and this goes back

00:07:32.600 --> 00:07:35.270
to another famous
neuroscientist,

00:07:35.270 --> 00:07:39.050
this time Wilder Penfield,
who is known to many people

00:07:39.050 --> 00:07:42.770
for his discovery of
somatotopic maps in the brain,

00:07:42.770 --> 00:07:46.960
that if you stimulate, in
the brain, in the area,

00:07:46.960 --> 00:07:49.940
the sensory area, then
you find that people

00:07:49.940 --> 00:07:53.240
have experience of tickling
on parts of the body.

00:07:53.240 --> 00:07:56.330
And adjacent parts
of cortex correspond

00:07:56.330 --> 00:07:58.100
to adjacent parts of the body.

00:07:58.100 --> 00:08:00.830
And he found a similar
homunculus in the motor area

00:08:00.830 --> 00:08:03.110
that you stimulate,
and you get movement

00:08:03.110 --> 00:08:05.190
in adjacent parts of the body.

00:08:05.190 --> 00:08:08.650
And he also proposed
another idea.

00:08:08.650 --> 00:08:13.040
And that was sort of a
transencephalic dimension

00:08:13.040 --> 00:08:14.870
to nervous system organization.

00:08:14.870 --> 00:08:17.330
And that's to say
that, down the midline

00:08:17.330 --> 00:08:19.330
of the central
nervous system, there

00:08:19.330 --> 00:08:22.430
are a group of structures that
don't seem to be specifically

00:08:22.430 --> 00:08:26.690
involved in specific aspects
of perception and action,

00:08:26.690 --> 00:08:28.940
but seem to be
about integration.

00:08:28.940 --> 00:08:32.010
And amongst them, particularly
the basal ganglia,

00:08:32.010 --> 00:08:33.919
he noted as being
important, and parts

00:08:33.919 --> 00:08:35.809
of the reticular formation.

00:08:35.809 --> 00:08:38.690
So Michael Frank was
here talking to you

00:08:38.690 --> 00:08:41.330
about basal ganglia,
so I'm not going

00:08:41.330 --> 00:08:45.350
to say much more about this,
but this is just to point out,

00:08:45.350 --> 00:08:47.870
in an slice in the
rat brain, these

00:08:47.870 --> 00:08:51.320
are the elements of the
basal ganglia, particularly,

00:08:51.320 --> 00:08:53.720
the striatum is
the input system.

00:08:53.720 --> 00:08:57.210
In the rat, the substantia nigra
and part of the globus pallidus

00:08:57.210 --> 00:08:58.850
are the output systems.

00:08:58.850 --> 00:09:03.350
And then you have, in the rat
brain, and also in our brains,

00:09:03.350 --> 00:09:05.720
you have massive
convergence onto the input

00:09:05.720 --> 00:09:10.100
area, the caudate putamen it
is also called, from the cortex

00:09:10.100 --> 00:09:11.610
and from the brain stem.

00:09:11.610 --> 00:09:14.000
So you have signals coming
in from all over the brain

00:09:14.000 --> 00:09:16.490
to the striatum, which
could be interpreted

00:09:16.490 --> 00:09:18.570
as a request for action.

00:09:18.570 --> 00:09:20.720
And then you have
inhibition coming out

00:09:20.720 --> 00:09:23.030
from the output structures
of the basal ganglia,

00:09:23.030 --> 00:09:25.370
here I'm showing it for
the substantia nigra,

00:09:25.370 --> 00:09:28.040
going back to all of
those areas of the brain.

00:09:28.040 --> 00:09:29.810
And this inhibition is tonic.

00:09:29.810 --> 00:09:31.760
And in order to have
functional reaction,

00:09:31.760 --> 00:09:33.680
you have to remove
the inhibition.

00:09:33.680 --> 00:09:39.770
So this is a system
that can give you

00:09:39.770 --> 00:09:41.240
some of that
behavioral integration

00:09:41.240 --> 00:09:43.790
that you need, the
ability to ensure that you

00:09:43.790 --> 00:09:45.620
do one thing at a time.

00:09:45.620 --> 00:09:47.870
You do that quickly.

00:09:47.870 --> 00:09:50.150
You do that consistently.

00:09:50.150 --> 00:09:52.700
You dedicate all of your
resources to the action

00:09:52.700 --> 00:09:54.870
that you want to do.

00:09:54.870 --> 00:09:57.200
Here's a little video of a rat.

00:09:57.200 --> 00:10:00.710
And I'm showing you some
integrated behavior over time

00:10:00.710 --> 00:10:01.790
in an intact rat.

00:10:01.790 --> 00:10:05.600
So this is a rat exploring
in a large container.

00:10:05.600 --> 00:10:08.089
And rats generally
don't like open spaces,

00:10:08.089 --> 00:10:10.130
so when you first put the
animal into this space,

00:10:10.130 --> 00:10:12.800
it will tend to
stay near the walls.

00:10:12.800 --> 00:10:15.320
And it prefers this
corner, which is dark.

00:10:15.320 --> 00:10:18.470
And of course, it's hungry too,
so there's a dish of food here.

00:10:18.470 --> 00:10:20.120
And eventually, it
gets up the courage

00:10:20.120 --> 00:10:21.710
to go out, collect
a piece of food,

00:10:21.710 --> 00:10:26.060
and it will take it back into
this dark corner to consume it.

00:10:26.060 --> 00:10:29.080
And one of the first
models that we built

00:10:29.080 --> 00:10:32.200
was a model of basal ganglia
operating as this, kind of,

00:10:32.200 --> 00:10:34.070
action-selection device.

00:10:34.070 --> 00:10:36.490
And with a simple
Kepler robot, this

00:10:36.490 --> 00:10:39.870
is a robot that just really uses
infrared sensors and a gripper

00:10:39.870 --> 00:10:40.900
arm.

00:10:40.900 --> 00:10:44.680
And we are using a model
of the basal ganglia

00:10:44.680 --> 00:10:48.010
to control decision
making about which actions

00:10:48.010 --> 00:10:51.820
to do at which time, and
to generate sequencing

00:10:51.820 --> 00:10:53.150
of those actions.

00:10:53.150 --> 00:10:58.120
So as the need to stay
close to walls diminishes,

00:10:58.120 --> 00:11:01.780
the robot, like the rat, goes
and collects these cylinders.

00:11:01.780 --> 00:11:05.230
And it carries them back into
the corners and deposits them.

00:11:05.230 --> 00:11:08.820
So a model of the central
brain structures-- and I'm

00:11:08.820 --> 00:11:12.415
happy to discuss in more detail
about how that model operates,

00:11:12.415 --> 00:11:14.560
and how similarities
to the model

00:11:14.560 --> 00:11:16.270
that Michael will
have described to you,

00:11:16.270 --> 00:11:19.000
but that's controlling the
behavior switching, if you

00:11:19.000 --> 00:11:21.980
like, in this robot.

00:11:21.980 --> 00:11:27.250
So I spent some time working
on this question of how

00:11:27.250 --> 00:11:30.850
central systems in the brain,
particularly the basal ganglia,

00:11:30.850 --> 00:11:33.470
are involved in the
integration of behavior,

00:11:33.470 --> 00:11:36.550
but I became frustrated
with not understanding what

00:11:36.550 --> 00:11:39.740
were the signals coming in to
the central brain structures

00:11:39.740 --> 00:11:42.820
and not understanding
what effects those brain

00:11:42.820 --> 00:11:47.030
structures were having on the
motor system of the animal.

00:11:47.030 --> 00:11:49.000
So I thought that
what we needed to do

00:11:49.000 --> 00:11:51.190
was look at complete
sensory motor loops.

00:11:51.190 --> 00:11:55.330
We needed to look at sensing and
action, and how those interact.

00:11:55.330 --> 00:11:57.640
And in our Psychology
Department,

00:11:57.640 --> 00:11:59.260
we have a neuroscience
group that

00:11:59.260 --> 00:12:01.930
works mainly with rats,
so it was natural for us

00:12:01.930 --> 00:12:03.670
to look at the rat.

00:12:03.670 --> 00:12:07.450
And in the rat, we know that one
of the key perception systems

00:12:07.450 --> 00:12:09.200
is the vertebral system.

00:12:09.200 --> 00:12:11.560
So here you see, this
is actually a pet rat,

00:12:11.560 --> 00:12:13.480
wandering around
on my windowsill

00:12:13.480 --> 00:12:15.040
in my house in Sheffield.

00:12:15.040 --> 00:12:18.400
And the thing to notice
is the whiskers here.

00:12:18.400 --> 00:12:20.500
And the whiskers are moving
back and forth pretty

00:12:20.500 --> 00:12:24.430
much all the time that
the rat is exploring.

00:12:24.430 --> 00:12:29.980
And we understand from nearly
100 years now of research

00:12:29.980 --> 00:12:32.530
that this system is very
important for the rat

00:12:32.530 --> 00:12:33.860
to understand the environment.

00:12:33.860 --> 00:12:36.040
In fact, if it's
completely dark,

00:12:36.040 --> 00:12:38.620
the rat would move around
in much the same way.

00:12:38.620 --> 00:12:40.240
And it would be
able to understand

00:12:40.240 --> 00:12:43.030
the world through
touch pretty well, even

00:12:43.030 --> 00:12:45.970
in the absence of vision.

00:12:45.970 --> 00:12:48.310
So this is the same
video, but now slow down

00:12:48.310 --> 00:12:51.910
10 times, and just to
show you these movements

00:12:51.910 --> 00:12:54.400
of the whiskers, and how
quite precise they are,

00:12:54.400 --> 00:12:58.540
because the rat isn't just,
in a stereotypical way,

00:12:58.540 --> 00:13:00.640
banging its whiskers
against the floor.

00:13:00.640 --> 00:13:02.530
It is lightly
touching the whiskers

00:13:02.530 --> 00:13:04.690
in places it will get
useful information.

00:13:04.690 --> 00:13:07.930
And you can see, when he puts
his head over the window sill

00:13:07.930 --> 00:13:10.630
here, the whiskers
push forward, as

00:13:10.630 --> 00:13:12.160
if he knows that
he's going to have

00:13:12.160 --> 00:13:15.140
to reach further forward if
he's going to find anything.

00:13:15.140 --> 00:13:17.590
Here you see him
exploring this wooden cup.

00:13:17.590 --> 00:13:20.740
And you can see light
touches by the whiskers.

00:13:20.740 --> 00:13:23.440
And you can also see that
the movement of the whiskers

00:13:23.440 --> 00:13:26.050
is being modulated by
the shape of the surface

00:13:26.050 --> 00:13:28.020
that he's investigating,
so there's

00:13:28.020 --> 00:13:30.670
some fairly subtle
control happening here.

00:13:30.670 --> 00:13:32.740
And I think it's
not too much to say

00:13:32.740 --> 00:13:36.430
that the way in which the
rat controls its whiskers

00:13:36.430 --> 00:13:38.200
has almost the same
richness as the way

00:13:38.200 --> 00:13:40.030
that we control our fingertips.

00:13:42.560 --> 00:13:44.680
So I'm interested in
how this plays out

00:13:44.680 --> 00:13:47.200
in terms of a layered
architecture story.

00:13:47.200 --> 00:13:49.880
And of course, many
people study this system.

00:13:49.880 --> 00:13:52.630
The beauty of it is, if
you're a neuroscientist,

00:13:52.630 --> 00:13:55.040
that you can look in the cortex.

00:13:55.040 --> 00:13:57.310
This is rat cortex here.

00:13:57.310 --> 00:14:02.050
And a huge area of rat cortex
is dedicated to somatosensation,

00:14:02.050 --> 00:14:06.010
to touch, of which a large
area is dedicated to whiskers.

00:14:06.010 --> 00:14:07.480
In fact, you zoom
in, you can find

00:14:07.480 --> 00:14:09.490
this area called barrel cortex.

00:14:09.490 --> 00:14:11.260
And with the right
kind of staining,

00:14:11.260 --> 00:14:15.700
you can find groups of cells
which preferentially receive

00:14:15.700 --> 00:14:18.070
signals from
individual whiskers,

00:14:18.070 --> 00:14:21.430
so for example, you can
move one whisker here,

00:14:21.430 --> 00:14:25.560
and you can know exactly where
you record in the barrel cortex

00:14:25.560 --> 00:14:27.970
to get a very strong
response from that whisker.

00:14:27.970 --> 00:14:30.820
And this means that barrel
cortex and the whisker system

00:14:30.820 --> 00:14:35.170
has become one of the prepared,
preferred preparations in which

00:14:35.170 --> 00:14:38.890
to study the cortical
microcircuit altogether,

00:14:38.890 --> 00:14:41.650
so people study this
system to really understand

00:14:41.650 --> 00:14:44.110
how cortex operates.

00:14:44.110 --> 00:14:46.390
Now, if we think
about this system

00:14:46.390 --> 00:14:50.110
as a pathway from the
whiskers up to barrel cortex,

00:14:50.110 --> 00:14:52.210
we're really only
capturing one element

00:14:52.210 --> 00:14:54.940
of what's going on in
the vertebral system.

00:14:54.940 --> 00:14:57.570
And that's this pathway
here from the vertebrae,

00:14:57.570 --> 00:15:00.520
via the trigeminal complex,
goes by the thalamus

00:15:00.520 --> 00:15:02.180
up to sensory cortex.

00:15:02.180 --> 00:15:05.920
And this is probably where 9
out of 10 papers on this system

00:15:05.920 --> 00:15:08.800
are published, but
actually, this system

00:15:08.800 --> 00:15:11.420
is only part of a
looped architecture,

00:15:11.420 --> 00:15:13.660
or we might say, a
layered architecture.

00:15:13.660 --> 00:15:16.210
And at each level of this
layered architecture,

00:15:16.210 --> 00:15:20.890
there's a completed loop, so
that sensing can affect action,

00:15:20.890 --> 00:15:25.060
so sensing on the vertebrae can
affect the movement and control

00:15:25.060 --> 00:15:26.770
of the vertebrae.

00:15:26.770 --> 00:15:28.810
So there's a loop
via the brainstem

00:15:28.810 --> 00:15:32.470
here, so that, directly
from the trigeminal complex,

00:15:32.470 --> 00:15:35.020
signals come back to the
facial nucleus, which

00:15:35.020 --> 00:15:38.290
is where the motor neurons
are that move the whiskers.

00:15:38.290 --> 00:15:40.600
There's a loop via
the midbrain here

00:15:40.600 --> 00:15:43.390
so that sensory signals
ascend very quickly

00:15:43.390 --> 00:15:45.490
to the midbrain
superior colliculus.

00:15:45.490 --> 00:15:49.000
And they come back to affect
how the whiskers move.

00:15:49.000 --> 00:15:51.970
And then, of course, there's
the loop via the cortex

00:15:51.970 --> 00:15:54.750
too, so there's essentially
those three loops, at least,

00:15:54.750 --> 00:15:56.920
that we need to think about.

00:15:56.920 --> 00:15:59.350
So since 2003,
we've been building

00:15:59.350 --> 00:16:02.800
different whiskered
robots, the aim being

00:16:02.800 --> 00:16:05.140
to instantiate our
theories about how

00:16:05.140 --> 00:16:08.280
whiskered control works in
this layered architecture

00:16:08.280 --> 00:16:11.080
and demonstrate it
in a robot platform.

00:16:11.080 --> 00:16:13.540
And often, actually,
building a robot platform

00:16:13.540 --> 00:16:15.760
causes us to ask new
questions that might not

00:16:15.760 --> 00:16:19.210
be obvious to you just by
doing biological experiments

00:16:19.210 --> 00:16:21.952
or even by doing simulation.

00:16:21.952 --> 00:16:23.410
Before I show you
some robots, just

00:16:23.410 --> 00:16:28.120
quickly show a little bit more
about the rat and its whiskers.

00:16:28.120 --> 00:16:30.230
So we began thinking we
could just build robots,

00:16:30.230 --> 00:16:32.260
but we quickly
realized that we didn't

00:16:32.260 --> 00:16:34.970
know enough about how rats
use their whiskers to do that.

00:16:34.970 --> 00:16:37.874
And that's partly because the
experiments that had been done

00:16:37.874 --> 00:16:39.790
haven't been done with
the purpose of building

00:16:39.790 --> 00:16:41.260
a whiskered robot.

00:16:41.260 --> 00:16:43.810
So when you try and
build a whiskered robot,

00:16:43.810 --> 00:16:46.680
you have to ask questions
like, how do the whiskers move?

00:16:46.680 --> 00:16:49.600
And when you look at a video
like this filmed from above,

00:16:49.600 --> 00:16:51.580
this is with a
high speed camera,

00:16:51.580 --> 00:16:54.130
you think, well, the whiskers
are sweeping backward

00:16:54.130 --> 00:16:56.110
and forward, like this.

00:16:56.110 --> 00:17:00.580
But in fact, if you put a
mirror just tilted down here

00:17:00.580 --> 00:17:02.146
and you see what
happens, then it

00:17:02.146 --> 00:17:03.770
turns out to be a
little bit different,

00:17:03.770 --> 00:17:07.450
so you see that the whiskers
are going up and down as much

00:17:07.450 --> 00:17:10.010
as they are going
backwards and forwards.

00:17:10.010 --> 00:17:12.300
So the whiskers are
actually sweeping like this,

00:17:12.300 --> 00:17:16.290
and they're making a series
of touches on the surface.

00:17:16.290 --> 00:17:20.560
And if you watch, you can
see that the whiskers are

00:17:20.560 --> 00:17:23.800
sort of playing down on the
surface, sort of in a sequence,

00:17:23.800 --> 00:17:27.819
quite quickly, so that
information might be giving you

00:17:27.819 --> 00:17:31.870
details about the shape of
the surfaces in your world.

00:17:31.870 --> 00:17:33.640
So we mainly look at
the long whiskers.

00:17:33.640 --> 00:17:35.590
This is a rat that's
running up an alley.

00:17:35.590 --> 00:17:38.560
And we put an unexpected
object in the alley, which

00:17:38.560 --> 00:17:41.950
could be this
aluminum rectangle,

00:17:41.950 --> 00:17:44.350
or it could be
this plastic step.

00:17:44.350 --> 00:17:47.050
And what you see is, if the
animal encounters something

00:17:47.050 --> 00:17:49.420
unexpected with its
long whiskers, then

00:17:49.420 --> 00:17:52.150
it turns very quickly
and investigates it.

00:17:52.150 --> 00:17:54.970
So the long whiskers
are like the periphery

00:17:54.970 --> 00:17:57.640
of a sensory system
that has a fovea.

00:17:57.640 --> 00:18:00.070
And the fovea at the
center of that system

00:18:00.070 --> 00:18:02.950
is a set of short whiskers
around the mouth, also

00:18:02.950 --> 00:18:06.700
the lips and the
nose, so that you

00:18:06.700 --> 00:18:09.670
can sniff and smell the surface
that you're investigating.

00:18:09.670 --> 00:18:13.180
So we can zoom in and see
that sensory fovea, here you

00:18:13.180 --> 00:18:16.690
see these short whiskers that
are being used to investigate

00:18:16.690 --> 00:18:20.219
this plastic puck, and the
longer whiskers investigating

00:18:20.219 --> 00:18:21.010
around the outside.

00:18:23.570 --> 00:18:26.710
So we have
recapitulated elements

00:18:26.710 --> 00:18:28.890
of this layered
architecture in our robot.

00:18:28.890 --> 00:18:31.060
And this is-- these
are the loops.

00:18:31.060 --> 00:18:33.260
And this was about
five years ago,

00:18:33.260 --> 00:18:35.650
we built a system with
a brain stem loop,

00:18:35.650 --> 00:18:37.260
and really, midbrain loop.

00:18:37.260 --> 00:18:39.770
And this is our
robot Scratchbot,

00:18:39.770 --> 00:18:43.750
which is the first of
the whiskered robots

00:18:43.750 --> 00:18:47.395
that we felt really was
capturing whisking in the way

00:18:47.395 --> 00:18:48.380
that the rat does it.

00:18:48.380 --> 00:18:52.780
It's running at about 4
hertz, whereas the real rat is

00:18:52.780 --> 00:18:55.150
whisking from 8 to
12 hertz, but it's

00:18:55.150 --> 00:18:58.780
scaled up to be about
four times rat size.

00:18:58.780 --> 00:19:00.640
And what it's
doing here is, it's

00:19:00.640 --> 00:19:02.680
using the whiskers
to orient to stimuli,

00:19:02.680 --> 00:19:05.380
so this is Martin Pearson
from Bristol Robotics Lab.

00:19:05.380 --> 00:19:08.290
He's putting an object
in the whisker field.

00:19:08.290 --> 00:19:11.260
And the robot is
turning and orienting

00:19:11.260 --> 00:19:12.980
to the touch with the object.

00:19:12.980 --> 00:19:15.520
It's putting its short
micro vibrissae, in fact,

00:19:15.520 --> 00:19:18.020
against the object
and exploring it.

00:19:18.020 --> 00:19:21.340
Now to do that, to detect
a stimulus on the whiskers

00:19:21.340 --> 00:19:24.680
and then turn is not a
fantastically hard task.

00:19:24.680 --> 00:19:27.640
The main challenge
is to work out

00:19:27.640 --> 00:19:29.650
where the whisker
was in its sweep

00:19:29.650 --> 00:19:31.270
when you made contact
with an object,

00:19:31.270 --> 00:19:33.322
because the whisker is
sweeping back and forth,

00:19:33.322 --> 00:19:34.780
so if you want to
know the location

00:19:34.780 --> 00:19:36.370
of the point of
contact, you need

00:19:36.370 --> 00:19:41.530
to integrate the position of the
whisker in its sweep, what you

00:19:41.530 --> 00:19:44.590
might call a theta
signal, and the presence

00:19:44.590 --> 00:19:46.210
of the contact on the whiskers.

00:19:46.210 --> 00:19:49.700
And the coincidence of those
two is detected in the brain.

00:19:49.700 --> 00:19:52.210
And we know that there are
cells in the barrel cortex

00:19:52.210 --> 00:19:54.520
that respond to
that coincidence.

00:19:54.520 --> 00:19:57.340
So we have in our robot a model
of the super colliculus, which

00:19:57.340 --> 00:19:59.200
is the location in
the brain which we

00:19:59.200 --> 00:20:01.900
think is involved in orienting.

00:20:01.900 --> 00:20:04.480
And in our model
of the colliculus,

00:20:04.480 --> 00:20:06.970
we have a head-centered
map, which

00:20:06.970 --> 00:20:10.660
looks for this coincidence
between a cell encoding

00:20:10.660 --> 00:20:13.370
the position of the whisker
in its sweep and a cell

00:20:13.370 --> 00:20:17.710
encoding a contact and makes
a turn to orient and explore

00:20:17.710 --> 00:20:20.177
that position.

00:20:20.177 --> 00:20:21.760
And then if we want
to actually create

00:20:21.760 --> 00:20:24.860
behavior, which is
integrated over time,

00:20:24.860 --> 00:20:28.030
so if the robot was just to
orient every time it touched

00:20:28.030 --> 00:20:31.080
something, that wouldn't
be very animal-like,

00:20:31.080 --> 00:20:32.960
particularly, you
don't want to orient

00:20:32.960 --> 00:20:35.230
every time you touch
the ground, so you just

00:20:35.230 --> 00:20:38.140
want to orient when you
touch important stimuli.

00:20:38.140 --> 00:20:40.820
So we put into our
model the basal ganglia

00:20:40.820 --> 00:20:44.020
so that we can decide whether
the contact we've just made

00:20:44.020 --> 00:20:45.850
is something we
want to investigate

00:20:45.850 --> 00:20:49.100
or something that doesn't
interest us so much.

00:20:49.100 --> 00:20:52.570
So we have a system
now with a midbrain

00:20:52.570 --> 00:20:55.630
that does orienting, a basal
ganglia that makes decisions

00:20:55.630 --> 00:20:57.160
about sequencing.

00:20:57.160 --> 00:20:59.810
And those two things
together give us

00:20:59.810 --> 00:21:03.450
reasonably lifelike behavior
in our robot, Scratchbot.

00:21:03.450 --> 00:21:05.800
And that's quite
a lot of what we

00:21:05.800 --> 00:21:08.710
have running now on the new
robot, MiRo, is this system.

00:21:08.710 --> 00:21:11.180
It's for orienting
and exploring.

00:21:11.180 --> 00:21:13.840
And we can use it-- we use it
here for tactile orienting,

00:21:13.840 --> 00:21:15.520
but of course, the
same system can

00:21:15.520 --> 00:21:17.170
underlie orienting
to sounds, if you

00:21:17.170 --> 00:21:21.650
can localize those, and space,
and orienting to visual stimuli

00:21:21.650 --> 00:21:23.020
too.

00:21:23.020 --> 00:21:25.990
So it turns out that this
isn't a complete solution

00:21:25.990 --> 00:21:29.260
to the problem of orienting
for our whiskered robot.

00:21:29.260 --> 00:21:31.900
And that's because
sometimes our robot

00:21:31.900 --> 00:21:34.690
would stop as it
was moving around

00:21:34.690 --> 00:21:38.024
and just move and
investigate a point in space

00:21:38.024 --> 00:21:39.190
where nothing was happening.

00:21:39.190 --> 00:21:41.579
We call that a ghost orient.

00:21:41.579 --> 00:21:43.120
And the problem is
that the whiskers,

00:21:43.120 --> 00:21:45.040
because they're
moving back and forth,

00:21:45.040 --> 00:21:47.680
they sometimes generate
signals in the strain

00:21:47.680 --> 00:21:50.770
gauges that are detecting
bending of the whisker.

00:21:50.770 --> 00:21:52.390
And sometimes those
signals, just as

00:21:52.390 --> 00:21:55.090
a consequence of the movement
and the mass of the whisker,

00:21:55.090 --> 00:21:57.550
are strong enough to
be above threshold

00:21:57.550 --> 00:21:59.570
to generate an
orient, so you get,

00:21:59.570 --> 00:22:02.350
if you like, these
ghost-orienting movements

00:22:02.350 --> 00:22:04.990
towards stimuli
that don't exist.

00:22:04.990 --> 00:22:08.590
And we know that rats don't make
these kind of ghost orients,

00:22:08.590 --> 00:22:11.920
so something else must
be going on in the brain.

00:22:11.920 --> 00:22:15.240
And one part of the brain
that might be helping here

00:22:15.240 --> 00:22:18.780
is a region called the
cerebellum, which, I'm not sure

00:22:18.780 --> 00:22:21.360
if you've covered that
in the summer school,

00:22:21.360 --> 00:22:24.180
but the cerebellum,
this large structure

00:22:24.180 --> 00:22:25.980
at the back of the right brain.

00:22:25.980 --> 00:22:29.010
One of its key
functions seems to be

00:22:29.010 --> 00:22:32.510
to make predictions
about sensory signals,

00:22:32.510 --> 00:22:35.580
and particularly, to be able
to predict sensory signals that

00:22:35.580 --> 00:22:37.755
have been caused by
your own movement.

00:22:37.755 --> 00:22:39.510
And there's a lovely
experiment that's

00:22:39.510 --> 00:22:43.200
been done by Blakemore et
al, where they put people

00:22:43.200 --> 00:22:44.760
into a scanner.

00:22:44.760 --> 00:22:49.360
And they investigated how they
responded to tickling stimuli.

00:22:49.360 --> 00:22:51.270
So of course, if
somebody tickles you,

00:22:51.270 --> 00:22:53.910
that can be quite amusing,
but unfortunately,

00:22:53.910 --> 00:22:56.940
if you try to tickle yourself,
it's really uninteresting.

00:22:56.940 --> 00:22:59.670
It doesn't work as a stimulus.

00:22:59.670 --> 00:23:04.530
And it's worth thinking about
why it is that self-tickling

00:23:04.530 --> 00:23:06.150
is so unrewarding.

00:23:06.150 --> 00:23:08.910
And one of the reasons is
that it's just not surprising.

00:23:08.910 --> 00:23:12.160
You know what's going to happen
when you tickle yourself,

00:23:12.160 --> 00:23:14.070
whereas if somebody
else is doing it,

00:23:14.070 --> 00:23:16.290
it's unexpected and surprising.

00:23:16.290 --> 00:23:20.670
So why is self-tickling
unexpected?

00:23:20.670 --> 00:23:22.560
Why is it not surprising?

00:23:22.560 --> 00:23:25.530
It must be because the brain
expects and anticipates

00:23:25.530 --> 00:23:27.570
the signal that
it's going to get.

00:23:27.570 --> 00:23:30.450
And what Blakemore
et al did was to show

00:23:30.450 --> 00:23:32.910
that the cerebellum
really lights up

00:23:32.910 --> 00:23:35.220
when you try to tickle
yourself, because it's

00:23:35.220 --> 00:23:38.340
estimating and predicting
the sensory signal,

00:23:38.340 --> 00:23:40.920
and using that to
cancel out, if you like,

00:23:40.920 --> 00:23:44.130
the signal that's
coming from your skin.

00:23:44.130 --> 00:23:48.030
The same thing is happening
in electric fish, which

00:23:48.030 --> 00:23:50.490
generate this broad
electric field which

00:23:50.490 --> 00:23:53.242
they use for catching prey.

00:23:53.242 --> 00:23:55.200
And they need to be able
to tell the difference

00:23:55.200 --> 00:23:58.800
between a distortion to the
electric field caused by a prey

00:23:58.800 --> 00:24:01.350
animal and a distortion
caused by their own movement,

00:24:01.350 --> 00:24:02.370
by swimming.

00:24:02.370 --> 00:24:05.080
And they do that by having
a very large cerebellum.

00:24:05.080 --> 00:24:06.780
So we put a model
of the cerebellum

00:24:06.780 --> 00:24:08.700
in our whiskered robot.

00:24:08.700 --> 00:24:11.020
And the cerebellum
predicts the noise

00:24:11.020 --> 00:24:13.830
you might get due to the
movement of the whiskers.

00:24:13.830 --> 00:24:15.930
And it learns
online to accurately

00:24:15.930 --> 00:24:18.150
predict what noise
signals you might get,

00:24:18.150 --> 00:24:19.920
and to cancel them
out, so you get

00:24:19.920 --> 00:24:24.420
a much better signal-to-noise
ratio in the robot.

00:24:24.420 --> 00:24:28.460
So we've dealt with whisking.

00:24:28.460 --> 00:24:29.940
And we've dealt with orienting.

00:24:29.940 --> 00:24:33.060
But as you saw with that
rat on the windowsill,

00:24:33.060 --> 00:24:35.291
the whisker movements
are really precise.

00:24:35.291 --> 00:24:36.540
And they're really controlled.

00:24:36.540 --> 00:24:38.550
And the rat seems
to really care about

00:24:38.550 --> 00:24:41.190
how it's moving its whiskers
and how it's touching.

00:24:41.190 --> 00:24:43.290
We call this active sensing.

00:24:43.290 --> 00:24:45.360
And if you look at
these high-speed videos,

00:24:45.360 --> 00:24:47.220
you can see, for
instance, this rat

00:24:47.220 --> 00:24:49.880
when it's exploring
this perspex block.

00:24:49.880 --> 00:24:53.354
The whiskers aren't moving in
a stereotype symmetric way.

00:24:53.354 --> 00:24:55.770
You can see that here, the
whiskers on the right-hand side

00:24:55.770 --> 00:24:57.940
are really reaching
round to try and reach

00:24:57.940 --> 00:24:59.770
the other side of the block.

00:24:59.770 --> 00:25:01.740
If you watch this rat
here, you see that too.

00:25:01.740 --> 00:25:03.960
You've got asymmetry.

00:25:03.960 --> 00:25:07.260
And you'll see that, even as
the rat comes up to the cylinder

00:25:07.260 --> 00:25:10.710
here, the whiskers at the
front are pushing forward

00:25:10.710 --> 00:25:14.170
while the ones at the back
are hardly moving at all,

00:25:14.170 --> 00:25:16.350
so there's some ability to
control even the whiskers

00:25:16.350 --> 00:25:18.130
on one side of the head.

00:25:18.130 --> 00:25:20.064
And when you move your
fingers, of course,

00:25:20.064 --> 00:25:22.230
there's some coupling between
your finger movements.

00:25:22.230 --> 00:25:24.510
You can't move them
entirely independently.

00:25:24.510 --> 00:25:26.760
And each of these whiskers
has its own muscle,

00:25:26.760 --> 00:25:29.490
so there's a degree
of independence

00:25:29.490 --> 00:25:31.690
in how the whiskers can move.

00:25:31.690 --> 00:25:34.720
And we find that when we
record over long intervals.

00:25:34.720 --> 00:25:36.290
So this was a study--

00:25:36.290 --> 00:25:37.580
[ELECTRONIC NOISE]

00:25:37.580 --> 00:25:42.880
--in which we recorded the
whisking muscles using EMG.

00:25:42.880 --> 00:25:46.410
And that's the sound that you
can hear as the rat explored.

00:25:46.410 --> 00:25:50.270
And we tracked the rat
as he was moving around.

00:25:50.270 --> 00:25:51.920
And we showed that,
whenever he came

00:25:51.920 --> 00:25:55.060
close to the edge
of the box here,

00:25:55.060 --> 00:25:56.720
the whiskers would
become asymmetric.

00:25:56.720 --> 00:25:58.970
And the whiskers that were
furthest away from the wall

00:25:58.970 --> 00:26:02.120
would push round to try and
touch the sides of the box.

00:26:02.120 --> 00:26:04.490
The whiskers that
were close to the wall

00:26:04.490 --> 00:26:06.180
would barely move at all.

00:26:06.180 --> 00:26:10.280
So we want to put that kind
of control into our robot.

00:26:10.280 --> 00:26:14.600
So I briefly want to come
back to this question of how

00:26:14.600 --> 00:26:17.160
we decompose control.

00:26:17.160 --> 00:26:21.470
So in our original robot
that was controlled

00:26:21.470 --> 00:26:24.050
by the basal ganglia,
and it's collecting cans,

00:26:24.050 --> 00:26:26.990
we decompose behaviors
into the different elements

00:26:26.990 --> 00:26:28.120
of behavior--

00:26:28.120 --> 00:26:31.520
looking for a can, picking it
up, carrying it to the wall,

00:26:31.520 --> 00:26:32.880
these sorts of things.

00:26:32.880 --> 00:26:35.180
And if we look in the
ethology literature,

00:26:35.180 --> 00:26:37.400
we find that people have
talked about these kinds

00:26:37.400 --> 00:26:38.850
of decompositions.

00:26:38.850 --> 00:26:41.330
There's a very famous
paper by Baerends

00:26:41.330 --> 00:26:42.780
about the herring gull.

00:26:42.780 --> 00:26:44.310
And with the herring
gull, there's

00:26:44.310 --> 00:26:50.090
this famous experiment where
the egg rolls out the nest.

00:26:50.090 --> 00:26:53.360
And the bird will retrieve
the egg with its bill

00:26:53.360 --> 00:26:55.220
and push it back into the nest.

00:26:55.220 --> 00:26:59.340
And it will do this same action
really reliably and repeatedly.

00:26:59.340 --> 00:27:01.250
And it can do it with
eggs of various size.

00:27:01.250 --> 00:27:03.380
It might even do
it for a Coke can.

00:27:03.380 --> 00:27:05.960
And if you take the egg
away during the movement,

00:27:05.960 --> 00:27:07.970
it will still
complete the movement.

00:27:07.970 --> 00:27:11.360
And ethologists have called
this a fixed action pattern,

00:27:11.360 --> 00:27:13.100
so it may be that
behavior is decomposed

00:27:13.100 --> 00:27:15.650
into action patterns.

00:27:15.650 --> 00:27:17.630
And that's one of the
ways, for instance,

00:27:17.630 --> 00:27:20.720
in which Rodney Brooks wants
to decompose robot behavior.

00:27:20.720 --> 00:27:23.030
We decompose it into
different things

00:27:23.030 --> 00:27:24.605
we might want the robot to do.

00:27:24.605 --> 00:27:26.480
And we can do that with
our whiskered robots.

00:27:26.480 --> 00:27:30.020
Here's another one with
its behavior decomposed

00:27:30.020 --> 00:27:32.090
into different kinds
of, if you like,

00:27:32.090 --> 00:27:36.270
orienting behaviors and
fixed action patterns.

00:27:36.270 --> 00:27:37.940
Another way to
decompose behavior

00:27:37.940 --> 00:27:40.730
is to think about where
your attention is, so

00:27:40.730 --> 00:27:43.070
where you put your
attention might decide

00:27:43.070 --> 00:27:44.540
what you're going to do next.

00:27:44.540 --> 00:27:47.180
And for an animal that
doesn't have arms,

00:27:47.180 --> 00:27:51.080
and of course most animals
except humans and some primates

00:27:51.080 --> 00:27:54.650
don't usually use their
forelimbs for much else

00:27:54.650 --> 00:27:56.390
other than locomotion.

00:27:56.390 --> 00:27:58.430
And they primarily
are positioning

00:27:58.430 --> 00:28:00.840
their head and their face.

00:28:00.840 --> 00:28:03.600
And their main effector,
then, is their mouth.

00:28:03.600 --> 00:28:05.930
So where you position
your attention

00:28:05.930 --> 00:28:08.520
could determine what
you're going to do next.

00:28:08.520 --> 00:28:10.580
So another way of
decomposing control

00:28:10.580 --> 00:28:12.977
is to solve the
attention problem first.

00:28:12.977 --> 00:28:14.685
And then once you
solve that, the problem

00:28:14.685 --> 00:28:17.180
of what you're going
to do is simplified.

00:28:17.180 --> 00:28:19.940
So in this robot,
we're controlling it

00:28:19.940 --> 00:28:22.190
by deciding where its
attention should go.

00:28:22.190 --> 00:28:26.150
And then the rest of the
body kind of follows.

00:28:26.150 --> 00:28:28.910
When humans have special
attention, of course,

00:28:28.910 --> 00:28:31.560
we explore that in
the visual modality.

00:28:31.560 --> 00:28:34.170
And we look at the saccadic
eye movements that people make.

00:28:34.170 --> 00:28:37.940
So in the famous
experiment, Albert Yarbus

00:28:37.940 --> 00:28:39.980
had people looking
at this picture

00:28:39.980 --> 00:28:41.990
and tracking where
their eyes would look.

00:28:41.990 --> 00:28:45.470
And of course, we look at the
socially-significant elements

00:28:45.470 --> 00:28:48.080
of the picture, people's
faces and so on,

00:28:48.080 --> 00:28:52.750
not just arbitrary points of
light, or corners, and so on.

00:28:52.750 --> 00:28:57.170
And we can actually calculate
a saliency map for space

00:28:57.170 --> 00:29:00.140
and say what are the
important parts of space

00:29:00.140 --> 00:29:02.690
for exploring and attending to.

00:29:02.690 --> 00:29:07.370
And we've taken that idea and
transferred it into our model

00:29:07.370 --> 00:29:08.630
for understanding the rat.

00:29:08.630 --> 00:29:11.510
And we thought about tactile
saliency maps, so can

00:29:11.510 --> 00:29:13.900
we, with a sense of
touch, think about areas

00:29:13.900 --> 00:29:17.000
of the world which are important
to explore and understand

00:29:17.000 --> 00:29:18.080
through touch?

00:29:18.080 --> 00:29:21.110
And can we use that to
control the movement

00:29:21.110 --> 00:29:24.470
of our robot, or in this
case, our simulation?

00:29:24.470 --> 00:29:28.070
So here, we have a form of
emergent wall following, which

00:29:28.070 --> 00:29:31.850
is a consequence of the
rat's spatial attention being

00:29:31.850 --> 00:29:35.830
driven by contact with
vertical objects, which we--

00:29:35.830 --> 00:29:39.230
we program it so that
the vertical surfaces

00:29:39.230 --> 00:29:41.090
are salient and interesting.

00:29:41.090 --> 00:29:43.130
And it has this salient zone.

00:29:43.130 --> 00:29:46.610
And it tries to put its
whiskers into the salient zone.

00:29:46.610 --> 00:29:49.700
And then here is a robot
instantiating this.

00:29:49.700 --> 00:29:51.380
This is Ben Mitchinson,
who's programmed

00:29:51.380 --> 00:29:52.730
many of these robots.

00:29:52.730 --> 00:29:54.800
And so what we're
doing now is following

00:29:54.800 --> 00:29:58.820
this biologically-inspired
orienting system

00:29:58.820 --> 00:29:59.930
to explore shapes.

00:29:59.930 --> 00:30:03.350
And in this case, he put his
own face in front of the robot.

00:30:03.350 --> 00:30:07.580
And you can see the robot making
light touches against his face

00:30:07.580 --> 00:30:11.420
and investigating it, looking--

00:30:11.420 --> 00:30:14.090
making a series of, if you
like, exploratory touches,

00:30:14.090 --> 00:30:17.720
somewhat like saccades,
somewhat like what

00:30:17.720 --> 00:30:19.670
you might imagine a
blind person would

00:30:19.670 --> 00:30:21.740
do if they were
investigating your face

00:30:21.740 --> 00:30:23.300
to try and recognize you.

00:30:23.300 --> 00:30:25.310
And Mitra Hartmann
from Northwestern

00:30:25.310 --> 00:30:27.200
has shown that you
can take signals

00:30:27.200 --> 00:30:30.040
off these kinds of whiskers
and reconstruct a face,

00:30:30.040 --> 00:30:33.410
so it should be
possible from this

00:30:33.410 --> 00:30:36.960
to build up from the touches,
the sequence of touches,

00:30:36.960 --> 00:30:39.080
a lot of rich information
about the object that's

00:30:39.080 --> 00:30:40.480
being investigated.

00:30:40.480 --> 00:30:42.202
How much time?

00:30:42.202 --> 00:30:42.910
I need to finish.

00:30:42.910 --> 00:30:44.630
OK, let me just skip through.

00:30:44.630 --> 00:30:47.362
So we've been doing--
working on the cortex.

00:30:47.362 --> 00:30:48.820
We have a number
of models of that,

00:30:48.820 --> 00:30:51.580
which I'd like to
show you, but I

00:30:51.580 --> 00:30:53.950
want to just finish,
just to make contact

00:30:53.950 --> 00:30:56.980
with John's talk, is
that we've been doing,

00:30:56.980 --> 00:31:00.640
in our robots, tactile
simultaneous localization

00:31:00.640 --> 00:31:01.270
and mapping.

00:31:01.270 --> 00:31:03.520
So this is our whiskered robot.

00:31:03.520 --> 00:31:05.830
And we have various models
for this, some of which

00:31:05.830 --> 00:31:07.780
are more hippocampal-like.

00:31:07.780 --> 00:31:10.130
This one, I think, was more
of an engineered model.

00:31:10.130 --> 00:31:12.700
But you can see the
robot just using touch

00:31:12.700 --> 00:31:15.340
on these artificial
whiskers, building up

00:31:15.340 --> 00:31:17.090
a map of its environment.

00:31:17.090 --> 00:31:19.600
These two lines show its
dead-reckoning position

00:31:19.600 --> 00:31:21.490
and its calculated position.

00:31:21.490 --> 00:31:24.550
And just using touch,
we can build up

00:31:24.550 --> 00:31:28.220
a reasonably accurate map of
the world that we're exploring.

00:31:28.220 --> 00:31:31.210
So Giorgio will
talk about the iCub.

00:31:31.210 --> 00:31:33.730
And I just wanted to mention
that, in the work we're

00:31:33.730 --> 00:31:36.280
doing with Giorgio, we
are very much trying

00:31:36.280 --> 00:31:38.360
to understand human cognition.

00:31:38.360 --> 00:31:41.680
I wrote a short article for New
Scientist on the possibility

00:31:41.680 --> 00:31:44.640
that robots might
one day have selves.