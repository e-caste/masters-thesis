WEBVTT

00:00:00.000 --> 00:00:02.435
[SQUEAKING]

00:00:02.435 --> 00:00:04.383
[RUSTLING]

00:00:04.383 --> 00:00:06.818
[CLICKING]

00:00:11.055 --> 00:00:12.180
FRANK SCHILBACH: All right.

00:00:12.180 --> 00:00:16.088
Welcome to lectures
seven and eight.

00:00:16.088 --> 00:00:17.880
We're going to talk
about risk preferences.

00:00:17.880 --> 00:00:18.830
Hello?

00:00:18.830 --> 00:00:21.190
We're going to talk
about risk preferences.

00:00:21.190 --> 00:00:23.010
In particular, sort
from the perspective

00:00:23.010 --> 00:00:25.440
of expected utility, which
is sort of the classical way

00:00:25.440 --> 00:00:27.270
of economics to view this.

00:00:27.270 --> 00:00:32.475
This is going to take one and
1/2, perhaps two lectures.

00:00:32.475 --> 00:00:34.350
Broadly speaking, we're
going to look at what

00:00:34.350 --> 00:00:35.820
does economics usually assume.

00:00:35.820 --> 00:00:38.340
How does economics think
about risk preferences,

00:00:38.340 --> 00:00:42.280
about choices involving risk?

00:00:42.280 --> 00:00:45.900
How do we think about sort of
measuring risk preferences?

00:00:45.900 --> 00:00:48.330
What are some of the
implications and what are some

00:00:48.330 --> 00:00:50.700
of the limits of risk
preferences in terms of what we

00:00:50.700 --> 00:00:53.760
can explain and what
we cannot explain?

00:00:53.760 --> 00:00:56.280
And then in the
following lectures

00:00:56.280 --> 00:00:59.280
we're going to have an
alternative model of reference

00:00:59.280 --> 00:01:01.792
dependence preferences
where essentially you're

00:01:01.792 --> 00:01:03.750
going to relax or change
some of the underlying

00:01:03.750 --> 00:01:10.770
assumptions on how to measure
preferences related to risk.

00:01:10.770 --> 00:01:14.170
Problem set two will be
posted soon-- later this week.

00:01:14.170 --> 00:01:16.380
I'm sure you can't
wait for this.

00:01:16.380 --> 00:01:22.183
A reminder, late submissions
will not be accepted.

00:01:22.183 --> 00:01:23.850
This is always like
a commitment problem

00:01:23.850 --> 00:01:26.370
because people come up with
all sorts of good excuses

00:01:26.370 --> 00:01:29.058
why they submitted
the problem set late

00:01:29.058 --> 00:01:30.600
and then I kind of
feel bad about it.

00:01:30.600 --> 00:01:33.030
So I'm here with
committing to not accepting

00:01:33.030 --> 00:01:34.530
any late submissions
for whatever

00:01:34.530 --> 00:01:37.200
reasons unless you have
sort of a medical excuse

00:01:37.200 --> 00:01:41.730
or sort of an excuse notice.

00:01:41.730 --> 00:01:44.460
So no my PDF was
corrupted and all sorts

00:01:44.460 --> 00:01:45.780
of other good reasons.

00:01:45.780 --> 00:01:48.060
I was a student once
as well and I know

00:01:48.060 --> 00:01:51.060
students are very creative.

00:01:51.060 --> 00:01:54.330
We will post previous problems
sets, midterms, and finals

00:01:54.330 --> 00:01:55.530
for you to practice overall.

00:01:55.530 --> 00:01:57.510
I think of the problem
sets less of a way

00:01:57.510 --> 00:02:01.650
for testing you or testing
sort of whether you can do it

00:02:01.650 --> 00:02:04.050
or not, but rather as a way
for you to practice things,

00:02:04.050 --> 00:02:07.388
whether you have understood
the materials in parts

00:02:07.388 --> 00:02:08.430
of the past problem sets.

00:02:08.430 --> 00:02:11.700
And midterms and finals will
sort of help you with that.

00:02:11.700 --> 00:02:14.160
As usual, please ask
questions on Piazza

00:02:14.160 --> 00:02:16.630
or come to office hours.

00:02:16.630 --> 00:02:18.180
So what we're
going to talk about

00:02:18.180 --> 00:02:20.160
is, broadly speaking
risk aversion.

00:02:20.160 --> 00:02:24.520
How do economists think
about choices involving risk?

00:02:24.520 --> 00:02:28.350
Then again, I sort of outline
sort of the very simple

00:02:28.350 --> 00:02:31.650
or the basic model of--

00:02:31.650 --> 00:02:33.420
main workhorse
model of economics--

00:02:33.420 --> 00:02:35.378
is to think about choices
involving risk, which

00:02:35.378 --> 00:02:37.100
is the expected utility model.

00:02:37.100 --> 00:02:38.885
We're going to then
think about how do we

00:02:38.885 --> 00:02:41.010
measure risk preferences,
the underlying preference

00:02:41.010 --> 00:02:45.600
parameters that sort of
are embedded in this model.

00:02:45.600 --> 00:02:48.780
We're going to lead then
to some absurd implications

00:02:48.780 --> 00:02:49.720
in particular.

00:02:49.720 --> 00:02:52.680
So discrepancy-- how people
tend to think about small scale

00:02:52.680 --> 00:02:54.540
and large scale risk aversion.

00:02:54.540 --> 00:02:56.820
What I mean by that--
essentially small gambles that

00:02:56.820 --> 00:03:00.300
involve a few dollars versus
really large scale choices

00:03:00.300 --> 00:03:02.430
that involve
thousands of dollars.

00:03:02.430 --> 00:03:05.760
And what I'm going to show you,
very similar to some degree

00:03:05.760 --> 00:03:10.860
to how we think about time
preferences where the typical

00:03:10.860 --> 00:03:15.330
exponential discounting model
cannot explain both short run

00:03:15.330 --> 00:03:17.848
and long run time preference
decisions that people make.

00:03:17.848 --> 00:03:19.390
That's just a sort
of a calibration--

00:03:19.390 --> 00:03:20.760
really very hard to do.

00:03:20.760 --> 00:03:22.680
Similarly, the
expected utility model

00:03:22.680 --> 00:03:27.270
has problems with reconciling
small scale and large scale

00:03:27.270 --> 00:03:29.273
choices that people make.

00:03:29.273 --> 00:03:30.690
I'll tell you that
in more detail.

00:03:30.690 --> 00:03:33.000
But in short, the
summary is if people

00:03:33.000 --> 00:03:36.960
are risk averse when it comes
to small gambles, that implies

00:03:36.960 --> 00:03:39.210
that they're absurdly
risk averse coming

00:03:39.210 --> 00:03:42.220
from large gambles if you sort
of take that model seriously.

00:03:42.220 --> 00:03:46.150
And so that's kind of like
not really true in reality.

00:03:46.150 --> 00:03:47.670
And so then we sort
think about how

00:03:47.670 --> 00:03:49.960
to relax those kinds
of assumptions.

00:03:49.960 --> 00:03:50.460
OK.

00:03:50.460 --> 00:03:53.850
So first let's think about what
kinds of choices and decisions

00:03:53.850 --> 00:03:56.070
do in fact involve
risk and uncertainty.

00:03:56.070 --> 00:04:00.930
What examples do we
have in your life?

00:04:00.930 --> 00:04:05.980
What is risky or what
would involve uncertainty?

00:04:05.980 --> 00:04:06.480
Yes?

00:04:06.480 --> 00:04:08.452
AUDIENCE: Whether
or not [INAUDIBLE]..

00:04:11.382 --> 00:04:12.340
FRANK SCHILBACH: Right.

00:04:12.340 --> 00:04:13.930
Whether or not to get education.

00:04:13.930 --> 00:04:15.880
Whether or not to
study and so on.

00:04:15.880 --> 00:04:17.680
Because the reward
often is like uncertain.

00:04:17.680 --> 00:04:17.860
Right?

00:04:17.860 --> 00:04:18.579
You might get a job.

00:04:18.579 --> 00:04:19.540
You might not get a job.

00:04:19.540 --> 00:04:21.040
You might do really
well in college.

00:04:21.040 --> 00:04:22.130
You might not.

00:04:22.130 --> 00:04:23.090
And so on and so forth.

00:04:23.090 --> 00:04:26.870
So the costs-- you might like
it, you might not like it,

00:04:26.870 --> 00:04:27.370
and so on.

00:04:27.370 --> 00:04:28.840
It's not clear.

00:04:28.840 --> 00:04:30.640
So the costs and
benefits are uncertain.

00:04:30.640 --> 00:04:32.240
There might be a recession
when you graduate.

00:04:32.240 --> 00:04:33.198
And so on and so forth.

00:04:33.198 --> 00:04:36.489
So the returns and costs
are both uncertain.

00:04:40.380 --> 00:04:40.880
Yes?

00:04:40.880 --> 00:04:42.358
AUDIENCE: Making
large purchases,

00:04:42.358 --> 00:04:44.230
like buying [INAUDIBLE].

00:04:44.230 --> 00:04:46.110
Because you don't
know [INAUDIBLE]..

00:04:46.110 --> 00:04:47.450
FRANK SCHILBACH: Yeah, exactly.

00:04:47.450 --> 00:04:50.400
You might buy a
house or you might

00:04:50.400 --> 00:04:53.582
think about buying or
renting more broadly.

00:04:53.582 --> 00:04:55.290
And there it depends
a lot on essentially

00:04:55.290 --> 00:04:56.915
what's happening to
the housing market.

00:04:56.915 --> 00:04:59.070
If the housing market
goes up or down,

00:04:59.070 --> 00:05:01.930
the choice to buy a house versus
renting is very different.

00:05:01.930 --> 00:05:02.430
Right?

00:05:02.430 --> 00:05:04.305
So if the housing market
goes up, most likely

00:05:04.305 --> 00:05:05.638
you should probably buy a house.

00:05:05.638 --> 00:05:07.650
If the housing market
actually happens to tank,

00:05:07.650 --> 00:05:10.050
the [INAUDIBLE] [? at ?]
[? least ?] it's a bad idea

00:05:10.050 --> 00:05:11.430
to do so.

00:05:11.430 --> 00:05:12.570
Yes?

00:05:12.570 --> 00:05:14.972
AUDIENCE: [INAUDIBLE]
[? renters ?] insurance.

00:05:14.972 --> 00:05:15.930
FRANK SCHILBACH: Right.

00:05:15.930 --> 00:05:18.210
So the two choices
that we have so far

00:05:18.210 --> 00:05:19.740
were essentially
choices involving

00:05:19.740 --> 00:05:21.210
risk where you
sort of essentially

00:05:21.210 --> 00:05:23.370
decide to do something
where the outcomes are

00:05:23.370 --> 00:05:25.105
uncertain or risky in some way.

00:05:25.105 --> 00:05:26.730
Now, what you're
saying, in some sense,

00:05:26.730 --> 00:05:28.770
is like, a bunch
of other choices,

00:05:28.770 --> 00:05:31.830
potentially, are risk
mitigation strategies.

00:05:31.830 --> 00:05:35.040
So you have, essentially,
certain risk in your life.

00:05:35.040 --> 00:05:36.840
And you have choices
where you could say,

00:05:36.840 --> 00:05:37.890
I could buy insurance.

00:05:37.890 --> 00:05:41.460
Or I could sort make other
choices that mitigate or reduce

00:05:41.460 --> 00:05:43.470
the risk that I'm exposed to.

00:05:43.470 --> 00:05:45.480
And one sort of
canonical example of that

00:05:45.480 --> 00:05:49.260
is purchasing any
type of insurance

00:05:49.260 --> 00:05:51.720
but, in particular, renter's
insurance, as you mentioned.

00:05:51.720 --> 00:05:53.460
Yes.

00:05:53.460 --> 00:05:54.231
Yeah?

00:05:54.231 --> 00:05:57.320
AUDIENCE: For farmers, the
crop they choose to grow.

00:05:57.320 --> 00:06:00.390
FRANK SCHILBACH: Yes, so
essentially, call that--

00:06:00.390 --> 00:06:03.210
in development in particular,
or development economics

00:06:03.210 --> 00:06:06.660
in particular, there's lots of
issues of production choices

00:06:06.660 --> 00:06:08.280
that people make.

00:06:08.280 --> 00:06:10.680
This could be like what crops
to grow, whether you should

00:06:10.680 --> 00:06:13.800
buy a machine, whether you
should start a business,

00:06:13.800 --> 00:06:14.300
and so on.

00:06:14.300 --> 00:06:16.440
So there's all sorts
of choices in terms

00:06:16.440 --> 00:06:21.360
of what business to go into,
what kinds of specifics,

00:06:21.360 --> 00:06:23.610
what product to sell
if you have a business.

00:06:23.610 --> 00:06:27.480
And in the farmer case,
what crops should you grow?

00:06:27.480 --> 00:06:28.860
Should you buy fertilizer?

00:06:28.860 --> 00:06:32.700
Should you use other inputs
and so on and so forth.

00:06:32.700 --> 00:06:34.080
Should you do
[INAUDIBLE] there's

00:06:34.080 --> 00:06:36.163
a bunch of different other--
should you intercrop?

00:06:36.163 --> 00:06:38.070
There's a bunch of
different other choices

00:06:38.070 --> 00:06:41.970
that you could make that
essentially involve risks,

00:06:41.970 --> 00:06:44.022
because the outcome,
essentially, is uncertain,

00:06:44.022 --> 00:06:46.230
because essentially, the
season might be good or bad.

00:06:46.230 --> 00:06:48.490
In the farmer's case,
if you, for example,

00:06:48.490 --> 00:06:50.190
purchase fertilizer
or a certain--

00:06:50.190 --> 00:06:54.815
for example, you could purchase
or use drought-resistant crops.

00:06:54.815 --> 00:06:56.190
Of course, if
there's no drought,

00:06:56.190 --> 00:06:57.690
then that's not
really that helpful.

00:06:57.690 --> 00:07:02.440
But if there's a drought,
that's really high return to do.

00:07:02.440 --> 00:07:02.950
Yes?

00:07:02.950 --> 00:07:03.450
Yes?

00:07:03.450 --> 00:07:05.812
AUDIENCE: Creating an
investment portfolio.

00:07:05.812 --> 00:07:07.020
FRANK SCHILBACH: Creating a--

00:07:07.020 --> 00:07:08.790
AUDIENCE: Investment portfolio.

00:07:08.790 --> 00:07:11.280
FRANK SCHILBACH: Yeah,
so investing your money

00:07:11.280 --> 00:07:16.050
into a different-- in the
stock market or in other sort

00:07:16.050 --> 00:07:17.940
of bonds or the like--

00:07:17.940 --> 00:07:20.080
how should you invest the money?

00:07:20.080 --> 00:07:22.920
That's kind of related,
to some degree,

00:07:22.920 --> 00:07:25.500
to the renting versus
buying a house.

00:07:25.500 --> 00:07:28.680
You can think of buying as
a house as one asset, one

00:07:28.680 --> 00:07:31.680
potential very sort of illiquid
asset that you could buy.

00:07:31.680 --> 00:07:33.157
Similarly, you could buy stocks.

00:07:33.157 --> 00:07:33.990
You could buy bonds.

00:07:33.990 --> 00:07:36.630
You could keep just
cash and so on.

00:07:36.630 --> 00:07:38.370
And there, that very
much depends on,

00:07:38.370 --> 00:07:41.112
the return depends
on things that

00:07:41.112 --> 00:07:43.070
are out of your hand,
which essentially is just

00:07:43.070 --> 00:07:45.420
what the stock market might do.

00:07:45.420 --> 00:07:48.330
So I think once you
think about choices

00:07:48.330 --> 00:07:51.150
involving risks, essentially
almost any choice

00:07:51.150 --> 00:07:56.430
in your life actually is risky
to some degree or uncertain,

00:07:56.430 --> 00:07:59.730
ranging from going to
college, doing problem sets,

00:07:59.730 --> 00:08:00.810
studying for exams.

00:08:00.810 --> 00:08:02.190
Which exams should
you study for?

00:08:02.190 --> 00:08:04.200
Which questions are
people going to ask?

00:08:04.200 --> 00:08:09.210
Health decisions-- should you
invest in your health or not?

00:08:09.210 --> 00:08:11.910
For a lot of diseases
that people might get,

00:08:11.910 --> 00:08:13.240
it's often very uncertain.

00:08:13.240 --> 00:08:18.000
So even if you're smoking
a lot, not every smoker

00:08:18.000 --> 00:08:19.245
falls sick or the like.

00:08:19.245 --> 00:08:23.880
No, just the risk of cancer
and other diseases increases.

00:08:23.880 --> 00:08:27.240
That sort of
financial investments,

00:08:27.240 --> 00:08:29.567
dating choices, and
so on and so forth--

00:08:29.567 --> 00:08:31.650
even friendship choices
are, in some sense, risky.

00:08:31.650 --> 00:08:33.150
If you want, riding a bicycle--

00:08:33.150 --> 00:08:35.490
that's very sort
of small choices--

00:08:35.490 --> 00:08:37.039
wearing a helmet versus not.

00:08:37.039 --> 00:08:38.789
Essentially, almost
anything in your life,

00:08:38.789 --> 00:08:40.706
if you think about what
are the outcomes, what

00:08:40.706 --> 00:08:42.690
are the different
choices that you have,

00:08:42.690 --> 00:08:46.020
and what are the outcomes
associated with those choices,

00:08:46.020 --> 00:08:49.668
almost all of those choices
are associated with uncertainty

00:08:49.668 --> 00:08:51.210
and a sense of you're
not quite sure.

00:08:51.210 --> 00:08:53.550
Is the return going
to be high or low?

00:08:53.550 --> 00:08:56.110
Then as I said before,
in addition to that,

00:08:56.110 --> 00:08:59.535
there's sort of risk mitigating
strategies and a sense of you

00:08:59.535 --> 00:09:01.560
have a lot of choices
in a lot of issues

00:09:01.560 --> 00:09:03.210
that are associated with risk.

00:09:03.210 --> 00:09:05.700
And now you can choose
to reduce your exposure

00:09:05.700 --> 00:09:08.670
to risk by purchasing
insurance or, for example, also

00:09:08.670 --> 00:09:11.760
by avoiding certain
behaviors, right?

00:09:11.760 --> 00:09:14.730
So if you're worried about
being robbed, for example,

00:09:14.730 --> 00:09:18.690
in a certain part
of town, you might

00:09:18.690 --> 00:09:20.850
choose to go through
that part of town.

00:09:20.850 --> 00:09:22.530
And that's a risky thing to do.

00:09:22.530 --> 00:09:25.002
Or you can have risk mitigating
strategies where you just

00:09:25.002 --> 00:09:27.210
don't leave your house, or
just go in different ways,

00:09:27.210 --> 00:09:29.700
or just never go into certain
areas, which essentially

00:09:29.700 --> 00:09:32.040
are ways to protect
you, to reduce your risk

00:09:32.040 --> 00:09:35.040
exposure overall.

00:09:35.040 --> 00:09:36.312
Any questions?

00:09:40.470 --> 00:09:44.180
OK, so now let me
sort of just tell you

00:09:44.180 --> 00:09:47.120
three broad, stylized facts that
we're going to try and explain

00:09:47.120 --> 00:09:48.530
or try to tackle.

00:09:48.530 --> 00:09:51.480
And that's kind of what
economics is trying to do.

00:09:51.480 --> 00:09:53.923
So the first question is--

00:09:53.923 --> 00:09:55.340
the first thing
that comes to mind

00:09:55.340 --> 00:09:57.950
when you think about
economics and modeling choices

00:09:57.950 --> 00:10:00.350
involving risk is risk aversion.

00:10:00.350 --> 00:10:01.850
How do we think
about risk aversion?

00:10:01.850 --> 00:10:02.900
Or what is risk aversion?

00:10:05.450 --> 00:10:06.950
Why are people averse to risk?

00:10:06.950 --> 00:10:08.600
Yeah.

00:10:08.600 --> 00:10:10.502
AUDIENCE: Risk aversion
is the tendency

00:10:10.502 --> 00:10:14.394
to avoid bets that are more
risky, even though they

00:10:14.394 --> 00:10:17.874
will still ostensibly
benefit you the same.

00:10:17.874 --> 00:10:18.890
FRANK SCHILBACH: Mhm.

00:10:18.890 --> 00:10:22.700
So one-- you said, essentially,
if there are certain bets that

00:10:22.700 --> 00:10:26.660
involve risk, where the expected
values or an expectation

00:10:26.660 --> 00:10:29.420
you're going to do pretty well--
perhaps better than some safe

00:10:29.420 --> 00:10:30.350
outcomes--

00:10:30.350 --> 00:10:33.830
people tend to avoid
those kinds of bets.

00:10:33.830 --> 00:10:36.420
And that we might
call risk aversion.

00:10:36.420 --> 00:10:38.510
So that's exactly right.

00:10:38.510 --> 00:10:40.342
But now, why are
people doing that?

00:10:40.342 --> 00:10:42.050
What are the underlying
reasons for that?

00:10:46.690 --> 00:10:48.850
Yes.

00:10:48.850 --> 00:10:50.860
AUDIENCE: Potentially
involved is

00:10:50.860 --> 00:10:55.500
loss aversion, which
in the readings,

00:10:55.500 --> 00:10:59.200
I believe, some
studies by [INAUDIBLE]

00:10:59.200 --> 00:11:03.100
and others mentioned that,
showed that we had aversions

00:11:03.100 --> 00:11:07.305
specifically to losing
money or utility

00:11:07.305 --> 00:11:10.020
rather than risk
in and of itself.

00:11:10.020 --> 00:11:11.162
But that might be wrong.

00:11:11.162 --> 00:11:12.120
FRANK SCHILBACH: Right.

00:11:12.120 --> 00:11:13.740
So one part would
be to say, people

00:11:13.740 --> 00:11:17.670
might sort of lose or gain
money in certain gambles.

00:11:17.670 --> 00:11:19.710
And what you're saying
is, essentially, people

00:11:19.710 --> 00:11:23.820
might not treat the losses the
same as they treat the gains.

00:11:23.820 --> 00:11:27.090
And then you might sort
of decline certain gambles

00:11:27.090 --> 00:11:28.350
or certain risks.

00:11:28.350 --> 00:11:31.770
You're just worried about losing
out, and you put a lot of value

00:11:31.770 --> 00:11:32.455
on that.

00:11:32.455 --> 00:11:33.330
That's exactly right.

00:11:33.330 --> 00:11:37.733
We're going to talk about this
next week in a lot more detail.

00:11:37.733 --> 00:11:39.900
But what are some other
reasons why people might not

00:11:39.900 --> 00:11:42.810
want to engage in risk?

00:11:42.810 --> 00:11:43.360
Yes.

00:11:43.360 --> 00:11:45.420
AUDIENCE: I'd rather be
definitely OK than either

00:11:45.420 --> 00:11:47.712
[? to ?] [? the ?] [? point ?]
between super successful

00:11:47.712 --> 00:11:48.624
or die.

00:11:48.624 --> 00:11:49.499
FRANK SCHILBACH: Mhm.

00:11:49.499 --> 00:11:50.515
And why is that?

00:11:50.515 --> 00:11:52.640
AUDIENCE: [INAUDIBLE]
diminishing marginal utility,

00:11:52.640 --> 00:11:53.040
[? maybe. ?]

00:11:53.040 --> 00:11:53.250
FRANK SCHILBACH: Right.

00:11:53.250 --> 00:11:54.840
So one part is-- and
that's exactly how

00:11:54.840 --> 00:11:57.450
economists think about this--
is diminishing marginal utility.

00:11:57.450 --> 00:12:00.480
That's to say, if
you're really poor,

00:12:00.480 --> 00:12:02.580
getting your first dollar
has really high value

00:12:02.580 --> 00:12:04.423
to you-- the reason
being that now,

00:12:04.423 --> 00:12:06.090
essentially, otherwise
you would starve,

00:12:06.090 --> 00:12:07.680
or you can't eat and so on.

00:12:07.680 --> 00:12:11.130
The value of whatever you
purchase with that dollar

00:12:11.130 --> 00:12:14.340
is really high, because you
just have nothing otherwise.

00:12:14.340 --> 00:12:16.260
Now, if I give you a
million dollars and then

00:12:16.260 --> 00:12:18.540
another dollar, then essentially
the additional dollar

00:12:18.540 --> 00:12:19.915
that I give you
after the million

00:12:19.915 --> 00:12:21.510
is just not doing very much.

00:12:21.510 --> 00:12:24.630
So the marginal utility
of that dollar is low.

00:12:24.630 --> 00:12:27.253
And that's sort of diminishing
marginal utility of wealth.

00:12:27.253 --> 00:12:29.170
That's exactly how
economists talk about this.

00:12:29.170 --> 00:12:33.450
We're going to get back to
that in a lot of detail.

00:12:33.450 --> 00:12:34.440
Yeah?

00:12:34.440 --> 00:12:36.232
AUDIENCE: I think if
you look a little more

00:12:36.232 --> 00:12:40.380
at extreme examples, [INAUDIBLE]
if I lose so much money,

00:12:40.380 --> 00:12:42.645
I won't be able to afford
my expenses or something.

00:12:42.645 --> 00:12:44.770
So it doesn't matter what
is [? created ?] [? by ?]

00:12:44.770 --> 00:12:50.842
[INAUDIBLE] lose
a lot [INAUDIBLE]

00:12:50.842 --> 00:12:51.800
FRANK SCHILBACH: Right.

00:12:51.800 --> 00:12:54.590
So there might be sort of
certain minimum standards,

00:12:54.590 --> 00:12:57.565
in some sense, that people
have over their outcomes.

00:12:57.565 --> 00:13:00.050
Or you say, for
example, you really

00:13:00.050 --> 00:13:03.140
want to have a place to sleep
or you want to have some meal.

00:13:03.140 --> 00:13:05.840
And essentially, if you're
below that threshold,

00:13:05.840 --> 00:13:10.100
essentially your marginal
utility anywhere below that

00:13:10.100 --> 00:13:11.870
is really high,
because you really want

00:13:11.870 --> 00:13:13.140
to get over that threshold.

00:13:13.140 --> 00:13:19.730
And so you might avoid
certain choices or investments

00:13:19.730 --> 00:13:20.570
or the like.

00:13:20.570 --> 00:13:22.760
If there's even a
small chance of getting

00:13:22.760 --> 00:13:26.520
below your threshold, you
might be really averse to that.

00:13:26.520 --> 00:13:28.730
But what are some more
perhaps psychological reasons

00:13:28.730 --> 00:13:30.540
why people don't like risks?

00:13:30.540 --> 00:13:31.040
Yeah?

00:13:31.040 --> 00:13:42.350
AUDIENCE: [INAUDIBLE]
[? potential ?] [INAUDIBLE]

00:13:42.350 --> 00:13:43.403
FRANK SCHILBACH: Mhm.

00:13:43.403 --> 00:13:44.070
So that's right.

00:13:44.070 --> 00:13:44.720
That's what people do.

00:13:44.720 --> 00:13:46.230
We're going to also
talk about that.

00:13:46.230 --> 00:13:49.430
But why do people
not like the risk?

00:13:49.430 --> 00:13:51.740
Or some people like,
actually, risk.

00:13:51.740 --> 00:13:55.640
But what is the issue about
having a lot of exposure?

00:13:55.640 --> 00:13:59.380
Why do people purchase
insurance, for example?

00:13:59.380 --> 00:14:00.250
Yes?

00:14:00.250 --> 00:14:02.618
AUDIENCE: Some amount of
uncertainty [INAUDIBLE]

00:14:02.618 --> 00:14:04.660
[? risk ?] [? aversion, ?]
[INAUDIBLE] the higher

00:14:04.660 --> 00:14:07.422
the uncertainty of the
outcome, [INAUDIBLE]

00:14:07.422 --> 00:14:08.380
FRANK SCHILBACH: Right.

00:14:08.380 --> 00:14:10.280
So there's one part
that's what you said,

00:14:10.280 --> 00:14:12.340
which is there's diminishing
marginal utility of wealth.

00:14:12.340 --> 00:14:13.900
And this is exactly how
we're going to model this

00:14:13.900 --> 00:14:15.670
and how economists
think about this.

00:14:15.670 --> 00:14:17.300
However, there's
other things involved,

00:14:17.300 --> 00:14:19.480
which is just things like
anxiety or uncertainty.

00:14:19.480 --> 00:14:21.250
People might just not--

00:14:21.250 --> 00:14:23.080
suppose a storm is coming up.

00:14:23.080 --> 00:14:24.340
I might purchase insurance.

00:14:24.340 --> 00:14:26.710
And if I purchase insurance,
like flood insurance,

00:14:26.710 --> 00:14:29.980
or the like for a house,
I might just feel much--

00:14:29.980 --> 00:14:32.230
I might sleep better at
night and so on and so forth.

00:14:32.230 --> 00:14:35.397
I might just feel
better about concerns--

00:14:35.397 --> 00:14:36.980
or like health
insurance, for example,

00:14:36.980 --> 00:14:40.360
might lower anxiety and so
on, because people are just

00:14:40.360 --> 00:14:42.670
not worried constantly
about like falling

00:14:42.670 --> 00:14:45.070
ill or like disasters happening.

00:14:45.070 --> 00:14:47.830
And that's beyond
potentially any

00:14:47.830 --> 00:14:50.710
diminishing marginal
utility of wealth.

00:14:50.710 --> 00:14:54.940
That sort of anxiety,
stress, worries, and so on.

00:14:54.940 --> 00:14:56.804
Any other reasons?

00:14:56.804 --> 00:14:58.070
Yeah?

00:14:58.070 --> 00:15:00.473
AUDIENCE: I think even beyond
people wanting to not be

00:15:00.473 --> 00:15:02.390
stressed and anxious,
there's also the element

00:15:02.390 --> 00:15:05.690
of, if you're buying insurance
to smooth your consumption

00:15:05.690 --> 00:15:08.090
between different
states of the world,

00:15:08.090 --> 00:15:12.840
it makes it a lot easier to plan
for states after [INAUDIBLE] If

00:15:12.840 --> 00:15:13.340
you're--

00:15:13.340 --> 00:15:13.700
FRANK SCHILBACH: Well,
that's interesting.

00:15:13.700 --> 00:15:15.225
AUDIENCE: [INAUDIBLE]

00:15:15.225 --> 00:15:16.100
FRANK SCHILBACH: Yes.

00:15:16.100 --> 00:15:16.975
That's exactly right.

00:15:16.975 --> 00:15:19.152
So in some sense, if
you have insurance,

00:15:19.152 --> 00:15:21.110
if you reduce risks in
the states of the world,

00:15:21.110 --> 00:15:23.240
you can sort of,
essentially, exclude a bunch

00:15:23.240 --> 00:15:24.365
of bad states of the world.

00:15:24.365 --> 00:15:26.282
For example, suppose you
buy health insurance,

00:15:26.282 --> 00:15:28.190
suppose you have flood
insurance, and so on.

00:15:28.190 --> 00:15:29.780
A lot of bad things
that might happen you

00:15:29.780 --> 00:15:30.720
might be able to deal with.

00:15:30.720 --> 00:15:32.240
And you don't have
to necessarily

00:15:32.240 --> 00:15:34.880
have a contingency plan
of what if I fall sick

00:15:34.880 --> 00:15:37.220
and then go bankrupt, and
all sorts of other bad things

00:15:37.220 --> 00:15:37.940
happen.

00:15:37.940 --> 00:15:39.710
Or what if I--

00:15:39.710 --> 00:15:40.712
there's flood insurance.

00:15:40.712 --> 00:15:42.170
I can't pay the
bills and then have

00:15:42.170 --> 00:15:44.010
to leave my house and so on.

00:15:44.010 --> 00:15:45.920
So essentially, it
makes planning easier,

00:15:45.920 --> 00:15:48.282
in part because it's just
sort of easier in the mind.

00:15:48.282 --> 00:15:49.490
People feel more comfortable.

00:15:49.490 --> 00:15:52.670
And part-- it's actually
computational or just easier

00:15:52.670 --> 00:15:53.420
to do.

00:15:53.420 --> 00:15:55.178
So I added some reasons here.

00:15:55.178 --> 00:15:56.720
There's a bunch of
different reasons.

00:15:56.720 --> 00:15:59.840
I think it's important to
understand that economists have

00:15:59.840 --> 00:16:03.740
modeled risk aversion
as diminishing

00:16:03.740 --> 00:16:05.010
marginal utility of wealth.

00:16:05.010 --> 00:16:07.310
That's a very simple
way of doing this.

00:16:07.310 --> 00:16:10.950
It captures a lot of things,
but perhaps not all of them.

00:16:10.950 --> 00:16:13.820
And so here's some
reasons that I mentioned.

00:16:13.820 --> 00:16:15.400
Sort of contingent
planning becomes

00:16:15.400 --> 00:16:16.400
harder if you have risk.

00:16:16.400 --> 00:16:18.530
That's what Maya just said.

00:16:18.530 --> 00:16:22.220
People are worried or
stressed or anxious when

00:16:22.220 --> 00:16:24.710
they have lots of uncertainty.

00:16:24.710 --> 00:16:27.160
People might feel regret
over missed opportunity.

00:16:27.160 --> 00:16:30.620
That's like, if I offer you
some insurance right now,

00:16:30.620 --> 00:16:34.340
and you might say, well,
it's actually unlikely

00:16:34.340 --> 00:16:36.363
that anything bad happens.

00:16:36.363 --> 00:16:38.030
But in case something
really bad happens

00:16:38.030 --> 00:16:40.340
and you had the chance to
actually avoid it, then

00:16:40.340 --> 00:16:43.310
you might feel particularly bad
not just because the outcome is

00:16:43.310 --> 00:16:45.230
bad, but because it
offered it to you

00:16:45.230 --> 00:16:47.930
and you didn't accept it.

00:16:47.930 --> 00:16:51.270
There's sort of disappointment
relative to expectations.

00:16:51.270 --> 00:16:54.410
This is essentially getting into
territory of losses and gains.

00:16:54.410 --> 00:16:56.000
When people have
certain expectations,

00:16:56.000 --> 00:16:58.640
they have an expectation to have
a certain income and the like.

00:16:58.640 --> 00:17:01.670
Now, if bad stuff happens, they
fall below those expectations

00:17:01.670 --> 00:17:03.860
and perceive those
outcomes then as losses

00:17:03.860 --> 00:17:08.508
compared to the status quo or
the expectations that they had.

00:17:08.508 --> 00:17:10.550
Again, economists think
about this as diminishing

00:17:10.550 --> 00:17:12.109
marginal utility of wealth.

00:17:12.109 --> 00:17:15.230
That's a very simple
way of modeling this.

00:17:15.230 --> 00:17:18.140
And we're going to see kind of
what the limitations of those

00:17:18.140 --> 00:17:18.770
are.

00:17:18.770 --> 00:17:20.270
Now, I'm going to
show you the three

00:17:20.270 --> 00:17:22.190
stylized facts about the world.

00:17:22.190 --> 00:17:23.690
And then we're going
to discuss kind

00:17:23.690 --> 00:17:25.220
of how to perhaps model that.

00:17:25.220 --> 00:17:27.230
So the first one is
essentially very simple.

00:17:27.230 --> 00:17:31.280
People are risk averse
in various ways.

00:17:31.280 --> 00:17:34.160
And one sort of basic fact
is that lots of people

00:17:34.160 --> 00:17:34.970
buy insurance.

00:17:34.970 --> 00:17:37.310
People are willing to pay
to purchase insurance that

00:17:37.310 --> 00:17:41.030
gives you essentially money
or an expectation less money

00:17:41.030 --> 00:17:42.560
than you pay, right?

00:17:42.560 --> 00:17:44.780
So fair insurance,
as economists would

00:17:44.780 --> 00:17:46.980
model is or think
about it, is to say

00:17:46.980 --> 00:17:49.340
if I purchase insurance
that pays you the expected

00:17:49.340 --> 00:17:51.360
value of the insurance.

00:17:51.360 --> 00:17:53.390
So if I pay a premium
for an insurance,

00:17:53.390 --> 00:17:55.550
there's a probability of
something bad happening

00:17:55.550 --> 00:17:59.480
and then sort of a loss or some
insurance payment that I get

00:17:59.480 --> 00:18:01.340
in case something bad happens.

00:18:01.340 --> 00:18:04.100
Fair insurance would be
the premium is essentially,

00:18:04.100 --> 00:18:11.343
in expectation, the same as the
expectation of the loss, which

00:18:11.343 --> 00:18:13.010
is the probability
of the loss occurring

00:18:13.010 --> 00:18:15.330
and the actual payment that
I get from the insurance.

00:18:15.330 --> 00:18:17.580
Of course, the insurance
industry wants to make money.

00:18:17.580 --> 00:18:20.750
So the insurance industry
will not offer fair insurance,

00:18:20.750 --> 00:18:22.370
but less than fair insurance.

00:18:22.370 --> 00:18:25.290
Essentially, there's a price
for purchasing insurance.

00:18:25.290 --> 00:18:27.290
Lots of people are willing
to pay for insurance.

00:18:27.290 --> 00:18:29.330
People are willing to pay
money to get insurance

00:18:29.330 --> 00:18:31.130
to reduce the risk
or the exposure

00:18:31.130 --> 00:18:32.690
to risks that they have.

00:18:32.690 --> 00:18:35.060
There's social security
in various ways

00:18:35.060 --> 00:18:37.370
where essentially people
sort of insure themselves

00:18:37.370 --> 00:18:41.330
or society insures them for old
age or not being able to take

00:18:41.330 --> 00:18:42.200
care of themselves.

00:18:42.200 --> 00:18:43.760
You could argue
that's perhaps also

00:18:43.760 --> 00:18:47.325
due to present bias or
other paternalistic reasons.

00:18:47.325 --> 00:18:48.950
But surely like
society, in some sense,

00:18:48.950 --> 00:18:51.230
is helping people
insure themselves

00:18:51.230 --> 00:18:56.240
against potential states
of the world where

00:18:56.240 --> 00:18:57.830
they might be in need.

00:18:57.830 --> 00:19:00.270
There's very sort of other--

00:19:00.270 --> 00:19:02.210
sorry-- institutions,
including sort

00:19:02.210 --> 00:19:05.000
of extended families, informal
insurance in developing

00:19:05.000 --> 00:19:07.830
countries, sharecropping,
and so on and so forth.

00:19:07.830 --> 00:19:08.938
What's sharecropping?

00:19:12.010 --> 00:19:12.510
Yes.

00:19:12.510 --> 00:19:17.400
AUDIENCE: When you go multiple
crops at the same time.

00:19:17.400 --> 00:19:18.370
FRANK SCHILBACH: No.

00:19:18.370 --> 00:19:21.150
That's intercropping
or the like,

00:19:21.150 --> 00:19:23.270
but there might be
referred to that as well.

00:19:23.270 --> 00:19:23.770
Yeah.

00:19:23.770 --> 00:19:27.913
AUDIENCE: It's when the person
rents out their land for you

00:19:27.913 --> 00:19:33.048
work on and you get all
the benefits from the land,

00:19:33.048 --> 00:19:36.017
but [? they ?] [INAUDIBLE]
[? rent ?] [INAUDIBLE]..

00:19:36.017 --> 00:19:37.350
FRANK SCHILBACH: Right, exactly.

00:19:37.350 --> 00:19:40.020
So it's essentially these
kinds of arrangement, which

00:19:40.020 --> 00:19:42.270
are often somebody has land.

00:19:42.270 --> 00:19:43.860
Somebody rents out the land.

00:19:43.860 --> 00:19:47.820
And then you have to
pay them something back

00:19:47.820 --> 00:19:49.920
and then can keep some
of the output and so on.

00:19:49.920 --> 00:19:51.900
And often that's
essentially some way

00:19:51.900 --> 00:19:53.725
essentially reducing risk.

00:19:53.725 --> 00:19:55.350
So there's various
sort of institution.

00:19:55.350 --> 00:19:57.902
But broadly speaking, we
think, in many situations,

00:19:57.902 --> 00:19:58.860
people don't like risk.

00:19:58.860 --> 00:20:02.940
And they look for ways to
reduce the exposure to risks.

00:20:02.940 --> 00:20:05.520
There's also these informal
insurance arrangements,

00:20:05.520 --> 00:20:08.615
which are things like
people get together.

00:20:08.615 --> 00:20:09.990
And they sort of
help each other.

00:20:09.990 --> 00:20:13.170
Whenever something bad
happens, one person

00:20:13.170 --> 00:20:15.990
is then being helped
by everybody else.

00:20:15.990 --> 00:20:19.260
And that's sort of replacing
some sort of formula

00:20:19.260 --> 00:20:21.600
for insurance schemes
and particularly

00:20:21.600 --> 00:20:23.220
in developing countries.

00:20:23.220 --> 00:20:26.220
Second, risk reduction
has its price.

00:20:26.220 --> 00:20:29.550
That is to say people are
willing to take on risk

00:20:29.550 --> 00:20:31.518
if the return is high enough.

00:20:31.518 --> 00:20:33.060
So another way to
put this is, if you

00:20:33.060 --> 00:20:36.150
want to purchase insurance,
usually you have to pay for it.

00:20:36.150 --> 00:20:38.190
The insurance industry
makes a lot of money.

00:20:38.190 --> 00:20:43.830
Put differently, people are
willing to take on some risk

00:20:43.830 --> 00:20:45.075
if things get cheaper, right?

00:20:45.075 --> 00:20:46.950
For example, if you
think about buying a car,

00:20:46.950 --> 00:20:48.825
you could buy a super
safe car with all sorts

00:20:48.825 --> 00:20:49.860
of safety features.

00:20:49.860 --> 00:20:50.970
Not everybody does that.

00:20:50.970 --> 00:20:54.510
The reason is because
cheaper cars are less safe.

00:20:54.510 --> 00:20:55.710
Cars are cheaper.

00:20:55.710 --> 00:20:57.210
So you're might
just sort of willing

00:20:57.210 --> 00:21:00.790
to take on some risk in some
situations for some price,

00:21:00.790 --> 00:21:01.290
right?

00:21:01.290 --> 00:21:03.690
When you think about
starting a restaurant,

00:21:03.690 --> 00:21:06.952
restaurants essentially
fail all the time.

00:21:06.952 --> 00:21:08.910
Yet people are always
sort of willing to do it.

00:21:08.910 --> 00:21:12.060
Presumably, the reason is
because if you actually

00:21:12.060 --> 00:21:14.200
succeed, you're going to
make quite a bit of money.

00:21:14.200 --> 00:21:16.020
So if there's a high
expected return,

00:21:16.020 --> 00:21:18.810
people are willing
to take on some risk.

00:21:18.810 --> 00:21:20.740
People put in money
into the stock market,

00:21:20.740 --> 00:21:22.670
so they increase
their risk exposure.

00:21:22.670 --> 00:21:25.170
The reason why they do that is
because, in expectation, they

00:21:25.170 --> 00:21:27.940
make quite a bit of money.

00:21:27.940 --> 00:21:31.298
But of course, that
often entails risk.

00:21:31.298 --> 00:21:33.840
So one way to think about the
entire sort of finance industry

00:21:33.840 --> 00:21:35.280
is risk intermediation.

00:21:35.280 --> 00:21:36.960
Essentially, there
are some businesses

00:21:36.960 --> 00:21:38.590
that have a lot of risk.

00:21:38.590 --> 00:21:42.630
And that risk is sort of
offloaded to investors.

00:21:42.630 --> 00:21:44.370
And the investors
accept that risk.

00:21:44.370 --> 00:21:46.170
They say, I'm willing
to take on that risk,

00:21:46.170 --> 00:21:48.730
but only for a good return.

00:21:48.730 --> 00:21:50.940
So I'm not going to
take on risk from you

00:21:50.940 --> 00:21:52.980
if I'm not, in
expectation, making money.

00:21:52.980 --> 00:21:55.290
But often, essentially,
there's a trade off between.

00:21:55.290 --> 00:21:57.120
And this is-- well, if you've
taken finance classes and so

00:21:57.120 --> 00:21:58.380
on, that's kind of obvious.

00:21:58.380 --> 00:22:01.440
There's a trade between
risk and expected return.

00:22:04.187 --> 00:22:05.770
In what situations
are people actually

00:22:05.770 --> 00:22:10.390
willing to take on risk
for its own sake or just--

00:22:10.390 --> 00:22:11.950
so I told you people
are risk averse.

00:22:11.950 --> 00:22:14.390
And that's true in
most situations.

00:22:14.390 --> 00:22:16.700
But where are people actually
willing to take on risks?

00:22:16.700 --> 00:22:17.020
Yes.

00:22:17.020 --> 00:22:18.346
AUDIENCE: [INAUDIBLE] casino?

00:22:18.346 --> 00:22:19.304
FRANK SCHILBACH: Right.

00:22:19.304 --> 00:22:21.280
Lots of people
actually go to casinos.

00:22:21.280 --> 00:22:26.690
And here, the expected return
is actually a negative.

00:22:26.690 --> 00:22:28.690
You know, you're going
to lose money on average.

00:22:28.690 --> 00:22:32.860
Unless you're sort of a smart
MIT student who can count cards

00:22:32.860 --> 00:22:34.570
in poker or something,
you're going

00:22:34.570 --> 00:22:35.980
to lose money essentially.

00:22:35.980 --> 00:22:39.670
So there must be some form of
some preference or some desire

00:22:39.670 --> 00:22:43.132
to take on risk in some
situations because you cannot

00:22:43.132 --> 00:22:45.340
just-- this is not like
investing in the stock market

00:22:45.340 --> 00:22:47.260
where, on average, you're
going to get money.

00:22:47.260 --> 00:22:49.420
If you go to the
casino, on average

00:22:49.420 --> 00:22:50.660
you're going to lose money.

00:22:50.660 --> 00:22:52.820
Now, you could say it's
so much fun and so on.

00:22:52.820 --> 00:22:54.070
There could also be addiction.

00:22:54.070 --> 00:22:56.290
There could be also
self-control issues and so on.

00:22:56.290 --> 00:22:58.373
Or there could be something
about people's beliefs

00:22:58.373 --> 00:23:00.413
or preferences that induce
them to take on risk.

00:23:00.413 --> 00:23:02.830
But notice that's different
from what we discussed before.

00:23:02.830 --> 00:23:05.500
That's not really consistent
with risk aversion

00:23:05.500 --> 00:23:08.560
because people choose to
increase the risk that they're

00:23:08.560 --> 00:23:09.790
exposed to.

00:23:09.790 --> 00:23:12.025
Any other-- yeah.

00:23:12.025 --> 00:23:13.818
AUDIENCE: Buying
lottery tickets.

00:23:13.818 --> 00:23:14.860
FRANK SCHILBACH: Exactly.

00:23:14.860 --> 00:23:19.810
People are buying lots
of lottery tickets.

00:23:19.810 --> 00:23:22.120
Similar, they're doing
lots of sports betting.

00:23:22.120 --> 00:23:24.970
And again, what you're doing
here is, to be very clear,

00:23:24.970 --> 00:23:26.560
on average you're
going to lose money

00:23:26.560 --> 00:23:30.010
and that you're going to
increase risk or the exposure

00:23:30.010 --> 00:23:30.790
to risk.

00:23:30.790 --> 00:23:33.147
And there's some questions
on why people are doing this.

00:23:33.147 --> 00:23:34.480
We're going to get back to this.

00:23:34.480 --> 00:23:36.188
We're going to not
talk about this today,

00:23:36.188 --> 00:23:37.570
but I sort of want to flag that.

00:23:37.570 --> 00:23:39.400
While people are
risk averse in many,

00:23:39.400 --> 00:23:42.610
in almost, nearly all
situations of the world

00:23:42.610 --> 00:23:44.330
of important choices
that you encounter,

00:23:44.330 --> 00:23:47.650
there are some choices where
people are, in fact, exposing

00:23:47.650 --> 00:23:52.090
themselves to risk in
addition to exposure to risks

00:23:52.090 --> 00:23:55.680
that actually has
high expected value.

00:23:55.680 --> 00:23:56.770
Any questions on this?

00:24:02.960 --> 00:24:03.610
OK.

00:24:03.610 --> 00:24:05.960
So now, we're going to talk
about the expected utility

00:24:05.960 --> 00:24:10.400
and sort of how do economists
think about how should we

00:24:10.400 --> 00:24:10.900
behave.

00:24:10.900 --> 00:24:13.150
And that's a normative model,
how the economists think

00:24:13.150 --> 00:24:16.090
about how people should
behave when it comes

00:24:16.090 --> 00:24:20.080
to choices involving risk.

00:24:20.080 --> 00:24:25.190
So what is expected utility?

00:24:25.190 --> 00:24:26.630
What does the model assume?

00:24:26.630 --> 00:24:28.040
Or what is it about?

00:24:32.750 --> 00:24:33.320
Yeah.

00:24:33.320 --> 00:24:35.830
AUDIENCE: It's the
utility of each state

00:24:35.830 --> 00:24:38.280
of the world multiplied by
the probability of that state

00:24:38.280 --> 00:24:39.647
of the word occurring.

00:24:39.647 --> 00:24:40.980
FRANK SCHILBACH: Right, exactly.

00:24:40.980 --> 00:24:42.610
So the assumption
here is there's

00:24:42.610 --> 00:24:43.860
different states of the world.

00:24:43.860 --> 00:24:45.980
There's good things and
bad things may happen.

00:24:45.980 --> 00:24:47.680
You might get a job.

00:24:47.680 --> 00:24:48.680
You might not get a job.

00:24:48.680 --> 00:24:51.120
You might get a good grade,
bad grade, and so on.

00:24:51.120 --> 00:24:53.390
You can sort of partition
the world or anything

00:24:53.390 --> 00:24:54.890
that's going to
happen in the future

00:24:54.890 --> 00:24:56.360
into different
states of the world.

00:24:56.360 --> 00:25:00.770
We can associate a
utility, so an outcome,

00:25:00.770 --> 00:25:03.680
and an associated utility with
that state of the world, right?

00:25:03.680 --> 00:25:06.060
If you get a good job,
you get a high income.

00:25:06.060 --> 00:25:07.550
And if you don't
get a job, you get

00:25:07.550 --> 00:25:09.230
a low income or
whatever or unemployment

00:25:09.230 --> 00:25:10.890
insurance or whatever.

00:25:10.890 --> 00:25:14.690
And there are certain utilities
associated with these outcomes.

00:25:14.690 --> 00:25:16.555
Expected utility,
now, is essentially

00:25:16.555 --> 00:25:18.680
say, OK, now for each of
these states of the world,

00:25:18.680 --> 00:25:21.110
there's a probability of the
state of the world happening.

00:25:21.110 --> 00:25:23.330
And I'm going to use essentially
the weighted average, which

00:25:23.330 --> 00:25:25.705
essentially is weighting each
state with their associated

00:25:25.705 --> 00:25:29.510
probability and then
using the associated

00:25:29.510 --> 00:25:30.890
utilities for each state.

00:25:30.890 --> 00:25:33.080
And the expectations
of those utilities

00:25:33.080 --> 00:25:35.193
is what's expected utility.

00:25:35.193 --> 00:25:36.360
And that's very complicated.

00:25:36.360 --> 00:25:38.443
I'm going to sort of get
[? to where ?] [? that ?]

00:25:38.443 --> 00:25:40.947
[? is ?] said in more
words than necessary.

00:25:40.947 --> 00:25:42.280
Let me sort of get back to this.

00:25:42.280 --> 00:25:47.980
So first, the thing about
expected monetary value--

00:25:47.980 --> 00:25:49.453
so suppose there's a gamble.

00:25:49.453 --> 00:25:50.870
And this is not a
very simplified.

00:25:50.870 --> 00:25:51.578
There's a gamble.

00:25:51.578 --> 00:25:53.690
I'll call it G over two
states of the world.

00:25:53.690 --> 00:25:57.380
State 1 occurs with probability
p and yields monetary payoff x.

00:25:57.380 --> 00:25:59.810
State 2 occurs with
probability 1 minus p

00:25:59.810 --> 00:26:02.120
and yields monetary payoff y.

00:26:02.120 --> 00:26:04.700
Now, the expected
monetary value--

00:26:04.700 --> 00:26:06.230
now, this is not
expected utility.

00:26:06.230 --> 00:26:07.710
This expected monetary value.

00:26:07.710 --> 00:26:10.640
This is how much money you get
in expectation-- is essentially

00:26:10.640 --> 00:26:12.920
just the weighted average
of those two things sort of

00:26:12.920 --> 00:26:14.870
weighted by the probabilities.

00:26:14.870 --> 00:26:17.138
So that's p times x
plus 1 minus p times y.

00:26:17.138 --> 00:26:19.430
That's just the expected
value of how much money you're

00:26:19.430 --> 00:26:21.470
going to get from this gamble.

00:26:21.470 --> 00:26:24.590
Now, this is just a
definition of fair gamble.

00:26:24.590 --> 00:26:26.570
And this is what economists
tend to use a lot.

00:26:26.570 --> 00:26:29.900
A fair gamble is
one with a price

00:26:29.900 --> 00:26:33.160
equal to its expected
monetary value, right?

00:26:33.160 --> 00:26:37.670
So if I ask you would you
like to take this gamble,

00:26:37.670 --> 00:26:39.813
you're going to ask kind
of, is this a fair gamble?

00:26:39.813 --> 00:26:41.480
Essentially, that's
just asking about is

00:26:41.480 --> 00:26:45.290
it paying the expected value
of this in terms of money.

00:26:45.290 --> 00:26:49.880
I put monetary in parentheses
because I could also provide

00:26:49.880 --> 00:26:51.650
you a fair gamble of apples.

00:26:51.650 --> 00:26:54.890
And then it would just be
the expected value of apples.

00:26:54.890 --> 00:26:58.460
That would be also a
fair gamble potentially.

00:26:58.460 --> 00:27:01.070
Now, what's the expected
utility of this gamble?

00:27:01.070 --> 00:27:03.020
Well, now, you need to
have a utility function

00:27:03.020 --> 00:27:04.650
for each of these outcomes.

00:27:04.650 --> 00:27:06.920
So if my utility
function is u of x,

00:27:06.920 --> 00:27:11.060
this kind of how much utility
I get in the state of actually

00:27:11.060 --> 00:27:13.220
getting x or y.

00:27:13.220 --> 00:27:16.343
So-called xi is where i
is the state of the world.

00:27:16.343 --> 00:27:18.260
So essentially, now,
it's the weighted average

00:27:18.260 --> 00:27:23.180
of p i times u of xi, so in
this case, p times u of x

00:27:23.180 --> 00:27:26.540
plus y minus p times u of y.

00:27:26.540 --> 00:27:28.010
Any questions on this so far?

00:27:36.240 --> 00:27:39.180
And so when you now think
about evaluating gambles

00:27:39.180 --> 00:27:42.420
using an expected utility,
if your utility function

00:27:42.420 --> 00:27:47.197
is linear, then you're
going to essentially decide

00:27:47.197 --> 00:27:49.530
the same way as if you were
just evaluating the expected

00:27:49.530 --> 00:27:52.980
monetary value, right?

00:27:52.980 --> 00:27:55.590
And if not, if the utility
function is concave and convex,

00:27:55.590 --> 00:27:59.070
then essentially people are
potentially risk averse.

00:27:59.070 --> 00:28:03.270
So how economists think
about expected monetary value

00:28:03.270 --> 00:28:05.430
is the history of
that used to be,

00:28:05.430 --> 00:28:07.800
the first theory that
people wrote down was,

00:28:07.800 --> 00:28:10.350
this was a model how people
thought people should behave.

00:28:10.350 --> 00:28:12.808
There was a normative model
that people wrote at some point

00:28:12.808 --> 00:28:16.800
and said, rational
people should essentially

00:28:16.800 --> 00:28:19.530
maximize monetary
payouts, which is

00:28:19.530 --> 00:28:24.600
say, if the expected monetary
value of a certain gamble

00:28:24.600 --> 00:28:25.980
is high, you should accept it.

00:28:25.980 --> 00:28:27.790
Or if it's higher
than its price,

00:28:27.790 --> 00:28:29.760
then you should accept
it, otherwise not.

00:28:29.760 --> 00:28:31.920
Now, it turns out that,
in practice, that's

00:28:31.920 --> 00:28:33.180
not descriptively accurate.

00:28:33.180 --> 00:28:35.370
That's just not how people
behave on the world.

00:28:35.370 --> 00:28:37.350
And in fact, and the
reason being that people

00:28:37.350 --> 00:28:39.210
are risk averse in
most situations.

00:28:42.390 --> 00:28:44.790
When using, now, the expected
monetary value, essentially

00:28:44.790 --> 00:28:46.540
they use the
expected money value

00:28:46.540 --> 00:28:48.790
as a definition for
risk neutrality.

00:28:48.790 --> 00:28:50.790
If somebody is risk
neutral, if somebody doesn't

00:28:50.790 --> 00:28:53.100
care at all about risk
in some situation,

00:28:53.100 --> 00:28:55.650
that person essentially just
is maximizing the expected

00:28:55.650 --> 00:28:57.685
monetary value, right?

00:28:57.685 --> 00:28:59.060
So a decision
maker is-- and this

00:28:59.060 --> 00:29:01.620
is a definition-- is risk
neutral if, for any lottery G,

00:29:01.620 --> 00:29:03.720
she is indifferent
between G and getting

00:29:03.720 --> 00:29:07.140
the expected monetary
value G for sure.

00:29:07.140 --> 00:29:09.660
And so the decision maker is
risk neutral if the utility

00:29:09.660 --> 00:29:12.868
function is linear, OK?

00:29:12.868 --> 00:29:14.910
Essentially, the more
money you get, then there's

00:29:14.910 --> 00:29:18.630
no diminishing marginal
utility of money.

00:29:18.630 --> 00:29:22.480
Now, what's risk aversion then?

00:29:22.480 --> 00:29:25.980
A decision maker is risk
averse if, for any lottery G,

00:29:25.980 --> 00:29:30.810
she prefers getting the expected
monetary value G for sure

00:29:30.810 --> 00:29:33.480
rather than taking
G. And the person

00:29:33.480 --> 00:29:35.940
is risk loving if
the person rather

00:29:35.940 --> 00:29:37.650
has the lottery
than the expected

00:29:37.650 --> 00:29:41.587
monetary value for sure.

00:29:41.587 --> 00:29:42.670
These are just definition.

00:29:42.670 --> 00:29:44.440
That's just the way how
economists think about risk.

00:29:44.440 --> 00:29:45.940
That's just definition,
defining how

00:29:45.940 --> 00:29:50.160
we think about risk aversion
and risk lovingness if you want.

00:29:50.160 --> 00:29:53.700
Now, let me give you just
a very simple example.

00:29:53.700 --> 00:29:58.140
Suppose a person with wealth,
$10,000 is offered a gamble.

00:29:58.140 --> 00:30:01.290
The gamble is you can gain
$500 with a 50% chance

00:30:01.290 --> 00:30:03.750
and lose $400 with a 50% chance.

00:30:03.750 --> 00:30:06.963
Will you accept this gamble?

00:30:06.963 --> 00:30:07.880
How do we do this now?

00:30:14.710 --> 00:30:18.980
Suppose I'm just maximizing
the expected monetary value.

00:30:18.980 --> 00:30:20.860
What am I going to do?

00:30:20.860 --> 00:30:21.646
Yeah.

00:30:21.646 --> 00:30:24.612
AUDIENCE: You take [INAUDIBLE]
something [INAUDIBLE]??

00:30:24.612 --> 00:30:25.570
FRANK SCHILBACH: Right.

00:30:25.570 --> 00:30:27.070
So what I'm going
to do is I'm going

00:30:27.070 --> 00:30:29.950
to just look at what's my
expected monetary value

00:30:29.950 --> 00:30:32.650
of accepting your
lottery, which is

00:30:32.650 --> 00:30:37.960
0.5, which is the probability
of a loss times 9,600.

00:30:37.960 --> 00:30:42.010
This is 10,000 minus the 400
that I lose plus 0.5 times

00:30:42.010 --> 00:30:46.510
10,000 plus 500,
which gives me 10,050.

00:30:46.510 --> 00:30:49.150
If I reject the lottery,
I'm just where I am before.

00:30:49.150 --> 00:30:51.160
Now, the risk neutral
decision maker

00:30:51.160 --> 00:30:54.520
will reject the gamble,
in fact, irrespective

00:30:54.520 --> 00:30:55.540
of the initial wealth.

00:30:55.540 --> 00:30:57.370
Because, essentially,
everything is linear,

00:30:57.370 --> 00:30:58.790
so you just drop out the wealth.

00:30:58.790 --> 00:31:01.270
You can just look at what's
the expected value regardless

00:31:01.270 --> 00:31:02.890
of how much money
the person has.

00:31:02.890 --> 00:31:03.920
AUDIENCE: So you mean
[INAUDIBLE] [? accepting ?]

00:31:03.920 --> 00:31:05.102
[INAUDIBLE]?

00:31:07.603 --> 00:31:08.770
FRANK SCHILBACH: Yes, sorry.

00:31:08.770 --> 00:31:11.600
That's a typo.

00:31:11.600 --> 00:31:12.310
Yes, sorry.

00:31:12.310 --> 00:31:12.920
That's a typo.

00:31:12.920 --> 00:31:14.700
Yes, thank you.

00:31:14.700 --> 00:31:15.200
Yeah.

00:31:15.200 --> 00:31:16.990
So exactly, the
expected monetary value

00:31:16.990 --> 00:31:21.280
is higher than the status
quo, so you accept the gamble.

00:31:21.280 --> 00:31:24.500
And that doesn't depend
on the initial wealth.

00:31:24.500 --> 00:31:25.400
OK.

00:31:25.400 --> 00:31:27.690
So now, what's the expected
utility maximizer do?

00:31:27.690 --> 00:31:30.470
And how does an expected utility
maximizer think about this?

00:31:40.460 --> 00:31:41.788
Yes?

00:31:41.788 --> 00:31:43.580
AUDIENCE: In their
calculation, rather than

00:31:43.580 --> 00:31:47.510
weighting the 9,600
and the 10,500,

00:31:47.510 --> 00:31:49.448
they'll weight
the utility value.

00:31:49.448 --> 00:31:50.490
FRANK SCHILBACH: Exactly.

00:31:50.490 --> 00:31:52.130
So now, we need the
utility function.

00:31:52.130 --> 00:31:56.330
What's the utility of 9,600,
the utility of 10,500,

00:31:56.330 --> 00:31:58.100
and the utility of 10,000?

00:31:58.100 --> 00:32:01.760
Now, will she accept the gamble?

00:32:01.760 --> 00:32:03.200
Well, now, it
depends essentially

00:32:03.200 --> 00:32:04.770
on the utility function.

00:32:04.770 --> 00:32:07.190
What's the shape of that
utility function look like?

00:32:07.190 --> 00:32:08.960
In particular, it
depends on the concavity

00:32:08.960 --> 00:32:10.590
of the utility function.

00:32:10.590 --> 00:32:13.020
So what do I mean by the
concavity of the utility

00:32:13.020 --> 00:32:13.520
function?

00:32:13.520 --> 00:32:15.220
This is concave function.

00:32:15.220 --> 00:32:16.670
What do I mean by that?

00:32:19.350 --> 00:32:20.850
What's the definition?

00:32:20.850 --> 00:32:21.647
Yes.

00:32:21.647 --> 00:32:22.712
AUDIENCE: [INAUDIBLE]

00:32:22.712 --> 00:32:23.670
FRANK SCHILBACH: Right.

00:32:23.670 --> 00:32:25.878
So one definition is a second
derivative is negative.

00:32:25.878 --> 00:32:26.820
That's exactly right.

00:32:26.820 --> 00:32:30.150
That's true if the function
is twice differentiable.

00:32:30.150 --> 00:32:31.860
We have a slightly
different definition

00:32:31.860 --> 00:32:33.930
that's slightly more
general because it doesn't

00:32:33.930 --> 00:32:36.150
depend on differentiability.

00:32:36.150 --> 00:32:39.120
But essentially, it's to say
it's the following definition,

00:32:39.120 --> 00:32:42.000
if the utility of a convex
combination of two outcomes--

00:32:42.000 --> 00:32:43.920
I'm going to tell you
about this in a second--

00:32:43.920 --> 00:32:47.940
is larger than the convex
combination of the utility

00:32:47.940 --> 00:32:49.930
of those outcomes.

00:32:49.930 --> 00:32:50.950
What do I mean by that?

00:32:50.950 --> 00:32:54.000
Suppose you have an outcome
x and a utility associated

00:32:54.000 --> 00:32:56.100
with that that's u of x.

00:32:56.100 --> 00:32:58.290
Suppose you have an
outcome y and a utility

00:32:58.290 --> 00:33:01.630
of u of y associated with that.

00:33:01.630 --> 00:33:04.090
And now, suppose you have a
convex combination of x and y,

00:33:04.090 --> 00:33:09.090
which is just p is a
probability of p times x

00:33:09.090 --> 00:33:10.980
plus 1 minus p times y.

00:33:10.980 --> 00:33:12.690
That's in the middle of x and y.

00:33:12.690 --> 00:33:17.790
So I take a weighted average
of x and y that adds up to 1.

00:33:17.790 --> 00:33:22.020
Now, if I have the utility
associated with that convex

00:33:22.020 --> 00:33:27.370
combination, that's u of
px plus 1 minus p times y.

00:33:27.370 --> 00:33:30.040
That's just the utility
associated with that.

00:33:30.040 --> 00:33:33.390
Now, if I draw a line
between those two graphs

00:33:33.390 --> 00:33:37.110
and look at what's the
convex combination of p,

00:33:37.110 --> 00:33:40.435
so what's p of u of x
plus 1 minus p of u of y?

00:33:40.435 --> 00:33:42.060
That's essentially
the weighted average

00:33:42.060 --> 00:33:45.330
of the utilities
associated with x and y.

00:33:45.330 --> 00:33:48.480
Now, the question
is, is the average

00:33:48.480 --> 00:33:50.200
of the utility of
the average higher

00:33:50.200 --> 00:33:53.218
or lower than the
average of the utilities?

00:33:53.218 --> 00:33:55.510
Can somebody explain this in
words of what I just said?

00:33:55.510 --> 00:33:56.680
Or what do I mean?

00:33:56.680 --> 00:33:58.000
Can somebody repeat this?

00:34:08.690 --> 00:34:09.190
Yes?

00:34:09.190 --> 00:34:11.496
AUDIENCE: I mean, technically,
we're just trying to see if you

00:34:11.496 --> 00:34:13.579
take two points in the
[INAUDIBLE] and draw a line

00:34:13.579 --> 00:34:16.302
between them, would the line
be [? below ?] [? the curve? ?]

00:34:16.302 --> 00:34:17.260
FRANK SCHILBACH: Right.

00:34:17.260 --> 00:34:19.090
Is the line above
or below the curve?

00:34:19.090 --> 00:34:21.460
In this case, the line
is below the curve.

00:34:21.460 --> 00:34:23.860
Now, what that means is,
if I give you two outcomes

00:34:23.860 --> 00:34:25.600
and I say, would
you rather have--

00:34:25.600 --> 00:34:27.610
you could have x and
y, or would you rather

00:34:27.610 --> 00:34:30.940
have the some weighted
average of x and y?

00:34:30.940 --> 00:34:34.120
Now, the question is, what's
the utility associated

00:34:34.120 --> 00:34:36.275
with this average of x and y?

00:34:36.275 --> 00:34:38.650
That's the thing that you see
here on the left upper side

00:34:38.650 --> 00:34:42.219
is u of p of x plus
1 minus p times y.

00:34:42.219 --> 00:34:45.699
That's essentially the utility
of the weighted average.

00:34:45.699 --> 00:34:48.538
Is that larger or smaller
than the weighted average

00:34:48.538 --> 00:34:50.830
of the utility, which is the
thing that I show you here

00:34:50.830 --> 00:34:51.667
below?

00:34:51.667 --> 00:34:53.500
And what you see is,
in this case-- and this

00:34:53.500 --> 00:34:55.540
is because the line is
exactly as I say-- it's

00:34:55.540 --> 00:34:56.830
below the utility function.

00:34:56.830 --> 00:34:59.050
If the line is below the
utility function, that

00:34:59.050 --> 00:35:02.560
means essentially that the
utility of the weighted average

00:35:02.560 --> 00:35:06.220
is higher than the weighted
average of the utilities, which

00:35:06.220 --> 00:35:09.130
means essentially the
function is concave.

00:35:09.130 --> 00:35:11.950
And that means essentially
that the person

00:35:11.950 --> 00:35:13.720
is risk averse, as we call it.

00:35:13.720 --> 00:35:17.020
You'd rather have the average
than the spread of the two

00:35:17.020 --> 00:35:19.370
outcomes.

00:35:19.370 --> 00:35:21.365
Any questions on
this or comments?

00:35:27.650 --> 00:35:28.150
OK.

00:35:28.150 --> 00:35:29.700
So you can look
at this in detail

00:35:29.700 --> 00:35:34.530
but essentially it's
a simple definition.

00:35:34.530 --> 00:35:37.560
So now, expected utility says
essentially the following.

00:35:37.560 --> 00:35:40.350
It says a risk averse person
rejects all fair gambles.

00:35:40.350 --> 00:35:42.650
And again, fair gambles
are gambles that pay you

00:35:42.650 --> 00:35:44.552
the expected monetary value.

00:35:44.552 --> 00:35:46.010
And the reason why
that person does

00:35:46.010 --> 00:35:48.890
that is because the
expected utility

00:35:48.890 --> 00:35:53.840
is lower than the utility of
the expected monetary value.

00:35:53.840 --> 00:35:56.180
Essentially, as
you just said, it's

00:35:56.180 --> 00:36:00.020
because the straight line is
below the utility function.

00:36:00.020 --> 00:36:02.510
And that's essentially exactly
the same definition here.

00:36:02.510 --> 00:36:05.690
Therefore, a risk
averse person who

00:36:05.690 --> 00:36:10.190
has a concave utility function
rejects all fair gambles.

00:36:10.190 --> 00:36:13.380
Now, what does expected
utility theory then say?

00:36:13.380 --> 00:36:17.370
Well, it says risky options are
valued by doing three things.

00:36:17.370 --> 00:36:20.657
One is you have to define
utility over final outcomes.

00:36:20.657 --> 00:36:23.240
And this is sort of getting back
what you were saying earlier.

00:36:23.240 --> 00:36:26.587
People might be worried about
losses or gains or the like.

00:36:26.587 --> 00:36:27.920
We're assuming all of this away.

00:36:27.920 --> 00:36:31.400
We're just saying, their final
outcomes-- how much money you

00:36:31.400 --> 00:36:34.940
have, what grades you have,
how many kids you have,

00:36:34.940 --> 00:36:37.160
and so on, these
are final outcomes,

00:36:37.160 --> 00:36:41.990
things that sort of where an
absolute value is defined.

00:36:41.990 --> 00:36:44.900
There's a utility associated
with those outcomes.

00:36:44.900 --> 00:36:46.910
It's not about you
expected more money

00:36:46.910 --> 00:36:48.200
or less money or the like.

00:36:48.200 --> 00:36:49.718
That's completely irrelevant.

00:36:49.718 --> 00:36:51.260
We're just looking
at final outcomes.

00:36:51.260 --> 00:36:53.177
How much money do you
end up actually getting?

00:36:53.177 --> 00:36:55.575
And we're associating
some utility with that.

00:36:55.575 --> 00:36:57.200
That's assumption
number one, or that's

00:36:57.200 --> 00:36:59.090
the first thing one does.

00:36:59.090 --> 00:37:02.300
Second is you weight these
utilities for each outcomes

00:37:02.300 --> 00:37:03.388
by its probability.

00:37:03.388 --> 00:37:05.180
Essentially, we know
what the probabilities

00:37:05.180 --> 00:37:06.750
are for each of those outcomes.

00:37:06.750 --> 00:37:10.220
We're going to take the weighted
average of these utilities.

00:37:10.220 --> 00:37:13.580
And then we sort
of adding them up.

00:37:13.580 --> 00:37:16.190
And then by adding
them up, essentially we

00:37:16.190 --> 00:37:17.960
can evaluate all
sorts of lotteries.

00:37:17.960 --> 00:37:20.600
And then we just
compare those lotteries

00:37:20.600 --> 00:37:22.310
either with some
fixed amount of money

00:37:22.310 --> 00:37:26.330
or some other lotteries, the
outcomes that we might get.

00:37:26.330 --> 00:37:28.857
Now, there's two key
implicit assumptions

00:37:28.857 --> 00:37:29.940
that are really important.

00:37:29.940 --> 00:37:32.070
One is only final
outcomes matter.

00:37:32.070 --> 00:37:34.100
It doesn't matter what
you expected in advance.

00:37:34.100 --> 00:37:36.142
It doesn't matter what
you thought you might get.

00:37:36.142 --> 00:37:38.250
And it doesn't matter
what you had yesterday.

00:37:38.250 --> 00:37:39.667
All of these things
are completely

00:37:39.667 --> 00:37:42.170
irrelevant in the simplest
form of expected utility

00:37:42.170 --> 00:37:44.420
unless you sort of have
information or the like.

00:37:44.420 --> 00:37:46.310
Only final outcomes matter.

00:37:46.310 --> 00:37:48.530
And then there is linearity
and probabilities.

00:37:48.530 --> 00:37:51.920
That's to say we put weight on
the different types of states

00:37:51.920 --> 00:37:56.360
of the world relative to what
the probability of those states

00:37:56.360 --> 00:37:57.410
are.

00:37:57.410 --> 00:38:00.320
So it cannot be that, if
something is twice as likely,

00:38:00.320 --> 00:38:02.480
you should put twice
as much weight on that

00:38:02.480 --> 00:38:04.400
in your evaluation
of the outcomes.

00:38:04.400 --> 00:38:08.000
It cannot be that this is
non-linear in certain ways.

00:38:08.000 --> 00:38:11.560
There's linearity
in probabilities.

00:38:11.560 --> 00:38:12.580
Any questions on this?

00:38:22.730 --> 00:38:25.670
So now, let me get back
to what I said previously.

00:38:25.670 --> 00:38:27.352
What are we assuming away here?

00:38:27.352 --> 00:38:29.060
What are the things
that are not in here?

00:38:48.370 --> 00:38:48.870
Yeah.

00:38:48.870 --> 00:38:51.698
AUDIENCE: [INAUDIBLE]

00:38:51.698 --> 00:38:52.740
FRANK SCHILBACH: Exactly.

00:38:52.740 --> 00:38:57.010
So essentially, all the other
things that we said previously

00:38:57.010 --> 00:38:58.740
we are assuming away,
for example, things

00:38:58.740 --> 00:39:01.680
like anxiety over certain
outcomes, worries, stress,

00:39:01.680 --> 00:39:02.730
and so on.

00:39:02.730 --> 00:39:05.976
I'm also assuming away regret.

00:39:05.976 --> 00:39:08.035
I'm assuming away
the gains and losses.

00:39:08.035 --> 00:39:09.660
So essentially,
anything we said before

00:39:09.660 --> 00:39:11.190
is essentially
just stripped away

00:39:11.190 --> 00:39:13.470
and simplified in
some sense and saying,

00:39:13.470 --> 00:39:15.840
we can explain a lot
of behaviors just using

00:39:15.840 --> 00:39:18.180
the concavity of the
utility function.

00:39:18.180 --> 00:39:19.758
Now, I have one example for you.

00:39:19.758 --> 00:39:21.300
And I think, I
encourage, you sort of

00:39:21.300 --> 00:39:23.190
for any of these kinds
of assumptions or kind

00:39:23.190 --> 00:39:26.288
of functions or things
that you see in economics,

00:39:26.288 --> 00:39:28.080
it's worth sort of
looking out in the world

00:39:28.080 --> 00:39:30.960
what people are actually
doing and trying to see

00:39:30.960 --> 00:39:33.408
is that actually compatible
with people, with behavior

00:39:33.408 --> 00:39:34.450
that we see in the world.

00:39:34.450 --> 00:39:36.460
And here's sort of one example.

00:39:36.460 --> 00:39:39.780
So I actually don't think
this is irrational behavior.

00:39:39.780 --> 00:39:43.170
And that's actually
a good example of so

00:39:43.170 --> 00:39:46.540
what we might confuse
with irrational behaviors.

00:39:46.540 --> 00:39:51.028
So I guess what we see is
that expected utility has

00:39:51.028 --> 00:39:53.070
a lot of trouble explaining
this behavior, right?

00:39:53.070 --> 00:39:55.770
Because essentially, you spent
like $5 on those lotteries.

00:39:55.770 --> 00:39:57.330
I'm offering you $10.

00:39:57.330 --> 00:39:59.310
So you get twice
as many tickets.

00:39:59.310 --> 00:40:01.570
So your probability of
winning will be twice as high.

00:40:01.570 --> 00:40:04.200
Presumably, you prefer
winning or losing.

00:40:04.200 --> 00:40:06.003
So, therefore, you
should obviously

00:40:06.003 --> 00:40:07.920
take that deal unless
there's some transaction

00:40:07.920 --> 00:40:09.180
costs and the like.

00:40:09.180 --> 00:40:10.950
People are not doing that.

00:40:10.950 --> 00:40:14.010
The main reason that's
mentioned here is regret.

00:40:14.010 --> 00:40:16.140
Now, what the person
was saying here

00:40:16.140 --> 00:40:18.450
is these are perhaps
irrational decisions.

00:40:18.450 --> 00:40:19.950
I actually don't
think that's right.

00:40:19.950 --> 00:40:22.770
Essentially, it's just we cannot
rationalize the decision that

00:40:22.770 --> 00:40:26.670
we see with expected utility
in the sense that it looks like

00:40:26.670 --> 00:40:28.590
the person behaves
in irrational ways,

00:40:28.590 --> 00:40:31.140
but the person may just
have regret aversion,

00:40:31.140 --> 00:40:33.780
something that essentially is
not in the utility function.

00:40:33.780 --> 00:40:35.880
We sort of modeled
it in the wrong way.

00:40:35.880 --> 00:40:37.650
And sort of, by
not capturing this,

00:40:37.650 --> 00:40:39.670
we might miss certain behaviors.

00:40:39.670 --> 00:40:42.090
Now, we're going to talk a lot
about-- not about lotteries

00:40:42.090 --> 00:40:42.450
right now.

00:40:42.450 --> 00:40:44.658
We're going to get back to
this a little bit in terms

00:40:44.658 --> 00:40:47.047
of why people engage in risk.

00:40:47.047 --> 00:40:49.380
But I just want to be clear
on what we're assuming here.

00:40:49.380 --> 00:40:50.838
We're assuming a
lot of stuff away,

00:40:50.838 --> 00:40:54.600
and I want you to
be aware of that.

00:40:54.600 --> 00:40:57.420
There's another
question which actually

00:40:57.420 --> 00:41:01.762
the question or the video did
not sort of try to tackle,

00:41:01.762 --> 00:41:03.720
which is why are people
playing these lotteries

00:41:03.720 --> 00:41:05.070
in the first place.

00:41:05.070 --> 00:41:07.210
Why engage in the lotteries
in the first place?

00:41:07.210 --> 00:41:09.815
In some sense, that
wasn't clear either.

00:41:09.815 --> 00:41:11.440
Again, we're going
to get back to that.

00:41:11.440 --> 00:41:13.977
But the point of the
video was to show you

00:41:13.977 --> 00:41:16.560
that, in some sense, these are
a bunch of assumptions that are

00:41:16.560 --> 00:41:18.205
in the expected utility model.

00:41:18.205 --> 00:41:19.830
Not all of these
assumptions are right.

00:41:19.830 --> 00:41:23.028
And you know, we want to
be sort of aware of that.

00:41:23.028 --> 00:41:25.320
But let me sort of just
summarize what I just told you.

00:41:25.320 --> 00:41:29.650
And this, in some sense, is
recap of 14.01 if you want,

00:41:29.650 --> 00:41:32.310
which I think in part you
also discussed in recitation.

00:41:32.310 --> 00:41:34.470
Or there's like a
handout from 14.01

00:41:34.470 --> 00:41:37.620
that you can look at to
study it in more details.

00:41:37.620 --> 00:41:39.330
So many important
economic choices

00:41:39.330 --> 00:41:43.530
involve risk and people are
risk averse in many contexts.

00:41:43.530 --> 00:41:47.160
The expected utility
model is a workhorse model

00:41:47.160 --> 00:41:50.120
of the economics
for studying risk.

00:41:50.120 --> 00:41:51.870
And the way it's done
is, essentially, one

00:41:51.870 --> 00:41:54.540
takes the weighted average of
utilities from final outcomes.

00:41:54.540 --> 00:41:57.270
That's what matters
for assessing outcomes.

00:41:57.270 --> 00:41:58.033
OK.

00:41:58.033 --> 00:41:59.700
And so, now, we're
going to see, OK, now

00:41:59.700 --> 00:42:01.560
taking that model
very seriously, what

00:42:01.560 --> 00:42:02.430
can be explained?

00:42:02.430 --> 00:42:06.900
And what are perhaps
the limits of doing so?

00:42:06.900 --> 00:42:09.210
And sort of risk
aversion comes solely

00:42:09.210 --> 00:42:13.270
and exclusively from the
concavity of the utility

00:42:13.270 --> 00:42:13.770
function.

00:42:13.770 --> 00:42:16.680
There's no other
reasons to avoid risk.

00:42:16.680 --> 00:42:20.160
Then essentially your
utility function is concave.

00:42:20.160 --> 00:42:20.760
OK.

00:42:20.760 --> 00:42:22.110
So now, how do we measure risk?

00:42:22.110 --> 00:42:23.910
And that's, again,
sort of definitions

00:42:23.910 --> 00:42:25.512
that economists use.

00:42:25.512 --> 00:42:26.970
When you think
about risk aversion,

00:42:26.970 --> 00:42:27.870
how do you measure this?

00:42:27.870 --> 00:42:30.120
Well, you measure it essentially
through the concavity

00:42:30.120 --> 00:42:32.802
of the utility function, which
is, as you were saying earlier,

00:42:32.802 --> 00:42:35.010
it's coming from the second
derivative of the utility

00:42:35.010 --> 00:42:35.820
function.

00:42:35.820 --> 00:42:38.340
There's two main measures
that economists use.

00:42:38.340 --> 00:42:40.860
There's sort of the
absolute or the coefficient

00:42:40.860 --> 00:42:43.830
of absolute risk aversion.

00:42:43.830 --> 00:42:45.570
We call that r.

00:42:45.570 --> 00:42:48.805
It's essentially taking
the second derivative,

00:42:48.805 --> 00:42:49.930
which tends to be negative.

00:42:49.930 --> 00:42:52.770
So we take the negative of that.

00:42:52.770 --> 00:42:54.720
We scale it by the
first derivative.

00:42:54.720 --> 00:42:58.250
That's essentially to
make it insensitive to

00:42:58.250 --> 00:43:01.440
if you multiply the utility
function by a constant.

00:43:01.440 --> 00:43:04.040
Presumably, that doesn't change
anything to your choices.

00:43:04.040 --> 00:43:06.490
So you risk aversion
should not change.

00:43:06.490 --> 00:43:09.900
And, therefore, we sort
of have to normalize

00:43:09.900 --> 00:43:12.920
or we divide by the
first derivative.

00:43:12.920 --> 00:43:15.780
A second version of that,
or an alternative version,

00:43:15.780 --> 00:43:19.440
is the coefficient of
relative risk aversion,

00:43:19.440 --> 00:43:22.620
which essentially is--

00:43:22.620 --> 00:43:23.790
we call it-- gamma.

00:43:23.790 --> 00:43:27.900
Gamma is x, the
wealth outcome that we

00:43:27.900 --> 00:43:32.040
look at times r times the
coefficient of absolute risk

00:43:32.040 --> 00:43:32.850
aversion.

00:43:32.850 --> 00:43:37.980
It's the elasticity of the slope
of the utility function, which

00:43:37.980 --> 00:43:39.150
I've written out here.

00:43:39.150 --> 00:43:41.040
And sort of one very
nice property of this--

00:43:41.040 --> 00:43:42.580
and again, that's a definition.

00:43:42.580 --> 00:43:43.740
There's not much
to argue with this.

00:43:43.740 --> 00:43:45.448
This is just how
economists measure this.

00:43:45.448 --> 00:43:47.320
One nice property
of this is, if you

00:43:47.320 --> 00:43:49.900
look at portfolio
models or the like,

00:43:49.900 --> 00:43:53.920
one implications of constant
relative risk aversion, which

00:43:53.920 --> 00:43:56.140
I'm going to show you
a function of in a bit,

00:43:56.140 --> 00:43:59.008
is that people with constant
relative risk aversion

00:43:59.008 --> 00:44:01.300
invest a constant share of
their wealth in risky assets

00:44:01.300 --> 00:44:03.490
regardless of their
level of wealth.

00:44:03.490 --> 00:44:08.560
That's a main sort of result
from a finance or portfolio

00:44:08.560 --> 00:44:09.880
models.

00:44:09.880 --> 00:44:11.958
In some sense, that's sort
of irrelevant for you.

00:44:11.958 --> 00:44:13.750
These are just definitions
in the sense of,

00:44:13.750 --> 00:44:15.640
if you wanted to
measure risk aversion,

00:44:15.640 --> 00:44:20.400
this is what economists
have used mostly, OK?

00:44:24.370 --> 00:44:26.680
Now, if I give you
this definition,

00:44:26.680 --> 00:44:28.210
how would you
actually measure this?

00:44:28.210 --> 00:44:30.310
If you wanted to know
my risk aversion,

00:44:30.310 --> 00:44:33.590
how would you do that?

00:44:33.590 --> 00:44:37.390
And so let me give you actually
a utility function here.

00:44:37.390 --> 00:44:40.600
So let me give you actually
two utility functions.

00:44:40.600 --> 00:44:42.430
Here's just examples
of one example

00:44:42.430 --> 00:44:46.570
of the constant absolute
risk aversion function

00:44:46.570 --> 00:44:48.130
that you see here.

00:44:48.130 --> 00:44:50.920
Or a Constant Relative
Risk Aversion, CRRA, this

00:44:50.920 --> 00:44:52.398
is what we mostly use.

00:44:52.398 --> 00:44:54.190
So that's just the
definition of a function

00:44:54.190 --> 00:44:56.750
that has the property that
it has constant relative risk

00:44:56.750 --> 00:44:57.250
aversion.

00:44:57.250 --> 00:44:59.500
You can sort of verify that.

00:44:59.500 --> 00:45:02.560
We're going to focus here on
CRRA functions, which are sort

00:45:02.560 --> 00:45:04.760
of what economists mostly use.

00:45:04.760 --> 00:45:07.150
So now, if I told you this
is my utility function,

00:45:07.150 --> 00:45:08.960
my totally function
looks like this,

00:45:08.960 --> 00:45:13.150
now how would you
estimate my risk aversion?

00:45:19.100 --> 00:45:21.728
AUDIENCE: [? I ?] can give
you two gambles and then

00:45:21.728 --> 00:45:23.372
[INAUDIBLE]?

00:45:23.372 --> 00:45:24.330
FRANK SCHILBACH: Right.

00:45:24.330 --> 00:45:27.120
So could you give me
essentially choices

00:45:27.120 --> 00:45:30.660
of outcomes that have
essentially some uncertainty

00:45:30.660 --> 00:45:32.610
or different risk involved.

00:45:32.610 --> 00:45:36.870
And then I'll give
you the choices.

00:45:36.870 --> 00:45:38.590
If I say I prefer
one over the other,

00:45:38.590 --> 00:45:39.840
can you tell what my gamma is?

00:45:45.456 --> 00:45:46.357
AUDIENCE: No.

00:45:46.357 --> 00:45:47.940
FRANK SCHILBACH:
What can you tell me?

00:45:47.940 --> 00:45:48.780
Or what can you say?

00:46:02.145 --> 00:46:05.210
AUDIENCE: I guess you
can say the [? extent, ?]

00:46:05.210 --> 00:46:07.370
but maybe not [INAUDIBLE]
value [INAUDIBLE]..

00:46:07.370 --> 00:46:07.640
FRANK SCHILBACH: Yeah.

00:46:07.640 --> 00:46:09.270
You can put some
bounds on it, right?

00:46:09.270 --> 00:46:10.620
So I'm going to show
you this in a second.

00:46:10.620 --> 00:46:12.080
But essentially,
if I say I prefer

00:46:12.080 --> 00:46:13.740
one option over
the other, you're

00:46:13.740 --> 00:46:15.740
going to have gamma on
the left-hand side, gamma

00:46:15.740 --> 00:46:18.407
on the right-hand side, and give
you some equations, essentially

00:46:18.407 --> 00:46:19.400
some inequality.

00:46:19.400 --> 00:46:22.425
And then if you
solve that equation,

00:46:22.425 --> 00:46:24.050
you're going to get
some bound on gamma

00:46:24.050 --> 00:46:27.350
that sort of essentially
tells you below or above.

00:46:27.350 --> 00:46:29.990
Or my risk aversion
must be below or above

00:46:29.990 --> 00:46:32.210
a certain number.

00:46:32.210 --> 00:46:33.190
What else could we do?

00:46:41.730 --> 00:46:42.230
Yes?

00:46:42.230 --> 00:46:44.200
AUDIENCE: [? Ask ?] [? them ?]
[? when they're ?] [INAUDIBLE]??

00:46:44.200 --> 00:46:44.740
FRANK SCHILBACH: Exactly.

00:46:44.740 --> 00:46:46.810
And that's what's
called the certainty

00:46:46.810 --> 00:46:50.680
or-- so the simplest way of
doing that is to say, here's

00:46:50.680 --> 00:46:53.650
a lottery between
some gains or losses

00:46:53.650 --> 00:46:55.510
or two gains with
certain probabilities.

00:46:55.510 --> 00:46:56.835
There's some risk involved.

00:46:56.835 --> 00:46:58.210
And then we could
ask you, what's

00:46:58.210 --> 00:47:01.360
the amount that makes you
indifferent between receiving

00:47:01.360 --> 00:47:05.167
that amount for sure and the
gamble that I'm offering you?

00:47:05.167 --> 00:47:07.000
Now, that's called the
certainty equivalent.

00:47:07.000 --> 00:47:08.800
Essentially, it's
the amount of money,

00:47:08.800 --> 00:47:12.460
if I have a certain gamble,
what's the amount of money

00:47:12.460 --> 00:47:15.070
that, if you get it for
sure, makes you exactly

00:47:15.070 --> 00:47:18.160
indifferent between that
amount of money for sure

00:47:18.160 --> 00:47:20.890
and the gamble, which
is uncertain, right?

00:47:20.890 --> 00:47:23.080
So if we then had the
certainty equivalent,

00:47:23.080 --> 00:47:24.910
now you could
essentially just back out

00:47:24.910 --> 00:47:29.020
what my gamma is by just
solving for gamma that's there.

00:47:29.020 --> 00:47:31.750
Let me actually show you that.

00:47:31.750 --> 00:47:33.413
There's another thing
that we could do.

00:47:33.413 --> 00:47:34.330
What else could we do?

00:47:34.330 --> 00:47:37.090
So we said, OK, if
you gamble, choices

00:47:37.090 --> 00:47:39.310
between different
gambles, I could ask you

00:47:39.310 --> 00:47:40.720
for certainty equivalent.

00:47:40.720 --> 00:47:43.030
Now, these are all kind
of lab ways of doing this.

00:47:43.030 --> 00:47:44.530
But if you looked
in the real world,

00:47:44.530 --> 00:47:46.180
if you try to sort of
figure out in the real world

00:47:46.180 --> 00:47:47.638
how are people
making these choices

00:47:47.638 --> 00:47:49.990
or choices in the world,
what kinds of choices could

00:47:49.990 --> 00:47:52.960
you observe to figure out
what people's gamma is?

00:47:52.960 --> 00:47:54.460
Yes.

00:47:54.460 --> 00:47:56.627
AUDIENCE: Could you sell
them insurance or an option

00:47:56.627 --> 00:47:58.752
to mitigate their risk and
figure out how much they

00:47:58.752 --> 00:47:59.780
value that mitigation?

00:47:59.780 --> 00:48:00.310
FRANK SCHILBACH: Exactly.

00:48:00.310 --> 00:48:01.000
That's exactly right.

00:48:01.000 --> 00:48:02.917
And that's exactly what
we're going to discuss

00:48:02.917 --> 00:48:04.990
and what people have done.

00:48:04.990 --> 00:48:08.200
Now, it's a little bit
tricky that in usually cases,

00:48:08.200 --> 00:48:11.410
if I just ask you what
insurance have you chosen,

00:48:11.410 --> 00:48:14.110
it's a little tricky to figure
out what your gamma actually

00:48:14.110 --> 00:48:17.050
is because I don't know
what options you had, right?

00:48:17.050 --> 00:48:20.290
So what I need is essentially
a choice set between--

00:48:20.290 --> 00:48:21.810
suppose I'm selling
you insurance.

00:48:21.810 --> 00:48:23.560
In particular, what
I'm going to show you,

00:48:23.560 --> 00:48:25.985
I think, next time is
Justin Sydnor's paper,

00:48:25.985 --> 00:48:27.610
where people can
choose between-- these

00:48:27.610 --> 00:48:30.910
are customers in a certain
home insurance where

00:48:30.910 --> 00:48:33.978
people have choices between
different deductibles, right?

00:48:33.978 --> 00:48:36.520
And now, I can essentially say,
if I choose a high deductible

00:48:36.520 --> 00:48:38.260
versus a low
deductible, essentially

00:48:38.260 --> 00:48:41.140
it's implicitly you're
choosing the risk exposure

00:48:41.140 --> 00:48:42.910
that you have for price.

00:48:42.910 --> 00:48:46.338
So in Sydnor's case, there's
four different options

00:48:46.338 --> 00:48:47.380
that people offer to him.

00:48:47.380 --> 00:48:49.578
That was essentially
both the choice set,

00:48:49.578 --> 00:48:52.120
like what are the choices that
people offered-- in this case,

00:48:52.120 --> 00:48:54.310
I guess they're often
offered four choices--

00:48:54.310 --> 00:48:57.640
and then the actual
choice that they made.

00:48:57.640 --> 00:48:59.660
Again, that's not
going to give you

00:48:59.660 --> 00:49:02.920
an exact gamma in terms of
pinning it down exactly what it

00:49:02.920 --> 00:49:05.290
is because there's four
different inequalities that you

00:49:05.290 --> 00:49:06.880
get from these choices.

00:49:06.880 --> 00:49:09.100
But you can actually
bound, as it turns out,

00:49:09.100 --> 00:49:12.490
people's risk aversion
pretty well using

00:49:12.490 --> 00:49:14.930
those kinds of choices.

00:49:14.930 --> 00:49:15.430
Exactly.

00:49:15.430 --> 00:49:18.040
So that's what we have here is
certain equivalence, choices

00:49:18.040 --> 00:49:20.330
from gambles, and
insurance choices.

00:49:20.330 --> 00:49:23.650
So let's start with
certainty equivalent.

00:49:23.650 --> 00:49:29.350
So suppose your wealth equals
either to $50,000 to $100,000

00:49:29.350 --> 00:49:31.660
each with probability 50%.

00:49:31.660 --> 00:49:34.837
Suppose that's
essentially there's

00:49:34.837 --> 00:49:35.920
lots of risk in your life.

00:49:35.920 --> 00:49:38.890
Either it's 50,000,
100,000, starting

00:49:38.890 --> 00:49:40.570
tomorrow you're
going to find out

00:49:40.570 --> 00:49:42.250
the chance of that is 50% each.

00:49:42.250 --> 00:49:43.750
Now, of course,
that's hypothetical,

00:49:43.750 --> 00:49:46.330
but let's suppose
that for a second.

00:49:46.330 --> 00:49:49.970
You're expected wealth
then, of course, is 75,000.

00:49:49.970 --> 00:49:52.660
Now, what guaranteed amount,
the certainty equivalent,

00:49:52.660 --> 00:49:56.000
of the WCE do you find
equally desirable?

00:49:56.000 --> 00:49:57.850
If I could make all
of your risk go away

00:49:57.850 --> 00:49:59.642
and just say I'm giving
you a fixed amount,

00:49:59.642 --> 00:50:01.730
what amount would you choose?

00:50:01.730 --> 00:50:11.070
Now, when you do
that, essentially,

00:50:11.070 --> 00:50:14.517
if you give me an amount
W, a certain equivalent,

00:50:14.517 --> 00:50:16.350
that gives me essentially
an equation, which

00:50:16.350 --> 00:50:18.270
is the utility from the
certainty equivalent,

00:50:18.270 --> 00:50:22.380
by definition, since
you just told me that,

00:50:22.380 --> 00:50:24.420
must be the same as
the weighted average

00:50:24.420 --> 00:50:26.315
of the utility of 50,000
and the ultimately

00:50:26.315 --> 00:50:30.420
of 100,000 with probability
50% each, right?

00:50:30.420 --> 00:50:32.940
And once you do that, now you
get essentially some nonlinear

00:50:32.940 --> 00:50:37.230
equation that depends on
gamma that you can solve.

00:50:37.230 --> 00:50:42.060
Perhaps not in closed form,
but you can essentially

00:50:42.060 --> 00:50:47.660
figure out what the answer is
in Mathematica or the like, OK?

00:50:47.660 --> 00:50:53.990
Now, as it turns out, now
you can solve for this.

00:50:53.990 --> 00:50:57.310
And the implied values of gamma
I've written down for here.

00:50:57.310 --> 00:51:02.765
So if you tell me here
70,000, gamma is 1.

00:51:02.765 --> 00:51:04.920
If you tell me 66,000, it's 2.

00:51:04.920 --> 00:51:06.190
58,000, it's 5.

00:51:06.190 --> 00:51:08.330
53,000, it's 10.

00:51:08.330 --> 00:51:13.040
51,000, it's 30.

00:51:13.040 --> 00:51:15.020
Who would say anything below 10?

00:51:24.810 --> 00:51:27.508
Yes, no?

00:51:27.508 --> 00:51:28.300
What would you say?

00:51:28.300 --> 00:51:30.430
AUDIENCE: By below,
you mean less than 10?

00:51:30.430 --> 00:51:32.728
FRANK SCHILBACH: So value
of gamma less than 10, yes.

00:51:32.728 --> 00:51:33.770
AUDIENCE: Yeah, for sure.

00:51:33.770 --> 00:51:35.062
FRANK SCHILBACH: Yes, for sure.

00:51:35.062 --> 00:51:38.140
That seems very reasonable.

00:51:38.140 --> 00:51:43.450
If you think about value of
30, if you had a value of 30,

00:51:43.450 --> 00:51:46.073
you probably would not leave
the house ever in some sense.

00:51:46.073 --> 00:51:47.740
You would not come
to class or something

00:51:47.740 --> 00:51:49.780
because you're worried
about some stuff falling

00:51:49.780 --> 00:51:51.610
on your head or the like.

00:51:51.610 --> 00:51:55.150
Because, again, let me show
you what the lottery was.

00:51:55.150 --> 00:52:00.340
The lottery was between 50,000
100,000 with 50% chance.

00:52:00.340 --> 00:52:02.290
If you tell me you're
indifferent between that

00:52:02.290 --> 00:52:05.170
and 51,000 for sure,
you're essentially

00:52:05.170 --> 00:52:09.730
valuing this small increment
coming from 50,000 to 51,209.

00:52:09.730 --> 00:52:12.790
That's $1,209.

00:52:12.790 --> 00:52:17.260
You value that a lot
compared to the 50% chance

00:52:17.260 --> 00:52:21.310
of actually getting $100,000.

00:52:21.310 --> 00:52:24.580
So we sort of think that, when
looking at these large scale

00:52:24.580 --> 00:52:26.710
choices, economists
often assume, I think,

00:52:26.710 --> 00:52:30.880
that people's gamma is
somewhere between 0 and 2, OK?

00:52:30.880 --> 00:52:33.370
So somewhere maybe
70,000, maybe even

00:52:33.370 --> 00:52:35.737
lower than that,
maybe 66,000, these

00:52:35.737 --> 00:52:38.320
are sort of reasonable choices
that we think people are making

00:52:38.320 --> 00:52:41.920
or you see people
making in their lives.

00:52:41.920 --> 00:52:44.695
Anything above that seems
like it's just not right

00:52:44.695 --> 00:52:46.570
because, in some sense,
that's not how people

00:52:46.570 --> 00:52:48.010
behave in the real world.

00:52:48.010 --> 00:52:50.950
People are comfortable with at
least some risk in their life

00:52:50.950 --> 00:52:52.430
when you look at them.

00:52:52.430 --> 00:52:55.030
So the broad lesson is that
choices involving large scale

00:52:55.030 --> 00:53:01.930
risk suggests that gamma
can't be too large, OK?

00:53:04.860 --> 00:53:06.030
Now, second we can say--

00:53:06.030 --> 00:53:08.388
OK, so those are
large scale choices.

00:53:08.388 --> 00:53:10.680
Now, we're going to look at
sort of small scale choices

00:53:10.680 --> 00:53:15.450
using small gambles as
[? Deckson ?] was just

00:53:15.450 --> 00:53:16.500
alluding to.

00:53:16.500 --> 00:53:19.890
So here's a choice involving
a small scale gamble.

00:53:19.890 --> 00:53:26.280
What if you had a 50-50 bet
to win $11 and lose $10?

00:53:26.280 --> 00:53:27.420
Who would take that bet?

00:53:33.900 --> 00:53:36.580
Who would not take it?

00:53:36.580 --> 00:53:37.210
OK.

00:53:37.210 --> 00:53:41.860
So suppose you know there's a
question kind of like, follow

00:53:41.860 --> 00:53:46.210
those questions, now,
since your utility is not

00:53:46.210 --> 00:53:48.940
necessarily linear, we need
to know what your wealth is.

00:53:48.940 --> 00:53:50.650
Suppose it's 20,000,
but you can choose

00:53:50.650 --> 00:53:52.120
all sorts of other numbers.

00:53:52.120 --> 00:53:54.920
And you turn down a
50-50 bet to win--

00:53:54.920 --> 00:53:56.930
this is 110 and lose 100.

00:53:56.930 --> 00:53:59.170
You could do this for
11 and 10 as well.

00:53:59.170 --> 00:54:02.410
What can we learn
now about your gamma?

00:54:02.410 --> 00:54:04.150
And this is what I
was saying earlier.

00:54:04.150 --> 00:54:06.370
Now, it's essentially, if
you turn down this bet,

00:54:06.370 --> 00:54:09.700
it must be that having 20,000,
which is the status quo if you

00:54:09.700 --> 00:54:11.770
turn down the bet,
the utility of that

00:54:11.770 --> 00:54:19.810
is larger than 50% of 20,000
plus 110 plus 0.5 times

00:54:19.810 --> 00:54:21.880
the utility of 20,000 minus 100.

00:54:21.880 --> 00:54:25.690
And again, I can sort of then
plug in the utility function

00:54:25.690 --> 00:54:28.240
and essentially solve for gamma.

00:54:28.240 --> 00:54:31.330
Now, if you solve for gamma--

00:54:31.330 --> 00:54:34.330
and some of the
next problem set is

00:54:34.330 --> 00:54:36.640
doing some of that--
is essentially

00:54:36.640 --> 00:54:41.980
rejecting this bet is implying
that gamma is larger than 18.

00:54:41.980 --> 00:54:44.260
Now, 18 is actually
not that large.

00:54:44.260 --> 00:54:46.660
But surely, 18 is larger than 2.

00:54:46.660 --> 00:54:48.910
And we just sort of
agreed earlier on

00:54:48.910 --> 00:54:51.520
that gamma should be
somewhere below 10,

00:54:51.520 --> 00:54:55.120
presumably somewhere
around 2 or maybe 1.

00:54:55.120 --> 00:54:57.580
So what we get here now is,
when you look at large scale

00:54:57.580 --> 00:55:00.040
choices, it looks
like people's gamma is

00:55:00.040 --> 00:55:04.390
somewhere between 0 and 2,
perhaps below 5 or something,

00:55:04.390 --> 00:55:06.010
but surely not above 10.

00:55:06.010 --> 00:55:08.290
When you look at small
scale choices that

00:55:08.290 --> 00:55:10.100
seem pretty reasonable--
and many of you

00:55:10.100 --> 00:55:14.017
seem to agree that you might
not want to take certain bets.

00:55:14.017 --> 00:55:15.850
Maybe you're credit
constrained or the like.

00:55:15.850 --> 00:55:20.000
But in any case, it looks like
people's gamma is really large.

00:55:20.000 --> 00:55:20.500
OK.

00:55:20.500 --> 00:55:22.125
And so, now, the
question is, how do we

00:55:22.125 --> 00:55:23.290
sort of reconcile this?

00:55:23.290 --> 00:55:27.790
How do we put these
things together?

00:55:27.790 --> 00:55:31.900
Now, Matthew Rabin has written a
paper of this and sort of says,

00:55:31.900 --> 00:55:35.200
this is not just sort of
an intuitive argument.

00:55:35.200 --> 00:55:38.050
This is a paper in
Econometrica from 2000.

00:55:38.050 --> 00:55:41.710
But in fact, he sort
of proves that, when

00:55:41.710 --> 00:55:44.920
people reject small
scale gambles, that just

00:55:44.920 --> 00:55:48.640
sort of implies crazy stuff
for large scale choices,

00:55:48.640 --> 00:55:51.760
essentially stuff that just
seems completely implausible.

00:55:51.760 --> 00:55:53.980
And essentially, he,
under minimal assumptions,

00:55:53.980 --> 00:55:58.700
proves that this doesn't
make a lot of sense.

00:55:58.700 --> 00:56:01.870
Now, what do I mean by this is
and what do we learn from this

00:56:01.870 --> 00:56:04.210
is that essentially the
marginal utility of money

00:56:04.210 --> 00:56:08.890
must decrease extremely
rapidly if you sort of take

00:56:08.890 --> 00:56:11.500
this model seriously.

00:56:11.500 --> 00:56:13.990
He does this under new
assumptions about the utility

00:56:13.990 --> 00:56:14.490
function.

00:56:14.490 --> 00:56:16.115
So it's not just
something special case

00:56:16.115 --> 00:56:17.830
that he sort of
doctored together

00:56:17.830 --> 00:56:20.560
with some special assumptions
of the utility function.

00:56:20.560 --> 00:56:22.570
The only thing, in
fact, that he's assuming

00:56:22.570 --> 00:56:28.580
is that the utility
function is weakly concave.

00:56:28.580 --> 00:56:29.080
OK.

00:56:29.080 --> 00:56:33.880
And so here's the example
that was also in your reading.

00:56:33.880 --> 00:56:37.180
Suppose there's Johnny, who
is a risk averse expected

00:56:37.180 --> 00:56:39.340
utility maximizer
where the utility

00:56:39.340 --> 00:56:41.380
function or the
second derivative

00:56:41.380 --> 00:56:43.960
is smaller or equal
than 0, meaning

00:56:43.960 --> 00:56:48.070
that essentially his utility
function is weakly concave.

00:56:48.070 --> 00:56:52.960
Suppose that person turns down
a 50-50 gamble of losing $10

00:56:52.960 --> 00:56:55.833
and gaining $11 for
any level of wealth.

00:56:55.833 --> 00:56:58.000
That assumption at the end,
for any level of wealth,

00:56:58.000 --> 00:57:00.800
is kind of important, but
actually not that important.

00:57:00.800 --> 00:57:03.430
You can sort of
relax that as well.

00:57:03.430 --> 00:57:06.430
For our purposes, we can
sort of mostly ignore it.

00:57:06.430 --> 00:57:08.710
Now, what's the
biggest Y such that we

00:57:08.710 --> 00:57:14.590
know Johnny will turn down a
50-50, lose 100, win Y bet?

00:57:14.590 --> 00:57:16.210
So here are the answers.

00:57:16.210 --> 00:57:20.372
And what's the correct answer?

00:57:20.372 --> 00:57:22.300
AUDIENCE: G.

00:57:22.300 --> 00:57:25.570
FRANK SCHILBACH:
G. And why is that?

00:57:25.570 --> 00:57:30.350
Or can somebody explain
what's going on?

00:57:34.970 --> 00:57:35.470
Yes.

00:57:39.710 --> 00:57:41.710
AUDIENCE: Is it
because he will reject

00:57:41.710 --> 00:57:43.290
this bet for any
level of wealth,

00:57:43.290 --> 00:57:48.260
so that kind of
implies that he's not

00:57:48.260 --> 00:57:50.413
able to accept
any level of risk?

00:57:50.413 --> 00:57:51.580
FRANK SCHILBACH: No, no, no.

00:57:51.580 --> 00:57:54.130
I think that's just because,
for the iteration forward

00:57:54.130 --> 00:57:57.010
in the proof of
the thing, he needs

00:57:57.010 --> 00:57:59.420
to sort make that argument.

00:57:59.420 --> 00:58:01.400
But in fact, that's
not essential.

00:58:01.400 --> 00:58:03.130
There's some
restrictions to that.

00:58:03.130 --> 00:58:05.620
You can prove the same
thing maybe not as

00:58:05.620 --> 00:58:07.838
stark in terms of a
result, but this is just

00:58:07.838 --> 00:58:09.130
because he's iterating forward.

00:58:09.130 --> 00:58:10.713
He needs to sort of
prove the sequence

00:58:10.713 --> 00:58:13.350
of utilities that derives.

00:58:13.350 --> 00:58:15.100
But it's actually not
necessarily central.

00:58:21.000 --> 00:58:21.870
Yes.

00:58:21.870 --> 00:58:26.073
AUDIENCE: I think the paper
argued that Johnny [INAUDIBLE]

00:58:26.073 --> 00:58:30.248
implied that the [INAUDIBLE]
[? utility ?] [INAUDIBLE] very

00:58:30.248 --> 00:58:32.658
[? rapidly decreasing, ?]
[? which means that ?] between

00:58:32.658 --> 00:58:36.915
that he will [INAUDIBLE].

00:58:36.915 --> 00:58:37.790
FRANK SCHILBACH: Yes.

00:58:37.790 --> 00:58:39.470
So what's happening
here is that--

00:58:41.990 --> 00:58:43.910
so let's sort of
start very simply.

00:58:43.910 --> 00:58:47.260
Let's start with
Johnny's first choice

00:58:47.260 --> 00:58:51.280
that says he rejects the
bet, which means essentially

00:58:51.280 --> 00:58:53.800
on the right-hand side
is utility of status quo,

00:58:53.800 --> 00:58:55.840
essentially just utility if w.

00:58:55.840 --> 00:58:58.735
On the left-hand side is
50% chance of winning $11

00:58:58.735 --> 00:59:02.020
and 50% chance of losing $10.

00:59:02.020 --> 00:59:04.660
Now, you can sort
of multiply this

00:59:04.660 --> 00:59:08.860
by 2 and rearrange, which
gives you the second line.

00:59:08.860 --> 00:59:11.800
Essentially, that says that
the increase in utility going

00:59:11.800 --> 00:59:17.110
from w to w plus 11 is smaller
than the increase in utility

00:59:17.110 --> 00:59:22.280
going from w minus 10 to w.

00:59:22.280 --> 00:59:25.390
OK, that's just the left-hand
side and the right-hand side.

00:59:25.390 --> 00:59:28.550
I'm just rearranging terms.

00:59:28.550 --> 00:59:30.490
So what that means
is that, again,

00:59:30.490 --> 00:59:31.990
like on the left-hand
side, how much

00:59:31.990 --> 00:59:36.520
does the utility increase
if I go from w to w plus 11?

00:59:36.520 --> 00:59:39.880
Essentially, if I add
$11 from coming from w,

00:59:39.880 --> 00:59:45.670
that utility that he values by
at most 10/11-- so each dollar

00:59:45.670 --> 00:59:47.620
that he gets on
the left-hand side

00:59:47.620 --> 00:59:51.400
is valued at most 10/11 as
much as the dollars between w

00:59:51.400 --> 00:59:54.010
minus 10 and w, right?

00:59:54.010 --> 00:59:57.558
So if you have $10 on the
right, $11 on the left,

00:59:57.558 --> 01:00:00.100
you prefer the right-hand side
over the left-hand side, which

01:00:00.100 --> 01:00:04.480
means each dollar must be valued
more on the right-hand side.

01:00:04.480 --> 01:00:06.770
Put differently, the dollars
on the left-hand side,

01:00:06.770 --> 01:00:10.850
that value is 10/11 of the
dollars on the right-hand side,

01:00:10.850 --> 01:00:11.960
OK?

01:00:11.960 --> 01:00:14.720
So just to repeat again,
on the right-hand side,

01:00:14.720 --> 01:00:16.250
we're adding $10.

01:00:16.250 --> 01:00:19.640
On the left-hand side,
we are adding $11

01:00:19.640 --> 01:00:22.830
or subtracting-- we're
adding $11 on left-hand side

01:00:22.830 --> 01:00:25.520
and we're subtracting $10
and the right-hand side.

01:00:25.520 --> 01:00:28.670
Now, since you prefer
the thing or the thing

01:00:28.670 --> 01:00:30.260
on the right-hand
side is larger,

01:00:30.260 --> 01:00:32.600
that must mean that each
dollar on the right-hand side

01:00:32.600 --> 01:00:33.680
is worth more.

01:00:33.680 --> 01:00:37.202
It's 11/10 compared to the
dollars on the left-hand side.

01:00:37.202 --> 01:00:39.410
Or put differently, each
dollar on the left-hand side

01:00:39.410 --> 01:00:43.500
has value 10/11 of each
dollar on the right-hand side.

01:00:43.500 --> 01:00:45.000
You can sort think
about this a bit.

01:00:45.000 --> 01:00:47.440
But trust me, that is correct.

01:00:47.440 --> 01:00:50.280
Now, there's diminishing
marginal utility.

01:00:50.280 --> 01:00:52.050
Essentially,
concavity sort of says

01:00:52.050 --> 01:00:55.140
that the marginal
dollar at w minus 10

01:00:55.140 --> 01:00:58.330
is at least as valuable as
the marginal dollar at w.

01:00:58.330 --> 01:01:02.910
That's essentially just simple
assumption of concavity,

01:01:02.910 --> 01:01:06.430
essentially just saying, there's
diminishing marginal utility.

01:01:06.430 --> 01:01:09.360
So the lower the amount
of wealth that you have,

01:01:09.360 --> 01:01:13.470
the weakly larger the
marginal utility is.

01:01:13.470 --> 01:01:16.050
So the marginal
utility at w minus 10

01:01:16.050 --> 01:01:19.710
is at least as large as
the marginal utility at w.

01:01:19.710 --> 01:01:21.570
And that marginal
utility for dollar

01:01:21.570 --> 01:01:26.850
is at least as valuable as the
marginal utility at w plus 11.

01:01:26.850 --> 01:01:29.400
Now, sort of taken
together, that means

01:01:29.400 --> 01:01:34.470
that Johnny values $1 at w
plus 11 by, at most, 10/11 as

01:01:34.470 --> 01:01:39.000
much as he values the
dollars at w minus 10.

01:01:39.000 --> 01:01:41.670
What does that mean is that
if you go from minus 10

01:01:41.670 --> 01:01:46.650
to a plus 11 essentially the
marginal dollar that you get

01:01:46.650 --> 01:01:51.420
is worth 10 11th as
much for every $21

01:01:51.420 --> 01:01:53.880
that he increases his Wilson.

01:01:58.210 --> 01:02:04.540
So I think, given some of
the confused faces I see,

01:02:04.540 --> 01:02:06.940
we might do some of
this in recitation.

01:02:06.940 --> 01:02:10.150
But this is essentially
simple algebra and using

01:02:10.150 --> 01:02:13.730
the minimal assumptions
that I made.

01:02:13.730 --> 01:02:15.190
Now, you can do
the same thing as

01:02:15.190 --> 01:02:17.203
like if the person
were $21 richer.

01:02:17.203 --> 01:02:19.120
So essentially, now, I'm
doing the same thing,

01:02:19.120 --> 01:02:22.330
just adding $21 on each side.

01:02:22.330 --> 01:02:24.070
I'm doing the exact same thing.

01:02:24.070 --> 01:02:28.420
And I'm going to get essentially
the exact same thing.

01:02:28.420 --> 01:02:32.890
It's essentially saying that he
values each dollar that he gets

01:02:32.890 --> 01:02:38.110
at w plus $32 by, at most, 10/11
to the power of 2 5/6 as much

01:02:38.110 --> 01:02:40.928
as he values the
dollars at w minus 10.

01:02:40.928 --> 01:02:43.220
So what I'm essentially doing
is I'm iterating forward.

01:02:43.220 --> 01:02:45.940
So I know the utility
function is concave by sort

01:02:45.940 --> 01:02:47.020
of your first choice.

01:02:47.020 --> 01:02:49.030
I know that essentially
[INAUDIBLE] utility

01:02:49.030 --> 01:02:51.982
is declining going on one side.

01:02:51.982 --> 01:02:54.190
So now, essentially taking
this forward-- essentially

01:02:54.190 --> 01:02:59.080
saying, well, for every $21,
you value each dollar by 10/11

01:02:59.080 --> 01:02:59.860
as much.

01:02:59.860 --> 01:03:01.360
So now, I'm saying,
well, if you had

01:03:01.360 --> 01:03:07.090
$21 plus $21 is $42
plus $29 is $63,

01:03:07.090 --> 01:03:09.620
your marginal utility must
be really declining very,

01:03:09.620 --> 01:03:11.060
very rapidly.

01:03:11.060 --> 01:03:14.380
So once you have a lot more
money, then essentially you

01:03:14.380 --> 01:03:17.500
just don't care at all about any
marginal dollar that you get.

01:03:17.500 --> 01:03:21.640
So you can do this by if
the person was $42 richer.

01:03:21.640 --> 01:03:24.470
Essentially, you'd care about
each dollar 5/6 as much.

01:03:24.470 --> 01:03:27.830
If it's $420, you care
about it 3/20 as much.

01:03:27.830 --> 01:03:30.580
And if you were $840
richer, you care about it

01:03:30.580 --> 01:03:32.480
only 2/100 as much.

01:03:32.480 --> 01:03:34.480
Essentially, that's to
say-- and this is exactly

01:03:34.480 --> 01:03:36.188
as you were saying--
the marginal utility

01:03:36.188 --> 01:03:38.950
plummets for substantial
changes in lifetime wealth.

01:03:38.950 --> 01:03:42.430
So you care less than 2%
about an additional dollar

01:03:42.430 --> 01:03:48.250
when you are $900 richer
than you are right now.

01:03:48.250 --> 01:03:51.730
That doesn't feel right,
but essentially it's

01:03:51.730 --> 01:03:55.840
a simple implication of
what was just assumed.

01:03:55.840 --> 01:03:56.890
There's no magic here.

01:03:56.890 --> 01:03:59.830
This is very simple
algebra and using

01:03:59.830 --> 01:04:01.930
very simple minor assumptions.

01:04:01.930 --> 01:04:04.660
But essentially, it's saying, if
this person rejects this gamble

01:04:04.660 --> 01:04:07.570
as we just had, it follows--

01:04:07.570 --> 01:04:10.090
and there's sort of complicated
proofs in the paper.

01:04:10.090 --> 01:04:11.800
But it follows
that, essentially,

01:04:11.800 --> 01:04:17.080
the additional for, if you
give the person $900 more,

01:04:17.080 --> 01:04:19.630
the person values
each dollar only 2%

01:04:19.630 --> 01:04:24.370
as much as when the
person is $900 richer.

01:04:24.370 --> 01:04:27.130
And so then you look
at these consequences.

01:04:27.130 --> 01:04:29.140
And you can read this
in the Rabin and Thaler

01:04:29.140 --> 01:04:32.560
paper or the original
Rabin paper if you like.

01:04:32.560 --> 01:04:35.943
Essentially, you get
these absurd conclusions.

01:04:35.943 --> 01:04:37.360
If you look at the
left-hand side,

01:04:37.360 --> 01:04:40.150
these are sort of like if an
expected utility maximizer

01:04:40.150 --> 01:04:42.010
always turns down certain bets.

01:04:42.010 --> 01:04:43.840
On the left-hand
side, it follows

01:04:43.840 --> 01:04:47.770
that he also turns on the
bets on the right-hand side.

01:04:47.770 --> 01:04:51.890
And we think, you
know, for example,

01:04:51.890 --> 01:04:54.820
if I told you losing
$10 or gaining

01:04:54.820 --> 01:04:57.280
$11, that seems like
a reasonable thing

01:04:57.280 --> 01:04:58.330
to reject perhaps.

01:04:58.330 --> 01:05:00.520
That seems like a thing
that one might do.

01:05:00.520 --> 01:05:03.500
At least, you guys were
saying that you might do that.

01:05:03.500 --> 01:05:05.080
Well, if that's
the case, then you

01:05:05.080 --> 01:05:11.620
should also accept or reject
the gamble of losing $100

01:05:11.620 --> 01:05:14.080
and gaining infinite
amount of dollars.

01:05:14.080 --> 01:05:17.170
And that seems obviously absurd.

01:05:17.170 --> 01:05:22.030
And so that can't
be really true.

01:05:22.030 --> 01:05:25.300
Now, what's going
on here essentially

01:05:25.300 --> 01:05:28.540
is to say is that the
utility function, as it

01:05:28.540 --> 01:05:32.200
is an expected utility,
has trouble reconciling

01:05:32.200 --> 01:05:35.650
people's small scale choices
and large scale choices.

01:05:35.650 --> 01:05:37.690
And it's similar to
what we talked about,

01:05:37.690 --> 01:05:39.370
like exponential discounting.

01:05:39.370 --> 01:05:41.410
We only have one
parameter here, which

01:05:41.410 --> 01:05:44.350
is gamma for both
gains and losses

01:05:44.350 --> 01:05:46.150
and for all sorts of scales.

01:05:46.150 --> 01:05:49.570
And that parameter is just not
able to fit people's choices

01:05:49.570 --> 01:05:50.560
in sensible ways.

01:05:50.560 --> 01:05:52.810
It seems to be people
have small scale risk

01:05:52.810 --> 01:05:54.410
aversion in some sense.

01:05:54.410 --> 01:05:58.540
And it seems to be people are
not incredibly risk averse

01:05:58.540 --> 01:06:00.490
for large amounts of money.

01:06:00.490 --> 01:06:04.180
And so, now, the expected
utility model cannot match both

01:06:04.180 --> 01:06:06.430
of those things.

01:06:06.430 --> 01:06:11.050
That's essentially what
the Rabin paper does.

01:06:11.050 --> 01:06:16.270
We'll talk about this in some
slower reform in recitation

01:06:16.270 --> 01:06:17.680
to sort of go over this.

01:06:17.680 --> 01:06:19.690
But in some sense, the
important part here

01:06:19.690 --> 01:06:21.550
is to understand the intuition.

01:06:21.550 --> 01:06:24.310
And intuition, essentially,
is that, if there's

01:06:24.310 --> 01:06:28.270
curvature over very small scales
or over very small stakes,

01:06:28.270 --> 01:06:30.940
it must be there's lots
of curvature going forward

01:06:30.940 --> 01:06:32.200
over large scales.

01:06:32.200 --> 01:06:34.130
And that's just not plausible.

01:06:34.130 --> 01:06:36.130
Because, essentially,
then people would just not

01:06:36.130 --> 01:06:39.400
value really, really
large amounts.

01:06:39.400 --> 01:06:44.380
And we know that people do value
money at least to some extent.

01:06:44.380 --> 01:06:47.200
Any questions on this overall?

01:06:52.470 --> 01:06:53.752
Yeah.

01:06:53.752 --> 01:06:57.810
AUDIENCE: [INAUDIBLE] I guess
[INAUDIBLE] [? mimicked ?]

01:06:57.810 --> 01:06:59.850
the [INAUDIBLE].

01:06:59.850 --> 01:07:02.783
I guess, does the [INAUDIBLE]
hyperbolic model essentially

01:07:02.783 --> 01:07:05.800
almost [? work ?]
[? here ?] where [INAUDIBLE]

01:07:05.800 --> 01:07:11.420
to [INAUDIBLE] singular
[INAUDIBLE] if someone tried

01:07:11.420 --> 01:07:15.210
to do the long-term,
short-term thing, [INAUDIBLE]..

01:07:15.210 --> 01:07:16.560
FRANK SCHILBACH: Yeah.

01:07:16.560 --> 01:07:18.690
So what we're going
to do is-- so notice

01:07:18.690 --> 01:07:20.970
that, here, he was
not assuming anything

01:07:20.970 --> 01:07:22.380
about the utility function.

01:07:22.380 --> 01:07:25.860
The only thing he was assuming,
or Rabin was assuming here,

01:07:25.860 --> 01:07:30.480
is that the person is
expected utility maximizer

01:07:30.480 --> 01:07:33.240
and that the utility
function is weakly, not even

01:07:33.240 --> 01:07:35.370
strictly, concave.

01:07:35.370 --> 01:07:38.820
Now, what that means is
you can't sort of just

01:07:38.820 --> 01:07:41.130
change the functional form.

01:07:41.130 --> 01:07:45.280
This is a general proof for any
utility function that you use.

01:07:45.280 --> 01:07:47.350
So what you have to do
now is either sort of say,

01:07:47.350 --> 01:07:49.770
well, there's some
other assumptions

01:07:49.770 --> 01:07:54.690
wrong about expected utility
in terms of weighting

01:07:54.690 --> 01:07:59.760
the probabilities or stuff
like that that essentially

01:07:59.760 --> 01:08:00.885
can explain the phenomenon.

01:08:00.885 --> 01:08:04.120
It could be something about
[INAUDIBLE] aversion and so on.

01:08:04.120 --> 01:08:05.532
These seem kind of unlikely.

01:08:05.532 --> 01:08:06.990
The most likely
thing-- and this is

01:08:06.990 --> 01:08:08.782
what I'm going to talk
about next week-- is

01:08:08.782 --> 01:08:12.480
Kahneman-Tversky's sort of loss
aversion framework where you

01:08:12.480 --> 01:08:16.649
say, if you put different
weight on gains versus losses,

01:08:16.649 --> 01:08:19.229
then essentially you
have two parameters.

01:08:19.229 --> 01:08:22.830
You have one parameter about
your risk aversion over gains.

01:08:22.830 --> 01:08:26.430
And you have a parameter that's
steers kind of how you feel

01:08:26.430 --> 01:08:28.529
about losses compared to gains.

01:08:28.529 --> 01:08:31.140
So once you do that, then you
have another degree of freedom.

01:08:31.140 --> 01:08:34.950
And you can explain a lot
of [? favors ?] potentially.

01:08:34.950 --> 01:08:37.152
But that's kind of the
equivalent of that exactly.

01:08:37.152 --> 01:08:38.819
But the difference
here is that it's not

01:08:38.819 --> 01:08:41.236
coming through the utility
function, the reason

01:08:41.236 --> 01:08:43.319
being that the problem is
actually not the utility

01:08:43.319 --> 01:08:43.819
function.

01:08:43.819 --> 01:08:46.830
Because as I said, there's
actually no assumption here

01:08:46.830 --> 01:08:49.080
that can even be
changed because it's

01:08:49.080 --> 01:08:51.510
very general for any
function that you assume,

01:08:51.510 --> 01:08:54.680
be it any of the ones that I
just showed you previously.

01:08:58.680 --> 01:08:59.180
OK.

01:09:03.870 --> 01:09:05.743
So then the last choice--

01:09:05.743 --> 01:09:08.160
[INAUDIBLE] doing we'll get
started on this and then going

01:09:08.160 --> 01:09:09.450
to finish next time--

01:09:09.450 --> 01:09:11.100
is, as your
classmate was saying,

01:09:11.100 --> 01:09:12.450
about insurance choices.

01:09:12.450 --> 01:09:14.050
So how do we do that?

01:09:14.050 --> 01:09:16.649
So this is a very nice
paper by Justin Sydnor,

01:09:16.649 --> 01:09:19.920
who's using sort of real
world insurance choices.

01:09:19.920 --> 01:09:23.288
And what's very nice about it
is that you might not say, well,

01:09:23.288 --> 01:09:25.080
I might sort of say,
well, college students

01:09:25.080 --> 01:09:27.990
and lab choices gives
you funky answers.

01:09:27.990 --> 01:09:29.760
And you might not
sort of believe

01:09:29.760 --> 01:09:32.529
that this is really predictive
of anything in the real world.

01:09:32.529 --> 01:09:34.439
So we really want
real world choices

01:09:34.439 --> 01:09:37.410
that people make in their lives.

01:09:37.410 --> 01:09:40.260
And sort of you might also
worry about demand effects

01:09:40.260 --> 01:09:42.240
and about sort of people
behaving a little bit

01:09:42.240 --> 01:09:43.630
funny in experiment.

01:09:43.630 --> 01:09:46.020
So let's find real world
choices that people have made

01:09:46.020 --> 01:09:46.770
and try to see.

01:09:46.770 --> 01:09:49.569
Maybe we can estimate
gamma using that.

01:09:49.569 --> 01:09:54.029
And so what Justin Sydnor
has is data from a large home

01:09:54.029 --> 01:09:56.250
insurance provider.

01:09:56.250 --> 01:09:58.625
He has a bunch of
standard policies.

01:09:58.625 --> 01:10:00.000
There's a random
sample of those.

01:10:00.000 --> 01:10:03.150
So there are 50,000
standard policies.

01:10:03.150 --> 01:10:06.900
What he has, importantly,
he has both the options

01:10:06.900 --> 01:10:09.390
that people had-- so
what is your choice set?

01:10:09.390 --> 01:10:11.490
Here's four different
choices for each person.

01:10:11.490 --> 01:10:14.790
And he has then the
choices that people made.

01:10:14.790 --> 01:10:17.550
Plus, he has claims that
people made after that.

01:10:17.550 --> 01:10:19.035
He has all the new
customers, which

01:10:19.035 --> 01:10:20.660
matters a little bit
because, you know,

01:10:20.660 --> 01:10:22.440
you might say new
customers are confused.

01:10:22.440 --> 01:10:24.900
Maybe the old ones are
the ones that are right.

01:10:24.900 --> 01:10:28.527
Now, the key part
here is the deductible

01:10:28.527 --> 01:10:29.610
that people were choosing.

01:10:29.610 --> 01:10:31.030
What is a deductible?

01:10:37.400 --> 01:10:38.208
Yes.

01:10:38.208 --> 01:10:40.000
AUDIENCE: How much
you'll pay out of pocket

01:10:40.000 --> 01:10:41.598
before the insurance kicks in?

01:10:41.598 --> 01:10:42.640
FRANK SCHILBACH: Exactly.

01:10:42.640 --> 01:10:45.620
So this is expenses
paid out of pocket

01:10:45.620 --> 01:10:48.980
before the insurer starts
paying any expenses.

01:10:48.980 --> 01:10:52.430
That would be like, if you
had some damage to your house

01:10:52.430 --> 01:10:56.330
for some small amount, you would
have to pay that for yourself.

01:10:56.330 --> 01:10:58.065
If you have some large
amount of damage,

01:10:58.065 --> 01:10:59.690
you have to still
pay the small amount.

01:10:59.690 --> 01:11:02.360
And then the insurer
would pay the rest.

01:11:02.360 --> 01:11:05.458
And that's usually used to
deter a large number of claims

01:11:05.458 --> 01:11:07.250
because you know the
insurance company just

01:11:07.250 --> 01:11:09.860
doesn't want to pay
for every $50 of damage

01:11:09.860 --> 01:11:10.930
that you might have.

01:11:10.930 --> 01:11:12.680
Because that's just
really costly for them

01:11:12.680 --> 01:11:15.720
to do for administrative costs.

01:11:15.720 --> 01:11:20.370
Now, what Sydnor has is choices
over menus of four deductibles.

01:11:20.370 --> 01:11:25.070
And again, as I said, he has
both individual choice set

01:11:25.070 --> 01:11:26.967
and their preferred options.

01:11:26.967 --> 01:11:28.550
If you only had the
preferred options,

01:11:28.550 --> 01:11:32.330
it would be very hard to figure
out kind of what actually--

01:11:32.330 --> 01:11:36.560
because you then can't really
say what's the counterfactual.

01:11:36.560 --> 01:11:39.180
You don't essentially what
else he could have chosen

01:11:39.180 --> 01:11:41.610
or he or she should have chosen.

01:11:41.610 --> 01:11:43.482
So you kind of want
to different options

01:11:43.482 --> 01:11:44.690
and then sort of the outcome.

01:11:44.690 --> 01:11:47.090
And then say, OK, since you
had these different options

01:11:47.090 --> 01:11:49.980
available, it must be that you
preferred one or the other.

01:11:49.980 --> 01:11:53.370
It must be that you're
risk averse or not.

01:11:53.370 --> 01:11:56.540
So here's kind of what
these data look like.

01:11:56.540 --> 01:11:59.010
The sample data are deductibles.

01:11:59.010 --> 01:11:59.510
OK.

01:11:59.510 --> 01:12:01.220
This is, again,
the amount that you

01:12:01.220 --> 01:12:04.310
have to pay out of pocket
until the insurer sort of kicks

01:12:04.310 --> 01:12:05.720
in and pays for you.

01:12:05.720 --> 01:12:08.060
There is the premium,
which is how much you

01:12:08.060 --> 01:12:09.920
have to pay every
year anyway regardless

01:12:09.920 --> 01:12:12.910
of what anything would happen.

01:12:12.910 --> 01:12:17.150
There's sort of, relative to the
$1,000 policy, kind of what's

01:12:17.150 --> 01:12:17.990
the premium.

01:12:17.990 --> 01:12:20.420
That's to say how much
more money you have

01:12:20.420 --> 01:12:22.340
to pay for a certain premium.

01:12:22.340 --> 01:12:26.900
So for example, choice
one has a premium of $504.

01:12:26.900 --> 01:12:31.400
Choice two has a
premium of $588.

01:12:31.400 --> 01:12:34.490
So that's $84 higher.

01:12:34.490 --> 01:12:38.570
You pay essentially $84
in premium every year

01:12:38.570 --> 01:12:43.080
to reduce your deductible
from $1,000 to $500.

01:12:43.080 --> 01:12:43.580
OK.

01:12:43.580 --> 01:12:45.080
So what you can do,
essentially, you

01:12:45.080 --> 01:12:47.900
can reduce your
deductible at a price.

01:12:47.900 --> 01:12:51.350
The price relative to the $1,000
policy is in the third column.

01:12:51.350 --> 01:12:53.970
And you see the deductible
on the left-hand side.

01:12:53.970 --> 01:12:56.120
So this person is
like policyholder--

01:12:56.120 --> 01:12:57.130
yeah.

01:12:57.130 --> 01:12:59.030
AUDIENCE: If you're
comparing their choices,

01:12:59.030 --> 01:13:02.060
couldn't it be that they're
just a more risky person and not

01:13:02.060 --> 01:13:04.658
necessarily risk averse?

01:13:04.658 --> 01:13:05.700
FRANK SCHILBACH: Correct.

01:13:05.700 --> 01:13:07.130
So that's exactly right.

01:13:07.130 --> 01:13:10.273
So there's sort of unobservable
risk that people might have.

01:13:10.273 --> 01:13:11.190
I'll get back to that.

01:13:11.190 --> 01:13:15.410
But essentially, what you
see is that a lot of people

01:13:15.410 --> 01:13:16.940
make very similar choices.

01:13:16.940 --> 01:13:19.910
Then on average, people's
risk is relatively low.

01:13:19.910 --> 01:13:21.410
So what you're
saying-- essentially,

01:13:21.410 --> 01:13:22.730
I need to know your claim rate.

01:13:22.730 --> 01:13:25.147
I need to know kind of what's
your probability of actually

01:13:25.147 --> 01:13:26.510
having any damages.

01:13:26.510 --> 01:13:28.520
And it turns out claim
rates are extremely

01:13:28.520 --> 01:13:31.070
low in the sample, the
order of magnitude something

01:13:31.070 --> 01:13:32.330
like below 5%.

01:13:32.330 --> 01:13:34.320
Or I think it's even lower.

01:13:34.320 --> 01:13:37.460
So it cannot be that everybody
is a high risk person.

01:13:37.460 --> 01:13:39.830
It can be potentially
that everybody thinks

01:13:39.830 --> 01:13:41.270
they're a high risk person.

01:13:41.270 --> 01:13:45.990
But, you know, then there's
a different mistake going on.

01:13:45.990 --> 01:13:47.600
So what he's
assuming, essentially,

01:13:47.600 --> 01:13:51.800
is, on average, it must be that
there's some high risk people

01:13:51.800 --> 01:13:53.070
and some low risk people.

01:13:53.070 --> 01:13:55.403
But essentially, he's sort
of kind of assuming this away

01:13:55.403 --> 01:13:57.560
and sort of saying, look,
on average claim rates

01:13:57.560 --> 01:13:58.590
are really low.

01:13:58.590 --> 01:14:03.890
It could be that there is some
fraction of really high risk

01:14:03.890 --> 01:14:04.610
people.

01:14:04.610 --> 01:14:07.340
But by definition,
since they're only

01:14:07.340 --> 01:14:09.830
something like 5%
of claim rates,

01:14:09.830 --> 01:14:11.420
it can't be that
there's everybody

01:14:11.420 --> 01:14:14.330
is a high risk person.

01:14:14.330 --> 01:14:18.230
So it must be that there's some
people who behave as if they're

01:14:18.230 --> 01:14:21.050
either really risk averse or
as if they think they're really

01:14:21.050 --> 01:14:22.040
high risk people.

01:14:22.040 --> 01:14:24.680
And this is kind of where
the old and new customers are

01:14:24.680 --> 01:14:25.250
helpful for.

01:14:25.250 --> 01:14:28.220
Because there are some customers
who have been at this company

01:14:28.220 --> 01:14:29.962
for, like, 10, 15 years.

01:14:29.962 --> 01:14:31.670
And sort of, there,
you know, you kind of

01:14:31.670 --> 01:14:35.660
should know what kind of
risk person you are perhaps.

01:14:35.660 --> 01:14:37.410
But that's a great question.

01:14:37.410 --> 01:14:39.590
I'll actually get back to that.

01:14:39.590 --> 01:14:43.610
OK, so policy holder one,
their home was built in 1966.

01:14:43.610 --> 01:14:45.850
He had an insured
value of 180,000.

01:14:45.850 --> 01:14:48.380
The menu available for this
policy in the same year

01:14:48.380 --> 01:14:50.138
was the following.

01:14:50.138 --> 01:14:52.430
And then he has also the
choice on the right-hand side.

01:14:52.430 --> 01:14:54.740
You see the policies
that are chosen.

01:14:54.740 --> 01:15:00.160
So that person chose, for
example, a deductible of $200

01:15:00.160 --> 01:15:05.120
and for a price of
$157 relative to paying

01:15:05.120 --> 01:15:07.790
the $1,000 deductible.

01:15:07.790 --> 01:15:14.390
Policyholder two, similarly,
sort of chose the first option.

01:15:14.390 --> 01:15:16.640
Notice that the price has
changed a little bit in part

01:15:16.640 --> 01:15:18.230
because the company
has sort of taken

01:15:18.230 --> 01:15:21.680
into account some covariates and
some risk in some ways already.

01:15:21.680 --> 01:15:23.960
So the company is kind
of pricing specifically

01:15:23.960 --> 01:15:26.390
depending on what your home
value is and maybe the area

01:15:26.390 --> 01:15:27.660
and so on and so forth.

01:15:27.660 --> 01:15:29.510
But since Sydnor has
all that information,

01:15:29.510 --> 01:15:32.370
he can sort of just
take that into account.

01:15:32.370 --> 01:15:35.970
Now, what can we now
say about risk aversion?

01:15:35.970 --> 01:15:38.460
How can we now sort
of estimate risk

01:15:38.460 --> 01:15:40.830
aversion using these choices?

01:15:51.150 --> 01:15:51.650
Yes.

01:15:51.650 --> 01:15:53.108
AUDIENCE: If you
know your house is

01:15:53.108 --> 01:15:58.152
[INAUDIBLE] and your
[INAUDIBLE] problems [INAUDIBLE]

01:15:58.152 --> 01:16:01.140
so then you don't have
to pay [INAUDIBLE]..

01:16:03.595 --> 01:16:04.470
FRANK SCHILBACH: Yes.

01:16:04.470 --> 01:16:05.910
So what you need to
know is essentially

01:16:05.910 --> 01:16:06.840
a number of different things.

01:16:06.840 --> 01:16:08.757
You need to know the
deductibles, the premiums

01:16:08.757 --> 01:16:11.090
for each option, the claim
probabilities, and the wealth

01:16:11.090 --> 01:16:11.850
levels.

01:16:11.850 --> 01:16:13.540
I'll talk about
this in more detail.

01:16:13.540 --> 01:16:17.220
But essentially, what you can do
is, for each of these options,

01:16:17.220 --> 01:16:21.030
you can write down an indirect
utility of wealth function.

01:16:21.030 --> 01:16:23.160
You essentially can write
down what's the expected

01:16:23.160 --> 01:16:25.660
utility of that option.

01:16:25.660 --> 01:16:30.760
And then you can essentially
just put bounds essentially

01:16:30.760 --> 01:16:34.000
on if you preferred
option one or option two.

01:16:34.000 --> 01:16:36.910
That tells me something
about your gamma.

01:16:36.910 --> 01:16:39.850
And so what Sydnor then does
is essentially estimate gamma

01:16:39.850 --> 01:16:41.980
using those different choices.

01:16:41.980 --> 01:16:43.810
I'm going to go over
that in a lot more

01:16:43.810 --> 01:16:48.090
detail and slower next time.