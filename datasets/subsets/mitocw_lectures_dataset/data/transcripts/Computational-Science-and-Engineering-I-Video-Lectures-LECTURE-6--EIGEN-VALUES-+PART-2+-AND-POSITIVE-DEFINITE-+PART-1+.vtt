WEBVTT

00:00:00.257 --> 00:00:02.340
The following content is
provided under a Creative

00:00:02.340 --> 00:00:03.620
Commons license.

00:00:03.620 --> 00:00:05.770
Your support will help
MIT OpenCourseWare

00:00:05.770 --> 00:00:10.050
continue to offer high quality
educational resources for free.

00:00:10.050 --> 00:00:13.440
To make a donation, or to
view additional materials

00:00:13.440 --> 00:00:16.150
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.150 --> 00:00:20.410
at ocw.mit.edu.

00:00:20.410 --> 00:00:22.200
PROFESSOR STRANG:
Actually, two things

00:00:22.200 --> 00:00:23.760
to say about eigenvalues.

00:00:23.760 --> 00:00:28.460
One is about matrices
in general and then

00:00:28.460 --> 00:00:30.940
the second is to focus
on our favorites,

00:00:30.940 --> 00:00:37.610
those second derivatives
and second differences.

00:00:37.610 --> 00:00:39.870
There's a lot to say
about eigenvalues

00:00:39.870 --> 00:00:42.810
but then we'll have
the main ideas.

00:00:42.810 --> 00:00:46.910
So the central idea
of course is to find

00:00:46.910 --> 00:00:51.970
these special directions and
we expect to find n directions,

00:00:51.970 --> 00:00:56.880
n eigenvectors y where
this n by n matrix

00:00:56.880 --> 00:01:03.320
is acting like a number in
each of those directions.

00:01:03.320 --> 00:01:06.640
So we have this for n
different y's and each one

00:01:06.640 --> 00:01:09.370
has its own eigenvalue lambda.

00:01:09.370 --> 00:01:12.490
And of course the
eig command in MATLAB

00:01:12.490 --> 00:01:15.870
will find the y's
and the lambdas.

00:01:15.870 --> 00:01:21.320
So it finds the y's and
the lambdas in a matrix.

00:01:21.320 --> 00:01:24.350
So that's what I'm going
to do now, straightforward.

00:01:24.350 --> 00:01:28.160
Any time I have n vectors, so
I have n of these y's, I've

00:01:28.160 --> 00:01:32.000
n y's and n lambdas.

00:01:32.000 --> 00:01:35.150
Well, if you give
me n vectors, I

00:01:35.150 --> 00:01:37.180
put them into the
columns of a matrix,

00:01:37.180 --> 00:01:38.810
almost without thinking.

00:01:38.810 --> 00:01:41.340
So can I just do that?

00:01:41.340 --> 00:01:44.090
So there is y_1, the
first eigenvector.

00:01:44.090 --> 00:01:47.240
That's y_2 to y_n.

00:01:47.240 --> 00:01:50.330
Okay, that's my
eigenvector matrix.

00:01:50.330 --> 00:01:54.460
Often I call it S. So
I'll stick with that.

00:01:54.460 --> 00:01:59.780
S will be the
eigenvector matrix.

00:01:59.780 --> 00:02:01.475
Since these are
eigenvectors I'm going

00:02:01.475 --> 00:02:05.570
to multiply that
matrix by A. That

00:02:05.570 --> 00:02:07.570
should bring out the key point.

00:02:07.570 --> 00:02:15.710
I'm just going to repeat
this, which is one at a time,

00:02:15.710 --> 00:02:18.800
by doing them all that once.

00:02:18.800 --> 00:02:23.350
So what happens if I multiply
a matrix by a bunch of columns?

00:02:23.350 --> 00:02:25.220
Matrix multiplication
is wonderful.

00:02:25.220 --> 00:02:26.880
It does the right thing.

00:02:26.880 --> 00:02:30.540
It multiplies A times
the first column.

00:02:30.540 --> 00:02:31.820
So let's put that there.

00:02:31.820 --> 00:02:37.230
A times the first column along
to A times the last column.

00:02:37.230 --> 00:02:39.380
Just column by column.

00:02:39.380 --> 00:02:41.390
But now we recognize these.

00:02:41.390 --> 00:02:43.590
They're special y's.

00:02:43.590 --> 00:02:45.490
They're special because
they're eigenvectors.

00:02:45.490 --> 00:02:53.440
So this is lambda_1*y_1 along
to that column is lambda_n*y_n.

00:02:53.440 --> 00:02:56.560
Right?

00:02:56.560 --> 00:02:59.280
Now I've used the fact that
they were eigenvectors.

00:02:59.280 --> 00:03:03.670
And now, one final neat step
of matrix multiplication

00:03:03.670 --> 00:03:10.010
is to factor out this same
eigenvector matrix again

00:03:10.010 --> 00:03:12.970
and realize, and
I'll look at it,

00:03:12.970 --> 00:03:17.460
that it's being multiplied
by this diagonal, that's

00:03:17.460 --> 00:03:23.230
now a diagonal matrix
of eigenvalues.

00:03:23.230 --> 00:03:26.610
So let's just look at
that very last step here.

00:03:26.610 --> 00:03:29.120
Here I had the first
column was lambda_1*y_1.

00:03:31.880 --> 00:03:35.880
I just want to see,
did I get that right?

00:03:35.880 --> 00:03:38.260
If I'm looking at
the first column

00:03:38.260 --> 00:03:42.170
where that lambda_1 is sitting,
it's going to multiply y_1

00:03:42.170 --> 00:03:45.610
and it'll be all zeroes
below so I'll have

00:03:45.610 --> 00:03:47.860
none of the other eigenvectors.

00:03:47.860 --> 00:03:51.760
So I'll have lambda_1*y_1,
just what I want.

00:03:51.760 --> 00:03:56.010
Got a little squeezed near
the end there, but so let

00:03:56.010 --> 00:03:57.810
me write above.

00:03:57.810 --> 00:04:03.540
The result is just A times
this eigenvector matrix

00:04:03.540 --> 00:04:10.040
that I'm going to
call S equals what?

00:04:10.040 --> 00:04:15.220
This is Ay=lambda*y
for all n at once.

00:04:15.220 --> 00:04:18.290
A times S is, what
have I got here?

00:04:18.290 --> 00:04:19.690
What's this?

00:04:19.690 --> 00:04:22.980
That's S. And what's
the other guy?

00:04:22.980 --> 00:04:25.650
That's the eigenvalue matrix.

00:04:25.650 --> 00:04:27.390
So it's just got n numbers.

00:04:27.390 --> 00:04:29.880
They automatically
go on the diagonal

00:04:29.880 --> 00:04:32.860
and it gets called
capital Lambda.

00:04:32.860 --> 00:04:37.340
Capital Lambda for the matrix,
little lambda for the numbers.

00:04:37.340 --> 00:04:42.630
So this is n, this
is all n at once.

00:04:42.630 --> 00:04:46.630
Straightforward.

00:04:46.630 --> 00:04:48.450
Now I'm going to
assume that I've

00:04:48.450 --> 00:04:52.390
got these n eigenvectors,
that I've been able to find

00:04:52.390 --> 00:04:55.130
n independent directions.

00:04:55.130 --> 00:04:57.520
And almost always, you can.

00:04:57.520 --> 00:05:01.380
For every symmetric matrix
you automatically can.

00:05:01.380 --> 00:05:06.050
So these y's are
independent directions.

00:05:06.050 --> 00:05:09.530
If those are the
columns of a matrix,

00:05:09.530 --> 00:05:12.900
yeah, here's a key
question about matrices.

00:05:12.900 --> 00:05:15.840
What can I say
about this matrix S

00:05:15.840 --> 00:05:19.210
if its n columns
are independent?

00:05:19.210 --> 00:05:20.790
Whatever that, you
know, we haven't

00:05:20.790 --> 00:05:23.830
focused in careful detail,
but we have an idea.

00:05:23.830 --> 00:05:28.450
That means sort of none of them
are combinations of the others.

00:05:28.450 --> 00:05:30.890
We really have n
separate directions.

00:05:30.890 --> 00:05:33.400
Then that matrix is?

00:05:33.400 --> 00:05:35.940
Invertible.

00:05:35.940 --> 00:05:39.280
A matrix that's got n
columns, independent,

00:05:39.280 --> 00:05:41.010
that's what we're hoping for.

00:05:41.010 --> 00:05:42.910
That matrix has an inverse.

00:05:42.910 --> 00:05:47.080
We can produce, well all the
good facts about matrices.

00:05:47.080 --> 00:05:48.610
This is a square matrix.

00:05:48.610 --> 00:05:50.950
So I can invert it if you like.

00:05:50.950 --> 00:05:53.920
And I can write A as S lambda.

00:05:53.920 --> 00:05:56.950
I'm multiplying on the
right by this S inverse.

00:05:56.950 --> 00:06:03.620
And there I have the
diagonalization of a matrix.

00:06:03.620 --> 00:06:06.070
The matrix has
been diagonalized.

00:06:06.070 --> 00:06:07.410
And what does that mean?

00:06:07.410 --> 00:06:13.100
Well this is, of course the
diagonal that we're headed for.

00:06:13.100 --> 00:06:16.440
And what it means is that
if I look at my matrix

00:06:16.440 --> 00:06:23.150
and I separate out the different
eigendirections, I could say,

00:06:23.150 --> 00:06:26.100
that the matrix in
those directions

00:06:26.100 --> 00:06:28.750
is just this diagonal matrix.

00:06:28.750 --> 00:06:36.400
So that's a short
way of saying it.

00:06:36.400 --> 00:06:40.810
Let me just carry
one step further.

00:06:40.810 --> 00:06:44.650
What would A squared be?

00:06:44.650 --> 00:06:50.620
Well now that I have it in this
cool form, S*lambda*S inverse,

00:06:50.620 --> 00:06:53.870
I would multiply two of those
together and what would I

00:06:53.870 --> 00:06:55.650
learn?

00:06:55.650 --> 00:06:59.440
If I do that multiplication
what comes out?

00:06:59.440 --> 00:07:02.330
First an S from here.

00:07:02.330 --> 00:07:04.420
And then what?

00:07:04.420 --> 00:07:05.490
Lambda squared.

00:07:05.490 --> 00:07:07.780
Why lambda squared?

00:07:07.780 --> 00:07:10.710
Because in the middle is
the S S inverse that's

00:07:10.710 --> 00:07:14.250
giving the identity matrix.

00:07:14.250 --> 00:07:16.960
So then the lambda
multiplies the lambda

00:07:16.960 --> 00:07:18.990
and now here is S inverse.

00:07:18.990 --> 00:07:22.860
Well A squared is S*lambda
squared*S inverse.

00:07:22.860 --> 00:07:25.370
What does that tell me in words?

00:07:25.370 --> 00:07:31.920
That tells me that the
eigenvectors of A squared are?

00:07:31.920 --> 00:07:33.300
The same.

00:07:33.300 --> 00:07:37.800
As for A. And it tells me that
the eigenvalues of A squared

00:07:37.800 --> 00:07:39.120
are?

00:07:39.120 --> 00:07:41.400
The squares.

00:07:41.400 --> 00:07:43.650
So I could do this.

00:07:43.650 --> 00:07:45.600
Maybe I did it
before, one at a time.

00:07:45.600 --> 00:07:53.760
Ay=lambda*y, multiply again by
A. A squared*y is lambda*Ay,

00:07:53.760 --> 00:07:59.720
but Ay is lambda*y so I'm
up to lambda squared*y.

00:07:59.720 --> 00:08:02.040
You should just see
that when you've

00:08:02.040 --> 00:08:06.460
got these directions then
your matrix is really simple.

00:08:06.460 --> 00:08:08.880
Effectively it's
a diagonal matrix

00:08:08.880 --> 00:08:11.530
in these good directions.

00:08:11.530 --> 00:08:17.280
So that just shows one way
of seeing-- And of course

00:08:17.280 --> 00:08:18.400
what about A inverse?

00:08:18.400 --> 00:08:20.960
We might as well
mention A inverse.

00:08:20.960 --> 00:08:24.540
Suppose A is invertible.

00:08:24.540 --> 00:08:28.710
Then what do I learn
about A inverse?

00:08:28.710 --> 00:08:32.380
Can I just invert that?

00:08:32.380 --> 00:08:34.000
I'm just playing
with that formula,

00:08:34.000 --> 00:08:39.800
so you'll kind of,
like, get handy with it.

00:08:39.800 --> 00:08:42.770
What would the inverse
be if I have three things

00:08:42.770 --> 00:08:45.330
in a row multiplied together?

00:08:45.330 --> 00:08:48.480
What's the inverse?

00:08:48.480 --> 00:08:51.480
So I'm going to take the
inverses in the opposite order,

00:08:51.480 --> 00:08:52.740
right?

00:08:52.740 --> 00:08:56.150
So the inverse of
that will come first.

00:08:56.150 --> 00:08:58.640
So what's that?

00:08:58.640 --> 00:09:02.390
Just S. The lambda
in the middle gets

00:09:02.390 --> 00:09:06.120
inverted and then
the S at the left,

00:09:06.120 --> 00:09:09.610
its inverse comes at the right.

00:09:09.610 --> 00:09:13.190
Well what do I learn from that?

00:09:13.190 --> 00:09:19.820
I learn that the eigenvector
matrix for A inverse is?

00:09:19.820 --> 00:09:21.360
Same thing, again.

00:09:21.360 --> 00:09:22.180
Same.

00:09:22.180 --> 00:09:24.380
Let me put just "Same".

00:09:24.380 --> 00:09:31.860
What's the eigenvalue
matrix for A inverse?

00:09:31.860 --> 00:09:37.070
It's the inverse of this guy,
so what does it look like?

00:09:37.070 --> 00:09:39.900
It's got one over lambdas.

00:09:39.900 --> 00:09:42.720
That's all it says.

00:09:42.720 --> 00:09:45.980
The eigenvalues for
A inverse are just

00:09:45.980 --> 00:09:49.460
one over the eigenvalues for A.

00:09:49.460 --> 00:09:54.210
If that is so, and it can't
be difficult, we could again,

00:09:54.210 --> 00:10:01.380
we could prove it sort
of like, one at a time.

00:10:01.380 --> 00:10:03.280
This is my starting
point, always.

00:10:03.280 --> 00:10:07.610
How would I get to A inverse
now and recover this fact

00:10:07.610 --> 00:10:13.510
that the eigenvalues for the
inverse, just turn them up.

00:10:13.510 --> 00:10:16.950
If A has an eigenvalue
seven, A inverse

00:10:16.950 --> 00:10:20.700
will have an eigenvalue 1/7.

00:10:20.700 --> 00:10:23.570
What do I do?

00:10:23.570 --> 00:10:26.700
Usually multiply both sides
by something sensible.

00:10:26.700 --> 00:10:28.630
Right?

00:10:28.630 --> 00:10:31.030
What shall I multiply
both sides by?

00:10:31.030 --> 00:10:34.990
A inverse sounds like
a good idea, right.

00:10:34.990 --> 00:10:36.930
So I'm multiplying both
sides by A inverse,

00:10:36.930 --> 00:10:40.370
so that just leaves y and
here is that number, here

00:10:40.370 --> 00:10:44.300
is A inverse times y.

00:10:44.300 --> 00:10:46.530
Well, maybe I should
do one more thing.

00:10:46.530 --> 00:10:48.910
What else shall I do?

00:10:48.910 --> 00:10:52.130
Divide by lambda.

00:10:52.130 --> 00:10:55.940
Take that number lambda and
put it over here as one lambda.

00:10:55.940 --> 00:11:00.030
Well, just exactly
what we're looking for.

00:11:00.030 --> 00:11:04.813
The same y has A
inverse, the same y

00:11:04.813 --> 00:11:08.210
as an eigenvector of A
inverse and the eigenvalue

00:11:08.210 --> 00:11:10.230
is one over lambda.

00:11:10.230 --> 00:11:13.660
Oh, and of course,
I should have said

00:11:13.660 --> 00:11:16.510
before I inverted
anything, what should I

00:11:16.510 --> 00:11:19.920
have said about the lambdas?

00:11:19.920 --> 00:11:21.600
Not zero.

00:11:21.600 --> 00:11:22.640
Right?

00:11:22.640 --> 00:11:28.870
A zero eigenvalue is a signal
the matrix isn't invertible.

00:11:28.870 --> 00:11:32.340
So that's perfect test.

00:11:32.340 --> 00:11:37.460
If the matrix is invertible, all
its eigenvalues are not zero.

00:11:37.460 --> 00:11:40.610
If it's singular, it's
got a zero eigenvalue.

00:11:40.610 --> 00:11:47.060
If a matrix is singular,
then Ay would be 0y for some,

00:11:47.060 --> 00:11:49.670
there'd be a vector
that that matrix kills.

00:11:49.670 --> 00:11:52.570
If A is not invertible,
there's a reason for it.

00:11:52.570 --> 00:11:55.730
It's because it takes
some vector to zero,

00:11:55.730 --> 00:12:01.580
and of course, you can't
bring it back to life.

00:12:01.580 --> 00:12:03.320
So shall I just
put that up here?

00:12:03.320 --> 00:12:08.290
Lambda=0 would tell me I
have a singular matrix.

00:12:08.290 --> 00:12:12.120
All lambda not equal
zero would tell me

00:12:12.120 --> 00:12:17.510
I have an invertible matrix.

00:12:17.510 --> 00:12:19.990
These are straightforward facts.

00:12:19.990 --> 00:12:25.310
It's taken down in this row
and it's just really handy

00:12:25.310 --> 00:12:30.690
to have up here.

00:12:30.690 --> 00:12:34.110
Well now I'm ready to move
toward the specific matrices,

00:12:34.110 --> 00:12:35.600
our favorites.

00:12:35.600 --> 00:12:38.190
Now, those are symmetric.

00:12:38.190 --> 00:12:41.780
So maybe before I
leave this picture,

00:12:41.780 --> 00:12:46.500
we better recall what is special
when the matrix is symmetric.

00:12:46.500 --> 00:12:49.480
So that's going to
be the next thing.

00:12:49.480 --> 00:12:53.200
So if A is symmetric I get
some extra good things.

00:12:53.200 --> 00:12:58.710
So let me take instead
of A, I'll use K.

00:12:58.710 --> 00:13:02.750
So that'll be my letter
for the best matrices.

00:13:02.750 --> 00:13:07.460
So symmetric.

00:13:07.460 --> 00:13:10.660
So now what's the deal
with symmetric matrices?

00:13:10.660 --> 00:13:12.930
The eigenvalues, the lambdas.

00:13:12.930 --> 00:13:16.030
I'll just call them the
lambdas and the y's.

00:13:16.030 --> 00:13:20.940
The lambdas are, do you
remember from last time?

00:13:20.940 --> 00:13:25.960
If I have a symmetric matrix,
the eigenvalues are all?

00:13:25.960 --> 00:13:26.900
Anybody remember?

00:13:26.900 --> 00:13:28.900
They're all real numbers.

00:13:28.900 --> 00:13:32.210
You can never run into
complex eigenvalues

00:13:32.210 --> 00:13:34.570
if you start with
a symmetric matrix.

00:13:34.570 --> 00:13:39.250
We didn't prove that but it's
just a few steps like those.

00:13:39.250 --> 00:13:42.870
And what about, most
important, what about the y's?

00:13:42.870 --> 00:13:44.110
The eigenvectors.

00:13:44.110 --> 00:13:48.940
They are, or can be chosen
to be, or whatever, anybody

00:13:48.940 --> 00:13:50.200
remember that fact?

00:13:50.200 --> 00:13:53.030
These are, like,
the golden facts.

00:13:53.030 --> 00:14:00.980
Every sort of bunch of
matrices reveals itself

00:14:00.980 --> 00:14:03.560
through what its
eigenvalues are like

00:14:03.560 --> 00:14:05.420
and what its
eigenvectors are like.

00:14:05.420 --> 00:14:08.590
And the most important class
is symmetric and that reveals

00:14:08.590 --> 00:14:12.730
itself through real
eigenvalues and...?

00:14:12.730 --> 00:14:13.990
Orthogonal, good.

00:14:13.990 --> 00:14:18.760
Orthogonal eigenvectors,
orthogonal.

00:14:18.760 --> 00:14:23.580
And in fact, since
I'm an eigenvector,

00:14:23.580 --> 00:14:27.030
I can adjust its
length as I like.

00:14:27.030 --> 00:14:29.380
Right?

00:14:29.380 --> 00:14:32.400
If y is an eigenvector,
11y is an eigenvector

00:14:32.400 --> 00:14:35.660
because I would just
multiply both sides by 11.

00:14:35.660 --> 00:14:40.860
That whole line of eigenvectors
is getting stretched by lambda.

00:14:40.860 --> 00:14:45.970
So what I want to do is
make them unit vectors.

00:14:45.970 --> 00:14:49.750
MATLAB will
automatically produce,

00:14:49.750 --> 00:14:53.100
eig would automatically
give you vectors that

00:14:53.100 --> 00:15:00.740
have been normalized to unit.

00:15:00.740 --> 00:15:03.630
Here's something good.

00:15:03.630 --> 00:15:05.820
So what does orthogonal mean?

00:15:05.820 --> 00:15:10.240
That means that one of them,
the dot product of one of them

00:15:10.240 --> 00:15:14.220
with another one is?

00:15:14.220 --> 00:15:17.180
Now that's not, I didn't
do the dot product yet.

00:15:17.180 --> 00:15:21.700
What symbol do I have to
write on left-hand side?

00:15:21.700 --> 00:15:23.440
Well you could say,
just put a dot.

00:15:23.440 --> 00:15:25.150
Of course.

00:15:25.150 --> 00:15:34.320
But dots are not cool, right?

00:15:34.320 --> 00:15:36.940
So maybe I should say
inner product, that's

00:15:36.940 --> 00:15:41.990
the more upper-class word.

00:15:41.990 --> 00:15:44.200
But I want to use transpose.

00:15:44.200 --> 00:15:45.720
So it's the transpose.

00:15:45.720 --> 00:15:47.130
That's the dot product.

00:15:47.130 --> 00:15:50.010
And that's the test
for perpendicular.

00:15:50.010 --> 00:15:51.450
So what's the answer then?

00:15:51.450 --> 00:15:55.300
I get a zero if i
is different from j.

00:15:55.300 --> 00:15:58.220
If I'm taking two
different eigenvectors

00:15:58.220 --> 00:16:01.520
and I take their dot product,
that's what you told me,

00:16:01.520 --> 00:16:02.960
they're orthogonal.

00:16:02.960 --> 00:16:05.780
And now what if i equals j?

00:16:05.780 --> 00:16:09.400
If I'm taking the dot
product with itself,

00:16:09.400 --> 00:16:11.960
each eigenvector with itself.

00:16:11.960 --> 00:16:16.920
So what does the dot product
of a vector with itself give?

00:16:16.920 --> 00:16:19.030
It'll be one because I'm normal.

00:16:19.030 --> 00:16:21.420
Exactly.

00:16:21.420 --> 00:16:23.520
What it always gives,
the dot product

00:16:23.520 --> 00:16:25.700
of a vector with
itself, you just

00:16:25.700 --> 00:16:28.880
realize that that'll be
y_1 squared, y_2 squared,

00:16:28.880 --> 00:16:31.960
it'll be the length squared.

00:16:31.960 --> 00:16:36.820
And here we're making
the length to be one.

00:16:36.820 --> 00:16:39.720
Well once again, if
I write something

00:16:39.720 --> 00:16:43.110
down like this which
is straightforward

00:16:43.110 --> 00:16:46.800
I want to express it
as a matrix statement.

00:16:46.800 --> 00:16:54.090
So I want to multiply, it'll
involve my good eigenvector

00:16:54.090 --> 00:16:55.670
matrix.

00:16:55.670 --> 00:17:00.250
And this will be what?

00:17:00.250 --> 00:17:03.740
I want to take all these
dots products at once.

00:17:03.740 --> 00:17:07.440
I want to take the dot product
of every y with every other y.

00:17:07.440 --> 00:17:08.790
Well here you go.

00:17:08.790 --> 00:17:14.480
Just put these guys in the rows,
now that we see that it really

00:17:14.480 --> 00:17:19.500
was the transpose
multiplying y, do you

00:17:19.500 --> 00:17:21.670
see that that's just done it?

00:17:21.670 --> 00:17:24.380
In fact, you'll tell me
what the answer is here.

00:17:24.380 --> 00:17:28.800
Don't shout it out, but let's
take it two or three entries

00:17:28.800 --> 00:17:31.680
and then you can shout it out.

00:17:31.680 --> 00:17:37.020
So what's the (1,
1) entry here of I

00:17:37.020 --> 00:17:39.690
guess that's what
we called S. And now

00:17:39.690 --> 00:17:41.680
this would be its transpose.

00:17:41.680 --> 00:17:44.950
And what I'm saying is if I
take-- Yeah, this is important

00:17:44.950 --> 00:17:47.530
because throughout
this course we're

00:17:47.530 --> 00:17:53.250
going to be taking A
transpose A, S transpose S,

00:17:53.250 --> 00:17:56.100
Q transpose Q,
often, often, often.

00:17:56.100 --> 00:17:58.340
So here we got the
first time at it.

00:17:58.340 --> 00:18:02.370
So why did I put a zero
there, because it's not it.

00:18:02.370 --> 00:18:03.880
What is it?

00:18:03.880 --> 00:18:06.670
What is that first entry?

00:18:06.670 --> 00:18:07.740
One.

00:18:07.740 --> 00:18:11.010
Because that's the row times
the column, that's a one.

00:18:11.010 --> 00:18:13.780
And what's the entry next to it?

00:18:13.780 --> 00:18:14.320
Zero.

00:18:14.320 --> 00:18:19.880
Right? y_1 dot product with
y_2 is, we're saying, zero.

00:18:19.880 --> 00:18:23.440
So what matrix have I got here?

00:18:23.440 --> 00:18:24.370
I've got the identity.

00:18:24.370 --> 00:18:28.690
Because y_2 with y_2 will
put a one there and all

00:18:28.690 --> 00:18:30.340
zeroes elsewhere.

00:18:30.340 --> 00:18:31.510
Zero, zero.

00:18:31.510 --> 00:18:34.760
And y_3 times y_3
will be the one.

00:18:34.760 --> 00:18:40.180
I get the identity.

00:18:40.180 --> 00:18:48.370
So this is for
symmetric matrices.

00:18:48.370 --> 00:18:53.520
In general, we can't expect the
eigenvectors to be orthogonal.

00:18:53.520 --> 00:18:57.160
It's these special
ones that are.

00:18:57.160 --> 00:19:02.640
But they're so important
that we notice.

00:19:02.640 --> 00:19:05.420
Now so this is the
eigenvector matrix

00:19:05.420 --> 00:19:09.680
S and this is its transpose.

00:19:09.680 --> 00:19:12.550
So I'm saying that for
a symmetric matrix,

00:19:12.550 --> 00:19:19.500
S transpose times S is I.
Well that's pretty important.

00:19:19.500 --> 00:19:22.920
In fact, that's
important enough that I'm

00:19:22.920 --> 00:19:27.530
going to give an
extra name to S,

00:19:27.530 --> 00:19:34.440
the eigenvector matrix when it
comes from a symmetric matrix,

00:19:34.440 --> 00:19:38.460
when it has a matrix with S
transpose times S equaling

00:19:38.460 --> 00:19:44.620
the identity is really
a good matrix to know.

00:19:44.620 --> 00:19:50.060
So let's just focus
on those guys.

00:19:50.060 --> 00:19:52.630
I can put that up here.

00:19:52.630 --> 00:19:57.340
So here's a matrix.

00:19:57.340 --> 00:20:00.410
Can I introduce a
different letter than S?

00:20:00.410 --> 00:20:05.540
It just helps you to remember
that this remarkable property

00:20:05.540 --> 00:20:06.710
is in force.

00:20:06.710 --> 00:20:10.090
That we've got it.

00:20:10.090 --> 00:20:15.310
So I'm going to call it--
When K is a symmetric matrix,

00:20:15.310 --> 00:20:24.370
I'll just repeat that,
then its eigenvector matrix

00:20:24.370 --> 00:20:29.520
has this S transpose
times S-- I'm

00:20:29.520 --> 00:20:35.590
going to call it Q. I'm going
to call the eigenvectors,

00:20:35.590 --> 00:20:44.920
so for this special
situation, A times--

00:20:44.920 --> 00:20:48.370
So I'm going to call the
eigenvector matrix Q.

00:20:48.370 --> 00:20:54.110
It's the S but it's worth
giving it this special notation

00:20:54.110 --> 00:21:02.710
to remind us that this is, so
Q is, an orthogonal matrix.

00:21:02.710 --> 00:21:06.950
There's a name for matrices
with this important property.

00:21:06.950 --> 00:21:09.840
And there's a letter
Q that everybody uses.

00:21:09.840 --> 00:21:12.690
An orthogonal matrix.

00:21:12.690 --> 00:21:14.170
And what does that mean?

00:21:14.170 --> 00:21:18.530
Means just what we said,
Q transpose times Q

00:21:18.530 --> 00:21:27.970
is I. What I've done here
is just giving a special,

00:21:27.970 --> 00:21:31.860
introducing a special
letter Q, a special name,

00:21:31.860 --> 00:21:36.690
orthogonal matrix for
what we found in the good,

00:21:36.690 --> 00:21:40.710
in this-- for eigenvectors
of a symmetric matrix.

00:21:40.710 --> 00:21:44.290
And this tells me
one thing more.

00:21:44.290 --> 00:21:46.210
Look what's happening here.

00:21:46.210 --> 00:21:51.160
Q transpose times Q is
giving the identity.

00:21:51.160 --> 00:21:54.600
What does that tell me
about the inverse of Q?

00:21:54.600 --> 00:22:00.710
That tells me here some matrix
is multiplying Q and giving I.

00:22:00.710 --> 00:22:02.050
So what is this matrix?

00:22:02.050 --> 00:22:06.600
What's another name
for this Q transpose?

00:22:06.600 --> 00:22:09.740
Is also Q inverse.

00:22:09.740 --> 00:22:12.190
Because that's what
defines the inverse matrix,

00:22:12.190 --> 00:22:23.580
that times Q should give I.
So Q transpose is Q inverse.

00:22:23.580 --> 00:22:26.140
I'm moving along here.

00:22:26.140 --> 00:22:33.170
Yes, please.

00:22:33.170 --> 00:22:37.990
The question was, shouldn't I
call it an orthonormal matrix?

00:22:37.990 --> 00:22:40.090
The answer is yes, I should.

00:22:40.090 --> 00:22:42.020
But nobody does.

00:22:42.020 --> 00:22:42.540
Dammit!

00:22:42.540 --> 00:22:45.340
So I'm stuck with that name.

00:22:45.340 --> 00:22:47.800
But orthonormal is
the proper name.

00:22:47.800 --> 00:22:50.170
If you call it an
orthonormal matrix,

00:22:50.170 --> 00:22:53.150
I'm happy because that's
really the right name

00:22:53.150 --> 00:22:54.870
for that matrix, orthonormal.

00:22:54.870 --> 00:22:58.780
Because orthogonal would just
mean orthogonal columns but

00:22:58.780 --> 00:23:01.380
we've taken this
extra little step

00:23:01.380 --> 00:23:03.500
to make all the lengths one.

00:23:03.500 --> 00:23:07.220
And then that gives us
this great property.

00:23:07.220 --> 00:23:09.260
Q transpose is Q inverse.

00:23:09.260 --> 00:23:14.780
Orthogonal matrices
are like rotations.

00:23:14.780 --> 00:23:19.270
I better give an example
of an orthogonal matrix.

00:23:19.270 --> 00:23:20.630
I'll do it right under here.

00:23:20.630 --> 00:23:22.970
Here is an orthogonal matrix.

00:23:22.970 --> 00:23:25.470
So what's the point?

00:23:25.470 --> 00:23:28.170
It's supposed to be a unit
vector in the first column

00:23:28.170 --> 00:23:31.940
so I'll put
cos(theta), sin(theta).

00:23:31.940 --> 00:23:34.390
And now what can go
in the second column

00:23:34.390 --> 00:23:36.990
of this orthogonal matrix?

00:23:36.990 --> 00:23:40.940
It's gotta be a unit vector
again because we've normalized

00:23:40.940 --> 00:23:46.500
and it's gotta be, what's the
connection to the first column?

00:23:46.500 --> 00:23:48.970
Orthogonal, gotta be orthogonal.

00:23:48.970 --> 00:23:51.400
So I just wanted to
put something here

00:23:51.400 --> 00:23:53.980
that sum of squares
is one, so I'll

00:23:53.980 --> 00:23:56.700
think cos(theta) and
sin(theta) again.

00:23:56.700 --> 00:23:59.430
But then I've got to
flip them a little

00:23:59.430 --> 00:24:01.060
to make it orthogonal to this.

00:24:01.060 --> 00:24:08.040
So if I put minus sin(theta)
there and plus cos(theta) there

00:24:08.040 --> 00:24:10.600
that certainly has
length one, good.

00:24:10.600 --> 00:24:14.580
And the dot product, can you do
the dot product of that column

00:24:14.580 --> 00:24:15.690
with that column?

00:24:15.690 --> 00:24:20.530
It's minus sine cosine,
plus sine cosine, zero.

00:24:20.530 --> 00:24:23.500
So there is a two
by two, actually

00:24:23.500 --> 00:24:26.740
that's a fantastic
building block out of which

00:24:26.740 --> 00:24:32.480
you could build many orthogonal
matrices of all sizes.

00:24:32.480 --> 00:24:38.390
That's a rotation by theta.

00:24:38.390 --> 00:24:41.400
That's a useful matrix to know.

00:24:41.400 --> 00:24:46.500
It takes every vector, swings
it around by an angle theta.

00:24:46.500 --> 00:24:47.330
What do I mean?

00:24:47.330 --> 00:24:53.980
I mean that Qx, Q times a
vector x, rotates x by theta.

00:24:53.980 --> 00:24:55.840
Let me put it.

00:24:55.840 --> 00:25:01.650
Qx rotates whatever vector x
you give it, you multiply by Q,

00:25:01.650 --> 00:25:07.370
it rotates it around by theta,
it doesn't change the length.

00:25:07.370 --> 00:25:16.246
So that would be an eigenvector
matrix of a pretty typical two

00:25:16.246 --> 00:25:19.660
by two.

00:25:19.660 --> 00:25:22.220
I see as I talk
about eigenvectors,

00:25:22.220 --> 00:25:24.650
eigenvalues there's
so much to say.

00:25:24.650 --> 00:25:29.150
Because everything you know
about a matrix shows up somehow

00:25:29.150 --> 00:25:31.450
in its eigenvectors
and eigenvalues

00:25:31.450 --> 00:25:38.030
and we're focusing
on symmetric guys.

00:25:38.030 --> 00:25:42.012
What happens to this
A=S*lambda*S inverse?

00:25:42.012 --> 00:25:42.970
Let's write that again.

00:25:42.970 --> 00:25:50.680
Now we've got K. It's
S*lambda*S inverse like any good

00:25:50.680 --> 00:25:57.630
diagonalization but now
I'm giving S a new name,

00:25:57.630 --> 00:25:59.220
which is what?

00:25:59.220 --> 00:26:04.790
Q. because when I give K,
when I use that letter K

00:26:04.790 --> 00:26:09.360
I'm thinking symmetric so
I'm in this special situation

00:26:09.360 --> 00:26:10.380
of symmetric.

00:26:10.380 --> 00:26:12.860
I have the lambda,
the eigenvalue matrix,

00:26:12.860 --> 00:26:16.990
and here I have Q inverse.

00:26:16.990 --> 00:26:20.300
But there's another
little way to write it

00:26:20.300 --> 00:26:24.970
and it's terrifically important
in mechanics and dynamics,

00:26:24.970 --> 00:26:26.600
everywhere.

00:26:26.600 --> 00:26:27.980
It's simple now.

00:26:27.980 --> 00:26:29.200
We know everything.

00:26:29.200 --> 00:26:31.880
Q lambda what?

00:26:31.880 --> 00:26:37.660
Q transpose.

00:26:37.660 --> 00:26:40.640
Do you see the
beauty of that form?

00:26:40.640 --> 00:26:48.190
That's called the principal
axis theorem in mechanics.

00:26:48.190 --> 00:26:50.680
It's called the spectral
theorem in mathematics.

00:26:50.680 --> 00:26:55.170
It's diagonalization, it's
quantum mechanics, everything.

00:26:55.170 --> 00:26:58.300
Any time you have
a symmetric matrix

00:26:58.300 --> 00:27:04.000
there's the wonderful
statement of how it breaks up

00:27:04.000 --> 00:27:07.440
when you look at its
orthonormal eigenvectors

00:27:07.440 --> 00:27:10.160
and its real eigenvalues.

00:27:10.160 --> 00:27:17.030
Do you see that once again
the symmetry has reappeared

00:27:17.030 --> 00:27:19.560
in the three factors?

00:27:19.560 --> 00:27:21.730
The symmetry has
reappeared in the fact

00:27:21.730 --> 00:27:25.740
that this vector is the
transpose of this one.

00:27:25.740 --> 00:27:34.320
We saw that for elimination
when these were triangular.

00:27:34.320 --> 00:27:40.760
That makes me remember what
we had in a different context,

00:27:40.760 --> 00:27:46.400
in the elimination when things
were triangular we had K=L*D*L

00:27:46.400 --> 00:27:48.540
transpose.

00:27:48.540 --> 00:27:55.430
I just squeezed that in to ask
you to sort of think of the two

00:27:55.430 --> 00:27:58.730
as two wonderful pieces
of linear algebra

00:27:58.730 --> 00:28:04.340
in such a perfect
shorthand, perfect notation.

00:28:04.340 --> 00:28:07.450
This was triangular
times the pivot matrix

00:28:07.450 --> 00:28:10.020
times the upper triangular.

00:28:10.020 --> 00:28:13.550
This is orthogonal times
the eigenvalue matrix

00:28:13.550 --> 00:28:17.020
times its transpose.

00:28:17.020 --> 00:28:20.130
And the key point
here was triangular

00:28:20.130 --> 00:28:28.020
and the key point
here is orthogonal.

00:28:28.020 --> 00:28:31.480
That took some time,
but it had to be done.

00:28:31.480 --> 00:28:33.440
This is the right
way to understand.

00:28:33.440 --> 00:28:37.910
That the central theme, it's a
highlight of a linear algebra

00:28:37.910 --> 00:28:42.140
course and we just
went straight to it.

00:28:42.140 --> 00:28:50.890
And now what I wanted to do
was look now at the special K.

00:28:50.890 --> 00:28:56.980
Oh, that's an awful pun.

00:28:56.980 --> 00:29:03.850
The special matrices that we
have, so those are n by n.

00:29:03.850 --> 00:29:06.930
And as I said last
time, usually it's

00:29:06.930 --> 00:29:10.180
not very likely that we
find all the eigenvalues

00:29:10.180 --> 00:29:16.780
and eigenvectors of this family
of bigger and bigger matrices.

00:29:16.780 --> 00:29:19.756
So now I'm going to
specialize to my n

00:29:19.756 --> 00:29:24.980
by n matrix K equals
twos down the diagonal,

00:29:24.980 --> 00:29:30.320
minus ones above and
minus ones below.

00:29:30.320 --> 00:29:32.560
What are the eigenvalues
of that matrix

00:29:32.560 --> 00:29:36.370
and what are the eigenvectors?

00:29:36.370 --> 00:29:39.330
How to tackle that?

00:29:39.330 --> 00:29:44.750
The best way is the way
we've done with the inverse

00:29:44.750 --> 00:29:47.780
and other ways of
understanding K,

00:29:47.780 --> 00:29:52.270
was to compare it with
the continuous problem.

00:29:52.270 --> 00:29:56.950
So this is a big matrix
which is a second difference

00:29:56.950 --> 00:29:59.820
matrix, fixed-fixed.

00:29:59.820 --> 00:30:04.060
Everybody remembers that the
boundary conditions associated

00:30:04.060 --> 00:30:05.790
with this are fixed-fixed.

00:30:05.790 --> 00:30:12.340
I want to ask you to look at
the corresponding differential

00:30:12.340 --> 00:30:13.550
equation.

00:30:13.550 --> 00:30:17.530
So you may not have
thought about eigenvectors

00:30:17.530 --> 00:30:19.490
of differential equations.

00:30:19.490 --> 00:30:21.770
And maybe I have to
call them eigenfunctions

00:30:21.770 --> 00:30:24.210
but the idea doesn't
change one bit.

00:30:24.210 --> 00:30:29.290
So what shall I look at?

00:30:29.290 --> 00:30:32.230
K corresponds to what?

00:30:32.230 --> 00:30:36.770
Continuous
differential business,

00:30:36.770 --> 00:30:40.200
what derivative, what?

00:30:40.200 --> 00:30:42.750
So I would like to
look at Ky=lambda*y.

00:30:46.550 --> 00:30:48.390
I'm looking for
the y's and lambdas

00:30:48.390 --> 00:30:54.510
and the way I'm going to
get them is to look at,

00:30:54.510 --> 00:30:56.850
what did you say it was?

00:30:56.850 --> 00:31:00.950
K, now I'm going to write down
a differential equation that's

00:31:00.950 --> 00:31:05.910
like this but we'll
solve it quickly.

00:31:05.910 --> 00:31:07.570
So what will it be?

00:31:07.570 --> 00:31:11.490
K is like, tell me again.

00:31:11.490 --> 00:31:17.490
Second derivative of y
with respect to x squared.

00:31:17.490 --> 00:31:20.650
And there's one more thing
you have to remember.

00:31:20.650 --> 00:31:22.610
Minus.

00:31:22.610 --> 00:31:25.820
And here we have lambda*y(x).

00:31:32.240 --> 00:31:36.860
That's an eigenvalue
and an eigenfunction

00:31:36.860 --> 00:31:40.660
that we're looking at for
this differential equation.

00:31:40.660 --> 00:31:44.180
Now there's another thing
you have to remember.

00:31:44.180 --> 00:31:48.200
And you'll know what it
is and you'll tell me.

00:31:48.200 --> 00:31:51.130
I could look for
all the solutions.

00:31:51.130 --> 00:31:53.770
Well, let me
momentarily do that.

00:31:53.770 --> 00:32:00.650
What functions have minus
the second derivative is

00:32:00.650 --> 00:32:02.580
a multiple of the function?

00:32:02.580 --> 00:32:05.380
Can you just tell me a few?

00:32:05.380 --> 00:32:07.250
Sine and cosine.

00:32:07.250 --> 00:32:10.350
I mean this is a fantastic
eigenvalue problem

00:32:10.350 --> 00:32:18.210
because its solutions
are sines and cosines.

00:32:18.210 --> 00:32:22.570
And of course we could combine
them into exponentials.

00:32:22.570 --> 00:32:29.810
We could have sine(omega*x)
or cos(omega*x) or we could

00:32:29.810 --> 00:32:33.480
combine those into
e^(i*omega*x),

00:32:33.480 --> 00:32:36.790
would be a combination of
those, or e^(-i*omega*x).

00:32:39.310 --> 00:32:45.400
Those are combinations of
these, so those are not new.

00:32:45.400 --> 00:32:47.750
We've gotten lots
of eigenfunctions.

00:32:47.750 --> 00:32:51.600
Oh, for every frequency omega
this solves the equation.

00:32:51.600 --> 00:32:54.100
What's the eigenvalue?

00:32:54.100 --> 00:32:57.710
If you guess the eigenfunction
you've got the eigenvalue just

00:32:57.710 --> 00:32:59.850
by seeing what happens.

00:32:59.850 --> 00:33:05.040
So what would the eigenvalue be?

00:33:05.040 --> 00:33:06.470
Tell me again.

00:33:06.470 --> 00:33:07.580
Omega squared.

00:33:07.580 --> 00:33:11.040
Because I take the second
derivative of the sine, that'll

00:33:11.040 --> 00:33:14.520
give me the cosine back to the
sine, omega squared comes out,

00:33:14.520 --> 00:33:17.160
omega comes out twice.

00:33:17.160 --> 00:33:19.440
Comes out with a minus
sign from the cosine

00:33:19.440 --> 00:33:25.480
and that minus sign is
just right to make it plus.

00:33:25.480 --> 00:33:27.700
Lambda is omega squared.

00:33:27.700 --> 00:33:29.470
So omega squared.

00:33:29.470 --> 00:33:31.680
All the way of course.

00:33:31.680 --> 00:33:38.080
Those are the eigenvalues.

00:33:38.080 --> 00:33:41.880
All our differential examples
had something more than just

00:33:41.880 --> 00:33:43.530
the differential equation.

00:33:43.530 --> 00:33:48.240
What's the additional thing that
a differential equation comes

00:33:48.240 --> 00:33:49.690
with?

00:33:49.690 --> 00:33:51.990
Boundary conditions.

00:33:51.990 --> 00:33:53.530
With boundary conditions.

00:33:53.530 --> 00:33:55.360
Otherwise we got too many.

00:33:55.360 --> 00:33:58.520
I mean we don't want
all of these guys.

00:33:58.520 --> 00:34:00.580
What boundary conditions?

00:34:00.580 --> 00:34:03.590
If we're thinking about
K, our boundary conditions

00:34:03.590 --> 00:34:09.530
should be fixed and fixed.

00:34:09.530 --> 00:34:11.930
So that's the full problem.

00:34:11.930 --> 00:34:17.060
This is part of the problem
not just an afterthought.

00:34:17.060 --> 00:34:21.710
Now these conditions,
that will be perfect.

00:34:21.710 --> 00:34:25.420
Instead of having all
these sines and cosines

00:34:25.420 --> 00:34:33.740
we're going to narrow down
to a family that satisfies

00:34:33.740 --> 00:34:36.330
the boundary conditions.

00:34:36.330 --> 00:34:40.480
First boundary condition is
it has to be zero at x=0.

00:34:40.480 --> 00:34:43.030
What does that eliminate now?

00:34:43.030 --> 00:34:45.770
Cosines are gone,
keeps the sines.

00:34:45.770 --> 00:34:49.430
Cosines are gone by that
first boundary condition.

00:34:49.430 --> 00:34:52.390
These are guys that are left.

00:34:52.390 --> 00:34:59.300
I won't deal with these at this
point because I'm down to sines

00:34:59.300 --> 00:35:01.610
already from one
boundary condition.

00:35:01.610 --> 00:35:06.820
And now, the other
boundary condition.

00:35:06.820 --> 00:35:12.620
The other boundary
condition has to at x=1,

00:35:12.620 --> 00:35:16.610
if it's going to work
sin(omega*x) has to be?

00:35:16.610 --> 00:35:22.470
Nope, what do I put now?
sin(omega), right? x is one.

00:35:22.470 --> 00:35:23.820
I'm plugging in here.

00:35:23.820 --> 00:35:26.690
I'm just plugging
in x=1 to satisfy.

00:35:26.690 --> 00:35:30.260
And it has to equal zero.

00:35:30.260 --> 00:35:37.590
So that means, that
pins down omega.

00:35:37.590 --> 00:35:39.430
Doesn't give me just
one omega, well tell me

00:35:39.430 --> 00:35:43.280
one omega that's okay then.

00:35:43.280 --> 00:35:45.920
The first omega that
occurs to you is?

00:35:45.920 --> 00:35:47.070
Pi.

00:35:47.070 --> 00:35:48.530
The sine comes back to pi.

00:35:48.530 --> 00:35:50.340
So we've got one. y_1.

00:35:50.340 --> 00:35:54.490
Our first guy is with
omega=pi is sin(pi*x).

00:36:00.540 --> 00:36:03.230
That's our fundamental mode.

00:36:03.230 --> 00:36:08.810
That's the number
one eigenfunction.

00:36:08.810 --> 00:36:12.050
And it is an eigenfunction,
it satisfies the boundary

00:36:12.050 --> 00:36:13.720
condition.

00:36:13.720 --> 00:36:15.500
Everybody would know
its picture, just

00:36:15.500 --> 00:36:17.710
one arch of the sine function.

00:36:17.710 --> 00:36:20.760
And the lambda that
goes with it, lambda_1,

00:36:20.760 --> 00:36:23.230
so this is the first
eigenfunction, what's

00:36:23.230 --> 00:36:25.960
the first eigenvalue?

00:36:25.960 --> 00:36:27.510
Pi squared, right.

00:36:27.510 --> 00:36:29.790
Because omega, we took to be pi.

00:36:29.790 --> 00:36:33.460
So lambda_1 is pi squared.

00:36:33.460 --> 00:36:36.510
We've got one.

00:36:36.510 --> 00:36:39.960
We were able to do it
because we could solve

00:36:39.960 --> 00:36:45.050
this equation in an easy way.

00:36:45.050 --> 00:36:47.450
Ready for a second one?

00:36:47.450 --> 00:36:49.580
What will the next one be?

00:36:49.580 --> 00:36:54.850
The next eigenfunction it's got
to, whatever its frequency is,

00:36:54.850 --> 00:36:57.640
omega, it's got to
have sin(omega)=0.

00:36:57.640 --> 00:37:00.260
What's your choice?

00:37:00.260 --> 00:37:01.530
2pi.

00:37:01.530 --> 00:37:06.950
So the next one is
going to be sin(2pi*x).

00:37:06.950 --> 00:37:10.960
And what will be the eigenvalue
that goes with that guy?

00:37:10.960 --> 00:37:14.900
lambda_2 will be
omega squared, which

00:37:14.900 --> 00:37:20.470
is 2pi squared, 2pi all squared,
so that's four pi squared.

00:37:20.470 --> 00:37:24.550
You see the whole list.

00:37:24.550 --> 00:37:28.600
The sines with these
correct frequencies

00:37:28.600 --> 00:37:33.520
are the eigenfunctions
of the second derivative

00:37:33.520 --> 00:37:36.900
with fixed-fixed
boundary conditions.

00:37:36.900 --> 00:37:39.890
And this is entirely typical.

00:37:39.890 --> 00:37:43.870
We don't have just n of them.

00:37:43.870 --> 00:37:45.770
The list goes on forever, right?

00:37:45.770 --> 00:37:48.680
The list goes on forever
because we're talking here

00:37:48.680 --> 00:37:50.890
about a differential equation.

00:37:50.890 --> 00:37:52.420
A differential
equation's somehow

00:37:52.420 --> 00:37:55.990
like a matrix of infinite size.

00:37:55.990 --> 00:38:04.370
And somehow these sines are the
columns of the infinite size

00:38:04.370 --> 00:38:06.140
eigenvector matrix.

00:38:06.140 --> 00:38:09.230
And these numbers, pi
squared, four pi squared,

00:38:09.230 --> 00:38:13.040
nine pi squared, 16pi
squared are the eigenvalues

00:38:13.040 --> 00:38:22.340
of the infinite
eigenvalue matrix.

00:38:22.340 --> 00:38:24.140
We got those answers quickly.

00:38:24.140 --> 00:38:30.710
And let's just mention that
if I changed to free-fixed

00:38:30.710 --> 00:38:36.240
or to free-free I could repeat.

00:38:36.240 --> 00:38:38.290
I'd get different y's.

00:38:38.290 --> 00:38:41.620
If I have different boundary
conditions I expect to get

00:38:41.620 --> 00:38:43.320
different y's.

00:38:43.320 --> 00:38:50.890
In fact, what would it look like
if that was y'=0 as the left

00:38:50.890 --> 00:38:55.410
end?

00:38:55.410 --> 00:38:59.770
What would you expect the
eigenfunctions to look like?

00:38:59.770 --> 00:39:01.300
They'd be cosines.

00:39:01.300 --> 00:39:02.650
They'd be cosines.

00:39:02.650 --> 00:39:06.040
And then we would have to
adjust the omegas to make

00:39:06.040 --> 00:39:11.410
them come out right
at the right-hand end.

00:39:11.410 --> 00:39:17.570
So this y(0)=0, the
fixed ones gave us sines,

00:39:17.570 --> 00:39:24.710
the free ones give us cosines,
the periodic ones if I had

00:39:24.710 --> 00:39:29.800
y(0)=y(1) so that I'm
just circling around,

00:39:29.800 --> 00:39:36.160
then I would expect these
e^(ikx)'s -- the textbook will,

00:39:36.160 --> 00:39:38.890
so I'm in the eigenvalue
section of course,

00:39:38.890 --> 00:39:42.630
and the textbook lists
the answers for the other

00:39:42.630 --> 00:39:44.040
possibilities.

00:39:44.040 --> 00:39:46.330
Let's go with this one.

00:39:46.330 --> 00:39:53.310
Because this is the one
that corresponds to K.

00:39:53.310 --> 00:40:04.700
We're now ready for
the final moment.

00:40:04.700 --> 00:40:14.030
And it is can we guess the
eigenvectors for the matrix?

00:40:14.030 --> 00:40:18.800
Now I'm going back to
the matrix question.

00:40:18.800 --> 00:40:22.480
And as I say, normally
the answer's no.

00:40:22.480 --> 00:40:24.170
Who could guess?

00:40:24.170 --> 00:40:25.810
But you can always hope.

00:40:25.810 --> 00:40:28.980
You can try.

00:40:28.980 --> 00:40:33.200
So what will I try?

00:40:33.200 --> 00:40:38.640
Here, let me draw
sin(x), sin(pi*x).

00:40:38.640 --> 00:40:42.150
And let me remember
that my matrix K was

00:40:42.150 --> 00:40:45.130
a finite difference matrix.

00:40:45.130 --> 00:40:47.360
Let's make it four by four.

00:40:47.360 --> 00:40:57.450
One, two, three, four let's say.

00:40:57.450 --> 00:40:59.180
What would be the
best I could hope for,

00:40:59.180 --> 00:41:02.970
for the eigenvector,
the first eigenvector?

00:41:02.970 --> 00:41:07.520
I'm hoping that the first
eigenvector of K is very,

00:41:07.520 --> 00:41:10.040
very like the
first eigenfunction

00:41:10.040 --> 00:41:15.950
in the differential equation,
which was this sin(pi*x),

00:41:15.950 --> 00:41:17.430
so that's sin(pi*x).

00:41:17.430 --> 00:41:20.350
Well, what do you hope for?

00:41:20.350 --> 00:41:23.640
What shall I hope
for as the components

00:41:23.640 --> 00:41:29.950
of y_1, the first eigenvector?

00:41:29.950 --> 00:41:32.170
It's almost too good.

00:41:32.170 --> 00:41:34.710
And as far as I know,
basically it only

00:41:34.710 --> 00:41:38.030
happens with these sines
and cosines example.

00:41:38.030 --> 00:41:41.830
These heights, I just
picked these, what I might

00:41:41.830 --> 00:41:46.710
call samples, of the thing.

00:41:46.710 --> 00:41:51.730
Those four values and of course
zero at that end and zero

00:41:51.730 --> 00:41:56.070
at that end, so
because K, the matrix K

00:41:56.070 --> 00:42:01.750
is building in the fixed-fixed.

00:42:01.750 --> 00:42:06.650
These four heights, these four
numbers, those four sines--

00:42:06.650 --> 00:42:12.360
In other words, what I hope
is that for Ky=lambda*y,

00:42:12.360 --> 00:42:16.730
I hope that y_1, the
first eigenvector,

00:42:16.730 --> 00:42:20.160
it'll be sin(pi*x),
but now what is x?

00:42:20.160 --> 00:42:24.100
So this is x here
from zero to one.

00:42:24.100 --> 00:42:27.650
So what's x there,
there, there and there?

00:42:27.650 --> 00:42:31.170
Instead of sin(pi*x),
the whole curve,

00:42:31.170 --> 00:42:33.770
I'm picking out
those four samples.

00:42:33.770 --> 00:42:39.420
So it'll be the sine
of, what'll it be here?

00:42:39.420 --> 00:42:42.080
Pi.

00:42:42.080 --> 00:42:46.880
Pi divided by n+1.

00:42:46.880 --> 00:42:48.800
Which in my picture
would be, we'll

00:42:48.800 --> 00:42:51.790
make it completely explicit.

00:42:51.790 --> 00:42:53.560
Five.

00:42:53.560 --> 00:42:57.630
It's 1/5 away along.

00:42:57.630 --> 00:43:00.650
Maybe I should make these
y's into column vectors

00:43:00.650 --> 00:43:03.540
since we're thinking
of them as columns.

00:43:03.540 --> 00:43:05.054
So here's y_1.

00:43:05.054 --> 00:43:06.970
sin(pi/5), sin(2pi/5),
sin(3pi/5), sin(4pi/5).

00:43:16.710 --> 00:43:21.420
That's the first eigenvector.

00:43:21.420 --> 00:43:22.990
And it works.

00:43:22.990 --> 00:43:27.800
And you could guess
now the general one.

00:43:27.800 --> 00:43:36.140
Well when I say it works, I
haven't checked that it works.

00:43:36.140 --> 00:43:37.630
I better do that.

00:43:37.630 --> 00:43:43.930
But the essential
point is that it works.

00:43:43.930 --> 00:43:46.620
I may not even do it today.

00:43:46.620 --> 00:43:50.830
So, in fact, tell me
the second eigenvector.

00:43:50.830 --> 00:43:55.840
Or tell me the second
eigenfunction over here.

00:43:55.840 --> 00:43:57.540
What's the second eigenfunction?

00:43:57.540 --> 00:44:02.830
Let me draw it with
this green chalk.

00:44:02.830 --> 00:44:06.440
So I'm going to draw y_2.

00:44:06.440 --> 00:44:09.720
Now what does y_2
look like? sin(2pi*x).

00:44:09.720 --> 00:44:13.230
What's the new picture here?

00:44:13.230 --> 00:44:16.910
It goes up.

00:44:16.910 --> 00:44:18.950
What does it do?

00:44:18.950 --> 00:44:24.620
By here it's got
back, oh no, damn.

00:44:24.620 --> 00:44:27.670
I would've been better with
three points in the middle,

00:44:27.670 --> 00:44:30.860
but it's correct.

00:44:30.860 --> 00:44:32.860
It comes down here.

00:44:32.860 --> 00:44:33.860
Right?

00:44:33.860 --> 00:44:37.250
That's sin(2pi*x).

00:44:37.250 --> 00:44:46.310
That's halfway along.

00:44:46.310 --> 00:44:48.220
I'll finish this guy.

00:44:48.220 --> 00:44:56.180
This'll be sin(2pi/5),
sin(4pi/5).

00:44:56.180 --> 00:44:58.540
See I'm sampling
this same thing.

00:44:58.540 --> 00:45:01.620
I'm sampling 2pi*x
at those same points.

00:45:01.620 --> 00:45:05.300
sin(6pi/5) and sin(8pi/5).

00:45:12.410 --> 00:45:15.720
Maybe let's accept
this as correct.

00:45:15.720 --> 00:45:17.270
It really works.

00:45:17.270 --> 00:45:19.250
It's the next eigenvector.

00:45:19.250 --> 00:45:23.200
And then there's a third one
and then there's a fourth one.

00:45:23.200 --> 00:45:28.120
And how many are
there? n usually.

00:45:28.120 --> 00:45:32.870
And in my case, what is n in
the picture I've drawn? n here

00:45:32.870 --> 00:45:35.110
is four.

00:45:35.110 --> 00:45:39.550
One, two, three, four. n is four
in that picture and that means

00:45:39.550 --> 00:45:41.250
that I'm dividing by n+1.

00:45:45.730 --> 00:45:49.290
That's really sin(pi*h).

00:45:49.290 --> 00:45:53.410
You remember I used
h as the step size.

00:45:53.410 --> 00:45:58.630
So h is 1/5, 1/(n+1), 1/5.

00:45:58.630 --> 00:46:03.810
So it's sin(pi*h), sin(2pi*h),
4pi*h-- 3pi*h, 4pi*h.

00:46:03.810 --> 00:46:07.980
Here's 2, sin(2pi*h),
sin(4pi*h), sin(6pi*h),

00:46:07.980 --> 00:46:08.480
sin(8pi*h).

00:46:15.670 --> 00:46:18.790
So I have two things to do.

00:46:18.790 --> 00:46:22.890
One is to remember what is the
remarkable property of these

00:46:22.890 --> 00:46:23.390
y's.

00:46:23.390 --> 00:46:26.380
So there's a y
that we've guessed.

00:46:26.380 --> 00:46:28.050
Right now you're
taking my word for it

00:46:28.050 --> 00:46:32.500
that it is the eigenvector
and this is the next one.

00:46:32.500 --> 00:46:34.850
I copied them out
of those functions.

00:46:34.850 --> 00:46:38.110
And just remind me, what
is it that I'm claiming

00:46:38.110 --> 00:46:42.190
to be true about y_1 and y_2.

00:46:42.190 --> 00:46:47.120
They are orthogonal,
there are orthogonal.

00:46:47.120 --> 00:46:52.330
Well to check that I'd
have to do some trig stuff.

00:46:52.330 --> 00:46:56.270
But what I was going to
do was come over here

00:46:56.270 --> 00:47:03.540
and say this was a symmetric
differential equation.

00:47:03.540 --> 00:47:07.610
We found its eigenfunctions.

00:47:07.610 --> 00:47:11.090
What do you think's
up with those?

00:47:11.090 --> 00:47:13.300
Those are orthogonal too.

00:47:13.300 --> 00:47:18.490
So this would be a
key fact in any sort

00:47:18.490 --> 00:47:24.530
of advanced applied math is
that the sine function is

00:47:24.530 --> 00:47:28.080
orthogonal to the sin(2x).

00:47:28.080 --> 00:47:30.390
That function as
orthogonal to this one.

00:47:30.390 --> 00:47:33.680
And actually that's what
makes the whole world

00:47:33.680 --> 00:47:36.320
of Fourier series work.

00:47:36.320 --> 00:47:40.610
So that was really
a wonderful fact.

00:47:40.610 --> 00:47:42.810
That this is orthogonal to this.

00:47:42.810 --> 00:47:47.740
Now you may, quite reasonably,
ask what do I mean by that?

00:47:47.740 --> 00:47:52.115
What does it mean for two
functions to be orthogonal?

00:47:52.115 --> 00:47:53.990
As long as we're getting
all these parallels,

00:47:53.990 --> 00:47:55.800
let's get that one too.

00:47:55.800 --> 00:47:57.890
I claim that this
function, which is this,

00:47:57.890 --> 00:48:02.350
is orthogonal to this function.

00:48:02.350 --> 00:48:05.200
What does that mean?

00:48:05.200 --> 00:48:08.200
What should these
functions-- Could I write

00:48:08.200 --> 00:48:11.970
dot or transpose or something?

00:48:11.970 --> 00:48:15.670
But now I'm doing
it for functions.

00:48:15.670 --> 00:48:21.700
I just want you to see
the complete analogy.

00:48:21.700 --> 00:48:26.500
So for vectors, what did I do?

00:48:26.500 --> 00:48:29.800
If I take a dot product I
multiply the first component

00:48:29.800 --> 00:48:32.050
times the first component,
second component times

00:48:32.050 --> 00:48:33.630
the second, so on, so on.

00:48:33.630 --> 00:48:36.127
Now what'll I do for functions?

00:48:36.127 --> 00:48:37.960
I multiply sin(pi*x) *
sin(2pi*x) at each x.

00:48:42.300 --> 00:48:44.400
Of course I've got a
whole range of x's.

00:48:44.400 --> 00:48:46.620
And then what do I do?

00:48:46.620 --> 00:48:48.340
I integrate.

00:48:48.340 --> 00:48:49.800
I can't add.

00:48:49.800 --> 00:48:52.770
I integrate instead.

00:48:52.770 --> 00:48:58.330
So I integrate one function
sin(pi*x) against the other

00:48:58.330 --> 00:49:06.060
function, sin(2pi*x), dx, and
I integrate from zero to one

00:49:06.060 --> 00:49:08.350
and the answer comes out zero.

00:49:08.350 --> 00:49:09.820
The answer comes out zero.

00:49:09.820 --> 00:49:13.310
The sine functions
are orthogonal.

00:49:13.310 --> 00:49:15.870
The sines are
orthogonal functions.

00:49:15.870 --> 00:49:19.610
The sine vectors are
orthogonal vectors.

00:49:19.610 --> 00:49:26.420
I normalize to length one and
they go right into my Q. So

00:49:26.420 --> 00:49:29.400
if I multiply, if I did that
times that, that dot product

00:49:29.400 --> 00:49:31.310
would turn out to be zero.

00:49:31.310 --> 00:49:35.200
If I had been a
little less ambitious

00:49:35.200 --> 00:49:39.870
and taken n to be two
or three or something

00:49:39.870 --> 00:49:41.390
we would have seen
it completely.

00:49:41.390 --> 00:49:48.920
But maybe doing
with four is okay.

00:49:48.920 --> 00:49:55.650
So great lecture
except for that.

00:49:55.650 --> 00:49:58.610
Didn't get there.

00:49:58.610 --> 00:50:03.130
So Wednesday's lecture is
sort of the bringing all

00:50:03.130 --> 00:50:07.610
these pieces together, positive
eigenvalues, positive pivots,

00:50:07.610 --> 00:50:09.120
positive definite.

00:50:09.120 --> 00:50:11.700
So come on Wednesday please.

00:50:11.700 --> 00:50:13.720
Come Wednesday.

00:50:13.720 --> 00:50:15.720
And Wednesday
afternoon I'll have

00:50:15.720 --> 00:50:18.160
the review session as usual.