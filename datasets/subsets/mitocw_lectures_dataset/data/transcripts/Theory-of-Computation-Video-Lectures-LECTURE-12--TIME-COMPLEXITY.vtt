WEBVTT

00:00:00.000 --> 00:00:01.980
[SQUEAKING]

00:00:01.980 --> 00:00:03.465
[RUSTLING]

00:00:03.465 --> 00:00:06.435
[CLICKING]

00:00:24.397 --> 00:00:25.980
MICHAEL SIPSER: So
welcome, everybody.

00:00:25.980 --> 00:00:27.995
Welcome back.

00:00:27.995 --> 00:00:29.620
Let's get started
with today's lecture.

00:00:33.580 --> 00:00:36.730
Where were we?

00:00:36.730 --> 00:00:41.770
On Tuesday, we
covered, the main topic

00:00:41.770 --> 00:00:48.100
was the recursion theorem,
which allows programs

00:00:48.100 --> 00:00:49.750
to self-reference.

00:00:49.750 --> 00:00:52.660
And we saw some
applications of that, too.

00:00:52.660 --> 00:00:57.680
So we gave a new proof
that ATM is undecidable.

00:00:57.680 --> 00:00:59.920
We looked at this language
of minimal Turing machine

00:00:59.920 --> 00:01:01.660
descriptions.

00:01:01.660 --> 00:01:04.989
And we had a short digression
into mathematical logic,

00:01:04.989 --> 00:01:08.230
where we looked at how
one shows that there

00:01:08.230 --> 00:01:11.320
are true, but
unprovable, statements

00:01:11.320 --> 00:01:13.480
in any reasonable formal system.

00:01:16.160 --> 00:01:19.730
So today, we're going
to shift gears entirely.

00:01:19.730 --> 00:01:25.020
And we're moving into the
second half of the course, where

00:01:25.020 --> 00:01:30.000
we are beginning a study
of computational complexity

00:01:30.000 --> 00:01:31.080
theory.

00:01:31.080 --> 00:01:34.140
And we'll say a
little bit about that

00:01:34.140 --> 00:01:37.020
during the course of
the lecture, of course.

00:01:37.020 --> 00:01:39.510
But the main things
that we are going

00:01:39.510 --> 00:01:43.530
to cover in terms of
content that you will need

00:01:43.530 --> 00:01:48.990
is defining the complexity
classes and the class P.

00:01:48.990 --> 00:01:51.150
And we'll prove a few
theorems along the way.

00:01:51.150 --> 00:01:55.490
But that's the main
objective of today's lecture.

00:01:55.490 --> 00:01:58.430
Computability theory, which was
the subject of the first half

00:01:58.430 --> 00:02:01.520
of the course, and which is
what the midterm exam is going

00:02:01.520 --> 00:02:06.260
to cover, was a subject
that was an active area

00:02:06.260 --> 00:02:12.390
of mathematical study in the
first part of the 20th century.

00:02:12.390 --> 00:02:16.250
It really got-- it
really dates back

00:02:16.250 --> 00:02:18.770
into the late 19th
century, in fact,

00:02:18.770 --> 00:02:22.130
when people were trying to
figure out how to formalize

00:02:22.130 --> 00:02:25.790
mathematical reasoning.

00:02:25.790 --> 00:02:29.510
But it really got
going in the 1930s

00:02:29.510 --> 00:02:32.900
with the work of Godel,
and Church, and Turing,

00:02:32.900 --> 00:02:37.400
who really formalized
for the first time what

00:02:37.400 --> 00:02:38.540
we mean by algorithm.

00:02:38.540 --> 00:02:41.750
And that allowed the study
of algorithms to really get

00:02:41.750 --> 00:02:43.250
started.

00:02:43.250 --> 00:02:45.470
And it had its impact,
as I mentioned,

00:02:45.470 --> 00:02:49.040
on the actual design,
building, and thinking

00:02:49.040 --> 00:02:50.720
about real computers.

00:02:53.540 --> 00:02:55.970
The main question, if you
kind of boil the subject

00:02:55.970 --> 00:03:01.940
down to a single question, is
some language decidable or not.

00:03:01.940 --> 00:03:04.640
In complexity theory,
which got started

00:03:04.640 --> 00:03:08.600
kind of when computability
theory more or less wrapped up

00:03:08.600 --> 00:03:10.683
as a subject, largely
because they answered many

00:03:10.683 --> 00:03:13.100
of the questions that they--
they answered pretty much all

00:03:13.100 --> 00:03:14.820
of the questions that
they were asking.

00:03:14.820 --> 00:03:19.040
So there really aren't
interesting unsolved questions

00:03:19.040 --> 00:03:21.290
left in that field.

00:03:21.290 --> 00:03:23.540
And you really need
mathematical questions

00:03:23.540 --> 00:03:26.900
to keep a subject alive,
unsolved questions.

00:03:26.900 --> 00:03:29.910
So complexity theory got
its start in the 1960s.

00:03:29.910 --> 00:03:32.750
And it continues on as an
active area of research

00:03:32.750 --> 00:03:34.880
to the present day.

00:03:34.880 --> 00:03:36.740
And I guess if you
could boil it down,

00:03:36.740 --> 00:03:41.390
it would be is a language
decidable with some restriction

00:03:41.390 --> 00:03:43.910
on the resources, such
as the amount of time,

00:03:43.910 --> 00:03:46.100
or memory, or some other--

00:03:46.100 --> 00:03:48.740
or some other kinds of resources
that you might provide,

00:03:48.740 --> 00:03:50.630
randomness, and so on?

00:03:50.630 --> 00:03:54.770
All of those are within the
area of computational complexity

00:03:54.770 --> 00:03:56.890
theory.

00:03:56.890 --> 00:04:00.210
So let's get ourselves
started with an example.

00:04:00.210 --> 00:04:03.090
Here is the language that
we've looked at in the past, a

00:04:03.090 --> 00:04:04.830
to the k, b to the k.

00:04:04.830 --> 00:04:10.980
And let's look at it now from
the perspective of complexity.

00:04:10.980 --> 00:04:12.690
All of the languages
that we're going

00:04:12.690 --> 00:04:14.340
to be studying in
complexity are all

00:04:14.340 --> 00:04:16.570
going to be decidable languages.

00:04:16.570 --> 00:04:19.260
So the question
of undecidability

00:04:19.260 --> 00:04:22.200
in complexity theory is
not really of interest.

00:04:22.200 --> 00:04:24.540
It's all decidable
languages, but the question

00:04:24.540 --> 00:04:26.430
is how decidable.

00:04:26.430 --> 00:04:29.055
What sort of resources do
you need to do the deciding?

00:04:31.660 --> 00:04:37.130
So for this language A,
how many steps are needed?

00:04:37.130 --> 00:04:39.530
Well, we're going to spend
a little time just kind

00:04:39.530 --> 00:04:43.550
of setting up the
definitions of the subject

00:04:43.550 --> 00:04:46.100
and kind of motivating them.

00:04:46.100 --> 00:04:49.280
So for this language A, when I
ask how many steps are needed,

00:04:49.280 --> 00:04:52.900
well, it's going to depend upon
which input you have in mind.

00:04:52.900 --> 00:04:57.520
Some inputs might require
more steps than others.

00:04:57.520 --> 00:05:00.570
So the way we're going
to set the subject up,

00:05:00.570 --> 00:05:04.260
which is the standard way
that people in this field

00:05:04.260 --> 00:05:09.810
look at it, and I think that
applies to lots of examples

00:05:09.810 --> 00:05:12.390
outside as well,
is that we're going

00:05:12.390 --> 00:05:15.810
to kind of group all of the
inputs of the same length

00:05:15.810 --> 00:05:17.400
together.

00:05:17.400 --> 00:05:23.430
And look at the maximum cost,
the maximum number of steps

00:05:23.430 --> 00:05:27.330
you need, to solve any one of
those inputs of a given length.

00:05:27.330 --> 00:05:29.202
And we'll do that
for each length.

00:05:29.202 --> 00:05:30.660
And the way we're
going to frame it

00:05:30.660 --> 00:05:33.630
is in terms of giving
a maximum, or what's

00:05:33.630 --> 00:05:37.710
called an upper bound, on
the amount of time that you

00:05:37.710 --> 00:05:43.590
need to solve all of
those inputs of length n.

00:05:43.590 --> 00:05:46.620
That's what's sometimes
called worst-case complexity.

00:05:46.620 --> 00:05:48.280
I'm sure many of you
seen this already.

00:05:48.280 --> 00:05:51.710
But just to make sure
we're all together on this,

00:05:51.710 --> 00:05:54.060
you might contrast
that, for example,

00:05:54.060 --> 00:05:56.160
with what's called
average case complexity.

00:05:56.160 --> 00:05:58.770
Where instead of looking
at the most difficult case

00:05:58.770 --> 00:06:01.320
among all inputs
of length n, you

00:06:01.320 --> 00:06:03.137
take the average of
all inputs of length n.

00:06:03.137 --> 00:06:05.220
And then you have to--
then it's a little bit more

00:06:05.220 --> 00:06:06.480
complicated, because
then you need

00:06:06.480 --> 00:06:08.700
to have a probability
distribution on those inputs

00:06:08.700 --> 00:06:09.243
and so on.

00:06:09.243 --> 00:06:11.160
We're not going to look
at it, in this course,

00:06:11.160 --> 00:06:12.030
from that perspective.

00:06:12.030 --> 00:06:13.260
We're only going to
be looking at what's

00:06:13.260 --> 00:06:14.520
called worst-case complexity.

00:06:17.850 --> 00:06:26.060
So let's begin, then, by
looking at this in more detail

00:06:26.060 --> 00:06:31.850
and taking as our
starting point the theorem

00:06:31.850 --> 00:06:36.580
that says that on a one
tape Turing machine, which

00:06:36.580 --> 00:06:41.740
is deciding this language
A, a to the k, b to the k,

00:06:41.740 --> 00:06:45.760
you can do this on a one
tape Turing machine, M,

00:06:45.760 --> 00:06:47.620
we're calling it.

00:06:47.620 --> 00:06:54.100
In at most some constant
times n squared steps,

00:06:54.100 --> 00:07:00.520
for any input of length n,
where the constant is going

00:07:00.520 --> 00:07:02.170
to be fixed independent of it.

00:07:06.020 --> 00:07:09.920
So this is going to be--

00:07:14.780 --> 00:07:18.430
having a constant in--

00:07:18.430 --> 00:07:21.927
factor in the complexity
is going to come up often.

00:07:21.927 --> 00:07:24.010
And so instead of saying
this over and over again,

00:07:24.010 --> 00:07:27.670
we're going to use
a notation that m

00:07:27.670 --> 00:07:30.760
uses order n squared steps.

00:07:30.760 --> 00:07:33.160
I'm sure many of you seen
that terminology as well.

00:07:33.160 --> 00:07:35.170
But just for the
purposes of making

00:07:35.170 --> 00:07:37.330
sure we're all
together on that, there

00:07:37.330 --> 00:07:40.420
is this big O and
little o notation.

00:07:40.420 --> 00:07:43.480
I'm expecting you to
be familiar with that.

00:07:43.480 --> 00:07:48.830
Big O is when you apply to
functions, as it's done.

00:07:48.830 --> 00:07:55.070
You say f is big O of g, as
for two functions f and g.

00:07:55.070 --> 00:07:59.000
It's basically if f is
less than or equal to g,

00:07:59.000 --> 00:08:01.780
if you're ignoring
constant factors.

00:08:01.780 --> 00:08:06.850
And you say f is little o of
g if f is strictly less than g

00:08:06.850 --> 00:08:08.410
if you're ignoring
constant factors.

00:08:08.410 --> 00:08:11.120
That's kind of one sort of
informal way of looking at it.

00:08:11.120 --> 00:08:13.930
The precise definition is
given up there on the slide.

00:08:13.930 --> 00:08:15.490
And if you haven't
seen it before,

00:08:15.490 --> 00:08:18.280
make sure you look
at it in the book,

00:08:18.280 --> 00:08:22.063
where it's all carefully
described and defined.

00:08:22.063 --> 00:08:23.980
So that you're comfortable
with these notions.

00:08:23.980 --> 00:08:25.360
Because it's
really-- we're going

00:08:25.360 --> 00:08:28.480
to be using this without
any further discussion

00:08:28.480 --> 00:08:29.260
from here on.

00:08:32.360 --> 00:08:35.059
So let's get to the proof,
then, of this theorem

00:08:35.059 --> 00:08:39.730
that you can do the language
A in order n squared steps.

00:08:39.730 --> 00:08:40.659
Not super hard.

00:08:40.659 --> 00:08:43.150
I think if I asked you to
come up with an algorithm

00:08:43.150 --> 00:08:44.800
to solve A, this
would be the algorithm

00:08:44.800 --> 00:08:46.690
that you would find basically.

00:08:46.690 --> 00:08:51.040
First, you would start off by
scanning the input w to make

00:08:51.040 --> 00:08:53.150
sure it's of the right form.

00:08:53.150 --> 00:08:58.580
So a run of a's followed by
a run of b's of some lengths.

00:08:58.580 --> 00:09:00.920
And if it's not of
that form, then you're

00:09:00.920 --> 00:09:03.560
going to reject right away.

00:09:03.560 --> 00:09:05.960
The next thing you'll do
is then go to a repeat

00:09:05.960 --> 00:09:09.050
loop in the Turing machine.

00:09:09.050 --> 00:09:13.190
And if you imagine, here is your
machine, here is the input w,

00:09:13.190 --> 00:09:16.615
you're going to go through
that repeating repeatedly.

00:09:16.615 --> 00:09:18.990
Of course, you can do this in
a number of different ways.

00:09:18.990 --> 00:09:23.090
But here's the way I have in
mind for you, on this slide,

00:09:23.090 --> 00:09:24.840
anyway.

00:09:24.840 --> 00:09:27.180
We're going to scan
the entire tape,

00:09:27.180 --> 00:09:35.050
crossing off a single a
and a single b on a scan.

00:09:35.050 --> 00:09:37.330
And then you're going to
keep doing that until you've

00:09:37.330 --> 00:09:40.360
crossed off everything.

00:09:40.360 --> 00:09:44.280
Unless you run out of a's
or you run out of b's.

00:09:44.280 --> 00:09:47.610
In that case, you're
going to reject.

00:09:47.610 --> 00:09:49.890
If you run out of a's or
b's before you run out

00:09:49.890 --> 00:09:54.120
of the other type, then you
know that you started out

00:09:54.120 --> 00:09:55.530
with an unequal number.

00:09:55.530 --> 00:09:57.360
And so the machine
is going to reject.

00:10:00.080 --> 00:10:03.560
If you've managed to cross them
all off without running out

00:10:03.560 --> 00:10:06.510
of one before the other,
then you'll accept.

00:10:06.510 --> 00:10:08.350
I know this is kind of obvious.

00:10:08.350 --> 00:10:10.980
But I think it's important to
get us all together on this

00:10:10.980 --> 00:10:12.160
at the beginning.

00:10:12.160 --> 00:10:15.840
So here's a little animation of
the Turing machine doing that.

00:10:19.590 --> 00:10:21.270
I'm not showing the
motion of the head.

00:10:21.270 --> 00:10:23.940
But you imagine the head
scanning back and forth,

00:10:23.940 --> 00:10:28.440
crossing off these a's and b's,
one a and one b on each pass,

00:10:28.440 --> 00:10:29.700
until they're all crossed off.

00:10:29.700 --> 00:10:31.230
And then it accepts.

00:10:31.230 --> 00:10:33.750
Unless of course, it
runs out of a's or b's

00:10:33.750 --> 00:10:36.570
before the other
type, then it rejects.

00:10:36.570 --> 00:10:40.990
OK, now let's do a very quick,
informal analysis of how

00:10:40.990 --> 00:10:42.550
much time this has taken.

00:10:42.550 --> 00:10:45.250
So the very first stage, I'm
calling each of these things

00:10:45.250 --> 00:10:49.270
stages of the Turing
machine to distinguish them

00:10:49.270 --> 00:10:51.310
from the steps of
the Turing machine,

00:10:51.310 --> 00:10:55.040
which are the individual
transition function moves.

00:10:55.040 --> 00:10:58.150
So this is the entire
stage of the machine.

00:10:58.150 --> 00:11:01.570
The very first stage
takes order n steps,

00:11:01.570 --> 00:11:04.980
because you have to make
a scan across the input.

00:11:04.980 --> 00:11:07.393
And then I'm not giving
all the full detail.

00:11:07.393 --> 00:11:09.060
Of course, you're
going to scan and then

00:11:09.060 --> 00:11:11.770
you're going to return the head
back to its starting position.

00:11:11.770 --> 00:11:16.915
I'm not-- that's just going
to be an extra factor of n,

00:11:16.915 --> 00:11:18.210
an extra n.

00:11:18.210 --> 00:11:20.760
And so that's where we're
talking about being order n

00:11:20.760 --> 00:11:23.760
steps for the very first stage.

00:11:23.760 --> 00:11:26.100
And then as you go
through the repeat

00:11:26.100 --> 00:11:28.170
loop, each time you go
through the repeat loop,

00:11:28.170 --> 00:11:31.290
you're going to cross
off one a and one b.

00:11:31.290 --> 00:11:35.130
So that's going to mean you're
going to have to do this

00:11:35.130 --> 00:11:37.740
roughly order-- you're going
have to do this order n times

00:11:37.740 --> 00:11:40.230
in order to cross off
all the a's and b's.

00:11:40.230 --> 00:11:43.710
So there's going to be order n
iterations of this repeat loop.

00:11:43.710 --> 00:11:46.470
Each one of them is going
to, again, require a scan.

00:11:46.470 --> 00:11:51.260
So that's order n steps for
each one of the iterations.

00:11:51.260 --> 00:11:57.640
So adding that all up, the very
top row gives us the order n

00:11:57.640 --> 00:11:59.530
and then we have the
order n iterations

00:11:59.530 --> 00:12:03.320
times order n steps is
order n squared steps.

00:12:03.320 --> 00:12:07.990
And so the sum of
these two is order n

00:12:07.990 --> 00:12:11.230
squared steps due to
the nature of arithmetic

00:12:11.230 --> 00:12:13.660
when you have the
big O notation.

00:12:13.660 --> 00:12:19.220
The dominant term overrides
all of the others.

00:12:19.220 --> 00:12:24.430
So that's, in a
nutshell, how we--

00:12:24.430 --> 00:12:27.010
well, this is our
very first example

00:12:27.010 --> 00:12:31.420
of analyzing the Turing machine
algorithm for a language.

00:12:31.420 --> 00:12:35.530
So let me ask you now whether
there is some other Turing

00:12:35.530 --> 00:12:37.870
machine, some other one
tape Turing machine which

00:12:37.870 --> 00:12:42.790
can do better than this
Turing machine does in terms

00:12:42.790 --> 00:12:44.720
of how much time it takes.

00:12:44.720 --> 00:12:48.510
So one idea that you might
have, instead of crossing off

00:12:48.510 --> 00:12:52.770
a single a or a single b,
maybe you can cross off two

00:12:52.770 --> 00:12:55.710
a's and two b's, or
10 a's and 10 b's.

00:12:55.710 --> 00:12:58.890
Well, that'll cut down the
running time by a factor of 10.

00:12:58.890 --> 00:13:01.020
But from the standpoint
of this theorem,

00:13:01.020 --> 00:13:04.360
it's still going to be an
order n squared algorithm.

00:13:04.360 --> 00:13:09.870
And so that really doesn't
change the amount of time

00:13:09.870 --> 00:13:13.695
used from the perspective of--

00:13:13.695 --> 00:13:15.180
from our perspective,
where we're

00:13:15.180 --> 00:13:17.970
going to be ignoring the
constant factors on the running

00:13:17.970 --> 00:13:20.580
time.

00:13:20.580 --> 00:13:23.570
So I ask you here,
can you do better

00:13:23.570 --> 00:13:26.780
than just improving things
by a constant factor?

00:13:26.780 --> 00:13:28.040
There we go.

00:13:28.040 --> 00:13:34.550
OK, so here's a check-in on
this problem, on the problem A,

00:13:34.550 --> 00:13:36.650
deciding A on a one
tape Turing machine.

00:13:36.650 --> 00:13:41.780
Can we do better
than order n squared,

00:13:41.780 --> 00:13:45.500
as I just described
in that theorem

00:13:45.500 --> 00:13:47.120
in that algorithm
for that theorem?

00:13:47.120 --> 00:13:51.680
Or can you get it
down to n log n?

00:13:51.680 --> 00:13:54.980
Or maybe you can get
it down to order n?

00:13:54.980 --> 00:13:57.020
What do you think?

00:13:57.020 --> 00:13:59.870
Obviously, we're
just getting started.

00:13:59.870 --> 00:14:04.250
But just make your best guess.

00:14:04.250 --> 00:14:06.455
And let me just post
that for you as a poll.

00:14:09.300 --> 00:14:11.897
What's most important to
me is that you understand

00:14:11.897 --> 00:14:13.980
the terminology that we're
using and the way we're

00:14:13.980 --> 00:14:16.440
discussing-- the way
we're talking about it.

00:14:16.440 --> 00:14:19.080
Because that's going
to be setting us

00:14:19.080 --> 00:14:20.970
up for the
definitions that we're

00:14:20.970 --> 00:14:24.930
going to come a little
bit later in the lecture.

00:14:24.930 --> 00:14:27.090
So I'm going to close the poll.

00:14:30.305 --> 00:14:31.930
We're kind of all
over the place on it.

00:14:31.930 --> 00:14:33.790
But that's good.

00:14:36.940 --> 00:14:40.570
Since we haven't really
covered this material yet.

00:14:40.570 --> 00:14:42.370
In fact, B is the
correct answer.

00:14:42.370 --> 00:14:46.480
We can improve this algorithm
down to order n log n,

00:14:46.480 --> 00:14:49.068
but not all the way
down to order n.

00:14:49.068 --> 00:14:51.610
So let me give-- let me show
you how you do it in order n log

00:14:51.610 --> 00:14:54.110
n on the next slide.

00:14:54.110 --> 00:15:00.030
And so here is a one
tape Turing machine

00:15:00.030 --> 00:15:05.790
that can decide A by using only
order n log n steps instead

00:15:05.790 --> 00:15:07.810
of order n squared steps.

00:15:07.810 --> 00:15:10.482
So this is a
significant improvement.

00:15:13.930 --> 00:15:16.770
So I'll describe
the Turing machine.

00:15:16.770 --> 00:15:21.690
Here, again, is the picture
of the machine on an input.

00:15:21.690 --> 00:15:24.210
And the very first
thing I need to say

00:15:24.210 --> 00:15:26.430
is that we're going to scan
to make sure the input is

00:15:26.430 --> 00:15:28.368
of the right form.

00:15:28.368 --> 00:15:29.910
And now, we're going
to-- again, it's

00:15:29.910 --> 00:15:33.660
going to be making repeated
passes over the input.

00:15:33.660 --> 00:15:36.810
But we're going to do it
a little differently now.

00:15:36.810 --> 00:15:39.210
Instead of crossing off a
single a and a single b,

00:15:39.210 --> 00:15:41.970
or some fixed number of a's and
a fixed number of b's, we're

00:15:41.970 --> 00:15:46.630
going to cross off every
other a and every other b.

00:15:46.630 --> 00:15:49.120
And that way, we're
going to essentially cut

00:15:49.120 --> 00:15:51.960
the number of a and b in half.

00:15:51.960 --> 00:15:54.720
And that's why the
number of iterations

00:15:54.720 --> 00:15:59.660
is only going to be a
log, instead of linear.

00:15:59.660 --> 00:16:01.370
So we're going to
cross off every other a

00:16:01.370 --> 00:16:02.210
and every other b.

00:16:05.430 --> 00:16:06.840
And at the same
time, we're going

00:16:06.840 --> 00:16:11.610
to keep track of the
parity, the even/odd parity

00:16:11.610 --> 00:16:15.120
of the number of
a's that we've seen

00:16:15.120 --> 00:16:17.760
and the parity of
the number of b's

00:16:17.760 --> 00:16:22.610
that we've seen that have
not yet been crossed off.

00:16:22.610 --> 00:16:24.860
And we're going to compare
those parities to make sure

00:16:24.860 --> 00:16:26.420
that they agree.

00:16:26.420 --> 00:16:30.380
If they ever disagree, we know
we started off with different

00:16:30.380 --> 00:16:33.870
numbers of a's and b's.

00:16:33.870 --> 00:16:36.120
And I'll illustrate
this in a second,

00:16:36.120 --> 00:16:40.880
just to make sure we
understand this algorithm.

00:16:40.880 --> 00:16:45.080
So I'm going to write down as
a little table of the parities

00:16:45.080 --> 00:16:45.980
that we've seen.

00:16:45.980 --> 00:16:47.810
And I'm going to
illustrate the algorithm

00:16:47.810 --> 00:16:49.850
with a little animation.

00:16:49.850 --> 00:16:53.720
So again, we're now
going to scan across,

00:16:53.720 --> 00:16:59.560
crossing off every other
a, and then every other b.

00:16:59.560 --> 00:17:03.510
But before we get to the b's, we
observe, as we cross these off,

00:17:03.510 --> 00:17:04.710
that we had six a's.

00:17:04.710 --> 00:17:06.150
Now, I'm not saying
we count them.

00:17:06.150 --> 00:17:08.339
We just keep track of
the even/odd parity.

00:17:08.339 --> 00:17:11.250
That can be done in the
finite control of the machine.

00:17:11.250 --> 00:17:13.530
Counting them would
be more complicated.

00:17:13.530 --> 00:17:15.030
But just keeping
track of the parity

00:17:15.030 --> 00:17:18.930
is something that the
finite automaton could do.

00:17:18.930 --> 00:17:21.855
So the parity in this case,
because they were six,

00:17:21.855 --> 00:17:23.966
is going to be even.

00:17:23.966 --> 00:17:25.049
Now, we cross off the b's.

00:17:28.260 --> 00:17:31.110
Same, even parity, now we're
going to return the head back

00:17:31.110 --> 00:17:33.060
to the beginning, I'm
obviously not showing

00:17:33.060 --> 00:17:34.230
the head moving here.

00:17:34.230 --> 00:17:36.420
We return the head
back to the beginning.

00:17:36.420 --> 00:17:39.090
And now, we scan across,
again, crossing off every other

00:17:39.090 --> 00:17:42.690
remaining a and counting the
parities of the remaining a's.

00:17:42.690 --> 00:17:45.540
So here now, it's
going to be this one

00:17:45.540 --> 00:17:48.370
and this one are going
to get crossed off.

00:17:48.370 --> 00:17:51.670
And there were three a's,
so that was odd parity.

00:17:51.670 --> 00:17:56.800
And the same for the b's,
three b's, odd parity.

00:17:56.800 --> 00:17:59.590
And now we return our head
back to the beginning,

00:17:59.590 --> 00:18:04.840
cross again, off every
other a and every other b.

00:18:04.840 --> 00:18:07.720
So that was odd parity,
there was just one.

00:18:07.720 --> 00:18:11.140
Crossing off the b, odd
parity because just one.

00:18:11.140 --> 00:18:13.550
They all agree.

00:18:13.550 --> 00:18:16.890
So the machine is
going to accept.

00:18:16.890 --> 00:18:19.260
Because everything
is now crossed off.

00:18:19.260 --> 00:18:23.500
And the parities
agreed along the way.

00:18:23.500 --> 00:18:25.770
Let me just say for
a second, obviously,

00:18:25.770 --> 00:18:27.810
if you ever get disagreement
on the parities,

00:18:27.810 --> 00:18:31.710
then that the number of
a's and the number of b's

00:18:31.710 --> 00:18:34.020
had to disagree.

00:18:34.020 --> 00:18:37.440
But how do we know that if the
parities always agree that we

00:18:37.440 --> 00:18:40.620
actually did start out with
the same number of a's as b's?

00:18:40.620 --> 00:18:43.230
And that, you could see that
in a number of different ways,

00:18:43.230 --> 00:18:47.940
but perhaps a cute way to
see it is there is actually--

00:18:47.940 --> 00:18:50.760
if you look at these parities ,
here the sequence of parities,

00:18:50.760 --> 00:18:52.450
actually in reverse.

00:18:52.450 --> 00:18:56.700
So if you say odd,
odd, even, and you

00:18:56.700 --> 00:18:58.770
look at the binary
representation

00:18:58.770 --> 00:19:01.440
of the number of
a's, which is six,

00:19:01.440 --> 00:19:04.998
so the binary
representation would be 110.

00:19:04.998 --> 00:19:07.050
The fact that you
get odd, odd, even

00:19:07.050 --> 00:19:10.060
and 110 is not a coincidence.

00:19:10.060 --> 00:19:12.570
In fact, the sequence
of parities in reverse

00:19:12.570 --> 00:19:19.800
that you get is exactly the same
as the binary representation.

00:19:19.800 --> 00:19:22.980
You'd have to confirm
that with a little proof.

00:19:22.980 --> 00:19:24.240
It's not hard.

00:19:24.240 --> 00:19:26.940
But that, once
you have confirmed

00:19:26.940 --> 00:19:32.418
that, you can see that if the
sequence of parities agree,

00:19:32.418 --> 00:19:33.960
then the numbers
have to be the same,

00:19:33.960 --> 00:19:37.800
because the binary
representations agreed.

00:19:37.800 --> 00:19:40.500
OK, so now getting
to the analysis here,

00:19:40.500 --> 00:19:43.170
again, order n steps
to do the check.

00:19:43.170 --> 00:19:45.180
Log n iterations.

00:19:45.180 --> 00:19:47.850
Each scan takes order n steps.

00:19:47.850 --> 00:19:52.950
So the total running time here
is going to be order n log n.

00:19:52.950 --> 00:19:55.200
It's going to be
the log n times n.

00:19:55.200 --> 00:19:58.750
That's where the n
log n comes from.

00:19:58.750 --> 00:20:00.690
Now, question you
might ask, could I

00:20:00.690 --> 00:20:02.100
do even better than that?

00:20:02.100 --> 00:20:06.640
Can I beat n log n by more
than any constant factor?

00:20:06.640 --> 00:20:11.170
So can I do little o of n log n?

00:20:11.170 --> 00:20:12.640
And the answer is no.

00:20:12.640 --> 00:20:15.640
This is the best
possible one tape Turing

00:20:15.640 --> 00:20:17.095
machine for this language.

00:20:19.760 --> 00:20:24.055
So a one tape Turing machine
cannot decide A by using little

00:20:24.055 --> 00:20:27.770
o of n log n steps.

00:20:27.770 --> 00:20:29.290
We're not going to prove that.

00:20:29.290 --> 00:20:31.930
I'm not going to ask you to
be responsible for the proof.

00:20:31.930 --> 00:20:35.710
But in fact, what
you can show is

00:20:35.710 --> 00:20:39.460
that any language that you can
do on a one tape Turing machine

00:20:39.460 --> 00:20:42.850
in the little o of n log n
steps turns out to be regular.

00:20:46.360 --> 00:20:50.100
So you can prove a
rather strong theme here.

00:20:50.100 --> 00:20:52.540
Not super difficult to prove.

00:20:52.540 --> 00:20:54.310
But I don't want to
spend a lot of time

00:20:54.310 --> 00:20:58.360
on proving grounds
for Turing machines.

00:20:58.360 --> 00:21:01.120
Because really the whole
purpose of setting this up

00:21:01.120 --> 00:21:03.760
using Turing machines is to talk
about algorithms in general,

00:21:03.760 --> 00:21:05.290
algorithms in
general, I'm not going

00:21:05.290 --> 00:21:08.140
to be focusing on the nitty
gritty of Turing machines.

00:21:11.200 --> 00:21:15.400
OK so what is my--

00:21:22.040 --> 00:21:24.230
yeah, so I wanted to
just stop and make

00:21:24.230 --> 00:21:27.660
sure that we are together here.

00:21:27.660 --> 00:21:30.230
So a brief pause.

00:21:30.230 --> 00:21:32.240
And feel free to send
me any questions.

00:21:38.330 --> 00:21:39.530
OK, this is a good question.

00:21:39.530 --> 00:21:41.360
If we can keep
track of parities,

00:21:41.360 --> 00:21:47.160
why can't we just keep track
of the number of a's or b's?

00:21:47.160 --> 00:21:49.260
Well, you could keep
track of the parity

00:21:49.260 --> 00:21:50.610
in the finite memory.

00:21:50.610 --> 00:21:53.950
And so you can do that
with effectively no work.

00:21:53.950 --> 00:21:57.010
But the finite memory cannot is
not enough for doing a count up

00:21:57.010 --> 00:22:00.050
to some arbitrarily
large number.

00:22:00.050 --> 00:22:02.870
Now, you could store
the count on the tape.

00:22:02.870 --> 00:22:06.740
But that's going to cost you
time to maintain that counter.

00:22:06.740 --> 00:22:17.000
And so that's not going
to be so simple as keeping

00:22:17.000 --> 00:22:19.790
track of the parity
in the finite memory.

00:22:25.300 --> 00:22:27.370
Somebody is asking if a
star b star is regular.

00:22:27.370 --> 00:22:29.150
Yes, a star b star is regular.

00:22:29.150 --> 00:22:30.880
So what?

00:22:30.880 --> 00:22:33.610
But a to the k, b to the
k, which is our language,

00:22:33.610 --> 00:22:35.008
is not regular.

00:22:35.008 --> 00:22:36.550
That's the language
we're looking at.

00:22:40.410 --> 00:22:45.120
So getting questions about what
happens with multiple tapes.

00:22:45.120 --> 00:22:48.920
We'll talk about
that in a second.

00:22:48.920 --> 00:22:51.740
Yes, we could do an order n
steps on a regular computer,

00:22:51.740 --> 00:22:52.550
sure.

00:22:52.550 --> 00:22:57.810
But for this slide,
anyway, we're

00:22:57.810 --> 00:22:59.460
looking at one tape
Turing machines.

00:23:04.950 --> 00:23:07.710
Getting questions about
big O and little o.

00:23:10.590 --> 00:23:13.230
For something to
be little o means

00:23:13.230 --> 00:23:18.190
it's less than any constant
factor times the function.

00:23:18.190 --> 00:23:20.850
So you have to look at the
definition in the book.

00:23:20.850 --> 00:23:23.670
I think enough
people in the class

00:23:23.670 --> 00:23:25.710
probably know this and
have seen this already,

00:23:25.710 --> 00:23:27.660
I don't want to spend
everybody's time on it.

00:23:27.660 --> 00:23:29.905
But please review
it in the book.

00:23:29.905 --> 00:23:31.530
Somebody is asking
if you need to store

00:23:31.530 --> 00:23:32.700
the parity on the tape.

00:23:32.700 --> 00:23:34.658
No, you can just store
it in the finite memory.

00:23:38.620 --> 00:23:40.620
I mean, storing in the
finite memory seems to me

00:23:40.620 --> 00:23:42.910
the simplest thing.

00:23:42.910 --> 00:23:44.360
Why don't we move on?

00:23:44.360 --> 00:23:47.710
Please feel free to ask
questions to the TAs as well.

00:23:47.710 --> 00:23:50.680
We have two TAs at least
here attending with me.

00:23:50.680 --> 00:24:06.600
So good, all right, all right,
so we cannot do better than

00:24:06.600 --> 00:24:09.360
a one tape Turing machine-- on
a one tape Turing machine than

00:24:09.360 --> 00:24:11.280
order n log n.

00:24:11.280 --> 00:24:13.440
And that's something
we can prove,

00:24:13.440 --> 00:24:15.720
though we're not
going to do it here.

00:24:15.720 --> 00:24:18.450
However, if you change the
model, for example, you

00:24:18.450 --> 00:24:21.210
use a two tape Turing machine,
then yes, as a lot of you

00:24:21.210 --> 00:24:24.700
are suggesting in the chat,
you can do better than that.

00:24:24.700 --> 00:24:28.190
So if we now have
a two tape Turing

00:24:28.190 --> 00:24:29.930
machine, or a multi-tape
Turing machine,

00:24:29.930 --> 00:24:32.390
you can do it in order n steps.

00:24:32.390 --> 00:24:36.990
And that's actually the point
I'm really trying to make here.

00:24:36.990 --> 00:24:42.710
So if you have here your
two tape Turing machine,

00:24:42.710 --> 00:24:48.310
then two tapes, same language.

00:24:48.310 --> 00:24:49.900
Now, what we're
going to do is copy

00:24:49.900 --> 00:24:51.700
the a's to the second tape.

00:24:51.700 --> 00:24:55.330
That we can do on a single pass.

00:24:55.330 --> 00:24:57.910
And then once the a's have
been copied to the second tape,

00:24:57.910 --> 00:25:03.040
we can continue on reading
the b's and match them off

00:25:03.040 --> 00:25:05.080
with the a's that appear
on the second tape.

00:25:05.080 --> 00:25:08.590
So in order n steps, you
can do the comparison,

00:25:08.590 --> 00:25:10.015
instead of order n log n steps.

00:25:12.290 --> 00:25:13.790
And of course, if
they match, you're

00:25:13.790 --> 00:25:16.550
going to accept,
otherwise reject.

00:25:16.550 --> 00:25:20.800
So let's just see,
here's a little animation

00:25:20.800 --> 00:25:21.900
demonstrating that.

00:25:21.900 --> 00:25:25.170
Of course, it's very simple.

00:25:25.170 --> 00:25:28.020
So here is-- here are the--
if you could see that,

00:25:28.020 --> 00:25:29.508
it came maybe a little too fast.

00:25:29.508 --> 00:25:30.800
Here, let's just show it again.

00:25:30.800 --> 00:25:33.320
Here is the heads moving
across and the a's

00:25:33.320 --> 00:25:37.220
coming down to the bottom.

00:25:37.220 --> 00:25:40.070
And now, the head, the upper
head is going to continue

00:25:40.070 --> 00:25:41.210
on reading the b's.

00:25:41.210 --> 00:25:44.210
The lower head is going to
go back to the beginning

00:25:44.210 --> 00:25:47.480
on the a's and matching
off the b's with the a's.

00:25:47.480 --> 00:25:49.380
And that's how we
can verify or check

00:25:49.380 --> 00:25:50.630
that they are the same number.

00:25:55.772 --> 00:25:57.730
So now in this case, they
were the same number.

00:25:57.730 --> 00:25:59.160
So the machine would accept.

00:25:59.160 --> 00:26:02.850
If they were a different number,
the machine would not accept.

00:26:02.850 --> 00:26:04.365
And the analysis is very simple.

00:26:08.070 --> 00:26:11.310
Each stage here is going to
take a linear number of steps,

00:26:11.310 --> 00:26:16.000
order n steps, because it just
consists of a single scan.

00:26:16.000 --> 00:26:20.040
There are no-- there are
no loops in this machine,

00:26:20.040 --> 00:26:20.910
no repeat loops.

00:26:23.730 --> 00:26:28.420
So question on this?

00:26:34.080 --> 00:26:38.430
All right, why don't
we move on then?

00:26:41.430 --> 00:26:45.690
Now, observe-- and the point
I'm really trying to make

00:26:45.690 --> 00:26:50.530
is that on a one
tape Turing machine,

00:26:50.530 --> 00:26:53.260
you can do it in n log
n, but not any better.

00:26:53.260 --> 00:26:54.700
But on a two tape
Turing machine,

00:26:54.700 --> 00:26:57.790
you can do it in order n.

00:26:57.790 --> 00:27:03.200
So there's a difference
in how much time you

00:27:03.200 --> 00:27:05.360
need to spend, how many
steps you need to spend,

00:27:05.360 --> 00:27:07.220
depending upon the model.

00:27:07.220 --> 00:27:10.380
And that's significant for us.

00:27:10.380 --> 00:27:12.770
So the number of steps
depends on the model.

00:27:12.770 --> 00:27:15.470
One tape Turing machine was
order n log n, multi-tape

00:27:15.470 --> 00:27:16.940
was order n.

00:27:16.940 --> 00:27:20.250
We call that model dependence.

00:27:20.250 --> 00:27:23.580
If you contrast that with the
situation in the complexity--

00:27:23.580 --> 00:27:28.090
in the computability
section of the course,

00:27:28.090 --> 00:27:30.810
we had model independence.

00:27:30.810 --> 00:27:34.030
The choice of the
model didn't matter.

00:27:34.030 --> 00:27:35.860
And that was nice for us.

00:27:35.860 --> 00:27:39.700
Because the theory
of the decidability

00:27:39.700 --> 00:27:42.160
didn't depend upon whether
you had a one tape Turing

00:27:42.160 --> 00:27:44.320
machine, or a multi-tape
Turing machine,

00:27:44.320 --> 00:27:49.150
it was all the same set of
decidable and recognizable

00:27:49.150 --> 00:27:51.440
languages.

00:27:51.440 --> 00:27:53.390
So we didn't have to
worry about which model

00:27:53.390 --> 00:27:54.570
we're actually
going to work with.

00:27:54.570 --> 00:27:56.195
We could work with
any model, even just

00:27:56.195 --> 00:27:59.990
an informal model of algorithm
would be good enough.

00:27:59.990 --> 00:28:05.180
Because we're going to end
up with the same notion

00:28:05.180 --> 00:28:07.360
in the end.

00:28:07.360 --> 00:28:13.500
Now that goes away
in complexity theory.

00:28:13.500 --> 00:28:17.640
Now, we have a difference,
depending upon the model.

00:28:17.640 --> 00:28:20.340
And from a mathematical
standpoint,

00:28:20.340 --> 00:28:23.480
that's a little less nice.

00:28:23.480 --> 00:28:27.150
Because which model
do you work with?

00:28:27.150 --> 00:28:30.680
If you want to understand the
complexity of some problem

00:28:30.680 --> 00:28:33.698
that you have at hand, now
you have to make a choice.

00:28:33.698 --> 00:28:35.490
You're going to work
with a Turing machine,

00:28:35.490 --> 00:28:37.575
or how many tapes,
or you're going

00:28:37.575 --> 00:28:39.200
to look at some other
model, and you're

00:28:39.200 --> 00:28:40.560
going to get different results.

00:28:40.560 --> 00:28:44.540
So it's somewhat less natural
from a mathematical standpoint

00:28:44.540 --> 00:28:47.710
just to talk about the
complexity of some problem.

00:28:47.710 --> 00:28:53.290
But we're going to kind of bring
back something close enough

00:28:53.290 --> 00:28:56.830
to model independence by
observing that even though we

00:28:56.830 --> 00:28:59.860
don't have model
independence, as we did

00:28:59.860 --> 00:29:04.270
in computability theory, we can
limit how much dependence there

00:29:04.270 --> 00:29:05.230
is.

00:29:05.230 --> 00:29:07.120
So the amount of
dependence is going

00:29:07.120 --> 00:29:10.180
to be low, as we
will see, provided

00:29:10.180 --> 00:29:13.210
you stick with a reasonable
class of deterministic models.

00:29:17.020 --> 00:29:19.270
So the dependence,
though it does exist,

00:29:19.270 --> 00:29:22.060
is not going to be that much.

00:29:22.060 --> 00:29:24.640
It's going to be
polynomial dependence.

00:29:24.640 --> 00:29:27.890
And we'll say exactly what
that means in a second.

00:29:27.890 --> 00:29:29.770
And from our
standpoint, that's going

00:29:29.770 --> 00:29:33.835
to be a small difference,
a negligible difference

00:29:33.835 --> 00:29:34.960
that we're going to ignore.

00:29:37.730 --> 00:29:40.450
So we're going to focus
on questions that do not

00:29:40.450 --> 00:29:44.080
depend on the model choice among
these reasonable deterministic

00:29:44.080 --> 00:29:44.950
models.

00:29:44.950 --> 00:29:46.720
Now, you may say,
well, that's not

00:29:46.720 --> 00:29:48.670
interesting from a
practical standpoint,

00:29:48.670 --> 00:29:51.490
because polynomial differences,
say the difference between n

00:29:51.490 --> 00:29:54.175
squared and n cubed certainly
make a difference in practice.

00:29:56.770 --> 00:30:14.730
But it really depends on
what kinds of questions

00:30:14.730 --> 00:30:16.660
you're focusing on.

00:30:16.660 --> 00:30:20.538
So if you want to look
at something that's

00:30:20.538 --> 00:30:26.560
a very precise distinction, say
between n squared and n cubed,

00:30:26.560 --> 00:30:30.043
then you might want to
focus in on which model

00:30:30.043 --> 00:30:31.210
you want to be working with.

00:30:31.210 --> 00:30:34.260
And that's going to be more the
domain of an algorithms class.

00:30:34.260 --> 00:30:36.450
But from our
standpoint, we're going

00:30:36.450 --> 00:30:40.120
to be looking at other,
still important, questions.

00:30:40.120 --> 00:30:44.610
But they are questions that
don't depend upon exactly

00:30:44.610 --> 00:30:46.290
which polynomial
you're going to have.

00:30:46.290 --> 00:30:48.270
We're going to be looking
more at distinctions

00:30:48.270 --> 00:30:50.520
between polynomial
and exponential.

00:30:50.520 --> 00:30:52.710
And still, there are
important practical questions

00:30:52.710 --> 00:30:57.150
that arise in that
somewhat different setting.

00:30:59.820 --> 00:31:02.580
So with that in
mind, we're going

00:31:02.580 --> 00:31:05.250
to continue to use
the one tape Turing

00:31:05.250 --> 00:31:08.550
machine as our basic
model of complexity.

00:31:08.550 --> 00:31:13.350
Since the model among the
reasonable deterministic models

00:31:13.350 --> 00:31:14.790
in the end is not
going to matter

00:31:14.790 --> 00:31:17.468
from the perspective of
the kinds of questions

00:31:17.468 --> 00:31:18.510
we're going to be asking.

00:31:25.190 --> 00:31:29.000
So with that, so we
are going to continue,

00:31:29.000 --> 00:31:33.380
then, it's important to remember
that from going forward,

00:31:33.380 --> 00:31:35.960
we're going to stick with the
one tape Turing machine model.

00:31:35.960 --> 00:31:38.585
Maybe that's something you would
have expected us to do anyway.

00:31:38.585 --> 00:31:41.360
But I'm trying to justify that
through this little discussion

00:31:41.360 --> 00:31:45.240
that we had so far, thus far.

00:31:45.240 --> 00:31:48.290
So now, we're going to start
defining things with the one

00:31:48.290 --> 00:31:51.563
tape model in mind.

00:31:51.563 --> 00:31:53.480
So first of all, if you
have a Turing machine,

00:31:53.480 --> 00:31:57.680
we're going to say it runs
in a certain amount of time.

00:31:57.680 --> 00:32:01.630
So if t is some sort of time
bound function, like n squared,

00:32:01.630 --> 00:32:04.570
or n log n, we'll
say the machine runs

00:32:04.570 --> 00:32:07.990
in that amount of time,
like n squared or n log n.

00:32:07.990 --> 00:32:13.990
if that machine M always halts
within that number of steps

00:32:13.990 --> 00:32:16.880
on all inputs of length n.

00:32:16.880 --> 00:32:21.200
So it always halts within t of
n steps on inputs of length n.

00:32:21.200 --> 00:32:25.200
Then we'll say that the
machine runs in t of n time.

00:32:25.200 --> 00:32:29.890
So in other words, if the
machine runs in n squared time,

00:32:29.890 --> 00:32:33.220
then the machine, when you
give it an input of length 10,

00:32:33.220 --> 00:32:35.140
it's got to be
guaranteed to halt

00:32:35.140 --> 00:32:39.880
within 100 steps, 10
squared, 100 steps,

00:32:39.880 --> 00:32:43.360
on every input of length 10.

00:32:43.360 --> 00:32:46.060
That's what it means
for the machine

00:32:46.060 --> 00:32:47.560
to be running in that much time.

00:32:47.560 --> 00:32:52.970
And it has to do that for every
n, for every input length.

00:32:52.970 --> 00:32:55.220
And width that, we're going
to come to the following

00:32:55.220 --> 00:32:58.760
definition, which is highlighted
in color, because it's

00:32:58.760 --> 00:32:59.925
going to be--

00:32:59.925 --> 00:33:01.550
we're going to be
using this definition

00:33:01.550 --> 00:33:02.552
throughout the semester.

00:33:02.552 --> 00:33:04.010
So it's important
to understand it.

00:33:06.640 --> 00:33:10.180
This is the definition of what's
called the time complexity

00:33:10.180 --> 00:33:12.350
classes.

00:33:12.350 --> 00:33:17.420
And what I'm going to do
is take some bound, t of n,

00:33:17.420 --> 00:33:22.020
and again, think of t of n
like a bound like n squared.

00:33:22.020 --> 00:33:25.560
So if you have time t of
n or like time n squared,

00:33:25.560 --> 00:33:28.020
that's going to be the
collection of all languages

00:33:28.020 --> 00:33:31.410
that you can decide
within time n squared

00:33:31.410 --> 00:33:33.190
or within time t of n.

00:33:33.190 --> 00:33:36.420
So in other words, it's a
collection of all languages B

00:33:36.420 --> 00:33:40.080
such that there's some
one tape Turing machine,

00:33:40.080 --> 00:33:42.480
here we're focusing again on
the one tape Turing machine,

00:33:42.480 --> 00:33:44.400
there is some deterministic
one tape Turing

00:33:44.400 --> 00:33:48.450
machine that decides
B. And that machine

00:33:48.450 --> 00:33:50.310
runs in that amount of time.

00:33:54.000 --> 00:33:55.970
So this is a collection
of languages.

00:33:58.920 --> 00:34:01.480
The time complexity class
is a set of languages.

00:34:01.480 --> 00:34:04.690
I'm going to draw
it now as a diagram.

00:34:04.690 --> 00:34:06.570
So if you take the
language, again,

00:34:06.570 --> 00:34:10.620
that we've been using as our
standard example, a to the k,

00:34:10.620 --> 00:34:15.250
b to the k, that's
n time n log n,

00:34:15.250 --> 00:34:19.449
as we observed two
slides to slides back,

00:34:19.449 --> 00:34:21.139
or three slides back.

00:34:21.139 --> 00:34:24.460
So on a one tape Turing machine,
you can do this language A

00:34:24.460 --> 00:34:26.080
in time n log n.

00:34:26.080 --> 00:34:29.350
So it's in the time
complexity class n log n.

00:34:29.350 --> 00:34:34.900
This region here captures
all of the languages

00:34:34.900 --> 00:34:38.020
that you can do in
order n log n time.

00:34:41.429 --> 00:34:47.100
For example, that also includes
all of the regular languages.

00:34:47.100 --> 00:34:47.644
Why is that?

00:34:50.750 --> 00:34:56.050
Well, any regular language can
be done on a one tape Turing

00:34:56.050 --> 00:35:00.980
machine in time order n, because
the Turing machine only just

00:35:00.980 --> 00:35:02.450
needs to scan across.

00:35:02.450 --> 00:35:05.510
Doesn't even need to write, just
need to scan across from left

00:35:05.510 --> 00:35:06.770
to right on the tape.

00:35:06.770 --> 00:35:10.300
And in n steps,
it has the answer.

00:35:10.300 --> 00:35:12.570
So all of the regular
languages are actually in time

00:35:12.570 --> 00:35:16.290
n, certainly a subset
of time n log n.

00:35:16.290 --> 00:35:18.580
And these all form a
kind of a hierarchy.

00:35:18.580 --> 00:35:20.490
So if you increase
the bound, you

00:35:20.490 --> 00:35:23.220
can imagine that the
class of languages

00:35:23.220 --> 00:35:29.970
grows as you allow the machine
to have more and more steps

00:35:29.970 --> 00:35:32.070
to do its computing.

00:35:32.070 --> 00:35:35.400
So these are all the languages
that you can do in n squared,

00:35:35.400 --> 00:35:39.400
order n squared time on a
one tape Turing machine,

00:35:39.400 --> 00:35:41.500
n cubed time on a one
tape Turing machine,

00:35:41.500 --> 00:35:46.480
and so on, 2 exponential time,
2 to the n time on a one tape

00:35:46.480 --> 00:35:47.240
Turing machine.

00:35:47.240 --> 00:35:50.860
These are all
collections of languages

00:35:50.860 --> 00:35:54.730
getting larger and larger
as we increase the bound.

00:36:01.780 --> 00:36:03.040
So someone is asking kind of--

00:36:06.220 --> 00:36:08.595
let's see, let me get to
some of these questions here.

00:36:08.595 --> 00:36:09.970
I'll try to get
to them in order.

00:36:24.130 --> 00:36:25.420
So somebody says if you have--

00:36:25.420 --> 00:36:28.780
a good question, if you
have a regular computer, so

00:36:28.780 --> 00:36:31.380
an ordinary sort of
random access computer,

00:36:31.380 --> 00:36:34.660
which we'll talk about that in
a second, can do it in order n,

00:36:34.660 --> 00:36:36.700
can you do it on a
multi-tape Turing machine

00:36:36.700 --> 00:36:37.900
also in order n time?

00:36:37.900 --> 00:36:39.983
Actually, I don't know the
answer to that offhand.

00:36:39.983 --> 00:36:41.800
I suspect the answer is no.

00:36:41.800 --> 00:36:46.090
That ordinary computers have
a random access capability

00:36:46.090 --> 00:36:47.860
that Turing machines do not.

00:36:47.860 --> 00:36:50.740
And so that there are going to
be some examples of problems

00:36:50.740 --> 00:36:52.357
that you can do with a random--

00:36:52.357 --> 00:36:54.940
with a regular computer that you
cannot do with the multi-tape

00:36:54.940 --> 00:36:57.850
Turing machine in order n time.

00:36:57.850 --> 00:37:02.090
I'd have to double check
that, though, so we can--

00:37:02.090 --> 00:37:05.290
it's also a question
what we believe is true

00:37:05.290 --> 00:37:06.935
and what we can
prove to be true.

00:37:06.935 --> 00:37:08.560
As we'll see, there
are a lot of things

00:37:08.560 --> 00:37:10.150
that we believe to be
true in this subject

00:37:10.150 --> 00:37:11.483
that we don't know how to prove.

00:37:14.043 --> 00:37:15.960
Somebody is asking kind
of an interesting sort

00:37:15.960 --> 00:37:17.043
of more advanced question.

00:37:17.043 --> 00:37:22.320
Is there some function
f, some function t

00:37:22.320 --> 00:37:26.490
where it's so big that
so that time t of n

00:37:26.490 --> 00:37:30.570
gives you all of the
decidable problems?

00:37:30.570 --> 00:37:31.920
It would be a very big t.

00:37:31.920 --> 00:37:35.850
But the answer actually
to that question is yes.

00:37:35.850 --> 00:37:37.980
But that's a little bit exotic.

00:37:37.980 --> 00:37:40.560
So let's not spend a lot
of time on that right here.

00:37:40.560 --> 00:37:42.120
But happy to talk
about that offline.

00:37:46.207 --> 00:37:47.290
It's a good question here.

00:37:47.290 --> 00:37:48.680
Somebody's asking
me does it mean

00:37:48.680 --> 00:37:51.680
that there are no languages
between order n and order n log

00:37:51.680 --> 00:37:54.890
n, because I pointed out
that anything below n log n

00:37:54.890 --> 00:37:56.390
is going to be regular.

00:37:56.390 --> 00:37:58.550
And so, as soon as
you get below n log n,

00:37:58.550 --> 00:37:59.630
you can do it in order n.

00:37:59.630 --> 00:38:03.660
And yes, there is what's
called a gap between order n

00:38:03.660 --> 00:38:05.760
and order n log n on a
one tape Turing machine.

00:38:05.760 --> 00:38:09.070
You don't get anything new
from order n until you jump up.

00:38:09.070 --> 00:38:15.150
So from order n to order n log
log n, nothing new shows up.

00:38:15.150 --> 00:38:17.660
So we'll talk about those kinds
of things a little bit down

00:38:17.660 --> 00:38:20.150
the road, when we look at
actually the relationship

00:38:20.150 --> 00:38:24.500
among these various classes,
and what we call a hierarchy

00:38:24.500 --> 00:38:26.480
theorem, which shows--

00:38:26.480 --> 00:38:29.300
how much bigger do you have
to make the bound in order

00:38:29.300 --> 00:38:30.800
to be sure you'll
get something new?

00:38:36.760 --> 00:38:42.830
All right, somebody's
asking is there

00:38:42.830 --> 00:38:46.005
a model which has the
same time complexity

00:38:46.005 --> 00:38:46.880
as a normal computer?

00:38:50.993 --> 00:38:52.910
Well, I mean, there's
the random access model,

00:38:52.910 --> 00:38:56.900
which is supposed to
capture a normal computer.

00:38:56.900 --> 00:39:02.490
So let me-- these are
all great questions, kind

00:39:02.490 --> 00:39:08.520
of more riffing off of this
into more advanced directions.

00:39:11.880 --> 00:39:14.470
Let's move on.

00:39:14.470 --> 00:39:17.130
Here's another check-in.

00:39:17.130 --> 00:39:20.160
Suppose we take-- this is a
little bit of a check to see

00:39:20.160 --> 00:39:21.458
how well--

00:39:21.458 --> 00:39:24.000
how comfortable you are with
the notions we've just presented

00:39:24.000 --> 00:39:26.550
and whether you can think
about some of the arguments

00:39:26.550 --> 00:39:29.680
that we've made and apply
them to a new language.

00:39:29.680 --> 00:39:37.140
So take the language ww reverse,
strings followed by their--

00:39:40.110 --> 00:39:41.700
followed by
themselves backwards.

00:39:41.700 --> 00:39:44.010
This language B are the
even length palindromes,

00:39:44.010 --> 00:39:45.720
if you will.

00:39:45.720 --> 00:39:49.170
What's the smallest
bound that you

00:39:49.170 --> 00:39:57.412
need to be able to
solve that language B?

00:39:57.412 --> 00:39:58.370
And I'll pose it as a--

00:40:02.380 --> 00:40:05.700
pose that as a question for you.

00:40:05.700 --> 00:40:16.660
So which time complexity
class is that language B in?

00:40:16.660 --> 00:40:21.190
Is it time order n, order
n log n, n squared, so on?

00:40:21.190 --> 00:40:21.940
What do you think?

00:40:28.480 --> 00:40:30.610
So we're about to come
to the coffee break.

00:40:30.610 --> 00:40:32.410
So why don't we--

00:40:35.445 --> 00:40:37.070
I'll answer any
questions that come up.

00:40:37.070 --> 00:40:40.440
I think we're got
everybody answered.

00:40:40.440 --> 00:40:41.915
So I'm going to end the polling.

00:40:41.915 --> 00:40:43.790
OK, make sure you're in
if you want to be in.

00:40:48.960 --> 00:40:53.015
So the correct answer is,
in fact, order n squared.

00:40:56.470 --> 00:40:57.220
It would be hard--

00:41:00.490 --> 00:41:03.490
reasonable guess here
would be order n log n.

00:41:03.490 --> 00:41:07.900
I mean, you can come up
with the same procedure

00:41:07.900 --> 00:41:09.850
as the one we showed
at the beginning,

00:41:09.850 --> 00:41:13.930
the order n squared procedure
for a to the k, b to the k

00:41:13.930 --> 00:41:16.900
works for ww reverse as well.

00:41:16.900 --> 00:41:19.990
You can just cross off,
sweep back and forth,

00:41:19.990 --> 00:41:25.950
crossing off a symbol
from w, and going across

00:41:25.950 --> 00:41:29.130
to the other side, crossing
off a symbol from w reverse.

00:41:29.130 --> 00:41:32.160
And that procedure will give
you an n squared and order

00:41:32.160 --> 00:41:33.240
n squared algorithm.

00:41:36.860 --> 00:41:39.140
You might imagine you can
improve it to order n log n.

00:41:39.140 --> 00:41:39.800
But you cannot.

00:41:39.800 --> 00:41:42.133
You can prove that order n
squared is the best possible.

00:41:44.970 --> 00:41:47.690
I'm a little unhappy that a lot
of you came up with order n,

00:41:47.690 --> 00:41:48.440
frankly.

00:41:48.440 --> 00:41:51.740
Because I already told
you that order n is--

00:41:51.740 --> 00:41:53.450
these are just
regular languages.

00:41:53.450 --> 00:41:55.460
Anything that you
can do in less than--

00:41:55.460 --> 00:41:57.680
a little o of n log n
is going to be regular.

00:41:57.680 --> 00:41:59.990
And we know this
language is not regular.

00:41:59.990 --> 00:42:05.030
So this was not a good answer.

00:42:05.030 --> 00:42:09.680
So please pay attention.

00:42:09.680 --> 00:42:15.790
And OK, so let us stop sharing.

00:42:15.790 --> 00:42:22.270
I will turn now to our
break for five minutes.

00:42:22.270 --> 00:42:25.750
And I'm happy to try to
take questions along the way

00:42:25.750 --> 00:42:31.510
as we're waiting
for the time to end.

00:42:31.510 --> 00:42:34.240
So let's see, let
me put this up here.

00:42:42.450 --> 00:42:44.330
Let me try to take
some of your questions.

00:42:50.910 --> 00:42:53.280
So someone is asking me
about quantum computers

00:42:53.280 --> 00:42:57.330
as reasonable models of--

00:42:57.330 --> 00:42:59.610
you may say a quantum
computer is a reasonable model

00:42:59.610 --> 00:43:01.090
of computation.

00:43:01.090 --> 00:43:02.010
And that's fine.

00:43:02.010 --> 00:43:03.850
I would not say it's
a reasonable model

00:43:03.850 --> 00:43:08.850
of deterministic computation,
at least from our standpoint.

00:43:08.850 --> 00:43:11.190
Let's not quibble
about the words.

00:43:11.190 --> 00:43:12.930
I'm not including
quantum computers

00:43:12.930 --> 00:43:18.120
in the collection of machines
that I have in mind right now

00:43:18.120 --> 00:43:20.790
when I'm talking about
the reasonable models

00:43:20.790 --> 00:43:23.730
of deterministic
computation that we're

00:43:23.730 --> 00:43:25.093
going to be discussing.

00:43:30.660 --> 00:43:31.335
Let's see.

00:43:33.923 --> 00:43:35.590
Oh, because a bunch
of people apparently

00:43:35.590 --> 00:43:40.030
are asking the TAs why
all regular languages can

00:43:40.030 --> 00:43:41.560
be done in order n.

00:43:48.200 --> 00:43:58.005
So if you think
about a DFA, which

00:43:58.005 --> 00:44:05.370
processes an input of
length n with n steps,

00:44:05.370 --> 00:44:11.290
and a DFA is I'm going to
be a type of Turing machine

00:44:11.290 --> 00:44:16.260
that never writes on its
tape, so if a DFA can do it

00:44:16.260 --> 00:44:19.450
in n steps, the Turing
machine can do it in n steps.

00:44:19.450 --> 00:44:21.910
And so therefore,
every regular language

00:44:21.910 --> 00:44:26.080
can be done in order n
steps on a Turing machine.

00:44:26.080 --> 00:44:27.550
Not sure where the confusion is.

00:44:27.550 --> 00:44:31.360
So please message me if
you're still not getting it.

00:44:39.550 --> 00:44:42.520
OK, somebody saying why are we
using one tape Turing machines

00:44:42.520 --> 00:44:43.810
instead of random access?

00:44:43.810 --> 00:44:47.860
Wouldn't it be better to use
the random access machines?

00:44:47.860 --> 00:44:52.360
If you were using-- if you're
trying to do algorithms, yes.

00:44:52.360 --> 00:44:54.280
That's a more reasonable model.

00:44:54.280 --> 00:44:56.835
We're trying to prove things
about the computation.

00:44:56.835 --> 00:44:58.210
And from that
standpoint, we want

00:44:58.210 --> 00:45:01.060
to use as simple a
model as possible.

00:45:01.060 --> 00:45:05.500
Trying to prove things using
random access computers

00:45:05.500 --> 00:45:06.550
is possible.

00:45:06.550 --> 00:45:08.200
It'd be very messy.

00:45:08.200 --> 00:45:11.043
So that's why we don't
use random access machines

00:45:11.043 --> 00:45:12.460
to prove the kinds
of things we're

00:45:12.460 --> 00:45:17.080
going to be proving about
computation that are really

00:45:17.080 --> 00:45:19.280
the meat and potatoes
of this course.

00:45:19.280 --> 00:45:23.200
So I mean, there's
compelling reasons

00:45:23.200 --> 00:45:25.450
why you would want to use a
simple model like a Turing

00:45:25.450 --> 00:45:29.320
machine, but not a powerful
model like a random access

00:45:29.320 --> 00:45:31.660
computer.

00:45:31.660 --> 00:45:38.280
So somebody's asking me,
does the class time order n

00:45:38.280 --> 00:45:40.170
log log n have any elements?

00:45:40.170 --> 00:45:43.080
Yes, it has all the regular
languages, but nothing else.

00:45:43.080 --> 00:45:46.620
Order n log log is it's
only the regular languages.

00:45:46.620 --> 00:45:49.590
You have to go all the way
up to n log n before you

00:45:49.590 --> 00:45:50.700
get something non-regular.

00:45:53.407 --> 00:45:55.490
Someone's asking me are
we going to talk about how

00:45:55.490 --> 00:45:56.780
the random access model works?

00:45:56.780 --> 00:45:57.280
No.

00:46:00.750 --> 00:46:04.840
That's beyond the
scope of this course,

00:46:04.840 --> 00:46:07.730
outside of what we're
going to be doing.

00:46:07.730 --> 00:46:11.540
We're going to talk
about Turing machines.

00:46:11.540 --> 00:46:13.670
Not because we care so
much about Turing machines.

00:46:13.670 --> 00:46:15.990
But I'm trying to prove
things about computation.

00:46:15.990 --> 00:46:17.990
And the Turing machines
are a convenient vehicle

00:46:17.990 --> 00:46:18.650
for doing that.

00:46:21.460 --> 00:46:23.650
Our candle has burned out.

00:46:23.650 --> 00:46:29.120
Why don't we return,
then, to the next slide.

00:46:29.120 --> 00:46:30.490
So everybody come back.

00:46:30.490 --> 00:46:33.340
So this answers one of the
questions I got on the chat.

00:46:33.340 --> 00:46:37.337
What actually is the dependency
between multi-tape Turing

00:46:37.337 --> 00:46:38.920
machines and one
tape Turing machines?

00:46:38.920 --> 00:46:40.600
Can we bound that in general?

00:46:40.600 --> 00:46:43.420
Yes, we can.

00:46:43.420 --> 00:46:46.360
We're going to show that
converting a multi-tape Turing

00:46:46.360 --> 00:46:49.240
machine to a one tape
Turing machine can, at most,

00:46:49.240 --> 00:46:54.790
blow up the amount of time
that's necessary by squaring.

00:46:54.790 --> 00:46:56.430
No, I acknowledge it's a lot.

00:46:56.430 --> 00:47:00.070
But it still allows you--

00:47:00.070 --> 00:47:03.250
but it's still small compared
with an exponential increase.

00:47:03.250 --> 00:47:05.710
And we're going to be
focusing, in this course,

00:47:05.710 --> 00:47:08.080
on things like the
difference between polynomial

00:47:08.080 --> 00:47:10.210
and exponential, not
between the different--

00:47:10.210 --> 00:47:15.040
not between the difference of--

00:47:15.040 --> 00:47:17.140
not the difference between
n squared and n cubed.

00:47:17.140 --> 00:47:18.640
That's going to be
less of a factor,

00:47:18.640 --> 00:47:19.810
less of an issue for us.

00:47:26.030 --> 00:47:30.920
So the way I'm
showing this theorem

00:47:30.920 --> 00:47:34.010
is that if you have a
multi-tape Turing machine that

00:47:34.010 --> 00:47:36.810
can do a language in a
certain amount of time,

00:47:36.810 --> 00:47:40.130
then it's in the time complexity
class of that time bound

00:47:40.130 --> 00:47:42.550
squared.

00:47:42.550 --> 00:47:44.100
And the way I'm
just saying that is

00:47:44.100 --> 00:47:49.590
because this is the bound that's
utilizing the one tape model.

00:47:49.590 --> 00:47:52.140
So another way of saying
that is converting

00:47:52.140 --> 00:47:58.490
multi-tape to one tape
squares the amount of time you

00:47:58.490 --> 00:48:01.820
need at most.

00:48:01.820 --> 00:48:06.170
So the way we're going
to prove that is simply

00:48:06.170 --> 00:48:09.710
by going back and remembering
the conversion that we already

00:48:09.710 --> 00:48:12.860
presented from
multi-tape to one tape.

00:48:12.860 --> 00:48:16.280
And observe that if we
analyze that conversion,

00:48:16.280 --> 00:48:19.670
it just ends up squaring
the amount of time

00:48:19.670 --> 00:48:20.810
that the multi-tape used.

00:48:24.190 --> 00:48:27.400
So why is that?

00:48:27.400 --> 00:48:29.620
So if you remember,
let's just make

00:48:29.620 --> 00:48:34.060
sure we're all together on this,
the way the single tape machine

00:48:34.060 --> 00:48:36.850
S simulates the multi
tape Turing machine

00:48:36.850 --> 00:48:43.412
M is that it takes the
contents of each of M's tapes,

00:48:43.412 --> 00:48:45.620
up to the place where there's
infinitely many blanks.

00:48:45.620 --> 00:48:47.920
Obviously you don't
store the infinite part.

00:48:47.920 --> 00:48:51.820
But the active
portion of each of M's

00:48:51.820 --> 00:48:54.520
tapes, you're going to
store them consecutively

00:48:54.520 --> 00:48:59.620
in separate blocks on S's
tape, on S's only tape.

00:48:59.620 --> 00:49:02.350
And now every time
M makes one move,

00:49:02.350 --> 00:49:11.080
S has to scan its
entire tape to see

00:49:11.080 --> 00:49:15.260
what's under each of the heads
and to do all the updating.

00:49:15.260 --> 00:49:18.290
So to simulate one step
of M's computation,

00:49:18.290 --> 00:49:22.970
S is going to use order of
t of n steps, where t of n

00:49:22.970 --> 00:49:26.070
is the total running time
that M is going to use.

00:49:26.070 --> 00:49:28.470
So why is t of m
steps coming up here?

00:49:28.470 --> 00:49:31.670
Well, that's because you
have to measure how--

00:49:31.670 --> 00:49:35.420
S is going to make a
scan across its tape.

00:49:35.420 --> 00:49:39.480
How big can its tape be?

00:49:39.480 --> 00:49:43.880
Well M, if it's trying to
use as much tape as possible,

00:49:43.880 --> 00:49:50.940
can use, at most, t
of n tape on each of--

00:49:50.940 --> 00:49:53.160
t of n cells on
each of its tapes.

00:49:53.160 --> 00:49:55.320
So altogether,
they're just going

00:49:55.320 --> 00:50:02.710
to be some constant number of
times t of n cells on S's tape.

00:50:02.710 --> 00:50:04.030
Do you see that?

00:50:04.030 --> 00:50:06.820
So each one of these is going
to be, at most, t of n long.

00:50:06.820 --> 00:50:09.670
So this all together is going
to be order t of n long.

00:50:09.670 --> 00:50:11.590
Because what can M do?

00:50:11.590 --> 00:50:14.920
It could send its head out,
say the head on this tape

00:50:14.920 --> 00:50:18.160
here, moving as fast as
possible to the right,

00:50:18.160 --> 00:50:19.480
using as much tape as it can.

00:50:19.480 --> 00:50:22.990
But you can only use t of
n cells in t of n time.

00:50:22.990 --> 00:50:24.940
So this is going
to be order t of n.

00:50:24.940 --> 00:50:27.400
So one step of
computation is going

00:50:27.400 --> 00:50:30.760
to be t of n steps
on S's computation.

00:50:30.760 --> 00:50:33.880
But M itself has t of n steps.

00:50:33.880 --> 00:50:36.550
So it's going to be
t of n times t of n

00:50:36.550 --> 00:50:38.260
for the total number
of steps that S

00:50:38.260 --> 00:50:40.932
is going to end up using.

00:50:40.932 --> 00:50:42.640
And that's where the
squaring comes from.

00:50:48.540 --> 00:50:52.050
Similar results, I'm not going
to do lots of simulations

00:50:52.050 --> 00:50:53.190
of one model by another.

00:50:53.190 --> 00:50:55.200
I think that you'll
get the idea.

00:50:55.200 --> 00:50:57.100
And you can, if
you're interested,

00:50:57.100 --> 00:50:59.440
you can study those on your own.

00:50:59.440 --> 00:51:02.370
But you can convert
multidimensional Turing

00:51:02.370 --> 00:51:06.700
machines to one tape
Turing machines, one tape

00:51:06.700 --> 00:51:09.630
ordinary linear--

00:51:09.630 --> 00:51:13.860
one tape, one
dimensional machines.

00:51:13.860 --> 00:51:18.330
And the bottom line
is that among all

00:51:18.330 --> 00:51:20.880
of the reasonable
models, they're

00:51:20.880 --> 00:51:25.580
all what are called
polynomially related if each

00:51:25.580 --> 00:51:30.070
can simulate the other with,
at most, a polynomial overhead.

00:51:30.070 --> 00:51:32.330
So if one of the machines
can use this t of n time,

00:51:32.330 --> 00:51:34.580
the other machine
that's simulating it

00:51:34.580 --> 00:51:37.070
would use t to the k
of n time for some k.

00:51:40.292 --> 00:51:42.000
That's what it means
for the two machines

00:51:42.000 --> 00:51:43.560
to be polynomially related.

00:51:43.560 --> 00:51:47.480
And all reasonable
deterministic models

00:51:47.480 --> 00:51:49.100
are polynomially related.

00:51:49.100 --> 00:51:52.513
So as we've already seen, one
tape and multi-tape Turing

00:51:52.513 --> 00:51:53.930
machines are
polynomially related,

00:51:53.930 --> 00:51:56.650
because converting multi-tape
to one tape blows you up by,

00:51:56.650 --> 00:51:58.510
at most, squaring.

00:51:58.510 --> 00:52:01.530
So k equals 2 in this case.

00:52:01.530 --> 00:52:03.180
Multidimensional
Turing machines,

00:52:03.180 --> 00:52:07.025
again, polynomially related,
the random access machine,

00:52:07.025 --> 00:52:09.150
which I'm not going to
define, but it's the machine

00:52:09.150 --> 00:52:11.790
that you might
imagine-- you would,

00:52:11.790 --> 00:52:15.030
I'm sure they must define in
some form in the algorithms

00:52:15.030 --> 00:52:18.330
classes, polynomially related.

00:52:18.330 --> 00:52:21.930
Cellular automata, which are
just arrays of finite automata

00:52:21.930 --> 00:52:27.590
that can communicate with
each other, similarly.

00:52:27.590 --> 00:52:32.400
All the reasonable
deterministic models,

00:52:32.400 --> 00:52:34.350
again, classical
models, I'm not talking

00:52:34.350 --> 00:52:38.700
about quantum computing,
are polynomially related.

00:52:38.700 --> 00:52:44.730
So we are-- that kind
of justifies our choice

00:52:44.730 --> 00:52:47.010
in picking one of
them, as long as we're

00:52:47.010 --> 00:52:48.750
going to ask
questions which don't

00:52:48.750 --> 00:52:50.805
depend upon the polynomial.

00:52:57.220 --> 00:53:03.620
Let's then talk about the
class P. So the class P,

00:53:03.620 --> 00:53:07.130
this is an important
definition for us.

00:53:07.130 --> 00:53:13.010
This is the collection
of all languages

00:53:13.010 --> 00:53:18.740
that you can do in time n to
the k for some k on a one tape

00:53:18.740 --> 00:53:19.820
Turing machine.

00:53:19.820 --> 00:53:21.340
Or as I've written
it over here, I

00:53:21.340 --> 00:53:24.890
don't know if this notation
is unfamiliar to you,

00:53:24.890 --> 00:53:27.860
but this is like just a big sum.

00:53:27.860 --> 00:53:29.900
But here, it's a
big union symbol.

00:53:29.900 --> 00:53:35.700
It's union over all values of
k of the time class n to the k.

00:53:35.700 --> 00:53:40.920
So this is time n, union time
n squared, union time n cubed,

00:53:40.920 --> 00:53:45.310
union time n to
the 4th, and so on.

00:53:45.310 --> 00:53:48.600
We call these the polynomial
time decidable languages.

00:53:51.640 --> 00:53:58.960
So we're going to be spending
a certain amount of effort

00:53:58.960 --> 00:54:04.980
exploring this class P
and other similar classes.

00:54:04.980 --> 00:54:06.912
Somebody's asking me
why is it a union.

00:54:06.912 --> 00:54:08.620
I'm not sure how else
you would write it.

00:54:08.620 --> 00:54:11.310
So if somebody-- if you have
a proposal for a different way

00:54:11.310 --> 00:54:12.630
to write it, that's fine.

00:54:12.630 --> 00:54:16.500
But this is k,
this is for all k.

00:54:16.500 --> 00:54:19.710
I don't know-- if you only had
a limited finite number of k's,

00:54:19.710 --> 00:54:21.210
you could just take
the biggest one.

00:54:21.210 --> 00:54:26.040
But since it's for all k, you
need to write it as a union.

00:54:26.040 --> 00:54:30.585
Now, I want to argue that the
class P is an important class.

00:54:33.810 --> 00:54:40.860
And why has it had so
much impact on the subject

00:54:40.860 --> 00:54:44.110
and in terms of
applications as well?

00:54:44.110 --> 00:54:47.190
So one thing is
that the class P is

00:54:47.190 --> 00:54:49.990
invariant for all reasonable
deterministic models.

00:54:49.990 --> 00:54:52.730
What do I mean by that?

00:54:52.730 --> 00:54:58.540
So we have defined the class P
in terms of these time classes

00:54:58.540 --> 00:55:00.250
here, which, in
turn, are defined

00:55:00.250 --> 00:55:03.130
in terms of the one tape model.

00:55:03.130 --> 00:55:08.330
So we have defined P by using
one tape Turing machines.

00:55:08.330 --> 00:55:13.700
Now if we had defined P in terms
of multi-tape Turing machines,

00:55:13.700 --> 00:55:18.530
we get exactly the same
class, because one tape

00:55:18.530 --> 00:55:20.960
and multi-tape Turing machines
are polynomially related

00:55:20.960 --> 00:55:22.080
to one another.

00:55:22.080 --> 00:55:25.880
And since we're taking the
union over all polynomials,

00:55:25.880 --> 00:55:30.850
that polynomial difference
is going to wash out.

00:55:30.850 --> 00:55:33.850
Similarly, we could
define P using

00:55:33.850 --> 00:55:36.880
any of the other reasonable
deterministic models.

00:55:36.880 --> 00:55:40.000
And we get exactly
the same class.

00:55:40.000 --> 00:55:43.140
So in a sense, we
get back what we--

00:55:43.140 --> 00:55:46.440
the situation that we had
in computability theory,

00:55:46.440 --> 00:55:50.590
when the class of
decidable languages

00:55:50.590 --> 00:55:53.620
didn't depend on
the choice of model.

00:55:53.620 --> 00:55:56.290
Here, the class
P does not matter

00:55:56.290 --> 00:56:01.430
depending upon the choice of
reasonable deterministic model.

00:56:01.430 --> 00:56:04.940
And we also kind of, even in the
case of computability theory,

00:56:04.940 --> 00:56:07.700
we have to stick with kind of
reasonable models that cannot

00:56:07.700 --> 00:56:09.500
do an infinite amount
of work in one step.

00:56:13.548 --> 00:56:15.840
I'm not going to define what
it means to be reasonable.

00:56:15.840 --> 00:56:17.810
That's, in a sense,
an informal notion.

00:56:17.810 --> 00:56:20.570
But among all of those
reasonable models,

00:56:20.570 --> 00:56:22.950
you're going to get
the same class P.

00:56:22.950 --> 00:56:25.700
The other thing that
makes P important

00:56:25.700 --> 00:56:32.110
is that P roughly
corresponds to the problems

00:56:32.110 --> 00:56:35.530
that you can solve in some
reasonable practical sense.

00:56:35.530 --> 00:56:39.280
Now, not exactly, problems
that require n to the hundredth

00:56:39.280 --> 00:56:47.005
time, you could argue cannot be
solved in any reasonable sense.

00:56:47.005 --> 00:56:49.900
But if you think
about it, for example,

00:56:49.900 --> 00:56:55.270
from the perspective
of cryptography,

00:56:55.270 --> 00:56:58.060
cryptographic codes
that people come up with

00:56:58.060 --> 00:57:00.620
are typically
designed to require,

00:57:00.620 --> 00:57:03.730
or the hope is that they would
require an exponential amount

00:57:03.730 --> 00:57:04.840
of effort to crack.

00:57:04.840 --> 00:57:07.930
If someone found even an n
to the hundredth algorithm

00:57:07.930 --> 00:57:11.110
to crack, that
would crack a code,

00:57:11.110 --> 00:57:13.210
people would feel that
the code is not secure,

00:57:13.210 --> 00:57:16.600
even though n to the
hundredth is still large.

00:57:16.600 --> 00:57:19.720
So it's a rough kind of test.

00:57:19.720 --> 00:57:22.420
But it's still used as
a kind of litmus test

00:57:22.420 --> 00:57:25.120
for practical solvability
if you can solve it

00:57:25.120 --> 00:57:26.470
in polynomial time.

00:57:26.470 --> 00:57:33.190
You basically figured out
how to avoid large searches

00:57:33.190 --> 00:57:36.550
if you can solve problems
in polynomial time.

00:57:36.550 --> 00:57:39.620
We'll say more about that later.

00:57:39.620 --> 00:57:42.820
But what I want
to bring out here

00:57:42.820 --> 00:57:47.470
is that we have combined,
here in the class P, something

00:57:47.470 --> 00:57:50.680
that's mathematically
nice, mathematically

00:57:50.680 --> 00:57:53.770
elegant with something
that's practically relevant.

00:57:53.770 --> 00:57:55.990
And when you have a
combination of the two,

00:57:55.990 --> 00:57:57.490
then you know you have a winner.

00:57:57.490 --> 00:57:59.675
Then you know how you
have a concept that's

00:57:59.675 --> 00:58:00.800
going to make a difference.

00:58:00.800 --> 00:58:02.710
And that's been true
for the class P.

00:58:02.710 --> 00:58:07.930
This has been very influential
within and without the theory

00:58:07.930 --> 00:58:10.990
of computation.

00:58:10.990 --> 00:58:12.540
So let's look at an example.

00:58:16.130 --> 00:58:18.500
Let's define a new language
we haven't seen before,

00:58:18.500 --> 00:58:20.900
though it's similar
to procedures

00:58:20.900 --> 00:58:22.730
that we've looked at before.

00:58:22.730 --> 00:58:25.250
The PATH language,
which is where

00:58:25.250 --> 00:58:29.820
I'm going to give you a graph
G, two nodes in the graph,

00:58:29.820 --> 00:58:35.350
s and t, where I'm thinking
of G as a directed graph.

00:58:35.350 --> 00:58:39.350
So directed means that the
connections between the nodes

00:58:39.350 --> 00:58:42.080
in G are going to be directed.

00:58:42.080 --> 00:58:43.520
And that they have
arrows on them.

00:58:43.520 --> 00:58:45.530
They're not just
lines, but they have

00:58:45.530 --> 00:58:48.790
an orientation with an arrow.

00:58:48.790 --> 00:58:52.870
So G is a directed graph
that has a path from s to t

00:58:52.870 --> 00:58:55.580
that respects the directions.

00:58:55.580 --> 00:58:58.840
So such a-- I think I might
even have a picture here, yeah.

00:58:58.840 --> 00:59:01.020
So imagine here,
here is your graph.

00:59:01.020 --> 00:59:02.770
If you can see it,
there are little arrows

00:59:02.770 --> 00:59:04.630
connecting the nodes.

00:59:04.630 --> 00:59:07.900
And I want to know is
there a path from the node

00:59:07.900 --> 00:59:10.120
s to the node t.

00:59:10.120 --> 00:59:14.560
So that is a picture of
a problem, an instance

00:59:14.560 --> 00:59:16.600
of a graph of a PATH problem.

00:59:19.330 --> 00:59:22.650
And I want to find an
algorithm for that.

00:59:22.650 --> 00:59:24.750
And I can show that there
is an algorithm that

00:59:24.750 --> 00:59:30.720
operates in polynomial
time for this PATH problem.

00:59:30.720 --> 00:59:38.430
And the algorithm, any of the
standard searching algorithms

00:59:38.430 --> 00:59:39.330
would work here.

00:59:39.330 --> 00:59:42.180
But let's just, for
completeness sake,

00:59:42.180 --> 00:59:45.870
include the breadth-first
search algorithm

00:59:45.870 --> 00:59:47.460
that we have explored
previously when

00:59:47.460 --> 00:59:49.840
we talk about finite automata.

00:59:49.840 --> 00:59:51.570
So we'll mark s.

00:59:51.570 --> 00:59:54.990
And they'll keep repeating
until nothing new is marked.

00:59:54.990 --> 00:59:56.820
And we'll mark all
of the nodes that

00:59:56.820 --> 01:00:04.590
were reachable by a single arrow
from a previously marked node.

01:00:04.590 --> 01:00:09.840
And then CFT is marked, After
you have marked everything

01:00:09.840 --> 01:00:10.470
you can get to.

01:00:10.470 --> 01:00:11.790
So you're going to mark--

01:00:11.790 --> 01:00:14.310
let's see, pictorially, here
I think I have this indicated.

01:00:14.310 --> 01:00:16.740
Yeah you're going to mark
all of the things that

01:00:16.740 --> 01:00:18.365
are reachable from the start--

01:00:18.365 --> 01:00:21.260
from the node s.

01:00:21.260 --> 01:00:24.500
And then see, after you
can't mark anything new,

01:00:24.500 --> 01:00:26.570
whether the node G is marked.

01:00:26.570 --> 01:00:28.070
And if it is, you'll accept.

01:00:28.070 --> 01:00:29.570
If it is not, you reject.

01:00:32.480 --> 01:00:34.643
Now, we can analyze this, too.

01:00:34.643 --> 01:00:36.560
And I'm not going to be
spending a lot of time

01:00:36.560 --> 01:00:38.840
analyzing algorithms here.

01:00:38.840 --> 01:00:42.550
But let's just do it
kind of this one time.

01:00:47.530 --> 01:00:50.420
We're doing a bunch
of iterations here.

01:00:50.420 --> 01:00:53.020
So we're going to be repeating
until nothing new is marked.

01:00:53.020 --> 01:00:55.570
So each time we
mark something new,

01:00:55.570 --> 01:00:58.960
we can only do that,
at most, n times.

01:00:58.960 --> 01:01:01.030
At which point, we've
marked everything.

01:01:01.030 --> 01:01:04.930
So the number of iterations
here is going to be, at most, n.

01:01:04.930 --> 01:01:07.210
And now for each time
we mark something,

01:01:07.210 --> 01:01:13.180
we have to look at all of
the previously marked nodes

01:01:13.180 --> 01:01:16.737
and see which things they
point at to mark them too.

01:01:16.737 --> 01:01:18.820
So this is going to be an
inner loop, which again,

01:01:18.820 --> 01:01:22.000
has, at most, n iterations,
because it's going through all

01:01:22.000 --> 01:01:23.860
of the previously marked nodes.

01:01:23.860 --> 01:01:31.100
And then once we have that,
we can scan G to see--

01:01:31.100 --> 01:01:36.777
to mark all of the new--

01:01:36.777 --> 01:01:38.360
all of the nodes
which we have not yet

01:01:38.360 --> 01:01:41.210
marked, whether they're
connected with a previously

01:01:41.210 --> 01:01:43.040
marked node by an edge.

01:01:43.040 --> 01:01:47.602
And I'm being generous here,
because I don't really care.

01:01:47.602 --> 01:01:50.060
This can be done in, at most,
n squared steps on a one tape

01:01:50.060 --> 01:01:50.765
Turing machine.

01:01:50.765 --> 01:01:52.640
I'm not going to describe
the implementation.

01:01:52.640 --> 01:01:54.710
But I'll leave it to
you as an exercise.

01:01:54.710 --> 01:01:58.080
But this is straightforward.

01:01:58.080 --> 01:01:59.630
So the total number
of steps here

01:01:59.630 --> 01:02:03.840
would be n iterations times
n iterations times n squared.

01:02:03.840 --> 01:02:06.300
So you're going to be, at most,
n to the 4th steps needed.

01:02:06.300 --> 01:02:08.360
So this is a
polynomial algorithm.

01:02:08.360 --> 01:02:10.010
And whether I ended
up with to the 4th,

01:02:10.010 --> 01:02:12.560
or n to the 5th, or n
cubed, I don't really care.

01:02:12.560 --> 01:02:15.740
Because I'm just trying
to illustrate that

01:02:15.740 --> 01:02:18.330
the total is polynomial.

01:02:18.330 --> 01:02:22.160
And that's all I'm going to
be typically asking you to do.

01:02:22.160 --> 01:02:25.040
So to show polynomial time,
what I'll be asking you to do

01:02:25.040 --> 01:02:29.360
is to show that each stage,
each stage of this algorithm,

01:02:29.360 --> 01:02:31.310
should be clearly polynomial.

01:02:31.310 --> 01:02:34.220
And that the total number
of stages, I'm sorry,

01:02:34.220 --> 01:02:37.520
this should say stages
here, should be polynomial.

01:02:37.520 --> 01:02:39.830
So each stage is polynomial.

01:02:39.830 --> 01:02:41.990
And after you're doing
all the iterations,

01:02:41.990 --> 01:02:45.500
the total number of stages that
are executed is polynomial.

01:02:45.500 --> 01:02:48.290
And so therefore, all together,
the total running time,

01:02:48.290 --> 01:02:53.010
the total number of steps,
is going to be polynomial.

01:02:53.010 --> 01:03:00.630
So that's the way we would
write up polynomial algorithms

01:03:00.630 --> 01:03:01.215
in this class.

01:03:04.390 --> 01:03:06.330
So let's see if there's
any questions here.

01:03:06.330 --> 01:03:08.475
I don't want to get too
far ahead of people.

01:03:16.350 --> 01:03:18.720
Let's see.

01:03:18.720 --> 01:03:21.990
Yes, in this theorem, I'm
talking about one tape Turing

01:03:21.990 --> 01:03:25.233
machines, because we're
defining everything in terms

01:03:25.233 --> 01:03:26.400
of one tape Turing machines.

01:03:26.400 --> 01:03:28.440
But now, at this
point, when we're

01:03:28.440 --> 01:03:31.620
talking about polynomial
time, my analysis

01:03:31.620 --> 01:03:33.870
is based on one tape
Turing machines.

01:03:33.870 --> 01:03:37.140
But in general, you could use
any reasonable deterministic

01:03:37.140 --> 01:03:39.630
model on which to carry
out your analysis,

01:03:39.630 --> 01:03:41.730
because they're all
polynomially equivalent.

01:03:41.730 --> 01:03:43.920
So from the perspective
of coming up

01:03:43.920 --> 01:03:48.690
with showing that a problem is
in polynomial time, is in P,

01:03:48.690 --> 01:03:52.650
you can use any of
the models that you

01:03:52.650 --> 01:03:55.005
wish that for convenient.

01:03:55.005 --> 01:03:56.130
Oh, that's a good question.

01:03:56.130 --> 01:03:58.860
What is n, thank you for
asking that question.

01:03:58.860 --> 01:04:04.740
n is always going to
be reserved to indicate

01:04:04.740 --> 01:04:07.320
the length of the input.

01:04:07.320 --> 01:04:13.280
So here, n is going to be
when we encode G, s, and t.

01:04:13.280 --> 01:04:14.990
And here, also, I
haven't said this,

01:04:14.990 --> 01:04:18.860
but I'm assuming that the
encoding that you're using

01:04:18.860 --> 01:04:20.840
is also somehow reasonable.

01:04:20.840 --> 01:04:22.610
I think we'll talk
a little bit more

01:04:22.610 --> 01:04:25.070
about that in the
next lecture, which is

01:04:25.070 --> 01:04:28.480
going to be after the midterm.

01:04:28.480 --> 01:04:32.140
But you can cause problems
if you intentionally

01:04:32.140 --> 01:04:35.290
tried to come up with
nasty encodings, which

01:04:35.290 --> 01:04:43.330
will represent things with
unnecessarily many characters.

01:04:43.330 --> 01:04:49.870
But if you try to be
reasonable, then just

01:04:49.870 --> 01:04:54.020
use any one of those
encodings, and you'll be fine.

01:04:54.020 --> 01:04:57.970
So yeah, so n is the length
of the representation

01:04:57.970 --> 01:04:58.600
of the input.

01:05:01.220 --> 01:05:01.720
Let's see.

01:05:06.290 --> 01:05:10.400
Someone's trying to
dig into the actual

01:05:10.400 --> 01:05:11.650
how this is running here.

01:05:11.650 --> 01:05:15.338
Scan G to mark all y
where xy is an edge.

01:05:15.338 --> 01:05:17.380
I'm saying that you can
do it in n squared steps.

01:05:32.410 --> 01:05:37.880
If you have x, you can mark it
in a certain place on the tape.

01:05:37.880 --> 01:05:40.250
And then as you're going
to every other node,

01:05:40.250 --> 01:05:43.370
every other edge,
you can go back

01:05:43.370 --> 01:05:47.720
and compare x with the x
of the edge and then see--

01:05:47.720 --> 01:05:49.960
and then find the y.

01:05:49.960 --> 01:05:52.850
I mean, it's just going to be
too messy to talk about here.

01:05:52.850 --> 01:05:55.460
I mean, I'll leave it
as an exercise to you.

01:05:55.460 --> 01:05:58.970
I'm not going to try to fumble
my way through explaining

01:05:58.970 --> 01:06:00.620
why you can do this
in n squared steps.

01:06:00.620 --> 01:06:01.880
But it's not hard.

01:06:09.730 --> 01:06:12.302
You guys are all really
hardcore algorithms folks.

01:06:12.302 --> 01:06:14.010
You want to know the
algorithms for this,

01:06:14.010 --> 01:06:16.530
I'm not going to do that, sorry.

01:06:16.530 --> 01:06:17.970
High level picture here.

01:06:21.410 --> 01:06:26.010
If you want-- if you want to
look at detailed analyses,

01:06:26.010 --> 01:06:29.490
this is not the
right course for you.

01:06:29.490 --> 01:06:31.290
Can k equal n?

01:06:31.290 --> 01:06:32.040
What is k?

01:06:40.540 --> 01:06:44.080
No, if you're talking about
this k here, k cannot equal n.

01:06:44.080 --> 01:06:46.690
We're not looking at n to the n.

01:06:46.690 --> 01:06:51.670
These are all fixed k, it's
like n squared, n cubed,

01:06:51.670 --> 01:06:54.520
but not n to the n is it going
to be an exponential bound.

01:06:54.520 --> 01:07:00.020
And so that's not going to be
included within this union.

01:07:00.020 --> 01:07:02.700
So we're near the
end of the hour.

01:07:02.700 --> 01:07:08.330
I'm going to introduce one last
language here, called HAMPATH.

01:07:08.330 --> 01:07:10.790
And the HAMPATH problem is--

01:07:14.850 --> 01:07:17.175
I'm going to ask now,
again, for a path from s

01:07:17.175 --> 01:07:19.980
to t, but now a
different kind of path,

01:07:19.980 --> 01:07:24.750
one that goes through every
node of G along the way.

01:07:24.750 --> 01:07:26.250
So I'm looking for
a path that goes,

01:07:26.250 --> 01:07:29.050
that hits every node of
G, not just the shortest,

01:07:29.050 --> 01:07:30.160
most direct path.

01:07:30.160 --> 01:07:33.540
But in a sense, the most
indirect path, the longest path

01:07:33.540 --> 01:07:37.350
that goes through from s to
t that visits everything else

01:07:37.350 --> 01:07:39.570
along the way.

01:07:39.570 --> 01:07:44.130
A path of that kind, that
hits every node of the graph

01:07:44.130 --> 01:07:47.220
is called a Hamiltonian path.

01:07:47.220 --> 01:07:48.690
Because the
mathematician Hamilton

01:07:48.690 --> 01:07:51.520
studied those and made some
definitions about that.

01:07:51.520 --> 01:07:52.763
I'm not going to--

01:07:52.763 --> 01:07:54.430
I don't actually know
the history there.

01:07:54.430 --> 01:07:58.260
But I just know they're
called Hamiltonian paths.

01:07:58.260 --> 01:07:59.970
So here's a picture.

01:07:59.970 --> 01:08:01.710
I want to get from s to t.

01:08:01.710 --> 01:08:04.440
But I want to sort of pick up
everything else along the way.

01:08:07.530 --> 01:08:10.700
So as you remember,
the PATH problem itself

01:08:10.700 --> 01:08:15.440
can be solved in P. And
what I'd like to know,

01:08:15.440 --> 01:08:17.470
can this simple
modification, where

01:08:17.470 --> 01:08:20.350
I'm asking you to visit
everything else along the way,

01:08:20.350 --> 01:08:22.079
is that problem also in P?

01:08:24.680 --> 01:08:28.090
And I'm going to pose this
as a check-in for you.

01:08:28.090 --> 01:08:29.660
But actually, before
I get to that,

01:08:29.660 --> 01:08:32.500
let me give you an
algorithm for HAMPATH

01:08:32.500 --> 01:08:37.729
that doesn't work to show it's
in P, because it's exponential.

01:08:37.729 --> 01:08:46.410
So here's an
algorithm for HAMPATH,

01:08:46.410 --> 01:08:52.439
where let's m the
number of nodes in G.

01:08:52.439 --> 01:08:54.090
And what I'm going
to do is I'm going

01:08:54.090 --> 01:09:00.689
to try every possible path
in G and see if it's actually

01:09:00.689 --> 01:09:04.590
works as a Hamiltonian
path, and accept if it is.

01:09:07.979 --> 01:09:12.310
And then if all paths
fail, then I'll reject.

01:09:12.310 --> 01:09:15.870
So I'm going to try every
possible routing through G.

01:09:15.870 --> 01:09:17.670
If you want to think
about it, think

01:09:17.670 --> 01:09:21.923
of m as every possible
permutation of the nodes of G.

01:09:21.923 --> 01:09:24.090
And then you're going to
see whether that's actually

01:09:24.090 --> 01:09:28.680
constitutes a path in G
that takes you from s to t

01:09:28.680 --> 01:09:30.749
and goes through
all of the nodes.

01:09:35.170 --> 01:09:39.240
So this algorithm would work.

01:09:39.240 --> 01:09:42.689
This would give you
a correct algorithm

01:09:42.689 --> 01:09:44.370
for the HAMPATH problem.

01:09:44.370 --> 01:09:47.100
The problem is,
the difficulty is

01:09:47.100 --> 01:09:51.300
that there are so many
possible paths that it's

01:09:51.300 --> 01:09:53.819
going to take you an
exponential number of steps

01:09:53.819 --> 01:09:55.290
to execute this algorithm.

01:09:55.290 --> 01:09:57.060
It's not a polynomial
time algorithm,

01:09:57.060 --> 01:09:58.770
because there are
many possible paths

01:09:58.770 --> 01:10:00.450
that you could go through.

01:10:00.450 --> 01:10:03.150
If you're looking at it
with a very crude bound,

01:10:03.150 --> 01:10:05.580
but you really can't
improve that significantly,

01:10:05.580 --> 01:10:08.100
there would be m
factorial, which

01:10:08.100 --> 01:10:13.740
is going to be much greater than
2 to the m paths of length m.

01:10:13.740 --> 01:10:16.210
So the algorithm is going
to run for exponential time,

01:10:16.210 --> 01:10:18.330
and not polynomial time.

01:10:18.330 --> 01:10:19.830
So my question for
you is, I'm going

01:10:19.830 --> 01:10:21.390
to pose it as a
check-in problem,

01:10:21.390 --> 01:10:23.520
is whether you could
actually do this problem

01:10:23.520 --> 01:10:25.900
in polynomial time.

01:10:25.900 --> 01:10:27.330
So why don't you
think about that

01:10:27.330 --> 01:10:28.830
as I'm setting up the question?

01:10:31.960 --> 01:10:36.890
So take the HAMPATH problem,
just like the PATH problem,

01:10:36.890 --> 01:10:38.980
which I described with
that marking algorithm,

01:10:38.980 --> 01:10:43.000
but now you want to hit
every node along the way,

01:10:43.000 --> 01:10:45.850
can you show that
problem as solvable in P?

01:10:45.850 --> 01:10:47.680
And there's a whole
range of possibilities

01:10:47.680 --> 01:10:50.920
here where either the
answer is yes, you

01:10:50.920 --> 01:10:58.080
can see what the polynomial
time algorithm is to definitely

01:10:58.080 --> 01:11:00.570
no, where you can prove there
is no such polynomial time

01:11:00.570 --> 01:11:01.710
algorithm.

01:11:01.710 --> 01:11:06.300
And I'll put this is the
check-in for you and see--

01:11:06.300 --> 01:11:09.350
I'm curious to see
what you come up with.

01:11:09.350 --> 01:11:11.360
Most people are
getting it wrong.

01:11:11.360 --> 01:11:13.220
Well, wrong, I don't you know--

01:11:13.220 --> 01:11:14.750
I'm not clear what
wrong is here.

01:11:17.610 --> 01:11:19.940
OK, are we done?

01:11:19.940 --> 01:11:24.278
Please check something.

01:11:24.278 --> 01:11:25.820
I see a few of you
have not answered.

01:11:25.820 --> 01:11:30.120
But the poll is running out.

01:11:30.120 --> 01:11:31.620
OK, time is up.

01:11:37.220 --> 01:11:45.650
So in fact, as I think many of
you know, but not all of you,

01:11:45.650 --> 01:11:47.100
this is an unsolved problem.

01:11:47.100 --> 01:11:49.320
This is a very famous
unsolved problem,

01:11:49.320 --> 01:11:51.680
which is equivalent to
the P versus NP problem

01:11:51.680 --> 01:11:54.262
that we're going to be
talking about very soon,

01:11:54.262 --> 01:11:56.720
which, among other things,
would be worth a million dollars

01:11:56.720 --> 01:11:58.140
if you solve it.

01:11:58.140 --> 01:12:00.620
So for those of you who
have answered a or e,

01:12:00.620 --> 01:12:02.768
please talk to me after lecture.

01:12:02.768 --> 01:12:04.310
And maybe we can
work on it together.

01:12:07.380 --> 01:12:12.150
No, so yeah, I think
most people would

01:12:12.150 --> 01:12:15.630
believe that the answer is no.

01:12:15.630 --> 01:12:18.250
But no one knows how to
prove it at this time.

01:12:18.250 --> 01:12:21.270
So I'm interested
in the folks who

01:12:21.270 --> 01:12:25.710
have come up with what
they think are solutions.

01:12:25.710 --> 01:12:29.670
And I should say that
there are some folks who

01:12:29.670 --> 01:12:33.000
believe that there might be
other outcomes besides just

01:12:33.000 --> 01:12:35.850
a simple no.

01:12:35.850 --> 01:12:39.300
Which might be
proven eventually.

01:12:39.300 --> 01:12:41.620
So we're going to
talk more about this.

01:12:41.620 --> 01:12:44.460
But this is the answer to
the question, just for your--

01:12:44.460 --> 01:12:46.590
just to make sure you
understand is that it's

01:12:46.590 --> 01:12:47.970
an unsolved problem right now.

01:12:47.970 --> 01:12:50.490
So we don't know.

01:12:50.490 --> 01:12:52.170
Definitely yes
and definitely no,

01:12:52.170 --> 01:12:55.710
at least according to the
state of knowledge of which I'm

01:12:55.710 --> 01:13:00.540
aware, are not correct answers.

01:13:00.540 --> 01:13:04.390
But any of the others,
well, who knows?

01:13:04.390 --> 01:13:09.240
So I think that's the end of
what I had to say for today.

01:13:09.240 --> 01:13:12.060
We covered complexity
theory as an introduction,

01:13:12.060 --> 01:13:14.100
looked at different
possible models,

01:13:14.100 --> 01:13:17.760
focused on the one
tape model, introduced,

01:13:17.760 --> 01:13:20.670
based on the one tape
model, these complexity

01:13:20.670 --> 01:13:25.650
classes, the class P. And we
showed an example of this PATH

01:13:25.650 --> 01:13:29.110
problem being in P. Talked also
about this HAMPATH problem,

01:13:29.110 --> 01:13:33.420
which we'll talk about
more after the midterm.

01:13:33.420 --> 01:13:36.603
OK, so I'll stick
around for a few minutes

01:13:36.603 --> 01:13:38.020
if you have any
further questions.

01:13:38.020 --> 01:13:42.525
Otherwise, so let me
just take questions here.

01:13:47.562 --> 01:13:49.520
Somebody is asking me
about my personal opinion

01:13:49.520 --> 01:13:52.490
on P versus NP.

01:13:52.490 --> 01:13:56.780
My personal opinion on P versus
NP is that P is not equal to NP

01:13:56.780 --> 01:14:00.860
and that we will
prove it someday.

01:14:00.860 --> 01:14:03.710
When I was a graduate
student back in the mid '70s,

01:14:03.710 --> 01:14:05.330
I thought it would
be solved by now.

01:14:05.330 --> 01:14:10.490
And in fact, I made a bet with
Len Adleman, who I subsequently

01:14:10.490 --> 01:14:13.850
ended up becoming the
A of the RSA code,

01:14:13.850 --> 01:14:15.890
that we would solve
it by the year 2000.

01:14:15.890 --> 01:14:18.080
And I bet what was
then a lot of money

01:14:18.080 --> 01:14:22.340
for me, which was an ounce of
gold, which I didn't end up--

01:14:22.340 --> 01:14:25.880
which I did end up paying
off to Len in the year 2000.

01:14:25.880 --> 01:14:28.490
So I'm not making any more bets.

01:14:28.490 --> 01:14:31.220
But I still believe
that it will be solved.

01:14:31.220 --> 01:14:34.587
Hopefully I'll get a
chance to see the solution.

01:14:34.587 --> 01:14:36.545
I spend a lot of time
thinking about it myself.

01:14:40.490 --> 01:14:43.910
Obviously, I haven't solved
it, otherwise we would know.

01:14:43.910 --> 01:14:50.013
But hopefully somebody will.

01:14:50.013 --> 01:14:51.430
I'm gettings asked
a question here

01:14:51.430 --> 01:14:53.055
that's kind of an
interesting question,

01:14:53.055 --> 01:14:57.880
but I don't really know
I'm sure I understand it.

01:14:57.880 --> 01:15:03.110
What's the largest possible
runtime of a decidable problem?

01:15:03.110 --> 01:15:05.630
What is the largest
decidable runtime?

01:15:05.630 --> 01:15:11.410
So anything that I
can describe can be--

01:15:11.410 --> 01:15:18.400
there are going to be
algorithms that run for longer.

01:15:21.660 --> 01:15:29.810
You can define an algorithm.

01:15:29.810 --> 01:15:33.350
You can define a runtime,
which would, in a sense,

01:15:33.350 --> 01:15:34.910
beats all other runtimes.

01:15:37.610 --> 01:15:41.630
So that any runtime is
going to be dominated

01:15:41.630 --> 01:15:44.270
by that extremely slow runtime.

01:15:44.270 --> 01:15:46.910
But it's not something
that one can describe.

01:15:46.910 --> 01:15:50.210
I can describe it to you
by mathematical procedure.

01:15:50.210 --> 01:15:53.880
But it's not going to
be something like 2

01:15:53.880 --> 01:15:55.940
to the 2 to the n.

01:15:55.940 --> 01:16:01.670
Somebody's here proposing a
solution to the HAMPATH problem

01:16:01.670 --> 01:16:03.440
by presuming polynomial time.

01:16:03.440 --> 01:16:05.390
Why is the following flawed?

01:16:05.390 --> 01:16:08.600
If s goes through all
nodes and ends up at t,

01:16:08.600 --> 01:16:10.040
Well, s we're not--

01:16:10.040 --> 01:16:12.440
you mean, I presume
you mean starting at s,

01:16:12.440 --> 01:16:16.730
if we end up going through
all nodes and end at t,

01:16:16.730 --> 01:16:20.900
the proposal is a
little complicated here.

01:16:20.900 --> 01:16:25.070
Basically, if I can
try to rephrase it,

01:16:25.070 --> 01:16:26.630
you want to try to--

01:16:26.630 --> 01:16:28.460
from every possible
node, you want

01:16:28.460 --> 01:16:32.540
to try to calculate a path
to t and also a path from s

01:16:32.540 --> 01:16:34.010
to that node.

01:16:34.010 --> 01:16:36.830
And you can do that
for all possible nodes.

01:16:36.830 --> 01:16:38.870
But there's no way to
really combine them

01:16:38.870 --> 01:16:41.840
into a single path
that visits all.

01:16:41.840 --> 01:16:43.910
Solving for each node
separately is not

01:16:43.910 --> 01:16:47.660
going to do the trick, because
you have to somehow combine

01:16:47.660 --> 01:16:52.170
all that information into a
single path, just one path that

01:16:52.170 --> 01:16:55.320
goes from s to t and visits all
the other nodes along the way.

01:16:55.320 --> 01:16:57.750
And that that is not--

01:16:57.750 --> 01:17:01.590
I don't see what
your proposal, how

01:17:01.590 --> 01:17:03.330
that's going to actually work.

01:17:03.330 --> 01:17:06.090
AUDIENCE: Professor Sipser.

01:17:06.090 --> 01:17:09.510
A question on the--

01:17:09.510 --> 01:17:12.000
we were kind of talking
about earlier, what

01:17:12.000 --> 01:17:15.570
we talked about today was
defined for the one tape Turing

01:17:15.570 --> 01:17:17.610
machines, correct?

01:17:17.610 --> 01:17:18.670
MICHAEL SIPSER: Yep

01:17:18.670 --> 01:17:22.770
AUDIENCE: So and you said we
could apply for the multi-tape

01:17:22.770 --> 01:17:24.660
ones, but are--

01:17:28.050 --> 01:17:30.690
I don't know if we talked
about earlier, if something

01:17:30.690 --> 01:17:32.567
is accepted by the
one tape machine,

01:17:32.567 --> 01:17:34.650
can it be applied to the
multi-tape Turing machine

01:17:34.650 --> 01:17:36.150
and vice versa?

01:17:36.150 --> 01:17:37.738
Are they interchangeable
like that?

01:17:37.738 --> 01:17:39.780
MICHAEL SIPSER: Well
they're interchangeable only

01:17:39.780 --> 01:17:43.990
in the sense that the amount of
time that you would need-- it's

01:17:43.990 --> 01:17:45.040
a different machine.

01:17:45.040 --> 01:17:48.580
If you have a multi-tape Turing
machine for some language,

01:17:48.580 --> 01:17:50.590
you can convert it to a
one tape Turing machine

01:17:50.590 --> 01:17:55.240
using the procedure that we
described earlier in the term.

01:17:55.240 --> 01:17:56.980
And you'll get a
different machine.

01:17:56.980 --> 01:17:59.510
It's going to run for a
different amount of time

01:17:59.510 --> 01:18:00.828
by using that procedure.

01:18:00.828 --> 01:18:03.370
The point is that the amount of
time that the one tape Turing

01:18:03.370 --> 01:18:04.787
machine is going
to run for is not

01:18:04.787 --> 01:18:09.010
that much worse than the
multi-tape Turing machine's

01:18:09.010 --> 01:18:09.740
time.

01:18:09.740 --> 01:18:17.710
So if the multi-tape Turing
machine's time was n cubed,

01:18:17.710 --> 01:18:21.050
the one tape Turing machine's is
going to be the square of that.

01:18:21.050 --> 01:18:23.290
So it's going to
be n to the 6th.

01:18:23.290 --> 01:18:24.670
But it's not going to be--

01:18:24.670 --> 01:18:26.920
going from multi-tape
to one tape

01:18:26.920 --> 01:18:30.410
is not going to convert you
from polynomial to exponential.

01:18:30.410 --> 01:18:32.830
That's the only point
I'm trying to make.

01:18:32.830 --> 01:18:34.660
It's going to convert
from one polynomial

01:18:34.660 --> 01:18:36.380
to a somewhat bigger polynomial.

01:18:36.380 --> 01:18:39.900
But it's still going to
leave you polynomial.

01:18:39.900 --> 01:18:41.340
I don't-- you don't seem--

01:18:41.340 --> 01:18:42.700
I can't see your face.

01:18:42.700 --> 01:18:46.440
AUDIENCE: No, I guess my opinion
is just, especially when we

01:18:46.440 --> 01:18:49.680
were talking about earlier,
when you were bringing it up,

01:18:49.680 --> 01:18:51.810
it just seemed like you
could just turn anything

01:18:51.810 --> 01:18:55.800
to a multi tape Turing machine
and completely cut the time

01:18:55.800 --> 01:18:56.640
out.

01:18:56.640 --> 01:18:59.340
If I had like
something in n log n,

01:18:59.340 --> 01:19:01.260
if I did it in the
multi-tape Turing machine,

01:19:01.260 --> 01:19:06.700
I have it in big O of
n, you know what I mean?

01:19:06.700 --> 01:19:09.220
It just seemed like the
multi-tape was so much more

01:19:09.220 --> 01:19:10.130
powerful.

01:19:10.130 --> 01:19:17.240
But then I guess not, with the
explanations and the models

01:19:17.240 --> 01:19:18.465
we were talking about today.

01:19:18.465 --> 01:19:19.840
MICHAEL SIPSER:
Yeah, I would not

01:19:19.840 --> 01:19:22.570
say-- the multi-tape Turing
machines are still pretty

01:19:22.570 --> 01:19:24.430
limited in their capabilities.

01:19:24.430 --> 01:19:29.080
And don't forget, when you have
a multi-tape Turing machine,

01:19:29.080 --> 01:19:31.090
you have only a fixed
number of tapes.

01:19:31.090 --> 01:19:33.820
I mean, you can also define
variations of multi-tape Turing

01:19:33.820 --> 01:19:41.220
machines that have an increasing
number of tapes as the input,

01:19:41.220 --> 01:19:44.530
either under program control,
it can launch new tapes.

01:19:44.530 --> 01:19:49.420
Or it could just have
more tapes depending

01:19:49.420 --> 01:19:53.050
upon the size of the input, that
would also be a possibility.

01:19:53.050 --> 01:19:55.240
That's not the model
that we have defined.

01:19:55.240 --> 01:19:58.550
But you could define
a model like that.

01:19:58.550 --> 01:20:00.340
But as long as the
total amount of work

01:20:00.340 --> 01:20:03.520
being done by the
machine at any step

01:20:03.520 --> 01:20:07.270
s going to be a
polynomial amount of work,

01:20:07.270 --> 01:20:10.300
then you can convert it to
a one tape Turing machine

01:20:10.300 --> 01:20:14.740
with only a polynomial
increase in the bound.

01:20:14.740 --> 01:20:17.700
You want to be
careful of machines--

01:20:17.700 --> 01:20:20.530
one thing I meant to say
but didn't say, so here

01:20:20.530 --> 01:20:25.270
would be an unreasonable
model, which you might

01:20:25.270 --> 01:20:27.048
think of as a plausible model.

01:20:27.048 --> 01:20:28.840
But it's not going to
be a reasonable model

01:20:28.840 --> 01:20:30.010
from our standpoint.

01:20:30.010 --> 01:20:32.590
And that would be a
model, for example,

01:20:32.590 --> 01:20:41.370
that can do full precision,
say, integer arithmetic

01:20:41.370 --> 01:20:43.630
with a unit cost per operation.

01:20:43.630 --> 01:20:48.570
So each operation
counts as costs 1.

01:20:48.570 --> 01:20:50.100
But I'm going to
allow you to do,

01:20:50.100 --> 01:20:55.360
for example, addition
and multiplication.

01:20:55.360 --> 01:21:03.080
The thing that's bad about that,
in terms of being unreasonable,

01:21:03.080 --> 01:21:09.530
is that after k step,
each time you do a step,

01:21:09.530 --> 01:21:14.570
you could double the size of
the integer by squaring it.

01:21:14.570 --> 01:21:17.720
After k steps, you can have an
integer, which is 2 to the k

01:21:17.720 --> 01:21:19.850
long.

01:21:19.850 --> 01:21:22.730
And now, doing
operations there is

01:21:22.730 --> 01:21:25.250
going to involve an
exponential amount of work,

01:21:25.250 --> 01:21:28.505
even in any reasonable sense.

01:21:28.505 --> 01:21:30.755
In a theoretical sense, and
also in a practical sense.

01:21:33.800 --> 01:21:35.600
A model that operates
like that is not

01:21:35.600 --> 01:21:39.290
going to be able to convert
to a one tape Turing machine

01:21:39.290 --> 01:21:42.332
with only a polynomial
increase, because it's

01:21:42.332 --> 01:21:43.790
doing an exponential
amount of work

01:21:43.790 --> 01:21:49.710
potentially within a
polynomial number of steps.

01:21:49.710 --> 01:21:53.540
So that's within a linear
number of steps, within n steps.

01:21:53.540 --> 01:22:01.510
So that's an example of an
unreasonable deterministic

01:22:01.510 --> 01:22:02.320
model.

01:22:02.320 --> 01:22:03.665
AUDIENCE: Yeah, thank you.

01:22:03.665 --> 01:22:04.540
MICHAEL SIPSER: Sure.

01:22:08.450 --> 01:22:11.960
AUDIENCE: So I'm just curious,
some idea just occurred to me.

01:22:11.960 --> 01:22:16.310
I guess if you have an Oracle
Turing machine, basically

01:22:16.310 --> 01:22:20.210
just so that you could look at
a Turing machine description

01:22:20.210 --> 01:22:23.540
and decide whether
it's a decider or not,

01:22:23.540 --> 01:22:26.600
then it'd be a little bit
interesting to think about what

01:22:26.600 --> 01:22:29.958
happens if you look at all--

01:22:29.958 --> 01:22:32.000
if you have a description
of a pair of the Turing

01:22:32.000 --> 01:22:34.040
machine and an input
string, then you

01:22:34.040 --> 01:22:36.950
can look at for all
size n descriptions

01:22:36.950 --> 01:22:43.220
of a pair, what's the most
steps that it takes for such

01:22:43.220 --> 01:22:47.040
a machine to convert it.

01:22:47.040 --> 01:22:49.880
So then you'd have combined
Turing machine and input string

01:22:49.880 --> 01:22:52.070
descriptions, where
you could look

01:22:52.070 --> 01:22:54.050
at what's the longest
it takes to convert.

01:22:54.050 --> 01:22:54.350
I don't know.

01:22:54.350 --> 01:22:56.060
It's just a random
thought that occurred.

01:22:56.060 --> 01:22:58.477
MICHAEL SIPSER: Yeah, so we
actually-- we're going to-- we

01:22:58.477 --> 01:23:02.642
will talk about Oracle Turing
machines later on in the term.

01:23:02.642 --> 01:23:04.100
These are machines
that have access

01:23:04.100 --> 01:23:06.960
to sort of free information.

01:23:06.960 --> 01:23:10.590
And that actually
turns out to be--

01:23:10.590 --> 01:23:12.830
there's some
interesting things you

01:23:12.830 --> 01:23:15.650
can say about what
happens when you're

01:23:15.650 --> 01:23:18.680
providing a machine with, in
a sense, information for free.

01:23:18.680 --> 01:23:23.795
That you might otherwise want
to charge it for actually

01:23:23.795 --> 01:23:24.920
computing that information.

01:23:24.920 --> 01:23:26.810
But let's just say
we're going to allow

01:23:26.810 --> 01:23:31.280
it to get that information
without being charged.

01:23:31.280 --> 01:23:33.800
And then how does that
affect the complexity

01:23:33.800 --> 01:23:36.960
of other problems, for example?

01:23:36.960 --> 01:23:40.400
And so we will talk
about that later.

01:23:40.400 --> 01:23:43.100
But too much of, I
think, of a digression

01:23:43.100 --> 01:23:46.070
at this moment to try
to define all that.

01:23:46.070 --> 01:23:48.170
But happy to chat with
you about it on Piazza

01:23:48.170 --> 01:23:50.630
if you want to raise
a question there.

01:23:50.630 --> 01:23:51.590
AUDIENCE: Thank you.

01:23:51.590 --> 01:23:54.270
MICHAEL SIPSER:
Sure, no problem.

01:23:54.270 --> 01:23:57.260
Somebody's asking me about
strategies for solving the P

01:23:57.260 --> 01:23:58.290
versus NP problem.

01:23:58.290 --> 01:24:00.290
We will talk also talk
about that a little later

01:24:00.290 --> 01:24:01.820
in the term as well.

01:24:01.820 --> 01:24:12.470
But clearly, it seems beyond the
reach of our present techniques

01:24:12.470 --> 01:24:15.950
to be able to prove that
some problems really

01:24:15.950 --> 01:24:16.730
take a long time.

01:24:16.730 --> 01:24:18.480
Like that Hamiltonian
path problem,

01:24:18.480 --> 01:24:21.530
it seems like there's
nothing really

01:24:21.530 --> 01:24:23.540
you can do with that
significantly better

01:24:23.540 --> 01:24:25.610
than trying all
possibilities as I

01:24:25.610 --> 01:24:30.380
described in that exponential
algorithm on the last slide.

01:24:30.380 --> 01:24:33.260
But how do you prove that?

01:24:33.260 --> 01:24:34.580
Nobody knows.

01:24:34.580 --> 01:24:41.645
So lots of people have
tried, including yours truly.

01:24:41.645 --> 01:24:43.770
I mean, I've spent a lot
of time thinking about it.

01:24:43.770 --> 01:24:45.080
Haven't succeeded with it.

01:24:45.080 --> 01:24:56.210
But there is somebody, I
think, someday, somebody

01:24:56.210 --> 01:24:59.570
will come up with the new idea
that's needed to solve it.

01:24:59.570 --> 01:25:02.270
But it's going to clearly take
some sort of a breakthrough,

01:25:02.270 --> 01:25:03.415
some sort of a new idea.

01:25:03.415 --> 01:25:05.540
It's not just going to be
a combination of existing

01:25:05.540 --> 01:25:07.915
ideas, existing methods.

01:25:11.210 --> 01:25:13.730
I think we're about
10 minutes past.

01:25:13.730 --> 01:25:15.020
A few of you are still here.

01:25:15.020 --> 01:25:16.670
I'm going to say
goodbye to you folks.

01:25:16.670 --> 01:25:21.840
And shortly, I'm going to
join my TAs for our weekly TA

01:25:21.840 --> 01:25:22.340
meeting.

01:25:22.340 --> 01:25:23.360
So see you guys.

01:25:23.360 --> 01:25:25.990
Thanks for being here.