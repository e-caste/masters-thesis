WEBVTT

1
00:00:01.350 --> 00:00:03.360 
hello my name is Bhavya.

2
00:00:04.100 --> 00:00:08.390 
i'm a phd student at the university of illinois at urbana-champaign.

3
00:00:09.390 --> 00:00:14.340 
i will be presenting our work titled scaling up
data science caused projects

4
00:00:14.490 --> 00:00:15.330 
a case study.

5
00:00:17.130 --> 00:00:21.170 
so project-based learning is considered crucial
for data science courses.

6
00:00:21.760 --> 00:00:23.640 
but it is also challenging to scale.

7
00:00:24.900 --> 00:00:29.010 
i will discuss our experience in an information retrieval and

8
00:00:29.010 --> 00:00:31.530 
text mining course offered in fall twenty twenty.

9
00:00:32.150 --> 00:00:33.790 
it was a fully online course.

10
00:00:34.670 --> 00:00:37.110 
there were about three seventy eight students

11
00:00:37.780 --> 00:00:42.330 
composed of dsg who were working professionals

12
00:00:42.960 --> 00:00:45.330 
undergraduates and graduate students.

13
00:00:46.360 --> 00:00:48.930 
there were eight tiers and one instructor.

14
00:00:49.810 --> 00:00:53.970 
and there was a mix of project types including research projects

15
00:00:54.460 --> 00:00:58.890 
competitions and students were also free to choose their own topics.

16
00:01:00.590 --> 00:01:02.860 
we were faced with the following two challenges.

17
00:01:03.390 --> 00:01:07.520 
firstly how do we ensure that high-quality feedback is provided

18
00:01:08.200 --> 00:01:13.120 
in a timely fashion secondly in spite of the high diversity

19
00:01:13.120 --> 00:01:17.130 
between the project types. how do we ensure that creating is

20
00:01:17.130 --> 00:01:18.600 
done in a fair fashion.

21
00:01:20.890 --> 00:01:23.810 
for the first challenge we implemented two solutions.

22
00:01:24.850 --> 00:01:28.990 
firstly the assessment was done in a tiered fashion

23
00:01:29.760 --> 00:01:33.490 
where each tier was responsible for about twenty projects.

24
00:01:34.180 --> 00:01:39.490 
and secondly the tears also assigned every student to peer

25
00:01:39.490 --> 00:01:44.260 
review about two projects in such a way that students working

26
00:01:44.260 --> 00:01:47.910 
on similar project topics graded each other's work.

27
00:01:49.550 --> 00:01:52.940 
we had three checkpoints initial mid-point and final

28
00:01:53.650 --> 00:01:58.480 
created by either the tears alone, or both the students and the tears

29
00:01:59.820 --> 00:02:04.890 
for the second challenge we set clear expectations and objective rubrics

30
00:02:05.280 --> 00:02:09.660 
based on reproducibility and completion of projects

31
00:02:11.630 --> 00:02:13.080 
to evaluate our design.

32
00:02:13.780 --> 00:02:16.630 
we asked students to participate in,

33
00:02:17.040 --> 00:02:21.630 
so always sharing their experience as an author and a reviewer

34
00:02:22.670 --> 00:02:25.850 
tears were also invited to participate in surveys.

35
00:02:27.440 --> 00:02:31.620 
we also analyzed the peer reviews submitted for the course projects.

36
00:02:33.590 --> 00:02:39.650 
so here are our main findings firstly the ts on average
took much less time

37
00:02:39.840 --> 00:02:42.060 
to grade the final stage of the projects

38
00:02:42.480 --> 00:02:44.570 
when compared to the peer reviewers.

39
00:02:45.470 --> 00:02:49.640 
they also reported that the peer reviews were useful for grading

40
00:02:52.020 --> 00:02:56.970 
overall reproducibility and manually assigning peer reviewers

41
00:02:57.450 --> 00:03:00.030 
proved to be challenging and time consuming.

42
00:03:02.020 --> 00:03:07.210 
students also found qualitative peer reviews
to be useful for project improvement.

43
00:03:07.540 --> 00:03:09.310 
and validation of their work

44
00:03:10.910 --> 00:03:16.030 
we also analyzed the length of the peer reviews
submitted by different students,

45
00:03:16.560 --> 00:03:21.710 
because longer reviews typically means high quality of reviews.

46
00:03:23.130 --> 00:03:28.180 
we found that ds two students gave significantly longer peer reviews.

47
00:03:28.860 --> 00:03:32.380 
and that could be because they are more experienced students

48
00:03:34.520 --> 00:03:37.300 
by closely looking at the peer review content.

49
00:03:37.820 --> 00:03:43.510 
we found that it served as a means to initiate student collaboration

50
00:03:45.530 --> 00:03:48.130 
finally majority of the students reported

51
00:03:48.590 --> 00:03:50.720 
that they found their grading to be fair.

52
00:03:53.940 --> 00:03:55.810 
here our main take-away is

53
00:03:56.610 --> 00:04:01.530 
firstly tiers and students with various levels of grading expertise

54
00:04:01.990 --> 00:04:06.650 
can offer different tiers of support at multiple project checkpoints.

55
00:04:08.020 --> 00:04:12.890 
secondly peer reviewing can foster student sub-communities

56
00:04:13.890 --> 00:04:17.360 
such that they collaborate to develop impactful projects.

57
00:04:18.880 --> 00:04:24.080 
thirdly we recommend using clear and objective rubrics for fair grading.

58
00:04:25.300 --> 00:04:31.050 
finally we identify a need for better tools for managing assessment of

59
00:04:31.180 --> 00:04:33.310 
ds course projects at scale

60
00:04:34.670 --> 00:04:37.660 
for more details please check out our paper.

61
00:04:38.550 --> 00:04:40.620 
thank you so much for watching this video.
