WEBVTT

1
00:00:00.470 --> 00:00:03.880 
hello i am phillip daniels and i want to present you a machine

2
00:00:03.880 --> 00:00:08.010 
learning approach for suggesting feedback and exercises in large courses.

3
00:00:08.430 --> 00:00:11.390 
my coffers are Stephan Krusche and Bernd Bruegg.

4
00:00:12.440 --> 00:00:15.530 
the problem we are looking at is that our student population grew

5
00:00:15.690 --> 00:00:17.990 
by a factor of five over the last ten years.

6
00:00:19.270 --> 00:00:22.320 
and we are now teaching our lecture introduction to self engineering

7
00:00:22.320 --> 00:00:24.200 
to over two thousand students.

8
00:00:24.990 --> 00:00:29.210 
still our focus is on face-to-face teaching and we do this by offering

9
00:00:29.390 --> 00:00:32.690 
interactive in-class exercises during the lecture and also

10
00:00:32.700 --> 00:00:34.900 
weekly tutor groups and homework exercises.

11
00:00:35.710 --> 00:00:38.870 
however, this results in what we call a grading nightmare.

12
00:00:39.620 --> 00:00:43.060 
over the course of the semester we need to assess roughly two hundred thousand

13
00:00:43.410 --> 00:00:47.040 
student answers which results in fourteen thousand assessments

14
00:00:47.040 --> 00:00:48.210 
that need to be done every week.

15
00:00:49.350 --> 00:00:53.010 
our goal is to reduce grading efforts by using automation.

16
00:00:53.480 --> 00:00:58.050 
we can already do this for program exercises and also for multiple-choice quizzes.

17
00:00:59.180 --> 00:01:03.020 
still we want to extend the computed feedback to more exercise types

18
00:01:03.140 --> 00:01:05.090 
and also improve consistency.

19
00:01:06.190 --> 00:01:10.050 
with this research we propose computer aided assessments
for texture exercises.

20
00:01:10.970 --> 00:01:12.860 
before I want to explain the year

21
00:01:13.470 --> 00:01:18.350 
system that we developed i want to talk about a lot statement based assessment concept.

22
00:01:18.750 --> 00:01:23.390 
so instead of assessing a texture exercise as a whole we

23
00:01:23.880 --> 00:01:28.050 
propose a segment based assessment concept which suggest that

24
00:01:28.340 --> 00:01:32.380 
rado feedback is created for individual segments of text which

25
00:01:32.390 --> 00:01:34.620 
results in a structured form of feedback.

26
00:01:35.490 --> 00:01:41.790 
this allows the system to propose human feedback for
individual segments that

27
00:01:42.080 --> 00:01:43.440 
share a similar meaning.

28
00:01:44.300 --> 00:01:48.550 
so in an ideal world when an instructor opens an assessment,

29
00:01:48.720 --> 00:01:52.620 
he only needs to check the feedback and can then save and continue

30
00:01:52.620 --> 00:01:53.560 
with the next assessment.

31
00:01:54.900 --> 00:01:58.740 
let's have a look at the approach that is called computer-aided feedback for

32
00:01:58.840 --> 00:02:00.850 
teacher exercises a short CoFee.

33
00:02:03.090 --> 00:02:05.420 
after the answers have been submitted to the system,

34
00:02:06.470 --> 00:02:10.940 
a CoFee performs a similarity analysis to identify clusters

35
00:02:10.950 --> 00:02:12.740 
of those segments that share similar meaning.

36
00:02:14.520 --> 00:02:17.210 
after this process is done the assessment can start.

37
00:02:19.170 --> 00:02:22.260 
the system provides feedback suggestions and presented to the

38
00:02:22.260 --> 00:02:24.350 
teacher who's reviewing the answer.

39
00:02:26.090 --> 00:02:29.560 
the teacher still reviews the feedback suggestions and also

40
00:02:29.960 --> 00:02:32.730 
can fill gaps that have not been

41
00:02:33.930 --> 00:02:37.510 
created by the system or to correct mistakes in case the feedback

42
00:02:37.510 --> 00:02:38.610 
suggestions are not accurate.

43
00:02:39.420 --> 00:02:43.880 
the resulting manual feedback is then used to improve the assessment knowledge

44
00:02:44.020 --> 00:02:47.170 
that the system uses to compute the feedback suggestions.

45
00:02:48.440 --> 00:02:52.070 
the assessment knowledge is empty in the beginning of the exercise and only trained

46
00:02:52.240 --> 00:02:55.640 
through the many reviews that are created by the teach us.

47
00:02:56.060 --> 00:02:59.650 
so naturally in the beginning there are no feedback suggestions and as the

48
00:02:59.930 --> 00:03:02.800 
assessment progresses more and more feedback suggestions can

49
00:03:02.800 --> 00:03:05.930 
be created and less manual reviews unnecessary.

50
00:03:08.190 --> 00:03:09.570 
in the long term we envision

51
00:03:10.350 --> 00:03:13.830 
the system to provide complete automatic reviews reviews also

52
00:03:13.830 --> 00:03:15.180 
based on the assessment knowledge.

53
00:03:16.070 --> 00:03:19.420 
that way we can offer a feedback loop where students can support

54
00:03:19.420 --> 00:03:21.130 
multiple times and still receive feedback.

55
00:03:22.100 --> 00:03:25.880 
we've implemented this approach in defeat and the system
that we call athene.

56
00:03:27.180 --> 00:03:29.910 
athene can be integrated into learning management systems.

57
00:03:30.380 --> 00:03:33.190 
in our case we've chosen a thomas which is a learning management

58
00:03:33.190 --> 00:03:34.810 
system developed at our research group.

59
00:03:36.770 --> 00:03:40.780 
the feedback engine that is now part of optimus used a similarity

60
00:03:40.780 --> 00:03:42.350 
analysis service from the athene system.

61
00:03:43.620 --> 00:03:47.180 
the athene consists of three components. first the segmentation

62
00:03:47.180 --> 00:03:51.170 
component that uses the python natural language toolkit this component identifies.

63
00:03:51.670 --> 00:03:55.160 
topics that a community used from all students in the ancestor and

64
00:03:55.520 --> 00:03:58.390 
then identifies segments that talk about

65
00:03:58.820 --> 00:04:01.240 
one topic within one student answer.

66
00:04:02.520 --> 00:04:05.190 
those segments are then later reviewed by the teachers.

67
00:04:06.610 --> 00:04:10.640 
next we have a language embedding component that converts the

68
00:04:10.950 --> 00:04:15.300 
segments into a vector representation which can then be used for further computation.

69
00:04:15.720 --> 00:04:17.070 
we use the eml language model

70
00:04:17.960 --> 00:04:18.780 
created by google.

71
00:04:20.170 --> 00:04:24.320 
last we perform a clustering of those multidimensional vector representations

72
00:04:24.570 --> 00:04:26.570 
using the hdb skin clustering algorithm.

73
00:04:27.560 --> 00:04:31.180 
those clusters identified in segments of a similar meaning.

74
00:04:32.980 --> 00:04:36.170 
the segments clusters and similarity metrics can then be shared

75
00:04:36.210 --> 00:04:38.200 
with the feedback engine that is part of optimus.

76
00:04:40.140 --> 00:04:44.650 
refused the athene system in two courses last summer

77
00:04:45.720 --> 00:04:48.100 
for a total of seventeen exercises.

78
00:04:48.780 --> 00:04:53.190 
as part of an evaluation we want to answer three research questions. first,

79
00:04:53.400 --> 00:04:57.180 
how much feedback cannot can be automatically suggested? second,

80
00:04:57.300 --> 00:05:01.130 
how accurate is to suggested feedback? and lastly, how the students

81
00:05:01.130 --> 00:05:03.640 
perceived the quality of the automatic feedback suggestions?

82
00:05:04.550 --> 00:05:10.360 
first coverage. an average twenty six percent of all submissions

83
00:05:10.580 --> 00:05:12.790 
could be automatically created by the athene system.

84
00:05:14.110 --> 00:05:17.130 
the best case scenario athene covered up to seventy

85
00:05:17.130 --> 00:05:19.250 
percent of reviews for feedback suggestions.

86
00:05:19.790 --> 00:05:25.100 
and this is without any previous training data or pretty for a pre-defined solution

87
00:05:25.450 --> 00:05:28.370 
all assessment knowledge was generated during the creating process.

88
00:05:29.510 --> 00:05:34.730 
second we looked at we chose a subset of nine exercises to analyze the accuracy.

89
00:05:34.980 --> 00:05:40.770 
therefore we analyzed how the teachers were working
fifty automatic feedback suggestions.

90
00:05:42.040 --> 00:05:45.070 
we can summarize that an average eighty five percent of the

91
00:05:45.230 --> 00:05:49.110 
suggestions were accepted by the creator and directly published to the students.

92
00:05:49.590 --> 00:05:52.390 
not a five percent were extended with an additional comment

93
00:05:53.210 --> 00:05:56.030 
and ten percent of the feedback suggestions were discarded.

94
00:05:57.210 --> 00:06:01.050 
lastly looking at the quality we asked students to rate the

95
00:06:01.050 --> 00:06:04.280 
usefulness of the received feedback on a five star scale.

96
00:06:06.370 --> 00:06:09.490 
our anecdotal evidence here suggests that

97
00:06:10.150 --> 00:06:13.890 
the quality has at least the feedback suggestions have at least

98
00:06:13.890 --> 00:06:17.030 
the same quality than manual feedback with

99
00:06:17.500 --> 00:06:21.950 
students being a bit more likely to give a five star rating on computer-aided feedback.

100
00:06:22.210 --> 00:06:24.940 
however, as only a few students participated

101
00:06:25.510 --> 00:06:27.870 
in this rating. this is only anecdotal evidence.

102
00:06:29.070 --> 00:06:32.140 
of future work includes training system with existing feedback

103
00:06:32.140 --> 00:06:34.390 
for example from a previous edition of the course.

104
00:06:34.950 --> 00:06:39.790 
next we want to use this structured data to also check the consistency between

105
00:06:40.130 --> 00:06:41.880 
the feedback for different students.

106
00:06:42.760 --> 00:06:46.760 
and lastly our evaluation so far has been focused on the software

107
00:06:46.760 --> 00:06:50.310 
engineering and computer science domain. we want to repeat the

108
00:06:50.310 --> 00:06:54.010 
evaluation in a different domain to prove that this concept

109
00:06:54.010 --> 00:06:56.610 
is independent of the computer science context.

110
00:06:57.530 --> 00:07:01.220 
to sum up the contributions we've developed a approach for

111
00:07:01.340 --> 00:07:05.500 
using supervised machine learning to create knowledge from assessment incrementally.

112
00:07:06.130 --> 00:07:09.670 
second we've implemented our approach as part of athene system.

113
00:07:10.150 --> 00:07:14.580 
and third we evaluated the athene system in two university courses with up to

114
00:07:14.820 --> 00:07:16.720 
one thousand eight hundred registered students.

115
00:07:17.410 --> 00:07:20.500 
thanks for interest in our research. and we're looking forward to discuss our

116
00:07:20.760 --> 00:07:22.350 
our system and our findings.
