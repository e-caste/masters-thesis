WEBVTT

1
00:00:00.660 --> 00:00:05.700 
Welcome to our excursion on game theory segregation
and potential functions. I am Pascal

2
00:00:05.810 --> 00:00:09.730 
and I'm Luise and will give you a brief
introduction into these topics.

3
00:00:10.120 --> 00:00:14.950 
We start with game theory. This
is a pretty old topic started

4
00:00:14.950 --> 00:00:17.910 
in the nineteen forties and
essentially it is the study of

5
00:00:17.910 --> 00:00:21.840 
mathematical models of strategic interaction
between rational decision makers.

6
00:00:23.120 --> 00:00:25.960 
The ingredients of every game
theoretic models are the following -

7
00:00:25.970 --> 00:00:30.060 
first of all we have strategic agents.
These agents choose strategies

8
00:00:30.060 --> 00:00:33.930 
and they do so to maximize some
potential, some utility function.

9
00:00:34.720 --> 00:00:38.900 
And for example one game would be the
famous rock paper scissors game

10
00:00:39.030 --> 00:00:42.000 
where we have two players and each
player essentially has different

11
00:00:42.000 --> 00:00:46.640 
actions playing rock, playing paper or
playing scissors and the strategy now

12
00:00:46.780 --> 00:00:50.420 
is any probability distribution over
these actions. So for example

13
00:00:50.420 --> 00:00:54.930 
a player could play a rock with
probability one half and paper

14
00:00:54.930 --> 00:00:57.670 
with probability one half. This
would be a valid strategy here.

15
00:00:58.480 --> 00:01:02.940 
Now if every agent chooses a strategy
this is called an outcome of the game

16
00:01:03.590 --> 00:01:06.480 
and we are interested not in any
outcome of the game but in

17
00:01:06.480 --> 00:01:09.480 
certain outcomes of the games which
are usually called equilibrium.

18
00:01:10.060 --> 00:01:15.000 
An equilibrium vector this is a
subset of all outcomes with

19
00:01:15.010 --> 00:01:18.170 
the certain property that they
are so called stable and stable

20
00:01:18.170 --> 00:01:22.390 
here means that an agent doesn't
want to change his current

21
00:01:22.390 --> 00:01:26.600 
strategy given the other strategies
by the other players. And there are

22
00:01:26.760 --> 00:01:29.250 
many names for this. This is the
nash equilibrium but there

23
00:01:29.250 --> 00:01:32.190 
are also different variants of this
definition called pairwise stability

24
00:01:32.190 --> 00:01:36.270 
or the core and so on. There's a rich
field studying these so called stable

25
00:01:36.990 --> 00:01:38.240 
situations of a game.

26
00:01:40.170 --> 00:01:43.670 
Now the core questions here
are essentially first of

27
00:01:43.670 --> 00:01:47.970 
all do these stable states of
this game exist at all and if

28
00:01:47.970 --> 00:01:51.170 
they exist which properties do
they have and so on. And another

29
00:01:51.170 --> 00:01:55.090 
thing is well how to essentially
design the game to enforce

30
00:01:55.100 --> 00:01:57.190 
the existence of
certain equilibria.

31
00:01:58.010 --> 00:02:02.120 
So this is the pure game theory
side and then later on

32
00:02:02.130 --> 00:02:06.210 
the more algorithmic point
of view came around.

33
00:02:06.220 --> 00:02:09.670 
This is called the algorithmic game
theory. This is essentially studying

34
00:02:09.670 --> 00:02:13.900 
the same questions but from an algorithmic
perspective. So instead of asking

35
00:02:14.050 --> 00:02:18.850 
do equilibria exist, we can ask
how can players find equilibria,

36
00:02:19.180 --> 00:02:25.430 
is the existence or the question if equilibria
exists is this is a computationally hard question,

37
00:02:25.750 --> 00:02:28.980 
can we approximate equilibria, what
is the impact of the selfishness

38
00:02:29.150 --> 00:02:32.470 
of the players on this underlying
optimization problem and

39
00:02:32.470 --> 00:02:35.180 
so on. So there are many questions
essentially we can turn all

40
00:02:35.180 --> 00:02:38.600 
these standard old questions
from the standard game theory

41
00:02:38.830 --> 00:02:41.470 
into more algorithmic questions
and this is what algorithmic

42
00:02:41.470 --> 00:02:42.570 
game theory is about.

43
00:02:43.980 --> 00:02:49.300 
And then the next step and this is the very current
trend in artificial intelligence research

44
00:02:49.500 --> 00:02:53.640 
is essentially that well many
artificial intelligence systems

45
00:02:53.640 --> 00:02:57.010 
are so called multi-agent systems.
So there you have rational

46
00:02:57.010 --> 00:03:00.590 
agents interacting with each other
and this essentially calls

47
00:03:00.590 --> 00:03:03.720 
for game theory to analyze these
situations. So essentially

48
00:03:03.720 --> 00:03:08.400 
we can ask the same questions also
for systems with multi agents.

49
00:03:08.950 --> 00:03:14.210 
So multiple agents. Alright and now
Luise will show you an example

50
00:03:14.210 --> 00:03:18.550 
of a very interesting real world
multi-agent systems which

51
00:03:18.550 --> 00:03:19.530 
we will then analyze.

52
00:03:20.730 --> 00:03:23.630 
Thanks Pascal. So we will start
with the phenomenon and the

53
00:03:23.640 --> 00:03:27.930 
phenomenon is called segregation
which is a pretty famous phenomenon

54
00:03:27.940 --> 00:03:33.080 
such a logical research. And it
means that the group of mixed

55
00:03:33.080 --> 00:03:37.490 
people tends to separate over
time. A pretty famous example

56
00:03:37.490 --> 00:03:40.750 
is residential segregation in the
US and you can see here plots

57
00:03:40.750 --> 00:03:45.050 
from the racial dot map from New York
City, Atlanta, Chicago and Los Angeles

58
00:03:45.510 --> 00:03:50.780 
where you see that different groups
with different ethnic backgrounds

59
00:03:51.080 --> 00:03:55.070 
live in their own communities.
You can see the green people,

60
00:03:55.070 --> 00:03:57.590 
the blue people, the red
people and they all have

61
00:03:58.080 --> 00:04:00.480 
the same ethical
background.

62
00:04:02.070 --> 00:04:06.530 
And segregation is the outcome of a strategic
location choice by selfish agents

63
00:04:07.170 --> 00:04:12.290 
where the people are the selfish agents and
they make they make different choices

64
00:04:12.540 --> 00:04:16.290 
and the outcome is
segregation then.

65
00:04:17.440 --> 00:04:22.670 
So there was a famous easy
model by Schelling which

66
00:04:22.670 --> 00:04:26.650 
was introduced in the seventies
and there are two types

67
00:04:26.650 --> 00:04:32.010 
of agents which are placed on the line
on a grid and agents have different

68
00:04:32.170 --> 00:04:36.160 
tolerance parameters. A tow
which is between zero and one.

69
00:04:36.630 --> 00:04:42.930 
So for instance one half means that agents
are happy if half of their neighbours

70
00:04:43.270 --> 00:04:47.540 
have the same type
as their own.

71
00:04:48.150 --> 00:04:52.410 
And if an agent is discontent
then she wants to swap

72
00:04:52.410 --> 00:04:54.600 
or jump randomly to
another position.

73
00:04:56.350 --> 00:05:00.190 
And the phenomenon which we
can then see is that from

74
00:05:00.190 --> 00:05:05.800 
an initial random placement the process
which is a severly segregated state

75
00:05:06.000 --> 00:05:09.720 
even if agents are very tolerant.
So if the tolerant parameter

76
00:05:09.720 --> 00:05:13.740 
is below one half and they are
fine with being in the minority.

77
00:05:15.220 --> 00:05:19.200 
And Schelling actually won the
Nobel Prize for this with the

78
00:05:19.200 --> 00:05:22.880 
book which was called
Micromotives vs. Macrobehaviour

79
00:05:23.500 --> 00:05:25.660 
which means that

80
00:05:27.690 --> 00:05:32.110 
the bias from agents in
their microperspective

81
00:05:32.160 --> 00:05:38.220 
leads to a phenomenon in the
macro in a macrophenomenon

82
00:05:38.690 --> 00:05:41.820 
and this explains why even a
population of tolerant agents

83
00:05:41.820 --> 00:05:44.070 
can end up in a
segregated state.

84
00:05:45.610 --> 00:05:48.670 
And if you want to play around a little
bit with this phenomenon you can

85
00:05:48.900 --> 00:05:54.815 
go to this website ncase.me/polygons/
and there you can

86
00:05:52.000 --> 00:05:54.815 
and there you can

87
00:05:54.815 --> 00:05:57.630 
see um how does
a phenomenon

88
00:05:58.760 --> 00:06:03.210 
reach out by the by
the by the agents.

89
00:06:04.670 --> 00:06:08.580 
And game theory dig model from
Schelling segregation was

90
00:06:08.580 --> 00:06:11.890 
introduced in two thousand and
eighteen and there we have a

91
00:06:11.900 --> 00:06:15.680 
model with strategic agent which are
placed on an arbitrary host graph.

92
00:06:15.940 --> 00:06:18.100 
And agents only care
about the neighborhood.

93
00:06:18.830 --> 00:06:21.090 
An agent is happy if

94
00:06:21.780 --> 00:06:25.670 
the number of same type
agents in his neighborhood

95
00:06:26.190 --> 00:06:31.030 
divided by the total number of
agents in the neighbourhood is

96
00:06:31.210 --> 00:06:33.410 
larger than the tolerance
perimeter tow.

97
00:06:34.560 --> 00:06:38.440 
So an agent has cost of zero
if she's happy, so if

98
00:06:38.890 --> 00:06:43.460 
more agents as a reflection of
the agent with the same type

99
00:06:43.460 --> 00:06:47.680 
is larger than tow otherwise
she wants to have

100
00:06:48.340 --> 00:06:53.790 
as many same type agents as
possible in her neighborhood. So

101
00:06:54.310 --> 00:06:57.500 
the cost are then
tow minus the

102
00:06:58.120 --> 00:07:00.880 
fraction of same type
neighbors in a neighborhood.

103
00:07:02.260 --> 00:07:05.290 
And then there are two
possibilities how

104
00:07:05.730 --> 00:07:10.370 
an agent can change a place,
so two different strategies,

105
00:07:10.390 --> 00:07:14.440 
the first one is in the so called
swap Schelling game that a

106
00:07:14.440 --> 00:07:18.760 
pair of unhappy agents can swap
positions. So the two unhappy

107
00:07:18.760 --> 00:07:21.690 
agents yellow and blue

108
00:07:22.490 --> 00:07:25.720 
can swap positions and are
both happy afterwards.

109
00:07:26.610 --> 00:07:28.680 
And the second game was
the Jump Schelling game.

110
00:07:29.220 --> 00:07:33.610 
There too unhappy agents can
jump to an empty position.

111
00:07:33.820 --> 00:07:38.340 
So the yellow agent is unhappy and
then she can jump to a position

112
00:07:38.340 --> 00:07:40.010 
where she is happy
afterwards.

113
00:07:41.640 --> 00:07:44.400 
And the research question
which we want to answer now

114
00:07:44.400 --> 00:07:48.480 
is can agents find an equilibrium
via iterative improving moves?

115
00:07:49.900 --> 00:07:55.760 
And the answers for the swap game, yes
if the tolerance parameter is below

116
00:07:55.860 --> 00:07:59.830 
or equal to one half, no if
the tolerance parameter

117
00:07:59.830 --> 00:08:01.170 
is larger than one half

118
00:08:01.820 --> 00:08:05.350 
and for the jump game it is
the answer is always no

119
00:08:05.970 --> 00:08:10.340 
for the entire range of
tolerance per meter.

120
00:08:11.130 --> 00:08:14.970 
And we can show this via a
potential function that

121
00:08:15.620 --> 00:08:19.310 
the game always converges and via
improving response circuits that

122
00:08:19.520 --> 00:08:21.490 
we gain no

123
00:08:22.270 --> 00:08:25.510 
convergence and Pascal will
show how. Yeah thanks.

124
00:08:26.500 --> 00:08:29.210 
Alright so we look at these two
things and we first start

125
00:08:29.210 --> 00:08:33.190 
with the positive result. So
we start with the idea how

126
00:08:33.190 --> 00:08:38.110 
to prove the statement that essentially
convergence is guaranteed if tow is

127
00:08:38.560 --> 00:08:42.650 
less than one half or equal to one
half and beyond in the swap game.

128
00:08:42.650 --> 00:08:45.300 
And convergence here means that
essentially you look at any

129
00:08:45.300 --> 00:08:49.630 
sequence of improving moves and this
sequence must be finite. So at some point

130
00:08:49.970 --> 00:08:54.120 
by iteratively improving the agents
will reach an equilibrium state.

131
00:08:55.020 --> 00:09:00.440 
And the key key tool for analyzing this
is a so called potential function

132
00:09:00.590 --> 00:09:03.880 
which is very well known tool
also in the algorithms

133
00:09:03.880 --> 00:09:06.780 
community. So you also use this
for analyzing the behavior of

134
00:09:06.780 --> 00:09:09.900 
algorithms or data structures
and we can do the same thing

135
00:09:09.900 --> 00:09:11.460 
here for analyzing
our game.

136
00:09:12.510 --> 00:09:16.320 
A potential function phi essentially
maps a state of the game

137
00:09:16.320 --> 00:09:20.910 
to real number. So to be more precise
we map the vector of strategies

138
00:09:20.910 --> 00:09:25.950 
to a real number here and this
we do so with the following

139
00:09:25.950 --> 00:09:30.440 
properties. We want to have for the
function phi the following should hold -

140
00:09:31.440 --> 00:09:37.380 
if agent if the sum agent improves then
also the potential should decrease

141
00:09:37.570 --> 00:09:40.290 
by at least some
value epsilon here.

142
00:09:41.140 --> 00:09:44.490 
And this means whenever an agent
improves we know the potential

143
00:09:44.490 --> 00:09:50.030 
function value will decrease
and to make this work we also

144
00:09:50.030 --> 00:09:53.410 
need that the minimum potential
function value is lower bounded,

145
00:09:53.410 --> 00:09:56.130 
so there is a trivial lower
bound for this value

146
00:09:57.170 --> 00:10:01.070 
and then with these two ingredients
well if agent improved

147
00:10:01.070 --> 00:10:05.100 
the potential decreases and we have
a lower bound. This means that

148
00:10:05.270 --> 00:10:08.910 
whenever the agents will get stuck
in a local minimum of this

149
00:10:09.070 --> 00:10:12.430 
function phi then this corresponds
to an equilibrium state

150
00:10:12.770 --> 00:10:17.050 
because a local minimum means
that no agent can improve on

151
00:10:17.050 --> 00:10:20.740 
your current strategy and this is exactly
the definition of an equilibrium here.

152
00:10:22.130 --> 00:10:28.000 
Alright now we use this concept for our swap
game with tow less or equals one half

153
00:10:28.300 --> 00:10:32.490 
and to make this proof
work we simply choose a

154
00:10:32.490 --> 00:10:36.130 
a suitable potential function in one
function which works very nicely here

155
00:10:36.290 --> 00:10:41.720 
is the following. Essentially
we sum up of all the agents

156
00:10:41.730 --> 00:10:45.860 
with sum up the number of neighbors
of other type in their neighborhood

157
00:10:46.100 --> 00:10:47.820 
and then we divide
all of this by two.

158
00:10:48.550 --> 00:10:52.440 
And if you think about it this
is exactly the same as if we

159
00:10:52.500 --> 00:10:56.340 
look at the graph and we count
the number of edges the number

160
00:10:56.340 --> 00:10:58.650 
of edges between agents
with different type.

161
00:10:59.510 --> 00:11:03.390 
And now for this potential
function so essentially any

162
00:11:03.910 --> 00:11:06.860 
any strategy vector
can now be

163
00:11:07.520 --> 00:11:11.090 
turned into a value by this function
here and now you can easily

164
00:11:11.090 --> 00:11:14.570 
check that the function has the
right properties that for example

165
00:11:14.580 --> 00:11:18.190 
if an agent improves then also
this value will drop and also

166
00:11:18.190 --> 00:11:21.790 
trivially this potential function has
a lower bound which is simply zero.

167
00:11:23.480 --> 00:11:27.260 
Alright now you can with this function
because this has the right properties

168
00:11:27.400 --> 00:11:30.820 
this also means that equilibria
will always exist and that

169
00:11:31.030 --> 00:11:33.930 
improving moves will always
converge to such an equilibrium.

170
00:11:35.720 --> 00:11:37.890 
Alright now you know
for the negative side

171
00:11:38.430 --> 00:11:42.140 
through the negative result for
the jump game we want to prove

172
00:11:42.150 --> 00:11:46.480 
that the convergence is not
guaranteed and essentially this

173
00:11:46.480 --> 00:11:50.740 
is independent of tow and we do this with
a so called improving response cycle.

174
00:11:51.620 --> 00:11:56.070 
Ok now what is this? Improving
response cycles is

175
00:11:56.070 --> 00:11:58.750 
something like the opposite of a
potential function. So essentially

176
00:11:58.750 --> 00:12:02.250 
this is a cyclic sequence, a
sequence of states of the game

177
00:12:02.880 --> 00:12:06.990 
and the next state in the sequence
is reached by an improving

178
00:12:06.990 --> 00:12:09.220 
move of some agents in
the previous state.

179
00:12:09.780 --> 00:12:13.610 
So this means we have a sequence
of improving moves to agents

180
00:12:13.610 --> 00:12:16.190 
improve and improve and improve
and then at some point they

181
00:12:16.190 --> 00:12:18.680 
end up in a state they
have seen before.

182
00:12:20.810 --> 00:12:25.830 
Alright and here's the proof for
the jump game and essentially

183
00:12:25.830 --> 00:12:30.610 
this proof works for all tow by
setting this value x essentially

184
00:12:30.610 --> 00:12:33.650 
to the right values just x has
just to be large enough.

185
00:12:34.350 --> 00:12:39.450 
And here you see essentially
four steps. So in the first

186
00:12:39.450 --> 00:12:43.730 
step you see a marked by red
essentially which agent jumps.

187
00:12:44.940 --> 00:12:48.550 
To understand this construction
you need to know that wherever

188
00:12:48.550 --> 00:12:50.470 
we have these
multiple nodes

189
00:12:51.380 --> 00:12:57.120 
with this x above, this means this
is a clique of x many nodes

190
00:12:57.120 --> 00:13:00.120 
so they are all interconnected
and whenever we have an edge

191
00:13:00.130 --> 00:13:03.240 
into such a clique or out of
such a clique this means this

192
00:13:03.240 --> 00:13:06.320 
edge is connected to all of the nodes
in that clique or essentially it

193
00:13:06.530 --> 00:13:09.880 
goes from all these nodes in the
clique to the into another node.

194
00:13:11.180 --> 00:13:14.680 
Now you see here that after these
four steps so each of these

195
00:13:14.680 --> 00:13:18.200 
four steps are improving moves
for the for the moving player

196
00:13:18.850 --> 00:13:22.780 
and at the end is actually we are
back to our original situation.

197
00:13:23.540 --> 00:13:28.840 
And this shows that by improving moves
convergence is not guaranteed.

198
00:13:28.850 --> 00:13:33.100 
So this means you can run into
these cycles and this also proves

199
00:13:33.110 --> 00:13:37.380 
that for this game no potential
function can exist. So essentially

200
00:13:37.380 --> 00:13:40.680 
the existence of an improving
response cycle is a proof that

201
00:13:40.680 --> 00:13:42.900 
there can be no potential
function for this game.

202
00:13:44.780 --> 00:13:49.840 
Right ok, so what we have seen
today and we've seen a very very

203
00:13:49.840 --> 00:13:53.310 
brief and quick introduction into
algorithmic game theory and

204
00:13:53.310 --> 00:13:57.460 
the main point is that this is a
model or a set of tools which

205
00:13:57.460 --> 00:14:00.850 
is suited for analyzing
interactions of selfish agents

206
00:14:01.120 --> 00:14:04.610 
and this is a very recent trend in
foundational AI research because

207
00:14:04.610 --> 00:14:07.380 
many AI systems essentially
are multi-agent systems.

208
00:14:08.290 --> 00:14:13.970 
Then as a as a concrete example we've
seenSchellings model for residential segregation

209
00:14:14.110 --> 00:14:16.230 
which is essentially an
agent based system

210
00:14:17.060 --> 00:14:21.850 
and we've seen here that essentially by
the selfish location choice of agents

211
00:14:21.950 --> 00:14:25.200 
we reach these segregated states which
we also see in the real world.

212
00:14:26.080 --> 00:14:30.680 
And now on the more technical side
we have seen potential function

213
00:14:30.730 --> 00:14:36.450 
which is a tool for analyzing dynamic systems,
more concrete for analyzing essentially

214
00:14:36.640 --> 00:14:40.200 
the behavior over time of these
dynamic systems and we have

215
00:14:40.200 --> 00:14:43.590 
seen that the existence of such
a potential function first

216
00:14:43.590 --> 00:14:46.630 
of all guarantees convergence to
equilibrium and at the same

217
00:14:46.630 --> 00:14:50.030 
time also proves that equilibria
also exist. And we have also

218
00:14:50.030 --> 00:14:53.190 
seen the other side that eventually
if we can prove that an

219
00:14:53.190 --> 00:14:57.220 
improving response cycle exists then
we know that no potential function

220
00:14:57.920 --> 00:14:58.760 
can exist.

221
00:14:59.990 --> 00:15:04.110 
Alright that's it from our side.
A very brief introduction

222
00:15:04.110 --> 00:15:08.710 
into game theory segregation and
potential functions. Thank you.
