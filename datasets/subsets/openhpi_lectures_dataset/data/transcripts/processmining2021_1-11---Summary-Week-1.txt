WEBVTT

1
00:00:00.750 --> 00:00:04.530 
Welcome to this video clip in which we summarise week one.

2
00:00:06.150 --> 00:00:11.159 
So we started this week by introducing business processes

3
00:00:11.160 --> 00:00:15.629 
and by introducing process mining, we looked

4
00:00:15.630 --> 00:00:18.178 
at the main elements, main artefacts used in process

5
00:00:20.250 --> 00:00:23.386 
mining. We identified the role of a blueprint process model, the

6
00:00:24.780 --> 00:00:29.489 
effect on the process, execution, environment, and primarily

7
00:00:29.490 --> 00:00:33.900 
also the data, the heterogeneous types of data that's been created

8
00:00:34.080 --> 00:00:36.319 
during business process executions.

9
00:00:37.020 --> 00:00:39.568 
We discussed then how we do events like a generation

10
00:00:42.090 --> 00:00:46.820 
and the event Laucke as a standardised representation of the process execution.

11
00:00:46.830 --> 00:00:51.240 
We can use event logs to do process discovery with the discovery

12
00:00:51.250 --> 00:00:55.740 
process model so we can do process enhancement and with event

13
00:00:56.130 --> 00:01:00.869 
the event look, we can also do conformance tracking and that will be done in the next

14
00:01:00.870 --> 00:01:01.870 
week.

15
00:01:03.570 --> 00:01:08.189 
To look at the event log generation, we started our endeavour simply

16
00:01:08.190 --> 00:01:11.522 
by a number of tables that we generated out of forms of spreadsheets

17
00:01:13.290 --> 00:01:17.640 
and so forth. So we the first thing that we did here now is step by step

18
00:01:18.690 --> 00:01:22.249 
way of looking at process mining is to extract the data.

19
00:01:22.280 --> 00:01:26.959 
So we needed to find process execution data and we needed to store

20
00:01:27.060 --> 00:01:28.170 
this in tables.

21
00:01:29.520 --> 00:01:31.676 
We then took a step from the data to events.

22
00:01:33.870 --> 00:01:38.400 
And that is very important because the data sometimes is not really

23
00:01:38.490 --> 00:01:43.230 
immediately related to events and we need to find ways of

24
00:01:43.500 --> 00:01:46.199 
transforming data to events.

25
00:01:46.200 --> 00:01:50.909 
And the events are then representing activities in the process.

26
00:01:50.910 --> 00:01:53.850 
So we identified events and also event types which represent

27
00:01:55.890 --> 00:01:57.510 
process activities.

28
00:01:58.890 --> 00:02:01.487 
We use timestamp information to order these events in

29
00:02:03.330 --> 00:02:07.799 
the context of an event log, and we used instant

30
00:02:07.800 --> 00:02:09.564 
correlation well to identify traces.

31
00:02:11.610 --> 00:02:16.199 
And the traces represent all the behaviour that we can find

32
00:02:16.470 --> 00:02:17.789 
in an event like.

33
00:02:20.220 --> 00:02:23.013 
We moved on to to discuss a little scenario or a sequence

34
00:02:25.050 --> 00:02:29.819 
of scenarios based on process discovery and process enhancement.

35
00:02:29.850 --> 00:02:34.319 
So we started without any process model which started just with

36
00:02:34.320 --> 00:02:36.574 
the execution data that we used for event like

37
00:02:39.030 --> 00:02:41.009 
generation in the first place.

38
00:02:42.420 --> 00:02:47.249 
Then we discovered a process model P one, and we found that the process

39
00:02:47.250 --> 00:02:52.160 
model P1 has a problem because not all claims are executed properly.

40
00:02:52.170 --> 00:02:54.816 
So we designed process model P to enhancing P one with

41
00:02:56.610 --> 00:02:58.240 
a clean update cycle.

42
00:02:58.800 --> 00:03:01.642 
We well, we implemented this and we discovered this and we

43
00:03:03.360 --> 00:03:08.110 
confirmed the implementation. So everything was was executed as planned.

44
00:03:09.520 --> 00:03:11.725 
We made one further step while with including

45
00:03:14.460 --> 00:03:18.380 
reviewing activity. So we had internal one internal review and activities and we

46
00:03:18.900 --> 00:03:23.509 
also activities for inviting reviews and receiving reviews.

47
00:03:24.180 --> 00:03:27.022 
And we in the process model, we said, well, this should be

48
00:03:28.650 --> 00:03:33.090 
all always done, all of these three activities and also concurrently.

49
00:03:34.810 --> 00:03:39.024 
We looked at the data and we found that, well, it's not exactly how it happened, so we

50
00:03:39.280 --> 00:03:42.661 
could discover a different we could discover a different way that the

51
00:03:44.050 --> 00:03:48.939 
events are organised. Sometimes events are missing and sometimes events were organised

52
00:03:48.940 --> 00:03:51.669 
in a different way. And this is where we discovered before.

53
00:03:53.630 --> 00:03:57.930 
In the last part of this first week, we looked as

54
00:03:58.190 --> 00:04:02.960 
at a simulated event logs or event logs,

55
00:04:03.380 --> 00:04:08.080 
and we use these logs to discover, process and enhance processes.

56
00:04:08.600 --> 00:04:11.540 
We were looking at, first of all, at exists log that you see

57
00:04:13.250 --> 00:04:17.329 
here on the left hand side, we briefly sketched

58
00:04:18.380 --> 00:04:21.320 
the inductive miner that is capable of abstracting behaviour

59
00:04:22.850 --> 00:04:25.429 
models or Petrine that out of this event.

60
00:04:25.430 --> 00:04:27.439 
Look, we had simulated different types of

61
00:04:30.020 --> 00:04:34.519 
event logs and we were using desco the process mining

62
00:04:34.520 --> 00:04:36.676 
to a disco to identify how to extract and to

63
00:04:39.140 --> 00:04:42.129 
mine. If you want to discover a directly follows graph and we

64
00:04:43.670 --> 00:04:48.199 
use this directly follows graph for a number of of additions

65
00:04:48.200 --> 00:04:51.169 
and of further enhancement of our process.

66
00:04:51.920 --> 00:04:55.252 
With that, we like to end the week one and we are looking forward to

67
00:04:56.420 --> 00:04:59.120 
meeting you then in week two of our online course.
