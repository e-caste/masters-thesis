WEBVTT

1
00:00:00.170 --> 00:00:04.190 
Welcome to this video clip in which we discuss
quality dimensions in Process Mining.

2
00:00:05.330 --> 00:00:09.690 
So, one of the key questions once
we have discovered a model

3
00:00:09.690 --> 00:00:13.780 
is of course how good is my model
and as we have seen in the

4
00:00:13.780 --> 00:00:17.590 
last week, there are many different
process discovery algorithms available.

5
00:00:18.140 --> 00:00:21.490 
And on top of that there are also
different parameters we can

6
00:00:21.490 --> 00:00:24.530 
use. So we can actually produce
many different models for the

7
00:00:24.960 --> 00:00:27.260 
very same event log and
the question is then

8
00:00:27.740 --> 00:00:31.440 
how good is the model that I have
just discovered and is there

9
00:00:31.440 --> 00:00:35.640 
any way to objectively assess
that. And what we would like to

10
00:00:35.640 --> 00:00:39.240 
introduce in the context of this
clip is that we can build

11
00:00:39.240 --> 00:00:42.440 
on the notion of underfitting
and overfitting from machine

12
00:00:42.440 --> 00:00:45.970 
learning to define such
objective quality dimensions.

13
00:00:46.390 --> 00:00:48.990 
So what is underfitting
and overfitting?

14
00:00:49.910 --> 00:00:53.030 
In machine learning we often fit
a model to training data for

15
00:00:53.030 --> 00:00:54.150 
the purpose of
prediction.

16
00:00:55.190 --> 00:00:59.040 
So if you look at this example what you
see here are a number of data points

17
00:00:59.470 --> 00:01:03.230 
and the red line represents a
model. And what you also see is

18
00:01:03.690 --> 00:01:07.410 
that there is a large distance from
the line to most of the data points

19
00:01:07.680 --> 00:01:10.820 
that the shape of the model and the
data is actually very different.

20
00:01:11.820 --> 00:01:14.980 
So in machine learning we would
call this underfitting because

21
00:01:15.110 --> 00:01:18.290 
the model and the red line here
is actually not a very good

22
00:01:18.290 --> 00:01:20.360 
representation of
the data points.

23
00:01:21.260 --> 00:01:25.350 
Another extreme case is this where
you can see that the red line in

24
00:01:25.510 --> 00:01:29.210 
of our model actually has a very
low distance, there's

25
00:01:29.210 --> 00:01:31.590 
a very low distance from the line
to most data points and at

26
00:01:31.590 --> 00:01:34.820 
the shape of the model in the data
are very similar and we could

27
00:01:34.820 --> 00:01:39.090 
argue here a bit too similar. So this
is what we refer to as overfitting.

28
00:01:40.020 --> 00:01:42.900 
So what we would like to have
both and machine learning also

29
00:01:42.900 --> 00:01:46.520 
in the context of process discovery
is a model that strikes

30
00:01:46.520 --> 00:01:50.810 
a balance between these two extremes. We would
like to have a reasonable abstraction

31
00:01:51.570 --> 00:01:55.380 
but we also would like to be not
would like to be too generic. So

32
00:01:56.570 --> 00:02:00.160 
in the context of process discovery
this is the very same problem.

33
00:02:00.160 --> 00:02:04.880 
We would like to discover a model that
is not too close to the event log

34
00:02:04.980 --> 00:02:09.290 
but also not too abstract, not too
generic and has nothing to do

35
00:02:09.460 --> 00:02:14.330 
with the event look anymore. So
let's take this idea and take

36
00:02:14.330 --> 00:02:15.590 
a look at our
process again.

37
00:02:16.570 --> 00:02:19.610 
So this is the claim handling
process we have been looking

38
00:02:19.610 --> 00:02:24.290 
at also in week one and what we
will do now is we will take

39
00:02:24.290 --> 00:02:25.920 
a look at this
particular fragment.

40
00:02:26.900 --> 00:02:31.480 
So here, this is the fragment after we
have conducted the completeness check

41
00:02:32.710 --> 00:02:36.390 
and have invited or conducted
these two reviews. So

42
00:02:36.850 --> 00:02:39.900 
the upper branch is the internal
review and the lower branch here

43
00:02:40.280 --> 00:02:41.820 
is the invitation
and then

44
00:02:42.620 --> 00:02:47.250 
we receive the
XOR review.

45
00:02:48.380 --> 00:02:51.390 
Important is that here in this
fragment, these two branches

46
00:02:51.390 --> 00:02:55.190 
are independent of each other and
so there is an end split. So these

47
00:02:55.650 --> 00:02:58.640 
activities can be executed in
different orders. What we would

48
00:02:58.640 --> 00:03:03.580 
like to do now is to take a look at how we
can represent this particular fragment

49
00:03:03.720 --> 00:03:05.530 
in different ways
with different

50
00:03:06.520 --> 00:03:09.510 
model fragments and how this relates
to underfitting and overfitting

51
00:03:09.710 --> 00:03:13.070 
and how this then helps us to
define such quality dimensions.

52
00:03:15.490 --> 00:03:19.960 
So what you see here is a so
called ad-hoc process. So this box

53
00:03:19.960 --> 00:03:23.340 
with this tiny wave means
that all these activities

54
00:03:23.740 --> 00:03:27.350 
all these three activities have
to be executed but the order

55
00:03:27.590 --> 00:03:31.560 
is not defined. So any order is
allowed. So whether we review

56
00:03:31.560 --> 00:03:35.210 
the claim internally first, whether we
invite the claim review first, whether we

57
00:03:36.380 --> 00:03:39.300 
receive the claim review
first is not defined here.

58
00:03:40.510 --> 00:03:44.020 
So already from from looking at
this example in more detail you

59
00:03:44.030 --> 00:03:47.450 
may realise that some combinations
may or may not really make

60
00:03:47.450 --> 00:03:50.670 
sense. For instance receiving the
claim review before inviting it.

61
00:03:50.790 --> 00:03:53.210 
According to this fragment
however this is allowed.

62
00:03:53.700 --> 00:03:56.420 
So if we take it
back to our

63
00:03:57.210 --> 00:04:00.080 
discussion of overfitting and unfitting,
we could argue that this

64
00:04:00.080 --> 00:04:04.590 
is underfitting. We have a very
generic fragment that allows

65
00:04:04.590 --> 00:04:06.540 
for a lot of
different traces

66
00:04:07.610 --> 00:04:13.020 
but is maybe a bit too abstract, too
generic and allows for too much

67
00:04:13.460 --> 00:04:15.140 
behavior, too many
different traces.

68
00:04:16.280 --> 00:04:17.770 
If we take a look
at this fragment

69
00:04:18.780 --> 00:04:22.850 
we see a sequence. So here the
order is very strictly defined.

70
00:04:22.850 --> 00:04:26.090 
in fact there is only one
specific activity order allowed.

71
00:04:26.650 --> 00:04:31.030 
The order is review claim internally, then
invite claim review and then receive claim.

72
00:04:31.440 --> 00:04:34.860 
This is the only order that is
allowed according to this fragment.

73
00:04:35.020 --> 00:04:38.440 
So it's a very strict fragment
of a very strict definition

74
00:04:38.940 --> 00:04:44.790 
of the activity order. Here we could
argue this is overfitting because it's

75
00:04:45.280 --> 00:04:49.220 
potentially way too strict. So we have
just one order that is allowed,

76
00:04:49.670 --> 00:04:52.460 
and depending on the event
log they might be simply

77
00:04:53.450 --> 00:04:56.230 
other activity orders
we have observed.

78
00:04:57.560 --> 00:05:01.700 
So this is the fragment we have
included in the original model.

79
00:05:01.810 --> 00:05:05.500 
Here we could argue that this strikes
balance between these two extremes.

80
00:05:05.650 --> 00:05:07.450 
So we have this
end split which

81
00:05:08.210 --> 00:05:12.330 
actually also comes with certain
restrictions. So as you can see, we

82
00:05:12.560 --> 00:05:15.540 
have to invite the claim review
before we can receive the claim

83
00:05:15.540 --> 00:05:19.530 
where this is defined in the
lower branch. But when we review

84
00:05:19.530 --> 00:05:23.370 
the claim internally it's not strictly
defined. So this can happen at any

85
00:05:23.470 --> 00:05:26.970 
given moment. So here we would
argue ok this strikes a balance

86
00:05:26.970 --> 00:05:28.050 
between this very

87
00:05:31.060 --> 00:05:35.400 
generous ad-hoc process and this
very strict notion of a sequence.

88
00:05:35.630 --> 00:05:38.280 
We could refer to this
as appropriate fitting.

89
00:05:40.950 --> 00:05:45.340 
If we take this idea and look at
quality dimensions, so based

90
00:05:45.340 --> 00:05:49.550 
on this idea of overfitting and
unfitting we can consider three

91
00:05:49.550 --> 00:05:51.890 
basic quality dimensions -
that is fitness,

92
00:05:52.340 --> 00:05:56.690 
precision and simplicity. Fitness
and precision are exactly

93
00:05:56.690 --> 00:05:59.840 
based on this idea of underfitting
and overfitting and characterize

94
00:05:59.840 --> 00:06:03.710 
the relationship between model
and event log. Simplicity then

95
00:06:03.710 --> 00:06:05.210 
only refers to
the model

96
00:06:06.590 --> 00:06:11.320 
but fitness and precision are
really based on this idea of

97
00:06:11.320 --> 00:06:13.580 
overfitting underfitting. So,
let's take a look.

98
00:06:14.860 --> 00:06:18.420 
Fitness tries to answer the
question - does the model cover the

99
00:06:18.420 --> 00:06:22.150 
traces from the event log? Yes, we
would like to make sure that

100
00:06:22.150 --> 00:06:25.960 
the model that we have discovered
can actually replay the

101
00:06:26.490 --> 00:06:30.700 
traces from the log. And this can
be quantified by exactly doing

102
00:06:30.700 --> 00:06:33.670 
that. So we can quantify this by
trying to replay each trace

103
00:06:33.670 --> 00:06:34.960 
from an event log
in the model

104
00:06:35.580 --> 00:06:38.960 
and then we can count how many
times we encounter an event

105
00:06:39.340 --> 00:06:42.270 
in the trace that cannot be
executed according to the model.

106
00:06:42.320 --> 00:06:44.920 
So if we take a look at
our claim process again,

107
00:06:45.850 --> 00:06:48.770 
we may for instance encounter a
trace of the event look where

108
00:06:49.510 --> 00:06:53.560 
the decision has been taken before
we have received the review.

109
00:06:53.870 --> 00:06:56.950 
This according to this model
would not be allowed and this

110
00:06:56.950 --> 00:07:00.210 
trace could accordingly not be
replayed in this model affecting

111
00:07:00.470 --> 00:07:03.810 
fitness negatively because the
model does not represent

112
00:07:04.330 --> 00:07:08.080 
a trace or does not cover a trace
we have actually seen in the log.

113
00:07:09.920 --> 00:07:13.350 
Precision turns it around. So, for
precision we are interested

114
00:07:13.350 --> 00:07:17.990 
in does the model allow for traces that
are not included in the event log.

115
00:07:19.060 --> 00:07:22.490 
So we would like to understand
does the model allow for traces

116
00:07:22.490 --> 00:07:23.390 
that we have not seen?

117
00:07:24.010 --> 00:07:27.190 
And we can quantify precision by
determining how many traces

118
00:07:27.190 --> 00:07:29.390 
from the model are not
part of the event log.

119
00:07:29.890 --> 00:07:32.630 
This however is not always
straightforward since many models

120
00:07:33.100 --> 00:07:36.270 
allow for infinite number of
traces. So let's take a look at

121
00:07:36.270 --> 00:07:38.610 
our example again to
illustrate this briefly.

122
00:07:39.060 --> 00:07:40.550 
So what you see
here is that

123
00:07:41.700 --> 00:07:46.610 
at the beginning there is of course the
possibility that this completeness check results

124
00:07:46.740 --> 00:07:51.250 
in the outcome that we realize
the claim is incomplete, we

125
00:07:51.830 --> 00:07:55.610 
have to receive an update and
we go through this cycle

126
00:07:56.260 --> 00:08:00.480 
and according to the model we can go
through this cycle many times. We can

127
00:08:00.850 --> 00:08:03.490 
go through the cycle once, we can
go through the cycle twice,

128
00:08:03.970 --> 00:08:06.740 
technically we can also go through
this cycle one hundred times.

129
00:08:07.380 --> 00:08:11.210 
And now we can imagine that this
is very unlikely to happen

130
00:08:11.210 --> 00:08:15.730 
in real life maybe. But the model
allows for it and this is exactly

131
00:08:15.920 --> 00:08:20.400 
what precision refers to - does the model
allow for traces that we have not

132
00:08:20.530 --> 00:08:24.070 
seen in the event log.
Lastly, simplicity

133
00:08:25.190 --> 00:08:28.060 
is concerned with a question
does the model represent event

134
00:08:28.060 --> 00:08:32.350 
log as simple as possible? So simplicity is
not concerned with the relationship between

135
00:08:32.670 --> 00:08:36.630 
event log and model but is really just
concerned with the model itself.

136
00:08:37.640 --> 00:08:39.510 
It can be quantified in
many different ways.

137
00:08:40.140 --> 00:08:43.820 
In many cases simplicity relates
to the number of model elements

138
00:08:43.900 --> 00:08:47.060 
and the model structure. So if we
take a look at this model again,

139
00:08:47.370 --> 00:08:51.850 
you can see that this model
is reasonably

140
00:08:51.850 --> 00:08:56.070 
easy, so it does not contain
a high number of elements.

141
00:08:56.070 --> 00:09:00.010 
It also does not contain complicated
structures and most importantly

142
00:09:01.080 --> 00:09:06.630 
that would be the baseline, here we cannot
simplify this model without really changing

143
00:09:06.870 --> 00:09:09.070 
the traces it covers.
