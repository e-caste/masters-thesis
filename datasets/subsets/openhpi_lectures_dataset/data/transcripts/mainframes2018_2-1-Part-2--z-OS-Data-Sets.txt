WEBVTT

1
00:00:00.550 --> 00:00:04.509 
Hello and welcome to the introduction to z/OS Datasets.

2
00:00:04.510 --> 00:00:08.500 
My name is Prof. Dr. Phillip Brune of the Neu Ulm University of Applied Sciences.

3
00:00:10.690 --> 00:00:15.999 
The file system of z/OS is special compared to filesystems

4
00:00:16.000 --> 00:00:20.859 
of operating systems that are more common to us, usually

5
00:00:22.180 --> 00:00:26.679 
like the file systems of Linux or Windows operating systems

6
00:00:26.680 --> 00:00:31.179 
or Unix operating systems, which are all hierarchical file systems,

7
00:00:31.180 --> 00:00:35.649 
meaning they have folders or directories containing files and other folders

8
00:00:35.650 --> 00:00:38.469 
and directories containing files. So they have a hierarchy.

9
00:00:40.000 --> 00:00:43.090 
The file system of z/OS is completely flat.

10
00:00:44.140 --> 00:00:48.639 
So basically, it just consists of files,

11
00:00:48.640 --> 00:00:53.079 
and these files are called datasets in the language

12
00:00:53.080 --> 00:00:55.991 
or the terminology of the mainframe of z/OS.

13
00:00:57.520 --> 00:01:02.199 
And also, these datasets, they are not

14
00:01:02.200 --> 00:01:07.359 
they cannot just be used, if you say, for example, a file on Windows or on Linux,

15
00:01:07.360 --> 00:01:11.829 
the file is just created, if it's not been saved before, this is not possible on the

16
00:01:11.830 --> 00:01:16.629 
z/OS file system. Every file on the file system has to be allocated

17
00:01:16.630 --> 00:01:21.249 
before it can be used the first time, and this step of allocation

18
00:01:21.250 --> 00:01:24.400 
means allocating memory on disk for this file.

19
00:01:25.630 --> 00:01:29.980 
Every file gets a size that is an initial size that is

20
00:01:31.300 --> 00:01:36.189 
associated with it during the allocation, which is the start size and

21
00:01:36.190 --> 00:01:40.029 
sometimes called as the primary extent, which is the size in the beginning.

22
00:01:40.030 --> 00:01:44.829 
And then during the allocation, a secondary extent is defined by which

23
00:01:44.830 --> 00:01:48.099 
the file can grow up to 15 times.

24
00:01:48.100 --> 00:01:52.659 
So in total, it's the primary extent plus maximum 15 times

25
00:01:52.660 --> 00:01:53.680 
the secondary extent.

26
00:01:54.910 --> 00:01:59.439 
If this is used completely, you

27
00:01:59.440 --> 00:02:04.089 
have to create a new file and copy the content in the new file, so files cannot

28
00:02:04.090 --> 00:02:05.739 
grow beyond this boundary.

29
00:02:07.030 --> 00:02:11.529 
And this is very typical for the mainframe, but very different from what

30
00:02:11.530 --> 00:02:16.029 
we are used to in other operating systems that for many of us,

31
00:02:16.030 --> 00:02:18.819 
are much more common at home, for example.

32
00:02:18.820 --> 00:02:22.840 
So these datasets, as they are called, are

33
00:02:24.190 --> 00:02:28.749 
allocated first and afterwards they they may be used and

34
00:02:32.740 --> 00:02:35.649 
this allocation takes place on a disk originally.

35
00:02:35.650 --> 00:02:40.269 
Today, of course, the I/O system of the of the mainframes

36
00:02:40.270 --> 00:02:44.859 
is completely virtualized to have storage systems, so we're not really

37
00:02:44.860 --> 00:02:47.439 
allocating files on physical disks anymore.

38
00:02:47.440 --> 00:02:49.929 
But logically still, this concept is there.

39
00:02:49.930 --> 00:02:54.549 
So in principle, a file is located on a disk and this

40
00:02:54.550 --> 00:02:57.939 
is called a volume in the mainframe terminology and

41
00:03:02.500 --> 00:03:05.169 
originally this volume had to be indicated.

42
00:03:05.170 --> 00:03:08.079 
Always when you wanted to open the file, you had to say, this is the volume, this is a

43
00:03:08.080 --> 00:03:12.249 
file. But then later on, the so-called catalogs were added.

44
00:03:12.250 --> 00:03:16.629 
And if a file is cataloged, meaning there's an entry in a central

45
00:03:18.130 --> 00:03:22.659 
repository or list where every file in the volume

46
00:03:22.660 --> 00:03:25.149 
is cataloged.

47
00:03:25.150 --> 00:03:30.069 
Then when you want to open it, the system looks in this catalog and

48
00:03:30.070 --> 00:03:32.049 
takes the volume out of there.

49
00:03:32.050 --> 00:03:37.029 
So, nowadays, if the file is cataloged, it's possible to access the files only

50
00:03:37.030 --> 00:03:38.710 
by the file name or the dataset name.

51
00:03:40.600 --> 00:03:45.249 
And the second thing is that the datasets have typically a record structure,

52
00:03:45.250 --> 00:03:48.159 
so they consist of records of a fixed length.

53
00:03:48.160 --> 00:03:52.659 
And these records are, uh, put together in blocks

54
00:03:52.660 --> 00:03:57.091 
which correspond to read, write operations that that can be read or written

55
00:03:59.290 --> 00:04:01.989 
in one step and

56
00:04:03.850 --> 00:04:08.289 
this record length also has to specify be specified when the when the file is

57
00:04:08.290 --> 00:04:11.469 
allocated and every record has the same length.

58
00:04:11.470 --> 00:04:13.719 
And so we have this strictly

59
00:04:16.240 --> 00:04:18.699 
regulated structure of this data sets.

60
00:04:19.720 --> 00:04:24.789 
And the names of the datasets are basically just

61
00:04:24.790 --> 00:04:29.679 
text or just strings that have some concepts to

62
00:04:29.680 --> 00:04:33.189 
give them a structure and organization since we do not have directories or things like

63
00:04:33.190 --> 00:04:38.109 
that. And these are the so-called qualifiers, so a dataset name

64
00:04:38.110 --> 00:04:42.579 
is a string with maximum of 44 characters, can be shorter, but maximum

65
00:04:42.580 --> 00:04:47.439 
44 characters. And it consists of so-called qualifiers and its qualifiers are separated

66
00:04:47.440 --> 00:04:51.850 
by dots, you can compare that maybe to the names of

67
00:04:53.410 --> 00:04:58.149 
the internet, the host names that you have dots and

68
00:04:59.440 --> 00:05:03.369 
domains, and so on. So in this sense, we have qualifiers and the qualifiers are separated

69
00:05:03.370 --> 00:05:08.259 
by dots. The full name is forty four characters, and in this example, it's split up into,

70
00:05:08.260 --> 00:05:12.789 
uh, five identical parts, apparently identical length, but

71
00:05:12.790 --> 00:05:17.259 
it doesn't have to be five. It can be also a different number, and the number of

72
00:05:17.260 --> 00:05:20.649 
dots can also be different. So it's basically that you have.

73
00:05:20.650 --> 00:05:26.529 
And it can be short, of course, to do not have to be so many dots or qualifiers.

74
00:05:26.530 --> 00:05:31.179 
Typically, the first qualifier, the so-called Top-Level Qualifier, is used for the

75
00:05:31.180 --> 00:05:35.859 
the user ID for normal user data and uh, for the system files or system

76
00:05:35.860 --> 00:05:40.719 
data sets. There are some reserved names and these are used and also to control

77
00:05:40.720 --> 00:05:45.219 
access rights and based on sort of names starting

78
00:05:45.220 --> 00:05:47.199 
with a certain qualifier, for example.

79
00:05:48.400 --> 00:05:52.929 
OK, so this is the the the basic structure of the of the

80
00:05:52.930 --> 00:05:57.429 
the file system of z/OS managing datasets.

81
00:05:57.430 --> 00:06:01.299 
And beside these flat files, there are also

82
00:06:02.470 --> 00:06:07.109 
so-called partitioned datasets, which are more or less the only type of structure

83
00:06:07.110 --> 00:06:11.649 
that the file system has. And this will be explained on the next

84
00:06:11.650 --> 00:06:16.149 
slide. Besides the normal flat dataset, which

85
00:06:16.150 --> 00:06:21.189 
is a simple file that you could read and process sequentially or an arbitrary order,

86
00:06:21.190 --> 00:06:25.969 
there is, uh, one type of special files that.

87
00:06:25.970 --> 00:06:30.889 
At least a similar to or has some resemblance to what we might call a directory,

88
00:06:30.890 --> 00:06:35.329 
but it's much simpler. It also does not provide a recursive hierarchical tree like

89
00:06:35.330 --> 00:06:38.329 
structure. And this is called the PDS.

90
00:06:38.330 --> 00:06:42.739 
So there are some datasets that are so-called PDS - partitioned datasets.

91
00:06:42.740 --> 00:06:47.299 
And later on there was an extended format called ePDS, which was edited, but

92
00:06:47.300 --> 00:06:49.759 
it's very similar regarding use.

93
00:06:50.930 --> 00:06:56.329 
And these two type of files can be understood as a kind of a library.

94
00:06:56.330 --> 00:07:01.609 
So basically, these PDS are just data sets, but

95
00:07:01.610 --> 00:07:06.619 
they have an internal structure that consists of a directory in the beginning.

96
00:07:06.620 --> 00:07:11.809 
So the first records of the blocks of the PDS are containing the directory,

97
00:07:11.810 --> 00:07:16.399 
and the directory basically is a list of names, maximum eight characters.

98
00:07:16.400 --> 00:07:20.089 
And these names refer to parts of the remaining

99
00:07:21.200 --> 00:07:25.909 
PDS so they can have an address that points to, for example, starting

100
00:07:25.910 --> 00:07:27.859 
point of what we call a member.

101
00:07:27.860 --> 00:07:32.569 
So these names are member names, member names at maximum eight characters, and

102
00:07:32.570 --> 00:07:38.029 
it refers to a part of the PDS after the directory header.

103
00:07:38.030 --> 00:07:41.720 
And this allows us to store information

104
00:07:42.920 --> 00:07:47.449 
under a name, so it is a sort of a collection of things, I can think of it as a very

105
00:07:47.450 --> 00:07:50.750 
simple one layer hierarchy in a way OK.

106
00:07:52.100 --> 00:07:56.839 
The members are addressed by specifying the member name after the file

107
00:07:56.840 --> 00:08:01.339 
name of the whole dataset in brackets, as you can see

108
00:08:01.340 --> 00:08:06.019 
it here and the members, of course,

109
00:08:06.020 --> 00:08:10.609 
are part of one dataset. So they all have to have the same block

110
00:08:10.610 --> 00:08:15.169 
and record size. So you cannot mix up things that it's only

111
00:08:15.170 --> 00:08:19.970 
because it's one dataset, it always has the same record size, for example.

112
00:08:21.080 --> 00:08:25.009 
And when you allocate a PDS, you need to specify how big your directory is because the

113
00:08:25.010 --> 00:08:29.209 
directory header has to have a fixed size, so the system knows when the first member

114
00:08:29.210 --> 00:08:33.739 
starts, and this has to be specified during allocation.

115
00:08:33.740 --> 00:08:38.389 
Additionally, to the information that needs to be specified for an ordinary data

116
00:08:38.390 --> 00:08:39.390 
set, for example.

117
00:08:43.659 --> 00:08:48.159 
And the last thing that's sort of a historic

118
00:08:48.160 --> 00:08:52.959 
legacy, but also an important concept that you need to know,

119
00:08:52.960 --> 00:08:57.069 
especially when you read, for example, job codes, program codes that have been written

120
00:08:57.070 --> 00:09:01.569 
long time ago is the structure of a hard disk

121
00:09:01.570 --> 00:09:06.459 
because it is used to determine the sizes of the,

122
00:09:06.460 --> 00:09:09.910 
for example, the primary extend of a dataset and the secondary extent.

123
00:09:10.960 --> 00:09:13.089 
So these are the so-called space units.

124
00:09:13.090 --> 00:09:17.799 
When you look to file our data sets, you need to specify how big it is

125
00:09:17.800 --> 00:09:22.239 
minimum and at maximum. And this this size is,

126
00:09:22.240 --> 00:09:26.799 
of course, today could be specified in kilobytes megabytes units that

127
00:09:26.800 --> 00:09:32.589 
we are used to. But in the past, that was the case that these units were always specified

128
00:09:32.590 --> 00:09:37.059 
in units that refer to the structure of a hard disk.

129
00:09:37.060 --> 00:09:41.380 
A hard disk in the mainframe environment is called a DASD.

130
00:09:42.860 --> 00:09:47.479 
Direct Access Storage Device, so this is basically a hard disk and

131
00:09:48.740 --> 00:09:53.479 
the disk space that is specified in units referring

132
00:09:53.480 --> 00:09:56.119 
to the the physical structure of the hard disk.

133
00:09:56.120 --> 00:10:00.350 
So, the hard disk up to today consists of a number of rotating

134
00:10:01.880 --> 00:10:07.639 
ferro oxide disks that contain the information

135
00:10:07.640 --> 00:10:12.349 
stored in a magnetic way and there's

136
00:10:13.500 --> 00:10:17.959 
a set of read-write heads that are

137
00:10:17.960 --> 00:10:22.489 
moving in and out from the center to the to the border of the disk

138
00:10:22.490 --> 00:10:27.439 
and these read-write heads they fly on top of the rotating disk and are very,

139
00:10:27.440 --> 00:10:31.909 
very thin layer of air and read and write information in

140
00:10:31.910 --> 00:10:36.469 
a magnetic way. And so this is the fundamental

141
00:10:36.470 --> 00:10:39.529 
structure and this used to be the case also in earlier times.

142
00:10:39.530 --> 00:10:44.059 
And because the read-write heads are

143
00:10:44.060 --> 00:10:48.739 
mounted on a sort of coomp that is like shown here

144
00:10:48.740 --> 00:10:53.539 
moves in and out. Always move in and out in the same way

145
00:10:53.540 --> 00:10:55.460 
you could read and write simultaneously.

146
00:10:56.510 --> 00:11:01.129 
A radial circle that is always stacked

147
00:11:01.130 --> 00:11:05.689 
on top of each other like it is shown here and this is called a cylinder, so one

148
00:11:05.690 --> 00:11:10.459 
radial circle of information is called

149
00:11:10.460 --> 00:11:15.319 
a track. So every disc has a track and all tracks that are directly

150
00:11:15.320 --> 00:11:17.569 
on top of each other are called a cylinder.

151
00:11:17.570 --> 00:11:22.279 
And these are the units that are used for storing and specifying the

152
00:11:22.280 --> 00:11:25.639 
volume amount, because in the past there used to be an IBM

153
00:11:26.720 --> 00:11:29.833 
hard disk device called the 3390.

154
00:11:30.860 --> 00:11:34.519 
This is sort of the original reference nowadays.

155
00:11:34.520 --> 00:11:38.839 
So in its original device, one track had 56 kilobytes and

156
00:11:40.190 --> 00:11:44.659 
one cylinder was 15 tracks or 15 disc discs on top of each other

157
00:11:44.660 --> 00:11:49.579 
and this is sort of the reference frame for specifying the

158
00:11:49.580 --> 00:11:52.039 
disc sizes until today, so we can specify

159
00:11:54.320 --> 00:11:59.149 
disk space in terms of cylinders or tracks, referring, for example, to this

160
00:11:59.150 --> 00:12:03.499 
original IBM hard disk. And this is frequently done in jobs and used to be done, and it's

161
00:12:03.500 --> 00:12:08.449 
still done today. So it's an important concept that you once should understand and you

162
00:12:08.450 --> 00:12:13.249 
especially work with sort of code that has been written before.

163
00:12:13.250 --> 00:12:17.749 
And of course, in modern systems, we do not have necessarily

164
00:12:17.750 --> 00:12:21.349 
we don't even have rotating disks could be solid state disks, for example, in the storage

165
00:12:21.350 --> 00:12:24.259 
system. So everything's virtual today.

166
00:12:24.260 --> 00:12:28.849 
So the modern mainframe has a complete storage virtualization

167
00:12:28.850 --> 00:12:33.409 
layer, which is called DFSMS, which is a component that automatically,

168
00:12:33.410 --> 00:12:37.819 
for example, handles the bare files storage.

169
00:12:37.820 --> 00:12:42.200 
It moves out files that are not frequently used, for example, from

170
00:12:43.310 --> 00:12:47.029 
from disk to tape or to other media.

171
00:12:47.030 --> 00:12:51.739 
So it turns in a transparent way, so the user doesn't see that in a few

172
00:12:51.740 --> 00:12:55.489 
months later accesses the file it's automatically recovered from from tape, for example.

173
00:12:55.490 --> 00:13:00.229 
So these are nice features which allow a transparent storage hierarchy depending on the

174
00:13:00.230 --> 00:13:02.209 
frequency of use of datasets.

175
00:13:02.210 --> 00:13:07.039 
And of course, all these cylinders and space settings

176
00:13:07.040 --> 00:13:12.019 
are sort of virtual that has no real three three nine or disk anymore, but

177
00:13:12.020 --> 00:13:16.489 
they are still used to specify the number of

178
00:13:16.490 --> 00:13:21.649 
bytes. Of course, alternatively we could use kilobytes, megabytes,

179
00:13:21.650 --> 00:13:22.650 
gigabytes as well.

180
00:13:23.840 --> 00:13:28.309 
So this was a short overview on the very specific features and

181
00:13:28.310 --> 00:13:32.299 
understanding the file system of the address is crucial and fundamental for understanding

182
00:13:32.300 --> 00:13:36.346 
the way how, for example, jobs are written and files interact with the I/O operations,

183
00:13:37.370 --> 00:13:39.499 
COBOL programs to I/O operations and so on.

184
00:13:39.500 --> 00:13:43.370 
Because it's the the underlying thing is how the data is stored, so it's necessary to get

185
00:13:44.450 --> 00:13:47.089 
fundamental understanding of that.

186
00:13:47.090 --> 00:13:48.090 
Thank you very much.
