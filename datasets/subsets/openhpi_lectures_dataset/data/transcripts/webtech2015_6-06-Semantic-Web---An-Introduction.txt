WEBVTT

1
00:00:04.820 --> 00:00:07.610 
Now I want to shortly introduce the Semantic Web.

2
00:00:10.080 --> 00:00:14.410 
If we look to the web there are a number of limitations. Remember

3
00:00:14.410 --> 00:00:21.010 
the web allows access to enormously large source of information, billions of documents

4
00:00:21.140 --> 00:00:25.340 
are published in the World Wide Web, search machine only

5
00:00:26.240 --> 00:00:29.700 
provide access to a small fraction

6
00:00:30.440 --> 00:00:32.830 
of indexed documents.

7
00:00:33.710 --> 00:00:38.170 
There are parts of the web so called deep web

8
00:00:38.660 --> 00:00:40.250 
that cannot reached via

9
00:00:40.920 --> 00:00:47.810 
links in documents. Also in the deep web there are additional billions of documents

10
00:00:49.130 --> 00:00:54.100 
available and the number of documents is doubling every six months.

11
00:00:54.850 --> 00:01:00.120 
So we are confronted with a huge amount of information and

12
00:01:00.120 --> 00:01:01.290 
of course the question is,

13
00:01:01.910 --> 00:01:05.830 
if there are an information overload, we want to find

14
00:01:05.830 --> 00:01:09.970 
content based,

15
00:01:11.420 --> 00:01:14.020 
we want to access data.

16
00:01:15.330 --> 00:01:19.340 
Let's have a look to this example. This is a typical website,

17
00:01:19.680 --> 00:01:25.470 
website of New York Times and for a human, if a human looks here then

18
00:01:25.590 --> 00:01:31.370 
immediately humans can see are there articles, there is advertisement, there are images,

19
00:01:31.990 --> 00:01:36.960 
but what is the relevant information? What is important? What is unimportant?

20
00:01:38.700 --> 00:01:40.290 
We as humans are trained

21
00:01:41.390 --> 00:01:45.360 
with our experience, with our knowledge of the world, we are trained to

22
00:01:45.550 --> 00:01:50.240 
shortly visit the headlines and only

23
00:01:50.940 --> 00:01:54.960 
keywords in the headline. And then we decide can we make decisions. Or this is important

24
00:01:55.190 --> 00:02:00.020 
article we need to read. We can see this is important for my special

25
00:02:00.190 --> 00:02:02.520 
profession or my special hobby.

26
00:02:04.210 --> 00:02:10.190 
Where is real information, what is advertisement, what is only to

27
00:02:10.550 --> 00:02:12.300 
bring me to buy something,

28
00:02:12.950 --> 00:02:15.960 
what is the meaning of the information?

29
00:02:16.650 --> 00:02:19.760 
These are question how credible is the information.

30
00:02:20.350 --> 00:02:26.330 
All this are question which we can answer on the basis, we as

31
00:02:26.330 --> 00:02:30.970 
humans can answer on the basis of our experience. But for a machine

32
00:02:31.930 --> 00:02:37.640 
to help us, to instruct information, to decide which of the information belongs to

33
00:02:37.960 --> 00:02:44.340 
to each other, which part is the actual redundant one- this

34
00:02:44.340 --> 00:02:45.660 
is difficult for machine.

35
00:02:47.590 --> 00:02:52.210 
Is that huge amount of information is actually useful?

36
00:02:53.100 --> 00:02:56.980 
So here for example is an article we with our understanding

37
00:02:56.980 --> 00:03:00.620 
of the world can immediately see, oh this is interesting in

38
00:03:00.620 --> 00:03:04.210 
all this information that are provided here to concentrate

39
00:03:04.570 --> 00:03:06.640 
on this article. This tells

40
00:03:07.300 --> 00:03:13.010 
the main story of this day's New York Times.

41
00:03:13.550 --> 00:03:18.240 
So human users have a contextual knowledge,

42
00:03:18.670 --> 00:03:25.680 
have a world knowledge which helps them to be able to interpret

43
00:03:26.500 --> 00:03:29.470 
in most cases information in a correct way.

44
00:03:31.570 --> 00:03:35.020 
You see if you would ask the program

45
00:03:35.980 --> 00:03:42.640 
to immediately extract those part of this newspaper which needs to be read,

46
00:03:43.780 --> 00:03:47.170 
it becomes really difficult before a robot

47
00:03:47.840 --> 00:03:54.370 
program a software agent cannot distinguish between important and insignificant information.

48
00:03:55.220 --> 00:04:00.270 
He can't understand the meaning of the information. And meaning

49
00:04:00.610 --> 00:04:07.490 
this is what humans help to make such decision between unimportant, important between relevant

50
00:04:07.770 --> 00:04:09.970 
irrelevant and so on.

51
00:04:10.600 --> 00:04:13.780 
So if we look for machines

52
00:04:14.460 --> 00:04:17.790 
to find out in this page since this is the most important

53
00:04:18.890 --> 00:04:20.850 
article on this day,

54
00:04:22.450 --> 00:04:25.040 
it's the first moment it's impossible.

55
00:04:25.890 --> 00:04:29.190 
But when we step back and see what we expect

56
00:04:29.760 --> 00:04:34.690 
that search engines do, then it is exactly what we expecting the

57
00:04:34.950 --> 00:04:36.020 
search machine

58
00:04:37.450 --> 00:04:42.780 
based on algorithm and automatic procedures should help us to find

59
00:04:42.950 --> 00:04:44.090 
relevant information.

60
00:04:44.870 --> 00:04:50.220 
But here is an example that it's so difficult to find relevant information.

61
00:04:50.340 --> 00:04:54.670 
So robot needs information about the meaning of the document,

62
00:04:54.670 --> 00:04:57.930 
about the meaning of the articles, about the meanings of the parts.

63
00:04:58.620 --> 00:05:00.370 
So if we would

64
00:05:01.690 --> 00:05:07.140 
attribute to this page, information which tells what is the

65
00:05:07.140 --> 00:05:09.560 
meaning of this article, what is the meaning of that part, what

66
00:05:09.560 --> 00:05:13.660 
is the meaning of this image, then all the robots, all the software

67
00:05:13.660 --> 00:05:20.480 
agents would be able to help us to identify important

68
00:05:21.100 --> 00:05:22.780 
things we need to read.

69
00:05:23.740 --> 00:05:26.760 
This information about the meaning

70
00:05:27.470 --> 00:05:35.280 
is called Metadata. Metadata- so this metadata are needed in addition

71
00:05:35.990 --> 00:05:38.060 
to the information of the

72
00:05:38.930 --> 00:05:45.920 
website that robots would be able to follow similar things,

73
00:05:46.510 --> 00:05:48.710 
to behave like we can do.

74
00:05:49.750 --> 00:05:55.060 
So for example if this part of the newspaper would be

75
00:05:55.860 --> 00:06:00.670 
characterized by the word 'advertisement', by the metadata 'advertisement',

76
00:06:01.250 --> 00:06:07.080 
then the robot would be immediately able to decide ok in all this

77
00:06:07.080 --> 00:06:10.350 
information provided in this newspaper, these parts are

78
00:06:11.010 --> 00:06:15.640 
advertisement. So this is paid to be displayed.

79
00:06:17.490 --> 00:06:23.070 
However if we look how webpages are constructed, they are

80
00:06:23.070 --> 00:06:29.970 
constructed on the basis of HTML. Then HTML only offers very limited options

81
00:06:30.190 --> 00:06:34.640 
for featuring, and for introducing metadata.

82
00:06:35.340 --> 00:06:37.700 
So you remember we have some metadata

83
00:06:41.870 --> 00:06:46.880 
markups, so here for example for the name to give the

84
00:06:46.880 --> 00:06:50.590 
name of the author, to give the name of the content, of the document,

85
00:06:50.870 --> 00:06:55.390 
document type and others, but this is only very limited

86
00:06:55.870 --> 00:07:05.260 
with a tech, with a markup meta-data, meta name, we can also give some key words

87
00:07:05.480 --> 00:07:06.990 
describing the document.

88
00:07:08.240 --> 00:07:14.250 
But this is only possible in a very limited, and very unspecific way.

89
00:07:15.100 --> 00:07:19.260 
So when we think to make the web more,

90
00:07:19.960 --> 00:07:29.480 
more usable by robots, or by software to help to identify important information,

91
00:07:30.030 --> 00:07:36.790 
then we need much more elaborated mechanisms to describe keywords and meta-data.

92
00:07:37.860 --> 00:07:42.710 
In the HTML, all the metadata must be created by the author and

93
00:07:42.710 --> 00:07:47.610 
if the author does not mention any metadata, then there are no

94
00:07:47.610 --> 00:07:48.700 
metadata available.

95
00:07:50.790 --> 00:07:54.570 
Originally this was no problem. No problem because originally

96
00:07:54.850 --> 00:07:57.320 
the web was made for humans.

97
00:07:58.090 --> 00:07:59.230 
But enabling

98
00:08:00.540 --> 00:08:06.010 
those enabling technology for the web, this was the markup language HTML

99
00:08:06.140 --> 00:08:12.810 
which could be used to design web pages and the cascading stylesheets

100
00:08:13.650 --> 00:08:18.440 
which can be used to describe how the documents are presented.

101
00:08:19.620 --> 00:08:27.120 
These means the interlinking mechanisms is wonderful to give humans information.

102
00:08:28.070 --> 00:08:33.740 
But it's no mean to describe the meaning

103
00:08:34.420 --> 00:08:40.380 
of this information. So the semantics, that is the meaning. So

104
00:08:40.380 --> 00:08:45.960 
semantic information cannot be provided neither by HTML nor

105
00:08:46.140 --> 00:08:47.420 
by cascading stylesheet.

106
00:08:50.150 --> 00:08:51.190 
So what is semantics?

107
00:08:51.830 --> 00:08:53.200 
When we think how to

108
00:08:54.560 --> 00:08:56.790 
add something to the

109
00:08:57.740 --> 00:09:04.590 
web documents so that also robots, software agents can understand the meaning,

110
00:09:05.250 --> 00:09:09.890 
cannot only analyze the characters of a document, but can also understand the meaning,

111
00:09:10.340 --> 00:09:17.630 
then we have to look to the semantics, that is a field, is a subfield

112
00:09:17.810 --> 00:09:25.930 
of linguistic. And semantics is dealing with sense and the meaning

113
00:09:26.510 --> 00:09:31.660 
of language information, or and of linguistic symbols.

114
00:09:32.460 --> 00:09:35.490 
Of course sense and meaning depends from languages.

115
00:09:35.940 --> 00:09:40.240 
Each language has its own semantic, own syntax. So

116
00:09:42.060 --> 00:09:47.570 
what semantic tries to do is to answer questions, like how is the sense

117
00:09:47.950 --> 00:09:54.970 
and the meaning of complex terms of a full web page can be deduced from those

118
00:09:55.230 --> 00:09:58.400 
of single terms from descriptors.

119
00:10:01.810 --> 00:10:04.630 
Of course semantic and syntax-

120
00:10:05.310 --> 00:10:07.300 
semantics is building on syntax.

121
00:10:07.970 --> 00:10:12.960 
To handle syntax is no problem for machines, for software, for robots.

122
00:10:13.510 --> 00:10:21.770 
But robots software agents have no clue from semantics. So what

123
00:10:22.240 --> 00:10:25.490 
is important to think about to bridge these both.

124
00:10:26.710 --> 00:10:30.260 
And the reason why we need to bridge this is that communication

125
00:10:30.810 --> 00:10:34.180 
every time requires a common understanding, a common understanding

126
00:10:34.180 --> 00:10:39.430 
of the syntax, and the semantics of the interchanged text of

127
00:10:39.440 --> 00:10:43.540 
the interchanged language symbols, of the interchanged character strings.

128
00:10:44.260 --> 00:10:49.020 
So if the case for humans, if the sender and the receiver

129
00:10:49.790 --> 00:10:54.610 
do not speak the same language, they cannot understand the meaning of the

130
00:10:55.380 --> 00:10:59.470 
message. So communication requires common understanding.

131
00:10:59.810 --> 00:11:03.590 
Common understanding of syntax and semantics because for the

132
00:11:03.590 --> 00:11:05.920 
understanding both components are important

133
00:11:06.860 --> 00:11:12.290 
for the language. So mutual understanding is only possible if

134
00:11:12.290 --> 00:11:18.720 
sender receiver have identical semantics, and if we asked how we can

135
00:11:19.850 --> 00:11:23.390 
enable robots, how we can enable software agents

136
00:11:23.870 --> 00:11:25.950 
to understand the meaning

137
00:11:26.600 --> 00:11:29.630 
of the documents, then we need

138
00:11:30.270 --> 00:11:34.380 
to think how we can help them, how we can

139
00:11:35.170 --> 00:11:40.340 
design the programs, the robots, the software agent in such a way

140
00:11:40.670 --> 00:11:45.400 
that they can deal or words also with meaning.

141
00:11:47.350 --> 00:11:49.590 
Let's have a look to a few examples.

142
00:11:50.720 --> 00:11:54.120 
With the limitations of the World Wide Web and let's look how

143
00:11:54.130 --> 00:11:57.490 
such index based search machines are working.

144
00:11:58.090 --> 00:12:01.040 
Typically this is a keyword based search. Here's an example.

145
00:12:01.640 --> 00:12:06.340 
It's a word typed in a query by the user, and then the search machine

146
00:12:06.770 --> 00:12:08.950 
gives a number of information

147
00:12:09.850 --> 00:12:16.420 
which is considered to be relevant because the word that was typed in

148
00:12:16.590 --> 00:12:18.690 
play an important role in this document.

149
00:12:20.480 --> 00:12:23.340 
But the problem is with such a search,

150
00:12:23.990 --> 00:12:29.110 
with searching a query, there are many irrelevant results retrieved.

151
00:12:29.300 --> 00:12:32.270 
For example a word can have different meanings, so called homonyms.

152
00:12:34.380 --> 00:12:37.910 
For example the word golf. Golf can mean

153
00:12:38.420 --> 00:12:44.130 
sport golf, can mean Volkswagen golf, golf can mean Gulf of Mexico.

154
00:12:45.210 --> 00:12:48.490 
A word has different meanings, a word has different context. If

155
00:12:49.210 --> 00:12:54.760 
a user type in golf, then he wants to have exact information,

156
00:12:54.870 --> 00:12:58.960 
say for example about golf sport and not about the golf car or

157
00:12:59.270 --> 00:13:02.570 
his golf holiday location.

158
00:13:03.550 --> 00:13:09.060 
On the other side, the index based search machine which are working by analyzing the

159
00:13:09.490 --> 00:13:15.090 
importance of characteristic strings inside a document, can't

160
00:13:15.090 --> 00:13:18.180 
find all relevant results. What's the reason?

161
00:13:19.360 --> 00:13:24.890 
The same. There are different words. Same character strings

162
00:13:25.280 --> 00:13:31.360 
that have the same meaning- synonyms. So all the information

163
00:13:32.010 --> 00:13:36.940 
that is available for the synonyms of the query are not

164
00:13:37.210 --> 00:13:39.570 
identified as important and

165
00:13:40.610 --> 00:13:44.860 
relevant to show to the user. So there is a lack of precise

166
00:13:44.860 --> 00:13:49.260 
context. So the requirement is that we want to,

167
00:13:50.330 --> 00:13:54.460 
that it's needed to introduce a formal terminology.

168
00:13:55.330 --> 00:13:58.410 
And this formal terminology is called ontology.

169
00:13:59.410 --> 00:14:05.960 
Such ontologies help to set the context so that it's possible to

170
00:14:06.110 --> 00:14:10.690 
interpret a query word in this. So ontology

171
00:14:11.840 --> 00:14:18.640 
is an explicit formal specification of a common conceptualisation that's scientific expression.

172
00:14:20.080 --> 00:14:24.970 
And ontology consists of a so called taxonomy and taxonomy

173
00:14:24.970 --> 00:14:29.220 
is a hierarchy of concepts of a keyboards

174
00:14:29.830 --> 00:14:32.280 
which help to say ok this word

175
00:14:32.910 --> 00:14:37.070 
is a sub species of this word.

176
00:14:37.550 --> 00:14:42.030 
So when a user looks for information about

177
00:14:43.560 --> 00:14:48.680 
this word, it makes also sense to give him some information about

178
00:14:48.980 --> 00:14:53.920 
the word in the hierarchy above, and more important about all the notions

179
00:14:54.130 --> 00:14:57.870 
below of this word. Of course the taxonomy is the

180
00:14:58.290 --> 00:15:02.560 
relation between different words, are relation between different concepts,

181
00:15:02.790 --> 00:15:05.790 
between different words, between different descriptors.

182
00:15:06.410 --> 00:15:12.400 
And if a system like Google would have information about such ontology,

183
00:15:12.830 --> 00:15:15.370 
it would be able to see

184
00:15:16.240 --> 00:15:23.520 
if the user is query something, said to provide all relevant

185
00:15:23.520 --> 00:15:28.570 
information. It makes also sense it is important to send information about what's

186
00:15:28.730 --> 00:15:34.410 
below in this taxonomical hierarchy about knowing about this word.

187
00:15:36.540 --> 00:15:40.970 
Another problem area systems

188
00:15:42.180 --> 00:15:47.350 
needs more information, needs formal methods to describe meaning is

189
00:15:47.510 --> 00:15:52.690 
that we often want to get an extraction of important information.

190
00:15:53.360 --> 00:15:56.510 
For human again, this is not difficult.

191
00:15:57.260 --> 00:16:01.610 
Human agents can extract information correctly, can do this fast.

192
00:16:01.830 --> 00:16:08.070 
But software agents, robots cannot without

193
00:16:10.720 --> 00:16:14.740 
measures, without methods, without tools.

194
00:16:15.160 --> 00:16:18.730 
Which tells them, which helps them to understand

195
00:16:19.440 --> 00:16:20.650 
the knowledge.

196
00:16:21.540 --> 00:16:22.920 
What we have, and what's

197
00:16:23.750 --> 00:16:29.960 
for us are important for example in this question how to extract information is,

198
00:16:30.150 --> 00:16:34.970 
we have a knowledge about the context. So if we see an article,

199
00:16:34.970 --> 00:16:38.480 
we know a lot around this topic, around this

200
00:16:39.390 --> 00:16:45.760 
country, around this politics whatever. And we have a certain world knowledge

201
00:16:45.930 --> 00:16:49.070 
which helps to place this

202
00:16:49.710 --> 00:16:52.770 
contextual information into the big picture.

203
00:16:53.610 --> 00:16:56.120 
So when we want software agents

204
00:16:56.830 --> 00:17:00.070 
to be able to extract information in the right way,

205
00:17:00.640 --> 00:17:06.330 
then we need them to get

206
00:17:07.080 --> 00:17:11.270 
this context knowledge, and we need them to get this world knowledge.

207
00:17:12.060 --> 00:17:16.860 
This is required to extract information from the text or from image-based

208
00:17:17.030 --> 00:17:18.580 
representation of information.

209
00:17:19.180 --> 00:17:24.850 
So requirement, we have to fulfill in order to

210
00:17:25.610 --> 00:17:31.210 
allow the software agents and robots to be able to perform such a task,

211
00:17:31.360 --> 00:17:36.220 
for information extraction is said the aggregation and interpretation of information

212
00:17:36.340 --> 00:17:38.590 
from different sources as possible. That

213
00:17:39.520 --> 00:17:46.390 
means are provided. HTML, CSS do not. That additional means are provided to support

214
00:17:46.550 --> 00:17:48.040 
machines in doing

215
00:17:49.520 --> 00:17:54.840 
this. Though this exactly was the vision for the so-called semantic web,

216
00:17:55.300 --> 00:17:58.110 
which was formulated by Tim Berners-Lee.

217
00:17:58.570 --> 00:18:05.120 
You remember he was one of the inventor of the World Wide Web

218
00:18:05.430 --> 00:18:08.730 
and he formulated in September 1998.

219
00:18:09.450 --> 00:18:15.200 
He envisioned the semantic web and this vision was that he said

220
00:18:15.430 --> 00:18:19.220 
the web was designed as an information space

221
00:18:19.890 --> 00:18:24.310 
with the goal that it should be useful not only for human-human communication

222
00:18:24.720 --> 00:18:29.020 
but also that machines would be able to participate and to help.

223
00:18:29.490 --> 00:18:34.810 
And participation and help is exactly to search information, to extract information,

224
00:18:35.160 --> 00:18:37.290 
to understand information.

225
00:18:38.900 --> 00:18:42.810 
HTML I already mentioned this as a language

226
00:18:43.230 --> 00:18:48.610 
for the information presentation in the web lacks any possibility to express

227
00:18:48.860 --> 00:18:51.210 
meaning of the displayed information.

228
00:18:52.320 --> 00:18:56.160 
So here we need additional technology.

229
00:18:58.260 --> 00:19:02.110 
Before we have view to the technology, let's have

230
00:19:02.110 --> 00:19:04.050 
a look to the potential of semantic web.

231
00:19:04.910 --> 00:19:10.030 
If we use a search machine today then for example and

232
00:19:10.680 --> 00:19:17.190 
query golf from 2015, then the

233
00:19:17.190 --> 00:19:22.310 
user must refine the query to get the search results he really

234
00:19:22.310 --> 00:19:25.650 
needs. Otherwise he gets a lot of ambiguous information.

235
00:19:26.170 --> 00:19:31.590 
So the first what he means when he type in golf- is it a car

236
00:19:32.030 --> 00:19:34.260 
is a sport or is anything other.

237
00:19:35.030 --> 00:19:37.680 
So user for example refines to car.

238
00:19:38.550 --> 00:19:41.670 
Next question what is this 2015?

239
00:19:42.270 --> 00:19:48.290 
Is this a year? The year of the construction of the car? It is a technical parameter?

240
00:19:49.560 --> 00:19:53.540 
What is it? So the user has to answer the question as

241
00:19:54.010 --> 00:19:58.630 
he is interested to take this as a year of construction. Then

242
00:19:59.850 --> 00:20:02.740 
the question what's the user looking for?

243
00:20:03.920 --> 00:20:08.630 
Does he look for a sales offer? Does he look for a manual car?

244
00:20:08.830 --> 00:20:10.780 
Does he look for anything else other?

245
00:20:11.390 --> 00:20:13.350 
So he has to refine. You see

246
00:20:14.100 --> 00:20:20.270 
machine search machine is stupid. So the user has to explain exactly

247
00:20:20.740 --> 00:20:22.990 
what kind of information he's interested.

248
00:20:23.810 --> 00:20:28.930 
Search machine has to ask must ask the user

249
00:20:29.390 --> 00:20:32.620 
to be able to get the meaning of its query.

250
00:20:34.410 --> 00:20:40.560 
If we look to the same example -how a search engine could be act tomorrow.

251
00:20:40.960 --> 00:20:42.870 
Search machine which

252
00:20:43.730 --> 00:20:48.410 
can base, can use techniques of semantic web.

253
00:20:49.350 --> 00:20:53.770 
And user type in same question go from 2015.

254
00:20:54.290 --> 00:20:58.030 
Then the search machine already knows a lot about a user.

255
00:20:58.630 --> 00:21:01.240 
He knows for example that the user

256
00:21:02.410 --> 00:21:06.100 
regularly checked results of professional golf tournaments.

257
00:21:06.940 --> 00:21:09.580 
He does this for example in the last months.

258
00:21:10.280 --> 00:21:14.400 
He has bought a set of golf clubs last year

259
00:21:15.290 --> 00:21:20.370 
via online shopping. The reason the machine knows it. The machine knows that

260
00:21:20.890 --> 00:21:23.810 
the user has subscribed to the newsgroup

261
00:21:24.280 --> 00:21:29.810 
about golf. So from all this, the user, the machine knows

262
00:21:31.010 --> 00:21:33.050 
that the user

263
00:21:34.370 --> 00:21:36.480 
is in the context of golf.

264
00:21:37.460 --> 00:21:42.280 
So it's not necessary to ask whether golf is a meaning car,

265
00:21:42.290 --> 00:21:46.320 
or golf or a geographical location.

266
00:21:47.050 --> 00:21:52.650 
The machine can conclude this from other action of the user,

267
00:21:52.900 --> 00:21:58.190 
and can use such information to combine this to get a little bit

268
00:21:59.190 --> 00:22:01.030 
about the understanding

269
00:22:01.670 --> 00:22:07.090 
of the word golf when this particular user is using this word.

270
00:22:09.010 --> 00:22:12.710 
Let's have another look in the future. How, when

271
00:22:14.240 --> 00:22:20.890 
the web semantic technology is available, is in place, what would be possible.

272
00:22:21.570 --> 00:22:26.070 
Then let's look how a family can organize a holiday trip.

273
00:22:26.920 --> 00:22:32.050 
So you can input to the agent. We want to have, we want to spend

274
00:22:32.370 --> 00:22:35.770 
a vacancy, we want to do the seaside. It should be

275
00:22:36.490 --> 00:22:40.170 
ten days or longer. We'll do this with family. It should

276
00:22:40.810 --> 00:22:45.460 
should not cost more than two thousand Dollar or Euro.

277
00:22:45.870 --> 00:22:50.610 
Then the agents can check the calendar, can check the calendar

278
00:22:50.620 --> 00:22:57.160 
of all family members, and can identify automatically without the help of

279
00:22:57.520 --> 00:23:00.870 
users possible free slots.

280
00:23:01.620 --> 00:23:04.790 
Then the agents can check holiday offerings

281
00:23:05.300 --> 00:23:10.510 
for exactly this free slots, for exactly the identified dates.

282
00:23:10.990 --> 00:23:15.610 
According to the requirements needs to find and analyze

283
00:23:16.150 --> 00:23:19.070 
orders from seaside locations.

284
00:23:21.500 --> 00:23:27.500 
Geographic parameters, family friendly golf course nearby. Because the

285
00:23:27.660 --> 00:23:34.330 
agent knows what family members like, and he can take all this information together

286
00:23:34.640 --> 00:23:40.040 
to evaluate and rank the offerings of different offerings.

287
00:23:41.900 --> 00:23:47.940 
Then if the agent found something that seems to be worse for closer consideration,

288
00:23:48.460 --> 00:23:53.430 
it can check free capacity and can compile a selection of matching offers.

289
00:23:54.080 --> 00:24:00.700 
It is able to organize and to retrieve and organize transportation

290
00:24:01.890 --> 00:24:05.360 
according to the choose location. All can be done

291
00:24:05.860 --> 00:24:10.530 
without interaction with the user. Then the agent can

292
00:24:10.930 --> 00:24:16.370 
come up and can finally present to the user a list of offerings

293
00:24:16.550 --> 00:24:20.370 
you can do this in a ranked way

294
00:24:21.990 --> 00:24:26.320 
that meets the requirements of the user, or that

295
00:24:27.970 --> 00:24:32.610 
what the users and the family in this case like to do. Families

296
00:24:32.610 --> 00:24:36.750 
member what they are used to do and can come up with an offer. But

297
00:24:36.990 --> 00:24:41.390 
to implement this, to make this vision a reality

298
00:24:42.380 --> 00:24:48.570 
in the web, we need technologies to help software agents to understand

299
00:24:48.890 --> 00:24:55.920 
meaning. The objective of the semantic web are that the knowledge, the

300
00:24:56.700 --> 00:24:59.280 
world knowledge, the context knowledge

301
00:25:00.040 --> 00:25:05.100 
needs to be organized in separate domains according to its meanings.

302
00:25:05.890 --> 00:25:11.410 
Then it's needed to have automated tools for maintainance

303
00:25:12.390 --> 00:25:19.140 
or removal of inconsistencies and extraction of new knowledge. Then the

304
00:25:20.900 --> 00:25:23.630 
today's keyboard based search

305
00:25:24.710 --> 00:25:29.280 
needs to be replaced by a context based search with specific

306
00:25:29.290 --> 00:25:31.260 
question and answering cycles.

307
00:25:32.020 --> 00:25:37.880 
Then a user-friendly search means that not stupid questions are asked.

308
00:25:38.110 --> 00:25:44.370 
Machines know what users like and can take this into account, into consideration

309
00:25:44.710 --> 00:25:46.230 
before presenting results.

310
00:25:46.950 --> 00:25:51.170 
Then the extraction and presentation of knowledge is necessary. Not

311
00:25:51.990 --> 00:25:56.460 
extraction and presentation of single character strings. This

312
00:25:57.010 --> 00:26:03.640 
is not enough. Answering questions or knowledge is more than only the characteristics thing.

313
00:26:04.190 --> 00:26:06.890 
Answering questions with dispersed documents.

314
00:26:07.440 --> 00:26:13.490 
This all exact determination, who many access which part of specific information

315
00:26:13.890 --> 00:26:19.530 
all these are objectives to make the vision, to implement vision

316
00:26:20.120 --> 00:26:21.020 
of semantic web.

317
00:26:22.230 --> 00:26:27.470 
Let's say a few words about the technical means and the technologies

318
00:26:27.670 --> 00:26:31.320 
that are used to implement the vision of semantic web.

319
00:26:32.090 --> 00:26:36.090 
To realize semantic web, a number of technologies with very

320
00:26:36.090 --> 00:26:37.480 
different purposes are needed.

321
00:26:39.660 --> 00:26:45.390 
What we have start to do at the beginning, any information source in the

322
00:26:45.510 --> 00:26:50.910 
semantic web must have a unified unique identifier.

323
00:26:51.580 --> 00:26:53.640 
This is posed by a URI,

324
00:26:55.210 --> 00:26:59.850 
URLS. So this is already in place. Then information in semantic web

325
00:27:00.050 --> 00:27:05.320 
must be expressed formally in order to be processed by automatic agents.

326
00:27:05.660 --> 00:27:13.730 
So what is needed is something like a unified syntax like XML, like XMLSchema.

327
00:27:14.530 --> 00:27:17.630 
Also this is already in place and we can build on.

328
00:27:18.070 --> 00:27:22.740 
Then simple semantic relations between information entities

329
00:27:23.140 --> 00:27:24.760 
must be expressible.

330
00:27:26.280 --> 00:27:32.950 
Needs to be able to express see semantic relation of different entities.

331
00:27:33.520 --> 00:27:41.180 
Here the RDF- Resource Description Framework was developed and RDFScheme

332
00:27:41.570 --> 00:27:47.410 
this is available as RDF technology and this allows

333
00:27:47.870 --> 00:27:54.100 
to express very simple semantic relations between different information entities.

334
00:27:54.510 --> 00:27:56.280 
But to implement the

335
00:27:57.160 --> 00:28:00.210 
semantic web, we need more technologies.

336
00:28:00.860 --> 00:28:05.310 
So for example different semantics must be explainable

337
00:28:05.710 --> 00:28:09.300 
in order to combine seemingly inconsistent information.

338
00:28:10.090 --> 00:28:16.240 
In the different context, different semantics are in place. But if a user

339
00:28:16.880 --> 00:28:20.390 
looks for something and we have different documents, then one

340
00:28:20.390 --> 00:28:23.660 
needs to be able to explain the

341
00:28:24.670 --> 00:28:30.830 
different semantics, and to compare them and for this we have ontologies,

342
00:28:31.710 --> 00:28:35.310 
taxonomies and others, I already said a few words about it.

343
00:28:35.740 --> 00:28:41.650 
Then it should be possible to create new information, to conclude new information

344
00:28:41.790 --> 00:28:47.570 
from existing ones. And here inference mechanisms are needed.

345
00:28:47.920 --> 00:28:53.060 
So for making conclusion for creating new knowledge out of given knowledge.

346
00:28:55.460 --> 00:29:01.870 
This mechanisms technologies are needed to be developed and then technology for data protection

347
00:29:02.470 --> 00:29:07.300 
is needed in terms of confidentiality, in terms of integrity.

348
00:29:07.720 --> 00:29:11.200 
And this must be applied because the more

349
00:29:11.810 --> 00:29:13.860 
personalised the information,if the

350
00:29:14.630 --> 00:29:19.860 
information is, the more important it is to protect this information.

351
00:29:20.300 --> 00:29:23.640 
Here we have techniques like XMLEncryption

352
00:29:24.460 --> 00:29:26.060 
and XMLSignature.

353
00:29:27.750 --> 00:29:33.750 
I can only give a rough idea of what's going on in this large

354
00:29:33.750 --> 00:29:39.480 
field of semantic web technologies. There are courses in OpenHPI available

355
00:29:39.610 --> 00:29:43.730 
which go into much more detail. Here I show you

356
00:29:44.370 --> 00:29:46.870 
what's the often called as

357
00:29:47.880 --> 00:29:52.530 
semantic development. We start with such technologies that we

358
00:29:52.530 --> 00:29:58.770 
can identify documents by means of URI, that we encode information,

359
00:29:59.310 --> 00:30:05.730 
then we have XML, we have technologies like XML, Namespaces, XML

360
00:30:05.980 --> 00:30:10.950 
Schema. Then this was the RDF of all the possibilities the

361
00:30:10.950 --> 00:30:16.320 
language which helps us to express simple semantic relations.

362
00:30:16.520 --> 00:30:22.750 
So here are the save documents. Here we start with the different datas and ontology

363
00:30:23.240 --> 00:30:31.210 
to describe context knowledge and to help, to explain the relation of one word

364
00:30:31.590 --> 00:30:34.480 
to other words. Then retrieving

365
00:30:36.660 --> 00:30:42.060 
new knowledge into retrieving languages the proofs that

366
00:30:42.060 --> 00:30:44.870 
this is consistent. And all

367
00:30:45.750 --> 00:30:52.040 
for needed for this type of information is trust. So this are various techniques.

368
00:30:52.420 --> 00:30:56.060 
There are few example. These techniques are developed.

369
00:30:56.620 --> 00:31:01.460 
Many researchers work on this, many researchers work on the goal

370
00:31:01.770 --> 00:31:08.520 
to help that in the semantic web. The semantic web and the information

371
00:31:08.520 --> 00:31:12.780 
that's available in semantic web feels and that robots that

372
00:31:12.790 --> 00:31:17.020 
are analyzing this information, that it looks like that these robots

373
00:31:17.250 --> 00:31:18.860 
understand the meaning.

374
00:31:20.070 --> 00:31:23.690 
They cannot understand the meaning but by means of such technology

375
00:31:24.030 --> 00:31:28.840 
we can help them to behave in a way like they understand the meaning.

376
00:31:29.070 --> 00:31:33.090 
More information about semantic web, you can get from this

377
00:31:33.550 --> 00:31:37.780 
OpenHPI course from how I talk about semantic web technologies.
