WEBVTT

1
00:00:00.460 --> 00:00:04.820 
This is Knowledge Graphs lecture number
five knowledge graph applications.

2
00:00:05.510 --> 00:00:08.890 
In this last part of lecture
number five we want to introduce

3
00:00:08.890 --> 00:00:12.630 
you to knowledge graph analytics
and in particular we want

4
00:00:12.630 --> 00:00:15.690 
to talk about knowledge mining
and knowledge discovery.

5
00:00:16.460 --> 00:00:20.910 
What is knowledge discovery? Usually
we refer to knowledge discovery

6
00:00:20.910 --> 00:00:25.380 
when you talk about databases and you want
to discover knowledge in databases. So

7
00:00:25.670 --> 00:00:29.540 
however this knowledge then can
be put into a knowledge graph

8
00:00:29.540 --> 00:00:34.510 
which means this is also of interest to
us. So what is knowledge discovery?

9
00:00:35.130 --> 00:00:39.720 
Knowledge discovery is the non-trivial
process of identifying valid

10
00:00:40.000 --> 00:00:44.290 
novel and potentially useful and
ultimately understandable patterns

11
00:00:44.660 --> 00:00:48.270 
in data sources and these data
sources of course might be massive.

12
00:00:48.990 --> 00:00:52.600 
Well it means to a certain degree
the discovered patterns should

13
00:00:52.600 --> 00:00:55.780 
also hold for new previously
unseen problem instances,

14
00:00:56.490 --> 00:01:00.830 
novel of course at least to the system
and preferably also to the user,

15
00:01:01.190 --> 00:01:05.830 
and potentially useful means they should
lead to some benefit to the user

16
00:01:05.930 --> 00:01:09.530 
or the task. And of course ultimately
understandable the end user

17
00:01:09.730 --> 00:01:14.150 
should be able to interpret the
patterns either immediately or after

18
00:01:14.300 --> 00:01:18.320 
some necessary preprocessing,
postprocessing sorry.

19
00:01:18.860 --> 00:01:24.580 
So two goals can be distinguished
for knowledge discovery.

20
00:01:24.580 --> 00:01:27.660 
First of course you want to explain
your data which means you do

21
00:01:27.890 --> 00:01:31.220 
descriptive modelling and this
explains the characteristic

22
00:01:31.360 --> 00:01:36.550 
and the behavior of the observed
data. However you can of course

23
00:01:36.550 --> 00:01:41.210 
use this to do predictions for
the future for previously you

24
00:01:41.210 --> 00:01:45.310 
know also unknown data and this
means this is predictive modelling

25
00:01:45.310 --> 00:01:49.160 
and this predicts the behavior of
the new data based on some model.

26
00:01:49.970 --> 00:01:51.420 
Very important
is of course

27
00:01:52.180 --> 00:01:56.120 
this is not always one hundred
percent the truth because

28
00:01:56.250 --> 00:01:58.790 
you are what you are doing is
modelling which means you are

29
00:01:58.790 --> 00:02:03.310 
talking about a model and a model
of course is only or most

30
00:02:03.310 --> 00:02:07.050 
times only a fraction, a subsection
of the real world and you

31
00:02:07.050 --> 00:02:10.800 
of course for a model you only
take into account what you need

32
00:02:10.800 --> 00:02:14.950 
for a specific purpose from reality.
So you don't cover entire reality

33
00:02:15.220 --> 00:02:20.540 
which means of course if you have a
descriptive or predictive model.

34
00:02:20.950 --> 00:02:27.470 
This not always produces let's say one hundred
percent correct predictions or explanations.

35
00:02:28.710 --> 00:02:34.030 
Ok so this basically is knowledge
mining and knowledge discovery.

36
00:02:34.840 --> 00:02:38.190 
The process of knowledge discovery
works in the following way: you start

37
00:02:38.500 --> 00:02:43.580 
with some data but however you first
have to identify what is exactly

38
00:02:43.790 --> 00:02:47.520 
the relevant data set that I
need or what kind of subset of

39
00:02:47.520 --> 00:02:50.450 
the data set that I have should
I take into account to come

40
00:02:50.450 --> 00:02:54.630 
up with the knowledge I'm looking for. So
first you try to prepare from your data

41
00:02:54.990 --> 00:02:56.040 
your target data.

42
00:02:57.790 --> 00:03:01.300 
The data so far is still raw,
which means you have to invest

43
00:03:01.300 --> 00:03:05.670 
a lot of preprocessing and cleaning.
For example you might have

44
00:03:06.010 --> 00:03:10.180 
the necessity or the requirement
to integrate data from different

45
00:03:10.180 --> 00:03:13.700 
sources and they might be formatted
in different way which means

46
00:03:13.860 --> 00:03:17.380 
you have to do normalisation
and stuff like that and there

47
00:03:17.380 --> 00:03:21.260 
might be noise for example and
data that you don't need within

48
00:03:21.260 --> 00:03:24.070 
your target data set and you
have to get rid of it. So

49
00:03:24.070 --> 00:03:28.410 
this is then a data cleaning
process and don't underestimate

50
00:03:28.410 --> 00:03:35.980 
this. So most time that is required for a data
mining or knowledge discovery process usually

51
00:03:36.180 --> 00:03:39.580 
it has to be invested in the
preprocessing step and the data

52
00:03:39.580 --> 00:03:42.070 
cleaning step. So this is
really really an effort

53
00:03:42.590 --> 00:03:47.060 
and then from the target data by applying
preprocessing and cleaning you will

54
00:03:47.320 --> 00:03:49.730 
get your
pre-processed data.

55
00:03:50.850 --> 00:03:55.200 
However you still have to do
further preparations when using

56
00:03:55.200 --> 00:04:00.300 
the stuff ultimately in data mining and
in knowledge discovery which means

57
00:04:00.530 --> 00:04:05.130 
you have to select potentially useful
features that your prediction

58
00:04:05.130 --> 00:04:08.870 
or your model should be based on.
These features sometimes have

59
00:04:08.870 --> 00:04:13.450 
to be transformed and sometimes
your dimension of the features

60
00:04:13.450 --> 00:04:17.370 
is too high and you have to do
dimensionality reduction and

61
00:04:17.370 --> 00:04:21.990 
of course you have to look into that that
it does not let's say falsify or changes

62
00:04:22.100 --> 00:04:25.970 
your data or your viewpoint. So this
is also a complicated process,

63
00:04:25.970 --> 00:04:29.940 
so from pre process data you
get to transformed data

64
00:04:31.690 --> 00:04:35.090 
and then based on all the useful
features that you have extracted

65
00:04:35.090 --> 00:04:38.600 
from your data you try to discover
patterns, patterns of interest.

66
00:04:38.600 --> 00:04:40.660 
You search for these kind of
patterns and this is really the

67
00:04:40.660 --> 00:04:45.060 
data mining process within the data
knowledge discovery process.

68
00:04:45.790 --> 00:04:49.400 
And when you find these patterns
what you do have to do of

69
00:04:49.400 --> 00:04:54.470 
course is you have to evaluate those patterns
based of course on the interestingness

70
00:04:54.610 --> 00:04:59.270 
and other measures for model
validation. So finally then after

71
00:04:59.400 --> 00:05:03.320 
evaluating your patterns you
might end up with new insight

72
00:05:03.320 --> 00:05:08.470 
and this is the knowledge. So this is the
knowledge discovery process that transforms

73
00:05:08.800 --> 00:05:12.750 
data ultimately then
into knowledge.

74
00:05:13.860 --> 00:05:17.150 
And what we want to do here
based on knowledge graph data

75
00:05:17.570 --> 00:05:22.040 
we want to do some knowledge
graph analytics.

76
00:05:22.810 --> 00:05:26.460 
Ok we have to come up with a
task first and let's discover

77
00:05:26.460 --> 00:05:30.210 
for example interesting
knowledge about physicists.

78
00:05:31.410 --> 00:05:34.710 
What we take it as a source here
is for example general knowledge

79
00:05:34.710 --> 00:05:39.130 
graphs like for example DBpedia
or wikidata. They contain data

80
00:05:39.130 --> 00:05:43.550 
about thousands of physicists.
And for the very first steps,

81
00:05:43.550 --> 00:05:47.520 
so the first step data acquisition
is ok where do we get the

82
00:05:47.520 --> 00:05:51.600 
data and of course to see what
kind of data we might expect

83
00:05:51.880 --> 00:05:55.320 
and here we take wikidata since it
contained simply more data than

84
00:05:55.570 --> 00:05:59.970 
DBpedia. We will have a look at a
random example of a physicist

85
00:06:00.410 --> 00:06:04.320 
within wikidata and as you might
guess we will have a look at

86
00:06:04.430 --> 00:06:05.600 
Joseph Fourier.

87
00:06:06.910 --> 00:06:11.840 
So first let's look at a random
example to see what kind of data

88
00:06:12.040 --> 00:06:16.510 
we have to expect. This is the
wiki data page of Joseph Fourier

89
00:06:16.510 --> 00:06:20.390 
and we have also linked that page so
you can click on it and on that page

90
00:06:20.510 --> 00:06:25.220 
again you see lots of information. We have
already talked about the structure here

91
00:06:25.460 --> 00:06:28.620 
of exactly the data. The only
thing we haven't talked about

92
00:06:28.620 --> 00:06:33.040 
so far is how really to access
data that is beyond the usual

93
00:06:33.040 --> 00:06:36.870 
triple scope which means how to
access qualifiers for example

94
00:06:36.870 --> 00:06:41.010 
and how to access statements directly
here in wikidata and this is the

95
00:06:41.150 --> 00:06:45.570 
first thing what we do before in
the end we acquire our data.

96
00:06:46.430 --> 00:06:50.910 
So this is some data which is
available about Joseph Fourier.

97
00:06:50.910 --> 00:06:54.830 
So for example his country of
citizenship and you see he was

98
00:06:54.830 --> 00:06:57.140 
of course here citizen
of many countries.

99
00:06:57.740 --> 00:07:01.470 
This is because it was a rather
turbulent times or a confused

100
00:07:01.480 --> 00:07:04.810 
time for example he was a citizen
of the kingdom of France

101
00:07:04.810 --> 00:07:08.640 
from seventeen sixty eight to
seventeen ninety two. I remember

102
00:07:08.640 --> 00:07:12.770 
that date so there was something yep it was
called the French Revolution which means

103
00:07:13.030 --> 00:07:16.640 
after that he was then citizen
of the first French republic.

104
00:07:17.070 --> 00:07:21.170 
And after that of course remember
Napoleon Bonaparte he was

105
00:07:21.170 --> 00:07:24.340 
a member of the first French
empire and so on and so on. So

106
00:07:24.570 --> 00:07:27.540 
this is all interesting information
and of course you want probably

107
00:07:27.780 --> 00:07:31.680 
to access these time qualifiers
that are given here.

108
00:07:32.110 --> 00:07:36.150 
So first of all we want to access
the statement as its entirety

109
00:07:36.530 --> 00:07:39.870 
and of course we also want to
execute the qualifier like the

110
00:07:39.870 --> 00:07:43.260 
start time and the end
time. How do we do that?

111
00:07:44.730 --> 00:07:46.080 
So first of all
very simple-

112
00:07:47.050 --> 00:07:50.080 
the basic thing that we already
know we can access the object

113
00:07:50.080 --> 00:07:54.360 
from the usual subject property
object organization here in

114
00:07:54.360 --> 00:07:59.010 
the database and for that we have to
use a specific namespace within

115
00:07:59.150 --> 00:08:02.320 
wikidata. So we have talked about
wiki data and you have seen

116
00:08:02.320 --> 00:08:05.930 
lots of queries within wiki data
and by that you know already

117
00:08:05.930 --> 00:08:09.690 
if we want to access here
by a property the object

118
00:08:10.350 --> 00:08:13.910 
for the property that we use
the name space that we

119
00:08:13.910 --> 00:08:20.420 
have to take is WDT. WDT always
connects an item to a value.

120
00:08:20.860 --> 00:08:24.620 
And you see here the triple
pattern that has to be applied.

121
00:08:24.620 --> 00:08:28.920 
So for example we want
to have, to know what

122
00:08:29.580 --> 00:08:34.420 
WDQ8772 this is Joseph
Fourier, so entities

123
00:08:34.430 --> 00:08:36.880 
in wikidata use the
namespace WD.

124
00:08:38.010 --> 00:08:41.760 
How is this guy connected to a
country which should be the object?

125
00:08:41.860 --> 00:08:45.480 
And of course the country of
citizenship is the property

126
00:08:45.480 --> 00:08:50.170 
P27 and we have to use here
the name space WDT. So

127
00:08:50.170 --> 00:08:54.000 
this is standard, we all know
that. So this is what we already

128
00:08:54.000 --> 00:08:58.510 
did in lots of the examples within
this part of that lecture.

129
00:08:59.980 --> 00:09:04.890 
Ok before we can really access the
qualifiers within a statement

130
00:09:04.890 --> 00:09:06.950 
we have to access the
entire statement.

131
00:09:07.560 --> 00:09:12.100 
So this means then the statement
where the country of citizenship

132
00:09:12.150 --> 00:09:15.750 
here is kingdom of France as an
object exactly this statement

133
00:09:15.750 --> 00:09:19.670 
we want to access and
you do this via a

134
00:09:20.250 --> 00:09:23.320 
name space which is
abbreviated simply as p.

135
00:09:24.210 --> 00:09:28.750 
It's exactly the same
property P27 but you simply

136
00:09:28.750 --> 00:09:33.500 
look for you know
with what object is

137
00:09:34.190 --> 00:09:39.670 
the entity Joseph Fourier connected to
via the p name space and this gives u

138
00:09:40.350 --> 00:09:42.650 
as a result in
the object

139
00:09:43.340 --> 00:09:46.930 
the address or the URI of the
statement of the entire statement

140
00:09:46.930 --> 00:09:50.880 
not the simple object but the entire
statement. So if you use instead

141
00:09:51.120 --> 00:09:56.480 
of WDT the namespace p these
namespace abbreviations are

142
00:09:56.480 --> 00:09:59.400 
already there in wikidata, so
you don't have to take care to

143
00:09:59.590 --> 00:10:03.230 
define these prefixes explicitly,
they are already there.

144
00:10:03.760 --> 00:10:05.100 
So then you use p

145
00:10:05.780 --> 00:10:07.520 
with a property P27

146
00:10:08.360 --> 00:10:10.520 
and then you read the stuff
into a new property

147
00:10:11.060 --> 00:10:16.660 
sorry into a new variable and you call this
simply a country statement for example.

148
00:10:16.830 --> 00:10:18.910 
And then you have one
of the statements

149
00:10:19.550 --> 00:10:21.520 
or all of the statements
about the country.

150
00:10:22.930 --> 00:10:26.230 
Ok now we have a URI

151
00:10:26.990 --> 00:10:32.380 
of this statement that contains
the country of citizenship

152
00:10:33.020 --> 00:10:38.050 
and now we are able to access
these qualifiers and for that

153
00:10:38.110 --> 00:10:42.040 
what you do there is simply ok
now you use another name space

154
00:10:42.040 --> 00:10:45.860 
and the name space for the
qualifiers is called PQ, Q of

155
00:10:45.860 --> 00:10:50.490 
course stands for qualifier in this connected
statement, so the entire statement

156
00:10:51.030 --> 00:10:52.690 
to it's qualifier
values.

157
00:10:53.630 --> 00:10:56.600 
So what we have to do if you want
to find let's say for example

158
00:10:56.600 --> 00:11:00.540 
the end time here of that statement
what we have to do is we

159
00:11:00.540 --> 00:11:05.630 
have to use of course in a subject the
address of the country statement

160
00:11:06.110 --> 00:11:09.140 
that we have found out
in the triple before

161
00:11:09.690 --> 00:11:14.270 
and then find out ok what is end
time, what's the idea of that

162
00:11:14.280 --> 00:11:17.410 
property that is
then probably P582

163
00:11:17.870 --> 00:11:22.470 
and this has to be connected to the
namespace PQ and this gives us

164
00:11:22.600 --> 00:11:26.170 
the value of the statement here
of that qualifier and this

165
00:11:26.170 --> 00:11:30.610 
is then the twenty
first september 1792.

166
00:11:31.830 --> 00:11:36.570 
So this is a way how you really
access this kind of data in

167
00:11:36.720 --> 00:11:40.800 
wikidata simply try it out and you
will see you will get access

168
00:11:40.800 --> 00:11:44.460 
to all of the data in there even
to the qualifier values which

169
00:11:44.460 --> 00:11:47.640 
is a bit more complicated than
your statements. However

170
00:11:48.120 --> 00:11:51.730 
you are able to access it and
to make use of it and we will

171
00:11:51.730 --> 00:11:52.970 
really use it
then later on.

172
00:11:53.700 --> 00:11:57.630 
So what we are going to do is
knowledge graph analytics with

173
00:11:57.630 --> 00:12:02.330 
SPARQL and this is a convenient and very
powerful way to analyze knowledge graph data,

174
00:12:02.930 --> 00:12:06.240 
especially if we take into account
the wiki data SPARQL endpoint

175
00:12:06.240 --> 00:12:09.510 
because it already provides us
with really nice visualization

176
00:12:09.510 --> 00:12:13.270 
tools like for example bar plots,
histograms, scatterplots,

177
00:12:13.430 --> 00:12:17.320 
timelines and other kind of graph
visualizations that we have already seen.

178
00:12:18.100 --> 00:12:20.290 
So let's start with
our analytics.

179
00:12:21.300 --> 00:12:26.670 
First SPARQL query what to do we want
to find out what other occupations

180
00:12:26.810 --> 00:12:31.750 
our physicists in wikidata really
have. So this is a rather

181
00:12:31.750 --> 00:12:34.720 
simple query we won't go into
detail you see here that I look

182
00:12:34.720 --> 00:12:38.370 
for scientists who have the occupation
physicist and then simply

183
00:12:38.370 --> 00:12:44.070 
I look for other occupations of exactly
those scientists while filtering out

184
00:12:44.300 --> 00:12:48.170 
in the second triple of course all
occupations which are physicists.

185
00:12:48.170 --> 00:12:51.150 
So I don't want to have them, I only
want to have the other occupations.

186
00:12:51.690 --> 00:12:54.410 
That's it. I of course I want to
have the names for that and here

187
00:12:54.610 --> 00:12:58.770 
I limit this to one hundred and
I don't do this live so you

188
00:12:58.770 --> 00:13:02.080 
can try it out for your own but
what will be the result of

189
00:13:02.090 --> 00:13:05.730 
that and in the end, so we have to
go back. You see there that we

190
00:13:05.870 --> 00:13:09.750 
go for a specific visualization
and it says default view bar

191
00:13:09.750 --> 00:13:12.940 
chart, this is for
visualizing a bar chart

192
00:13:14.040 --> 00:13:17.210 
and the result then will be the
following bar chart and you

193
00:13:17.210 --> 00:13:21.070 
see here this is interesting again
you see a nice distribution

194
00:13:21.070 --> 00:13:25.540 
with a long tail and of course
most occupation of physicists

195
00:13:25.540 --> 00:13:29.600 
if you look closer here to the little
small font you will see that most

196
00:13:29.730 --> 00:13:34.180 
of the other occupations of
physicists are university teacher

197
00:13:34.190 --> 00:13:37.850 
or scientist for example. And
this is much more frequent than

198
00:13:37.850 --> 00:13:40.920 
for example the occupation
an aircraft pilot.

199
00:13:41.460 --> 00:13:44.100 
But there are also physicists
who are aircraft pilot you can

200
00:13:44.100 --> 00:13:47.180 
look it up exactly in
that kind of graphics.

201
00:13:48.280 --> 00:13:51.890 
So this is a first let's say
visual kind of analysis, but of

202
00:13:51.890 --> 00:13:53.700 
course we want
to know more.

203
00:13:54.360 --> 00:13:59.170 
And for that of course we first have
to gather lots of information

204
00:13:59.170 --> 00:14:03.890 
as many information as possible. And for that
of course we access the physicist data

205
00:14:04.300 --> 00:14:09.080 
in wikidata. However we have to prepare
it in a way that we can use it.

206
00:14:09.430 --> 00:14:12.580 
So we want to have a table in
the end that gives us you see

207
00:14:12.580 --> 00:14:14.450 
this in the query
here you know

208
00:14:15.740 --> 00:14:18.080 
for each citizen
we want to know

209
00:14:18.550 --> 00:14:21.790 
in how many countries
did this citizen live.

210
00:14:22.190 --> 00:14:24.910 
When was the birth date of that
citizen? That we have you know

211
00:14:25.080 --> 00:14:31.110 
that we can order them in time? How many
other occupations did that physicist have?

212
00:14:31.250 --> 00:14:36.710 
How many employers did he have? How many
awards did he receive? In how many

213
00:14:37.060 --> 00:14:41.660 
learned societies was he or she a
member of? And of course talking

214
00:14:41.660 --> 00:14:45.910 
about gender we have to look for
the sex and then also we look

215
00:14:45.910 --> 00:14:50.800 
for the fields let's say within
physics what the physicist

216
00:14:50.810 --> 00:14:55.130 
was occupied with and what was of
his interest. So this exactly

217
00:14:55.130 --> 00:14:57.850 
is what we were looking for its
a more or less complicated

218
00:14:57.850 --> 00:15:01.500 
query aggregated here by physicist
and I look for you know

219
00:15:01.630 --> 00:15:05.170 
all of the counts of the numbers
that we are looking for. You

220
00:15:05.170 --> 00:15:09.380 
might again try it out. This is a
long query, you see the result

221
00:15:09.380 --> 00:15:11.100 
then here on the
next page.

222
00:15:12.010 --> 00:15:15.800 
So I can show you we have
already prepared it here and

223
00:15:15.930 --> 00:15:20.530 
when you carry it out you get a
list like that and here you see

224
00:15:20.630 --> 00:15:24.520 
we have the physicists here, we
have the birthdate. So here

225
00:15:24.940 --> 00:15:28.350 
if we do a data analysis we are
not interested in let's say

226
00:15:28.350 --> 00:15:31.570 
the clear names of the physicists,
we are only interested in

227
00:15:31.570 --> 00:15:34.970 
the features of the physicist
here, like the birth date and

228
00:15:34.970 --> 00:15:38.190 
here we only select the year
because this is easier to handle.

229
00:15:38.520 --> 00:15:41.380 
Then we have the countries, number
of countries they lived in,

230
00:15:41.380 --> 00:15:47.000 
number of occupations, number of employers,
number of awards received, number of

231
00:15:47.370 --> 00:15:50.380 
how in how many learned societies
they have been member of

232
00:15:50.390 --> 00:15:52.180 
and so on and so on and
we have a gender.

233
00:15:52.670 --> 00:15:57.010 
Let's say then here. So this
is the data that we have.

234
00:15:58.280 --> 00:16:00.510 
To make use of the data
what you simply do is

235
00:16:01.500 --> 00:16:04.520 
copy all the stuff, download all
the stuff - you have a download

236
00:16:04.520 --> 00:16:09.130 
button here if you want to and what we
did here is we simply copied the data

237
00:16:09.440 --> 00:16:14.300 
to a spreadsheet, and of course you can here
use collaborative spreadsheets from google.

238
00:16:14.510 --> 00:16:18.480 
We did this and here we have all
the data about the physicists

239
00:16:18.480 --> 00:16:20.830 
that we had as a result

240
00:16:21.600 --> 00:16:25.010 
in the SPARQL query here in that
spreadsheet. If you wonder

241
00:16:25.010 --> 00:16:29.330 
how to do that, you can export
this results of the SPARQL

242
00:16:29.330 --> 00:16:34.560 
query here as a csv file for example.
So you say download results

243
00:16:34.560 --> 00:16:39.820 
and for that you can here for
example select csv and csv you

244
00:16:39.820 --> 00:16:44.520 
can directly then also import here in the
spreadsheet and then you have exactly

245
00:16:44.620 --> 00:16:46.450 
this here in the
spreadsheet.

246
00:16:47.480 --> 00:16:50.400 
We have prepared it so far, we
have the spreadsheet and now

247
00:16:50.400 --> 00:16:53.150 
you might think ok so let's
start data analysis.

248
00:16:54.040 --> 00:16:57.280 
We are not completely finished
with cleaning up the stuff of

249
00:16:57.280 --> 00:17:02.440 
course. What we have to do is for
example we have a look bit look closer

250
00:17:02.780 --> 00:17:06.300 
to exactly the data we have. What
I did here was simply looking

251
00:17:06.300 --> 00:17:12.690 
at the data by sorting you know the
entire table for or by different

252
00:17:13.010 --> 00:17:16.930 
columns and if you sorted for
example here by birthdate you

253
00:17:16.930 --> 00:17:21.080 
will find out that there is interestingly
an only fourteen year old physicist

254
00:17:21.520 --> 00:17:24.380 
which is interesting and also
there are so many physicists

255
00:17:24.380 --> 00:17:27.910 
almost twenty who were born in the
year two thousand on the first

256
00:17:28.120 --> 00:17:32.450 
of january which is
also kind of strange.

257
00:17:33.480 --> 00:17:36.890 
Whatever you do with that of
course it doesn't seem valid so

258
00:17:36.890 --> 00:17:40.710 
you have to check what does it mean.
And if you then go exactly to these

259
00:17:41.100 --> 00:17:45.310 
wikidata pages and look at the birth
dates you will find out that

260
00:17:45.510 --> 00:17:47.730 
here somebody did
not write really

261
00:17:48.370 --> 00:17:52.250 
uh the year two thousand and the
first of january in the birth date

262
00:17:52.580 --> 00:17:56.720 
their birthdate was not exactly known
and somebody wrote their only

263
00:17:56.840 --> 00:18:00.740 
20th century or
something like that.

264
00:18:02.450 --> 00:18:06.310 
And therefore this kind of
data has been generated. So

265
00:18:06.710 --> 00:18:11.270 
you have to decide what to do with it
since it were only twenty we simply

266
00:18:11.740 --> 00:18:15.620 
skipped them out from our calculations
and then of course created

267
00:18:15.620 --> 00:18:19.890 
a new table that you access now
and exactly on that table we

268
00:18:19.890 --> 00:18:23.720 
want to start and begin our
analysis. So the question is can

269
00:18:23.720 --> 00:18:26.210 
we trust all the data? You have
to look deeper into that and

270
00:18:26.210 --> 00:18:30.580 
you have to clean up the stuff
which is often a lot of work.

271
00:18:32.100 --> 00:18:34.740 
Ok now we have the data now we
want to know more about the

272
00:18:34.740 --> 00:18:37.550 
data which means we have to
apply some kind of statistics.

273
00:18:38.350 --> 00:18:41.710 
And one of the let's say most
convenient things if you want

274
00:18:41.710 --> 00:18:45.160 
to get more insight into
numerical data is you know

275
00:18:45.790 --> 00:18:49.510 
drop box plots and look at a few
statistical measures. For that

276
00:18:49.510 --> 00:18:53.020 
you have to know how to read box
plots. So this is an arbitrary

277
00:18:53.020 --> 00:18:56.750 
box plot of data that we have
here and for example you see

278
00:18:56.750 --> 00:18:59.890 
here some interesting facts about
the data on the left side. So

279
00:19:00.190 --> 00:19:03.060 
the data we are looking at here
is only let's say one column

280
00:19:03.060 --> 00:19:06.690 
within a table and the minimum
value there we have is minus

281
00:19:06.690 --> 00:19:09.850 
eighty six and the maximum value
we have there is thirteen

282
00:19:09.850 --> 00:19:13.820 
hundred twenty nine. And you see
a few more you see something

283
00:19:13.820 --> 00:19:17.230 
which is referred to as a median
,you have a mean - mean is clear.

284
00:19:17.230 --> 00:19:20.030 
You count all the values together
and you divide it by the number,

285
00:19:20.030 --> 00:19:23.280 
so this is the average value. The
average value here is thirty

286
00:19:23.280 --> 00:19:25.390 
eight point eight five and
you have a few more.

287
00:19:26.030 --> 00:19:30.250 
And all of these values here are also
noted in the so called box plot

288
00:19:30.490 --> 00:19:35.170 
that you see here. First thing
which you might know if you know

289
00:19:35.170 --> 00:19:38.360 
a little bit about statistics is
the so called median. The median

290
00:19:38.710 --> 00:19:41.880 
is the values separating the higher
half from the lower half of

291
00:19:41.890 --> 00:19:45.160 
the data which means half of the
data is larger than the median

292
00:19:45.160 --> 00:19:47.770 
and half of the data is
smaller than the median.

293
00:19:48.250 --> 00:19:53.940 
And in our case you see here the median
is lying at number seventeen. So

294
00:19:54.630 --> 00:19:57.450 
half of the data are smaller than
seventeen, other half of the

295
00:19:57.450 --> 00:20:00.770 
data is larger than seventeen. This
already gives you some insight

296
00:20:00.770 --> 00:20:03.200 
how the values are
distributed.

297
00:20:04.580 --> 00:20:08.460 
To gain more insight you see
where fifty percent of all the

298
00:20:08.460 --> 00:20:12.220 
data actually is located and
for that you have besides the

299
00:20:12.220 --> 00:20:15.360 
median you have the first
quartile and third quartile.

300
00:20:15.840 --> 00:20:20.410 
And what is in between these two quartiles
is the so called inter-quartiles range

301
00:20:20.540 --> 00:20:24.390 
and there in our case you see
for example the first quartile

302
00:20:24.580 --> 00:20:28.180 
is starting at three and the third
quartile at fifty one which

303
00:20:28.180 --> 00:20:31.860 
means fifty percent of all of the data
lies in the range between three

304
00:20:32.260 --> 00:20:37.090 
and fifty one. This means the
inter quartile range between the

305
00:20:37.090 --> 00:20:39.040 
first and the
third quartiles.

306
00:20:41.050 --> 00:20:45.190 
And then you have these so called
whiskers which connect you know

307
00:20:45.560 --> 00:20:47.960 
these quartiles upper
and lower quartiles

308
00:20:48.370 --> 00:20:54.380 
with let's say the range where we see
our valid data and this usually is

309
00:20:54.770 --> 00:20:58.650 
an area that is usually or roughly
the interquartiles range

310
00:20:58.650 --> 00:21:02.610 
times one point five. Sometimes
it's a bit lower sometimes

311
00:21:02.610 --> 00:21:05.870 
it's a bit higher but people
usually say this is the let's say

312
00:21:05.870 --> 00:21:11.970 
the area of the interesting values
that we are talking about. And this

313
00:21:12.100 --> 00:21:16.000 
it is where the whiskers are and
this everything which is outside

314
00:21:16.000 --> 00:21:20.270 
the whiskers usually is referred to
as an outlier and you have to look

315
00:21:20.560 --> 00:21:24.040 
you know what to do with the
data, how far is it away, can

316
00:21:24.040 --> 00:21:28.510 
we trust the data has to be further
validated and stuff like that. So this

317
00:21:28.680 --> 00:21:34.470 
already gives you some insight how your
data your specific data is distributed

318
00:21:34.800 --> 00:21:41.510 
where you probably might already find patterns
then for future knowledge analysis.

319
00:21:42.690 --> 00:21:44.480 
and exactly how
to do that?

320
00:21:45.120 --> 00:21:49.170 
You can learn this by looking
into the color notebook that

321
00:21:49.180 --> 00:21:52.910 
we have prepared for you because you
can also do this kind of analysis

322
00:21:53.330 --> 00:21:58.060 
based on pipe. I only give you a
brief overview over that thing.

323
00:21:58.170 --> 00:22:01.580 
You have to do this of course in self
study to understand it better but

324
00:22:01.770 --> 00:22:04.520 
I will walk you
quickly through. So

325
00:22:05.160 --> 00:22:09.270 
we have prepared here exactly that
kind of knowledge graph example

326
00:22:09.530 --> 00:22:13.430 
and what you have to do first as always
in python and you have to load

327
00:22:13.550 --> 00:22:17.590 
a bunch of libraries and then
what you have to do is here

328
00:22:17.840 --> 00:22:22.610 
to access the spreadsheet we have
prepared for you within our material.

329
00:22:22.840 --> 00:22:24.620 
You have to enable

330
00:22:25.990 --> 00:22:30.130 
that collab notebook to read from
your google drive. So this

331
00:22:30.130 --> 00:22:32.610 
is then the next one, for that
you need another library and

332
00:22:32.610 --> 00:22:34.280 
then you have to
authenticate.

333
00:22:36.130 --> 00:22:39.980 
I did it already. If you
authenticate you will be displayed

334
00:22:39.980 --> 00:22:45.340 
a web page. You go to that web page
then there will be you have to

335
00:22:45.870 --> 00:22:49.000 
you have to log on with your
google account and then a string

336
00:22:49.000 --> 00:22:52.620 
will be displayed and you have
to copy that string here and

337
00:22:52.640 --> 00:22:56.600 
of course they give you exactly
instructions what you do

338
00:22:56.670 --> 00:22:59.580 
and you authorize here with
google and then you are

339
00:23:00.020 --> 00:23:03.690 
capable of directly accessing
that. So now we are

340
00:23:05.100 --> 00:23:07.880 
all preparations are finished
and what we can do is we can

341
00:23:07.880 --> 00:23:11.900 
start to analyze our data. So first
thing to do I import pandas

342
00:23:11.900 --> 00:23:16.000 
this is a statistic package and
what I do here is simply I

343
00:23:16.460 --> 00:23:21.760 
run the very first thing which
means we are reading here

344
00:23:21.860 --> 00:23:24.930 
our spreadsheet from google docs
and then we are simply looking

345
00:23:24.930 --> 00:23:27.790 
yeah what's the data? So we are
looking for we are reading the data

346
00:23:27.790 --> 00:23:30.850 
into a structure which is referred
to as physicists and then

347
00:23:30.850 --> 00:23:35.100 
we look at the first ten lines.
So this is the command head

348
00:23:35.160 --> 00:23:37.870 
and which they had ten and you
see here this is the first ten

349
00:23:37.870 --> 00:23:41.700 
lines of our data. We have physicists
where we have here you know

350
00:23:41.890 --> 00:23:44.880 
the identifier of the physicists.
We don't care about that and

351
00:23:44.880 --> 00:23:47.930 
you have the birthdate, countries,
occupations and so on and so on.

352
00:23:50.370 --> 00:23:55.750 
To find out some insights about
our data you can use here the

353
00:23:55.760 --> 00:23:58.980 
method described and with describe
you see something similar

354
00:23:58.980 --> 00:24:03.220 
like that we had on the slides.
So you see here for example

355
00:24:03.220 --> 00:24:06.860 
that we have overall fourteen hundred
and sixty lines in that table

356
00:24:07.070 --> 00:24:10.510 
so fourteen hundred and sixty
physicists have been described. You

357
00:24:10.510 --> 00:24:15.800 
see here the mean value - that's the average,
you see here the standard deviation value,

358
00:24:16.000 --> 00:24:19.280 
the minimum value, the maximum
value. So we can see for example

359
00:24:19.280 --> 00:24:23.070 
for our physicists here the
earliest birth date we have in

360
00:24:23.070 --> 00:24:26.680 
the table is sixteen hundred and
thirty two and the latest birth date

361
00:24:26.910 --> 00:24:29.320 
they are still in there is
the year two thousand.

362
00:24:29.770 --> 00:24:33.370 
And you have here also the median
this is fifty percent so

363
00:24:33.370 --> 00:24:36.780 
the median of our birth dates here
would be nineteen hundred and twenty.

364
00:24:37.340 --> 00:24:40.260 
It's already interesting insight
which means most of the physicists

365
00:24:40.260 --> 00:24:44.630 
we have fifty percent are born in
the twentieth century or later.

366
00:24:45.730 --> 00:24:51.190 
Ok however it's much nicer to
look at this stuff in graphics

367
00:24:51.190 --> 00:24:57.010 
to visualize it for that we
use the matplotlib library.

368
00:24:57.220 --> 00:24:59.730 
So with that you can do
very nice diagrams.

369
00:25:01.000 --> 00:25:05.400 
simply have a look at it and we
do here histograms for all

370
00:25:05.750 --> 00:25:10.900 
of the columns we have and you
see here histograms it starts

371
00:25:10.900 --> 00:25:14.130 
here alphabetically. So for the
awards this is the histogram

372
00:25:14.130 --> 00:25:16.790 
for the awards, there are a few
physicists who received really

373
00:25:16.790 --> 00:25:18.930 
lots of awards and you
have a long tail.

374
00:25:19.450 --> 00:25:22.620 
This is the birthdate record with
see here most of the people

375
00:25:22.620 --> 00:25:24.630 
born here in the
twentieth century.

376
00:25:25.480 --> 00:25:29.910 
This is the country's numbers.
So most of the physicists

377
00:25:29.910 --> 00:25:32.990 
have been member only in one country
and there are several then

378
00:25:33.320 --> 00:25:37.420 
who have been citizens of more
countries. The number of

379
00:25:37.870 --> 00:25:42.470 
employers so here you have the employers
most cities umm most physicists

380
00:25:42.470 --> 00:25:47.150 
were employed on only by one
employer. So others had several

381
00:25:47.150 --> 00:25:50.180 
more So they were even physicists
with fourteen employers, that's

382
00:25:50.410 --> 00:25:54.470 
very much. This is the number of
fields they were interested

383
00:25:54.470 --> 00:25:55.860 
in. Here you have the

384
00:25:56.460 --> 00:26:01.680 
number of societies they have been member
in, and we continue here. This is

385
00:26:01.980 --> 00:26:07.270 
the number of occupations they have
been besides being a physicist.

386
00:26:07.560 --> 00:26:10.850 
And what you do next of course you
look at all the stuff in box plots

387
00:26:11.140 --> 00:26:15.520 
so you can have a combined box
plot. And I again put everything

388
00:26:15.520 --> 00:26:17.850 
in one table. And you
see here yeah this is

389
00:26:18.270 --> 00:26:21.280 
simply because of the value
distribution we have here before

390
00:26:21.280 --> 00:26:26.080 
the birthdate values that range up to
two thousand and of course the other

391
00:26:26.220 --> 00:26:29.250 
ranges are quite small like the
number of occupations or the

392
00:26:29.250 --> 00:26:32.070 
number of countries, therefore
you can't read much in it. So

393
00:26:32.070 --> 00:26:34.650 
we have to look
this up you know

394
00:26:35.960 --> 00:26:39.870 
column by column. We start
here with a column birthdate

395
00:26:40.830 --> 00:26:44.230 
and you see here yeah so most of
our physicists are born here

396
00:26:44.230 --> 00:26:47.070 
in the twentieth century, this is
again the median at nineteen

397
00:26:47.070 --> 00:26:50.400 
twenty and a few are there that
read date back and are already

398
00:26:50.400 --> 00:26:54.530 
treated outlier if they are born
you know in the first half

399
00:26:54.540 --> 00:26:56.780 
of the eighteenth
century. Interesting.

400
00:26:58.000 --> 00:27:00.250 
But this of course does not hold
for all of the people, it only

401
00:27:00.250 --> 00:27:04.010 
holds for the profession of
physicist. Then we have this here

402
00:27:04.010 --> 00:27:06.450 
the same box plot for the
number of countries,

403
00:27:08.680 --> 00:27:11.530 
a box plot for the
number of occupations,

404
00:27:13.380 --> 00:27:17.780 
a box plot for the number of employers.
So you can make your own thoughts and

405
00:27:18.120 --> 00:27:22.600 
draw the conclusions out of
exactly these distributions than

406
00:27:22.600 --> 00:27:25.810 
we have here members of
societies as you see here.

407
00:27:26.280 --> 00:27:30.240 
And lastly a number of fields
they were interested in.

408
00:27:32.580 --> 00:27:37.360 
It would be interesting since we also
have you know data about the gender.

409
00:27:38.090 --> 00:27:40.930 
What's the gender distribution
and you see here if we look

410
00:27:40.930 --> 00:27:44.550 
here at the gender and count the
values we have thirteen hundred

411
00:27:44.550 --> 00:27:48.270 
and ninety three male physicist
but only sixty seven female

412
00:27:48.270 --> 00:27:51.350 
physicists. So these
are not really much.

413
00:27:52.690 --> 00:27:55.620 
If we look at the birth dates we
can also count the birth dates.

414
00:27:55.620 --> 00:27:59.800 
you see here the most let's say
that the year with the highest

415
00:27:59.800 --> 00:28:03.700 
number of birth dates is nineteen twenty
eight with twenty eight physicists,

416
00:28:03.960 --> 00:28:07.150 
nineteen thirty six with twenty
six physicist and so on and

417
00:28:07.150 --> 00:28:09.480 
so on. And it of course
become smaller.

418
00:28:10.790 --> 00:28:15.840 
Let's do a bit of graphics in the
end. So we can do also something

419
00:28:15.840 --> 00:28:20.160 
which is called a scatter plot where you
try to relate data with each other.

420
00:28:20.420 --> 00:28:25.400 
What we do here for example we put
the data of the number of fields

421
00:28:25.790 --> 00:28:31.290 
on the y axis and of course
here the birthdate on, I will

422
00:28:31.290 --> 00:28:33.730 
make this a bit smaller that
it fits into the screen,

423
00:28:35.670 --> 00:28:40.620 
into the x axis. And you see here
most of the people of course

424
00:28:40.620 --> 00:28:44.730 
they are only working in one field and
several people are working in many fields,

425
00:28:44.870 --> 00:28:48.310 
and for example here in the early
days of physics so people

426
00:28:48.570 --> 00:28:52.620 
also were working in lots of different
fields so they were more universal

427
00:28:52.940 --> 00:28:59.420 
than today. Today people are most likely
more focused, more specialized.

428
00:28:59.420 --> 00:29:02.700 
That could be one of the
conclusions that you might draw.

429
00:29:05.600 --> 00:29:08.990 
You can even put more data in
these kind of gotta plots.

430
00:29:08.990 --> 00:29:13.370 
What we did here for example we
tried to use also the dot size

431
00:29:13.370 --> 00:29:17.250 
and where we were using colors to
make some more data visible.

432
00:29:17.250 --> 00:29:21.360 
So this is again the birthdate is
the x axis , here is occupations,

433
00:29:21.360 --> 00:29:26.290 
number of occupations in the y axis,
the size of the plots here gives you

434
00:29:26.500 --> 00:29:30.880 
the number of fields these people
were interested in and the

435
00:29:30.880 --> 00:29:34.370 
colour gives you the number of
awards. So most are here in the

436
00:29:34.370 --> 00:29:38.180 
lower ranges which means everything
is quite blue then it becomes

437
00:29:38.180 --> 00:29:41.830 
turquoise and then yellow
and sometimes also red but

438
00:29:42.620 --> 00:29:45.610 
you can't see much of that you
can play around with it also

439
00:29:45.610 --> 00:29:50.080 
with the dots sizes and which
you know feature to associate

440
00:29:50.080 --> 00:29:54.340 
with which property here in the graph
and of course you can then come up

441
00:29:54.500 --> 00:29:59.790 
with interesting plots that try to
give you insights in what exactly

442
00:30:00.010 --> 00:30:03.070 
is shown here in

443
00:30:04.120 --> 00:30:08.080 
the data. The very last thing I'm
going to show you is of course

444
00:30:08.080 --> 00:30:10.890 
if you have this different kind
of features you probably want

445
00:30:10.890 --> 00:30:14.160 
to know which of these features
might be correlated or not.

446
00:30:14.590 --> 00:30:18.610 
And for this you do or you try
to create a correlation matrix

447
00:30:18.610 --> 00:30:22.660 
and do a correlation coefficient
analysis. And if we try to

448
00:30:22.660 --> 00:30:26.760 
find what is correlated to the
value of birth date you will

449
00:30:26.760 --> 00:30:29.790 
see here for example there are
only weak correlations. But this

450
00:30:29.790 --> 00:30:34.800 
seems to be a bit stronger
negative a negative

451
00:30:34.810 --> 00:30:37.910 
correlation between
the birth date and

452
00:30:38.690 --> 00:30:41.990 
the number of how many societies
you are member in and the

453
00:30:41.990 --> 00:30:44.330 
number of occupations
you have, which means

454
00:30:45.030 --> 00:30:49.480 
in previous times probably you had
more occupations on the side

455
00:30:49.790 --> 00:30:52.610 
because physicists probably could
not make a living I don't know.

456
00:30:52.930 --> 00:30:56.110 
And of course you remember
in more societies

457
00:30:57.810 --> 00:31:00.920 
that's an interesting insight
and you have to find some you

458
00:31:00.920 --> 00:31:05.710 
know features or explanations to
explain this further. So there

459
00:31:05.710 --> 00:31:09.390 
is much more to discover in this
branch. Just look at it and

460
00:31:09.520 --> 00:31:14.700 
try to find out more about
physicists. This was only a quick

461
00:31:14.950 --> 00:31:19.860 
insight or first glance into how to
do data analysis with data you

462
00:31:20.010 --> 00:31:24.090 
gain from knowledge graph. So here
was the data acquisition step

463
00:31:24.210 --> 00:31:27.650 
within the knowledge graph and
then to see what we can find

464
00:31:27.650 --> 00:31:30.940 
out what additional knowledge
we could conclude.

465
00:31:32.190 --> 00:31:35.870 
That's it for that lecture number
five. We will continue then

466
00:31:35.880 --> 00:31:39.350 
with lecture number six when we
have a look at advanced knowledge

467
00:31:39.350 --> 00:31:40.470 
graph applications.
