WEBVTT

1
00:00:00.500 --> 00:00:05.040 
Hello, my name is Max and I would
like to welcome you back to this

2
00:00:05.150 --> 00:00:08.780 
second video of the series on
Energy-Aware Resource Management

3
00:00:08.790 --> 00:00:12.330 
in Heterogeneous Computing Systems.
So, in this video, I'm going

4
00:00:12.330 --> 00:00:17.450 
to focus on some research approaches
for improving energy efficiency and

5
00:00:18.120 --> 00:00:19.400 
GPU based workloads.

6
00:00:20.700 --> 00:00:24.340 
This research is conducted
together with my colleagues

7
00:00:24.340 --> 00:00:28.350 
at the Operating Systems and Middleware
group at HPI which is led by

8
00:00:28.560 --> 00:00:29.580 
Professor
Andreas Polze.

9
00:00:30.990 --> 00:00:34.300 
Our ultimate goal is
to find various

10
00:00:34.300 --> 00:00:38.660 
approaches for improving the energy efficiency
of heterogeneous computing systems.

11
00:00:40.470 --> 00:00:46.660 
So, as Sven talked in his
video about some strategies

12
00:00:46.660 --> 00:00:48.950 
about influencing
power consumption,

13
00:00:49.690 --> 00:00:53.180 
let me pick up on this slide.
So, there are 3 major

14
00:00:53.710 --> 00:00:55.030 
strategies that we see,

15
00:00:55.630 --> 00:01:01.720 
one is working differently which can be using
fewer or additional computer resources,

16
00:01:02.600 --> 00:01:06.700 
the second approach is working
at different times, so

17
00:01:07.090 --> 00:01:12.020 
if your jobs are not bound by a strict
deadline you can run them later

18
00:01:13.870 --> 00:01:15.780 
to match the
energy profiles.

19
00:01:16.540 --> 00:01:18.030 
These two
approaches are

20
00:01:18.960 --> 00:01:22.790 
quite intensely studied also
by other research groups

21
00:01:23.240 --> 00:01:28.070 
and another approach that we are
focusing on at our research group is

22
00:01:28.610 --> 00:01:34.250 
that we want to work elsewhere meaning that
we want to use other hardware components

23
00:01:35.810 --> 00:01:39.250 
then those that are commonly
used for certain workloads.

24
00:01:40.680 --> 00:01:46.410 
So, let me dive into the first
approach which is using balanced

25
00:01:46.410 --> 00:01:48.980 
hardware for workloads
at hands. So,

26
00:01:49.960 --> 00:01:54.430 
we saw that for many GPU based
workloads if you're looking

27
00:01:54.430 --> 00:01:58.420 
closer at the actual
utilization of your GPU,

28
00:02:00.040 --> 00:02:01.510 
there are certain
workloads that

29
00:02:02.190 --> 00:02:06.760 
do not really fully exploit all the
resources that are available.

30
00:02:07.330 --> 00:02:11.150 
So, this might seem trivial
at first sight but

31
00:02:12.240 --> 00:02:16.650 
if your workload doesn't really
utilize your GPU but it's still

32
00:02:17.290 --> 00:02:21.370 
burning a lot of energy that's
really not very efficient, so

33
00:02:21.780 --> 00:02:26.260 
it might be wise to step back and
consider using different hardware that

34
00:02:26.630 --> 00:02:28.710 
is perhaps more
balanced and

35
00:02:29.810 --> 00:02:33.350 
instead of using the highest
possible performance hardware.

36
00:02:34.270 --> 00:02:40.460 
So, this graph can be seen here, it's
extracted from a very recent article

37
00:02:41.430 --> 00:02:45.060 
where people compared certain
machine learning workloads

38
00:02:45.950 --> 00:02:49.920 
run on a one of these
new Apple M1 CPU's

39
00:02:50.890 --> 00:02:52.850 
which are quite
capable compared

40
00:02:53.700 --> 00:02:57.650 
to an NVIDIA V100 GPU
and as you can see

41
00:02:58.290 --> 00:03:03.410 
while of course, the Apple CPU
takes a little bit longer because

42
00:03:03.410 --> 00:03:06.390 
it's a much lower power
hardware obviously

43
00:03:07.010 --> 00:03:09.980 
but considering that
it just takes

44
00:03:10.760 --> 00:03:12.810 
a small fraction
of the energy,

45
00:03:15.810 --> 00:03:18.380 
the increased
execution time isn't

46
00:03:18.950 --> 00:03:21.640 
as bad as you would
expect it to be.

47
00:03:22.740 --> 00:03:26.440 
So, inspired by this
optimization we performed

48
00:03:26.440 --> 00:03:28.410 
a little bit of
a case study

49
00:03:30.170 --> 00:03:33.870 
in the context of another paper
that we've published. So, there

50
00:03:33.870 --> 00:03:39.220 
the goal was to use compression to
increase data transfer efficiency

51
00:03:39.580 --> 00:03:44.420 
between main memory and accelerator
memory but also between

52
00:03:45.720 --> 00:03:50.780 
head nodes of a cluster master
node and compute nodes

53
00:03:50.920 --> 00:03:54.790 
equipped with accelerators, and
there the simple idea is

54
00:03:55.340 --> 00:03:57.860 
to compress data before
it's transmitted

55
00:03:58.330 --> 00:04:02.010 
to the compute node
and decompress it

56
00:04:02.740 --> 00:04:06.820 
right in the accelerator memory.
So, by reducing the data volume

57
00:04:07.120 --> 00:04:10.170 
you can save some energy
because moving data is

58
00:04:10.720 --> 00:04:14.520 
one of the most significant
contributors to energy consumption

59
00:04:15.250 --> 00:04:17.210 
in modern computer
architectures.

60
00:04:18.070 --> 00:04:21.250 
And as a little bit of
a side observation

61
00:04:21.950 --> 00:04:24.390 
that we made while
writing this paper is

62
00:04:24.910 --> 00:04:30.920 
that when we applied our GPU based
decompression algorithm on different

63
00:04:31.260 --> 00:04:36.490 
GPU hardware there were some interesting
effects. So first, we started

64
00:04:36.680 --> 00:04:41.050 
with as a baseline with an NVIDIA
Tesla K80 card, it's not a

65
00:04:41.630 --> 00:04:43.770 
very recent model but
one that we have

66
00:04:44.620 --> 00:04:49.360 
found is still available in many
GPU computer infrastructures,

67
00:04:49.940 --> 00:04:51.450 
so it's still
interesting.

68
00:04:52.190 --> 00:04:53.490 
So, here you can see

69
00:04:55.060 --> 00:04:59.180 
the decompression performance in
terms of throughput and megabytes

70
00:04:59.180 --> 00:05:01.220 
per second is
quite decent

71
00:05:02.300 --> 00:05:03.720 
and on the
right-hand side

72
00:05:04.450 --> 00:05:08.050 
you can see megabytes
per second per watt.

73
00:05:09.630 --> 00:05:13.560 
And as a next step we

74
00:05:14.180 --> 00:05:18.050 
deployed the same task on a much
smaller embedded computing device,

75
00:05:18.410 --> 00:05:22.230 
one of these NVIDIA Jetson
TX2 development boards.

76
00:05:22.630 --> 00:05:24.780 
So this is a
small ARM-based

77
00:05:25.440 --> 00:05:29.930 
SOC developed by NVIDIA which also
comes equipped with an internal GPU.

78
00:05:30.570 --> 00:05:32.460 
And of course, you
can see that

79
00:05:33.260 --> 00:05:36.720 
the raw compute throughput
is just roughly one third

80
00:05:37.130 --> 00:05:42.450 
of the high-end K80 GPU but in
terms of energy efficiency

81
00:05:42.450 --> 00:05:45.700 
you can almost get seven
times the amount of

82
00:05:46.160 --> 00:05:48.870 
compression throughput
per watt spent.

83
00:05:49.510 --> 00:05:56.350 
So this is quite a quite an
improvement of power efficiency here

84
00:05:56.980 --> 00:05:57.480 


85
00:05:59.470 --> 00:06:00.360 
but since this

86
00:06:01.770 --> 00:06:06.270 
Jetson development board is
quite exotic hardware we also

87
00:06:06.620 --> 00:06:08.780 
performed these tests
on an additional

88
00:06:09.650 --> 00:06:15.880 
compute oriented GPU from NVIDIA
but more from the balanced end

89
00:06:16.610 --> 00:06:18.430 
of the performance
spectrum.

90
00:06:19.070 --> 00:06:23.120 
And there we could see that
using this Tesla T4 instead

91
00:06:23.120 --> 00:06:28.320 
of the K80, we got mild
improvements in the compression

92
00:06:28.320 --> 00:06:31.820 
decompression throughput which
is quite nice, I mean 1.2

93
00:06:32.250 --> 00:06:36.440 
isn't really much but it's still an
improvement but at the same time

94
00:06:37.270 --> 00:06:42.010 
we're almost
getting 2.4 times

95
00:06:42.840 --> 00:06:44.700 
the throughput
per watt spent,

96
00:06:45.570 --> 00:06:49.270 
which is again quite
nice considering that

97
00:06:50.040 --> 00:06:52.830 
the workload hasn't changed at
all. So, the implementation

98
00:06:53.310 --> 00:06:58.240 
didn't change for either of these tested
platforms, it's just the same platform

99
00:06:58.630 --> 00:07:03.740 
the same workload deployed on different
platforms and just by choosing

100
00:07:04.990 --> 00:07:09.640 
the best suitable hardware for the
task you can already increase

101
00:07:10.020 --> 00:07:11.720 
power efficiency
significantly.

102
00:07:15.860 --> 00:07:19.640 
Even though our focus is mostly
on this a third point on

103
00:07:19.640 --> 00:07:23.020 
working elsewhere, so on different
types of hardware components,

104
00:07:23.910 --> 00:07:27.070 
we didn't leave the other
parts completely uncovered.

105
00:07:27.480 --> 00:07:32.620 
So, at the moment we are also
working on a project which is

106
00:07:32.620 --> 00:07:35.840 
actually, a master's thesis by
a student while we're trying

107
00:07:35.840 --> 00:07:39.810 
to apply this approach of using
additional of your resources.

108
00:07:41.020 --> 00:07:43.650 
So, this is the second approach
that I want to talk about here,

109
00:07:45.290 --> 00:07:49.070 
yeah it's a based on a master
thesis by Felix Grzelka

110
00:07:50.340 --> 00:07:57.360 
and there, the key story is that for some
workloads energy efficiency can be improved

111
00:07:57.650 --> 00:08:02.500 
just by choosing different power
profiles of your hardware. So,

112
00:08:02.950 --> 00:08:07.080 
all or most hardware nowadays
can be configured at

113
00:08:07.090 --> 00:08:09.190 
different power levels
so you can set them to

114
00:08:09.630 --> 00:08:12.070 
maximum performance or
you can choose to

115
00:08:13.520 --> 00:08:16.790 
allocate a smaller
power envelope,

116
00:08:17.610 --> 00:08:22.860 
and by that reduce the power consumption
and the overall energy consumed

117
00:08:23.010 --> 00:08:26.000 
per computational
task. So,

118
00:08:28.050 --> 00:08:32.060 
we started with a brief
exploration using the

119
00:08:32.700 --> 00:08:37.040 
quite a well-known machine
learning workload

120
00:08:38.740 --> 00:08:43.500 
for the fine-tuning step and we
used NVIDIA Tesla V100 GPU's.

121
00:08:44.080 --> 00:08:46.880 
And what we did
here is that we

122
00:08:47.960 --> 00:08:53.120 
tried out different clock settings
of the GPU. So, by setting

123
00:08:53.120 --> 00:08:57.020 
a lower GPU speed,
of course, the

124
00:08:58.510 --> 00:09:01.280 
time to complete the
task increases

125
00:09:02.370 --> 00:09:05.790 
but it's not a linear

126
00:09:06.880 --> 00:09:09.910 
increase but a rather

127
00:09:10.950 --> 00:09:14.430 
more interesting curve, especially
when you're comparing it

128
00:09:14.990 --> 00:09:19.530 
with the overall energy required
to complete this task. And

129
00:09:19.530 --> 00:09:21.100 
as you can see
there is this

130
00:09:22.020 --> 00:09:28.940 
local minimum which indicates that if
you're choosing lower clock speeds

131
00:09:29.330 --> 00:09:30.900 
you can find the
sweet spot

132
00:09:31.840 --> 00:09:35.900 
where you're losing not
much performance but

133
00:09:36.530 --> 00:09:39.120 
you can also save a lot of
energy at the same time.

134
00:09:39.860 --> 00:09:41.050 
So, this initial

135
00:09:42.690 --> 00:09:46.500 
exploration motivated us to dig
a little bit deeper here.

136
00:09:47.060 --> 00:09:49.910 
So, we tested out this

137
00:09:50.600 --> 00:09:53.790 
hypothesis with
additional workloads.

138
00:09:55.790 --> 00:10:01.140 
So, again here we have in the chart
this "bert" machine learning

139
00:10:01.380 --> 00:10:05.030 
workload but we also
included others, so a

140
00:10:05.490 --> 00:10:10.820 
well known image classification
network such as "mnist"

141
00:10:11.050 --> 00:10:13.590 
and different implementations
and also "resnet".

142
00:10:14.090 --> 00:10:16.190 
But we didn't
just want to

143
00:10:17.240 --> 00:10:21.070 
entirely focus on machine learning
workloads but we also wanted

144
00:10:21.280 --> 00:10:24.270 
to check if our observation
also applies for

145
00:10:24.680 --> 00:10:29.190 
more traditional scientific computing
workloads such as an n-body simulation.

146
00:10:30.490 --> 00:10:37.470 
So, we performed the same experiment for
these workloads and as you can see

147
00:10:39.050 --> 00:10:42.540 
there are some workloads
such as "mnist"

148
00:10:42.990 --> 00:10:48.580 
"mnist-dense" or "resnet", where the
performance loss is just very minor. So,

149
00:10:49.100 --> 00:10:49.700 
let me also

150
00:10:51.120 --> 00:10:55.540 
provide you with these data of this chart
in tabular form, so that it can be

151
00:10:55.900 --> 00:10:58.700 
parsed more easily.
So, as you can see

152
00:10:59.980 --> 00:11:05.450 
in those both cases, you don't even
have to sacrifice 10% of performance

153
00:11:05.710 --> 00:11:07.870 
or even less in
order to get

154
00:11:08.530 --> 00:11:13.410 
quite notable improvements in terms of
energy efficiency of this workload.

155
00:11:14.500 --> 00:11:17.610 
So, this I think is a very
important takeaway,

156
00:11:19.070 --> 00:11:23.430 
if you consider that not all
computational tasks are bound

157
00:11:23.430 --> 00:11:27.260 
by a super strict deadlines and
if you're willing to sacrifice

158
00:11:27.260 --> 00:11:31.670 
a little bit of execution time
in order to get massive

159
00:11:32.770 --> 00:11:37.090 
efficiency improvements, for example,
sacrificing on 19% of performance

160
00:11:37.470 --> 00:11:41.860 
for 42% of additional
efficiency, that is

161
00:11:43.200 --> 00:11:47.300 
very notable. And we would like to
encourage as many people out there

162
00:11:47.940 --> 00:11:49.780 
to think if they
really have to

163
00:11:50.670 --> 00:11:53.770 
run the fastest or if they
would rather want to

164
00:11:54.960 --> 00:11:56.790 
run their tasks the
most efficient.

165
00:11:59.130 --> 00:12:02.510 
That already brings me to the
conclusion of this talk. So,

166
00:12:03.810 --> 00:12:05.960 
why all these
approaches

167
00:12:07.000 --> 00:12:10.690 
are investigated by our
group is the result of

168
00:12:11.650 --> 00:12:15.480 
the fact that GPU based
virtualization techniques are still

169
00:12:15.480 --> 00:12:20.010 
not as capable as CPU based
virtualization. So, on the CPU side

170
00:12:21.290 --> 00:12:24.430 
if you have a workload that
doesn't fully utilize your cpu

171
00:12:24.450 --> 00:12:27.860 
that's not a problem because
you're just sharing your CPU

172
00:12:28.740 --> 00:12:33.230 
across multiple virtual
machines and by that

173
00:12:34.110 --> 00:12:38.190 
you can improve the efficiency and
utilization of your hardware drastically.

174
00:12:38.500 --> 00:12:42.930 
But since GPU based virtualization
is still not at this point

175
00:12:42.930 --> 00:12:46.700 
where CPU based virtualization is
today, this is not applicable.

176
00:12:47.490 --> 00:12:50.190 
Therefore we have to find
these workarounds, which is:

177
00:12:51.640 --> 00:12:55.790 
first, you should check your
workload, don't just look at

178
00:12:57.350 --> 00:12:59.980 
the very simple
indicators that

179
00:13:00.450 --> 00:13:04.350 
may look like if your GPU is fully
utilized but if you're looking

180
00:13:04.350 --> 00:13:08.900 
at additional performance counters of
your hardware, you can quickly see that

181
00:13:09.260 --> 00:13:14.290 
many workloads are leaving resources
idle. And if you see that your

182
00:13:15.010 --> 00:13:18.160 
workload is one of
these workloads then

183
00:13:18.630 --> 00:13:22.700 
and of course, you don't
have the time or budget or

184
00:13:23.290 --> 00:13:27.140 
not the availability of source
code to actually optimize the

185
00:13:27.140 --> 00:13:29.170 
implementations and make
it more efficient

186
00:13:29.580 --> 00:13:34.090 
then please consider one of the
approaches of either lowering

187
00:13:34.090 --> 00:13:35.870 
the power state of
your hardware to

188
00:13:37.130 --> 00:13:38.750 
make the execution
more efficient.

189
00:13:39.910 --> 00:13:45.390 
The other was approach-2 and the first
approaches to consider porting,

190
00:13:46.160 --> 00:13:48.130 
consider porting
your workload

191
00:13:48.810 --> 00:13:52.360 
to more balanced hardware
that is much more efficient

192
00:13:53.720 --> 00:13:58.410 
or that may be much more efficient than the
highest performance hardware available.

193
00:13:59.790 --> 00:14:05.120 
And this might seem like a very
trivial observation but since

194
00:14:05.130 --> 00:14:07.350 
all this computer hardware
costs quite a lot

195
00:14:09.420 --> 00:14:14.880 
it's not uncommon in certain domains
to keep your hardware running for a

196
00:14:15.590 --> 00:14:16.970 
for as long as possible

197
00:14:17.760 --> 00:14:21.170 
but if you run in a situation
where you operate your

198
00:14:22.120 --> 00:14:25.890 
hardware that was once very expensive
for an overextended period of time,

199
00:14:26.410 --> 00:14:29.320 
you're running into the situation
that this hardware actually

200
00:14:29.320 --> 00:14:33.510 
consumes so much energy that it
might be so much more efficient to

201
00:14:33.820 --> 00:14:37.430 
switch to more recent
hardware that is offering

202
00:14:37.990 --> 00:14:41.670 
either the same or perhaps even much
much higher performance levels

203
00:14:42.330 --> 00:14:45.680 
at much lower energy
consumption rates. So,

204
00:14:46.260 --> 00:14:49.930 
these are my points that I want you to
take away from this presentation and

205
00:14:50.470 --> 00:14:51.510 
Thanks for watching.
