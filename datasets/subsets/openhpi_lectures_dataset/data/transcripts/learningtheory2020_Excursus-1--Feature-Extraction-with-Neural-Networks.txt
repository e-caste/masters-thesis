WEBVTT

1
00:00:00.910 --> 00:00:05.330 
Hello, today's excursion will be
about the feature extraction.

2
00:00:05.950 --> 00:00:11.150 
So the long journey from a pile of images
into a set of well learnable features.

3
00:00:12.050 --> 00:00:14.930 
For this we're going to
use a neural network

4
00:00:15.710 --> 00:00:20.440 
and neural network is a collection
of so called Ã rtificial neurons.

5
00:00:22.380 --> 00:00:26.070 
Those have a well defined architecture
and architecture describes

6
00:00:26.270 --> 00:00:30.990 
how many neurons there are and between
which neurons there are connections.

7
00:00:32.300 --> 00:00:37.420 
On each neuron has inputs and outputs.
It does some internal computation

8
00:00:38.520 --> 00:00:42.210 
and passes the output off the
computation to its output.

9
00:00:43.740 --> 00:00:47.080 
A group of neurons that
serves a similar function

10
00:00:47.570 --> 00:00:54.980 
we call it a block and a couple of
blocks that all share a common

11
00:00:55.410 --> 00:00:59.080 
set of input blocks,
we call a layer.

12
00:01:01.230 --> 00:01:05.120 
A neuron well we have a bunch
of them in our body and most

13
00:01:05.120 --> 00:01:08.240 
of you have probably taken a
biology class in the past.

14
00:01:08.810 --> 00:01:11.290 
So a neuron has
some inputs

15
00:01:12.070 --> 00:01:19.250 
and does some kind of magic
with those inputs and if the

16
00:01:19.880 --> 00:01:23.170 
result of this magic is
always some threshold

17
00:01:23.740 --> 00:01:25.020 
it produces an output.

18
00:01:26.610 --> 00:01:30.480 
For us and for the artificial
neurons we're talking about we

19
00:01:30.480 --> 00:01:33.590 
also have inputs that are
of numerical nature

20
00:01:34.370 --> 00:01:40.140 
and those inputs get modified by
some weights. Those are random

21
00:01:40.840 --> 00:01:46.280 
in the first place and get adjusted to
minimize the error of each neuron.

22
00:01:47.710 --> 00:01:53.150 
Those wait get then those weighted
inputs get then summed up

23
00:01:53.780 --> 00:01:55.880 
and if thos eoutput sum

24
00:01:56.510 --> 00:01:57.940 
is over some threshold

25
00:01:59.350 --> 00:02:00.340 
we do activation.

26
00:02:01.660 --> 00:02:06.580 
So for example this is an
activation of type relay

27
00:02:08.760 --> 00:02:14.370 
the sum of all those weighted inputs
is over some specific threshold

28
00:02:14.990 --> 00:02:19.060 
we just feed it in a linear
manner into our output.

29
00:02:21.320 --> 00:02:26.220 
So we now have neurons defined
and to sum it up a neuron takes

30
00:02:26.220 --> 00:02:30.020 
weighted values and computes an
aggregation of those values

31
00:02:30.430 --> 00:02:32.430 
dependent on its
own weight.

32
00:02:35.540 --> 00:02:38.370 
Now I'm going to talk about
convolutional neural networks.

33
00:02:38.470 --> 00:02:41.760 
Those are a specific subtype
of neural networks

34
00:02:42.430 --> 00:02:48.590 
and they share some common architecture
types. So we have an input

35
00:02:49.010 --> 00:02:50.290 
for example an image

36
00:02:51.140 --> 00:02:55.950 
and then we do convolutions.
So a convolution takes one

37
00:02:57.570 --> 00:03:01.320 
small chunk of the image.
So for example nine

38
00:03:01.780 --> 00:03:03.640 
pixels in the
neighborhood

39
00:03:04.550 --> 00:03:09.260 
and then does some computation
on it and because

40
00:03:10.230 --> 00:03:16.560 
we can do it, we do multiple of
those convolutions in parallel. So

41
00:03:17.300 --> 00:03:18.390 
in the end we have

42
00:03:19.600 --> 00:03:21.820 
in this image for
example four

43
00:03:22.800 --> 00:03:26.610 
sets of convolution that are being
applied to the same image.

44
00:03:27.010 --> 00:03:31.150 
We then do a subsampling step
on then more convolutions and

45
00:03:31.320 --> 00:03:34.330 
again sub-sampling and then
more convolutions and

46
00:03:34.980 --> 00:03:38.770 
in the end we have a fully
connected layer through a bunch

47
00:03:38.770 --> 00:03:42.950 
of neurons that all can talk to
each other or are all connected

48
00:03:42.950 --> 00:03:45.780 
to each other and they kind
of decide. In our case

49
00:03:46.350 --> 00:03:48.220 
do we see a
butterfly or not.

50
00:03:49.680 --> 00:03:51.660 
So let's have a closer
look at the convolution.

51
00:03:53.450 --> 00:03:58.100 
So for 2D images we normally
do a 2D convolution,

52
00:03:58.890 --> 00:04:03.710 
that is we look at for example a
neighbourhood of nine pixels here and just

53
00:04:04.230 --> 00:04:07.760 
sum them all up and then we
slide one step to the right

54
00:04:07.770 --> 00:04:11.140 
take the next nine pixels
and sum them all up.

55
00:04:12.840 --> 00:04:17.240 
The other possible type of block
we are being confronted in

56
00:04:17.880 --> 00:04:20.250 
the convolution
neural network

57
00:04:20.900 --> 00:04:24.620 
is a pooling layer.
So pooling

58
00:04:25.130 --> 00:04:28.690 
for example the max pooling
looks like for example

59
00:04:29.140 --> 00:04:33.520 
two by two blocks and
then says ok two by two

60
00:04:34.080 --> 00:04:37.430 
pixel chunks and says ok I
just take the highest value.

61
00:04:38.010 --> 00:04:39.650 
So while the
convolution

62
00:04:41.060 --> 00:04:46.180 
makes the value in our output
higher the max pooling

63
00:04:46.970 --> 00:04:52.520 
reduces them and does not sum
them all up but decides for

64
00:04:52.870 --> 00:04:55.280 
some most
important value.

65
00:04:57.030 --> 00:05:02.040 
So both the 2D convolution
and max pooling

66
00:05:02.040 --> 00:05:06.870 
block are working on segments of the
input array and aggregate nearby points

67
00:05:07.300 --> 00:05:07.940 
all together.

68
00:05:10.380 --> 00:05:14.460 
Now we have all that is needed for building
our own student architecture with python.

69
00:05:15.370 --> 00:05:17.260 
In this example
we use carets.

70
00:05:17.880 --> 00:05:21.820 
It is a high level python library
for building neural networks.

71
00:05:22.520 --> 00:05:26.080 
And we start with instantiating
a sequential network.

72
00:05:26.850 --> 00:05:28.830 
And then we add a
convolution layer.

73
00:05:29.800 --> 00:05:34.710 
So the parameters sixteen mean we want
to have in the end sixteen copies

74
00:05:35.260 --> 00:05:40.240 
of the image, the three by three
is the size of all convolutions,

75
00:05:41.270 --> 00:05:44.520 
the padding same means when
we have a convolution that

76
00:05:45.040 --> 00:05:48.980 
looks at the bottom of the
image so a couple of the

77
00:05:49.500 --> 00:05:53.800 
pixels it's looking at are
not really on the image,

78
00:05:54.540 --> 00:05:58.140 
it just fills them up with the
original values from the image

79
00:05:58.800 --> 00:06:01.390 
and the activation relu
is the rectangular

80
00:06:02.320 --> 00:06:04.500 
activation function
I talk to

81
00:06:05.310 --> 00:06:08.980 
in the beginning plus the input
shaped one hundred twenty eight

82
00:06:08.990 --> 00:06:12.860 
by one hundred twenty eight by three
means we have one hundred eight

83
00:06:14.380 --> 00:06:19.660 
by one hundred twenty eight pixels
and three colour channels rgb.

84
00:06:21.260 --> 00:06:25.420 
We then add a max pooling
2D line with a two by two

85
00:06:26.870 --> 00:06:31.870 
pooling size and then do the same
step again, this time with

86
00:06:32.340 --> 00:06:34.890 
thirty two convolutions

87
00:06:36.370 --> 00:06:42.120 
and max pooling again on one more time
the convolution with sixty four

88
00:06:42.230 --> 00:06:44.940 
convolutions and
max pooling again

89
00:06:45.590 --> 00:06:48.010 
and one more convolution
one hundred twenty eight

90
00:06:48.710 --> 00:06:51.830 
and max pooling. And in the end
we add the flattening and

91
00:06:51.830 --> 00:06:52.510 
the dense layer.

92
00:06:57.380 --> 00:07:01.220 
This can we now train
with our image set. So

93
00:07:02.020 --> 00:07:05.930 
we have a bunch of pictures
that either show a butterfly

94
00:07:05.940 --> 00:07:08.840 
or not and then we
feed them into this

95
00:07:09.460 --> 00:07:12.650 
neural network in different
training settings.

96
00:07:14.120 --> 00:07:20.200 
So I talked in the beginning about
the weights being adjusted

97
00:07:20.510 --> 00:07:25.550 
to minimize the error and we
can we can do this after each

98
00:07:26.270 --> 00:07:28.820 
individual sample being
processed by the network.

99
00:07:29.320 --> 00:07:33.910 
This is then called online learning and
with batch sizes of one or we can

100
00:07:35.360 --> 00:07:40.990 
or we can feed multiple values
through this network before

101
00:07:41.500 --> 00:07:44.440 
actually minimizing the error
and adjusting the weights.

102
00:07:45.100 --> 00:07:46.700 
This is done called
mini batch.

103
00:07:47.650 --> 00:07:52.140 
For instance we tested here batch sizes of
sixty four and one hundred twenty eight.

104
00:07:52.570 --> 00:07:57.850 
Or we can also do a full batch testing.
That means we feed all the values

105
00:07:58.420 --> 00:08:01.220 
in each epoch through
the whole network

106
00:08:01.750 --> 00:08:02.820 
and then adjust
the weights.

107
00:08:04.070 --> 00:08:07.010 
And if we look at the values
here we can see that this

108
00:08:07.810 --> 00:08:11.750 
CNN architecture we tested
performs best with many batches

109
00:08:11.750 --> 00:08:17.080 
so we decided for the rest of this
feature extraction for the rest of

110
00:08:17.990 --> 00:08:20.780 
this excursion whenever I talk
about our train network

111
00:08:21.960 --> 00:08:23.940 
we took the mini batch
sizes of sixty four.

112
00:08:29.610 --> 00:08:33.940 
So how do we get from this classifier
network into a feature extractor?

113
00:08:35.270 --> 00:08:40.810 
I talked about having multiple
convolutions and multiple copies

114
00:08:40.810 --> 00:08:43.440 
of the same image at
some certain points

115
00:08:44.370 --> 00:08:50.330 
and the idea is quite easy. We just
ignore the flatten and the dense layer

116
00:08:50.980 --> 00:08:56.560 
we cut them off and go
from a max pooling layer

117
00:08:57.320 --> 00:09:02.010 
to an output. So we reconstruct
the original image size and

118
00:09:02.520 --> 00:09:06.900 
overlay the overlaid
by the individual

119
00:09:07.560 --> 00:09:10.860 
max pooling results. And
then we flatten it and

120
00:09:11.370 --> 00:09:13.120 
get a nice long vector

121
00:09:13.730 --> 00:09:15.750 
with hopefully
meaningful

122
00:09:16.830 --> 00:09:19.690 
features that can be used
for further learning.

123
00:09:23.350 --> 00:09:27.530 
If we cut this network off after certain
points for example after the first

124
00:09:28.130 --> 00:09:33.420 
convolutionary 2D layer or we can here
visualize what this network sees.

125
00:09:33.970 --> 00:09:35.830 
So in the end as
at the beginning

126
00:09:36.550 --> 00:09:40.160 
we can quite easily
identify the butterflies

127
00:09:41.240 --> 00:09:44.480 
but the more and more we get
downstream on this network

128
00:09:45.240 --> 00:09:48.820 
to for instance to
the last 2D layer

129
00:09:49.410 --> 00:09:52.370 
the shape of the butterfly is
not easily recognizable and is

130
00:09:52.370 --> 00:09:55.910 
more about abstract patterns.
So we can see that this

131
00:09:56.680 --> 00:10:01.910 
neural network does something
on the images and produces

132
00:10:03.050 --> 00:10:07.860 
new features and hopefully we can
learn those with other learners.

133
00:10:11.110 --> 00:10:12.780 
So let's sum this up.

134
00:10:13.830 --> 00:10:15.430 
We drop the flatten
and dense layer,

135
00:10:16.830 --> 00:10:20.790 
the output from logs max pooling 2D layer
is used for the for the classification,

136
00:10:21.810 --> 00:10:24.860 
we get a vector with eight
thousand one hundred ninety two

137
00:10:24.860 --> 00:10:27.950 
values that can now be
extracted from each image

138
00:10:29.460 --> 00:10:34.890 
and we have we have we do this
extraction on six thousand

139
00:10:34.890 --> 00:10:36.330 
four hundred and sixteen
data points. Now

140
00:10:37.270 --> 00:10:40.630 
we can use that we can then
useful further classification.

141
00:10:42.590 --> 00:10:44.250 
So let's do the
classification task

142
00:10:45.010 --> 00:10:51.090 
and here is a bunch off learning
algorithms we tested. So we have the SGD

143
00:10:52.800 --> 00:10:57.040 
classifier. This is a
support vector machine

144
00:10:57.990 --> 00:10:59.410 
we have the perceptron

145
00:11:00.630 --> 00:11:02.180 
and then we have also

146
00:11:03.050 --> 00:11:06.760 
things like random
decision tree

147
00:11:07.380 --> 00:11:11.850 
that is we try to do
good decisions on

148
00:11:12.530 --> 00:11:15.240 
the basis of individual
features to

149
00:11:15.940 --> 00:11:18.720 
split up the data
set more and more,

150
00:11:19.560 --> 00:11:22.210 
we have things like nearest
centroid classifier,

151
00:11:22.960 --> 00:11:28.080 
that is we position all of the data
points into high dimensional space,

152
00:11:28.730 --> 00:11:30.500 
a thousand dimensions
in this case

153
00:11:31.390 --> 00:11:35.470 
and then try to project the
position of the individual data

154
00:11:35.470 --> 00:11:39.430 
points in the room and maps
them into their classes.

155
00:11:40.390 --> 00:11:46.090 
We have with the sbc one more support
vector machine with a different kernel

156
00:11:47.330 --> 00:11:50.100 
and we have tested
another perceptron

157
00:11:50.870 --> 00:11:52.930 
with limited
iteration depth.

158
00:11:54.430 --> 00:11:58.210 
Let's focus for the evaluation
on the perceptron and the svm.

159
00:12:00.010 --> 00:12:04.180 
So for those we have measured
the accuracy and the loss

160
00:12:04.870 --> 00:12:08.510 
and they both do perform
quite well with accuracies

161
00:12:09.570 --> 00:12:12.220 
after only seeing a
few data points

162
00:12:12.830 --> 00:12:14.860 
of well above
eighty percent.

163
00:12:17.930 --> 00:12:19.150 
To summarize this up.

164
00:12:19.850 --> 00:12:22.960 
CNN architectures are widely
used for classification tasks.

165
00:12:24.010 --> 00:12:27.930 
We built a CNN for classifying images
with butterflies and trained it.

166
00:12:28.900 --> 00:12:32.310 
We dropped the last layer and
extracted features for our image.

167
00:12:33.630 --> 00:12:36.620 
We trained other classifiers
on those extracted features.
