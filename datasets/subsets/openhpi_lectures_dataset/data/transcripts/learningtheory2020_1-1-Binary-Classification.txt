WEBVTT

1
00:00:00.860 --> 00:00:03.690 
Hello and welcome to the MOOC
computational learning theory

2
00:00:03.880 --> 00:00:06.380 
and the first video
binary classification.

3
00:00:07.120 --> 00:00:10.890 
Binary classification is a
dichomotization applied to a practical

4
00:00:10.890 --> 00:00:14.830 
situation. I will show you one in
a minute. So we want to find

5
00:00:14.830 --> 00:00:20.180 
the answer to a question which can
only be yes or no, so one or zero.

6
00:00:21.030 --> 00:00:24.730 
This has many important applications,
for example in medicine,

7
00:00:24.890 --> 00:00:28.840 
in quality control in the industry
or in information retrieval.

8
00:00:30.100 --> 00:00:34.440 
Methods are there are a variety
of methods, for example

9
00:00:34.440 --> 00:00:37.840 
support vector machines and neural
networks, but many many more

10
00:00:38.120 --> 00:00:41.210 
and which one is suitable highly
depends on the problem.

11
00:00:42.500 --> 00:00:46.080 
There are many metrics with which
you can evaluate the performance

12
00:00:46.090 --> 00:00:49.270 
of such a predictor that gives
you the zeroes or ones.

13
00:00:50.150 --> 00:00:54.320 
And yeah often the two groups are not
symmetric, for example in medicine.

14
00:00:55.370 --> 00:00:59.270 
So what is our exampl? Well at
first side it's not as serious

15
00:00:59.270 --> 00:01:02.770 
as the ones you saw in the last
slide. So we want to know if

16
00:01:02.770 --> 00:01:05.090 
we see a big picture is
there a butterfly.

17
00:01:05.610 --> 00:01:08.400 
I think you all agree that there
is a butterfly on this one,

18
00:01:08.400 --> 00:01:09.680 
so the answer is one.

19
00:01:10.300 --> 00:01:15.020 
There is also a lot of them but only one
that is already hatched on this one,

20
00:01:15.370 --> 00:01:19.230 
there is no butterfly on that one,
there are many on this one,

21
00:01:19.420 --> 00:01:23.720 
and none on that one and so on.
So you get a bunch of images

22
00:01:23.920 --> 00:01:27.750 
and you know the answers for
these images. And what we want

23
00:01:27.750 --> 00:01:31.860 
is we want a predictor so we want
something that for an unknown image

24
00:01:32.070 --> 00:01:35.520 
tells us whether there is a
butterfly on it or not.

25
00:01:37.160 --> 00:01:40.840 
Ok so how is this done in practice?
Well in practice you get

26
00:01:40.840 --> 00:01:45.090 
a lot of labelled observations that
usually are labelled by humans.

27
00:01:45.840 --> 00:01:50.270 
Well nowadays not always. And then
you split it up into a training set

28
00:01:50.530 --> 00:01:51.510 
and a test set.

29
00:01:54.880 --> 00:01:57.710 
Eighty per cent and twenty per
cent is usually a good rate.

30
00:01:59.230 --> 00:02:02.800 
What I don't want to go into
detail with but often you

31
00:02:02.800 --> 00:02:06.110 
don't look at the pictures themselves
but at some kind of feature

32
00:02:06.110 --> 00:02:09.880 
vector which extracts certain important,
hopefully important, properties.

33
00:02:11.360 --> 00:02:14.410 
In the next step, this is the
real learning step, the machine

34
00:02:14.410 --> 00:02:17.220 
learner whichyou have to choose an
advance, we talked about the

35
00:02:17.220 --> 00:02:21.700 
many options on the last slide,
gets the training sequences

36
00:02:21.710 --> 00:02:24.970 
also like the eighty percent
or some part of it, as

37
00:02:24.970 --> 00:02:28.230 
much as it needs. And then it
infers a prediction model.

38
00:02:29.330 --> 00:02:33.650 
And this prediction model gives for
every picture you can imagine

39
00:02:33.650 --> 00:02:35.500 
an answer zero or one.

40
00:02:36.360 --> 00:02:40.870 
And what you do is you already have the
test set that has been labelled too

41
00:02:41.050 --> 00:02:46.020 
and with the test set you can evaluate
the other quality of your predictor.

42
00:02:47.690 --> 00:02:52.060 
Ok so we did that for an
SVM and a perceptron.

43
00:02:53.470 --> 00:02:59.150 
And on the left side you can see the
accuracy that is the quality measure

44
00:02:59.320 --> 00:03:03.340 
of the predictors. And what we did
is we fed the machine learner

45
00:03:03.560 --> 00:03:08.290 
more and more examples. So we have
more than four thousand but

46
00:03:08.290 --> 00:03:13.680 
as you can see there was already quite a
good accuracy, above eighty percent,

47
00:03:13.800 --> 00:03:17.250 
when we showed them seventy
pictures. So we started showing

48
00:03:17.250 --> 00:03:21.590 
ten pictures, then we computed a
predictor, we evaluated it, then

49
00:03:21.590 --> 00:03:25.370 
we showed them twenty pictures, we
computed predictor and evaluated it

50
00:03:25.530 --> 00:03:29.930 
and so on and so on. And on the left
side you can see the zero one loss.

51
00:03:30.710 --> 00:03:34.470 
We will go into more detail about
this application of machine

52
00:03:34.470 --> 00:03:38.030 
learning in an excursion as this
is not the topic off the book

53
00:03:38.030 --> 00:03:43.110 
which is computational learning theory,
so a model, a theoretical analysis.

54
00:03:43.950 --> 00:03:47.970 
So I said already that the real
learning process is the

55
00:03:47.970 --> 00:03:52.950 
step where the training set or the training
data is fed to the machine learner

56
00:03:53.100 --> 00:03:54.970 
and it outputs a
prediction model.

57
00:03:55.920 --> 00:04:00.520 
So a question that we will formalize
and will always be important

58
00:04:00.530 --> 00:04:03.890 
through the whole course is
can a machine learner,

59
00:04:04.680 --> 00:04:09.530 
which we have to specify the
domain and range of later,

60
00:04:10.250 --> 00:04:13.530 
learn a well performing
prediction model,

61
00:04:14.580 --> 00:04:16.290 
which we call F,

62
00:04:18.580 --> 00:04:22.660 
from an increasing amount of
training data, which we call tow.

63
00:04:24.410 --> 00:04:28.210 
Ok so where does Tow come from?
How can we formalize this?

64
00:04:28.400 --> 00:04:31.630 
I mean in our example we had
the images that were labelled

65
00:04:31.640 --> 00:04:33.850 
but we want a more
general framework.

66
00:04:34.530 --> 00:04:37.390 
So this will be the content
of the next video

67
00:04:37.810 --> 00:04:39.360 
and thank you
for listening.
