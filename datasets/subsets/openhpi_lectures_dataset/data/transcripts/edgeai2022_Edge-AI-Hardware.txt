WEBVTT

1
00:00:00.920 --> 00:00:02.220 
Hello and welcome.

2
00:00:02.609 --> 00:00:08.099 
This video will offer an overview of edgeAI hardware.

3
00:00:08.099 --> 00:00:09.890 
Since 2012,

4
00:00:09.900 --> 00:00:15.250 
media has been dominating the AI chip and on its GPUs.

5
00:00:15.259 --> 00:00:21.609 
Although they consume a lot of power and are expensive to run, there's no choice.

6
00:00:21.620 --> 00:00:30.219 
About four years ago, Google announced that they had designed the tensor processing unit to speed up the deep learning inference

7
00:00:30.230 --> 00:00:31.410 
in the data center.

8
00:00:32.039 --> 00:00:42.759 
This has triggered a major technology companies at startups competing to launch dedicated AI chips specifically for data

9
00:00:42.759 --> 00:00:44.090 
center and edges.

10
00:00:45.140 --> 00:00:47.530 
According to the report from ABI

11
00:00:47.530 --> 00:00:52.579 
Research, a global technology market consulting company,

12
00:00:52.590 --> 00:01:04.799 
it is estimated that by 2025 the revenue of the edgeAI chip set market will reach $12.2 billion US dollars

13
00:01:04.810 --> 00:01:12.609 
and the revenue of the cloud AI chipset market will reach 11.9 billion US dollars

14
00:01:12.819 --> 00:01:22.560 
and the edgeAI chipset markets probably so you support the cloudAI chipset market which is quite interesting prediction.

15
00:01:23.109 --> 00:01:33.459 
And industries increasingly needs to solve problems related to data privacy, power efficiency, low latency and

16
00:01:33.459 --> 00:01:36.489 
the powerful computing performance on devices.

17
00:01:37.930 --> 00:01:44.530 
EdgeAI will be one of the solution for all of those problems. In the next five years,

18
00:01:44.540 --> 00:01:54.219 
it is expected that AI training and inference will be carried out at various edge devices and even down to the sensor nodes.

19
00:01:55.019 --> 00:02:03.750 
According to the Gartner's forecast by 2020 the number of global IOT devices will exceed 20 billion.

20
00:02:04.319 --> 00:02:13.250 
An important reason for the growth is that the number of the internet of things devices, connections has shown a linear growth

21
00:02:13.259 --> 00:02:19.729 
trend. At the same time, the equipment itself has become more and more intelligent.

22
00:02:20.560 --> 00:02:31.610 
In fact, edgeAI chips are no longer the corner area. Companies including Google, NVIDIA, Huawei launched edgeAI chips in the

23
00:02:31.610 --> 00:02:32.909 
past two years.

24
00:02:32.919 --> 00:02:38.699 
AI chip competition has spared and from cloud to the edge.

25
00:02:39.930 --> 00:02:49.069 
Next we will briefly introduce the current development of edgeAI hardware including the types of hardware to choose from and

26
00:02:49.080 --> 00:02:50.289 
how they support

27
00:02:50.300 --> 00:02:51.900 
edgeAI features.

28
00:02:53.770 --> 00:02:59.840 
NVIDIA is still the main supplier of AI computing hardware. In the field of cloud computing,

29
00:02:59.849 --> 00:03:03.229 
its GPU products dominate the market.

30
00:03:03.240 --> 00:03:12.840 
Similarly, it has also introduced the rarity of AI hardware suitable for edge computing. Among them Jeston Nano and Jason NX

31
00:03:12.840 --> 00:03:15.740 
has been widely used.

32
00:03:15.750 --> 00:03:22.110 
They all launched two types of products board card and develop kit.

33
00:03:22.509 --> 00:03:33.300 
The board card is very suitable for embedded system environment and the developed kit can design an independent edge prototype

34
00:03:33.310 --> 00:03:37.199 
by connecting the mobile power supplier and the camera.

35
00:03:37.210 --> 00:03:47.710 
We can see that the next AI computing power is stronger in these two products which is about 20 times that of nano. At the

36
00:03:47.710 --> 00:03:48.509 
same time,

37
00:03:48.520 --> 00:03:59.150 
the NX also has a better CPU and RAM configuration. NX is equipped with 48 tensor cores while nano is not equipped

38
00:03:59.150 --> 00:04:00.340 
with tensor core.

39
00:04:00.349 --> 00:04:06.580 
Of course the price of NX is also four times higher than nano.

40
00:04:06.590 --> 00:04:16.600 
You may be curious what is the difference between cuda core and the tensor core. Simply speaking tensor core and cuda decor

41
00:04:16.610 --> 00:04:18.399 
are both computing units.

42
00:04:18.410 --> 00:04:28.120 
Cuda core is a general purpose floating point operation unit while tensor core is highly optimized execution unit designed

43
00:04:28.129 --> 00:04:38.970 
to perform tensor and metrics operations. And these operations are the core computation function using deep learning. Compared

44
00:04:38.970 --> 00:04:48.079 
with the ordinary cuda core tensor cores can provide up to 12 times the peak value in the training

45
00:04:48.089 --> 00:04:51.720 
and six times the peak value in the inference higher.

46
00:04:53.810 --> 00:04:58.350 
This table shows the comparison result on various AI task.

47
00:04:59.300 --> 00:05:08.199 
The involved task including image classification, image super resolution, semantic segmentation, object detection, post

48
00:05:08.199 --> 00:05:19.110 
detection and language model BERT which very complicated comparison list. And this task have different input resolutions and

49
00:05:19.110 --> 00:05:24.589 
the input sequence lens for BERT is 128 which is a standard value.

50
00:05:24.980 --> 00:05:34.800 
And the frame pro seconds rates has been measured in the evaluation where the limited latency means that the minimum latency

51
00:05:34.800 --> 00:05:43.220 
throughput results were obtained with the maximum batch size that could not exceed 15 millisecond latency.

52
00:05:43.980 --> 00:05:46.709 
So the 50 millisecond for BERT.

53
00:05:46.930 --> 00:05:50.939 
Otherwise a batch size of one was used.

54
00:05:51.560 --> 00:06:00.709 
The maximum throughput results were obtained without the latency limitation and illustrates the maximum performance that can

55
00:06:00.709 --> 00:06:01.740 
be achieved.

56
00:06:01.750 --> 00:06:08.079 
We can see that Jeston index has a way better computation capacity than nano.

57
00:06:08.089 --> 00:06:18.019 
It has from 9.7 times to 23 times better FPS result compared to nano across various tasks.

58
00:06:18.420 --> 00:06:23.879 
However, it is much worse than the latest

59
00:06:23.879 --> 00:06:26.680 
GPU A100.

60
00:06:26.689 --> 00:06:35.000 
So for example A100 is 53 times faster than the NX on the BERT based inference task.

61
00:06:37.779 --> 00:06:42.879 
Raspberry Pi is a microcomputer that we are already familiar with.

62
00:06:42.889 --> 00:06:49.990 
Inter also launched a neural compute stick suitable for edge computing where NCS2

63
00:06:50.050 --> 00:06:59.829 
is the current version which is actually a USB memory stick and needs to be used with an external host.

64
00:06:59.839 --> 00:07:07.949 
NCS has very good flexibility and supports most mainstream deep learning frameworks and operating systems.

65
00:07:08.660 --> 00:07:17.050 
It uses the open vino engine to support a common API for CPU, GPU, VPU and FPGA.

66
00:07:17.870 --> 00:07:27.009 
This advantage is that it requires an external host system and computing power is limited, very limited.

67
00:07:27.019 --> 00:07:32.620 
It allows upgrading AI to existing system very simply and quickly.

68
00:07:32.629 --> 00:07:40.069 
It is also useful for a hobby approach, demo approach and small batch projects.

69
00:07:42.410 --> 00:07:54.040 
Coral offers google's edgeAI TPU hardware and it has launched a varity of products including computing sticks similar to the

70
00:07:54.040 --> 00:07:54.970 
Inter NCS

71
00:07:54.970 --> 00:08:01.170 
and the deep dev board similar to NVIDIA nano. For AI computation,

72
00:08:01.180 --> 00:08:04.579 
it has a capacity of four TOPS.

73
00:08:05.350 --> 00:08:16.240 
Coral only supports Ubuntu OS and AI framework only supports tensorflow lite which is a variant that supports a limited

74
00:08:16.240 --> 00:08:18.310 
number of neural network layers.

75
00:08:19.430 --> 00:08:27.850 
It does not even support the complete tensorflow lite but only supports the model quantized to 8 bit 2 integers.

76
00:08:27.860 --> 00:08:40.100 
And in contrast NCS two supports FP 16 so the 16 bit floating points in addition to int8. So far it supports pretrained

77
00:08:40.100 --> 00:08:43.759 
model for four computer vision task and speech recognition

78
00:08:43.769 --> 00:08:50.110 
where intel and Nvidia do better, they provide much more pretrained models.

79
00:08:50.120 --> 00:09:01.149 
Coral providers complete system such as wifi and encryption engine making it ideal for consumer electronics, such as home

80
00:09:01.149 --> 00:09:06.309 
electronics, IOT devices. For the consumer electronics industry,

81
00:09:06.470 --> 00:09:08.360 
they have great significance.

82
00:09:10.080 --> 00:09:15.820 
This is the result of a performance comparison officially provided by NVIDIA.

83
00:09:15.830 --> 00:09:25.879 
We see that the performance of using raspberry pi along in the lowest and the speed is too slow that it can hardly be used

84
00:09:25.879 --> 00:09:31.169 
in the practical applications. After using the inter NCS

85
00:09:31.179 --> 00:09:33.759 
the result has been largely improved.

86
00:09:33.769 --> 00:09:44.269 
For example, the mobile Net V2 for image classification has achieved real time performance with 30 FPS but NCS does

87
00:09:44.269 --> 00:09:55.730 
not perform particularly while on other tasks except the classification. Jetson nano achieves is above 10 FPS on most

88
00:09:55.730 --> 00:09:57.070 
of the visual tasks

89
00:09:57.080 --> 00:10:07.590 
in the table. Its resolution of input image continues to increase performance may drop significantly and the results of the

90
00:10:07.590 --> 00:10:19.139 
coral TPU dev board is strongest reaching 130 FPS on the MobileNet V2 and which is twice that of nano.

91
00:10:19.149 --> 00:10:23.289 
It is also the fastest SSD object detection.

92
00:10:23.600 --> 00:10:27.320 
However, too few types of models are supported.

93
00:10:27.330 --> 00:10:33.730 
So a more comprehensive comparison results cannot be obtained in the current stage.

94
00:10:36.370 --> 00:10:46.259 
Another possible edge AI hardware accelerator is Huawei is Atlas. The Atlas 200 AI acceleration module, integrates ascend

95
00:10:46.269 --> 00:10:54.750 
310 AI processor which can be applied in edge device such as smart cameras, robots or the drones.

96
00:10:55.299 --> 00:11:03.950 
This AI module is also available as a stand alone development kit and has also been integrated into Atlas 500

97
00:11:03.950 --> 00:11:11.299 
Smart station. Atlas 500 is highly adaptable and supports cloud edge synergy.

98
00:11:12.340 --> 00:11:21.740 
It can be widely deployed in the edge environment to meet the application needs of complex environments such as smart

99
00:11:21.740 --> 00:11:23.429 
city or smart campus.

100
00:11:25.360 --> 00:11:34.970 
The AI computing capacity of this accelerator is somehow at the same level as NVIDIA Jetson NX. For instance, the peak

101
00:11:34.980 --> 00:11:39.990 
performance is 22 TOPS using INT8.

102
00:11:40.000 --> 00:11:55.850 
It uses ascend 310 neural computing chips is 2 Davinci max AI course integrated with 8 ARM A55 CPU cores. I think having

103
00:11:55.850 --> 00:12:00.870 
more choices in the market is always a good news for the customers.

104
00:12:00.870 --> 00:12:04.179 
For the end users.

105
00:12:04.179 --> 00:12:05.100 


106
00:12:05.110 --> 00:12:12.580 
Xilinx FPGA is also interesting hardware platform for edgeAI especially for embedded systems.

107
00:12:16.269 --> 00:12:27.570 
Xilinx also provided its edgeAI solution kits. It's called edgeboards and corresponding software development framework

108
00:12:27.580 --> 00:12:40.049 
and which can also directly parse the model graph and trained weights that are saved out of popular deep learning frameworks

109
00:12:40.049 --> 00:12:42.950 
including Caffe, pytorch and tensorflow.

110
00:12:43.590 --> 00:12:54.809 
So which has already ready to use functions like pruning, quantization, compiler runtime and efficient programmable IP

111
00:12:54.820 --> 00:12:55.169 


112
00:12:55.169 --> 00:12:55.549 


113
00:12:55.549 --> 00:13:05.289 
which allows the deploying neural network on the varity of platforms on edge or in popular cloud and several

114
00:13:05.299 --> 00:13:07.740 
server architectures.

115
00:13:08.279 --> 00:13:12.320 
So which is provided several productivity advantages.

116
00:13:12.379 --> 00:13:23.649 
For example platform reuses, it can swap different acceleration applications with the same platform and porting application

117
00:13:23.649 --> 00:13:32.830 
across different platforms is also possible and open source runtime can take care of the host device, communications through

118
00:13:32.830 --> 00:13:34.309 
PCIe

119
00:13:34.320 --> 00:13:35.669 
Or embedded.

120
00:13:36.019 --> 00:13:44.950 
It offers a lot of box acceleration functions with minimum to zero code change to the existing AI applications.

121
00:13:44.960 --> 00:13:52.149 
I believe the customized AI chips will become the main computing resources in the future AI applications.

122
00:13:52.159 --> 00:14:01.840 
In fact, in addition to this traditional mainstream chief manufacturers, many startups also focus on developing AI chips

123
00:14:01.850 --> 00:14:08.389 
in edge computing fields such as IOT Market. An important feature

124
00:14:08.389 --> 00:14:13.909 
development trend is the cold design of AI algorithms and hardwares.

125
00:14:15.269 --> 00:14:17.450 
Thank you very much for watching the video
