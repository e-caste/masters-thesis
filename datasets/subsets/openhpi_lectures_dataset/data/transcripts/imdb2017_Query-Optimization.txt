WEBVTT

1
00:00:04.400 --> 00:00:06.600 
This is a nice quote from
Thomas Neumann, who is

2
00:00:06.600 --> 00:00:10.100 
a professor at TU Munich

3
00:00:10.100 --> 00:00:15.150 
and he basically says that you
can optimize as much on the

4
00:00:15.150 --> 00:00:18.180 
storage engine, on the execution
engine as you want - usually you

5
00:00:18.180 --> 00:00:21.210 
get like maybe 60%
percent as Intel has shown

6
00:00:21.210 --> 00:00:25.250 
improvements there but
optimizing the query

7
00:00:25.250 --> 00:00:29.290 
optimizer often gives us
performance improvements

8
00:00:29.290 --> 00:00:31.310 
by a factor of ten or
even more as we see later.

9
00:00:32.320 --> 00:00:35.350 
This basically says once
you have your optimized

10
00:00:35.350 --> 00:00:39.390 
storage engine or your execution
engine, it's often worth looking

11
00:00:39.390 --> 00:00:43.430 
into the query optimizer before
you further optimize your next

12
00:00:43.430 --> 00:00:46.460 
SIMD generation, because there
is a really huge potential

13
00:00:47.470 --> 00:00:50.500 
for performance improvements
in the query optimizer.

14
00:00:52.520 --> 00:00:57.570 
I hope you all know that
SQL is declarative so

15
00:00:57.570 --> 00:01:01.610 
you don't tell the database how
this query is executed, which

16
00:01:01.610 --> 00:01:05.650 
operator follows, which
operator follows which

17
00:01:05.650 --> 00:01:08.680 
operator but you just say what
you want to have, what you want

18
00:01:08.680 --> 00:01:12.720 
to receive from the database.
What the query optimizer

19
00:01:12.720 --> 00:01:17.770 
now does is, it takes
this first plan and builds

20
00:01:17.770 --> 00:01:19.790 
logically
equivalent plans,

21
00:01:20.800 --> 00:01:23.830 
many many of these, so often
thousand of hundred of plans

22
00:01:23.830 --> 00:01:26.860 
and then tries to
find the plan with the

23
00:01:26.860 --> 00:01:30.900 
lowest expected costs. What
these costs can be you can see

24
00:01:30.900 --> 00:01:34.940 
here on the bottom.
This might be

25
00:01:34.940 --> 00:01:37.970 
algorithmic costs, for
example the complexity of your

26
00:01:37.970 --> 00:01:40.100 
sort operation, this
might be logical costs

27
00:01:40.100 --> 00:01:43.103 
where you try to estimate the
output size of each operator

28
00:01:44.104 --> 00:01:47.107 
or physical costs, for
example IO bandwidth or

29
00:01:47.107 --> 00:01:51.111 
cache misses.
Interesting part is that

30
00:01:51.111 --> 00:01:55.115 
previously, databases
like DB2 which

31
00:01:55.115 --> 00:01:58.118 
were disk resident, usually
optimized for the physical

32
00:01:58.118 --> 00:02:01.121 
part because you have your
one single large bottleneck

33
00:02:01.121 --> 00:02:02.122 
which was IO
block acesses

34
00:02:03.123 --> 00:02:07.127 
and now with increasingly
more data in memory

35
00:02:08.128 --> 00:02:11.131 
we are moving a little bit, or the
trend goes to the logical costs

36
00:02:11.131 --> 00:02:13.133 
that most databases just
concentrate on logical costs

37
00:02:14.134 --> 00:02:17.137 
that means you want to
minimize your output size

38
00:02:17.137 --> 00:02:20.140 
of each operator which has the
advantage also that you need

39
00:02:20.140 --> 00:02:24.144 
to transfer less memory.
What you usually do is

40
00:02:24.144 --> 00:02:26.146 
you execute all
the filters first

41
00:02:27.147 --> 00:02:31.151 
or you do, well you execute
operations first where you expect

42
00:02:31.151 --> 00:02:35.155 
that the output size will be
minimal and then later you do

43
00:02:35.155 --> 00:02:37.157 
the joins or you do
some sorting and so on.

44
00:02:37.157 --> 00:02:41.161 
We try to rearrange operators in
order to minimize the expected

45
00:02:41.161 --> 00:02:44.164 
output size, the logical costs.
That is basically the main

46
00:02:44.164 --> 00:02:45.165 
concept of query
optimization.

47
00:02:48.168 --> 00:02:52.172 
Query optimization usually
works in two steps,

48
00:02:52.172 --> 00:02:55.175 
they are kind of related,
depends on the system,

49
00:02:55.175 --> 00:02:57.177 
but usually there are
two steps. They are first

50
00:02:57.177 --> 00:03:00.180 
they are semantic query
transformations and simple

51
00:03:00.180 --> 00:03:03.183 
heuristics. Then the second
step is a little bit more

52
00:03:03.183 --> 00:03:07.187 
complex where you have
cost models to estimate

53
00:03:07.187 --> 00:03:10.190 
for example, join costs

54
00:03:10.190 --> 00:03:14.194 
and try to re-order operators.
Let us look at some examples

55
00:03:14.194 --> 00:03:17.197 
for that, the first
part is about query

56
00:03:17.197 --> 00:03:21.201 
reformulation. We try to
exploit semantic query

57
00:03:22.202 --> 00:03:25.205 
transformations, that means
we transform the query

58
00:03:26.206 --> 00:03:29.209 
into a new query which
is logically equivalent

59
00:03:29.209 --> 00:03:32.212 
and hopefully we find
a reformulation that

60
00:03:32.212 --> 00:03:35.215 
is easier to process,
that has lower costs.

61
00:03:35.215 --> 00:03:38.218 
A pretty simple example is,
there in the middle of the

62
00:03:39.219 --> 00:03:42.222 
of the slide we have
a selection on A

63
00:03:42.222 --> 00:03:46.226 
and you select all tuples
that have a value A

64
00:03:46.226 --> 00:03:50.230 
less than ten and bigger than
ten so obviously you can,

65
00:03:50.230 --> 00:03:53.233 
the optimizer could see
here that we don't have to

66
00:03:53.233 --> 00:03:56.236 
access the data at all, we don't
have to scan the data twice in

67
00:03:56.236 --> 00:04:00.240 
the column A. We can just
return an empty result set.

68
00:04:00.240 --> 00:04:04.244 
The example on
the bottom chose

69
00:04:04.244 --> 00:04:07.247 
another simplification
or reformulation

70
00:04:07.247 --> 00:04:10.250 
of a query where we
simplify the selection on A.

71
00:04:10.250 --> 00:04:15.255 
I think it's rather obvious
if we select all the

72
00:04:15.255 --> 00:04:18.258 
tuples where A is smaller than
ten we don't have to check if

73
00:04:18.258 --> 00:04:20.260 
they are smaller than twenty
because that's a given.

74
00:04:23.263 --> 00:04:26.266 
Another standard
optimization

75
00:04:27.267 --> 00:04:30.270 
is the so called predicate push
down that you can see on the

76
00:04:30.270 --> 00:04:33.273 
top there where we push down
our selection on the attribute

77
00:04:33.273 --> 00:04:38.278 
B into our sub query here, but
this is a natural join between

78
00:04:38.278 --> 00:04:41.281 
T1 and T2, we push
down the selection into

79
00:04:41.281 --> 00:04:45.285 
the sub query here
and on the bottom you

80
00:04:45.285 --> 00:04:49.289 
see a simple
reformulation

81
00:04:49.289 --> 00:04:53.293 
or simplification of
an equation. These are

82
00:04:53.293 --> 00:04:56.296 
bread and butter
operations of

83
00:04:56.296 --> 00:04:58.298 
a query
optimizer. This is

84
00:04:58.298 --> 00:05:01.301 
something that every query
optimizer does and needs to do

85
00:05:01.301 --> 00:05:04.304 
in order to optimize
your queries.

86
00:05:05.305 --> 00:05:10.310 
Some heuristics that are
a little bit more tricky

87
00:05:10.310 --> 00:05:14.314 
to do are shown
here on the top.

88
00:05:14.314 --> 00:05:18.318 
We have, for example as
you have said already,

89
00:05:18.318 --> 00:05:22.322 
we have the strategy that we
always execute the filters

90
00:05:22.322 --> 00:05:25.325 
first. We always
execute the filters,

91
00:05:25.325 --> 00:05:29.329 
we order them by restrictiveness,
so we want to execute the

92
00:05:29.329 --> 00:05:32.000 
filters first that we
consider the most restrictive

93
00:05:32.332 --> 00:05:36.336 
afterwards we might
do the joins or other

94
00:05:36.336 --> 00:05:40.340 
operators but usually you always
want to execute the filters

95
00:05:40.340 --> 00:05:44.344 
first. Another example we have
just shown is the predicate

96
00:05:44.344 --> 00:05:47.347 
push down, which usually
always makes sense

97
00:05:48.348 --> 00:05:52.352 
and join re-ordering
which we will talk about

98
00:05:52.352 --> 00:05:54.354 
later in a second. But

99
00:05:55.355 --> 00:05:58.358 
the important thing here
is to recognize that these

100
00:05:58.358 --> 00:06:01.361 
are heuristics so they
don't have to be true

101
00:06:01.361 --> 00:06:04.364 
but they are a good starting
point for every optimizer because

102
00:06:04.364 --> 00:06:08.368 
usually they are always true,
usually. You can easily can

103
00:06:08.368 --> 00:06:10.370 
have cases where it's
not true but for the vast

104
00:06:10.370 --> 00:06:15.375 
majority of cases optimizing
using these rules might

105
00:06:15.375 --> 00:06:17.377 
be fine but if you imagine
an example where you,

106
00:06:18.378 --> 00:06:20.380 
maybe we have the world
population table and

107
00:06:20.380 --> 00:06:23.383 
you join this with all the
presidents of the United States.

108
00:06:23.383 --> 00:06:27.387 
This is a highly restrictive
join, right? Maybe you have

109
00:06:27.387 --> 00:06:29.389 
five or ten
living presidents,

110
00:06:29.389 --> 00:06:33.393 
so this join result will be really
small but if you join for all,

111
00:06:33.393 --> 00:06:36.396 
Â if you select then all the male
presidents of United States,

112
00:06:37.000 --> 00:06:39.399 
well this is not the
most effective selection

113
00:06:39.399 --> 00:06:42.402 
so this is a case where a
join might be more useful to

114
00:06:42.402 --> 00:06:46.406 
do before the selection, might be
better to do that before selection.

115
00:06:46.406 --> 00:06:49.409 
But again, usually
you are rather good

116
00:06:49.409 --> 00:06:50.410 
using these heuristics.

117
00:06:54.414 --> 00:06:56.416 
Here we have an
example where we

118
00:06:56.416 --> 00:06:59.419 
again show you the
the logical query plan

119
00:06:59.419 --> 00:07:03.423 
and how we can reformulate the
query plan into a logically

120
00:07:03.423 --> 00:07:07.427 
equivalent plan where we
estimate the costs to be lower.

121
00:07:07.427 --> 00:07:10.430 
What we do here is just
what we have discussed

122
00:07:10.430 --> 00:07:14.434 
before, we do the selections
first so the selections here are

123
00:07:14.434 --> 00:07:17.437 
on state = hessen
and the birth year

124
00:07:17.437 --> 00:07:22.442 
larger than 2010 and
before we join now we do

125
00:07:22.442 --> 00:07:25.445 
both selections on the locations
table and the world population

126
00:07:25.445 --> 00:07:28.448 
table. Join these
both tables afterwards

127
00:07:29.449 --> 00:07:34.454 
and hopefully we have
lower estimated costs.

128
00:07:34.454 --> 00:07:37.457 
We have shown you have
the input sizes here

129
00:07:37.457 --> 00:07:40.460 
as, before optimizing
the query, we are joining

130
00:07:40.460 --> 00:07:44.464 
eight billion tuples with
one hundred tuples from the

131
00:07:45.465 --> 00:07:50.470 
actors table. This is a
huge just a huge join if you

132
00:07:50.470 --> 00:07:53.473 
have seen the join examples
yesterday and the run times,

133
00:07:54.474 --> 00:07:57.477 
this is probably in the minutes or
so, this would probaly be in the

134
00:07:57.477 --> 00:08:00.480 
minutes or hours to
have a join over eight

135
00:08:00.480 --> 00:08:06.486 
billion tuples, un-optimized.
But if we compare the plan

136
00:08:06.486 --> 00:08:09.489 
now to the right side
where we re-order

137
00:08:09.489 --> 00:08:12.492 
the operators, you can see that
we have now a sequential scan

138
00:08:12.492 --> 00:08:14.494 
in the beginning on
eight million tuples.

139
00:08:14.494 --> 00:08:18.498 
We have seen how fast sequential
scans are on dictionary encoded

140
00:08:18.498 --> 00:08:22.502 
columns with SIMD and so on
so this is a comparatively

141
00:08:23.503 --> 00:08:26.506 
simple and
fast operation

142
00:08:26.506 --> 00:08:29.509 
and we can reduce
the input size

143
00:08:29.509 --> 00:08:32.512 
for a much more expensive
operation - the join here.

144
00:08:34.514 --> 00:08:37.517 
The next step that
you usually do is

145
00:08:37.517 --> 00:08:39.519 
you build your physical
query plan, once you have

146
00:08:40.520 --> 00:08:43.523 
your query plan that we consider
as the best plan we have

147
00:08:43.523 --> 00:08:46.526 
found or the best plan
to be there, we translate

148
00:08:46.526 --> 00:08:49.529 
this plan with logical
operators to the

149
00:08:49.529 --> 00:08:51.531 
actual database operators
that our database

150
00:08:52.532 --> 00:08:54.534 
implementation offers us.
That might be different

151
00:08:54.534 --> 00:08:57.537 
joins, for example here we have
a hash join and a sort merge join

152
00:08:57.537 --> 00:09:00.540 
so now we try to find the
best possible way to do

153
00:09:00.540 --> 00:09:04.544 
our join and build a physical
query plan. This plan really

154
00:09:04.544 --> 00:09:06.546 
includes physical
operators.

155
00:09:11.551 --> 00:09:15.555 
What we need to have
in place for all these

156
00:09:15.555 --> 00:09:18.558 
estimations, for all
these cost estimations are

157
00:09:18.558 --> 00:09:21.561 
good statistics. Every
database relies on

158
00:09:21.561 --> 00:09:26.566 
the statistics that we have in
place to, for example, to have

159
00:09:26.566 --> 00:09:29.569 
an estimate on how
expensive is my filter

160
00:09:29.569 --> 00:09:36.576 
on the column first
name. Such statistics

161
00:09:36.576 --> 00:09:39.579 
include, for example the
number of distinct values.

162
00:09:39.579 --> 00:09:42.582 
This is usually a given for our
database, for Hyrise or SAP HANA

163
00:09:42.582 --> 00:09:46.586 
because every column is
dictionary encoded so we have this

164
00:09:46.586 --> 00:09:49.589 
number already. Another
statistic might be the

165
00:09:49.589 --> 00:09:52.592 
presence or
absence of indices,

166
00:09:52.592 --> 00:09:55.595 
often make sense to use
indices, in some cases where

167
00:09:55.595 --> 00:09:58.598 
a filter is really restrictive,
so we want to know if we have

168
00:09:58.598 --> 00:10:01.601 
these indices. It
makes sense to have

169
00:10:01.601 --> 00:10:03.603 
or it is nice to have the
value distribution, we

170
00:10:03.603 --> 00:10:06.606 
come back later to that,
top-n values and so on.

171
00:10:06.606 --> 00:10:09.609 
Which help you to estimate
the costs of an operator

172
00:10:09.609 --> 00:10:13.613 
without executing it first
obviously. What we can

173
00:10:13.613 --> 00:10:17.617 
see here is an
example for the world

174
00:10:17.617 --> 00:10:21.621 
population table, how it could
look implemented so we have the

175
00:10:21.621 --> 00:10:23.623 
data in the table obviously
and then we have this

176
00:10:24.624 --> 00:10:27.627 
metadata. This metadata
includes all the first,

177
00:10:28.628 --> 00:10:32.632 
all the attributes and
type of the attributes

178
00:10:32.632 --> 00:10:35.635 
this is what you need, that is
what you always need obviously for

179
00:10:35.635 --> 00:10:37.637 
your table but then you
have also the index columns

180
00:10:37.637 --> 00:10:38.638 
and the statistics.

181
00:10:41.641 --> 00:10:43.643 
These statistics
include, for example,

182
00:10:43.643 --> 00:10:48.648 
the min and max, here, in this
example it's the birth year so we

183
00:10:48.648 --> 00:10:51.651 
have a minimum of 1900

184
00:10:51.651 --> 00:10:53.653 
and the maximum of 2017.

185
00:10:54.654 --> 00:10:57.657 
It might include distinct counts,
so how many distinct values

186
00:10:57.657 --> 00:11:00.660 
do we have in that
particular column.

187
00:11:00.660 --> 00:11:03.663 
As we have said, usually
that's a given if we

188
00:11:03.663 --> 00:11:06.666 
have dictionary encoding
and then we have for

189
00:11:06.666 --> 00:11:10.670 
example histograms and
they are really important

190
00:11:10.670 --> 00:11:13.673 
for a couple of
operators, for example,

191
00:11:13.673 --> 00:11:15.675 
selections or
join estimations.

192
00:11:15.675 --> 00:11:19.679 
If you imagine that you have
a query, give me all the

193
00:11:19.679 --> 00:11:23.683 
people having the
first name Martin

194
00:11:24.684 --> 00:11:27.687 
and you could basically

195
00:11:27.687 --> 00:11:29.689 
before executing
the query, when you

196
00:11:29.689 --> 00:11:32.692 
want to estimate the cost, you
could look into the histogram

197
00:11:32.692 --> 00:11:35.695 
and you might see that is
rather a uniform distribution

198
00:11:36.696 --> 00:11:38.698 
so there is a distinct
count of 1,000 maybe.

199
00:11:38.698 --> 00:11:42.702 
I would expect my results,
that will be 1,000th of

200
00:11:42.702 --> 00:11:44.704 
the overall table if
I select on Martin

201
00:11:45.705 --> 00:11:47.707 
but if you now select
all the people who are

202
00:11:47.707 --> 00:11:51.711 
from a particular country,
this distribution is

203
00:11:52.712 --> 00:11:54.714 
absolutely not uniform,
so this is highly skewed.

204
00:11:54.714 --> 00:11:57.717 
There is a huge difference if
you have a filter on the country

205
00:11:57.717 --> 00:12:01.721 
Germany which is a
result set of maybe 80

206
00:12:01.721 --> 00:12:04.724 
million I guess and then you
have a selection on the U.S which

207
00:12:04.724 --> 00:12:07.727 
is four times the size and then
you have a selection on China

208
00:12:07.727 --> 00:12:10.730 
which might be pretty much I
think a quarter of the people

209
00:12:10.730 --> 00:12:13.733 
of the general population of the world.
Basically there is a huge skew on

210
00:12:13.733 --> 00:12:16.736 
that and you want to be
able to recognize that skew

211
00:12:17.737 --> 00:12:19.739 
in order to estimate the
cost of your operators.

212
00:12:23.743 --> 00:12:26.746 
This is basically,

213
00:12:26.746 --> 00:12:29.749 
so as soon as you have
these statistics and you

214
00:12:29.749 --> 00:12:32.752 
know how to use them, what you
want to do is join reordering

215
00:12:32.752 --> 00:12:35.755 
because that's
one of the most

216
00:12:35.755 --> 00:12:38.758 
expensive parts of the database
that's joining and the order

217
00:12:38.758 --> 00:12:40.760 
of joins and the order
of how they are executed.

218
00:12:41.761 --> 00:12:44.764 
We can use some
information here again that

219
00:12:44.764 --> 00:12:47.767 
the database provides us,
for example if we know about

220
00:12:47.767 --> 00:12:51.771 
a following key
relationship we can

221
00:12:51.771 --> 00:12:55.775 
use that information to
improve our cost estimation

222
00:12:55.775 --> 00:12:57.777 
for a join between
two tables.

223
00:12:57.777 --> 00:13:00.780 
We can check if we have
previously selected

224
00:13:01.781 --> 00:13:04.784 
on a uniform distribution
or maybe on a top five

225
00:13:05.785 --> 00:13:07.787 
on attribute that is among
the top five attributes.

226
00:13:07.787 --> 00:13:09.789 
We can use this
information

227
00:13:10.790 --> 00:13:14.794 
to better predict how large or
how expensive our join will be.

228
00:13:18.798 --> 00:13:23.803 
Just a simple example, why we
want to do this join re-ordering,

229
00:13:23.803 --> 00:13:25.805 
If you have, if
you join these

230
00:13:25.805 --> 00:13:29.809 
three relations here,
there's a so called

231
00:13:29.809 --> 00:13:34.814 
join-associativity that means
that you can re-order these joins

232
00:13:34.814 --> 00:13:38.818 
in any form that you want,
atleast if it's an inner-join.

233
00:13:38.818 --> 00:13:41.821 
Instead of joining
relation one or two first

234
00:13:41.821 --> 00:13:44.824 
and then joining it with
relation three, you could also

235
00:13:44.824 --> 00:13:49.829 
switch the order and
join two with three

236
00:13:49.829 --> 00:13:53.000 
first for example, because these
joins might be faster to do.

237
00:13:55.835 --> 00:13:58.838 
What have we learned
about query optimization?

238
00:13:58.838 --> 00:14:03.843 
It just becomes increasingly
important, so if you look at OLTP

239
00:14:03.843 --> 00:14:06.846 
systems, all you do
usually there in 90 %

240
00:14:06.846 --> 00:14:10.850 
of the cases is, you have your
access via the primary key,

241
00:14:10.850 --> 00:14:14.854 
you access your primary key index,
because there usually always is one

242
00:14:14.854 --> 00:14:17.857 
and then that's pretty much done.
But now with all the analytical

243
00:14:17.857 --> 00:14:20.860 
systems with mixed
workloads where you execute

244
00:14:20.860 --> 00:14:22.862 
transaction queries and
complex analytical queries,

245
00:14:23.863 --> 00:14:26.866 
the query optimization or the
optimizer becomes increasingly

246
00:14:26.866 --> 00:14:27.867 
important.

247
00:14:29.869 --> 00:14:32.872 
However as we, challenging
tasks that we have

248
00:14:32.872 --> 00:14:35.875 
shown in the last slides, pretty
much all the databases are

249
00:14:35.875 --> 00:14:38.878 
still not very accurate
in estimating the costs

250
00:14:38.878 --> 00:14:43.883 
and it is computationally
really expensive

251
00:14:43.883 --> 00:14:45.885 
operation to optimize
the queries. Usually

252
00:14:46.886 --> 00:14:49.889 
no database will give you the
perfect plan, they just stop at

253
00:14:49.889 --> 00:14:51.891 
some time because the are
just too many alternatives

254
00:14:52.892 --> 00:14:56.896 
and try to give you the best
estimate, the best plan they

255
00:14:56.896 --> 00:14:58.898 
can find in a certain
amount of time.
