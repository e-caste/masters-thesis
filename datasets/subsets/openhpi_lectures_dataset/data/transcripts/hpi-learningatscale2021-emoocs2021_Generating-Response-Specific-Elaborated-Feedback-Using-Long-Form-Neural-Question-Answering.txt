WEBVTT

1
00:00:00.840 --> 00:00:05.830 
greetings. my name is andrew.
only i'm a professor at the university of memphis.

2
00:00:06.450 --> 00:00:10.300 
the paper i'm presenting is
titled generating response specific

3
00:00:10.310 --> 00:00:14.300 
elaborated feedback using
long form neural question answering.

4
00:00:15.660 --> 00:00:18.790 
the key problem this work
addresses is how to help students

5
00:00:18.790 --> 00:00:19.970 
when they make mistakes.

6
00:00:20.770 --> 00:00:23.090 
this kind of help is commonly called feedback.

7
00:00:23.640 --> 00:00:27.250 
it comes in many flavors like
telling the student they're incorrect

8
00:00:27.800 --> 00:00:28.960 
telling them the answer

9
00:00:29.650 --> 00:00:33.180 
or explaining their mistake to
them which is called elaborated feedback

10
00:00:34.060 --> 00:00:38.180 
unfortunately while elaborated
feedback is better.

11
00:00:38.180 --> 00:00:39.430 
it is harder for e-learning to implement.

12
00:00:40.240 --> 00:00:42.950 
because there are many ways
to be wrong elaborated feedback

13
00:00:42.950 --> 00:00:44.690 
must be dynamically generated.

14
00:00:45.510 --> 00:00:49.960 
and this paper we use a question
answering approach where given

15
00:00:49.960 --> 00:00:55.740 
a test item like this a close item and an incorrect
student answer like this.

16
00:00:56.370 --> 00:01:00.030 
we generate an elaborated
feedback as shown in green

17
00:01:00.490 --> 00:01:02.820 
using long form neural question answering

18
00:01:03.850 --> 00:01:07.430 
to do this we construct
a synthetic question shown in yellow

19
00:01:07.990 --> 00:01:10.870 
representing what the student should have asked,

20
00:01:11.740 --> 00:01:15.740 
but didn't the green portion is thus the system's answer
to the synthetic question.

21
00:01:16.490 --> 00:01:19.130 
the remainder of this talk
will describe the approach and an

22
00:01:19.130 --> 00:01:22.500 
ablation style evaluation using expert human judges.

23
00:01:24.010 --> 00:01:27.420 
our jumping-off point is the explain like on five task.

24
00:01:28.650 --> 00:01:30.720 
this is modeled off a form on reddit

25
00:01:31.460 --> 00:01:37.080 
where the rules specify that responses to
questions are explanations not answers

26
00:01:37.490 --> 00:01:39.220 
and accessible to lay people

27
00:01:40.070 --> 00:01:44.570 
that yell i five task is one
type of long form question answering

28
00:01:45.500 --> 00:01:49.350 
because the task is open domain
meaning questions can be on any topic.

29
00:01:50.010 --> 00:01:53.010 
long form systems typically have two models

30
00:01:53.450 --> 00:01:57.070 
a retriever model that gets relevant documents,

31
00:01:57.070 --> 00:02:00.520 
and a reader model that extracts information
from them and creates an answer.

32
00:02:01.240 --> 00:02:05.900 
thus the dataset for the l i five task consists
of questions and answers

33
00:02:06.160 --> 00:02:10.270 
scraped from the reddit forum
along with supporting web documents

34
00:02:10.270 --> 00:02:11.890 
extracted from common krol.

35
00:02:13.010 --> 00:02:18.250 
this is an example for how do jellyfish
function without brains or nervous systems.

36
00:02:18.770 --> 00:02:24.480 
as you can see the answer actually refutes
the presupposition of the question

37
00:02:24.990 --> 00:02:28.790 
that jellyfish actually do have nervous
systems but not brains.

38
00:02:30.870 --> 00:02:34.760 
here's a conceptual diagram of the
retriever reader described

39
00:02:34.760 --> 00:02:38.940 
on the last slide. so how can we tune
this for elaborated feedback?

40
00:02:40.020 --> 00:02:42.310 
our approach is to leave the models alone,

41
00:02:42.850 --> 00:02:45.230 
because we don't have training
data for feedback,

42
00:02:45.970 --> 00:02:50.640 
instead we can intervene on model io
shown by the yellow arrows.

43
00:02:51.470 --> 00:02:55.830 
for question we used a fixed synthetic
question on the relationship

44
00:02:55.840 --> 00:02:59.370 
between the incorrect answer
a and the correct answer b.

45
00:03:00.360 --> 00:03:04.910 
for documents we retrieve from
a course textbook in the normal way

46
00:03:05.080 --> 00:03:09.590 
in this case using elastic search,
but inject documents we think will be useful

47
00:03:09.920 --> 00:03:12.350 
like definitions and the test item they nest.

48
00:03:13.250 --> 00:03:16.620 
we also filter documents missing either a or b

49
00:03:17.040 --> 00:03:20.460 
on the premise that they are
not relevant to questions about

50
00:03:20.460 --> 00:03:22.390 
the relationship between a and b.

51
00:03:23.620 --> 00:03:28.110 
for answer we filter out sentences
that don't contain a or b

52
00:03:28.560 --> 00:03:30.770 
on the premise they are not
relevant to the answer.

53
00:03:32.730 --> 00:03:36.730 
because our approach was
developed by exploring
a small set of test cases.

54
00:03:37.150 --> 00:03:41.190 
we conducted an ablation style
human evaluation study,

55
00:03:41.190 --> 00:03:44.550 
focusing on the four interventions
at the document and answer stages.

56
00:03:45.100 --> 00:03:48.480 
we therefore had sixteen conditions
where each intervention

57
00:03:48.480 --> 00:03:51.420 
was present or not. these were presented

58
00:03:52.100 --> 00:03:55.360 
in a survey with eighty real items to rate,

59
00:03:56.030 --> 00:04:00.670 
each item looking like this, so there were
five items per condition per survey.

60
00:04:01.530 --> 00:04:03.700 
these were cat counterbalance
in a latin square.

61
00:04:04.390 --> 00:04:08.170 
additionally there were twenty
control items that were degraded

62
00:04:08.170 --> 00:04:12.230 
versions of real items, raters
who did not score significantly

63
00:04:12.230 --> 00:04:16.190 
lower on these items were deemed to
have lower liability and excluded.

64
00:04:17.100 --> 00:04:20.530 
as shown in the example there
were two ratings per item,

65
00:04:21.070 --> 00:04:22.970 
each measured on a hundred point slider.

66
00:04:23.580 --> 00:04:27.540 
one was if the explanation
was correct and informative,

67
00:04:28.130 --> 00:04:31.380 
and the other was if the explanation
was grammatical and fluent.

68
00:04:32.470 --> 00:04:35.390 
the participants were thirty
nurses or doctors.

69
00:04:35.850 --> 00:04:38.910 
this was done to ensure they
had high familiarity with a topic

70
00:04:39.420 --> 00:04:41.610 
which was college anatomy and physiology.

71
00:04:42.330 --> 00:04:46.220 
there integrator agreement
was quite high with chrome box alpha

72
00:04:46.340 --> 00:04:47.750 
greater than point eight three.

73
00:04:48.910 --> 00:04:52.910 
we used mixed effects beta
regression to evaluate the interventions.

74
00:04:53.710 --> 00:04:57.310 
for correct and informative
ratings we found that definition

75
00:04:57.310 --> 00:04:59.140 
only was the best condition.

76
00:05:00.620 --> 00:05:05.530 
we also found that both definitions
and test item or clothes item

77
00:05:05.930 --> 00:05:08.530 
significantly improved ratings
when they were included.

78
00:05:09.850 --> 00:05:15.040 
but both filtering documents in
answer sentences decreased rating significantly.

79
00:05:16.550 --> 00:05:19.240 
we saw a similar pattern
for grammatical influence

80
00:05:20.190 --> 00:05:22.850 
again definition only was
the best condition.

81
00:05:23.780 --> 00:05:26.920 
we found that definition
significantly improved ratings,

82
00:05:27.450 --> 00:05:30.460 
but filtering documents
significantly decreased ratings.

83
00:05:31.520 --> 00:05:35.120 
in conclusion we presented
an approach to generating elaborated

84
00:05:35.120 --> 00:05:40.590 
feedback using the role long-form
question answering and human evaluation ablation study.

85
00:05:41.630 --> 00:05:46.060 
the feedback was generally rated
highly as you can see in this diagram the mean,

86
00:05:46.270 --> 00:05:49.040 
medians four point seven five or higher,

87
00:05:50.350 --> 00:05:53.790 
and the approach is general and
only requires indexing a textbook

88
00:05:54.130 --> 00:05:56.400 
with an off the shelf system like elastic search.
