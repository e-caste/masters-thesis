WEBVTT

1
00:00:00.860 --> 00:00:04.600 
Welcome to this video clip in which we discuss the topic of Decision Mining.

2
00:00:06.380 --> 00:00:10.420 
So far we have strongly focused on the control-flow perspective.

3
00:00:10.430 --> 00:00:13.811 
So what does it mean? Well, so far we have mostly looked at the order

4
00:00:15.230 --> 00:00:19.101 
of activities. So in the context of discovery, we have looked at in which order

5
00:00:20.060 --> 00:00:23.690 
are the activities executed to, of course, represent this in a model.

6
00:00:24.020 --> 00:00:28.283 
In the context of conformity checking, we have looked at the order and event log traces

7
00:00:28.670 --> 00:00:32.260 
and checked whether this violates the order of the blueprint model traces.

8
00:00:33.080 --> 00:00:36.740 
So you see there is a strong focus on the order of activities.

9
00:00:38.720 --> 00:00:43.369 
What we would like to motivate here and what we would like to explain is, of course,

10
00:00:43.370 --> 00:00:47.599 
that there are other aspects in the process that are just as relevant as the order of

11
00:00:47.600 --> 00:00:52.369 
activities, and one particularly important example are decisions

12
00:00:52.370 --> 00:00:56.240 
or decisions taking a different moment in the process.

13
00:00:56.600 --> 00:01:00.491 
And to understand how these decisions are taken and

14
00:01:01.190 --> 00:01:06.019 
whether we can relate this to data is something that is very important

15
00:01:06.020 --> 00:01:07.939 
for different types of analysis.

16
00:01:08.060 --> 00:01:09.449 
Let's look at an example.

17
00:01:10.130 --> 00:01:14.629 
So what you see here at the bottom is a slightly modified version of

18
00:01:14.630 --> 00:01:15.979 
our claim process.

19
00:01:16.580 --> 00:01:21.069 
And if we look at the details, we can see that we again received the claim

20
00:01:21.080 --> 00:01:25.069 
and we check for completeness and then there is an XOR split.

21
00:01:25.400 --> 00:01:27.280 
So we make a decision here.

22
00:01:27.290 --> 00:01:31.939 
So either we classify the claim as a high-value claim

23
00:01:31.940 --> 00:01:35.900 
and then we invite a claim review. We follow this path or

24
00:01:36.470 --> 00:01:39.704 
we classify the claim as a regular value claim, and then we simply

25
00:01:41.510 --> 00:01:44.090 
review the claim internally and we make a decision.

26
00:01:44.960 --> 00:01:49.519 
If you now look at this trace here, you see that this trace is

27
00:01:49.520 --> 00:01:53.000 
actually conforming from a control plus control perspective.

28
00:01:53.040 --> 00:01:56.240 
So what does it mean if you look at the model.

29
00:01:56.480 --> 00:02:00.919 
Yes. Or receive claim, check claim completeness, classify

30
00:02:01.060 --> 00:02:05.359 
as regular value claim, review case internally,

31
00:02:05.930 --> 00:02:09.850 
make a decision so you can see that this trace can be perfectly replayed in this

32
00:02:10.460 --> 00:02:14.282 
model. There are no problems. So we could conclude from a conformance checking

33
00:02:14.810 --> 00:02:16.410 
perspective, everything is fine.

34
00:02:17.120 --> 00:02:19.521 
However, what if the claim value of that case was

35
00:02:21.620 --> 00:02:24.139 
actually above 10,000 Euros?

36
00:02:25.380 --> 00:02:30.389 
So you see that we have added a label here which indicates how the decision

37
00:02:30.540 --> 00:02:33.235 
should be taken, and you see that once the claim amount

38
00:02:35.520 --> 00:02:38.264 
is actually above 10,000 Euros, we should or that's what

39
00:02:39.960 --> 00:02:43.249 
the model asked for, should classify the claim as a high-value claim.

40
00:02:43.260 --> 00:02:47.327 
And obviously, that did not happen here. So we could argue from a data perspective,

41
00:02:48.210 --> 00:02:51.983 
from a decision perspective, this is actually not conforming just because the

42
00:02:52.680 --> 00:02:57.199 
order, the control flow is in line with the model, that does not mean that

43
00:02:57.210 --> 00:03:00.444 
the model execution of that process was conforming, you know, once

44
00:03:01.680 --> 00:03:04.309 
we take the data perspective into account.

45
00:03:04.320 --> 00:03:08.069 
And this is something that we would like to understand better.

46
00:03:08.080 --> 00:03:12.539 
So decisions play an important role and to understand decisions and to be able

47
00:03:12.540 --> 00:03:16.770 
to use the decision logic in a different context

48
00:03:16.980 --> 00:03:20.400 
is something that we would like to look at in the context of this clip.

49
00:03:21.840 --> 00:03:23.849 
Okay, decision mining, so what we will do

50
00:03:26.370 --> 00:03:30.180 
is we will look at decision mining as a classification problem.

51
00:03:31.140 --> 00:03:34.849 
So what does it mean? So there are a number of steps we have to go through.

52
00:03:35.220 --> 00:03:38.119 
First, we have to identify the decision points.

53
00:03:38.160 --> 00:03:42.720 
So this is, again, our original process and also in our original process model,

54
00:03:43.020 --> 00:03:46.695 
we have two decisions. So here, right after we check full-time completeness

55
00:03:48.120 --> 00:03:50.490 
and after we decide on claim coverage.

56
00:03:50.790 --> 00:03:52.240 
So these are our decision points.

57
00:03:52.920 --> 00:03:56.030 
Second, we have to identify the resulting classes.

58
00:03:56.040 --> 00:03:57.779 
That is the decision outcomes.

59
00:03:58.030 --> 00:04:02.669 
So what are the decision outcomes? Well, after checking for claim completeness, this

60
00:04:02.760 --> 00:04:05.090 
claim can be obviously incomplete or complete.

61
00:04:05.280 --> 00:04:08.759 
These are two outcomes. And after deciding on the claim coverage, there

62
00:04:09.810 --> 00:04:12.319 
could be an acceptance or rejection.

63
00:04:12.510 --> 00:04:16.389 
So these are the two outcomes after making the decision here.

64
00:04:18.029 --> 00:04:22.529 
Now we can label the traces in the log with these respective classes.

65
00:04:22.710 --> 00:04:25.454 
So you can imagine if we have a trace in our log, we can

66
00:04:27.240 --> 00:04:31.160 
analyze for this particular trace what the outcomes were for this decision.

67
00:04:31.170 --> 00:04:35.670 
So maybe there was a trace where indeed the claim was complete and

68
00:04:36.090 --> 00:04:40.529 
the claim was accepted. So then we can label this trace complete and

69
00:04:40.530 --> 00:04:44.519 
accepted. So we can use the decision outcome simply to label the trace.

70
00:04:44.520 --> 00:04:46.807 
And we can do that for every trace or an event log.

71
00:04:48.870 --> 00:04:53.500 
And then the idea is now we get to the classification problem part.

72
00:04:53.550 --> 00:04:56.833 
We can use the other available attributes to predict these classes.

73
00:04:57.480 --> 00:05:02.120 
So what we would like to do is we would like to understand how were these decisions made?

74
00:05:02.130 --> 00:05:05.266 
So can we predict these decisions based on other data attributes

75
00:05:06.720 --> 00:05:11.279 
that we have available? And this is then something that we can this is a question

76
00:05:11.280 --> 00:05:14.610 
we can answer using the decision-making model.

77
00:05:16.080 --> 00:05:19.853 
If we look into machine learning, we see that there are different methods for

78
00:05:19.890 --> 00:05:22.709 
classification of actually many methods.

79
00:05:23.430 --> 00:05:27.959 
There are some standard methods that you may have heard of decision trees, support

80
00:05:27.960 --> 00:05:30.000 
vector machines, neural networks.

81
00:05:30.190 --> 00:05:32.249 
So there are many different ones available.

82
00:05:33.780 --> 00:05:38.459 
For the purpose of this clip, we will consider a simple approach based

83
00:05:38.460 --> 00:05:42.899 
on decision trees. So there are a couple of advantages associated with decision

84
00:05:42.900 --> 00:05:45.938 
trees. Decision trees are intuitive and easy to explain, which

85
00:05:47.550 --> 00:05:50.539 
is also important once we have once we obtain such a decision

86
00:05:52.230 --> 00:05:56.309 
tree, we can actually explain this to a stakeholder, which in the context of course, of

87
00:05:56.310 --> 00:06:01.230 
business process management and process mining is often important that we can explain

88
00:06:01.560 --> 00:06:03.809 
the outcomes to business stakeholders.

89
00:06:03.810 --> 00:06:07.485 
So that's typically possible with decision trees because they're reasonably

90
00:06:08.610 --> 00:06:12.530 
easy to understand. Second, decision trees do not require a lot of normalization

91
00:06:13.560 --> 00:06:18.089 
or scaling of data. And third, decision trees can also deal with missing values.

92
00:06:18.090 --> 00:06:22.829 
So these are some conceptual arguments why decision trees are actually a good choice

93
00:06:23.220 --> 00:06:27.779 
and also decision trees allow us to nicely illustrate how decision mining

94
00:06:28.080 --> 00:06:32.459 
can work. So let's look at an example to illustrate

95
00:06:32.580 --> 00:06:37.110 
how this works. It's a simple example, but I think it will suffice to

96
00:06:37.350 --> 00:06:39.750 
illustrate the mechanism that we are interested in.

97
00:06:39.990 --> 00:06:42.440 
So what you see here is an overview of a number of

98
00:06:44.880 --> 00:06:49.170 
cases. We have the claim ID,  we have the client ID and

99
00:06:49.500 --> 00:06:54.029 
we have a theft value that is associated with this particular claim, and we

100
00:06:54.030 --> 00:06:58.499 
have a policy type, either standard or premium, and we have

101
00:06:58.500 --> 00:07:01.499 
our label. So this is the decision that we would like to predict.

102
00:07:01.500 --> 00:07:03.269 
This is the decision we are interested in.

103
00:07:03.510 --> 00:07:05.970 
And here it's accept or reject.

104
00:07:07.180 --> 00:07:08.999 
So how does a decision tree work?

105
00:07:09.420 --> 00:07:13.781 
The mechanism of a decision tree is, of course, that decision tree tries to automatically

106
00:07:13.920 --> 00:07:16.517 
identify the attributes that allow us to predict this

107
00:07:18.420 --> 00:07:21.199 
value. And this works as follows.

108
00:07:21.390 --> 00:07:25.679 
A decision tree would split this data set in a suitable way,

109
00:07:26.160 --> 00:07:30.277 
and it would try to split it in such a way that the resulting groups are as

110
00:07:31.020 --> 00:07:34.990 
homogeneous as possible with respect to the target variable.

111
00:07:35.010 --> 00:07:37.899 
So in this case, with respect to our decision.

112
00:07:37.920 --> 00:07:40.615 
So in an optimal scenario, we would simply like to find

113
00:07:42.480 --> 00:07:44.939 
a variable that allows us to split this in two groups.

114
00:07:45.300 --> 00:07:49.199 
For one, we have just accepts for the other we have just rejects.

115
00:07:49.200 --> 00:07:52.350 
Of course, this is not typically the case in practice.

116
00:07:53.250 --> 00:07:56.582 
Life is not that easy. But let's look at this particular dataset and

117
00:07:57.690 --> 00:08:01.439 
see what we can do by stepwise splitting this dataset.

118
00:08:02.340 --> 00:08:06.407 
So if we look at the policy type first, we see again there are standard and premium

119
00:08:06.480 --> 00:08:09.861 
customers. And if we now split this data set based on this particular

120
00:08:11.100 --> 00:08:12.959 
attribute, we obtain the following.

121
00:08:14.610 --> 00:08:18.870 
So we obtain two subsets. The first actually looks very nice because we see that

122
00:08:19.080 --> 00:08:23.759 
the premium customers always get their claim accepted and

123
00:08:24.690 --> 00:08:28.369 
we can argue whether this is good or bad. But this is something that we have found here.

124
00:08:28.650 --> 00:08:30.839 
So the premium customers always get accepted.

125
00:08:30.870 --> 00:08:33.173 
So here there is no further work required here.

126
00:08:34.830 --> 00:08:39.359 
However, we see that here we have still some mix of acceptance and rejections

127
00:08:39.840 --> 00:08:44.070 
and we need to obviously find another attribute to better understand

128
00:08:44.700 --> 00:08:49.110 
how we can predict this for this particular subset.

129
00:08:50.160 --> 00:08:52.806 
So what we have left here is actually the theft value.

130
00:08:53.100 --> 00:08:57.629 
And if you take a close look, you see that all these cases where the

131
00:08:57.630 --> 00:09:00.178 
theft value is a 1000 Euros or more are rejected and

132
00:09:02.160 --> 00:09:06.749 
the other ones are accepted. So what we would obtain from our

133
00:09:06.840 --> 00:09:11.519 
decision tree analysis here would be that the decision tree

134
00:09:11.850 --> 00:09:14.669 
would tell us okay the policy type of premium we have and accept.

135
00:09:14.950 --> 00:09:18.772 
And if the policy type of standard, then we have to look into the theft value.

136
00:09:19.590 --> 00:09:24.029 
And if the theft value is a 1000 Euros or higher, we obtain a

137
00:09:24.030 --> 00:09:25.990 
reject, if it's lower, we get an accept.

138
00:09:26.822 --> 00:09:29.125 
Again, this is of course a very simple example.

139
00:09:30.600 --> 00:09:33.720 
And in real life things do not turn out so perfectly.

140
00:09:33.930 --> 00:09:38.100 
But this illustrates a bit how we can use the case attributes

141
00:09:39.120 --> 00:09:43.230 
and label cases. So we have labeled our cases with the decision here

142
00:09:43.680 --> 00:09:48.239 
and we can automatically derive how these are to understand how

143
00:09:48.240 --> 00:09:51.033 
these decisions are being taken and can visualize this in

144
00:09:52.830 --> 00:09:54.120 
the context of a decision tree.

145
00:09:55.760 --> 00:10:00.140 
So what can we do with this model, we can do different things with this

146
00:10:00.350 --> 00:10:02.509 
decision logic that we have just discovered.

147
00:10:02.510 --> 00:10:06.620 
In the context of discovery, we can complement our model with decision logic.

148
00:10:06.890 --> 00:10:11.669 
So this is something that we have actually seen before in this introductory example.

149
00:10:11.930 --> 00:10:14.282 
So here now, if we were to discover a model from

150
00:10:16.730 --> 00:10:20.650 
an event log we don't know how the decisions were being taken, maybe we discover

151
00:10:21.590 --> 00:10:24.559 
this fragments of the activities or you can control flow.

152
00:10:24.950 --> 00:10:29.179 
But by also doing decision mining on top, we realize, OK,

153
00:10:29.420 --> 00:10:31.460 
this is how the decisions are being taken.

154
00:10:32.090 --> 00:10:37.129 
And then we can introduce a label here at the decision point, which accurately

155
00:10:37.130 --> 00:10:41.780 
tells us how the decision is being made and in which case we follow which path.

156
00:10:42.590 --> 00:10:45.726 
Again, here we have this ideal scenario where we could perfectly

157
00:10:47.360 --> 00:10:51.623 
categorize all the cases. It's not going to be the case in practice, but the idea could

158
00:10:51.950 --> 00:10:55.100 
be still applied and we could still use decision mining to

159
00:10:56.420 --> 00:10:59.479 
enhance sort of, say, discovered process models.

160
00:11:01.070 --> 00:11:05.469 
In the context of conformance, there are a couple of things we can look into as well.

161
00:11:05.480 --> 00:11:10.309 
So the first thing is, is the discovery logic in line with existing guidelines.

162
00:11:10.430 --> 00:11:14.509 
So if you look at this decision model of this decision tree here,

163
00:11:14.930 --> 00:11:19.669 
we can now check, well, is this actually the way how we want to make decisions?

164
00:11:19.680 --> 00:11:24.229 
So do we actually want to accept all premium customers no matter

165
00:11:24.230 --> 00:11:27.366 
what, or is 1000 Euros is actually the cutoff that we would like

166
00:11:28.700 --> 00:11:33.380 
to see? So these are some explicit things we can reflect on by comparing simply

167
00:11:33.680 --> 00:11:37.100 
decision model that we have discovered with existing guidelines.

168
00:11:37.910 --> 00:11:42.559 
And the third and last aspect is that we can, of course, also

169
00:11:43.700 --> 00:11:46.639 
see whether there are cases where this logic is violated.

170
00:11:46.640 --> 00:11:50.217 
So maybe we have discovered this and we could not perfectly fit all cases

171
00:11:51.470 --> 00:11:56.139 
into this model. And then, of course, there are cases where the decision would

172
00:11:56.450 --> 00:11:58.820 
is not in line with our expectations.

173
00:11:58.830 --> 00:12:02.870 
So, for example, for this one here, so we see that the Theft value is around

174
00:12:03.350 --> 00:12:06.292 
1200 Euros and policy type is standard and we still see an accept.

175
00:12:07.520 --> 00:12:12.409 
And well, if the answer to this question was yes,

176
00:12:12.530 --> 00:12:16.450 
if we believe that this perfectly reflects our existing guidelines and policies,

177
00:12:17.330 --> 00:12:21.019 
well, then we should also expect that all cases follow this logic.

178
00:12:21.260 --> 00:12:23.480 
And here for this case, this is clearly not the case.

179
00:12:24.410 --> 00:12:29.269 
So we would then basically act on it because we have discovered

180
00:12:29.270 --> 00:12:31.970 
a nonconforming case.

181
00:12:33.830 --> 00:12:38.419 
To summarize, the data perspective provides relevant information for both

182
00:12:38.420 --> 00:12:43.039 
discovery and conformance and decision mining allows us to understand and

183
00:12:43.040 --> 00:12:47.179 
also model how decisions are taken for the modeling, by the way, of

184
00:12:47.990 --> 00:12:51.959 
decisions there is a standard decision model in notation standard from the object

185
00:12:52.730 --> 00:12:56.899 
management group, which can be explicitly used to make decisions.

186
00:12:56.930 --> 00:13:01.730 
This is also something that many organizations do because as you can imagine,

187
00:13:02.510 --> 00:13:06.430 
the decisions in real life were not always as easy as the ones that we have just

188
00:13:07.070 --> 00:13:09.912 
looked at. So, yeah, better models are required to capture

189
00:13:11.720 --> 00:13:12.989 
the complexity of this.

190
00:13:14.130 --> 00:13:18.323 
Second, we can use decision mining to reflect on existing

191
00:13:18.770 --> 00:13:23.179 
guidelines. We have just seen that, yes, if we discover a decision tree decision model,

192
00:13:23.180 --> 00:13:26.330 
we can then check, OK is this in line with our expectations?

193
00:13:26.750 --> 00:13:31.610 
And if the answer is yes, then we can identify nonconforming cases

194
00:13:32.060 --> 00:13:34.340 
based on decision logic violations.

195
00:13:35.620 --> 00:13:38.170 
There are also some limitations that should be taken to account.

196
00:13:38.200 --> 00:13:42.759 
I've already mentioned the problem of noise, and we cannot expect

197
00:13:42.760 --> 00:13:46.533 
that all cases can be perfectly categorized as something that we have to deal

198
00:13:47.350 --> 00:13:51.020 
with. And there are also some restrictions based on process control.

199
00:13:51.110 --> 00:13:54.549 
So, as you know, our original model contains the loop

200
00:13:55.600 --> 00:13:59.889 
after checking for completeness. So if we take a decision multiple times

201
00:14:00.160 --> 00:14:05.349 
in the same process instance, you can imagine the labelling is not as straightforward

202
00:14:05.350 --> 00:14:09.789 
as we have introduced it here. But these are all issues

203
00:14:09.790 --> 00:14:14.409 
that can be dealt with and decision mining is an important addition

204
00:14:14.410 --> 00:14:18.789 
to the control flow perspective that we have discussed before.
