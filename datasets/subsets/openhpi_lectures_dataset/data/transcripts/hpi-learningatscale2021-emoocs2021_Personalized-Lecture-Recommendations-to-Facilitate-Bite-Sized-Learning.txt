WEBVTT

1
00:00:02.230 --> 00:00:05.450 
i'm a Meltem tutar and i'm a recommendations data scientist.

2
00:00:07.020 --> 00:00:10.300 
so i'm here today to talk about a work in progress paper on

3
00:00:11.040 --> 00:00:13.020 
creating lecture recommendations.

4
00:00:15.190 --> 00:00:19.810 
so Udemy is a course marketplace where some users can create courses

5
00:00:19.810 --> 00:00:21.640 
and other users consume courses.

6
00:00:22.250 --> 00:00:26.130 
so we're now experimenting with smaller units of learning such as lectures.

7
00:00:26.530 --> 00:00:29.940 
we believe that by surfacing stand alone and interesting lectures

8
00:00:29.940 --> 00:00:33.260 
from our over fifty thousand course catalogue we can allow

9
00:00:33.260 --> 00:00:38.050 
users to find more diverse material and make learning more approachable for them.

10
00:00:39.980 --> 00:00:43.480 
though this comes with some challenges since most of our user

11
00:00:43.480 --> 00:00:46.440 
lecture interaction data comes through course enrolments.

12
00:00:46.900 --> 00:00:48.460 
it's tricky how to translate,

13
00:00:49.240 --> 00:00:54.180 
those interactions into recommendations for lectures that are independent.

14
00:00:55.150 --> 00:00:58.600 
and interesting to users that may not be enrolled in the rest of the course.

15
00:00:59.110 --> 00:01:03.630 
so lectures in a given course may not necessarily be stand-alone,

16
00:01:04.800 --> 00:01:08.260 
lectures earlier on in the course are watched more

17
00:01:09.490 --> 00:01:13.310 
to lectures that are watched and of course it may be difficult

18
00:01:13.310 --> 00:01:17.310 
to tell which luxuries are liked more. and then traditional

19
00:01:17.310 --> 00:01:20.110 
collaborative filtering methods are likely to recommend lectures

20
00:01:20.110 --> 00:01:21.180 
from the same source

21
00:01:21.960 --> 00:01:27.560 
given these challenges we decided to implement an unsupervised clustering based approach.

22
00:01:28.650 --> 00:01:32.860 
our hypothesis is that fundamental concepts are repeated within

23
00:01:32.860 --> 00:01:36.550 
many courses on the same topic hence by applying clustering.

24
00:01:36.630 --> 00:01:38.750 
we can identify these concepts.

25
00:01:40.500 --> 00:01:44.990 
so we apply clustering and filtering to all the lecture

26
00:01:45.680 --> 00:01:48.070 
within a topic on their caption data.

27
00:01:48.770 --> 00:01:52.740 
and we generate a set of candidate lectures for each topic,

28
00:01:53.230 --> 00:01:56.420 
and then for a given user we look at their top topic affinities

29
00:01:56.420 --> 00:01:59.760 
which we already have generated previously and we randomly

30
00:01:59.760 --> 00:02:02.270 
sample from these candidate lectures and

31
00:02:03.080 --> 00:02:07.080 
create a lecturer recommendation unit. all a thousand topics

32
00:02:07.080 --> 00:02:09.690 
are generated in paralysed approach in one hour.

33
00:02:11.330 --> 00:02:14.230 
we utilize non-negative matrix factorization for clustering.

34
00:02:16.610 --> 00:02:20.500 
this allows us to learn the top words associated with a cluster

35
00:02:20.500 --> 00:02:23.540 
and also the top documents associated with a cluster.

36
00:02:24.040 --> 00:02:27.240 
this so we can interpret cluster output easily,

37
00:02:27.780 --> 00:02:30.960 
and because it was fast we decided to go with enema.

38
00:02:33.050 --> 00:02:37.410 
and the purpose of the filtering that i mentioned that we do after the clustering.

39
00:02:37.670 --> 00:02:41.090 
so that we can remove clusters that are noisy also those clusters

40
00:02:41.090 --> 00:02:44.330 
that are learning the wrong part of the lecture such as an

41
00:02:44.330 --> 00:02:47.840 
example here where the beginning lecture phrases are learned

42
00:02:47.850 --> 00:02:49.430 
instead of the lecture content.

43
00:02:50.940 --> 00:02:54.790 
here's an example lecture recommendation we can see that the top

44
00:02:55.210 --> 00:02:58.590 
topic affinities are unity python painting drawing and the

45
00:02:58.590 --> 00:03:01.830 
lectures are highly related to these affinities.

46
00:03:01.830 --> 00:03:03.220 
we've seen this for multiple users.

47
00:03:04.160 --> 00:03:06.760 
so that's why we believe that our approach is promising.

48
00:03:07.790 --> 00:03:11.630 
so we've laid down the pipeline for our approach and now we

49
00:03:11.630 --> 00:03:14.220 
believe we can make improvements in each section of the

50
00:03:14.700 --> 00:03:20.010 
pipeline such as changing the input data instead of utilizing.

51
00:03:20.010 --> 00:03:23.790 
the beginning of captions taking key moments trying other clustering

52
00:03:23.790 --> 00:03:27.940 
methodology, such as sparse negative matrix factorization experimenting

53
00:03:27.940 --> 00:03:30.450 
with other embedding techniques or

54
00:03:31.410 --> 00:03:35.060 
filtering methods such as wikipedia graph based filtering.

55
00:03:35.700 --> 00:03:39.320 
our immediate plan is to collect larger amounts of reliable

56
00:03:39.320 --> 00:03:43.310 
user lecture preference data. so we can evaluate each of these improvements.

57
00:03:45.190 --> 00:03:47.540 
thank you for your time and if you have any questions feel

58
00:03:47.540 --> 00:03:51.390 
free to reach me at meltem tutar at com.
