WEBVTT

1
00:00:00.000 --> 00:00:03.300 
The first thing you have to
know is when we talk about data

2
00:00:03.300 --> 00:00:08.800 
aging it's not archiving.
Archiving is something we know for

3
00:00:08.800 --> 00:00:11.110 
30 years, it has been
used in all disk based

4
00:00:11.110 --> 00:00:16.160 
databases and and it basically means
you have some legal requirements

5
00:00:16.160 --> 00:00:20.200 
to keep your data for ten years,
accessible, in your database and

6
00:00:20.200 --> 00:00:24.240 
there are compliance
requirements and based on these

7
00:00:25.250 --> 00:00:28.280 
requirements you have
rules that write data

8
00:00:28.280 --> 00:00:31.310 
out of your database to
a certain archive file.

9
00:00:32.320 --> 00:00:36.360 
In the end the data is
transformed from relational schema

10
00:00:36.360 --> 00:00:40.400 
into an archives schema, that's
something we don't want to

11
00:00:40.400 --> 00:00:42.420 
have for aging,
definitely.

12
00:00:44.440 --> 00:00:48.480 
As I just said archiving
is data that is older

13
00:00:48.480 --> 00:00:49.490 
than ten years
for example,

14
00:00:50.500 --> 00:00:54.540 
long horizontal
or long time span.

15
00:00:54.540 --> 00:00:58.580 
Aging is more, ok, what can we
get out of the database that is

16
00:00:58.580 --> 00:01:01.610 
let's say three years old
and not relevant anymore.

17
00:01:02.620 --> 00:01:06.660 
But still all the data, even
if you start aging data that is

18
00:01:06.660 --> 00:01:10.700 
two years old you have to make
sure that it's still accessible.

19
00:01:10.700 --> 00:01:14.740 
If there is someone asking
a question, give me a

20
00:01:14.740 --> 00:01:19.790 
document ID 4000, you
have to give him an answer

21
00:01:19.790 --> 00:01:24.840 
and you can't tell ok, well
it's aged so we can't access

22
00:01:24.840 --> 00:01:26.860 
any more, you have to
do some special things.

23
00:01:27.870 --> 00:01:30.900 
It must be accessible and
transparent for the application

24
00:01:31.910 --> 00:01:36.960 
yeah and it's brand new.
The thing, why is it

25
00:01:36.960 --> 00:01:40.100 
brand new? You would maybe
ask, okay, actually the

26
00:01:40.100 --> 00:01:45.105 
basic problem of data aging is
that you don't want to handle

27
00:01:45.105 --> 00:01:50.110 
or the important data
the same way as your

28
00:01:50.110 --> 00:01:54.114 
irrelevant data. You have data
that is really relevant for your

29
00:01:54.114 --> 00:01:57.117 
application and we can
show with our bachelor

30
00:01:57.117 --> 00:02:01.121 
project, this is a really small
percentage of the overall data

31
00:02:02.122 --> 00:02:07.127 
and you really want to, yeah, have
this faster on your fingertips

32
00:02:07.127 --> 00:02:11.131 
than the irrelevant data.
But you don't have to have a

33
00:02:11.131 --> 00:02:15.135 
MBA of business
administration

34
00:02:15.135 --> 00:02:19.139 
to get to know, ok, you want
to have more effort on the

35
00:02:19.139 --> 00:02:26.146 
relevant stuff. A stone-old challenge,
yeah well it's stone-old since

36
00:02:26.146 --> 00:02:29.149 
databases are built,
you have this problem

37
00:02:30.150 --> 00:02:34.154 
and typically - or it
was solved basically

38
00:02:34.154 --> 00:02:38.158 
by the idea of
buffering of disk-pages.

39
00:02:39.159 --> 00:02:44.164 
I don't know how familiar you are with
paging but basically you all have all

40
00:02:44.164 --> 00:02:47.167 
your data on a disk
and once you need some

41
00:02:47.167 --> 00:02:52.172 
blocks or disk blocks, you read
them and cache them in your main

42
00:02:52.172 --> 00:02:54.174 
memory, so you have
them accessible.

43
00:02:55.175 --> 00:02:58.178 
You measure the
hotness of a disk

44
00:02:58.178 --> 00:03:02.182 
page so you know, ok this page
is accessed a lot of times so

45
00:03:02.182 --> 00:03:06.186 
it is kept in your cache
and once your cache is full

46
00:03:06.186 --> 00:03:10.190 
the page that is
accessed least recently

47
00:03:11.191 --> 00:03:18.198 
is evicted. You have this by
the fundamental architecture

48
00:03:18.198 --> 00:03:23.203 
of disk space data bases already
support this concept of data

49
00:03:23.203 --> 00:03:28.208 
relevance. You have a page list
management and all your database

50
00:03:28.208 --> 00:03:32.212 
is optimized for
disk pages, all

51
00:03:32.212 --> 00:03:37.217 
your indices don't
point to a certain bite

52
00:03:38.218 --> 00:03:43.223 
but they point to a certain
page and you know, ok this page

53
00:03:43.223 --> 00:03:47.227 
is cached, you can
directly access this.

54
00:03:47.227 --> 00:03:52.232 
DB2 for example
says okay, you

55
00:03:52.232 --> 00:03:56.236 
basically need five percent
of your overall data amount

56
00:03:56.236 --> 00:04:01.241 
as a cache in your
main memory to

57
00:04:01.241 --> 00:04:06.246 
to answer 80 and
98 percent of all

58
00:04:06.246 --> 00:04:07.247 
your accesses.

59
00:04:10.250 --> 00:04:13.253 
We all know that disk based
databases are not the future

60
00:04:15.255 --> 00:04:18.258 
and the reason for
this is mixed workload,

61
00:04:18.258 --> 00:04:21.261 
or one reason for
this is mixed workload

62
00:04:21.261 --> 00:04:25.265 
because these databases
are not able to

63
00:04:25.265 --> 00:04:30.270 
to process queries that scan
over an entire column. Once you

64
00:04:30.270 --> 00:04:34.274 
do that without having a
secondary index, without

65
00:04:34.274 --> 00:04:37.277 
having a primary index,
your basically lost because

66
00:04:37.277 --> 00:04:40.280 
the entire column needs to be
scanned and this means all your

67
00:04:41.281 --> 00:04:44.284 
data for this table
has to be loaded into

68
00:04:44.284 --> 00:04:47.287 
your cache and this ruins
the overall concept.

69
00:04:49.289 --> 00:04:53.293 
This way, this is the reason we have
HANA for real-time mixed workload

70
00:04:53.293 --> 00:04:56.296 
on transactional
data. This means

71
00:04:57.297 --> 00:05:03.303 
today everything is in main
memory, all the last ten years must

72
00:05:03.303 --> 00:05:06.306 
be in main memory so they
are bite addressible.

73
00:05:07.307 --> 00:05:10.310 
Yeah you can argue,
you can load the

74
00:05:11.311 --> 00:05:15.315 
column wise the data but once
you have a star select everything

75
00:05:15.315 --> 00:05:18.000 
has to be loaded
into main memory

76
00:05:18.318 --> 00:05:21.321 
so basically everything
is there. This means

77
00:05:21.321 --> 00:05:25.325 
that irrelevant, cold data
blocks precious resources.

78
00:05:25.325 --> 00:05:28.328 
You scan entire columns
without the data that is

79
00:05:29.329 --> 00:05:34.334 
not relevant for your result
set. Today there is no solution

80
00:05:34.334 --> 00:05:39.339 
for mixed workload. Our
goal is how do we identify

81
00:05:39.339 --> 00:05:42.342 
and pin the relevant
data in main memory

82
00:05:43.343 --> 00:05:46.346 
and separate this for
the irrelevant data

83
00:05:47.347 --> 00:05:51.351 
and as a second point how do
we avoid access on cold data.

84
00:05:53.353 --> 00:05:57.357 
Three short examples for
a mixed workload. You have

85
00:05:57.357 --> 00:05:59.359 
a single select, you
have a range select,

86
00:06:00.360 --> 00:06:04.364 
a range star select, and you have
an aggregation on your revenue.

87
00:06:05.365 --> 00:06:08.368 
Completely different
queries and basically these

88
00:06:08.368 --> 00:06:12.372 
queries make your
life pretty hard

89
00:06:13.373 --> 00:06:17.377 
because it's hard to
predict or anticipate what

90
00:06:17.377 --> 00:06:21.381 
or how the data is accessed. If
you always know, ok your access

91
00:06:21.381 --> 00:06:24.384 
pass is the primary
key or secondary index,

92
00:06:24.384 --> 00:06:27.387 
there are ways how you
can separate hot and cold.

93
00:06:28.388 --> 00:06:32.392 
But if you have different queries
like this and the selection

94
00:06:32.392 --> 00:06:36.396 
can be on basically any
column of your table,

95
00:06:37.397 --> 00:06:41.401 
it's hard to tell if you
partition your data just

96
00:06:41.401 --> 00:06:44.404 
on your year column

97
00:06:45.405 --> 00:06:49.409 
and say ok everything from this
year and the last year is hot,

98
00:06:49.409 --> 00:06:52.412 
you can tell okay if
someone is asking for such

99
00:06:52.412 --> 00:06:55.415 
a query you can say ok
you have to go to the cold

100
00:06:55.415 --> 00:07:00.420 
but if someone is asking this query,
you have a problem because there

101
00:07:00.420 --> 00:07:04.424 
is no year in your
data selection.

102
00:07:05.425 --> 00:07:09.429 
As I said this gets a

103
00:07:09.429 --> 00:07:12.432 
major problem if we were
talking about mixed workloads.

104
00:07:14.434 --> 00:07:19.439 
Our requirements for
the concept I'm going to

105
00:07:19.439 --> 00:07:24.444 
present is we need flexibility,
ideally full application transparency

106
00:07:24.444 --> 00:07:28.448 
that means the application
shouldn't tell the database

107
00:07:28.448 --> 00:07:32.452 
what is hot and what is cold,
the database alone should

108
00:07:33.453 --> 00:07:38.458 
know or see what data is
relevant for the workload

109
00:07:38.458 --> 00:07:43.463 
it's running on and
we see a point that

110
00:07:43.463 --> 00:07:49.469 
for mixed workloads you
can not only partition

111
00:07:49.469 --> 00:07:53.473 
horizontally you also should
have a concept, an idea

112
00:07:53.473 --> 00:07:58.478 
how you are partition vertically
because mixed workload or

113
00:07:58.478 --> 00:08:03.483 
analytic queries typically
don't project the anti table

114
00:08:03.483 --> 00:08:06.486 
but just certain columns like
the revenue that is relevant,

115
00:08:06.486 --> 00:08:10.490 
you want to aggregate over a
long time period so let's give

116
00:08:10.490 --> 00:08:14.494 
me the average
price for the last

117
00:08:14.494 --> 00:08:18.498 
five years. You don't want to
have to last five years and hot

118
00:08:18.498 --> 00:08:21.501 
but you want to have just the
revenue or that the price of

119
00:08:21.501 --> 00:08:22.502 
the last five
years and hot.

120
00:08:24.504 --> 00:08:28.508 
Of course it must be deterministic,
if you have a good idea

121
00:08:28.508 --> 00:08:32.512 
how you or application idea
how you partition data,

122
00:08:32.512 --> 00:08:35.515 
let's say ok everything
that is a still open

123
00:08:35.515 --> 00:08:38.518 
from the last two
years should be in

124
00:08:39.519 --> 00:08:44.524 
hot. You have to
know, ok, when

125
00:08:44.524 --> 00:08:49.529 
a query comes in, can I, do I have
to go the cold or is it enough

126
00:08:49.529 --> 00:08:53.533 
to just scan or work on
the hot part of your data.

127
00:08:55.535 --> 00:08:58.538 
The concept we're
thinking on or

128
00:08:58.538 --> 00:09:03.543 
thinking about is basically
three steps. The first

129
00:09:03.543 --> 00:09:07.547 
one is that we want to sample the
actual workload that is coming

130
00:09:07.547 --> 00:09:11.551 
from the application.
The second one

131
00:09:12.552 --> 00:09:16.556 
is that we periodically analyze
the workload that has been

132
00:09:16.556 --> 00:09:20.560 
sampled and derive
from that certain rules

133
00:09:20.560 --> 00:09:24.564 
that show us, ok what
selection is relevant for the

134
00:09:24.564 --> 00:09:26.566 
application, how does
the application or

135
00:09:26.566 --> 00:09:30.570 
the reports running on
the data access the data.

136
00:09:30.570 --> 00:09:34.574 
The third one is that we also
want to use the same rules

137
00:09:34.574 --> 00:09:38.578 
during query execution
to tell, ok this query

138
00:09:38.578 --> 00:09:44.584 
can be answered or is matching
a certain rule so we know

139
00:09:45.585 --> 00:09:49.589 
the data is in hot and we can
skip a scanning or processing

140
00:09:49.589 --> 00:09:50.590 
on the cold data.

141
00:09:53.593 --> 00:09:58.598 
If we try to visualize
this a little bit

142
00:09:59.599 --> 00:10:03.603 
basically you have, depending on
the complexity of your workload

143
00:10:03.603 --> 00:10:09.609 
on a certain table, a set
of rules that in combination

144
00:10:09.609 --> 00:10:12.612 
or the union
of those rules

145
00:10:13.613 --> 00:10:19.619 
represent the hot data, so these
are two rules as an example

146
00:10:20.620 --> 00:10:24.624 
the first one says 'okay
the revenue year and

147
00:10:24.624 --> 00:10:28.628 
customer column from this table
where the year is larger than

148
00:10:28.628 --> 00:10:31.631 
2009 and the
customers are in

149
00:10:32.632 --> 00:10:35.635 
this predicate.

150
00:10:36.636 --> 00:10:40.640 
These information we get
from the workload sampling so

151
00:10:40.640 --> 00:10:46.646 
we know ok, this access path is
typical for our workload overall

152
00:10:46.646 --> 00:10:49.649 
application and we
have a second one,

153
00:10:49.649 --> 00:10:52.652 
a query that just asked, ok
give me everything that is open.

154
00:10:52.652 --> 00:10:56.656 
We know this is relevant
for our application,

155
00:10:56.656 --> 00:11:00.660 
we derive rules for that and
all of those rules together or

156
00:11:00.660 --> 00:11:06.666 
as a union can be used to classify
or identify the hot tuples.

157
00:11:07.667 --> 00:11:12.672 
Everything that is not in this
range or is not selected by

158
00:11:12.672 --> 00:11:18.678 
those rules is aged, clockwise.
We know, ok there are thousand

159
00:11:18.678 --> 00:11:22.682 
tuples that do not
match our criteria

160
00:11:23.683 --> 00:11:27.687 
so we create a new block
of data that can be moved

161
00:11:28.688 --> 00:11:34.694 
on a cold node or on flash.
Well there are multiple

162
00:11:34.694 --> 00:11:38.698 
options we are
looking into and

163
00:11:38.698 --> 00:11:43.703 
this is a periodical
process but

164
00:11:43.703 --> 00:11:47.707 
still we're or we have
to sample the workload

165
00:11:47.707 --> 00:11:51.711 
while it's running. Lets start
what we've done so far and what

166
00:11:51.711 --> 00:11:57.717 
we've evaluated. One thing
we started is a building or

167
00:11:57.717 --> 00:12:01.721 
implementing such a concept in
Hyrise research database, the

168
00:12:01.721 --> 00:12:06.726 
first thing we had to do is
put horizontal partitioning

169
00:12:06.726 --> 00:12:11.731 
for a certain column, so we,
hyrise is a column store that

170
00:12:11.731 --> 00:12:14.734 
can be partitioned
additionally, horizontally.

171
00:12:15.735 --> 00:12:21.741 
We can have such a
horizontal partitioning

172
00:12:22.742 --> 00:12:26.746 
and we can have different
storage allocations,

173
00:12:26.746 --> 00:12:30.750 
so the red ones are allocated
in main memory so basically.

174
00:12:30.750 --> 00:12:34.754 
You can say ok are pinned, they
are always direct accessible

175
00:12:34.754 --> 00:12:37.757 
and the blue ones
are allocated with a

176
00:12:38.758 --> 00:12:42.762 
EMC, it's a PCI F flash

177
00:12:42.762 --> 00:12:46.766 
card that provides you
certain address space

178
00:12:47.767 --> 00:12:51.771 
and if you put a vector
or data into this

179
00:12:51.771 --> 00:12:56.776 
address area, it potentially
can reside on flash if the cache

180
00:12:56.776 --> 00:12:58.778 
is full.

181
00:13:01.781 --> 00:13:04.784 
If you access this, you
can assure everything is

182
00:13:05.785 --> 00:13:10.790 
in hot, if you access a tuple
here it might happen that

183
00:13:10.790 --> 00:13:14.794 
this data is not in main
memory but must be cached from

184
00:13:14.794 --> 00:13:17.797 
the flash card or from
the PCI Flash card.

185
00:13:19.799 --> 00:13:23.803 
What we also implemented is an
aging check, before the query

186
00:13:23.803 --> 00:13:27.807 
execution. We get the
query and we say ok let's

187
00:13:27.807 --> 00:13:31.811 
match this with our rules and
once we know this we can say

188
00:13:31.811 --> 00:13:35.815 
ok, it's enough to scan
or operate onthe red

189
00:13:35.815 --> 00:13:40.820 
areas, just the first partitions.
We have hot only operators

190
00:13:40.820 --> 00:13:44.824 
that, for example, just
scan the the hot area

191
00:13:44.824 --> 00:13:49.829 
well. Then, what we have also did
in the last year is a bachelor

192
00:13:49.829 --> 00:13:53.833 
project where we started with
the idea that i just explained.

193
00:13:54.834 --> 00:13:58.838 
As you just commented,
you want to know how

194
00:13:58.838 --> 00:14:01.841 
good is this or
is this feasible

195
00:14:01.841 --> 00:14:06.846 
to sample data from your
workload so specifically that

196
00:14:06.846 --> 00:14:11.851 
you can extract or derive good
rules that help you to classify

197
00:14:11.851 --> 00:14:14.854 
the data. This system runs
one point five billion queries

198
00:14:14.854 --> 00:14:18.858 
each day, so quite a lot
of data and we trace it

199
00:14:18.858 --> 00:14:23.863 
for a couple of days and we
parsed it, so we extracted

200
00:14:23.863 --> 00:14:26.866 
the selection
criteria, the different

201
00:14:26.866 --> 00:14:29.869 
the query types or
the prepare state.

202
00:14:32.872 --> 00:14:35.875 
Just short, our
overall architecture,

203
00:14:35.875 --> 00:14:41.881 
we have the trace file, this
was where the SQL HANA tracefile

204
00:14:41.881 --> 00:14:45.885 
came in. We parsed, we cleaned it,
so in the end we had a workload

205
00:14:45.885 --> 00:14:50.890 
or no, we traced it, then
we had the workload parser

206
00:14:50.890 --> 00:14:54.894 
that went over each and every
query and selected the data

207
00:14:54.894 --> 00:14:58.898 
or extracted the data from
the query and wrote this data

208
00:14:58.898 --> 00:15:02.000 
into our HANA
statistics server.

209
00:15:02.902 --> 00:15:04.904 
It was also a HANA
system where you had a

210
00:15:04.904 --> 00:15:08.908 
relational schema where all
the characteristics are or have

211
00:15:08.908 --> 00:15:14.914 
been written down. The API
basically is just an interface

212
00:15:14.914 --> 00:15:18.918 
for the user interface, there
are some fancy queries that go

213
00:15:18.918 --> 00:15:25.925 
over the data and
prepare it so the user

214
00:15:25.925 --> 00:15:30.930 
can exploratively go through
the workload and see how is this

215
00:15:30.930 --> 00:15:36.936 
data selected in table x-y and
how is the query distribution

216
00:15:36.936 --> 00:15:39.939 
etc. This is our explorative
workload analyzer,

217
00:15:40.940 --> 00:15:43.943 
the first thing
you see is a

218
00:15:43.943 --> 00:15:47.947 
complete overview of the entire
database. We have just grouped the

219
00:15:47.947 --> 00:15:50.950 
transactional tables, master data
data tables, views, customizing

220
00:15:50.950 --> 00:15:54.954 
tables, different table types. As
we already heard, transactional

221
00:15:54.954 --> 00:15:57.957 
tables are the ones that really
hurt and we also see this

222
00:15:58.958 --> 00:16:02.962 
based on the tuple count,
the transactional tables

223
00:16:02.962 --> 00:16:04.964 
take the most,

224
00:16:05.965 --> 00:16:08.968 
the biggest share of the overall
data. We look into especially

225
00:16:08.968 --> 00:16:12.972 
transactional tables. Cany you
press somewhere around here?

226
00:16:12.972 --> 00:16:15.975 
You get some information
and can press there.

227
00:16:15.975 --> 00:16:19.979 
We are drilling down and now we
see all the transactional tables,

228
00:16:19.979 --> 00:16:23.983 
transactional tables only.
The blue ones are the

229
00:16:23.983 --> 00:16:28.988 
ones we have traced,
these are special

230
00:16:28.988 --> 00:16:31.991 
financial
interesting tables

231
00:16:32.992 --> 00:16:38.998 
and also some really, really big
tables that have been especially

232
00:16:38.998 --> 00:16:43.100 
interesting. We can
just go for the COBK.

233
00:16:43.100 --> 00:16:48.100 
This is a controlling
object document header

234
00:16:48.100 --> 00:16:52.101 
so header and item
tables are pretty

235
00:16:53.101 --> 00:16:58.101 
frequent in SAP systems
and this is one of them

236
00:16:58.101 --> 00:17:03.102 
that holds actually
your controlling object.

237
00:17:03.102 --> 00:17:06.102 
So if you have a revenue
center or cost center

238
00:17:06.102 --> 00:17:10.103 
you can put certain cost
of your accounting on

239
00:17:11.103 --> 00:17:15.103 
to those objects.

240
00:17:16.103 --> 00:17:19.103 
The first screen basically
just gives you an overview. We

241
00:17:19.103 --> 00:17:24.104 
have here selected the table, it
gives an overview of the workload,

242
00:17:24.104 --> 00:17:28.104 
it gives you an overview
of the workload types so

243
00:17:28.104 --> 00:17:33.105 
as we have parsed every
query, we can tell ok is the

244
00:17:33.105 --> 00:17:35.105 
key select query, a
partial key select query

245
00:17:35.105 --> 00:17:39.105 
and so on. We also looked into the
projection, how many star select

246
00:17:39.105 --> 00:17:42.106 
projections do we have?
Partial projections

247
00:17:43.106 --> 00:17:46.106 
mean ok, just a couple
of fields are projected

248
00:17:47.106 --> 00:17:50.107 
and so on. Here are the top
ten query templates, the

249
00:17:50.107 --> 00:17:55.107 
most relevant
access types on this

250
00:17:55.107 --> 00:17:59.107 
table. If we go to
query distribution

251
00:18:03.108 --> 00:18:07.108 
we also see how the workload
develops over a certain time frame.

252
00:18:07.108 --> 00:18:12.109 
If we just select, so this is
just a group by the different

253
00:18:12.109 --> 00:18:15.109 
query types. If you
select a certain

254
00:18:16.109 --> 00:18:21.110 
query template, you also see
ok, there's a certain pattern.

255
00:18:21.110 --> 00:18:25.110 
This one is not that interesting,
but you can see on other

256
00:18:25.110 --> 00:18:28.110 
tables that there are really
interesting patterns like

257
00:18:29.110 --> 00:18:33.111 
the query always starts at 8 am
the morning and ends at 2 pm.

258
00:18:34.111 --> 00:18:37.111 
One idea behind this or
could be that we have

259
00:18:37.111 --> 00:18:41.112 
something like
prefetching,

260
00:18:41.112 --> 00:18:45.112 
as you know, this query comes
in, you could pre fetch.

261
00:18:46.112 --> 00:18:49.112 
Currently I don't think this
is an option, you want to have

262
00:18:49.112 --> 00:18:52.113 
all you data in your
main or your master

263
00:18:52.113 --> 00:18:57.113 
store and don't reload from the
cold store into the hot again

264
00:18:57.113 --> 00:19:03.114 
but it might be an
interesting aspect.

265
00:19:04.114 --> 00:19:07.114 
There are some other
visualisations about

266
00:19:07.114 --> 00:19:13.115 
insert/update ratio, different
visualisations and the last

267
00:19:13.115 --> 00:19:15.115 
thing, I think it's
interesting for this

268
00:19:17.115 --> 00:19:19.115 
presentation is the
template selection.

269
00:19:19.115 --> 00:19:23.116 
What you see here
is once again

270
00:19:24.116 --> 00:19:28.116 
our top ten query
templates and at the top

271
00:19:29.000 --> 00:19:34.000 
are the columns, used for selection.
For this query template you

272
00:19:34.000 --> 00:19:37.117 
see the column
MANDANT and the column

273
00:19:38.117 --> 00:19:43.118 
KOSTENKREIS.
I'm not sure but

274
00:19:44.118 --> 00:19:47.118 
this column is used for data
selection. If you just hover over

275
00:19:47.118 --> 00:19:48.118 
this template,

276
00:19:50.119 --> 00:19:55.119 
the template here okay. You
see there's another one,

277
00:19:56.119 --> 00:20:00.120 
so we can scroll here, there are
obviously more than just four

278
00:20:00.120 --> 00:20:03.120 
columns relevant for selection
if you just scroll over.

279
00:20:03.120 --> 00:20:07.120 
The other ones are
coming, more more more.

280
00:20:07.120 --> 00:20:14.121 
Ok, this is BELNR
(Belegnummer). We see

281
00:20:14.121 --> 00:20:18.121 
what values have we selected
for this query template.

282
00:20:20.122 --> 00:20:24.122 
We can go or just
press on this

283
00:20:25.122 --> 00:20:30.123 
and see the distribution.
We know, okay, there are

284
00:20:30.123 --> 00:20:34.123 
143 million
distinct values

285
00:20:35.123 --> 00:20:40.124 
in this column, we have extracted
some additional statistics from

286
00:20:40.124 --> 00:20:44.124 
the productive system.
We know 12,000 are

287
00:20:44.124 --> 00:20:47.124 
or have been distinct
values, have been selected

288
00:20:47.124 --> 00:20:53.125 
in that time frame. We
see the template below

289
00:20:53.125 --> 00:20:57.125 
but this means that all the
other ones have never been

290
00:20:57.125 --> 00:21:02.126 
used for data selection.
The idea is to take

291
00:21:03.126 --> 00:21:07.126 
these information or
this data and build our

292
00:21:07.126 --> 00:21:11.127 
aging rules with
this information.

293
00:21:11.127 --> 00:21:16.127 
We could select those values,
for example just select

294
00:21:16.127 --> 00:21:21.128 
the three. Ok, you
can see all the

295
00:21:21.128 --> 00:21:24.128 
values in there
and how often

296
00:21:24.128 --> 00:21:27.128 
it has been selected,
just select it as well

297
00:21:28.128 --> 00:21:33.129 
and this one, ok. Now
we go out to, just press

298
00:21:33.129 --> 00:21:37.129 
somewhere in
the grey spot.

299
00:21:38.129 --> 00:21:41.130 
Currently this is all manual
work, we're looking at what

300
00:21:41.130 --> 00:21:44.130 
we have extracted from
the workload and we can

301
00:21:44.130 --> 00:21:48.130 
select values that should
be part of the hot data,

302
00:21:49.000 --> 00:21:54.131 
manual process. If we
go on rules, we see

303
00:21:54.131 --> 00:21:57.131 
such a rule, it's
pretty simple and easy

304
00:21:58.131 --> 00:22:03.132 
but it's part of a demo. One
step we could go further,

305
00:22:03.132 --> 00:22:07.132 
that would be the calculation and
I think it will take some time

306
00:22:07.132 --> 00:22:11.133 
because what is happening if
you are pressing calculate

307
00:22:12.133 --> 00:22:16.133 
is that we are checking all the
queries on this table against this

308
00:22:16.133 --> 00:22:22.134 
rule. How many queries
or if we take these three

309
00:22:22.134 --> 00:22:27.134 
values into our hot part, how
many queries can be answered

310
00:22:27.134 --> 00:22:31.135 
having this data? You are
just checking, ok how many

311
00:22:32.135 --> 00:22:36.135 
queries run on these three values
and this has been calculated

312
00:22:36.135 --> 00:22:39.135 
and you it here,
well I think it

313
00:22:40.136 --> 00:22:43.136 
takes more than
eight seconds.

314
00:22:44.136 --> 00:22:49.136 
Oh no. Ok it
was a simple one

315
00:22:50.137 --> 00:22:53.137 
it's a little bit faster.
You see okay for this query

316
00:22:54.137 --> 00:22:59.137 
you can have a, can
you hover on this bar?

317
00:22:59.137 --> 00:23:04.138 
Six percent with just those
three values, six percent of

318
00:23:04.138 --> 00:23:08.138 
this query can be answered
and here is the total.

319
00:23:12.139 --> 00:23:16.139 
Six percent of the overall, so
it's not very good so far and

320
00:23:16.139 --> 00:23:20.140 
we could go on and improve those
rules but obviously we don't

321
00:23:20.140 --> 00:23:23.140 
want to make this manually
but automatically.

322
00:23:23.140 --> 00:23:26.140 
Below that we could, if
we would have the data,

323
00:23:26.140 --> 00:23:30.141 
see how much data would
be in hot, just run those

324
00:23:30.141 --> 00:23:34.141 
rules on the data and we would
know, ok, five percent of our

325
00:23:34.141 --> 00:23:39.141 
data is hot. Re-calculate is not
necessary, if we would have more

326
00:23:39.141 --> 00:23:41.142 
than one rule, we could
recalculate and so on and so on.

327
00:23:42.142 --> 00:23:43.142 
Basically that's it.
