WEBVTT

1
00:00:00.830 --> 00:00:05.840 
Hi, my name is Benjamin Bergner.
I'm a PhD student at the chair

2
00:00:05.840 --> 00:00:09.790 
Digital Health and Machine Learning
of professor Christoph Lippert.

3
00:00:10.340 --> 00:00:16.030 
My research revolves around the design
of neural network architectures

4
00:00:16.850 --> 00:00:19.690 
in the field of computer
vision and radiology.

5
00:00:20.470 --> 00:00:22.820 
In this presentation,
I talk about

6
00:00:23.610 --> 00:00:25.980 
energy efficient
deep learning

7
00:00:27.030 --> 00:00:31.470 
and what makes deep learning
so energy intensive.

8
00:00:33.910 --> 00:00:37.590 
First of all, let's look at the state-
of-the-art deep learning algorithms.

9
00:00:38.250 --> 00:00:43.060 
If we look over time how compute
intensive those algorithms

10
00:00:43.060 --> 00:00:47.190 
are, we see a doubling time in
computational requirements every

11
00:00:47.210 --> 00:00:51.930 
three point four month, according
to a study of open AI.

12
00:00:52.580 --> 00:00:53.980 
What are the
reasons for that?

13
00:00:55.560 --> 00:00:58.710 
First of all, we have ever
increasing dataset

14
00:00:59.120 --> 00:01:03.730 
sizes but this is not everything.
Also, we see an increasing

15
00:01:03.730 --> 00:01:07.780 
number of parameters which range
from the millions into the

16
00:01:08.100 --> 00:01:11.910 
billions of parameters in
modern architectures.

17
00:01:12.420 --> 00:01:17.210 
Last but not least, we see also that
those algorithms are trained

18
00:01:17.210 --> 00:01:21.990 
in an iterative fashion in order
to optimise the parameters.

19
00:01:22.750 --> 00:01:25.880 
So the data set which
can be very large

20
00:01:26.730 --> 00:01:31.200 
is traversed several times - hundreds
of times until the optimal

21
00:01:31.200 --> 00:01:32.810 
set of parameters
is found.

22
00:01:34.290 --> 00:01:38.860 
Also, you do not train a neural
network only once. You do it several

23
00:01:38.860 --> 00:01:42.730 
hundreds, sometimes even thousands,
of experiments until you

24
00:01:42.730 --> 00:01:44.320 
have developed your
final version.

25
00:01:45.640 --> 00:01:49.690 
And after you have trained and experimented
and tuned the neural network,

26
00:01:49.880 --> 00:01:51.180 
it goes into production.

27
00:01:51.910 --> 00:01:55.090 
And during production you
use it for inference.

28
00:01:55.670 --> 00:01:57.930 
And imagine for
example, you

29
00:01:58.880 --> 00:02:03.440 
have a neural network that runs
in an autonomously driving car

30
00:02:03.550 --> 00:02:10.060 
for example, it has to produce
predictions several times in a second

31
00:02:10.950 --> 00:02:12.340 
which is very costly.

32
00:02:14.130 --> 00:02:16.370 
As another example,
there's a

33
00:02:17.230 --> 00:02:20.140 
recent study from 2019

34
00:02:20.650 --> 00:02:25.540 
in which researchers have analyzed
the carbon footprint of

35
00:02:25.540 --> 00:02:29.610 
a very large language model. And
training this large language

36
00:02:29.610 --> 00:02:33.690 
model resulted in a carbon footprint
of six hundred and twenty

37
00:02:33.690 --> 00:02:38.410 
six pounds of CO2 emissions.
To put this a little bit into

38
00:02:38.410 --> 00:02:40.520 
perspective, this
corresponds to

39
00:02:41.130 --> 00:02:45.830 
a carbon footprint of an average
American adult over a period

40
00:02:45.830 --> 00:02:48.570 
of seventeen years, which
is quite shocking.

41
00:02:49.480 --> 00:02:54.970 
As another example, training a rather
medium sized neural network

42
00:02:54.990 --> 00:03:00.170 
over a period of six months with lots
of thousands of experiments for RnD

43
00:03:00.280 --> 00:03:04.540 
but also to produce an algorithm
for per production system,

44
00:03:05.090 --> 00:03:09.840 
this roughly corresponds to
the carbon footprint of an

45
00:03:10.810 --> 00:03:14.830 
average American adult over
a period of two years.

46
00:03:16.850 --> 00:03:21.650 
For images, this is even worse.
A neural network has to look

47
00:03:21.950 --> 00:03:25.640 
at every location in the
image to make a prediction,

48
00:03:26.150 --> 00:03:30.560 
which in this case is dog, even
though the background is not

49
00:03:30.560 --> 00:03:34.690 
very representative for the
problem. So those are not salient

50
00:03:34.690 --> 00:03:37.300 
features that are
pertinent to the class.

51
00:03:37.950 --> 00:03:40.590 
so an efficient neural
network could attend

52
00:03:41.040 --> 00:03:45.710 
to the interesting areas in the
image and only focus on them

53
00:03:45.710 --> 00:03:48.040 
and analyze them in order
to make a prediction.

54
00:03:50.190 --> 00:03:55.540 
Another problem with images in
general and medical images in particular

55
00:03:55.930 --> 00:03:58.010 
is that those images

56
00:03:58.620 --> 00:04:03.410 
can be quite large and RnD we
have oftentimes images ranging

57
00:04:03.440 --> 00:04:05.790 
in the image dimensions
from two hundred

58
00:04:06.240 --> 00:04:07.770 
to maybe four hundred.

59
00:04:08.650 --> 00:04:13.720 
If we go into the medical domain,
we see much larger images

60
00:04:13.720 --> 00:04:15.060 
into the mega pixels.

61
00:04:15.730 --> 00:04:20.560 
Even though the interesting area,
which is an abnormality for example,

62
00:04:21.190 --> 00:04:23.520 
can be quite small
in comparison.

63
00:04:25.380 --> 00:04:27.090 
Take another example -

64
00:04:27.700 --> 00:04:32.950 
whole-slide images in pathology. Those
images go into the giga pixels

65
00:04:33.210 --> 00:04:37.200 
and the signal to noise
ratio can even be smaller.

66
00:04:38.760 --> 00:04:45.240 
Or, for example, CT scans or MRI
scans those images exhibit a

67
00:04:45.240 --> 00:04:48.850 
third depth dimension
which make them very

68
00:04:49.430 --> 00:04:53.680 
high resolutional and the signal
to noise ratio also is very

69
00:04:53.680 --> 00:04:55.780 
small if you look
for abnormalities.

70
00:04:58.630 --> 00:05:03.350 
Now, let's look in general at a
high resolution image. Those

71
00:05:03.350 --> 00:05:07.650 
images are applied to a neural
network algorithm. This could

72
00:05:07.650 --> 00:05:11.420 
for example be a convolutional neural
network which is here represented as an

73
00:05:11.630 --> 00:05:15.990 
encoder. Now this encoder
displayed here in red

74
00:05:16.500 --> 00:05:20.760 
is very energy inefficient because
it has to scan the whole image

75
00:05:20.920 --> 00:05:24.250 
which could be very
large in size.

76
00:05:25.330 --> 00:05:30.080 
Now after this network has been
applied, it will produce a vector

77
00:05:30.080 --> 00:05:35.350 
representation of the image which
then is used to make a prediction.

78
00:05:35.480 --> 00:05:39.830 
In the radiology context, this could be
whether the image shows something normal

79
00:05:39.960 --> 00:05:40.790 
or abnormal.

80
00:05:43.960 --> 00:05:47.700 
Now let's look at an efficient
version of this algorithm.

81
00:05:48.360 --> 00:05:53.190 
One very simple solution would be
to simply downscale the image

82
00:05:53.480 --> 00:06:00.480 
to form a low resolution image but this is
a problem especially of details matter.

83
00:06:01.160 --> 00:06:03.260 
For example, an
abnormality

84
00:06:04.100 --> 00:06:07.500 
needs to be processed in high
resolution to determine whether

85
00:06:07.500 --> 00:06:09.880 
it is - it shows an
abnormality or not.

86
00:06:10.900 --> 00:06:12.750 
Also for example
autonomously

87
00:06:13.470 --> 00:06:18.280 
driving cars, a street sign needs to
be detected in order to determine

88
00:06:18.520 --> 00:06:20.690 
how fast the car can go.

89
00:06:22.750 --> 00:06:24.630 
So, this is not
sufficient.

90
00:06:25.290 --> 00:06:30.300 
But how could we tweak this system
to make it more energy efficient?

91
00:06:31.070 --> 00:06:36.090 
So in this example, we have colored
an intermediate representation

92
00:06:36.500 --> 00:06:41.290 
of the neural network in dark green.
We could look at it and aggregate

93
00:06:41.720 --> 00:06:44.180 
a feature map
representation

94
00:06:44.970 --> 00:06:50.520 
which highlights the salient image
parts. So, those parts that the system

95
00:06:50.720 --> 00:06:53.240 
should focus on in order
to make its decision.

96
00:06:54.310 --> 00:06:59.110 
Now we could look at the high
resolution image and extract

97
00:06:59.150 --> 00:07:03.360 
patches at the corresponding
locations that are highlighted

98
00:07:03.360 --> 00:07:07.250 
before from the peripheral view
of the low resolution network.

99
00:07:08.950 --> 00:07:14.550 
Now, after we have extracted those patches
those can be applied to a separate

100
00:07:14.930 --> 00:07:20.070 
encoder which is again energy
efficient as it only has to process

101
00:07:20.510 --> 00:07:22.550 
very small
sized patches.

102
00:07:24.420 --> 00:07:29.830 
After those encoders are applied, it
will yield vector representations

103
00:07:29.830 --> 00:07:31.570 
for each of
those patches.

104
00:07:32.490 --> 00:07:36.170 
Finally, those
patches and

105
00:07:37.250 --> 00:07:42.400 
the vector representation of the low
resolution image is aggregated to form

106
00:07:42.580 --> 00:07:49.190 
an aggregated mean version of this vector
representation which is finally used

107
00:07:49.430 --> 00:07:51.030 
to make the prediction.

108
00:07:53.040 --> 00:07:55.510 
Now, let's look at an
example to make this

109
00:07:56.040 --> 00:07:59.900 
better understandable. So
here's a simple example of a

110
00:08:00.400 --> 00:08:05.010 
large resolution image, in this case
it's five hundred times five hundred

111
00:08:05.410 --> 00:08:09.830 
pixels and the task is to
detect the majority digit

112
00:08:10.250 --> 00:08:15.040 
in this image. This image in
particular shows five digits - three

113
00:08:15.040 --> 00:08:18.070 
of them are five and two
of them are random,

114
00:08:18.480 --> 00:08:21.900 
and there is much more noise
included in the image to make

115
00:08:21.900 --> 00:08:26.080 
the task more difficult. Now
applying this algorithm

116
00:08:27.540 --> 00:08:29.560 
yields those
five patches,

117
00:08:30.280 --> 00:08:33.610 
which is exactly what we are
looking for. We want to look at

118
00:08:33.620 --> 00:08:37.080 
only the salient parts in the
image that are important for the

119
00:08:37.240 --> 00:08:43.080 
task at hand. In this case, the
final aggregated vector is used

120
00:08:43.080 --> 00:08:46.590 
to make the prediction which
will yield the correct number

121
00:08:46.790 --> 00:08:48.510 
or digit, which is five.

122
00:08:50.040 --> 00:08:53.300 
Of course we could also
look at more pixels and

123
00:08:53.780 --> 00:09:01.160 
more patches and this will yield many
redundant patches around the signal

124
00:09:01.350 --> 00:09:05.760 
but also including some noise
which indicates that this is

125
00:09:05.760 --> 00:09:09.850 
maybe too much and we could stop
before and maybe extract between

126
00:09:09.850 --> 00:09:11.440 
five and fifty patches.

127
00:09:13.900 --> 00:09:17.390 
In terms of performance, if we
compare a baseline that is applied

128
00:09:17.390 --> 00:09:20.590 
to the high resolution image
with a standard neural network,

129
00:09:20.810 --> 00:09:24.260 
we get an accuracy of
ninety two percent.

130
00:09:24.880 --> 00:09:28.820 
If we extract five patches, we
get already eighty six percent

131
00:09:28.820 --> 00:09:31.820 
which is not as good as the
baseline but it's a good start.

132
00:09:32.330 --> 00:09:36.960 
If we then apply fifty patches
to the problem, we outperform

133
00:09:36.960 --> 00:09:42.120 
the baseline by a large margin and we
achieve an accuracy of ninety nine percent.

134
00:09:42.460 --> 00:09:47.000 
More important though for this talk
is the energy that is consumed.

135
00:09:48.120 --> 00:09:53.670 
for the baseline and the patch approach.
For the baseline, looking at the original

136
00:09:53.900 --> 00:09:56.910 
high dimensional
image resolution,

137
00:09:57.630 --> 00:10:02.800 
the algorithm has to scan two
hundred and fifty thousand pixels.

138
00:10:03.420 --> 00:10:07.060 
With five patches we only have
to look at nine percent of it

139
00:10:07.460 --> 00:10:12.120 
and with fifty patches we can reduce
the energy consumption by half

140
00:10:12.370 --> 00:10:14.910 
even though we outperformed
the baseline model.

141
00:10:15.880 --> 00:10:19.790 
Now imagine, we would scale this
image up to one thousand five

142
00:10:19.790 --> 00:10:23.280 
hundred pixels times one thousand
five hundred pixels and we

143
00:10:23.290 --> 00:10:26.040 
again look at the baseline
and the energy consumption.

144
00:10:26.540 --> 00:10:30.010 
In this case the
network has to

145
00:10:30.940 --> 00:10:36.390 
scan and analyze over two
million pixels and if we look

146
00:10:36.390 --> 00:10:40.050 
at our patch approach,
this will result in an

147
00:10:40.490 --> 00:10:44.980 
energy consumption compared with
only two to seven percent

148
00:10:44.980 --> 00:10:49.700 
of those two million pixels. To put
this a little bit into perspective,

149
00:10:49.820 --> 00:10:53.960 
we have seen in the introductory
slides the energy consumption

150
00:10:53.960 --> 00:10:57.850 
of a large scale natural language
processing a model which

151
00:10:58.150 --> 00:11:01.260 
resulted in an energy
consumption or footprint

152
00:11:02.100 --> 00:11:04.670 
of CO2 emissions
of an

153
00:11:05.540 --> 00:11:07.430 
average American adult

154
00:11:08.110 --> 00:11:13.010 
over a period of two years.
If we now apply our system

155
00:11:13.520 --> 00:11:17.880 
to this problem and we develop
the algorithm over a period

156
00:11:17.880 --> 00:11:21.590 
of six months as
compared to the study,

157
00:11:22.230 --> 00:11:27.060 
we can reduce the carbon
footprint to two to seven weeks,

158
00:11:27.690 --> 00:11:33.410 
which is a considerable reduction
in energy consumption. And

159
00:11:33.410 --> 00:11:38.730 
the same holds also for inference if
you put such a system into production.

160
00:11:40.610 --> 00:11:45.890 
In summary, we have seen that neural
networks show an exponential growth

161
00:11:46.080 --> 00:11:49.420 
in compute resources and
therefore also in energy.

162
00:11:50.500 --> 00:11:53.720 
We have seen that there
are many applications

163
00:11:54.520 --> 00:11:59.010 
that use large scale images.
Among them is radiology,

164
00:11:59.590 --> 00:12:03.880 
is pathology but also
is autonomous driving.

165
00:12:05.250 --> 00:12:08.750 
We have also seen that the compute
resources, if we don't do

166
00:12:08.750 --> 00:12:12.520 
anything about it, typically scale
with the image resolution.

167
00:12:13.630 --> 00:12:19.190 
And we have seen an example how we can
reduce the energy consumption considerably

168
00:12:19.410 --> 00:12:21.960 
while we are improving
on the accuracy.

169
00:12:23.570 --> 00:12:26.520 
If you want to stay up to date
about this project and you want

170
00:12:26.520 --> 00:12:31.320 
to see how we apply this to
medical images, you can check the

171
00:12:31.900 --> 00:12:33.980 
page on the screen
from time to time.

172
00:12:35.990 --> 00:12:38.500 
With this I want
to conclude

173
00:12:39.110 --> 00:12:40.170 
and thank you
for watching.
