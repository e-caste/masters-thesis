WEBVTT

1
00:00:01.030 --> 00:00:05.440 
Hello and welcome to this course!
the purpose of it is that you

2
00:00:05.440 --> 00:00:10.610 
understand what is hardware
acceleration, when to use it and why.

3
00:00:10.930 --> 00:00:15.740 
but also show you what is memory
guarantee and why it is so interesting.

4
00:00:17.030 --> 00:00:20.270 
we'll go through the different existing
architecture of acceleration

5
00:00:20.500 --> 00:00:24.340 
and present you CAPI and openCAPI
so that you can understand

6
00:00:24.340 --> 00:00:26.290 
the power of this
great evolution.

7
00:00:27.110 --> 00:00:30.830 
I'm Bruno Mesnet and working
on openCAPI implement and

8
00:00:30.830 --> 00:00:35.510 
IBM company and I am delighted to share
with you this awesome technology.

9
00:00:39.110 --> 00:00:43.930 
did you ever dream that your function
would be up to x30 faster?

10
00:00:44.700 --> 00:00:47.650 
when cutting in half the latency
of your function help?

11
00:00:48.300 --> 00:00:53.690 
and how about increasing bandwidth
to your has memory by 1.5x?

12
00:00:54.010 --> 00:00:57.940 
if so, I think hardware
acceleration can really help.

13
00:01:00.820 --> 00:01:07.280 
you may all know it for
decades, it was there. today

14
00:01:07.290 --> 00:01:08.650 
this is no longer
true. indeed

15
00:01:10.130 --> 00:01:14.030 
CPUs are being asked to it
could be more and more

16
00:01:14.040 --> 00:01:18.490 
leading to slower performance.
application functions are becoming

17
00:01:18.500 --> 00:01:23.630 
increasingly complex leading
to longer run times.

18
00:01:23.630 --> 00:01:28.930 
memory devices and data access
requirements are increasing speed

19
00:01:29.050 --> 00:01:35.380 
outpacing CPUs. and this leads to the
fact that with the current technology

20
00:01:35.520 --> 00:01:37.470 
hardware is overloaded.

21
00:01:38.400 --> 00:01:42.240 
and you know what, bad news.
it's only going to get worse.

22
00:01:44.560 --> 00:01:47.430 
the next set of chance
is already here.

23
00:01:48.050 --> 00:01:53.340 
you all know that we are generating
more and more data, even more

24
00:01:53.460 --> 00:01:56.080 
these data are very
often constructed.

25
00:01:56.820 --> 00:02:01.430 
and we now all want the result of the
processing of this data in real-time.

26
00:02:02.130 --> 00:02:06.310 
so let's take an example to understand
numbers. just think about that

27
00:02:06.310 --> 00:02:08.840 
you have one
terabyte of data.

28
00:02:09.500 --> 00:02:14.430 
it will take roughly twenty seconds to be
ingested across a four by hundreds Gigabyte

29
00:02:14.650 --> 00:02:18.430 
per second network. as we
can see the answers that

30
00:02:20.660 --> 00:02:26.790 
and today machine learning algorithm
is more and more complex operation

31
00:02:27.440 --> 00:02:31.370 
and you've understood the need for
a real revolution in computing

32
00:02:31.380 --> 00:02:33.100 
search and networking.

33
00:02:35.150 --> 00:02:40.600 
these challenges affect virtually
all computing fields from those

34
00:02:40.640 --> 00:02:46.170 
that need to process and analyze video
images and streams useful surveillance

35
00:02:47.050 --> 00:02:51.840 
to real-time banking and
financial data analysis

36
00:02:52.030 --> 00:02:53.930 
like for credit card
fraud detection.

37
00:02:55.040 --> 00:02:59.740 
but really this challenge affects any
fields, but needs a good algorithm

38
00:02:59.740 --> 00:03:04.750 
acceleration, compression encryption,
or meshing and deep learning.

39
00:03:06.920 --> 00:03:10.460 
ok. so now that's a chip, is
it software or hardware?

40
00:03:11.670 --> 00:03:16.470 
the software provides a faster time to
market low-cost and portable variables

41
00:03:16.470 --> 00:03:22.450 
to platforms. but the general complex
algorithm is slow the execute.

42
00:03:23.820 --> 00:03:27.360 
so hardware? it can
return really faster

43
00:03:28.590 --> 00:03:32.960 
with reduced power consumption
and lower latency due to

44
00:03:32.960 --> 00:03:39.380 
increased parallelism and bandwidth. however,
the hardware is more difficult to design. so

45
00:03:39.820 --> 00:03:44.250 
often less possible due to coding
language and recording requirements

46
00:03:44.250 --> 00:03:46.190 
between different
hardware platforms.

47
00:03:47.630 --> 00:03:51.740 
so isn't there a solution taking
only advantage of both?

48
00:03:54.460 --> 00:03:59.240 
the solution comes with what we
call hardware acceleration and

49
00:03:59.240 --> 00:04:03.480 
there may be two options, GPUs
which have thousands of

50
00:04:03.490 --> 00:04:08.160 
GPUs design with highly parallelization
logic leading to very fast run time

51
00:04:08.160 --> 00:04:09.510 
and results.

52
00:04:10.150 --> 00:04:16.580 
and if J which are programmed for your logic
and aisles to meet your exact needs.

53
00:04:16.980 --> 00:04:20.220 
GPUs are fast and why f
and j are real-time?

54
00:04:21.010 --> 00:04:25.480 
meaning with predictable latency
and this makes all the difference

55
00:04:25.490 --> 00:04:27.750 
especially for data A
position for example.

56
00:04:28.940 --> 00:04:33.540 
so let's focus of this already
own effigy technology which

57
00:04:33.540 --> 00:04:34.450 
could be the solution.

58
00:04:37.470 --> 00:04:39.930 
In fact, FPGAs
are very famous

59
00:04:41.140 --> 00:04:44.880 
for the complexity to code them
and exotic languages such as

60
00:04:44.880 --> 00:04:46.510 
VHDL.

61
00:04:47.560 --> 00:04:51.530 
this has always been totally
unaffordable for a suffering coder.

62
00:04:51.980 --> 00:04:54.590 
once you have the expertise
to write some code,

63
00:04:55.100 --> 00:04:59.600 
it is very point, well what
we called synthesis,

64
00:04:59.670 --> 00:05:03.300 
and mate into logic cells and
then programmed on FPGA.

65
00:05:04.290 --> 00:05:06.030 
well, this is
hopefully the most.

66
00:05:08.510 --> 00:05:11.190 
thanks to new compilers
an intelligence

67
00:05:11.940 --> 00:05:18.230 
analyzer, FPGA can be programmed using
C and C++ in a friendly environment

68
00:05:18.960 --> 00:05:22.880 
with built-in facilities to handle
all the complex stuff and

69
00:05:22.880 --> 00:05:26.640 
let the code focusing on
the algorithm by itself.

70
00:05:27.360 --> 00:05:31.700 
the open source framework OC-ACCEL
which is the follow one of SNAP.

71
00:05:31.910 --> 00:05:36.350 
it was designed on purpose to on service,
no need to have specific congregate

72
00:05:36.350 --> 00:05:39.610 
skills to program FPGA
of any code can do it.

73
00:05:40.330 --> 00:05:43.830 
and we will come back deeper
on that in the next course.

74
00:05:45.520 --> 00:05:47.610 
so what is an FPGA?

75
00:05:48.270 --> 00:05:52.160 
think about the pretty fine resource
that you connect, and to order

76
00:05:52.160 --> 00:05:56.260 
such as together they build the
logic you want when your function.

77
00:05:57.390 --> 00:06:02.180 
all these resources are physically
connected in the reprogrammable chip

78
00:06:02.410 --> 00:06:04.310 
using a programmable
switch.

79
00:06:05.250 --> 00:06:08.160 
you also choose FPGA
board you need,

80
00:06:08.850 --> 00:06:11.190 
which will contain the
resource you need.

81
00:06:12.060 --> 00:06:15.900 
and meaning different types of
memory or specific layers.

82
00:06:16.650 --> 00:06:20.280 
you also choose the FPGA on the
board for the amount of logic

83
00:06:20.290 --> 00:06:25.370 
and the specific resource you want defining
it, such as an R processor, very high

84
00:06:25.720 --> 00:06:28.440 
speed transceiver or a
hinder button with memory.

85
00:06:31.750 --> 00:06:36.030 
now that we have looked at the concept
of hardware acceleration FPGA.

86
00:06:36.420 --> 00:06:38.050 
let's have a look at the
different ways to access them.

87
00:06:43.090 --> 00:06:48.090 
as an example, let's consider comparing data
in hostmemory vs in the cloud or network.

88
00:06:50.720 --> 00:06:54.920 
in the standard CPU you set up
without any acceleration, the CPU

89
00:06:54.920 --> 00:07:00.310 
access the data from the host memory
handle application and function

90
00:07:00.550 --> 00:07:04.730 
and output data to the network or
the cloud through a network card.

91
00:07:05.790 --> 00:07:12.600 
when the challenges we previously discussed
the CPU gets overburden and slows while

92
00:07:12.940 --> 00:07:15.040 
and the network
communication burns down.

93
00:07:17.490 --> 00:07:19.990 
so this is our
starting point.

94
00:07:21.650 --> 00:07:27.960 
now in classic HW acceleration,
FPGA is introduced to relieve

95
00:07:27.970 --> 00:07:31.230 
the specific function needing
acceleration from the CPU.

96
00:07:31.760 --> 00:07:36.160 
this lightens the duty of the
CPU and allows for facile

97
00:07:36.160 --> 00:07:38.560 
functional execution
on the FPGA.

98
00:07:40.010 --> 00:07:44.360 
however, the CPU still handles
all the data and memory

99
00:07:44.630 --> 00:07:46.300 
and facing the
host memory.

100
00:07:47.160 --> 00:07:50.950 
in fact, the CPU must now copy
the data needed by the FPGA

101
00:07:50.960 --> 00:07:55.540 
onto the FPGA thus
making another

102
00:07:55.990 --> 00:07:58.040 
separate copies
of the data.

103
00:07:58.660 --> 00:08:04.190 
this is a lack of data coherency as
wrong time and data management issues.

104
00:08:08.340 --> 00:08:12.830 
at this point adding FPGA to
a CPU moved the problem

105
00:08:13.410 --> 00:08:14.940 
what does not serve.

106
00:08:17.870 --> 00:08:19.920 
that I do weld as
you can imagine

107
00:08:20.810 --> 00:08:25.370 
would be that the FPGA could be
master and access only the

108
00:08:25.370 --> 00:08:28.400 
data he needs right
from the host memory.

109
00:08:29.790 --> 00:08:36.800 
this is exactly what CAPI and OpenCAPI do. CAPI
stands for coherent access process interface.

110
00:08:37.070 --> 00:08:41.420 
no software driver, no data
copy. this means that

111
00:08:42.220 --> 00:08:48.420 
saving CPU and memory originally used
by the driver, but also bandwidth

112
00:08:49.370 --> 00:08:54.320 
to the host memory. this means also to simplify
the codings since CPU and FPGA can share

113
00:08:54.510 --> 00:08:57.830 
the same memory area
using the same address.

114
00:09:03.510 --> 00:09:08.040 
we can now have the best of
both wealthes, OC-Accel gets

115
00:09:08.050 --> 00:09:11.340 
the advantage of software
development while exhibiting the

116
00:09:11.340 --> 00:09:16.210 
software function of the FPGA relates
to the slow software run time.

117
00:09:17.350 --> 00:09:22.050 
on the hardware side, FPGA meets
or exceeds their advantage one

118
00:09:22.070 --> 00:09:24.550 
OC-Accel address
or the issues.

119
00:09:25.760 --> 00:09:31.070 
in fact, by adding the CAPI
or OpenCAPI attach FPGA.

120
00:09:31.500 --> 00:09:34.230 
we're just changing the
server architecture.

121
00:09:35.100 --> 00:09:40.980 
for the CPU smoothly moving
to a memory century server.

122
00:09:41.700 --> 00:09:46.830 
the FPGA is the master and is
considered now by the system

123
00:09:46.840 --> 00:09:50.170 
as appear to the other
cores of your system.

124
00:09:52.970 --> 00:09:55.820 
we are already in the third
generation of CAPI.

125
00:09:56.740 --> 00:09:59.050 
In P8 we just
have CAPI1.0.

126
00:09:59.850 --> 00:10:03.960 
In P9 we now have
a CAPI2.0 built

127
00:10:04.650 --> 00:10:08.550 
over the interface that
PCleGen4x8 interface

128
00:10:09.190 --> 00:10:12.590 
and is able to handle fourteen
gigabytes per second.

129
00:10:15.300 --> 00:10:21.140 
and now in P9, we had also the OpenCAPI3.0
using a specific high speed link

130
00:10:21.540 --> 00:10:25.950 
reaching twenty two gigabytes per seconds
and cutting the latency by two.

131
00:10:26.820 --> 00:10:28.260 
this is really awesome one.
Let´s summary things.

132
00:10:31.600 --> 00:10:36.910 
open copy provides not only a very
high bandwidth and very low latency,

133
00:10:37.140 --> 00:10:43.830 
but also direct access to host memory,
meaning keeping data coherency.

134
00:10:44.750 --> 00:10:49.080 
on top of that CPU is free
and coding becomes simple.

135
00:10:50.290 --> 00:10:55.860 
Do you want to know more? just
contact us, following all of us.

136
00:10:55.870 --> 00:10:58.240 
we will be delighted to
answer all your questions.

137
00:10:58.900 --> 00:11:01.800 
thank you. thanks for listening
and have a good day!
