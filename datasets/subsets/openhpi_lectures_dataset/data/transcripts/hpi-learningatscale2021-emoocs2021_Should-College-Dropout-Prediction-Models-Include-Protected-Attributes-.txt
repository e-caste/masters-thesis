WEBVTT

1
00:00:01.240 --> 00:00:06.970 
hi my name is Renzhe Yu,
a phd candidate at a university of california, Irvine.

2
00:00:07.790 --> 00:00:13.840 
this paper titled should college dropout prediction models include protected attributes

3
00:00:14.280 --> 00:00:19.430 
is in collaboration with Hansol Lee and RenÃ© F.Kizilcec from Cornell university.

4
00:00:21.380 --> 00:00:26.560 
nowadays there have been an increasing number of early warning systems

5
00:00:26.890 --> 00:00:29.540 
adopted by higher education institutions,

6
00:00:30.050 --> 00:00:33.710 
which use student data to predict whether a student will drop

7
00:00:33.710 --> 00:00:39.560 
out of a course or a program and provide such information to instructors

8
00:00:39.780 --> 00:00:43.850 
academic advisors and other practitioners on campus.

9
00:00:45.850 --> 00:00:48.670 
why would we need his algorithmic systems ?

10
00:00:49.270 --> 00:00:54.450 
first increasing student retention or persistence is a central

11
00:00:54.450 --> 00:00:56.660 
policy goal in higher education,

12
00:00:57.390 --> 00:01:02.610 
also the limited human resources at institutions make it challenging

13
00:01:02.610 --> 00:01:06.350 
to address individual students risk just in time.

14
00:01:06.940 --> 00:01:12.380 
so data says the solutions such as these systems can help allocate

15
00:01:12.380 --> 00:01:15.530 
existing resources in a more efficient manner.

16
00:01:17.760 --> 00:01:22.550 
a controversial issue around such systems is whether the underlying

17
00:01:22.550 --> 00:01:26.110 
predictive model should include protected attributes.

18
00:01:26.840 --> 00:01:31.620 
protected attributes or characteristics based on which discrimination

19
00:01:31.620 --> 00:01:39.840 
is prescribed as illegal, such as gender, race, age, religion and genetic information.

20
00:01:40.770 --> 00:01:45.580 
for one thing including them can better capture systematic inequalities

21
00:01:45.990 --> 00:01:49.190 
in the educational environment of different student groups,

22
00:01:49.700 --> 00:01:53.660 
which may well apply to future students from the same group.

23
00:01:54.610 --> 00:01:59.540 
at the same time however, stigmas and stereotypes could carry

24
00:01:59.540 --> 00:02:04.060 
over to future students and reproduce existing inequalities

25
00:02:04.410 --> 00:02:07.220 
when these models are put into practice.

26
00:02:09.560 --> 00:02:14.560 
in this context we examine the inclusion of protected attributes

27
00:02:14.890 --> 00:02:18.390 
in college dropout production in a real world setting,

28
00:02:18.960 --> 00:02:23.660 
and evaluate how this inclusion affects the overall performance

29
00:02:23.950 --> 00:02:26.230 
and fairness of the predictions.

30
00:02:27.390 --> 00:02:31.790 
specifically we construct a model to predict drop out after

31
00:02:31.790 --> 00:02:36.770 
the first year for over one hundred thousand online and residential

32
00:02:37.280 --> 00:02:40.830 
college students at a public university in the US.

33
00:02:41.900 --> 00:02:46.720 
the predictors include protected attributes incoming attributes

34
00:02:46.950 --> 00:02:50.160 
and students' college records in the first semester.

35
00:02:51.020 --> 00:02:56.560 
as in the actual use case, we use historical data to train the model

36
00:02:56.770 --> 00:02:59.200 
and test on the most recent core.

37
00:03:01.590 --> 00:03:03.980 
we train two identical models,

38
00:03:04.850 --> 00:03:10.460 
one with protected attributes caught aware
and one without them caught blind.

39
00:03:11.380 --> 00:03:15.830 
this table shows that across different algorithms whether we

40
00:03:15.830 --> 00:03:20.820 
include protected attributes or not in the model doesn't make a difference

41
00:03:21.010 --> 00:03:26.450 
on the overall performance as evaluated by accuracy recall

42
00:03:26.450 --> 00:03:29.620 
and should not be afraid or tnr in the model.

43
00:03:31.170 --> 00:03:37.610 
why importantly we want to evaluate the fairness
consequences of protected attributes?

44
00:03:38.170 --> 00:03:42.480 
what we mean by fair is that a model trained on a population ?

45
00:03:42.630 --> 00:03:45.670 
should have equal performance on different sectors.

46
00:03:46.170 --> 00:03:51.720 
so we compare each pair of groups defined by a protected attribute

47
00:03:51.830 --> 00:03:56.340 
such as male and female, and check the differences on the three

48
00:03:56.340 --> 00:03:58.350 
performance metrics between them.

49
00:03:59.330 --> 00:04:00.870 
we plot the result here,

50
00:04:02.160 --> 00:04:06.620 
which show that while the predictions are biased against some

51
00:04:06.870 --> 00:04:12.430 
groups in most cases. this fairness or bias level is not much

52
00:04:12.440 --> 00:04:17.200 
affected by the inclusion or exclusion of protected attributes.

53
00:04:19.450 --> 00:04:23.090 
we then take a deeper dive into the model's prediction behavior.

54
00:04:23.740 --> 00:04:28.750 
this plots illustrate how to ranking of individual protections change

55
00:04:28.870 --> 00:04:32.160 
after we include protected attributes in the model.

56
00:04:32.960 --> 00:04:38.100 
the take away is that including protected attributes will marginally equalize the

57
00:04:38.860 --> 00:04:43.420 
predicted drop out per probabilities between different subgroups,

58
00:04:43.980 --> 00:04:47.980 
which may lead to slightly higher fairness levels.

59
00:04:49.840 --> 00:04:55.520 
so overall our results marginally suggest that in the context

60
00:04:55.520 --> 00:04:59.630 
of a college drop a prediction including protected attributes

61
00:04:59.640 --> 00:05:03.060 
is better than not doing so for the sake of fairness.

62
00:05:03.790 --> 00:05:08.960 
in addition our visual approach presents a way of auditing for

63
00:05:09.060 --> 00:05:12.620 
fairness with regard to multiple protected attributes.

64
00:05:13.290 --> 00:05:17.870 
finally our comprehensive analysis reveals the general challenge

65
00:05:18.130 --> 00:05:23.220 
of accurately predicting drop-out which will be part of our future work.

66
00:05:24.250 --> 00:05:28.740 
thank you and please read our paper for to find
more detailed information.
