WEBVTT

1
00:00:03.000 --> 00:00:12.000 
We can do count, sum, average, median, maximum,
minimum and more. So this is just starting

2
00:00:12.000 --> 00:00:19.000 
there more functions for OLAP. And than they
are basically in this functions, which are

3
00:00:19.000 --> 00:00:27.000 
coded by stored procedures or with stored
procedures inside the system. Just to look

4
00:00:27.000 --> 00:00:33.000 
at how they could play here we have one example
on the table.

5
00:00:33.000 --> 00:00:39.000 
We count the citizens per country.

6
00:00:39.000 --> 00:00:47.000 
The system is running now through the attribute
vector and calculates whenever there is a

7
00:00:47.000 --> 00:00:53.000 
new country than there is a new entry in the
result.

8
00:00:53.000 --> 00:01:03.000 
And for each country we add up now the number
of occurrences and in the end when we are

9
00:01:03.000 --> 00:01:05.000 
done with the table, [...]

10
00:01:05.000 --> 00:01:14.000 
When we are through we go back in the dictionary
and fetch now with the value IDs of the countries

11
00:01:14.000 --> 00:01:29.000 
and we have results: USA 3, UK 1, Germany
1. It is relatively simple.

12
00:01:29.000 --> 00:01:40.000 
We can build the applications by using these
functions and this is a huge advantage. The

13
00:01:40.000 --> 00:01:52.000 
main point we have to put in here is performing
these calculations inside the database. We

14
00:01:52.000 --> 00:02:01.000 
do comparisons on the Integer level and we
do calculations on the Integer level inside

15
00:02:01.000 --> 00:02:05.000 
the database and then the values are converted
back on the way to results.

16
00:02:05.000 --> 00:02:19.000 
Result sets - we have not discussed that so
far. Result sets can only be of limited size.

17
00:02:19.000 --> 00:02:26.000 
Why? It does not mean anything to give the
user or results back of 8 billion tuples.

18
00:02:26.000 --> 00:02:36.000 
Nobody can do anything with that. So a meaning
for a result set has to be digestible by a

19
00:02:36.000 --> 00:02:43.000 
human. Result sets for a machine we want to
copy all the people living in the world and

20
00:02:43.000 --> 00:02:49.000 
sent this data set to somebody else is it
different question, we can do this with the

21
00:02:49.000 --> 00:02:57.000 
same SQL but result sets for humans have to
be meaningful. In order to be meaningful they

22
00:02:57.000 --> 00:03:03.000 
have to be small enough that they can be digested.
It does not mean anything to produce a result

23
00:03:03.000 --> 00:03:10.000 
set of 10,000 tuples. Nobody can digest this,
I would say that 1,000 is probably already

24
00:03:10.000 --> 00:03:19.000 
upper limit. Thousand even if we page through
sequentially and we have 100 on the page,

25
00:03:19.000 --> 00:03:25.000 
this is 10 pages, if we have 10 on the page
it is 100 pages, nobody looks through a list

26
00:03:25.000 --> 00:03:33.000 
of 100 pages. The programmers might think,
this is a good result and flip through the

27
00:03:33.000 --> 00:03:44.000 
list. People are not doing this.
SAP introduced R3, so in the 90Â´s, to cope

28
00:03:44.000 --> 00:03:51.000 
with the larger results that on top of the
results which came back from the database

29
00:03:51.000 --> 00:03:59.000 
the application can set filters and shows
only selected values. So you could select

30
00:03:59.000 --> 00:04:05.000 
by date, you could sort the results, so the
application worked on the top of the results

31
00:04:05.000 --> 00:04:12.000 
again. In the in-memory database we would
not do this anymore. We would work in the

32
00:04:12.000 --> 00:04:16.000 
database. So the database performance is so
much higher that it does not mean anything

33
00:04:16.000 --> 00:04:25.000 
to first select a larger data set, bring this
in the application and than work on this larger

34
00:04:25.000 --> 00:04:31.000 
data set. In the old days the data acquisition
was the expensive part, now the data acquisition

35
00:04:31.000 --> 00:04:37.000 
is the cheap part. So we let the database
do it and as a consequence of that we push

36
00:04:37.000 --> 00:04:50.000 
as much of the selection of the aggregation
functions into the database.

37
00:04:50.000 --> 00:04:59.000 
That means, in an application which has an
interaction with the user and we gather what

38
00:04:59.000 --> 00:05:05.000 
the user wants to do, so he wants to see Italy,
he wants to see the male, than we push this

39
00:05:05.000 --> 00:05:11.000 
into account, than we push this down into
database and we get the smallest possible

40
00:05:11.000 --> 00:05:20.000 
results back to the application. If the user
has a next query than we go back into the

41
00:05:20.000 --> 00:05:30.000 
database. This will show in statistics as
more transactions, instead of sitting in one

42
00:05:30.000 --> 00:05:36.000 
transaction and play with the data the user
goes back in place where is the original database.

43
00:05:36.000 --> 00:05:43.000 
I believe this is clearly the better solution
than to have a multi-step processes, much

44
00:05:43.000 --> 00:05:52.000 
easier to program and it is most likely the
higher performance anyways and it is in overall

45
00:05:52.000 --> 00:06:02.000 
cost probably also the clearly better solution,
so push as much as possible down to the database.

46
00:06:02.000 --> 00:06:07.000 
Especially when it is standard functions,
when it is not standard functions, so when

47
00:06:07.000 --> 00:06:16.000 
we have to write an individual stored procedure,
than probably it turns around, that the stored

48
00:06:16.000 --> 00:06:26.000 
procedure should not be extremely complicated
and with heavy application logic the boarder

49
00:06:26.000 --> 00:06:33.000 
line is, does an application you need in financials
or in sales order time currency conversion.

50
00:06:33.000 --> 00:06:41.000 
Currency conversion is not trivial. There
are many rules and there is some complexity

51
00:06:41.000 --> 00:06:50.000 
involved, there are tables involved, which
permanently change the content, the values

52
00:06:50.000 --> 00:07:05.000 
are changing of exchange rates. This is boarder
line to push this down into the database.

53
00:07:05.000 --> 00:07:12.000 
There is more applications specific logic,
which better stays in the application: exception

54
00:07:12.000 --> 00:07:25.000 
handling, anything which has to do with presentation
anyway, so that should stay in the application.

55
00:07:25.000 --> 00:07:34.000 
Everything which is clean math, despite this
is not really 100% precise term, clean math

56
00:07:34.000 --> 00:07:43.000 
should go down into the database. The database
calculates at least a factor 100 faster than

57
00:07:43.000 --> 00:07:53.000 
for example in SAP or an compiled ABAP program
calculates and even Java calculates many many

58
00:07:53.000 --> 00:08:00.000 
times slower than the database because of
the nature of the Integer and the direct access

59
00:08:00.000 --> 00:08:10.000 
to the data. So push as much as possible.
When we take now programs written 15 years

60
00:08:10.000 --> 00:08:19.000 
ago, in the earlier days, of SQL and rewrite
them, the experience is that a lot of code

61
00:08:19.000 --> 00:08:26.000 
can be eliminated because of a lot of functionality
can be just described in the clarity form

62
00:08:26.000 --> 00:08:32.000 
a SQL statement and push down into database
so the first experience in the SAP is by rewriting

63
00:08:32.000 --> 00:08:41.000 
programs, pushing down everything into database,
old programs is that 70-80% of the code can

64
00:08:41.000 --> 00:08:49.000 
be eliminated. So huge simplification, this
is not new, this have been done earlier. The

65
00:08:49.000 --> 00:09:00.000 
reason if you want to know why SAP did not
use stored procedures and calculation inside

66
00:09:00.000 --> 00:09:07.000 
the database, when we started 20 years ago
the first database was slow, relatively slow

67
00:09:07.000 --> 00:09:14.000 
and we took everything away from the database
as much as possible and any extension beyond

68
00:09:14.000 --> 00:09:20.000 
the primitive SQL functions were different
and they had different implementations and

69
00:09:20.000 --> 00:09:26.000 
different databases and the decision was to
support multiple databases, so therefore SAP

70
00:09:26.000 --> 00:09:32.000 
never used stored procedures and when you
do not use the stored procedures, than you

71
00:09:32.000 --> 00:09:42.000 
do not use OLAP aggregate functions, so we
used only the primitive ones, now it is just

72
00:09:42.000 --> 00:09:52.000 
the opposite as much as possible, either standard
SQL functions, extended SQL functions from

73
00:09:52.000 --> 00:10:01.000 
the OLAP world or the stored procedures individually
developed, so SAP has built a library for

74
00:10:01.000 --> 00:10:08.000 
business function and all kind of typical
business calculations in this library are

75
00:10:08.000 --> 00:12:08.000 
optimized and can be invoked via SQL by the
application.
