WEBVTT

1
00:00:00.350 --> 00:00:04.010 
Hello my name is Stephan Lutz. I'm from IBM Technical Sales

2
00:00:04.010 --> 00:00:07.660 
for power systems in Germany and in this video I will talk

3
00:00:07.670 --> 00:00:10.850 
about high availability in power systems.

4
00:00:13.020 --> 00:00:16.300 
So, first of all why do we need high availability?

5
00:00:17.500 --> 00:00:21.230 
Of course if you went for example to an automatic

6
00:00:21.230 --> 00:00:24.090 
teller machine and want to get some money from your bank then

7
00:00:24.090 --> 00:00:28.180 
the system needs to be up always, all the time. It's during the

8
00:00:28.180 --> 00:00:32.130 
day, during the night all the time. And because of that you need

9
00:00:32.130 --> 00:00:34.990 
to avoid downtime. So the system does not

10
00:00:35.770 --> 00:00:37.810 
can't be down at any time.

11
00:00:38.660 --> 00:00:42.910 
Down times are divided into two parts - there are planned down

12
00:00:42.910 --> 00:00:48.050 
times and unplanned down times. So planned down times is for example

13
00:00:48.050 --> 00:00:51.320 
if you want to do a hardware upgrade or you want to repair

14
00:00:51.320 --> 00:00:56.390 
something or do a software update, installing firmware and things like that.

15
00:00:56.850 --> 00:01:01.590 
And there are also unplanned down times such as errors in the

16
00:01:01.590 --> 00:01:05.630 
machine or in the application, a hardware failure and things like that.

17
00:01:06.420 --> 00:01:09.760 
In the graph below you see that hardware failures

18
00:01:09.760 --> 00:01:12.940 
for example is only one percent of the outages

19
00:01:13.830 --> 00:01:18.250 
that occur in an application. Most of the

20
00:01:19.620 --> 00:01:24.060 
outages are planned down times and these down times of course

21
00:01:24.060 --> 00:01:25.900 
as I said need to be avoided.

22
00:01:30.250 --> 00:01:33.680 
To avoid down times and especially unplanned down times, you

23
00:01:33.680 --> 00:01:39.390 
can use some technologies. There are two basically of them.

24
00:01:39.620 --> 00:01:44.130 
One is an Internal-Managed technology and one is an External-Managed technology.

25
00:01:44.830 --> 00:01:49.120 
Internal managed means that you create a cluster of

26
00:01:49.130 --> 00:01:52.900 
servers in this case and the servers all talk to each other

27
00:01:52.910 --> 00:01:56.930 
inside a cluster and try to figure out if the partner is still

28
00:01:56.940 --> 00:01:58.320 
alive and still available.

29
00:01:59.090 --> 00:02:00.960 
If it's not available anymore,

30
00:02:01.560 --> 00:02:06.420 
one partner for example, then the system decides to take over the control

31
00:02:06.790 --> 00:02:10.230 
of the application from one system to another. But everything

32
00:02:10.230 --> 00:02:13.850 
inside this class is managed internally, inside a cluster.

33
00:02:15.190 --> 00:02:18.920 
Second possibility is the external managed high availability.

34
00:02:19.560 --> 00:02:23.040 
Here we are talking only about a single instance,

35
00:02:23.040 --> 00:02:25.960 
a single operating system with the application on top of it

36
00:02:26.330 --> 00:02:30.250 
and if this system a runs on a hardware,

37
00:02:30.680 --> 00:02:34.080 
and this hardware will fail, then we need an external instance

38
00:02:34.080 --> 00:02:40.670 
that discovers that issue and makes sure to restart that virtual machine,

39
00:02:40.820 --> 00:02:47.020 
that application on another system. We also talk about this technology,

40
00:02:48.230 --> 00:02:52.390 
about the term remote restart. So it's nothing else as remote restart.

41
00:02:55.090 --> 00:02:58.820 
Let's talk a little bit more about the internal managed concepts.

42
00:02:58.820 --> 00:03:02.500 
So the cluster technology, what you see here on the left hand

43
00:03:02.500 --> 00:03:08.330 
side is a single cluster, an active passive cluster. That means

44
00:03:08.330 --> 00:03:11.390 
we have one active side, in this case on the left hand side,

45
00:03:11.620 --> 00:03:14.440 
here we have the application running and if this

46
00:03:14.460 --> 00:03:17.240 
system is broken for whatever reason

47
00:03:17.950 --> 00:03:21.010 
the cluster partner two on the right hand side will take over

48
00:03:21.010 --> 00:03:24.410 
the control of the application. So it means it will access the

49
00:03:24.410 --> 00:03:29.580 
disks, it will take the IP address and make the IP available

50
00:03:29.580 --> 00:03:31.900 
on that system and then will start the application.

51
00:03:33.010 --> 00:03:37.310 
This is done by cluster systems or cluster technologies like

52
00:03:37.310 --> 00:03:41.710 
powerHA on power systems. This is a product that is available

53
00:03:41.710 --> 00:03:45.450 
for all operating systems. It's available for AIX, it's available for Linux

54
00:03:45.580 --> 00:03:48.660 
and it's also available for an IBM AI operating system.

55
00:03:49.860 --> 00:03:52.960 
On the right hand side we see an active active cluster.

56
00:03:53.630 --> 00:03:57.730 
That means we have a several systems, in this case four, that

57
00:03:57.730 --> 00:04:01.790 
are all working on the same disks, on the same data.

58
00:04:03.010 --> 00:04:06.750 
This concept is often used by parallel databases such as

59
00:04:06.750 --> 00:04:11.390 
DB2 pureScale or Oracle RAC. In this case if one of the cluster

60
00:04:11.390 --> 00:04:14.780 
partners fails for whatever reason, then that's not

61
00:04:15.280 --> 00:04:17.840 
not so important because we have still three

62
00:04:18.250 --> 00:04:21.040 
other partners in this case and then the three partners

63
00:04:21.580 --> 00:04:23.740 
have a little bit more work to do. But

64
00:04:25.420 --> 00:04:29.080 
in principle, there are still three partners that can work on the data and

65
00:04:30.250 --> 00:04:32.240 
work on the requests that will be

66
00:04:32.990 --> 00:04:34.250 
sent to the database.

67
00:04:38.710 --> 00:04:42.310 
Yeah, let's talk a little bit more about a simple

68
00:04:42.500 --> 00:04:46.540 
HA cluster. What we see here is a two node cluster,

69
00:04:46.540 --> 00:04:50.100 
node 1 and node 2. Each node has an application running and we

70
00:04:50.100 --> 00:04:55.160 
are working on a mirrored disk subsystem, so we have a synchronous mirror and two

71
00:04:55.960 --> 00:05:00.540 
storage subsystems and all the other parts are also of course

72
00:05:00.540 --> 00:05:04.690 
redundant. So we have a redundant access to the network and

73
00:05:04.690 --> 00:05:07.260 
of course a redundant network to the disks.

74
00:05:08.360 --> 00:05:11.980 
So, something that is very important in such an environment is

75
00:05:12.100 --> 00:05:16.680 
to figure out if a component really failed, is broken, is

76
00:05:18.010 --> 00:05:22.840 
is off so to say because let's imagine we do simply

77
00:05:22.840 --> 00:05:27.620 
just an IP ping over the network from node 2 to node 1 for example,

78
00:05:27.950 --> 00:05:31.760 
and if this ping doesn't work anymore. Can we then be sure that

79
00:05:31.760 --> 00:05:37.150 
the system is really broken? No, we can't because perhaps there is

80
00:05:37.470 --> 00:05:43.290 
somebody working on the network lines and simply cut the lines between the two

81
00:05:43.490 --> 00:05:47.300 
nodes. In this case the IP connection would be broken but the

82
00:05:47.300 --> 00:05:50.700 
system is still alive and is still working on the data on the disks.

83
00:05:51.250 --> 00:05:55.100 
So therefore we need a set a separate way to figure out

84
00:05:55.110 --> 00:05:56.740 
if a system is really broken.

85
00:05:57.820 --> 00:06:01.920 
And we do this in a cluster with heart beats and as I said,

86
00:06:01.920 --> 00:06:05.890 
we need at a minimum two ways of doing that. So in this

87
00:06:05.890 --> 00:06:09.130 
case as you see here we have an IP heart beat over a network

88
00:06:09.340 --> 00:06:13.700 
and we also do a storage heart beat. And if we figure out

89
00:06:13.700 --> 00:06:17.350 
the IP connection is broken and there is no traffic anymore on

90
00:06:17.350 --> 00:06:22.940 
the storage then we can be sure that the system is out of business, is

91
00:06:23.460 --> 00:06:24.790 
in error state for example.

92
00:06:27.040 --> 00:06:30.060 
Well, now what can happen in such an environment?

93
00:06:30.060 --> 00:06:33.120 
If a storage fails this is not so important because

94
00:06:33.120 --> 00:06:37.690 
we have a mirror subsystem so the applications can still run on their

95
00:06:38.090 --> 00:06:40.570 
own nodes, but only with one storage

96
00:06:41.190 --> 00:06:43.950 
subsystem with only one mirror but it's okay

97
00:06:44.610 --> 00:06:50.530 
for a while. If a whole node fails and as I said we need to

98
00:06:50.530 --> 00:06:54.390 
discover that over a minimum of two ways. If that happens then

99
00:06:54.390 --> 00:06:58.480 
the application will be moved to the second node. So the application

100
00:06:58.480 --> 00:07:02.830 
LPAR 1 will be moved to node 2 and will then run on this system.

101
00:07:03.410 --> 00:07:07.230 
The take over of course will take some minutes usually but

102
00:07:07.240 --> 00:07:11.650 
this could be done automatically and the system will be back after

103
00:07:11.890 --> 00:07:13.070 
a short amount of time.

104
00:07:17.640 --> 00:07:23.570 
Let's talk a little bit more about disasters, disaster scenarios

105
00:07:23.570 --> 00:07:29.260 
or disaster recovery which is a separate topic in the availability space.

106
00:07:29.720 --> 00:07:35.970 
So what we see on the left hand side is for example an active

107
00:07:36.650 --> 00:07:40.840 
primary data centre or two data centres

108
00:07:42.150 --> 00:07:46.360 
in one area. So there we have two servers for example as we

109
00:07:46.360 --> 00:07:49.430 
see. One is the active one, one was the backup one and we have two

110
00:07:49.430 --> 00:07:54.400 
storages. So the same concept as we just saw in the active passive cluster

111
00:07:55.070 --> 00:07:57.210 
foils a minute ago.

112
00:07:57.990 --> 00:08:01.940 
We use a synchronous mirroring for that. So that means both

113
00:08:02.020 --> 00:08:06.580 
storages have the same data and they have it at the same

114
00:08:06.790 --> 00:08:10.460 
at the same time, so there is no time difference

115
00:08:10.770 --> 00:08:14.010 
until the second system gets the same data.

116
00:08:15.690 --> 00:08:19.290 
Yeah if a system fails there then it's no issue, as I said

117
00:08:19.490 --> 00:08:22.040 
before and then the second system will take over.

118
00:08:22.460 --> 00:08:25.890 
But now let's imagine we have a disaster, a big event happened,

119
00:08:25.890 --> 00:08:30.610 
a fire or a power outage or a tornado or hurricane or whatever.

120
00:08:31.500 --> 00:08:36.370 
Then in such a case, often both systems are perhaps

121
00:08:36.370 --> 00:08:39.990 
not running anymore and we need a backup solution for that too.

122
00:08:40.760 --> 00:08:45.980 
In this case, customers often use so called DR data centers.

123
00:08:46.360 --> 00:08:51.030 
That means first of all, we go in a data center that is

124
00:08:51.100 --> 00:08:55.290 
many many kilometers from the first one, from the primary one

125
00:08:57.300 --> 00:09:02.490 
away. So often we use there hundreds of kilometers or this could

126
00:09:02.790 --> 00:09:08.100 
also span over continents if you like. So in this case we have there another

127
00:09:08.510 --> 00:09:12.300 
data center with another system. So in this case for example

128
00:09:12.300 --> 00:09:18.040 
a DR system called CBU. This is a power term coiled capacity backup unit

129
00:09:18.270 --> 00:09:21.890 
that means that this server has only a minimum amount of resources

130
00:09:21.890 --> 00:09:24.700 
activated that could be used, so the system is up and running

131
00:09:25.010 --> 00:09:30.960 
and just or only in case of a disaster the additional resources

132
00:09:30.960 --> 00:09:34.530 
will be activated and then the workload can be transferred

133
00:09:34.540 --> 00:09:39.150 
to the DR side. From a storage point of view, we have also another

134
00:09:39.150 --> 00:09:41.230 
storage box on the

135
00:09:41.830 --> 00:09:45.780 
in the DR data centre with a third data copy

136
00:09:46.340 --> 00:09:50.950 
and here often we use asynchronous mirroring. So that means

137
00:09:52.010 --> 00:09:55.630 
the data there could be a little bit older than the data on

138
00:09:55.630 --> 00:09:59.820 
the previous data centre. But you need of course to think about

139
00:09:59.830 --> 00:10:02.810 
that if this is okay for you i mean

140
00:10:03.230 --> 00:10:06.300 
many customer for many customers this is ok because if you

141
00:10:06.300 --> 00:10:09.320 
have a real disasters then you have other issues and problems

142
00:10:09.710 --> 00:10:11.650 
then thinking about

143
00:10:13.730 --> 00:10:17.440 
the latest seconds of data that are missing. But it depends.

144
00:10:17.440 --> 00:10:21.140 
I mean if it's your bank account then you want to make sure that all

145
00:10:21.440 --> 00:10:25.510 
transfers of course are also on the DR size. So it depends what you want to

146
00:10:26.330 --> 00:10:29.580 
secure, what your environment your application is.

147
00:10:30.460 --> 00:10:32.620 
Such an environment it's also possible

148
00:10:33.810 --> 00:10:35.400 
to survive a disaster.

149
00:10:39.470 --> 00:10:44.010 
Okay, let's talk a little bit more about external managed availability

150
00:10:44.010 --> 00:10:48.230 
concepts. As I already said in this case we have only one operating

151
00:10:48.580 --> 00:10:52.860 
system in use and one application that is running on this operating

152
00:10:52.860 --> 00:10:55.180 
system. So in this case on the left server.

153
00:10:56.190 --> 00:10:59.420 
If the server is broken for whatever reason then an external

154
00:10:59.420 --> 00:11:02.680 
instance can figure out that it's broken

155
00:11:03.110 --> 00:11:08.960 
again over two ways for IP and storage usually and if it

156
00:11:08.960 --> 00:11:12.670 
sees the system is broken then it will initiate a transfer

157
00:11:12.680 --> 00:11:16.470 
or a remote restart. So it means the virtual machine which will

158
00:11:16.470 --> 00:11:21.680 
be rebuilt on the second system, the data will

159
00:11:21.890 --> 00:11:25.940 
be accessed, the disks will be accessed and the IP will be

160
00:11:26.750 --> 00:11:28.630 
also transferred to the second system.

161
00:11:29.340 --> 00:11:32.730 
Of course the minimum requirement for that is first of all

162
00:11:32.730 --> 00:11:35.650 
that your virtual machine is fully virtualized and that all

163
00:11:35.650 --> 00:11:39.590 
the resources that you need the disks and the IP ranges are

164
00:11:39.590 --> 00:11:43.960 
working on the backup side. This is absolutely necessary,

165
00:11:43.960 --> 00:11:45.330 
otherwise it will not work.

166
00:11:46.280 --> 00:11:49.730 
Yeah, with that you can move the application to the second side.

167
00:11:53.090 --> 00:11:56.510 
Okay how can we do this in power systems? In power systems we

168
00:11:56.510 --> 00:12:01.100 
have the HMC, hardware management console that is working on

169
00:12:01.100 --> 00:12:05.190 
the virtualization of power systems. With that you can also

170
00:12:05.190 --> 00:12:10.100 
start and stop virtual machines or define stuff. And this is also the instance

171
00:12:10.210 --> 00:12:14.720 
where you can initiate a remote restart. But in this case it's always

172
00:12:15.580 --> 00:12:22.370 
a manual take over. The HMC can't do that automatically.

173
00:12:22.930 --> 00:12:27.100 
And the reason is very simple the HMC only sees the power systems.

174
00:12:27.240 --> 00:12:31.520 
It has only a connection to the power system, it has no connection to the storage.

175
00:12:31.740 --> 00:12:36.210 
So in this case we only have one heartbeat or one possibility

176
00:12:36.210 --> 00:12:40.320 
to check if a system is really broken. And if only the network

177
00:12:40.320 --> 00:12:44.230 
connection is broken then again we have an issue because the

178
00:12:45.030 --> 00:12:50.040 
LPAR might be still up and running. So that's why the HMC can

179
00:12:50.050 --> 00:12:52.850 
do a remote restart but only in a manual

180
00:12:53.580 --> 00:12:56.890 
with a manual command. So the administrator that is doing or

181
00:12:56.890 --> 00:12:58.680 
executing the command needs to know

182
00:13:00.510 --> 00:13:03.670 
that it's okay and that he knows what he is doing.

183
00:13:04.990 --> 00:13:08.190 
Yeah, the command you can see are start LPAR and then they

184
00:13:08.190 --> 00:13:12.090 
simply say I want to restart an LPAR and you define what

185
00:13:12.090 --> 00:13:15.160 
is the source system and what is the target system and then the

186
00:13:15.260 --> 00:13:18.060 
LPAR will be rebuilt on the second system and started.

187
00:13:22.810 --> 00:13:26.640 
Third party tools. There are also third party tools but

188
00:13:27.290 --> 00:13:32.610 
external instances that can control this and make it automatically.

189
00:13:32.980 --> 00:13:37.120 
For example we have a product called VM recovery manager and

190
00:13:37.120 --> 00:13:41.210 
this product has also the possibility not only to have

191
00:13:41.210 --> 00:13:47.410 
a look on the server side but this one can also look into the storage environment.

192
00:13:47.770 --> 00:13:52.630 
So if you have an external storage like a SAN environment with SAN storage behind

193
00:13:52.960 --> 00:13:57.560 
this system that we are VM restart system the cases as mentioned here in the

194
00:13:58.060 --> 00:14:01.280 
graph, can have a look and sees if

195
00:14:02.170 --> 00:14:05.310 
if two heartbeats fail so the IP one and the storage one in

196
00:14:05.310 --> 00:14:09.790 
this case, it can automatically trigger a remote restart event

197
00:14:09.980 --> 00:14:12.610 
so that the virtual machine will be transferred to the second

198
00:14:12.610 --> 00:14:13.990 
side to the second system.

199
00:14:15.410 --> 00:14:18.750 
This is only one possibility. We have also other products like

200
00:14:18.750 --> 00:14:25.670 
powerVC for example. This is a openstack based virtualization management system.

201
00:14:25.990 --> 00:14:30.010 
There you also have the possibility to have an automatic remote restart.

202
00:14:30.410 --> 00:14:33.110 
So this is not the only one possible.

203
00:14:37.700 --> 00:14:41.920 
Okay, that's all I have. Thank you very much for your attention.
