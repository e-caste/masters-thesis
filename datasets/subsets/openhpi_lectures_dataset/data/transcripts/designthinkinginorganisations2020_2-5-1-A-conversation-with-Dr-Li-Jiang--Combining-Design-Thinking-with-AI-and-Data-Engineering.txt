WEBVTT

1
00:00:17.330 --> 00:00:23.390 
Welcome everyone to our class on mastering
design thinking in organizations

2
00:00:23.490 --> 00:00:28.070 
and today I have the great
pleasure to talk to Li Jiang who is a

3
00:00:28.070 --> 00:00:32.190 
PhD from Stanford University
and also a lecturer there for

4
00:00:32.200 --> 00:00:37.710 
AI in design thinking. So
welcome, Li, and maybe you want to

5
00:00:37.720 --> 00:00:42.480 
say a few words about yourself
as well and your career path.

6
00:00:49.970 --> 00:00:55.610 
I'm Li Jiang from Stanford
University and then by training

7
00:00:55.860 --> 00:01:01.670 
I'm focused on robotics
AI and also design thinking

8
00:01:01.980 --> 00:01:07.090 
because I also teach that.
I then have been working in the

9
00:01:07.090 --> 00:01:12.590 
field of robotics and AI for many
years and also design-thinking.

10
00:01:12.750 --> 00:01:17.560 
In the past five to six years I
also spent a lot of time in

11
00:01:17.560 --> 00:01:23.650 
the field of education in trying to figure
out what is the best strategy for

12
00:01:23.880 --> 00:01:29.230 
our education system to adapt
to the batsman of robotics at AI.

13
00:01:29.240 --> 00:01:34.060 
Li, since you're an expert
on artificial intelligence for

14
00:01:34.210 --> 00:01:39.700 
many years already, I was wondering if
you can maybe start this interview with

15
00:01:40.070 --> 00:01:44.640 
with describing from your own words
what would you think artificial

16
00:01:44.640 --> 00:01:49.110 
intelligence is and I'm also
interested to learn more about

17
00:01:49.110 --> 00:01:56.330 
where we are in the process. So is
AI already very mature

18
00:01:56.330 --> 00:02:01.050 
or are we in the beginning of the
process? Maybe let's start here.

19
00:02:01.200 --> 00:02:08.700 
So we are at the very beginning of
this era of machine intelligence.

20
00:02:08.930 --> 00:02:14.810 
Frankly speaking, that the breakthrough
we had in the past ten years

21
00:02:15.130 --> 00:02:20.100 
it's not like brand brand new
as some of these ideas were

22
00:02:20.110 --> 00:02:25.840 
pretty old. It's just because we had
enough computing power and data,

23
00:02:26.110 --> 00:02:32.600 
so that we can make those kind of old
algorithm work much much better.

24
00:02:33.180 --> 00:02:39.610 
And now we are as of twenty twenty
we are in the time that trying to

25
00:02:39.930 --> 00:02:43.820 
find more and more applications
and trying to find more data

26
00:02:44.100 --> 00:02:52.560 
so that we can make more use of AI. So
the foundation or the fundamental

27
00:02:52.850 --> 00:03:00.750 
changes are not happening as fast
as like a few years back. However

28
00:03:00.930 --> 00:03:07.790 
I would not say AI is slowing down. In fact
it is probably accelerating in

29
00:03:07.980 --> 00:03:12.880 
the way that effect your life because
they become more and more usable

30
00:03:13.190 --> 00:03:19.770 
and you will see a lot of things become
impacted by AI in your everyday life.

31
00:03:19.890 --> 00:03:24.910 
All the stuff that you're
using, all the apps in

32
00:03:24.910 --> 00:03:28.730 
the cell phones and other smart
devices around you, they will have

33
00:03:28.980 --> 00:03:34.100 
either simple or more complicated
AI algorithms in there, so

34
00:03:34.100 --> 00:03:39.310 
that it becomes smarter and
they can help you better. Yes.

35
00:03:40.000 --> 00:03:43.790 
So it's kind of like a,
right now we're in a time

36
00:03:43.790 --> 00:03:48.720 
frame where we will have more and more
applications with AI. Yeah.

37
00:03:48.730 --> 00:03:55.170 
When you look at the education, I
heard you talking about AI thinking

38
00:03:55.580 --> 00:03:58.660 
once in a lecture at
Stanford

39
00:03:59.420 --> 00:04:03.520 
and it somehow
stuck to my mind.

40
00:04:03.980 --> 00:04:10.130 
So is this new school of thinking that
is competing with design thinking or

41
00:04:10.250 --> 00:04:14.570 
what is it exactly and
can you differentiate this?

42
00:04:15.720 --> 00:04:20.660 
The notion of AI
thinking is that

43
00:04:21.090 --> 00:04:29.020 
we find a it is sometimes, we
feel it's, let's say, it

44
00:04:29.020 --> 00:04:35.270 
is a disadvantage of our current
education system that we only

45
00:04:35.270 --> 00:04:41.270 
teach AI or robotics related stuff
in the college or graduate school.

46
00:04:42.320 --> 00:04:47.230 
And it is not really available for,
let's say, K-12 students.

47
00:04:47.530 --> 00:04:51.820 
K12 students only get to
learn these, for example,

48
00:04:51.820 --> 00:04:55.790 
mathematics and then they start
to learn physics and chemistry

49
00:04:55.790 --> 00:04:59.630 
in middle school and that kind of
stuff. However the

50
00:05:00.260 --> 00:05:07.020 
in era of AI, this
technology will impact. Its

51
00:05:07.020 --> 00:05:10.820 
like a platform level
innovation or

52
00:05:11.840 --> 00:05:15.680 
change. It will pretty much
effect everything around you, so

53
00:05:15.680 --> 00:05:20.050 
that it will become a common sense
in the future that you need

54
00:05:20.050 --> 00:05:25.640 
to somehow understand the concept
of AI and how it works. If you don't

55
00:05:26.090 --> 00:05:30.880 
then you are actually in a
very, in a position that has

56
00:05:30.880 --> 00:05:35.780 
a lot of disadvantages of it. So you
don't even know how this device is working,

57
00:05:35.920 --> 00:05:41.890 
then you will be fooled by the device. For
example, if you have some news apps

58
00:05:42.070 --> 00:05:45.300 
and then you click the few buttons
and then all of sudden all

59
00:05:45.300 --> 00:05:51.120 
these news about that will come
and then you are surrounded

60
00:05:51.120 --> 00:05:55.550 
by this like really small bubble
and created by AI. If you really

61
00:05:55.550 --> 00:05:58.770 
don't know how AI works then
you feel that is the world.

62
00:05:58.780 --> 00:06:03.180 
No that's not the world, that's the
virtual world created by AI because AI

63
00:06:03.310 --> 00:06:07.960 
only feeds you with the information
that you might be interested in.

64
00:06:08.060 --> 00:06:13.520 
AI tries to guess what you're
interested in. So we pointed out this

65
00:06:13.760 --> 00:06:20.600 
AI thinking. We think it's something that
need to be understand by everyone,

66
00:06:20.830 --> 00:06:23.850 
not just engineering students, not
just computer science students,

67
00:06:23.850 --> 00:06:28.050 
it needs to be understood by
everyone and has three levels. So

68
00:06:28.050 --> 00:06:32.680 
the first level is that everyone need
to have a general understanding

69
00:06:32.720 --> 00:06:37.360 
of how AI works and the second
one, in the second level is that

70
00:06:37.480 --> 00:06:41.810 
you have the ability to differentiate
the human capability

71
00:06:42.200 --> 00:06:47.080 
and the machine capability which
is AI, or robot with AI. So

72
00:06:47.080 --> 00:06:50.830 
then you can differentiate and
a third one is that you get the

73
00:06:50.830 --> 00:06:56.850 
ability to work with
robots with AI or AI. So

74
00:06:56.860 --> 00:07:01.630 
these are the three levels and I don't
see AI thinking competing with

75
00:07:01.750 --> 00:07:06.810 
design thinking because they're actually
complementary. They're the two

76
00:07:06.950 --> 00:07:11.470 
important things that
the student need to know

77
00:07:11.590 --> 00:07:16.110 
together to have a better
life in the future, because

78
00:07:16.560 --> 00:07:21.860 
as I mentioned, our AI is still pretty
rudimentary and in which

79
00:07:21.860 --> 00:07:26.540 
sense a lot of these AI are basically
just doing mathematics mapping.

80
00:07:26.690 --> 00:07:32.400 
We have input, we map to the output
but then it's not that smart

81
00:07:32.400 --> 00:07:38.450 
but it is smart enough to do a lot of
repetitive mental and labour work

82
00:07:38.760 --> 00:07:45.270 
in the sense that it still don't
have human creativity. It might

83
00:07:45.270 --> 00:07:51.710 
never have human creativity. However
how to make us more creative,

84
00:07:52.000 --> 00:07:54.490 
that's the job lead
to design-thinking.

85
00:07:55.210 --> 00:07:57.840 
So they work together
in a very nice way.

86
00:07:58.390 --> 00:08:03.200 
Do you teach them both together
or what is your remedy for

87
00:08:03.200 --> 00:08:08.540 
helping young people? I mean, you mentioned
k12 students, right? So are you really

88
00:08:08.540 --> 00:08:13.240 
starting their early or in
school or how do you make

89
00:08:13.250 --> 00:08:19.870 
that? Here is the thing. For example,
in a design-thinking

90
00:08:19.870 --> 00:08:25.850 
class we only teach design thinking
in the sum of the experiment

91
00:08:25.850 --> 00:08:29.830 
class I teach, not really I have
already started teaching

92
00:08:29.830 --> 00:08:32.320 
some class that combined
AI thinking and

93
00:08:32.800 --> 00:08:37.610 
and some of like education
stuff like a few years back

94
00:08:37.610 --> 00:08:43.040 
at Stanford. So I want to raise
the awareness of this thing.

95
00:08:43.450 --> 00:08:50.990 
it's but then it gets a lot of
people attention. So AI thinking,

96
00:08:51.260 --> 00:08:58.590 
we think it need to be treated more
seriously by the k12 educators

97
00:08:58.850 --> 00:09:04.630 
so that we can start to introduce
that in the k12 schools

98
00:09:04.670 --> 00:09:09.710 
and for that actually I did some
experiment. So working with

99
00:09:09.750 --> 00:09:15.320 
some schools around Stanford
we actually gathered together

100
00:09:15.470 --> 00:09:21.910 
student from first grade all the way up
to twelfth grade and then I changed

101
00:09:22.180 --> 00:09:27.010 
the, you know, basically it's
the same kind of robotics AI

102
00:09:27.010 --> 00:09:31.490 
class that we teach at Stanford
but we must search the accountant,

103
00:09:31.500 --> 00:09:36.880 
get rid of the very heavy
mathematics but every mathematic

104
00:09:36.890 --> 00:09:40.900 
equation have a background
meaning. We teach the background meaning.

105
00:09:40.900 --> 00:09:45.730 
But you have to find a very smart
way to teach younger kids bout that though.

106
00:09:45.840 --> 00:09:49.590 
Like it takes really days and days of
thinking, what is the, you

107
00:09:49.590 --> 00:09:53.520 
know, right way to teach them but we
manage do that and then I ran

108
00:09:53.520 --> 00:09:57.710 
a experiment. So I teach them that
kind of like a graduate level

109
00:09:57.720 --> 00:10:02.390 
robotics class and what I found
is that actually most people

110
00:10:02.400 --> 00:10:08.100 
above third grade are able to
understand it completely. So shocking.

111
00:10:08.110 --> 00:10:11.970 
So which proves that we don't
need to wait until graduate

112
00:10:11.970 --> 00:10:17.330 
school to teach them that and another
thing I found is that

113
00:10:17.570 --> 00:10:24.400 
one class I taught them power
exoskeleton which means

114
00:10:24.400 --> 00:10:28.040 
that I told them, I
teach them armor suits

115
00:10:28.700 --> 00:10:32.920 
but armor suit have a scientific
name which is power exoskeleton,

116
00:10:32.970 --> 00:10:37.010 
a lot of researches do research
on it. And then in the class

117
00:10:37.120 --> 00:10:41.940 
I gave a talk a lot about armor suit
get them so excited and then

118
00:10:41.940 --> 00:10:46.060 
I gave them a
definition of power exoskeleton.

119
00:10:46.160 --> 00:10:50.010 
The first one is they have to
have a human inside the robot,

120
00:10:50.020 --> 00:10:54.940 
right, the humans inside the robot, and
then the robot need to amplify

121
00:10:55.890 --> 00:11:00.710 
that human's capability and then
at this time I remember is

122
00:11:00.710 --> 00:11:05.650 
a third grader, either a third grader
or even a second grade girl

123
00:11:05.710 --> 00:11:08.790 
raised her head and stand
up saying I have a question.

124
00:11:09.390 --> 00:11:16.210 
Are cars powered exoskeletons?
I was shocked and like

125
00:11:17.110 --> 00:11:21.100 
that's a very reasonable question
and I never ever thought

126
00:11:21.100 --> 00:11:24.590 
about that because you know
we're human, we are

127
00:11:24.600 --> 00:11:29.130 
adults, we're kind of trapped
by all the rules that we,

128
00:11:29.620 --> 00:11:36.900 
you know, we learned, right. So as a
sort of expert in robotics and AI

129
00:11:37.030 --> 00:11:41.410 
and who does research in this
field I actually never thought

130
00:11:41.410 --> 00:11:46.690 
about that car is a powered exoskeleton and I
checked with my colleagues and they're like

131
00:11:46.840 --> 00:11:51.120 
wow that's interesting because
they don't have these frames

132
00:11:51.120 --> 00:11:54.470 
in their mind. When they hear this
they're like cars are powered

133
00:11:54.470 --> 00:11:58.540 
xoskeleton. They are right.
Cars are powered exoskeleton.

134
00:11:59.340 --> 00:12:05.660 
Kids are looking at the world differently.
Right? Exactly, so we

135
00:12:05.660 --> 00:12:09.300 
should not be looking down upon
theri capability saying

136
00:12:09.300 --> 00:12:13.590 
hey you're too young to learn
is. No, they are ready as long as we

137
00:12:13.590 --> 00:12:16.600 
can provide the
correct methods.

138
00:12:17.020 --> 00:12:22.780 
So what can be learned as design
thinkers from that kind

139
00:12:22.780 --> 00:12:28.010 
of thinking? So, would you recommend TO
change in our curriculum something too?

140
00:12:28.460 --> 00:12:33.020 
And if yes, how should we do
that? I mean, by looking from

141
00:12:33.020 --> 00:12:37.080 
the design thinking lanes to AI.
I think design thinking is

142
00:12:37.080 --> 00:12:43.890 
a very nice and tangible way to teach
people how to create stuff, like

143
00:12:43.890 --> 00:12:49.820 
how to become more creative and
that's where AI is very lack of.

144
00:12:50.080 --> 00:12:55.430 
AI does have some kind of creativity,
but that is not human creativity.

145
00:12:55.690 --> 00:12:59.350 
It is kind of like machine creativity.
If you see like

146
00:12:59.360 --> 00:13:03.580 
a lot of his drawings from AI, or, you
know, some music created by AI,

147
00:13:03.800 --> 00:13:09.630 
if your training data, really
you know, come from human,

148
00:13:09.910 --> 00:13:14.700 
then sometime it become kind of
human but it's still different.

149
00:13:14.710 --> 00:13:20.590 
Like for example I had a good
friend who is a very famous

150
00:13:21.090 --> 00:13:28.330 
pianist and it's very,
let's say, for AI isn't the

151
00:13:28.330 --> 00:13:34.080 
composer or like a robot pianist.
For robot to play it can play

152
00:13:34.090 --> 00:13:38.670 
perfectly every time but every
time it's same or you can add

153
00:13:38.720 --> 00:13:44.090 
variables but it's still programmed.
It's not like a human pianist

154
00:13:44.090 --> 00:13:48.520 
that this guy can play for thousand
times and every time is different.

155
00:13:48.650 --> 00:13:53.000 
The same piece one is happy one is
sad, and that's just different.

156
00:13:53.000 --> 00:13:59.260 
So then, I think, for design
thinking practitioners, they need

157
00:13:59.260 --> 00:14:05.530 
to know AI thinking so that the
key for AI thinking is to enable

158
00:14:05.540 --> 00:14:12.390 
people to know where is the boundary
between the machine and the human.

159
00:14:12.750 --> 00:14:16.630 
And then you focus your training
on the human side and then you

160
00:14:16.750 --> 00:14:23.330 
let the machines -- the machines
that ask that. So for example

161
00:14:23.510 --> 00:14:29.810 
we will never train a kid to run
faster than a sporty car or

162
00:14:29.810 --> 00:14:33.780 
even a normal car. There's no human
being that can run faster than a car,

163
00:14:34.710 --> 00:14:38.600 
given the kind of cars in 2020, right?
Not in the nineteen fifties,

164
00:14:38.920 --> 00:14:44.360 
but training a human to run faster
than a car is meaningless. It's

165
00:14:44.360 --> 00:14:49.250 
the same thing if you train a
person who can do really really

166
00:14:49.250 --> 00:14:53.210 
good of something that is
actually can be done by you know

167
00:14:53.210 --> 00:14:56.960 
robots with an AI then you better
give up because the AI with

168
00:14:56.970 --> 00:15:00.630 
robot or robot with AI will
do way better than you

169
00:15:01.070 --> 00:15:05.290 
and in a perfect way and they
don't complain, they don't need

170
00:15:05.290 --> 00:15:07.970 
to, you know, they
don't need weekends.

171
00:15:08.570 --> 00:15:13.220 
So focus on the human side
and design thinking help

172
00:15:13.220 --> 00:15:16.170 
us to focus on the
human side.

173
00:15:17.220 --> 00:15:22.490 
I mean, now we have been talking about
young kids and the important

174
00:15:22.490 --> 00:15:28.230 
in k12 is to start as early
as possible but unfortunately

175
00:15:28.280 --> 00:15:32.640 
we as adults, we also have to deal
with the situation. I mean, it might

176
00:15:32.650 --> 00:15:38.320 
take a bit until the next generation
grows up and and takes

177
00:15:38.320 --> 00:15:43.650 
over leadership in organizations.
So by looking at the adults

178
00:15:43.650 --> 00:15:49.760 
and the experience that you have and
you know a lot of famous founders and

179
00:15:50.210 --> 00:15:57.980 
business men. So what is
the impact on us as adults?

180
00:15:58.190 --> 00:16:03.330 
Can we catch up? Should we catch
up? Should we invest in some

181
00:16:03.340 --> 00:16:08.270 
kind of training? If yes, in what kind?
So what is the impact

182
00:16:08.270 --> 00:16:15.770 
on the organization and us? I think
the impact on the organization side

183
00:16:15.890 --> 00:16:22.570 
is gonna be, you can either say
that's exciting or sad. The exciting

184
00:16:22.850 --> 00:16:30.970 
part is that the AI or AI
plus robots, you know robots with AI

185
00:16:31.520 --> 00:16:37.660 
is gonna unleash a lot of
productivity.

186
00:16:38.620 --> 00:16:42.740 
That productivity
will collide with the human's

187
00:16:42.740 --> 00:16:49.680 
capability or the human who can do
repetitive mental and labor work,

188
00:16:50.110 --> 00:16:56.570 
so that as the leader of a company
or the executives of a company,

189
00:16:56.970 --> 00:17:02.660 
they will do their calculation,
right? For example, if some job

190
00:17:02.800 --> 00:17:09.190 
can be done nicely by robots with
AI then they will do their

191
00:17:09.190 --> 00:17:11.850 
calculation, try to figure out
what is the cost difference

192
00:17:11.850 --> 00:17:17.600 
and most of the time they will find out
that actually to use robots gonna be

193
00:17:18.000 --> 00:17:22.550 
much nicer and cheaper and more
accurate and easy to maintain.

194
00:17:22.790 --> 00:17:28.700 
So then in the next ten to twenty
years we will see this trend of

195
00:17:28.810 --> 00:17:34.680 
shifting that will happen. That
will happen. Then for average

196
00:17:34.680 --> 00:17:41.340 
workers then I think you better
think about it and then there's

197
00:17:41.340 --> 00:17:45.930 
a rule of thumb for now, for
twenty twenty that

198
00:17:46.110 --> 00:17:52.680 
machines are able to deal things
that you need to think about

199
00:17:52.680 --> 00:17:57.930 
for maybe like a second or two. If
something only need you think

200
00:17:57.930 --> 00:18:01.430 
for like a second or two, for
example when you see a cat, you

201
00:18:01.430 --> 00:18:05.500 
know that's a cat. Then okay, that
that will be done by a machine.

202
00:18:05.740 --> 00:18:10.850 
If the job you're doing are
consist of a whole bunch of

203
00:18:10.850 --> 00:18:14.560 
jobs that only take one or
two seconds of thinking

204
00:18:15.670 --> 00:18:20.230 
then you probably will
be in trouble.

205
00:18:20.750 --> 00:18:28.160 
So if your job needs a lot of thinking
and create a lot of new stuff,

206
00:18:28.290 --> 00:18:31.700 
then most likely that you
will be pretty much okay,

207
00:18:32.720 --> 00:18:38.160 
because you are focused on the human
side. So that's kind of the role

208
00:18:38.160 --> 00:18:42.160 
that it's more I'd like to give
us, I'd like to give people

209
00:18:42.230 --> 00:18:47.230 
advice that is practical,
you know. You can listen

210
00:18:47.230 --> 00:18:50.870 
to it and you can do something
about it. So that's kind of my take.

211
00:18:51.160 --> 00:18:55.710 
So yeah, it will have some profound
impact but people can

212
00:18:55.720 --> 00:19:00.680 
prepare for it, yeah. I mean when you
talk about preparing for it, so,

213
00:19:00.880 --> 00:19:04.840 
how would you start with it?
Let's assume you're forty

214
00:19:04.840 --> 00:19:10.420 
five years old, so is there a
possibility to catch up and

215
00:19:10.430 --> 00:19:15.140 
to get back into this creativity
part or into this part where you

216
00:19:15.660 --> 00:19:19.840 
not only have to think two
seconds about it, or what?

217
00:19:20.690 --> 00:19:26.730 
Yeah, I understand that when
you're like in the forties,

218
00:19:27.060 --> 00:19:34.330 
well, just like you and me.
I think in the future

219
00:19:35.230 --> 00:19:36.560 
we have to be in the

220
00:19:37.440 --> 00:19:41.080 
in the mode of studying
throughout our life.

221
00:19:41.870 --> 00:19:45.220 
I think that, I
think in the past

222
00:19:45.860 --> 00:19:50.220 
you studied a subject, let's say you
go through the k12 and

223
00:19:50.220 --> 00:19:54.080 
you get into a very good college
and then you did your undergrad

224
00:19:54.450 --> 00:19:58.850 
and then you decide to get the master,
get a phd, then okay you're expert

225
00:19:58.850 --> 00:20:01.630 
in this field for the rest of
your life. And that kind of

226
00:20:02.200 --> 00:20:06.860 
time is already history. You have
to keep learning. No matter

227
00:20:06.870 --> 00:20:12.050 
what you do, you have to keep
learning. So it's kind of like

228
00:20:12.330 --> 00:20:17.890 
say, to my mind I feel at forty five
you can still learn a lot of stuff.

229
00:20:18.120 --> 00:20:22.180 
At least I feel that way. So
if you feel like an and forty

230
00:20:22.190 --> 00:20:27.100 
five, I'm not able to learn
anything, then you better

231
00:20:27.100 --> 00:20:30.070 
sort this out because I feel
like forty five you're still

232
00:20:30.070 --> 00:20:34.620 
in the middle of your time
and actually, I feel forty

233
00:20:34.620 --> 00:20:38.850 
five is probably around the best
time that you're already

234
00:20:39.440 --> 00:20:42.670 
you're out of your parent's control
for a long time right, but

235
00:20:42.670 --> 00:20:47.590 
then you know what you want and
you can really control

236
00:20:48.120 --> 00:20:52.510 
what you want to do every day
and you control your own time.

237
00:20:52.620 --> 00:20:56.430 
So you can learn some stuff that
you really want to learn. So

238
00:20:56.430 --> 00:21:00.890 
I think learning is a part of our life
that we have to get used to it

239
00:21:01.070 --> 00:21:06.510 
and enjoy it. Keep learning
and that's

240
00:21:06.520 --> 00:21:10.930 
part of the future, I guess. And AI is pushing
us to do that because if you don't,

241
00:21:11.570 --> 00:21:13.310 
then you will be
left behind.

242
00:21:14.810 --> 00:21:20.010 
Okay, so maybe a last question
to you and I think I am

243
00:21:20.010 --> 00:21:25.960 
allowed to ask because you're
surrounded by all your Stanford community.

244
00:21:26.300 --> 00:21:32.490 
How can you envision the future in 20
years when it comes to

245
00:21:32.650 --> 00:21:38.310 
design thinking and AI? I mean
sure, it's really far

246
00:21:38.320 --> 00:21:42.050 
away, but, I mean, you're surrounded
by so many brilliant people.

247
00:21:42.240 --> 00:21:47.040 
I'm sure you have thought about it.
So, what can you imagine?

248
00:21:48.930 --> 00:21:57.110 
I would hope in twenty years
that we will start to teach AI

249
00:21:57.110 --> 00:22:03.520 
thinking and design thinking both,
simultaneousely start from grade one

250
00:22:03.730 --> 00:22:10.500 
in k12. In that way I think
in twenty years we will be

251
00:22:10.500 --> 00:22:14.680 
surrounded by a lot of smart machines
and things like that and a

252
00:22:15.110 --> 00:22:20.390 
lot of our jobs will be
handled by them and and then

253
00:22:20.560 --> 00:22:28.980 
in order for us to train people to
become a person who can contribute more,

254
00:22:29.440 --> 00:22:35.120 
then they have to have a creative
mindset which design thinking

255
00:22:35.370 --> 00:22:41.270 
can help. On the other side keep
tracking where is the advancement of

256
00:22:41.270 --> 00:22:47.030 
machine and where's the boundary
between human and machine. One thing

257
00:22:47.250 --> 00:22:51.530 
about this boundary is that it
keeps moving, it's not staying

258
00:22:51.530 --> 00:22:56.300 
there forever. No, it's moving, it's
moving. So that's why we have

259
00:22:56.300 --> 00:23:00.270 
to keep moving, keep thinking and
then we know where this boundary

260
00:23:00.270 --> 00:23:05.030 
is and then we focus on the creativity
side, on the human side. So

261
00:23:05.170 --> 00:23:08.360 
that's what I hope, like, that's
owhy I'm spending time on the

262
00:23:08.360 --> 00:23:12.750 
educational side to push this to
happen because if this thing

263
00:23:12.750 --> 00:23:18.090 
does not happen we still use our
current education system

264
00:23:18.100 --> 00:23:23.910 
and way of educating our kids, then we
will get into trouble in the future.

265
00:23:24.050 --> 00:23:26.470 
Yeah. Thank you Li for this highly interesting
conversation. Like always I enjoyed to talk

266
00:23:30.230 --> 00:23:36.110 
to you and to get inspired
by your thoughts and insights.

267
00:23:36.610 --> 00:23:40.750 
So also to the participants
and listeners of today's lecture

268
00:23:40.750 --> 00:23:45.910 
and class, thank you for being here with us.
And today I had an interview with

269
00:23:46.040 --> 00:23:51.390 
Li Jiang from Stanford University, an
expert in AI and design thinking.

270
00:23:52.040 --> 00:23:55.390 
Thank you very much and goodbye.
