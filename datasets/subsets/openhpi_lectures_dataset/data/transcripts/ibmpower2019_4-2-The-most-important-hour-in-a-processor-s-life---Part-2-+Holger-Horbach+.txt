WEBVTT

1
00:00:00.620 --> 00:00:03.019 
OK, so now

2
00:00:03.020 --> 00:00:04.759 
we know how to create a verification

3
00:00:04.760 --> 00:00:06.649 
environment and we're ready to actually

4
00:00:06.650 --> 00:00:07.650 
find some bugs.

5
00:00:08.690 --> 00:00:10.759 
So how do we do that?

6
00:00:10.760 --> 00:00:12.109 
Well, we just started running the

7
00:00:12.110 --> 00:00:13.699 
environment and we start collecting

8
00:00:13.700 --> 00:00:16.099 
those bugs, it's not quite

9
00:00:16.100 --> 00:00:17.100 
that easy.

10
00:00:18.050 --> 00:00:20.029 
I guess in the early phase of

11
00:00:20.030 --> 00:00:22.069 
a project, we

12
00:00:22.070 --> 00:00:23.839 
will quickly find the first few bugs.

13
00:00:23.840 --> 00:00:25.759 
We will flush out these low hanging

14
00:00:25.760 --> 00:00:28.219 
fruit that I was talking about before.

15
00:00:28.220 --> 00:00:31.039 
But once the design actually

16
00:00:31.040 --> 00:00:33.289 
stabilizes and the design

17
00:00:33.290 --> 00:00:35.479 
quality level has increased,

18
00:00:35.480 --> 00:00:36.949 
it's going to be increasingly hard to

19
00:00:36.950 --> 00:00:38.209 
find bugs.

20
00:00:38.210 --> 00:00:40.009 
But it's going to be increasingly

21
00:00:40.010 --> 00:00:41.479 
important to actually find the

22
00:00:41.480 --> 00:00:43.069 
remaining bugs, because those are the

23
00:00:43.070 --> 00:00:45.079 
really interesting ones and those

24
00:00:45.080 --> 00:00:46.621 
are the really mean ones

25
00:00:47.810 --> 00:00:49.309 
that will cause so much pain at a later

26
00:00:49.310 --> 00:00:50.299 
point.

27
00:00:50.300 --> 00:00:52.609 
So how do we

28
00:00:52.610 --> 00:00:53.479 
tackle these?

29
00:00:53.480 --> 00:00:55.190 
I've pulled some numbers from

30
00:00:56.330 --> 00:00:58.819 
the POWER9 project, and this shows

31
00:00:58.820 --> 00:01:00.829 
that to find a single

32
00:01:00.830 --> 00:01:02.959 
interesting and mean bug,

33
00:01:02.960 --> 00:01:05.149 
it takes us about a million tests.

34
00:01:06.270 --> 00:01:08.299 
It takes us about 500, this

35
00:01:08.300 --> 00:01:09.878 
is billion, sim ticks,

36
00:01:11.010 --> 00:01:13.679 
and we end up generating about

37
00:01:13.680 --> 00:01:15.899 
250 GB of coverage

38
00:01:15.900 --> 00:01:17.069 
data per day.

39
00:01:17.070 --> 00:01:18.779 
So that that's that's a lot.

40
00:01:18.780 --> 00:01:20.369 
Those are huge numbers.

41
00:01:20.370 --> 00:01:22.799 
So how how can we even

42
00:01:22.800 --> 00:01:24.809 
think about running these

43
00:01:24.810 --> 00:01:26.159 
huge amount of tests?

44
00:01:28.870 --> 00:01:30.969 
Well, we'll have to divide

45
00:01:30.970 --> 00:01:33.159 
the problem down into manageable

46
00:01:33.160 --> 00:01:35.379 
chunks and

47
00:01:35.380 --> 00:01:36.415 
we will have to start parallelising.

48
00:01:39.060 --> 00:01:41.039 
So this is the time to

49
00:01:41.040 --> 00:01:42.779 
start looking at the options that we

50
00:01:42.780 --> 00:01:45.209 
have of dividing the verification

51
00:01:45.210 --> 00:01:47.279 
problem down into smaller chunks,

52
00:01:47.280 --> 00:01:50.339 
so I guess the most obvious solution

53
00:01:50.340 --> 00:01:52.409 
is really to decrease the

54
00:01:52.410 --> 00:01:55.619 
size of the device under test

55
00:01:55.620 --> 00:01:58.379 
by starting to remove components

56
00:01:58.380 --> 00:02:00.479 
that we do not want to focus on

57
00:02:00.480 --> 00:02:01.699 
at a certain point of time.

58
00:02:03.020 --> 00:02:05.269 
And this is exactly what happens

59
00:02:05.270 --> 00:02:07.519 
as we make our way up the so-called

60
00:02:07.520 --> 00:02:09.198 
integration chain.

61
00:02:09.199 --> 00:02:10.399 
We'll take a look at all of these

62
00:02:10.400 --> 00:02:12.379 
levels in detail in a

63
00:02:12.380 --> 00:02:14.449 
couple of minutes, but I did want

64
00:02:14.450 --> 00:02:16.099 
to give just a quick overview first.

65
00:02:17.870 --> 00:02:20.359 
The simplest type of verification

66
00:02:20.360 --> 00:02:22.219 
will usually happen at the so-called

67
00:02:22.220 --> 00:02:24.559 
macro level or

68
00:02:24.560 --> 00:02:26.569 
designer sim level.

69
00:02:26.570 --> 00:02:28.429 
Macro is a piece of logic, a small

70
00:02:28.430 --> 00:02:30.229 
piece of logic that serves a very

71
00:02:30.230 --> 00:02:32.389 
specific function and that

72
00:02:32.390 --> 00:02:33.949 
implements or that implements a

73
00:02:33.950 --> 00:02:35.899 
specific algorithm.

74
00:02:35.900 --> 00:02:37.939 
It ranges from only a few

75
00:02:37.940 --> 00:02:40.009 
latches to maybe a couple of

76
00:02:40.010 --> 00:02:41.010 
hundred latches.

77
00:02:42.030 --> 00:02:43.409 
At this level, we're really, really

78
00:02:43.410 --> 00:02:45.389 
focusing on the implementation

79
00:02:45.390 --> 00:02:47.849 
of the logic when we do our testing.

80
00:02:47.850 --> 00:02:49.529 
The next level is the the so-called

81
00:02:49.530 --> 00:02:50.530 
unit level.

82
00:02:51.320 --> 00:02:52.909 
At this level, we're starting to

83
00:02:52.910 --> 00:02:55.849 
combine various macros

84
00:02:55.850 --> 00:02:57.349 
and we're also starting to shift our

85
00:02:57.350 --> 00:02:59.479 
verification focus to

86
00:02:59.480 --> 00:03:01.160 
the so-called micro architecture.

87
00:03:02.210 --> 00:03:04.189 
And as we move our way up the

88
00:03:04.190 --> 00:03:05.839 
integration chain, we're going to be

89
00:03:05.840 --> 00:03:08.059 
looking at core level verification.

90
00:03:08.060 --> 00:03:10.339 
At this level, we're really focusing

91
00:03:10.340 --> 00:03:12.529 
on the architecture

92
00:03:12.530 --> 00:03:13.699 
of the microprocessor.

93
00:03:15.050 --> 00:03:16.999 
This is also called element level,

94
00:03:17.000 --> 00:03:18.799 
whereas element level usually has a

95
00:03:18.800 --> 00:03:19.969 
slightly different focus.

96
00:03:19.970 --> 00:03:21.499 
We're looking more at integration type

97
00:03:21.500 --> 00:03:22.500 
problems.

98
00:03:24.190 --> 00:03:26.319 
As we start going up

99
00:03:26.320 --> 00:03:28.149 
higher, the integration chain, we will

100
00:03:28.150 --> 00:03:30.009 
then start building so-called chip

101
00:03:30.010 --> 00:03:31.989 
level models where we have a

102
00:03:31.990 --> 00:03:34.929 
lot of units interacting,

103
00:03:34.930 --> 00:03:36.979 
may have a lot of cores interacting.

104
00:03:37.990 --> 00:03:39.889 
We want to start looking at cache

105
00:03:39.890 --> 00:03:41.769 
coherency and we can take it even

106
00:03:41.770 --> 00:03:43.809 
further. We can actually start

107
00:03:43.810 --> 00:03:46.269 
putting in not only the main CPU

108
00:03:46.270 --> 00:03:48.369 
chip, for example, we will also

109
00:03:48.370 --> 00:03:50.859 
be putting in I/O chips

110
00:03:50.860 --> 00:03:53.019 
to create what we call a system

111
00:03:53.020 --> 00:03:53.889 
level environment.

112
00:03:53.890 --> 00:03:55.779 
At this level, we're focusing mostly on

113
00:03:55.780 --> 00:03:57.699 
hardware-firmware interaction.

114
00:03:57.700 --> 00:03:59.169 
We can start running some real

115
00:03:59.170 --> 00:04:00.999 
performance tests and generating some

116
00:04:01.000 --> 00:04:02.889 
performance benchmarks.

117
00:04:02.890 --> 00:04:05.659 
And we're looking at I/O interaction.

118
00:04:05.660 --> 00:04:07.969 
So let's take a look at all

119
00:04:07.970 --> 00:04:09.564 
of these levels in a little more detail

120
00:04:09.565 --> 00:04:10.669 
now.

121
00:04:10.670 --> 00:04:12.739 
So for the device under tests

122
00:04:12.740 --> 00:04:14.479 
we're looking at here, you can see it

123
00:04:14.480 --> 00:04:16.879 
really consists just of

124
00:04:16.880 --> 00:04:19.518 
a mere nine latches,

125
00:04:19.519 --> 00:04:21.889 
along with some combination of logic.

126
00:04:21.890 --> 00:04:24.719 
It's a parity checker.

127
00:04:24.720 --> 00:04:26.959 
And if we want to start

128
00:04:26.960 --> 00:04:28.970 
verifying this bit of logic,

129
00:04:31.010 --> 00:04:32.779 
this will usually be done by the logic

130
00:04:32.780 --> 00:04:34.289 
designer himself.

131
00:04:34.290 --> 00:04:35.479 
He's going to be using some kind of

132
00:04:35.480 --> 00:04:37.729 
directed test written directly

133
00:04:37.730 --> 00:04:38.779 
at the signal level.

134
00:04:40.030 --> 00:04:42.129 
Very, very simple test.

135
00:04:42.130 --> 00:04:44.609 
This is referred to as designer sim.

136
00:04:44.610 --> 00:04:46.439 
For these tests, there's usually no

137
00:04:46.440 --> 00:04:48.479 
self checking mechanisms, the

138
00:04:48.480 --> 00:04:49.919 
test is just being run and the

139
00:04:49.920 --> 00:04:52.289 
correctness of the test is then

140
00:04:52.290 --> 00:04:54.479 
being assured by having the designer

141
00:04:54.480 --> 00:04:56.759 
take a look at simulation waveforms.

142
00:04:59.960 --> 00:05:02.269 
Going up the integration chain,

143
00:05:02.270 --> 00:05:04.399 
the unit level environment, that's

144
00:05:04.400 --> 00:05:06.259 
the that's really the first time the

145
00:05:06.260 --> 00:05:08.389 
verification engineers come into

146
00:05:08.390 --> 00:05:09.390 
play.

147
00:05:10.790 --> 00:05:12.859 
So the device under test has now

148
00:05:12.860 --> 00:05:14.149 
grown to contain

149
00:05:15.530 --> 00:05:17.629 
a certain number of macros, and

150
00:05:17.630 --> 00:05:19.099 
I guess in this little diagram you can

151
00:05:19.100 --> 00:05:21.259 
see we're looking at a piece

152
00:05:21.260 --> 00:05:23.479 
of logic that may have an arbiter.

153
00:05:23.480 --> 00:05:24.799 
You can find our little parity

154
00:05:24.800 --> 00:05:26.259 
generator in there.

155
00:05:26.260 --> 00:05:28.129 
There's a couple of registers that can

156
00:05:28.130 --> 00:05:31.039 
be accessed and there may be some

157
00:05:31.040 --> 00:05:32.040 
state machine.

158
00:05:34.480 --> 00:05:36.729 
The verification environment we create

159
00:05:36.730 --> 00:05:38.799 
at this level is no longer

160
00:05:38.800 --> 00:05:40.779 
going to operate at the signal level,

161
00:05:40.780 --> 00:05:42.909 
we want to make sure we

162
00:05:42.910 --> 00:05:45.129 
raise the abstraction level so we

163
00:05:45.130 --> 00:05:47.769 
start driving transactions

164
00:05:47.770 --> 00:05:50.259 
into this environment instead of really

165
00:05:50.260 --> 00:05:51.369 
wiggling the individual signals

166
00:05:51.370 --> 00:05:52.370 
directly.

167
00:05:53.410 --> 00:05:55.509 
There's one really, really important

168
00:05:55.510 --> 00:05:57.519 
aspect about unit environments, too,

169
00:05:57.520 --> 00:05:59.439 
and that's the aspect of self checking,

170
00:06:00.790 --> 00:06:02.529 
the environment needs to be able to

171
00:06:02.530 --> 00:06:04.079 
detect errors by itself.

172
00:06:05.110 --> 00:06:07.029 
And it needs to be able to flag these

173
00:06:07.030 --> 00:06:09.699 
and report those to

174
00:06:09.700 --> 00:06:12.069 
the verification framework.

175
00:06:12.070 --> 00:06:13.779 
And that is required to make the

176
00:06:13.780 --> 00:06:15.429 
environment so-called regressionable,

177
00:06:15.430 --> 00:06:17.359 
we'll go into a little more detail in

178
00:06:17.360 --> 00:06:18.360 
the second.

179
00:06:18.990 --> 00:06:21.299 
One other thing that's really important

180
00:06:21.300 --> 00:06:23.759 
for these unit environments is

181
00:06:23.760 --> 00:06:25.469 
they provide enhanced tracing

182
00:06:25.470 --> 00:06:27.479 
capabilities

183
00:06:27.480 --> 00:06:30.539 
that will ease debug at a later point.

184
00:06:30.540 --> 00:06:33.359 
So I was talking about the needs

185
00:06:33.360 --> 00:06:35.399 
to parallelise the efforts to

186
00:06:35.400 --> 00:06:37.199 
make sure we really get to these large

187
00:06:37.200 --> 00:06:39.109 
number of tests that we can run.

188
00:06:39.110 --> 00:06:41.249 
There's two dimensions of

189
00:06:41.250 --> 00:06:43.259 
parallelisation. For one will

190
00:06:43.260 --> 00:06:45.329 
parallelise by employing

191
00:06:45.330 --> 00:06:47.489 
multiple teams, multiple

192
00:06:47.490 --> 00:06:48.490 
unit teams,

193
00:06:49.680 --> 00:06:51.329 
each of these unit teams will be

194
00:06:51.330 --> 00:06:53.429 
responsible for verifying

195
00:06:53.430 --> 00:06:55.799 
an individual unit

196
00:06:55.800 --> 00:06:57.629 
and I guess the majority of the

197
00:06:57.630 --> 00:06:59.519 
verification effort and resources are

198
00:06:59.520 --> 00:07:01.439 
actually spent at this unit level.

199
00:07:02.460 --> 00:07:04.679 
Unit verification teams will usually

200
00:07:04.680 --> 00:07:07.319 
consist of about one to five engineers.

201
00:07:07.320 --> 00:07:09.359 
Always depends on the complexity of

202
00:07:09.360 --> 00:07:11.459 
the unit that we're looking at.

203
00:07:11.460 --> 00:07:13.499 
The key point really is

204
00:07:13.500 --> 00:07:14.999 
that we want to make sure that all of

205
00:07:15.000 --> 00:07:16.559 
these unit teams can actually work

206
00:07:16.560 --> 00:07:19.289 
independently and

207
00:07:19.290 --> 00:07:21.449 
we're trying to achieve that by making

208
00:07:21.450 --> 00:07:23.429 
sure we partition the units in a

209
00:07:23.430 --> 00:07:25.747 
way that they're always

210
00:07:27.040 --> 00:07:29.195 
divided by well-defined interfaces.

211
00:07:30.670 --> 00:07:32.979 
We can also group these unit teams into

212
00:07:32.980 --> 00:07:35.349 
domains, so we will have core

213
00:07:35.350 --> 00:07:37.479 
units, we will

214
00:07:37.480 --> 00:07:40.149 
have what we call nest or

215
00:07:40.150 --> 00:07:41.169 
uncore units.

216
00:07:41.170 --> 00:07:43.419 
These usually

217
00:07:43.420 --> 00:07:45.459 
focus on the interconnect buses

218
00:07:45.460 --> 00:07:47.619 
that we have on these chips.

219
00:07:47.620 --> 00:07:49.719 
We'll have some IO unit teams.

220
00:07:49.720 --> 00:07:51.819 
And there's a pervasive

221
00:07:51.820 --> 00:07:54.219 
domain that focuses

222
00:07:54.220 --> 00:07:56.349 
on the maintenance and initialization

223
00:07:56.350 --> 00:07:58.599 
infrastructure on

224
00:07:58.600 --> 00:07:59.600 
the chip.

225
00:08:00.490 --> 00:08:02.859 
So that's one level of parallelisation,

226
00:08:02.860 --> 00:08:04.959 
but not only are we parallelising

227
00:08:04.960 --> 00:08:06.489 
by splitting the effort into multiple

228
00:08:06.490 --> 00:08:08.410 
teams, we will also

229
00:08:09.970 --> 00:08:12.459 
parallelise by running multiple

230
00:08:12.460 --> 00:08:14.049 
instances of tests.

231
00:08:14.050 --> 00:08:16.419 
So we'll have our constrained

232
00:08:16.420 --> 00:08:18.489 
random unit environment and we will set

233
00:08:18.490 --> 00:08:20.739 
it up to make sure it can run many,

234
00:08:20.740 --> 00:08:23.859 
many, many thousand tests every day.

235
00:08:23.860 --> 00:08:26.469 
We're actually using large simulation

236
00:08:26.470 --> 00:08:28.309 
farms, sim farms.

237
00:08:28.310 --> 00:08:29.919 
I guess you could consider it as a

238
00:08:29.920 --> 00:08:32.709 
simulation cloud that we're utilizing

239
00:08:32.710 --> 00:08:35.798 
to execute these tests.

240
00:08:35.799 --> 00:08:37.509 
And there's a lot of infrastructure

241
00:08:37.510 --> 00:08:39.643 
that's being entertained to enable

242
00:08:41.799 --> 00:08:43.449 
this infrastructure to make sure we can

243
00:08:43.450 --> 00:08:45.489 
submit our simulation jobs,

244
00:08:45.490 --> 00:08:47.979 
we can gather the results, and

245
00:08:47.980 --> 00:08:50.169 
we can later present them

246
00:08:50.170 --> 00:08:51.399 
to the verification team in a

247
00:08:51.400 --> 00:08:52.400 
consistent manner.

248
00:08:55.270 --> 00:08:57.959 
Going up the integration chain.

249
00:08:57.960 --> 00:09:00.000 
We can start combining various

250
00:09:01.350 --> 00:09:02.849 
unit environments into so-called

251
00:09:02.850 --> 00:09:04.019 
element environments.

252
00:09:05.870 --> 00:09:07.849 
So at this level, the device

253
00:09:07.850 --> 00:09:10.459 
under test integrates various units

254
00:09:10.460 --> 00:09:12.799 
and we're starting to focus

255
00:09:12.800 --> 00:09:14.647 
on integration problems.

256
00:09:17.430 --> 00:09:19.559 
Have we instantiated the unit

257
00:09:19.560 --> 00:09:22.349 
correctly, are all the interfaces

258
00:09:22.350 --> 00:09:24.659 
connected correctly to the

259
00:09:24.660 --> 00:09:26.639 
units, interact

260
00:09:26.640 --> 00:09:28.289 
with each other in the correct way?

261
00:09:29.820 --> 00:09:31.919 
As we start integrating more units,

262
00:09:31.920 --> 00:09:33.239 
we're also going to start looking at

263
00:09:33.240 --> 00:09:35.439 
longer debug cycles and

264
00:09:35.440 --> 00:09:37.979 
the defect turnaround is going to be

265
00:09:37.980 --> 00:09:40.109 
larger due to the increasing

266
00:09:40.110 --> 00:09:41.279 
complexity.

267
00:09:41.280 --> 00:09:43.319 
Also, the simulation performance

268
00:09:43.320 --> 00:09:44.639 
get worse.

269
00:09:44.640 --> 00:09:46.949 
The bigger the model, the slower

270
00:09:46.950 --> 00:09:48.149 
the simulation is going to be.

271
00:09:50.440 --> 00:09:52.569 
One special form of

272
00:09:52.570 --> 00:09:54.949 
this element

273
00:09:54.950 --> 00:09:57.439 
environment is the core environment,

274
00:09:57.440 --> 00:09:58.759 
so if we're looking at a real

275
00:09:58.760 --> 00:10:00.080 
microprocessor core,

276
00:10:02.000 --> 00:10:03.979 
this environment will allow us to shift

277
00:10:03.980 --> 00:10:05.869 
our focus towards verifying

278
00:10:05.870 --> 00:10:07.010 
architectural aspect.

279
00:10:08.340 --> 00:10:10.319 
So we're going to, we're actually

280
00:10:10.320 --> 00:10:12.809 
going to generate real architectural

281
00:10:12.810 --> 00:10:15.689 
test cases using

282
00:10:15.690 --> 00:10:18.479 
pre-advanced random test case generator

283
00:10:18.480 --> 00:10:20.129 
and these architectural test cases,

284
00:10:20.130 --> 00:10:22.139 
they're essentially random

285
00:10:22.140 --> 00:10:24.449 
instruction streams, machine

286
00:10:24.450 --> 00:10:26.579 
instructions that we can then

287
00:10:26.580 --> 00:10:28.709 
convert into a binary format and

288
00:10:28.710 --> 00:10:30.989 
load into the instruction cache

289
00:10:30.990 --> 00:10:32.879 
that is now part of the device under

290
00:10:32.880 --> 00:10:33.749 
test.

291
00:10:33.750 --> 00:10:35.759 
So if we run the

292
00:10:35.760 --> 00:10:37.859 
simulation now, we will

293
00:10:37.860 --> 00:10:40.229 
actually have the device under test

294
00:10:40.230 --> 00:10:41.230 
executing

295
00:10:42.930 --> 00:10:44.909 
real instructions and we can check the

296
00:10:44.910 --> 00:10:46.529 
results of the execution of each of

297
00:10:46.530 --> 00:10:47.530 
these instructions.

298
00:10:50.700 --> 00:10:52.859 
So let's take

299
00:10:52.860 --> 00:10:54.989 
yet another step up the integration

300
00:10:54.990 --> 00:10:57.029 
ladder and let's take

301
00:10:57.030 --> 00:10:58.749 
a look at the so-called system level

302
00:10:58.750 --> 00:10:59.750 
verification.

303
00:11:00.790 --> 00:11:02.949 
So at this level of devise under tests

304
00:11:02.950 --> 00:11:04.689 
integrates a complete system, it's

305
00:11:04.690 --> 00:11:06.159 
going to have a CPU, it's going to have

306
00:11:06.160 --> 00:11:07.419 
I/O chips, it's going to have some

307
00:11:07.420 --> 00:11:08.420 
memory.

308
00:11:09.130 --> 00:11:11.379 
And our verification efforts,

309
00:11:11.380 --> 00:11:12.939 
they will shift towards what we call

310
00:11:12.940 --> 00:11:15.669 
hardware-software code simulation.

311
00:11:15.670 --> 00:11:17.799 
We will load real firmware

312
00:11:17.800 --> 00:11:18.800 
into the memory.

313
00:11:19.810 --> 00:11:21.729 
And we'll load some system management

314
00:11:21.730 --> 00:11:23.679 
software and we will start executing

315
00:11:23.680 --> 00:11:24.680 
this.

316
00:11:25.110 --> 00:11:26.849 
There's many reasons why we want to do

317
00:11:26.850 --> 00:11:28.650 
this. I mean, one of the reasons is

318
00:11:30.210 --> 00:11:32.789 
we want to reduce the bring up time

319
00:11:32.790 --> 00:11:33.790 
on the test floor.

320
00:11:35.900 --> 00:11:38.539 
Meaning once we have our hands on real

321
00:11:38.540 --> 00:11:39.540 
hardware.

322
00:11:40.310 --> 00:11:41.736 
And we want to bring up this real

323
00:11:41.737 --> 00:11:43.369 
hardware, we need to make sure that

324
00:11:43.370 --> 00:11:45.469 
this test floor

325
00:11:45.470 --> 00:11:47.089 
time is minimized.

326
00:11:47.090 --> 00:11:48.679 
Test floor time is really, really expensive.

327
00:11:48.680 --> 00:11:50.749 
So anything we can do before

328
00:11:50.750 --> 00:11:52.609 
actually getting the real hardware

329
00:11:52.610 --> 00:11:54.799 
helps us a lot.

330
00:11:54.800 --> 00:11:56.779 
So that's why we're investing

331
00:11:56.780 --> 00:11:58.759 
into this so-called virtual bring up or

332
00:11:58.760 --> 00:11:59.760 
virtual power on.

333
00:12:01.040 --> 00:12:03.019 
At the system level, we can also

334
00:12:03.020 --> 00:12:04.659 
start running performance benchmarks.

335
00:12:05.840 --> 00:12:07.609 
These are going to be pretty meaningful

336
00:12:07.610 --> 00:12:09.349 
numbers because now we're not just

337
00:12:09.350 --> 00:12:11.539 
looking at one CPU,

338
00:12:11.540 --> 00:12:13.049 
we're looking at the complete system.

339
00:12:13.050 --> 00:12:15.919 
So we will also get numbers

340
00:12:15.920 --> 00:12:18.919 
about maybe the I/O throughput

341
00:12:18.920 --> 00:12:20.959 
and other things, very important

342
00:12:20.960 --> 00:12:21.960 
benchmarks.

343
00:12:24.620 --> 00:12:26.899 
Starting to integrate these

344
00:12:26.900 --> 00:12:28.999 
many chips

345
00:12:29.000 --> 00:12:31.339 
is obviously going to

346
00:12:31.340 --> 00:12:33.289 
make the model, the device under test

347
00:12:33.290 --> 00:12:35.719 
much more complex.

348
00:12:35.720 --> 00:12:37.819 
Turnaround times tend to be very

349
00:12:37.820 --> 00:12:39.919 
long at this level, and

350
00:12:39.920 --> 00:12:42.439 
simulation time will also drastically

351
00:12:42.440 --> 00:12:44.689 
decrease because

352
00:12:44.690 --> 00:12:46.399 
the model is so big, the simulator's

353
00:12:46.400 --> 00:12:48.379 
going to take a long time to

354
00:12:48.380 --> 00:12:50.269 
actually calculate the state of the

355
00:12:50.270 --> 00:12:51.270 
model.

356
00:12:51.770 --> 00:12:52.770 
So.

357
00:12:54.220 --> 00:12:56.349 
While all of the

358
00:12:56.350 --> 00:12:58.479 
previous levels that we talked about,

359
00:12:58.480 --> 00:13:00.819 
we will usually run on a

360
00:13:00.820 --> 00:13:02.739 
software simulator, which is

361
00:13:02.740 --> 00:13:04.839 
essentially an application

362
00:13:04.840 --> 00:13:07.689 
that runs on a standard Linux system.

363
00:13:07.690 --> 00:13:09.849 
The system level environments, they

364
00:13:09.850 --> 00:13:11.326 
run on what's called a hardware

365
00:13:12.870 --> 00:13:14.279 
simulation accelerator.

366
00:13:14.280 --> 00:13:16.609 
So an accelerator

367
00:13:16.610 --> 00:13:19.019 
is a computer system

368
00:13:19.020 --> 00:13:21.449 
that runs on specialized hardware

369
00:13:21.450 --> 00:13:23.789 
and is designed for the sole purpose

370
00:13:23.790 --> 00:13:25.709 
of speeding up hardware's simulation

371
00:13:25.710 --> 00:13:27.809 
and these hardware accelerators,

372
00:13:27.810 --> 00:13:29.849 
they have a throughput that is order of

373
00:13:29.850 --> 00:13:32.159 
magnitude higher than a standard

374
00:13:32.160 --> 00:13:33.989 
software simulator.

375
00:13:33.990 --> 00:13:35.699 
And throughput, how do we measure that?

376
00:13:35.700 --> 00:13:37.859 
Well, that's measured based

377
00:13:37.860 --> 00:13:39.269 
on simulation cycles that we can

378
00:13:39.270 --> 00:13:40.270 
execute per second.

379
00:13:41.640 --> 00:13:43.589 
So running on these accelerators,

380
00:13:43.590 --> 00:13:45.419 
however, that comes with a price.

381
00:13:46.590 --> 00:13:48.539 
The maximum throughput on these

382
00:13:48.540 --> 00:13:51.449 
accelerators we can only achieve

383
00:13:51.450 --> 00:13:53.519 
when we try to minimize the interaction

384
00:13:53.520 --> 00:13:55.229 
of the device and or test with the

385
00:13:55.230 --> 00:13:57.419 
verification environment,

386
00:13:57.420 --> 00:14:00.209 
so we need to make sure

387
00:14:00.210 --> 00:14:02.249 
we will usually decrease the

388
00:14:02.250 --> 00:14:03.969 
size of the verification environments.

389
00:14:03.970 --> 00:14:05.939 
A lot of the checking is going to be

390
00:14:05.940 --> 00:14:06.940 
turned off.

391
00:14:08.080 --> 00:14:09.699 
And we won't be transporting it from

392
00:14:09.700 --> 00:14:12.789 
the lower levels onto the system level.

393
00:14:12.790 --> 00:14:15.849 
Unfortunately, this also includes

394
00:14:15.850 --> 00:14:17.409 
getting rid of some of the tracing and

395
00:14:17.410 --> 00:14:19.479 
debug capabilities,

396
00:14:19.480 --> 00:14:21.489 
which also makes debug at

397
00:14:21.490 --> 00:14:24.399 
this level much more complex and slow

398
00:14:24.400 --> 00:14:26.379 
than at the previous

399
00:14:26.380 --> 00:14:28.129 
levels, at the lower levels.

400
00:14:28.130 --> 00:14:30.249 
So the requirement for

401
00:14:30.250 --> 00:14:32.409 
initial design quality

402
00:14:32.410 --> 00:14:34.599 
is much higher at the

403
00:14:34.600 --> 00:14:36.040 
system level verification.

404
00:14:39.830 --> 00:14:41.869 
There's a nice chart that I

405
00:14:41.870 --> 00:14:43.549 
just wanted to show real quick here.

406
00:14:44.750 --> 00:14:46.789 
This shows what the bug

407
00:14:46.790 --> 00:14:48.679 
rate or what the expected bug rate is

408
00:14:48.680 --> 00:14:50.659 
that we see per integration level

409
00:14:50.660 --> 00:14:52.069 
and it gives you the first curve that's

410
00:14:52.070 --> 00:14:52.999 
the designer sim.

411
00:14:53.000 --> 00:14:55.129 
And it starts very early

412
00:14:55.130 --> 00:14:57.499 
because it has very few requirements.

413
00:14:59.090 --> 00:15:00.799 
It flushes out a lot of the bugs.

414
00:15:00.800 --> 00:15:02.539 
It make sure there's a good initial

415
00:15:02.540 --> 00:15:04.389 
design quality.

416
00:15:04.390 --> 00:15:07.539 
Once the the macro levels

417
00:15:07.540 --> 00:15:09.399 
have good quality, we can start running

418
00:15:09.400 --> 00:15:11.379 
the units verification environments,

419
00:15:11.380 --> 00:15:13.569 
you can see it's

420
00:15:13.570 --> 00:15:15.279 
shifted to the right by a little.

421
00:15:15.280 --> 00:15:16.539 
So it starts a little later.

422
00:15:17.680 --> 00:15:20.049 
It will also still find many bugs,

423
00:15:20.050 --> 00:15:21.434 
not quite as much as during designer

424
00:15:21.435 --> 00:15:22.299 
sim.

425
00:15:22.300 --> 00:15:23.379 
But these are going to be the more

426
00:15:23.380 --> 00:15:25.599 
interesting bugs as the design

427
00:15:25.600 --> 00:15:27.789 
quality increases and

428
00:15:27.790 --> 00:15:29.759 
as the bug count decreases for the unit

429
00:15:29.760 --> 00:15:31.989 
environments, we can start integrating

430
00:15:31.990 --> 00:15:33.729 
the unit environments into the element

431
00:15:33.730 --> 00:15:35.739 
or chip environments.

432
00:15:35.740 --> 00:15:36.879 
We'll start running those.

433
00:15:36.880 --> 00:15:38.859 
We'll find fewer bugs, but

434
00:15:38.860 --> 00:15:41.109 
again, maybe more interesting ones.

435
00:15:41.110 --> 00:15:43.059 
And then all the way on the right, you

436
00:15:43.060 --> 00:15:45.279 
can see the system level

437
00:15:45.280 --> 00:15:47.319 
verification effort starting very

438
00:15:47.320 --> 00:15:49.479 
late and usually only

439
00:15:49.480 --> 00:15:51.699 
finding few horrible bugs

440
00:15:51.700 --> 00:15:52.719 
at this point in time.

441
00:15:52.720 --> 00:15:54.819 
I guess the bugs that we're expecting

442
00:15:54.820 --> 00:15:57.579 
to find at this point are more

443
00:15:57.580 --> 00:16:00.009 
firmware bugs or hardware-firmware

444
00:16:00.010 --> 00:16:01.919 
interaction bugs.

445
00:16:01.920 --> 00:16:04.259 
So if the system level of verification

446
00:16:04.260 --> 00:16:06.329 
environment was not already

447
00:16:06.330 --> 00:16:08.459 
complex enough for POWER9,

448
00:16:08.460 --> 00:16:10.799 
we we had to tackle

449
00:16:10.800 --> 00:16:12.929 
another unique and new challenge

450
00:16:13.980 --> 00:16:15.419 
that had to be solved by the

451
00:16:15.420 --> 00:16:16.859 
verification teams.

452
00:16:16.860 --> 00:16:18.196 
So if you take a look at POWER9,

453
00:16:20.280 --> 00:16:22.289 
it has a focus

454
00:16:22.290 --> 00:16:24.599 
on artificial intelligence

455
00:16:24.600 --> 00:16:26.429 
and deep learning capabilities.

456
00:16:26.430 --> 00:16:28.409 
And this is facilitated by

457
00:16:28.410 --> 00:16:30.509 
having a super, super fast

458
00:16:30.510 --> 00:16:32.879 
interconnect to

459
00:16:32.880 --> 00:16:35.019 
a bunch of GPUs and nVidia

460
00:16:35.020 --> 00:16:37.139 
GPUs. There's a protocol

461
00:16:37.140 --> 00:16:39.629 
that nVidia supports called

462
00:16:39.630 --> 00:16:40.630 
NVLink.

463
00:16:41.100 --> 00:16:42.840 
And the architecture

464
00:16:44.910 --> 00:16:46.919 
created by this supports

465
00:16:46.920 --> 00:16:49.889 
a shared coherency between

466
00:16:49.890 --> 00:16:51.989 
the GPU memory and the system

467
00:16:51.990 --> 00:16:52.990 
memory.

468
00:16:53.890 --> 00:16:55.989 
This means that if we have a

469
00:16:55.990 --> 00:16:57.379 
CPU like the POWER9,

470
00:16:58.960 --> 00:17:00.279 
it's going to be able to check out a

471
00:17:00.280 --> 00:17:02.349 
cache line from some GPU

472
00:17:02.350 --> 00:17:04.328 
memory and actually make modifications

473
00:17:04.329 --> 00:17:06.399 
to it without having the software

474
00:17:06.400 --> 00:17:07.509 
stack interact.

475
00:17:07.510 --> 00:17:09.639 
And this really enables very, very

476
00:17:09.640 --> 00:17:11.979 
fast data exchange

477
00:17:11.980 --> 00:17:14.289 
between the processor

478
00:17:14.290 --> 00:17:16.328 
and the GPUs, which is essential

479
00:17:16.329 --> 00:17:18.699 
if you want to run deep learning

480
00:17:18.700 --> 00:17:19.700 
workloads.

481
00:17:22.380 --> 00:17:23.910 
Coherency always poses a

482
00:17:25.290 --> 00:17:27.299 
complicated verification

483
00:17:27.300 --> 00:17:29.879 
challenge, so

484
00:17:29.880 --> 00:17:31.529 
we decided that there had to be some

485
00:17:31.530 --> 00:17:33.150 
kind of simulation

486
00:17:34.290 --> 00:17:36.779 
for this feature.

487
00:17:36.780 --> 00:17:38.969 
The problem here was that

488
00:17:38.970 --> 00:17:41.009 
the development team was

489
00:17:41.010 --> 00:17:42.539 
split across two companies.

490
00:17:42.540 --> 00:17:44.969 
Now you've got nVidia supplying

491
00:17:44.970 --> 00:17:47.519 
the GPS and you've got IBM supplying

492
00:17:47.520 --> 00:17:49.799 
the POWER9 processor.

493
00:17:49.800 --> 00:17:51.839 
And both of these companies use

494
00:17:51.840 --> 00:17:54.300 
different verification methodologies.

495
00:17:55.920 --> 00:17:56.999 
nVidia is focusing on an industry

496
00:17:57.000 --> 00:17:59.189 
standard UVM

497
00:17:59.190 --> 00:18:01.799 
- universal verification methodology,

498
00:18:01.800 --> 00:18:05.249 
whereas IBM has its proprietary

499
00:18:05.250 --> 00:18:06.609 
verification solution called

500
00:18:08.910 --> 00:18:09.839 
Fusion RTX.

501
00:18:09.840 --> 00:18:11.819 
And that was what's being applied

502
00:18:11.820 --> 00:18:12.820 
for POWER9.

503
00:18:13.050 --> 00:18:14.050 
So.

504
00:18:14.520 --> 00:18:16.529 
The challenge now was

505
00:18:16.530 --> 00:18:18.629 
to combine these

506
00:18:18.630 --> 00:18:20.609 
two different verification

507
00:18:20.610 --> 00:18:23.279 
environments and different simulators

508
00:18:23.280 --> 00:18:25.349 
into one environment

509
00:18:25.350 --> 00:18:26.350 
and to combined testbench

510
00:18:27.457 --> 00:18:29.489 
to essentially stitch together the

511
00:18:29.490 --> 00:18:31.949 
POWER9 processor

512
00:18:31.950 --> 00:18:34.679 
with the GPUs to form

513
00:18:34.680 --> 00:18:36.299 
a super testbench.

514
00:18:36.300 --> 00:18:38.369 
And we call this

515
00:18:38.370 --> 00:18:39.935 
the SuperStitch testbench.

516
00:18:41.580 --> 00:18:43.619 
So the key challenge was to

517
00:18:43.620 --> 00:18:45.689 
actually facilitate a simulation

518
00:18:45.690 --> 00:18:48.539 
environment that could enable us

519
00:18:48.540 --> 00:18:51.029 
to run and coordinate

520
00:18:51.030 --> 00:18:52.769 
two separate simulators and two

521
00:18:52.770 --> 00:18:55.309 
separate simulation environments.

522
00:18:55.310 --> 00:18:57.469 
They not only have to be able

523
00:18:57.470 --> 00:18:59.629 
to actually run in parallel, they also

524
00:18:59.630 --> 00:19:01.879 
need to be able to communicate

525
00:19:01.880 --> 00:19:04.009 
with each other to exchange information

526
00:19:04.010 --> 00:19:06.859 
about signal values,

527
00:19:06.860 --> 00:19:08.989 
pass-fail status or

528
00:19:08.990 --> 00:19:11.209 
simulation stages.

529
00:19:11.210 --> 00:19:13.459 
So to enable this, we created

530
00:19:13.460 --> 00:19:14.460 
a tool called

531
00:19:15.560 --> 00:19:17.359 
XTB - Cross Testbench tool.

532
00:19:17.360 --> 00:19:20.389 
And the diagram on the right shows

533
00:19:20.390 --> 00:19:22.189 
how this actually is supposed to work.

534
00:19:22.190 --> 00:19:25.219 
So we will essentially spawn a process

535
00:19:25.220 --> 00:19:27.769 
which runs the tool or invokes the

536
00:19:27.770 --> 00:19:29.209 
XTB tool.

537
00:19:29.210 --> 00:19:31.369 
This again will spawn two

538
00:19:31.370 --> 00:19:32.569 
additional processes.

539
00:19:32.570 --> 00:19:35.209 
Process B in this example would be

540
00:19:35.210 --> 00:19:37.339 
the IBM simulator running

541
00:19:37.340 --> 00:19:39.469 
the Fusion verification

542
00:19:39.470 --> 00:19:41.449 
environment and Process C

543
00:19:41.450 --> 00:19:43.669 
would in this case be

544
00:19:43.670 --> 00:19:45.809 
the industry

545
00:19:45.810 --> 00:19:47.909 
standard simulator running a UVM

546
00:19:47.910 --> 00:19:48.910 
test bench.

547
00:19:50.270 --> 00:19:52.459 
Including the nVidia GPU, whereas

548
00:19:52.460 --> 00:19:54.749 
the IBM

549
00:19:54.750 --> 00:19:57.299 
simulator would contain the POWER9

550
00:19:57.300 --> 00:19:59.369 
chip as the device

551
00:19:59.370 --> 00:20:00.370 
under test.

552
00:20:01.190 --> 00:20:02.899 
The testbenches themselves had to be

553
00:20:02.900 --> 00:20:05.419 
instrumented and changed slightly,

554
00:20:05.420 --> 00:20:07.459 
so they had to

555
00:20:07.460 --> 00:20:09.049 
have some hooks inserted

556
00:20:11.420 --> 00:20:13.459 
that would provide for

557
00:20:13.460 --> 00:20:16.519 
the communication services

558
00:20:16.520 --> 00:20:19.219 
that XTB enables.

559
00:20:19.220 --> 00:20:21.109 
So these are the orange boxes you see

560
00:20:21.110 --> 00:20:23.599 
here, small modifications

561
00:20:23.600 --> 00:20:25.549 
that needed to be made.

562
00:20:25.550 --> 00:20:27.769 
But this enabled us to actually

563
00:20:27.770 --> 00:20:30.409 
run the two simulations

564
00:20:30.410 --> 00:20:32.180 
in parallel.

565
00:20:34.040 --> 00:20:36.079 
The mechanism that we use to have the

566
00:20:36.080 --> 00:20:38.299 
processes communicate is

567
00:20:38.300 --> 00:20:40.309 
MPI, which is essentially the

568
00:20:40.310 --> 00:20:41.899 
standard for inter process

569
00:20:41.900 --> 00:20:42.900 
communication.

570
00:20:44.030 --> 00:20:46.099 
The effort of creating this new cross

571
00:20:46.100 --> 00:20:47.899 
testbench tool paid off.

572
00:20:47.900 --> 00:20:49.999 
At the end, three bugs were actually

573
00:20:50.000 --> 00:20:51.079 
being found.

574
00:20:51.080 --> 00:20:53.149 
So one of them was based on

575
00:20:53.150 --> 00:20:55.439 
a misinterpretation of the interface

576
00:20:55.440 --> 00:20:56.539 
spec.

577
00:20:56.540 --> 00:20:58.130 
In this case, the polarity of

578
00:20:59.640 --> 00:21:01.679 
a sign bit was wrong, causing

579
00:21:01.680 --> 00:21:03.449 
incorrect results.

580
00:21:03.450 --> 00:21:05.129 
A second problem was actually a cache

581
00:21:05.130 --> 00:21:07.229 
coherency problem, where

582
00:21:07.230 --> 00:21:09.329 
the POWER9 chip did not

583
00:21:09.330 --> 00:21:11.459 
clear a so-called reservation

584
00:21:11.460 --> 00:21:13.169 
that it had on a certain cache line.

585
00:21:13.170 --> 00:21:15.329 
So this was a really good find.

586
00:21:15.330 --> 00:21:17.369 
And the third problem that resulted in

587
00:21:17.370 --> 00:21:19.679 
a potential deadlock situation where

588
00:21:19.680 --> 00:21:22.199 
the POWER9 chip would

589
00:21:22.200 --> 00:21:24.239 
not send an acknowledgment

590
00:21:24.240 --> 00:21:26.279 
for a certain request that the GPU had

591
00:21:26.280 --> 00:21:27.280 
initially sent.

592
00:21:29.240 --> 00:21:31.579 
So this already

593
00:21:31.580 --> 00:21:32.960 
takes me to the end of the lecture.

594
00:21:36.930 --> 00:21:39.239 
I hope I was able to give everyone

595
00:21:39.240 --> 00:21:41.219 
a glimpse on what

596
00:21:41.220 --> 00:21:42.659 
it takes to actually develop a server

597
00:21:42.660 --> 00:21:44.639 
processor, and I was able

598
00:21:44.640 --> 00:21:46.679 
to actually give behind the

599
00:21:46.680 --> 00:21:48.569 
scenes look at the verification

600
00:21:48.570 --> 00:21:49.919 
process.

601
00:21:49.920 --> 00:21:52.139 
It's a lot of work and it consumes

602
00:21:52.140 --> 00:21:54.239 
a lot of human and

603
00:21:54.240 --> 00:21:56.219 
computing resources, but

604
00:21:56.220 --> 00:21:58.349 
it definitely pays off in the end.

605
00:21:58.350 --> 00:22:00.479 
So I guess one

606
00:22:00.480 --> 00:22:02.699 
of the successes and I had to include

607
00:22:02.700 --> 00:22:04.049 
is this nice picture here

608
00:22:05.250 --> 00:22:07.919 
this year, two

609
00:22:07.920 --> 00:22:09.989 
POWER9 based systems actually made it

610
00:22:09.990 --> 00:22:11.099 
into the top five hundred

611
00:22:11.100 --> 00:22:13.229 
supercomputing list ranking and spot

612
00:22:13.230 --> 00:22:14.670 
one and three.

613
00:22:16.170 --> 00:22:17.789 
I included the snippets on the slide

614
00:22:17.790 --> 00:22:18.790 
here.

615
00:22:20.300 --> 00:22:22.109 
So they're from the top 500 lists and

616
00:22:22.110 --> 00:22:23.359 
then they measure the compute

617
00:22:23.360 --> 00:22:25.489 
performance using the

618
00:22:25.490 --> 00:22:27.649 
LINPACK benchmark that's focused

619
00:22:27.650 --> 00:22:29.689 
on solving linear equations

620
00:22:29.690 --> 00:22:32.239 
and it has seen some critique

621
00:22:32.240 --> 00:22:34.489 
in the past because it's supposedly

622
00:22:34.490 --> 00:22:36.679 
a little too specific for certain

623
00:22:36.680 --> 00:22:38.029 
architectures.

624
00:22:38.030 --> 00:22:39.199 
There's a new benchmark that's

625
00:22:39.200 --> 00:22:40.670 
emerging. It's called the HPCG -

626
00:22:42.140 --> 00:22:44.630 
High Performance Conjugate Gradients.

627
00:22:45.700 --> 00:22:47.379 
This is supposed to be a little broader

628
00:22:47.380 --> 00:22:49.419 
measure and it's supposed

629
00:22:49.420 --> 00:22:51.489 
to more closely match the

630
00:22:51.490 --> 00:22:54.069 
computational and data

631
00:22:54.070 --> 00:22:56.079 
access patterns

632
00:22:56.080 --> 00:22:57.609 
for current applications.

633
00:22:57.610 --> 00:22:59.049 
But even for this benchmark,

634
00:23:00.670 --> 00:23:02.280 
the IBM system, it's called Summit,

635
00:23:03.400 --> 00:23:04.400 
took the number

636
00:23:05.770 --> 00:23:07.749 
one spot with a pretty good lead.

637
00:23:07.750 --> 00:23:09.999 
So I guess I'll close

638
00:23:10.000 --> 00:23:12.159 
the presentation with these final

639
00:23:12.160 --> 00:23:14.169 
words. And I guess all that's

640
00:23:14.170 --> 00:23:16.179 
left for me to say is really thanks for

641
00:23:16.180 --> 00:23:18.189 
listening and

642
00:23:18.190 --> 00:23:19.449 
I hope you can enjoy the rest of the

643
00:23:19.450 --> 00:23:20.450 
lecture.
