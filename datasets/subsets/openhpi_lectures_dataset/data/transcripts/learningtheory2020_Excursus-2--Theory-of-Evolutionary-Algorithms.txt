WEBVTT

1
00:00:00.860 --> 00:00:05.800 
Hello everyone and welcome to this nice excursion
about theory of evolutionary algorithms.

2
00:00:06.220 --> 00:00:10.890 
My name's Martin and today I'll introduce
you to evolutionary algorithms,

3
00:00:11.130 --> 00:00:14.830 
when you could use them, what
they're used for and why would

4
00:00:14.830 --> 00:00:18.600 
even consider theory of evolutionary
algorithms to begin with.

5
00:00:19.190 --> 00:00:22.590 
I would like to start with the
setting of evolutionary algorithms,

6
00:00:23.190 --> 00:00:27.560 
that is just the very general setting
of mathematical optimization.

7
00:00:28.160 --> 00:00:31.400 
So if you want to have a look at
this curve down there for example

8
00:00:32.090 --> 00:00:35.620 
we would see ok if we assume
minimizing this function that's

9
00:00:35.620 --> 00:00:39.780 
quite an easy function to minimize,
right. So we see where the minimum is,

10
00:00:40.010 --> 00:00:43.910 
so not much effort required to
actually optimize this function.

11
00:00:45.500 --> 00:00:49.640 
Next example would be more complex functions,
something like this for example,

12
00:00:49.800 --> 00:00:53.390 
but I guess you would also try and
figure out where the optimum

13
00:00:53.390 --> 00:00:56.480 
is you could just look at
the gradient, hessian and

14
00:00:56.480 --> 00:01:00.240 
you are good to go. So basically
this is also kind of easy problem.

15
00:01:00.800 --> 00:01:04.360 
You can also look at something
something far more complex than that

16
00:01:04.360 --> 00:01:08.830 
or something more vague, a combinational
optimization problems for example

17
00:01:09.100 --> 00:01:12.920 
like finding shortest path.
That's a task that navigational

18
00:01:12.920 --> 00:01:15.960 
devices for example in your car
or your smartphone have to

19
00:01:15.960 --> 00:01:20.130 
face on a day to day basis, and
this is also a problem that

20
00:01:20.130 --> 00:01:23.660 
can be easily solved, for example
using dextrous algorithm.

21
00:01:24.200 --> 00:01:28.830 
There are even far more harder problems
like for example satisfiability

22
00:01:28.830 --> 00:01:31.480 
problem or the travelling
salesperson problem.

23
00:01:31.920 --> 00:01:37.240 
For that still certain dedicated
optimizers exist that were quite well

24
00:01:37.500 --> 00:01:40.910 
although they are not necessarily
give you an optimal solution.

25
00:01:42.030 --> 00:01:46.260 
So basically saying while we're in the
setting of mathematical optimisation

26
00:01:46.880 --> 00:01:50.920 
we have problems for which we
have dedicated solvers like for

27
00:01:50.920 --> 00:01:54.080 
example these three tasks
we just see here.

28
00:01:54.670 --> 00:01:58.710 
Now these are settings in which we
would not like to use evolutionary

29
00:01:58.710 --> 00:02:01.790 
algorithms because we can solve
these problems differently.

30
00:02:01.840 --> 00:02:06.100 
We already have some nice solvers
that can solve the task, so

31
00:02:06.100 --> 00:02:09.990 
we do not require something fancy
like an evolutionary algorithm.

32
00:02:10.450 --> 00:02:14.310 
So now what do we actually need
evolutionary algorithms for then?

33
00:02:14.460 --> 00:02:20.140 
So let's have a look at this scenario now.
We're still in the setting of optimization,

34
00:02:20.340 --> 00:02:24.300 
but now let's just consider some
alternative problems different

35
00:02:24.300 --> 00:02:29.010 
from the ones we just saw before.
So the first for example would be

36
00:02:29.150 --> 00:02:33.040 
a wind farm right. So we have all
these wind generators and now

37
00:02:33.040 --> 00:02:36.660 
we just ask what is an optimal
placement of all these wind

38
00:02:36.660 --> 00:02:41.220 
generators such that the energy
output by this wind farm in total

39
00:02:41.550 --> 00:02:46.680 
is maximized. This is kind of
tough to formalize, I wouldn't

40
00:02:46.680 --> 00:02:50.530 
even know how to do this but I
kind of would like to optimize

41
00:02:50.530 --> 00:02:55.730 
this. How would I do this? A different
actually quite common scenario is

42
00:02:56.010 --> 00:02:58.540 
that you just have a schedule.
So you have tons of people you

43
00:02:58.540 --> 00:03:02.000 
want to schedule them at certain
points in time over like vast

44
00:03:02.000 --> 00:03:05.890 
scale for example a year or so and
all of the individual people have

45
00:03:05.890 --> 00:03:10.510 
different skills since there are many
different constraints tied to that.

46
00:03:10.650 --> 00:03:14.790 
So how would you go about this
or also like manufacturing a

47
00:03:14.790 --> 00:03:18.500 
car engines, you may know how to
build a standard car engine

48
00:03:18.500 --> 00:03:22.480 
but maybe you want to tweak it a bit to
gain some more performance out of this.

49
00:03:22.960 --> 00:03:26.860 
How would you go about this, or
for example keyboard layout.

50
00:03:27.280 --> 00:03:30.880 
I mean standard keyboard layout
is kind of common but there are

51
00:03:31.020 --> 00:03:35.010 
ones that allow you to type faster.
How would you go about this

52
00:03:35.270 --> 00:03:38.900 
or very classic examples. So this
picture is actually from the wikipedia

53
00:03:39.380 --> 00:03:43.350 
like a satellite antenna. So this
has actually been constructed

54
00:03:43.350 --> 00:03:45.400 
using an evolutionary
algorithm.

55
00:03:46.100 --> 00:03:50.810 
Now what all of these scenarios
have in common is we can kind

56
00:03:50.810 --> 00:03:55.150 
of tell how good a certain solution
is, like for example, if

57
00:03:55.150 --> 00:03:58.790 
I look at the schedule I can tell you
whether that's a good or bad schedule

58
00:03:59.120 --> 00:04:02.400 
or the same with the wind farm for
example, I can just simulate

59
00:04:02.400 --> 00:04:04.140 
what the energy output
would be of that.

60
00:04:04.720 --> 00:04:09.370 
But we don't necessarily know how
we would write this down or

61
00:04:09.560 --> 00:04:14.480 
maybe we have some nice intuition behind this
problem but cannot really formalize this.

62
00:04:14.850 --> 00:04:18.800 
So we can only say whether a
solution is good or not but we

63
00:04:18.800 --> 00:04:23.220 
cannot generalize this to an entire
function that we would like to optimize.

64
00:04:23.650 --> 00:04:28.410 
So basically we are in this kind of
setting called black-box optimization.

65
00:04:28.740 --> 00:04:33.640 
So the problem itself appears as
a black box to us. So we only

66
00:04:33.640 --> 00:04:38.640 
have some ideas of how to solve it but we
don't know what it actually looks like.

67
00:04:38.820 --> 00:04:43.600 
And we just call this function f
in our scenario for now. And

68
00:04:43.600 --> 00:04:47.540 
this is the scenario that
evolutionary algorithms thrive in.

69
00:04:47.940 --> 00:04:51.130 
So let's get an idea of how
the general framework for

70
00:04:51.130 --> 00:04:53.210 
such evolutionary
algorithms looks like.

71
00:04:54.080 --> 00:04:56.870 
So this is the blackbox
we want to optimize.

72
00:04:57.850 --> 00:05:00.530 
So in evolutionary
algorithms we just have

73
00:05:01.040 --> 00:05:05.180 
a number of solutions, so all of these
dots there we call them individuals

74
00:05:05.410 --> 00:05:08.430 
are just some solutions. So you
can think of them for example

75
00:05:08.430 --> 00:05:12.500 
like a schedule just each of them
represents a different schedule

76
00:05:12.530 --> 00:05:17.400 
or just like some arrangement of these
wind generators in this wind park.

77
00:05:18.100 --> 00:05:22.820 
Now the next thing we do is we
just generate some offspring

78
00:05:23.040 --> 00:05:26.560 
and this is where we use randomness
usually. Since we do not

79
00:05:26.560 --> 00:05:31.140 
know what to do we just make some
guesses. So maybe as you also do

80
00:05:31.330 --> 00:05:33.370 
I don't know when you're taking
a test or so when you don't

81
00:05:33.370 --> 00:05:36.000 
know what the correct
answer is you just guess

82
00:05:36.510 --> 00:05:39.630 
these great individuals should
be some of these guesses.

83
00:05:40.180 --> 00:05:44.660 
We call this variation and if
we just use a single solution

84
00:05:44.660 --> 00:05:48.560 
to create a new solution we talk
of mutation, if we combine

85
00:05:48.560 --> 00:05:52.340 
different solutions to a new
solution we talk of cross over

86
00:05:53.110 --> 00:05:58.090 
and so far all we did is just using
randomness. So we did not use the

87
00:05:58.440 --> 00:06:01.840 
function that we want to optimize,
we also call this the fitness

88
00:06:01.840 --> 00:06:06.910 
function in this context at all so
far. So now we're going to use it

89
00:06:07.490 --> 00:06:11.190 
and actually narrow down all the
solutions we have so far. This

90
00:06:11.190 --> 00:06:14.970 
is what we call selection. So we
just select a subset out of

91
00:06:14.980 --> 00:06:18.820 
all of the solutions, the old and
the new solutions to create

92
00:06:19.080 --> 00:06:23.290 
a new hopefully better set of
solutions. So a common approach

93
00:06:23.290 --> 00:06:27.680 
here is that you just choose the
best solutions out of this

94
00:06:27.680 --> 00:06:31.520 
entire set of solutions. It's also
what we call elitist selection

95
00:06:31.810 --> 00:06:35.610 
and this is where the fitness
function comes into play. So this

96
00:06:35.620 --> 00:06:41.090 
introduces a bias into the set of
solutions and kind of implicitly

97
00:06:41.090 --> 00:06:44.360 
tells the algorithm what
we want to optimize for.

98
00:06:44.940 --> 00:06:48.610 
And now all that's left to do is
just going back to the start

99
00:06:48.610 --> 00:06:52.330 
so we iterate this process. This
is the entire framework of

100
00:06:52.330 --> 00:06:57.170 
evolutionary algorithms. So it is just
this iterative process of guessing

101
00:06:57.300 --> 00:06:59.910 
taking what is good and then
just crossing your fingers and

102
00:06:59.910 --> 00:07:03.350 
hoping that you'll eventually get
better and better solutions.

103
00:07:04.420 --> 00:07:09.000 
This is the general idea and now
if you recall I want to talk

104
00:07:09.000 --> 00:07:13.030 
about theory of evolutionary
algorithms in this excursion here.

105
00:07:13.500 --> 00:07:18.670 
So now let me tell you a bit of
why we perform theoretical

106
00:07:18.670 --> 00:07:23.730 
analyses on evolutionary algorithms
and what this looks like roughly,

107
00:07:23.840 --> 00:07:28.260 
or what the idea is because right
now we only have the framework

108
00:07:28.510 --> 00:07:31.360 
and we know ok they're used
for black box optimization,

109
00:07:31.950 --> 00:07:36.080 
but this is very vague that's
the idea right. So how can we

110
00:07:36.090 --> 00:07:38.530 
think about this in
theoretical terms.

111
00:07:39.150 --> 00:07:43.100 
And for this I just present like
a general fitness landscape

112
00:07:43.260 --> 00:07:47.980 
so just something I made up. We
just assume this represents

113
00:07:47.980 --> 00:07:52.890 
some kind of problem and has some
properties that may appear

114
00:07:52.890 --> 00:07:58.470 
in many different problems that we actually
want to optimize using these algorithms.

115
00:07:59.000 --> 00:08:02.870 
Now if we have this exemplary
fitness landscape here, we'll

116
00:08:02.870 --> 00:08:07.910 
just place our individuals there right.
So our population on this grid

117
00:08:08.030 --> 00:08:11.350 
and now we would just look at a
single iteration for example

118
00:08:11.830 --> 00:08:15.750 
and all of these individuals would
move on this fitness landscape.

119
00:08:16.490 --> 00:08:19.920 
So this is what an evolutionary
algorithm could behave like

120
00:08:19.920 --> 00:08:23.510 
on this fitness landscape and
now if we perform theoretical

121
00:08:23.510 --> 00:08:27.870 
analyses we want to understand, ok
how does the algorithm perform

122
00:08:28.040 --> 00:08:31.830 
in general settings how can it
cope with certain structures

123
00:08:31.830 --> 00:08:35.670 
we see inside of this fitness
landscape, how long does it take,

124
00:08:35.680 --> 00:08:39.650 
will it succeed, what kind of
operators are useful to kind

125
00:08:39.650 --> 00:08:43.560 
of cope with these situations?
Let's consider one example. We

126
00:08:43.560 --> 00:08:47.180 
have the slope here. So we can
think of like a hill climbing

127
00:08:47.540 --> 00:08:52.880 
ability of the algorithm right. So how easy
is it for certain algorithms to actually

128
00:08:53.060 --> 00:08:56.370 
climb up the slope. Is this
a hard task? And if so

129
00:08:56.910 --> 00:09:00.800 
how hard is it or how long does
it take if it's easy? This is

130
00:09:00.800 --> 00:09:04.940 
one question we could ask if we want
to analyze theoretical algorithms.

131
00:09:05.160 --> 00:09:08.360 
Or like another property we have
over there is like this gap.

132
00:09:08.770 --> 00:09:13.490 
We can imagine an individual on
top of the right plateau so

133
00:09:14.100 --> 00:09:18.490 
if it wants to increase its fitness,
so its quality of the solution

134
00:09:18.490 --> 00:09:21.820 
than it has to jump over this
gap, then of course we can ask

135
00:09:21.820 --> 00:09:25.450 
the same question how long does
it take for this individual

136
00:09:25.450 --> 00:09:29.130 
to actually notice that there is
a gap and to cross it to get

137
00:09:29.140 --> 00:09:30.730 
into better
fitness values.

138
00:09:31.790 --> 00:09:35.970 
Or if we imagine this plateau up
there we have a large region

139
00:09:35.980 --> 00:09:40.290 
where all solutions have the same quality.
So we cannot discern the solutions

140
00:09:40.500 --> 00:09:44.240 
with respect to their quality but
only with respect to how they look.

141
00:09:44.830 --> 00:09:48.500 
Now how would we go about this for
example if we want to optimise

142
00:09:48.510 --> 00:09:52.830 
this fitness function? And like
one last example here we

143
00:09:52.830 --> 00:09:58.150 
have this one peak up there, everything else
basically the plateau in the neighborhood

144
00:09:58.360 --> 00:10:00.380 
only have this one
single solution that

145
00:10:00.880 --> 00:10:04.380 
has like far better fitness than
everything else. We call this

146
00:10:04.380 --> 00:10:07.540 
a needle in the haystack problem.
So basically there's only one

147
00:10:07.540 --> 00:10:12.260 
dedicated solution in a large array of
solutions that have the same quality.

148
00:10:12.480 --> 00:10:16.730 
How are we able to figure out
what, where the solution is

149
00:10:16.730 --> 00:10:20.700 
and how long does this take
again. So these are all of just

150
00:10:20.700 --> 00:10:23.970 
some questions we would like to
answer when performing theoretical

151
00:10:23.970 --> 00:10:28.520 
analyses of the evolutionary algorithm. So
getting a better deeper understanding

152
00:10:28.800 --> 00:10:33.380 
of how they behave for a certain
structures that may occur

153
00:10:33.700 --> 00:10:37.900 
and we hope that occur in a lot
of real world problems. So a

154
00:10:37.910 --> 00:10:40.770 
lot of fitness landscapes or
problems that we personally

155
00:10:40.780 --> 00:10:46.350 
cannot formalize directly but only do so
implicitly via just telling the algorithm

156
00:10:46.660 --> 00:10:49.290 
ok this solution is good,
this solution is bad.

157
00:10:50.300 --> 00:10:54.820 
Now in this context, so in theoretical
analysis of evolutionary

158
00:10:54.820 --> 00:10:58.410 
algorithms we have of course
benchmark functions. So we usually

159
00:10:58.410 --> 00:11:01.220 
do not look at such complex fitness
landscapes right. This is

160
00:11:01.220 --> 00:11:03.460 
why we have these
example for

161
00:11:04.130 --> 00:11:08.050 
properties that we show there but
instead we just look at them

162
00:11:08.060 --> 00:11:13.920 
individually and maybe combine them
eventually to larger fitness landscapes.

163
00:11:14.400 --> 00:11:19.030 
So if we look at theory benchmarks
we get back to this black-box

164
00:11:19.030 --> 00:11:21.420 
setting because evolutionary
algorithms are

165
00:11:21.880 --> 00:11:27.450 
ultimately black-box optimization
algorithms. So now we as the theoreticians

166
00:11:27.780 --> 00:11:32.880 
can just say ok how do we want to want
the fitness function to look like.

167
00:11:33.130 --> 00:11:37.480 
And since we need to analyze an algorithm
ultimately this algorithm needs to

168
00:11:37.800 --> 00:11:40.970 
be able to talk with this black
box and for this we need to

169
00:11:40.970 --> 00:11:45.540 
define the interface for the black
box. And in theory usually we

170
00:11:45.540 --> 00:11:49.070 
use this kind of interface. So
the discrete hypercube and we

171
00:11:49.070 --> 00:11:52.780 
map it to the real numbers or
like easier put we look a bit

172
00:11:52.780 --> 00:11:58.100 
strings of length and so just n
different symbols, zero or one each,

173
00:11:58.610 --> 00:12:02.890 
this is what we give the black box
as input and what we retrieve

174
00:12:02.890 --> 00:12:06.910 
from it is just any real number. So
we're scoring these bit strings.

175
00:12:07.650 --> 00:12:12.850 
And the most common theory benchmark
function used is called OneMax.

176
00:12:13.290 --> 00:12:18.480 
So as you can see in the picture this again
represents the hill-climbing ability

177
00:12:18.720 --> 00:12:22.650 
of an evolutionary algorithm so
just providing an easy slope.

178
00:12:23.390 --> 00:12:27.670 
The function itself just maps a bit
string to the sum of its ones.

179
00:12:27.970 --> 00:12:31.920 
As the name suggests it just counts
the ones in the bit string

180
00:12:31.940 --> 00:12:37.180 
and we just say ok this is a maximization
problem we want to maximize the fitness.

181
00:12:37.360 --> 00:12:40.990 
So ultimately saying we wanna get
the bit string that consist

182
00:12:41.000 --> 00:12:43.250 
of only ones
ultimately.

183
00:12:43.900 --> 00:12:47.800 
So if we look at the plot here of
how this function looks like

184
00:12:48.110 --> 00:12:52.140 
so down on the x axis I just
have the number of ones often

185
00:12:52.140 --> 00:12:57.000 
individual. Right so this is just one number
how many ones does this bit string contain,

186
00:12:57.350 --> 00:13:01.000 
and on the y-axis we have the
function value if we plotted

187
00:13:01.000 --> 00:13:05.900 
we see ok this is a very easier
linear function that we see there.

188
00:13:06.460 --> 00:13:10.830 
Now keep in mind here still since
the x axis is a projection

189
00:13:10.940 --> 00:13:14.760 
from all bit strings to the
number of ones in there that

190
00:13:15.400 --> 00:13:18.820 
in the slope we have like different
cardinality of bit strings

191
00:13:18.820 --> 00:13:21.890 
that actually have this number
of ones. If we look at the top

192
00:13:21.890 --> 00:13:25.970 
right for example there is only
one bitstream that has only ones

193
00:13:26.420 --> 00:13:30.100 
and bottom left there's also only
one bit string that has zero

194
00:13:30.100 --> 00:13:33.660 
ones so only zeroes basically,
but in the centre for example

195
00:13:33.660 --> 00:13:38.460 
bit strings that have n over to ones
there are n choose n over two

196
00:13:38.830 --> 00:13:43.430 
of these, rights. So they are distributed
the number of individuals with these ones

197
00:13:43.640 --> 00:13:47.260 
are distributed according to the
binomial coefficient. So basically

198
00:13:47.260 --> 00:13:50.170 
saying it's a lot easier to make
progress but we're kind of

199
00:13:50.260 --> 00:13:54.110 
in the center of this curve and
the more we get to the top

200
00:13:54.110 --> 00:13:58.130 
the harder it gets to make progress because
there are fewer and fewer solutions

201
00:13:58.350 --> 00:14:05.010 
that actually have a better fitness. Ok so
this is like the easiest fitness function

202
00:14:05.140 --> 00:14:08.560 
one could probably come up with
for theoretical analyses that

203
00:14:08.560 --> 00:14:12.320 
is kind of interesting. And now
we would like to understand

204
00:14:12.330 --> 00:14:16.290 
ok considering some evolutionary
algorithms how long do they

205
00:14:16.290 --> 00:14:20.190 
actually need to optimize this
specific function. So how well

206
00:14:20.490 --> 00:14:26.530 
do they perform as hill climbers and for
this we consider one specific algorithm

207
00:14:26.770 --> 00:14:31.330 
just as an example because this
is kind of also the easiest

208
00:14:31.330 --> 00:14:35.210 
algorithm one could think of,
also the most commonly analyzed

209
00:14:35.430 --> 00:14:40.120 
the (1+1) EA. EA obviously stands
for evolutionary algorithm

210
00:14:40.520 --> 00:14:44.630 
and will now find out what this one plus
one structure actually represents.

211
00:14:45.010 --> 00:14:49.360 
So the one plus one EA only
consists of a single individual

212
00:14:49.390 --> 00:14:53.200 
so there is not this population that
we introduced before but only

213
00:14:53.510 --> 00:14:58.330 
this one individual and since we're
looking at optimizing bit strings

214
00:14:58.640 --> 00:15:03.100 
this represents just one bit string
of length n, right. We also

215
00:15:03.100 --> 00:15:06.640 
talk of the genotype of this
individual then. So here we just

216
00:15:06.640 --> 00:15:10.450 
see ok is zero one and so on
just some sort of bit strings

217
00:15:10.450 --> 00:15:11.740 
that we want
to optimize

218
00:15:12.690 --> 00:15:16.820 
and now we need to create some offspring
in order to keep the algorithm

219
00:15:17.130 --> 00:15:19.510 
get it started basically,
keep it going,

220
00:15:19.950 --> 00:15:23.930 
and we do so with mutations we
only have one individual that

221
00:15:23.930 --> 00:15:28.310 
is we take the bit string we have,
we copy it and then we change

222
00:15:28.310 --> 00:15:33.130 
some of the bits in there. So for
example we see here the second

223
00:15:33.130 --> 00:15:37.520 
bit got changed from one to zero
and like also at the end of

224
00:15:37.520 --> 00:15:40.600 
this first part zero
got changed into one.

225
00:15:41.210 --> 00:15:46.630 
And the way the algorithm performs
this mutation is that for each bit

226
00:15:47.130 --> 00:15:50.710 
individually and independently of
any other changes that may occur

227
00:15:50.930 --> 00:15:54.640 
the bit is flipped with a
probability of one over n so where

228
00:15:54.650 --> 00:15:56.300 
n is the length of
the bitstring.

229
00:15:57.020 --> 00:16:01.030 
Of course this n says that in
expectation we flew one bit

230
00:16:01.240 --> 00:16:05.010 
but as you see we of course
also have the possibility

231
00:16:05.010 --> 00:16:09.350 
of flipping more than one bit or
even no bit at all basically just

232
00:16:09.450 --> 00:16:11.200 
making a copy of
an individual.

233
00:16:12.030 --> 00:16:16.220 
And now if we want to hopefully
start with one theoretical

234
00:16:16.800 --> 00:16:20.750 
point here basically, so the
probability of flipping exactly

235
00:16:20.750 --> 00:16:25.290 
one that just gives an impression of how
to calculate the probabilities in there.

236
00:16:25.590 --> 00:16:29.090 
So in order to flip exactly one
bit and I don't care about

237
00:16:29.100 --> 00:16:31.740 
which bit I flip, I just
want to flip a single bit

238
00:16:32.270 --> 00:16:36.530 
means out of the n minus one
remaining bit positions

239
00:16:36.960 --> 00:16:40.650 
none of them flips. So this is
this probability of one minus

240
00:16:40.650 --> 00:16:44.690 
one over n that means a certain
bit is not flipped and all

241
00:16:44.690 --> 00:16:48.440 
but this one bit position that
I want to flip does not flip.

242
00:16:48.610 --> 00:16:52.280 
So we get because they're all
independent one minus one over

243
00:16:52.280 --> 00:16:56.900 
n to the n minus one now if you
know some nice inequalities

244
00:16:56.900 --> 00:17:00.440 
or so you see ok this is lower
bounded by one over EA.

245
00:17:00.740 --> 00:17:04.930 
So basically a constant probability
of performing exactly one bit flip.

246
00:17:05.480 --> 00:17:08.610 
Maybe as an exercise for you you
could also think of ok how

247
00:17:08.610 --> 00:17:11.620 
can you upper bound this
term looks pretty similar.

248
00:17:12.500 --> 00:17:15.320 
But I mean this is left as an
exercise for now, I just wanted

249
00:17:15.320 --> 00:17:19.830 
to give you an impression of how we kind
of work with these probabilities.

250
00:17:20.410 --> 00:17:24.190 
Ok so now that we have these two
individuals and this is why

251
00:17:24.190 --> 00:17:27.590 
it's called the 1+1 EA because
we at the one parent

252
00:17:27.590 --> 00:17:31.990 
individual and now we have the one offspring
individual, we perform selection

253
00:17:32.160 --> 00:17:36.320 
with respect to the fitness function.
So this is where our fitness

254
00:17:36.320 --> 00:17:40.210 
function f comes into play and
here we just perform elitist

255
00:17:40.210 --> 00:17:44.360 
selection. So meaning we choose the
individual that has the better fitness.

256
00:17:44.900 --> 00:17:47.980 
And just for the sake of simplicity
assume we don't know what

257
00:17:47.980 --> 00:17:52.350 
f looks here in this example that
just the offspring wins, so

258
00:17:52.350 --> 00:17:56.770 
we kick out the parent and now we go
into the iteration process, meaning

259
00:17:57.070 --> 00:18:00.510 
this individual becomes the new
parent for the next iteration

260
00:18:00.720 --> 00:18:04.820 
and we would iterate what we
did. So this is the basic loop

261
00:18:04.820 --> 00:18:06.560 
of the1+1 EA.

262
00:18:07.400 --> 00:18:11.610 
And now we saw two things, the one hand
we had the onemax fitness function

263
00:18:11.940 --> 00:18:16.610 
and we have the 1+1 EA and now
we combine these two result.

264
00:18:17.820 --> 00:18:21.460 
So this is what we're going to
talk here. So you can see this

265
00:18:21.460 --> 00:18:25.260 
has been proven in the year two
thousand and two which is kind

266
00:18:25.260 --> 00:18:29.620 
of long ago but also not that
long ago if you think about

267
00:18:29.870 --> 00:18:33.320 
how easy the concept of evolutionary
algorithms basically is.

268
00:18:33.640 --> 00:18:37.370 
So it's a rather new
topic I would say.

269
00:18:38.280 --> 00:18:41.860 
So let's see how the theorem looks
like that combines these things

270
00:18:42.150 --> 00:18:46.840 
just says, ok, the one plus one EA
optimizes one mix of dimension n

271
00:18:47.220 --> 00:18:51.950 
in theta of n log n iterations
in expectation. So theta and

272
00:18:51.950 --> 00:18:57.550 
log n just means n look n up to constant
factors but what's important here

273
00:18:57.760 --> 00:19:02.270 
is this in expectation, because if
you recall our imitation step

274
00:19:02.280 --> 00:19:06.310 
or variation in general makes
usually use of randomness. So

275
00:19:06.310 --> 00:19:08.520 
meaning that evolutionary
algorithms are

276
00:19:08.940 --> 00:19:14.020 
random randomized algorithms and
thus mean the run time the

277
00:19:14.020 --> 00:19:17.780 
the number of iterations it takes
for them to get certain solutions

278
00:19:17.970 --> 00:19:22.330 
of course can vary and thus we make
a statement about the expected

279
00:19:22.347 --> 00:19:27.027 
the expected value of this time. So this
is why we talk about expectation here.

280
00:19:27.600 --> 00:19:31.440 
Of course one could ask why is the
expected value useful at all.

281
00:19:31.900 --> 00:19:35.860 
In fact people do not care that
much about the expectation

282
00:19:35.860 --> 00:19:41.470 
but more about concentration. So
the probability of how likely

283
00:19:41.470 --> 00:19:45.250 
is it for the algorithm for example
to take n log n iterations.

284
00:19:45.840 --> 00:19:50.690 
However the expected value usually can
be used quite well to derive such

285
00:19:50.930 --> 00:19:54.050 
concentration balance, like for
example using Markov's inequality

286
00:19:54.050 --> 00:19:58.600 
or so, you would already see the probability
that the one plus one EA takes

287
00:19:58.990 --> 00:20:04.070 
double as long on one makes then
this n log n iterations for

288
00:20:04.070 --> 00:20:10.140 
example is it most probability one half. So
we kind of already get strong concentration

289
00:20:10.470 --> 00:20:15.010 
around this n log n, a kind of
from Markov's inequality.

290
00:20:15.990 --> 00:20:20.870 
Now I wanted to highlight one
more thing regarding this

291
00:20:20.870 --> 00:20:24.840 
theorem here and this is how
the one plus one EA one makes

292
00:20:24.850 --> 00:20:29.330 
actually interact in here. So
we have our one plus one EA

293
00:20:29.730 --> 00:20:33.580 
and as I said beforehand is a
black-box optimization algorithm

294
00:20:33.580 --> 00:20:37.030 
because it's an evolutionary
algorithm that means the algorithm

295
00:20:37.030 --> 00:20:40.830 
itself does not see what's inside
of this black box, right. If

296
00:20:40.830 --> 00:20:44.250 
it knew that it would optimize
onemax it would not take so

297
00:20:44.250 --> 00:20:47.510 
long because I mean we saw
beforehand what the maximum of one

298
00:20:47.510 --> 00:20:50.160 
max is, right. It's just the
bit string that consists of

299
00:20:50.620 --> 00:20:53.930 
exclusively ones so if the
algorithm knew that it could of

300
00:20:53.930 --> 00:20:57.320 
course just output the this
respective history immediately

301
00:20:57.540 --> 00:21:01.710 
but it does not know what's in there.
So we as sneaky theoreticians

302
00:21:01.710 --> 00:21:05.300 
we can look inside of this black
box if we perform theoretical

303
00:21:05.300 --> 00:21:08.730 
analyses and then we know what's
going on but the algorithm

304
00:21:08.730 --> 00:21:12.890 
itself does not know what it's
doing. So it has to learn what

305
00:21:12.890 --> 00:21:16.740 
these structure of this function looks
like by just making these mutations

306
00:21:16.880 --> 00:21:20.130 
and then getting feedback in the
selection step from this fitness

307
00:21:20.130 --> 00:21:22.610 
function. So this is something
that's important to keep in mind.

308
00:21:22.920 --> 00:21:27.620 
This is at the heart of the analysis
of evolutionary algorithms.

309
00:21:28.580 --> 00:21:32.810 
Now if you're interested in how
this result is derived I have

310
00:21:32.810 --> 00:21:37.000 
two little pointers for you. So one
of them is the coupon collector.

311
00:21:37.210 --> 00:21:40.760 
There's a wikipedia article on that
that's quite informative actually.

312
00:21:41.170 --> 00:21:45.260 
Kind of similar problem
basically it's the 1+1 EA

313
00:21:45.640 --> 00:21:51.200 
but you only flip exactly one bit
every iteration. Then you can see ok

314
00:21:51.400 --> 00:21:55.080 
this takes already these n log
n iterations and expectation

315
00:21:55.260 --> 00:21:59.800 
and now even if you allow to flip
multiple bits but as I explained

316
00:21:59.800 --> 00:22:04.780 
beforehand with his more complex operation
as we see this doesn't change anything

317
00:22:04.940 --> 00:22:08.940 
up to constant factors with
respect to the expected value of

318
00:22:08.950 --> 00:22:11.500 
of the content of finding
an optimal solution.

319
00:22:12.210 --> 00:22:15.490 
Now of course I mean since this
is a bit more complex over

320
00:22:15.490 --> 00:22:18.980 
the years, so this result was
derived in two thousand and two.

321
00:22:19.160 --> 00:22:22.780 
So over the years better tools
have been developed to actually

322
00:22:22.780 --> 00:22:25.500 
perform this analysis
far more efficiently.

323
00:22:25.930 --> 00:22:29.460 
If you want to have a look into this
you can just search for drift theory.

324
00:22:29.730 --> 00:22:34.070 
This is a mathematical toolkit,
a toolkit of nice tools that

325
00:22:34.080 --> 00:22:38.240 
actually help you in analyzing such
processes especially evolutionary

326
00:22:38.240 --> 00:22:42.140 
algorithms. So it has been tailored with
respect to such processes in mind

327
00:22:42.360 --> 00:22:46.150 
and this gives you very easy tool
to actually derive this result

328
00:22:46.150 --> 00:22:47.630 
within just some lines.

329
00:22:48.800 --> 00:22:52.370 
And that's actually all that I
wanted to talk about today. So

330
00:22:52.380 --> 00:22:55.040 
thank you very much. I had a
lot of fun. I hope you too

331
00:22:55.620 --> 00:22:57.420 
and have a great
day. Bye.
