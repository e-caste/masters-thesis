WEBVTT

1
00:00:00.990 --> 00:00:05.470 
Welcome to Knowledge Graphs. This is lecture
number four knowledge representation

2
00:00:05.600 --> 00:00:10.410 
with ontologies. In the very first
part of this lecture we want

3
00:00:10.410 --> 00:00:14.230 
to talk about a brief
history of ontologies.

4
00:00:14.750 --> 00:00:18.740 
So you might remember from one of
the very first lectures that

5
00:00:18.750 --> 00:00:22.810 
we said people can't share knowledge if
they don't speak a common language.

6
00:00:23.300 --> 00:00:26.670 
What does it take to speak a
common language and what exactly

7
00:00:26.670 --> 00:00:32.340 
is that kind of knowledge that we want to
share? We know already that knowledge

8
00:00:32.440 --> 00:00:37.760 
is a subset of all true beliefs. And
to share that kind of knowledge

9
00:00:37.760 --> 00:00:42.240 
what we need is first common symbols
and concepts defined by syntax

10
00:00:42.480 --> 00:00:45.920 
and of course we have to come to
an agreement about their meaning

11
00:00:45.920 --> 00:00:47.200 
which is the semantics.

12
00:00:48.320 --> 00:00:53.890 
Moreover things that we have might
be aggregated might be classified

13
00:00:53.890 --> 00:00:57.760 
into concepts and stuff like that
then we have a taxonomy and

14
00:00:57.760 --> 00:01:01.340 
there are associations and
relations of those concepts which

15
00:01:01.370 --> 00:01:05.030 
then can be of course organized
with the help of a Thesaurus.

16
00:01:06.400 --> 00:01:10.810 
But what we also have to express
are rules and knowledge about

17
00:01:10.810 --> 00:01:14.380 
of course which kind of relations
are allowed and makes sense

18
00:01:14.380 --> 00:01:17.630 
and for that and to do that we
need in computer science than

19
00:01:17.630 --> 00:01:23.270 
at least ontology. So ontologies are full-fledged
knowledge representations and this

20
00:01:23.580 --> 00:01:25.900 
is what we are going
to talk about.

21
00:01:27.610 --> 00:01:33.620 
Before that let's go back in history
and talk about what was ontology

22
00:01:33.750 --> 00:01:37.910 
in the beginning. In the beginning
there were no ontologies

23
00:01:38.180 --> 00:01:43.000 
plural but there was ontology
which is kind of metaphysics.

24
00:01:43.640 --> 00:01:48.870 
In philosophy ontology is the
philosophical study of the nature

25
00:01:48.870 --> 00:01:53.850 
of being, existence, or reality,
as well as the basic categories

26
00:01:53.850 --> 00:01:59.300 
of being and their relations. And the first two
and most important philosophers of antiquity

27
00:01:59.520 --> 00:02:04.820 
they thought about exactly that stuff.
However they phrased it as metaphysics

28
00:02:04.940 --> 00:02:09.420 
was Plato and Aristotle. Aristotle
came up with the very first

29
00:02:09.620 --> 00:02:15.330 
ten basic categories in which he
tried to put all things that

30
00:02:15.330 --> 00:02:20.150 
exist in the world in terms of a
so called upper ontology. So

31
00:02:20.480 --> 00:02:23.960 
these two guys were rather
important for our subject here.

32
00:02:25.830 --> 00:02:30.030 
However nowadays the typical
computer scientist would define

33
00:02:30.030 --> 00:02:32.460 
ontology in a different
way. For us

34
00:02:33.220 --> 00:02:37.730 
ontology can be rephrased as an
explicit formal specification

35
00:02:37.730 --> 00:02:42.100 
of a shared conceptualisation. So this
pretty concise definition comes from

36
00:02:42.300 --> 00:02:44.590 
Thomas Gruber
from the 1990s.

37
00:02:45.070 --> 00:02:49.960 
And we however have to explain
every single word what it exactly

38
00:02:49.960 --> 00:02:52.220 
mean to understand it.
So let's have a look.

39
00:02:52.650 --> 00:02:56.050 
We are talking about so called
conceptualizations. What's a

40
00:02:56.050 --> 00:02:59.140 
conceptualisation? This is nothing
else but an abstract model

41
00:02:59.640 --> 00:03:02.790 
where we are talking about some
specific domain that has to

42
00:03:02.790 --> 00:03:07.750 
be modeled and we identify relevant
concepts and relations within

43
00:03:07.960 --> 00:03:13.910 
that domain. It must be explicit. This
means that all of the concepts we

44
00:03:13.910 --> 00:03:17.550 
are talking about must be defined.
If there is something undefined

45
00:03:17.550 --> 00:03:21.000 
then it's incomplete and we can't
deal with it. So it must be

46
00:03:21.010 --> 00:03:24.130 
explicit. All concepts we are
talking about should be defined.

47
00:03:25.140 --> 00:03:30.120 
Third and I guess most important
term for us as computer scientists

48
00:03:30.380 --> 00:03:35.990 
it must be a formal conceptualisation,
meaning it must be machine understandable.

49
00:03:37.420 --> 00:03:41.120 
You remember understandable
means what? Exactly.

50
00:03:41.720 --> 00:03:46.580 
You have to interpret the data correctly.
Then you understand the data. So

51
00:03:48.030 --> 00:03:52.600 
how do we do that? What can machines really
understand and interpret correctly?

52
00:03:53.000 --> 00:03:54.440 
Mostly it's logic. So

53
00:03:55.440 --> 00:04:00.670 
formal knowledge representations
are based on formal mathematical

54
00:04:00.670 --> 00:04:03.940 
logic. What kind of logic we choose
is something else. We will

55
00:04:03.940 --> 00:04:07.980 
talk about that later. But everything
here is based on logic simply

56
00:04:08.180 --> 00:04:13.100 
because we want to do inferences.
We want to do deductions and

57
00:04:13.100 --> 00:04:18.770 
this has to be valid and for that we need
really a formal mathematical logic.

58
00:04:19.910 --> 00:04:23.700 
And of course the other most
important thing here is

59
00:04:24.560 --> 00:04:28.970 
we all must reach consensus about
the ontology. If I understand

60
00:04:28.970 --> 00:04:32.690 
something completely different about
an ontology that we have defined

61
00:04:32.790 --> 00:04:33.510 
than you

62
00:04:34.770 --> 00:04:39.290 
yeah then we can't communicate. Of
course we need shared understanding.

63
00:04:39.290 --> 00:04:44.060 
We need consensus. So therefore
say it again on ontology is

64
00:04:44.060 --> 00:04:49.350 
an explicit formal specification
of a shared conceptualisation.

65
00:04:51.570 --> 00:04:56.780 
How do we now represent ontologies?
Ontologies of course can

66
00:04:56.780 --> 00:04:58.150 
be represented
by a simple

67
00:04:58.830 --> 00:05:04.590 
conceptualization that then has classes,
relations and instances. Classes themselves

68
00:05:04.860 --> 00:05:09.160 
they are abstract groups, sets or
collection of objects and they

69
00:05:09.300 --> 00:05:11.140 
represent the
ontology concepts.

70
00:05:11.900 --> 00:05:16.260 
Classes usually can characterize by their
attributes and attributes you know that

71
00:05:16.410 --> 00:05:22.090 
these are some kind name value pairs.
So for example I could define

72
00:05:22.110 --> 00:05:26.070 
carbon dioxide in a rather informal
way to say it's a colorless

73
00:05:26.070 --> 00:05:30.130 
gas with a density about sixty
percent higher than that of

74
00:05:30.140 --> 00:05:33.700 
dry air and carbon dioxide
consists of a carbon atom

75
00:05:34.140 --> 00:05:39.200 
covalently double bonded to two
oxygen atoms. That's very informal

76
00:05:39.200 --> 00:05:41.870 
and of course for a computer
difficult to read. So therefore

77
00:05:41.870 --> 00:05:47.160 
one can go step by step towards more
formal representation. So for example

78
00:05:47.370 --> 00:05:51.550 
here we have a semi formal description
of carbon dioxide where I give it

79
00:05:51.750 --> 00:05:55.790 
you know a name which is a string,
a chemical formula and mass

80
00:05:55.790 --> 00:05:59.850 
a density a sublimation temperature
and so on. So this kind

81
00:05:59.850 --> 00:06:02.590 
of list would be already a
semi formal definition.

82
00:06:04.140 --> 00:06:09.020 
However we want to go to full fledged
formal models and this means of course

83
00:06:09.190 --> 00:06:13.310 
we want to define classes that are
related to other classes and

84
00:06:13.420 --> 00:06:17.660 
we want to define relations which
are special attributes whose

85
00:06:17.660 --> 00:06:21.430 
values then of course are other
objects which means of other

86
00:06:21.430 --> 00:06:25.360 
classes and not simply values. So
here for example what you see here

87
00:06:25.560 --> 00:06:30.420 
we have defined greenhouse gas which
is a subclass of an air pollutant.

88
00:06:30.630 --> 00:06:35.980 
Likewise radioactive air pollutants which
are also a subclass of air pollutants

89
00:06:36.200 --> 00:06:40.790 
and both of them might be the
main subject of a scientific

90
00:06:41.020 --> 00:06:45.540 
article and scientific article usually
is caused by academic writing.

91
00:06:46.070 --> 00:06:50.240 
And air pollutants also have a cause
and this is usually air pollution

92
00:06:50.450 --> 00:06:54.510 
and air pollution might be
the cause of a lung cancer.

93
00:06:55.220 --> 00:07:00.200 
You see here this is a full fledged
formal model with classes

94
00:07:00.200 --> 00:07:04.210 
and relations between these classes.
But we can do more. So in

95
00:07:04.210 --> 00:07:08.510 
ontologies for example you can also
define rules or constraints that

96
00:07:08.880 --> 00:07:14.290 
define or exactly what kind of
values are allowed. So for example

97
00:07:14.290 --> 00:07:17.800 
you could say air pollution has
the cause car but not only

98
00:07:17.800 --> 00:07:22.210 
one but many cars. So this is an
end to one relation. It might

99
00:07:22.210 --> 00:07:25.460 
also have the cause of a
volcanic eruption and there of

100
00:07:25.460 --> 00:07:27.560 
course one is enough to
cause air pollution.

101
00:07:28.010 --> 00:07:31.150 
Smoke on the other hand is a
subclass of air pollution and

102
00:07:31.150 --> 00:07:35.100 
this might be a one to one
relation. So one smog event is of

103
00:07:35.100 --> 00:07:38.560 
course sub-class of one air
pollution event for example.

104
00:07:39.580 --> 00:07:42.850 
As it rain might have caused air
pollution and then you have diseases.

105
00:07:43.280 --> 00:07:48.510 
Diseases might have the cause might be
cause of an air pollution and of course

106
00:07:48.790 --> 00:07:52.160 
an air pollution can cause many
diseases and many diseases

107
00:07:52.170 --> 00:07:55.170 
or one disease can be caused by
many different kinds of air

108
00:07:55.170 --> 00:07:58.360 
pollution. So this is
an n to m constraint.

109
00:07:59.920 --> 00:08:04.830 
For the yellow embossed part that
you see here where we have

110
00:08:04.830 --> 00:08:08.040 
cars and volcanic eruptions we
might say that for example the

111
00:08:08.040 --> 00:08:12.570 
classes car and volcanic eruption they
don't share common elements, which means

112
00:08:12.790 --> 00:08:18.150 
they are disjunctive. So their intersection
is the empty set. So these are

113
00:08:19.030 --> 00:08:24.090 
example constraints that can be
represented within an ontology.

114
00:08:24.190 --> 00:08:28.640 
So these classes, relations and
constraints can be further combined

115
00:08:28.650 --> 00:08:33.640 
to form more complex statements. And
among those complex statements

116
00:08:33.640 --> 00:08:37.950 
are rather special cases of knowledge
like the so called formal axioms.

117
00:08:38.340 --> 00:08:41.760 
I give you an example of a formal
axiom based on our previous

118
00:08:41.760 --> 00:08:45.960 
example. You could say it's not
possible to disprove climate change.

119
00:08:47.100 --> 00:08:52.860 
And usually these kind of axioms describe
knowledge that cannot be expressed simply

120
00:08:53.180 --> 00:08:55.690 
with the help of the other
existing components. So they are

121
00:08:55.690 --> 00:08:58.950 
an axiom and based on that
axiom you can of course then

122
00:08:59.350 --> 00:09:02.670 
build up new deductions new
influences and stuff like that

123
00:09:02.670 --> 00:09:05.660 
and combine them with the rest
of your knowledge. So this

124
00:09:06.060 --> 00:09:10.790 
are the constituent part of
ontologies that we will talk about.

125
00:09:11.770 --> 00:09:15.130 
And of course so far we have
talked mostly about classes and

126
00:09:15.130 --> 00:09:18.610 
the relations between the classes and
the constraints between the classes.

127
00:09:18.950 --> 00:09:22.380 
There is also the instance levels
of the elements which belong

128
00:09:22.380 --> 00:09:26.380 
to those classes. As you see here
carbon dioxide might be an

129
00:09:26.380 --> 00:09:30.610 
instance of greenhouse gas which
is a subclass of air pollutant.

130
00:09:31.020 --> 00:09:34.710 
In this instance carbon dioxide of
course has a specific chemical

131
00:09:34.710 --> 00:09:37.800 
formula that is unique for that
instance and it also has a

132
00:09:37.800 --> 00:09:40.930 
name carbon dioxide which is
unique to the instance.

133
00:09:41.750 --> 00:09:45.410 
Usually you distinguish these two
different types of knowledge

134
00:09:45.410 --> 00:09:49.770 
and everything which is related to
the classes, the concepts and

135
00:09:49.940 --> 00:09:54.050 
relations in general. This is the so
called terminological knowledge

136
00:09:54.490 --> 00:09:58.200 
and on the other hand you have the
knowledge about the instances.

137
00:09:58.330 --> 00:10:01.680 
And this is the so called assertional
knowledge. And both together

138
00:10:01.680 --> 00:10:07.360 
usually form a knowledge base and in
our case also then a knowledge graph.

139
00:10:07.650 --> 00:10:11.220 
Where else we will see knowledge graphs
are more on the instance side,

140
00:10:11.370 --> 00:10:17.870 
however they are bound to ontologies
and by that gain a lot more strength

141
00:10:18.020 --> 00:10:20.040 
in terms of semantics.

142
00:10:21.210 --> 00:10:26.080 
So in the next part of the
lecture I will show you why

143
00:10:26.250 --> 00:10:29.940 
we do need logic for formal
knowledge representation.
