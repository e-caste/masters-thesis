WEBVTT

1
00:00:03.990 --> 00:00:06.820 
Hi everyone, thank you Nils for the introduction.

2
00:00:08.610 --> 00:00:12.100 
Thank you for inviting me to this talk.

3
00:00:12.880 --> 00:00:16.830 
I'll be talking about our cleanAI initiative at Krallmann.

4
00:00:17.050 --> 00:00:21.430 
which is part of our cleanIT curriculum that we are currently developing.

5
00:00:22.490 --> 00:00:25.970 
And the talk will be definitely about a tool that we're trying

6
00:00:25.970 --> 00:00:29.140 
to integrate in one of our current curriculum for cleanAI

7
00:00:29.520 --> 00:00:31.570 
which is the carbon monitor for machine learning

8
00:00:33.210 --> 00:00:36.830 
and the project advisors Prof Dr Hermann Krallmann the

9
00:00:36.830 --> 00:00:40.740 
founder of Krallmann AG and my colleague Maximilian Ambros.

10
00:00:43.560 --> 00:00:48.650 
To give you a little bit of an idea about where I work, maybe not

11
00:00:49.460 --> 00:00:54.230 
too much detail but we're located in Berlin, Munich and

12
00:00:54.410 --> 00:00:55.930 
Hamburg where I'm currently sitting.

13
00:00:57.360 --> 00:01:00.150 
So the company was founded in 2006

14
00:01:00.970 --> 00:01:03.330 
by Prof. Dr Hermann Krallmann.

15
00:01:04.980 --> 00:01:09.060 
We have a bit more than a hundred employees at the company

16
00:01:09.360 --> 00:01:13.310 
and some freelancers. We have a number of

17
00:01:13.870 --> 00:01:20.080 
customers in different areas or industries from banking to insurance,

18
00:01:20.340 --> 00:01:24.570 
the energy sector, innovation, and and also some collaboration

19
00:01:24.570 --> 00:01:25.860 
with universities as well.

20
00:01:28.010 --> 00:01:30.010 
Our main areas

21
00:01:30.710 --> 00:01:33.860 
of services are in process digitalization,

22
00:01:34.390 --> 00:01:38.820 
in particularly for process mining and robotic process automation

23
00:01:38.820 --> 00:01:43.750 
and business process management. And in the area of cloud strategy, we

24
00:01:43.920 --> 00:01:48.700 
have also conducted a number of project for cloud information and security

25
00:01:50.650 --> 00:01:54.100 
and also in the area of interior management.

26
00:01:55.220 --> 00:01:56.910 
We have different project managers here

27
00:01:57.310 --> 00:02:03.440 
at our company who are able to do different projects from

28
00:02:03.440 --> 00:02:05.810 
coaching and managing projects

29
00:02:07.890 --> 00:02:11.680 
from the beginning and then also in terms of doing facility

30
00:02:11.680 --> 00:02:16.130 
management and operations as well. And we have also particular

31
00:02:16.130 --> 00:02:19.710 
focus in the software engineering area as well as software

32
00:02:19.710 --> 00:02:23.580 
modernization chatbot development and so on.

33
00:02:24.090 --> 00:02:29.730 
And also we have quite interesting projects in the area of data science

34
00:02:30.100 --> 00:02:34.960 
concerning machine learning, cloud data warehousing, and especially NLU NLP

35
00:02:35.970 --> 00:02:38.570 
we have done quite a lot of interesting projects.

36
00:02:41.960 --> 00:02:46.090 
And coming to my talk today, I think sort of a motivation

37
00:02:46.170 --> 00:02:48.960 
for today's talk definitely

38
00:02:49.680 --> 00:02:53.360 
would be like the Clean IT curriculum we're developing at the moment.

39
00:02:54.170 --> 00:02:58.620 
It's quite a growing area and

40
00:02:59.130 --> 00:03:01.730 
we have seen four components to it.

41
00:03:02.250 --> 00:03:07.840 
One side is with regards to idea organization Clean IT

42
00:03:08.760 --> 00:03:14.010 
organization level. How can we actually sort of adopt best practices

43
00:03:14.760 --> 00:03:18.190 
at the thought of and are at an organization level

44
00:03:18.770 --> 00:03:22.750 
and the other one is with regards to data centers, power data centers

45
00:03:22.910 --> 00:03:27.190 
constructed, how much energy do they sort of consume?

46
00:03:27.750 --> 00:03:31.780 
So what I thought of the possibilities to two kind of way

47
00:03:31.780 --> 00:03:36.100 
to put your data centers looking in terms of where the green

48
00:03:36.800 --> 00:03:40.370 
energy so to say.

49
00:03:41.560 --> 00:03:44.470 
And also in terms of sustainable software engineering

50
00:03:45.080 --> 00:03:50.220 
how can we sort of have efficient algorithms and also in terms of databases

51
00:03:50.650 --> 00:03:54.450 
how can we have like sort of efficient database structures,

52
00:03:54.850 --> 00:03:58.380 
which is sort of part of the sustainable software engineering.

53
00:03:59.250 --> 00:04:04.050 
In particular what I'll be talking about is the cleanAI module

54
00:04:04.790 --> 00:04:07.110 
which is also part of the cleanIT curriculum.

55
00:04:07.920 --> 00:04:10.050 
AI particularly machine learning

56
00:04:10.770 --> 00:04:14.040 
has produced tremendous results in the past few years

57
00:04:14.650 --> 00:04:16.020 
and of course

58
00:04:19.090 --> 00:04:22.980 
they're quite tremendous and and add so much value

59
00:04:23.440 --> 00:04:29.190 
starting from like face recognition, like playing games

60
00:04:29.910 --> 00:04:34.760 
with regards to a reinforcement learning like go and chess. But

61
00:04:35.170 --> 00:04:37.860 
how much energy is consumed? To do all this

62
00:04:38.590 --> 00:04:43.180 
the models are trained for more than maybe weeks or even months.

63
00:04:44.230 --> 00:04:48.410 
So during this process of course a lot of energy is consumed and

64
00:04:49.030 --> 00:04:50.610 
other other result of that

65
00:04:51.420 --> 00:04:56.030 
is a large amount of carbon dioxide emitted of course. And

66
00:04:56.490 --> 00:05:00.440 
this really also depends on the energy mix

67
00:05:01.300 --> 00:05:03.790 
which is used to power the local electricity grid.

68
00:05:04.590 --> 00:05:06.420 
It could be called petroleum

69
00:05:07.340 --> 00:05:11.300 
or it could also be renewable energy sources which is better.

70
00:05:13.740 --> 00:05:18.620 
What is interesting is like this was sort of a paper

71
00:05:18.760 --> 00:05:24.360 
done by a researcher from a MIT amherst a group of researchers

72
00:05:24.840 --> 00:05:29.280 
What they did was like sort of try to benchmark the state of the art

73
00:05:30.100 --> 00:05:35.610 
NLP models from bird to gpt to elmo and then what they came

74
00:05:35.610 --> 00:05:40.300 
up with was quite interesting comparing the amount of carbon

75
00:05:41.150 --> 00:05:46.340 
dioxide emitted which was to train AI models consumes about three hundred

76
00:05:46.460 --> 00:05:49.550 
equivalent to three hundred round trips from San francisco to New york.

77
00:05:49.730 --> 00:05:54.420 
Or it could be also equivalent to how much five cars emit

78
00:05:55.150 --> 00:05:58.740 
during their lifetime which is the carbon content.

79
00:05:59.190 --> 00:06:04.330 
So this is quite a popular paper in this area

80
00:06:07.780 --> 00:06:10.490 
and then to talk a little bit about our clean IT curriculum,

81
00:06:10.490 --> 00:06:14.710 
what we intend to have six modules where we thought of an overview

82
00:06:15.170 --> 00:06:19.970 
and then also clean IT in the cloud and in the area of clean AI

83
00:06:20.390 --> 00:06:24.260 
sustainable software engineering and also clean IT at

84
00:06:24.810 --> 00:06:30.180 
organization level in different IT projects how can we sort of adopt

85
00:06:30.480 --> 00:06:35.000 
different best practices to also manage projects,

86
00:06:35.180 --> 00:06:42.020 
So this is kind of a what is driving a the cleanAI part because

87
00:06:42.020 --> 00:06:46.900 
we wanted to have sort of a practical

88
00:06:46.900 --> 00:06:50.020 
engagement with also people. We're going to take

89
00:06:50.070 --> 00:06:52.180 
the training or the thought of the curriculum

90
00:06:52.990 --> 00:06:57.320 
so that it is interesting and then it's kind of actual so they have

91
00:06:57.460 --> 00:07:01.970 
some kind of tool to kind of play with and then measure the

92
00:07:02.130 --> 00:07:03.390 
carbon footprint.

93
00:07:07.240 --> 00:07:10.730 
And then these are quite the guiding questions

94
00:07:10.740 --> 00:07:13.670 
of why we wanted to implement the tool.

95
00:07:14.700 --> 00:07:19.710 
They are the four core points how much energy the training

96
00:07:19.710 --> 00:07:23.520 
of models consume and how do

97
00:07:23.520 --> 00:07:28.150 
we measure that consumption in complex training complex AI models.

98
00:07:29.340 --> 00:07:33.970 
Are there any optimisation potentials or trade-offs in terms of accuracy

99
00:07:34.330 --> 00:07:39.880 
and efficiency as well and lastly how do we monitor the

100
00:07:39.880 --> 00:07:45.050 
carbon footprint which is quite important for us.

101
00:07:49.570 --> 00:07:53.950 
So I think maybe to give a brief background

102
00:07:54.070 --> 00:07:58.250 
how we measure the carbon footprint we intend to measure and because

103
00:07:58.580 --> 00:08:02.020 
we're still improving the tool.So how do we

104
00:08:02.020 --> 00:08:03.210 
measure the carbon footprint

105
00:08:06.110 --> 00:08:08.190 
so as I said I mean machine learning

106
00:08:08.810 --> 00:08:12.650 
has produced so many great results a lot of benefits but a

107
00:08:12.650 --> 00:08:16.670 
lot of energy consumption to process large amount of data and training models.

108
00:08:17.280 --> 00:08:21.450 
So the right question to ask is how do we measure one and then

109
00:08:21.450 --> 00:08:23.810 
the next step is how do we compare

110
00:08:25.040 --> 00:08:27.610 
different running different models in terms of

111
00:08:28.220 --> 00:08:31.910 
the carbon footprint that is important, and then how do we track

112
00:08:32.240 --> 00:08:37.360 
the emission of training the models on-premise or on cloud.

113
00:08:38.390 --> 00:08:43.160 
And going further we can say are there any optimization opportunities?

114
00:08:43.350 --> 00:08:46.110 
Currently we look at three different

115
00:08:46.620 --> 00:08:51.320 
cases or options, one is going at a code level

116
00:08:51.360 --> 00:08:54.280 
called optimization, you can have

117
00:08:54.760 --> 00:08:58.850 
the other one is maybe sort of introducing

118
00:08:59.390 --> 00:09:02.970 
some form of cost function where we can penalize

119
00:09:04.060 --> 00:09:08.510 
models with the kind of go beyond a certain threshold

120
00:09:08.520 --> 00:09:12.070 
for carbon emission that could be one option. And the other one is

121
00:09:12.190 --> 00:09:15.540 
of course cloud locations we could

122
00:09:15.980 --> 00:09:19.950 
prefer or choose to train our models in the cloud where

123
00:09:20.560 --> 00:09:21.910 
there's more green energy.

124
00:09:23.130 --> 00:09:27.380 
It could be Google cloud platform or the Amazon

125
00:09:27.380 --> 00:09:29.390 
or Microsoft Azure. So these are

126
00:09:30.280 --> 00:09:31.180 
the possibilities.

127
00:09:35.430 --> 00:09:38.970 
So having seen that then we wanted to come up with

128
00:09:38.970 --> 00:09:42.510 
what features do we want, our tool to have

129
00:09:44.080 --> 00:09:45.040 
for the first that comes

130
00:09:45.840 --> 00:09:49.840 
as it should be python based as most of the machine learning

131
00:09:50.450 --> 00:09:54.270 
is happening in python and we want the tool to actually integrate

132
00:09:54.610 --> 00:09:57.110 
existing code bases easily.

133
00:09:58.750 --> 00:10:03.030 
And also we wanted to be in terms of extensibility

134
00:10:03.780 --> 00:10:06.630 
whenever there's a new hardware that we want

135
00:10:06.630 --> 00:10:10.170 
to measure the power, for then we should be able to easily

136
00:10:10.170 --> 00:10:13.340 
integrate that and into the tool

137
00:10:13.840 --> 00:10:17.550 
and flexibility of course. The user should have

138
00:10:17.550 --> 00:10:21.480 
full control of what is actually monitored and that because

139
00:10:21.820 --> 00:10:28.120 
then they can get some form of ability to compare and contrast

140
00:10:28.550 --> 00:10:32.350 
running different training models, analyze the data and

141
00:10:32.350 --> 00:10:33.980 
come up with a report.

142
00:10:35.740 --> 00:10:37.770 
And the other one is automatic.

143
00:10:38.480 --> 00:10:41.450 
Currently, what we have it like sort of a command line tool where we

144
00:10:41.940 --> 00:10:44.790 
run on the command line and then produce

145
00:10:44.790 --> 00:10:46.760 
visualisation after the training is

146
00:10:47.610 --> 00:10:51.360 
finished. But we want to give the option to

147
00:10:52.460 --> 00:10:56.050 
automatically produce the visualizations and the carbon footprint

148
00:10:56.170 --> 00:10:57.840 
in the process

149
00:10:59.340 --> 00:11:04.300 
environment. Of course we want the tool to

150
00:11:04.660 --> 00:11:08.070 
be easily accessible or could be imported in any

151
00:11:08.740 --> 00:11:11.660 
python environment. It could be in the cloud or local machine

152
00:11:12.170 --> 00:11:16.110 
so that would be a nice feature to have

153
00:11:16.790 --> 00:11:21.890 
and the other one is recommendation. So it should be able to produce

154
00:11:22.210 --> 00:11:28.390 
a form of suggestion of a computed carbon equivalent value

155
00:11:28.540 --> 00:11:32.210 
if the model would have been run in a different cloud platform

156
00:11:32.220 --> 00:11:34.250 
of a region and of a different region.

157
00:11:35.180 --> 00:11:39.060 
So this kind of insights could be really not nice to have at all

158
00:11:43.440 --> 00:11:46.150 
and coming back to the carbon footprint estimation.

159
00:11:47.270 --> 00:11:52.390 
So currently what we do is with regards to the carbon footprint composition

160
00:11:52.770 --> 00:11:54.550 
we have three options,

161
00:11:55.210 --> 00:11:59.670 
one is the global energy mix data that we've been able to extract

162
00:12:00.370 --> 00:12:04.560 
and the other one is cloud emissions data. Our impact

163
00:12:04.680 --> 00:12:07.690 
which will be implemented in the next phase

164
00:12:08.140 --> 00:12:12.430 
and the other one is current tree emissions data where we have

165
00:12:12.450 --> 00:12:16.100 
the energy mix to generate the electricity

166
00:12:17.770 --> 00:12:22.870 
grid for each country. So that we can then

167
00:12:22.870 --> 00:12:27.810 
use those to estimate the carbon footprint

168
00:12:28.370 --> 00:12:34.550 
from hardware power consumption. So the focus for

169
00:12:34.710 --> 00:12:37.030 
the first phase with more from hardware site,

170
00:12:37.570 --> 00:12:41.280 
next iterative step would be including

171
00:12:41.280 --> 00:12:46.070 
the cloud emissions data with regard to google cloud computing.

172
00:12:46.100 --> 00:12:50.860 
So we want to have a precise estimate

173
00:12:51.570 --> 00:12:53.990 
with regards to cloud emissions data.

174
00:12:54.820 --> 00:12:57.660 
One important factor

175
00:12:58.700 --> 00:13:02.890 
which would be important is the power that effectiveness

176
00:13:04.460 --> 00:13:08.280 
which would be used in the estimation process,

177
00:13:09.870 --> 00:13:13.480 
and then the other one of course the electric energy consumption of the hardware.

178
00:13:13.690 --> 00:13:16.800 
This is also the important part for the estimation

179
00:13:20.100 --> 00:13:23.220 
to give a general idea what

180
00:13:23.220 --> 00:13:28.640 
the theory is. I won't go into how it's computed in detail but it is

181
00:13:29.040 --> 00:13:33.610 
a factor which tells us how efficient

182
00:13:33.780 --> 00:13:39.290 
a computer data center effectively uses or consumes the energy

183
00:13:40.330 --> 00:13:43.770 
to put it in a general formula we can have it

184
00:13:43.770 --> 00:13:48.180 
like total facility energy divided by the equipment energy.

185
00:13:49.980 --> 00:13:54.810 
So the interesting part about PUE is it's

186
00:13:54.980 --> 00:13:56.390 
the most popular

187
00:13:57.260 --> 00:14:00.990 
factor used for estimation but maybe one interesting

188
00:14:01.590 --> 00:14:07.480 
thing that needs to be considered is it doesn't take into account the location,

189
00:14:07.730 --> 00:14:12.340 
for example a data center which is put in a location where the temperature is

190
00:14:12.540 --> 00:14:17.670 
higher and also considering a data center which is put in a

191
00:14:17.930 --> 00:14:20.380 
location where there's lot of low temperature.

192
00:14:20.940 --> 00:14:26.520 
Then if you have for example the data center and a location with higher temperature

193
00:14:26.790 --> 00:14:32.340 
let's say, 1.6, and value of 1.5 PE and then

194
00:14:32.380 --> 00:14:37.290 
the data center in a location with low temperature. Let's say 1.5

195
00:14:37.980 --> 00:14:41.310 
then the idea is how can we incorporate

196
00:14:41.940 --> 00:14:42.900 


197
00:14:44.140 --> 00:14:50.620 
a temperature like outside temperature for estimation? Because of course

198
00:14:51.350 --> 00:14:55.310 
we have to take into consideration like not only the equipment

199
00:14:55.310 --> 00:14:58.280 
energy is important but there are also other overheads like

200
00:14:58.290 --> 00:15:02.940 
cooling and lighting for the infrastructure so those needs to be considered.

201
00:15:03.110 --> 00:15:07.060 
And then if you consider actually the cooling of course in terms of temperature

202
00:15:07.780 --> 00:15:11.520 
a data centre in low temperature area wouldn't need

203
00:15:11.520 --> 00:15:14.840 
as much energy for it for the cooling system. So

204
00:15:15.370 --> 00:15:17.410 
that is actually one

205
00:15:18.460 --> 00:15:21.880 
important thing to consider here and the typical values are

206
00:15:21.880 --> 00:15:23.960 
1.5

207
00:15:25.260 --> 00:15:28.930 
and the actual the ideal value two would be 1.

208
00:15:29.190 --> 00:15:33.320 
That's the aim, so here what we have is sort of

209
00:15:33.320 --> 00:15:36.820 
a general formula how we compute the total electric consumption where

210
00:15:36.950 --> 00:15:39.830 
we say he total which is measured in kilowatt hours

211
00:15:40.250 --> 00:15:43.290 
and then we have thought of the role power consumption of the

212
00:15:43.290 --> 00:15:46.410 
device and then we multiply that by the

213
00:15:46.870 --> 00:15:50.330 
power usage effectiveness coefficient or factor

214
00:15:51.160 --> 00:15:55.550 
and the next step is computing the carbon footprint which is in kilograms

215
00:15:55.880 --> 00:16:00.210 
where we take the total electric consumption and then multiply that by

216
00:16:00.320 --> 00:16:04.010 
the carbon intensity which is in kilograms per kilowatt hour

217
00:16:04.560 --> 00:16:09.120 
and the carbon intensity of the electric electricity consumed is

218
00:16:09.330 --> 00:16:14.700 
actually based on the weighted average of emissions from the different energy sources

219
00:16:14.890 --> 00:16:17.250 
and those energy sources depend

220
00:16:17.670 --> 00:16:22.730 
on the mix of energy sources that are used to power the local electricity grid.

221
00:16:22.970 --> 00:16:23.610 


222
00:16:28.910 --> 00:16:32.270 
And then what is interesting for us is

223
00:16:32.720 --> 00:16:37.610 
applying those things that i've mentioned before.

224
00:16:38.060 --> 00:16:41.880 
The features for the tool building and then applying that to

225
00:16:42.020 --> 00:16:44.640 
a use case, a project we're currently running

226
00:16:45.770 --> 00:16:49.640 
we tested it on a sample data set

227
00:16:50.170 --> 00:16:53.530 
so that the case what we have is of a harmonised

228
00:16:53.530 --> 00:16:55.190 
or HS code classification,

229
00:16:56.040 --> 00:16:58.970 
this is quite an interesting

230
00:16:59.410 --> 00:17:05.760 
project. So the idea is we want to predict

231
00:17:06.220 --> 00:17:10.750 
the correct HS code for international movement of goods based on

232
00:17:10.980 --> 00:17:13.860 
product description which is provided by the user

233
00:17:15.350 --> 00:17:18.180 
as you can see here on the screen,

234
00:17:18.890 --> 00:17:23.670 
the idea is we have a t shirt here and then we have thirteen digits.

235
00:17:23.790 --> 00:17:25.880 
As you can see we have six

236
00:17:26.650 --> 00:17:29.550 
digits which are of international standard and the rest

237
00:17:29.550 --> 00:17:32.740 
four are specific to. countries

238
00:17:33.270 --> 00:17:38.910 
So we took a eight digit code a commodity HS codes,

239
00:17:39.460 --> 00:17:42.830 
a data set and then we wanted to predict

240
00:17:44.370 --> 00:17:49.350 
the class. So as you can see here they're thought of hierarchies, there is

241
00:17:49.450 --> 00:17:53.890 
the first two digits are chapters and the second the next two are like headings

242
00:17:54.320 --> 00:17:57.900 
and then as you continued down there you have like sort of sub-categories

243
00:17:58.290 --> 00:18:01.610 
and then you have heading, subheading and as you go down the

244
00:18:01.610 --> 00:18:05.150 
hierarchy then the differences between the individual items becomes

245
00:18:05.820 --> 00:18:09.690 
quite small. The difference in terms of description

246
00:18:09.690 --> 00:18:10.910 
is quite the challenge

247
00:18:11.730 --> 00:18:16.640 
and also the descriptions are usually short. So we had this to challenge so

248
00:18:17.260 --> 00:18:20.280 
we had implemented

249
00:18:21.210 --> 00:18:27.870 
a fusion, a classifier, where we say maybe the text classifier of course produces

250
00:18:28.780 --> 00:18:34.710 
good results but can we add another input like image

251
00:18:35.070 --> 00:18:38.790 
so that we can combine the two and then come up with

252
00:18:38.880 --> 00:18:41.630 
a combined

253
00:18:42.560 --> 00:18:45.520 
prediction based on the two classifiers

254
00:18:46.010 --> 00:18:48.080 
and then finally predict

255
00:18:49.140 --> 00:18:50.150 
the eight digit code.

256
00:18:50.870 --> 00:18:56.950 
As you see here, so the interesting sort of results are so

257
00:18:57.360 --> 00:19:01.390 
we use two convolutional neural network classifiers

258
00:19:03.220 --> 00:19:07.320 
and then came up finally got like a ninety percent accuracy

259
00:19:08.040 --> 00:19:11.530 
and the other one is like for the text classifier. We applied

260
00:19:11.530 --> 00:19:14.960 
the birch model which is a state-of-the-art NLP model

261
00:19:15.580 --> 00:19:18.810 
and then ofcourse a convolutional neural network. Combining

262
00:19:18.810 --> 00:19:22.010 
the two we get a ninety six percent. So we have

263
00:19:22.200 --> 00:19:26.570 
a six percent jump and then looking at it generally we have

264
00:19:26.570 --> 00:19:30.850 
a one percent improvement over the text-only classifier.

265
00:19:30.860 --> 00:19:33.750 
As you can see, you have eighty five that is the maximum

266
00:19:35.160 --> 00:19:37.770 
and then the difference from ninety six percent is

267
00:19:40.710 --> 00:19:42.840 
the maximum

268
00:19:43.600 --> 00:19:46.720 
for the text classifier, so the difference is

269
00:19:46.720 --> 00:19:49.930 
one percent improvement over the text-only classifier and then

270
00:19:49.930 --> 00:19:54.140 
looking at the image classifier we have a twelve percent improvement

271
00:19:54.280 --> 00:19:59.090 
over image only classifier. So the idea is the question to ask here now is

272
00:19:59.630 --> 00:20:03.640 
how can we optimize the accuracy and energy efficiency

273
00:20:03.640 --> 00:20:08.780 
of the trend models? Are we happy with ninety percent or ninety six percent?

274
00:20:09.440 --> 00:20:12.930 
So that's what we're trying to answer. And then

275
00:20:13.590 --> 00:20:15.950 
now let's go to the

276
00:20:16.610 --> 00:20:20.540 
generated output from the tool. So what we have here is

277
00:20:20.540 --> 00:20:24.310 
the same output for the convolutional neural network model

278
00:20:25.590 --> 00:20:28.780 
as we have, as you can see here we have different details

279
00:20:30.080 --> 00:20:34.150 
and then we have equivalent carbon emission and then where

280
00:20:34.760 --> 00:20:39.250 
their model was trained in terms of location, where the machine which is on

281
00:20:40.300 --> 00:20:44.750 
on-premise not in a cloud and then how long it took

282
00:20:45.370 --> 00:20:46.730 
over the sample data set?

283
00:20:47.520 --> 00:20:50.790 
And as you can see here we have the total carbon emission

284
00:20:50.790 --> 00:20:53.730 
of 0.0 kilograms which is quite

285
00:20:55.690 --> 00:21:00.390 
right. Why is that zero? Because we can see there so

286
00:21:00.410 --> 00:21:04.340 
it has been rounded to one decimal point that way

287
00:21:04.370 --> 00:21:09.150 
because it was quite a low value, but to go over that or to help

288
00:21:09.290 --> 00:21:11.290 
and understanding the emission then

289
00:21:11.690 --> 00:21:15.890 
we computed an equivalent carbon emission value

290
00:21:16.040 --> 00:21:17.360 
comparing it to

291
00:21:17.980 --> 00:21:22.230 
household emissions and then how many miles driven

292
00:21:22.570 --> 00:21:27.210 
and also number of minutes or hours of

293
00:21:27.220 --> 00:21:29.210 
a thirty two inch LCD tv watched.

294
00:21:30.350 --> 00:21:34.440 
As you can see here, well I thought of almost 0.3 or 0.2 percent

295
00:21:34.840 --> 00:21:37.710 
which is quite low and then this is equivalent to

296
00:21:37.710 --> 00:21:38.870 
sixteen minutes

297
00:21:39.470 --> 00:21:42.710 
or thirty two inch LCD tv watched. So this is

298
00:21:43.190 --> 00:21:49.620 
for the CNN model and then going to the burtt model now we can see quite

299
00:21:49.880 --> 00:21:54.630 
an improvement in the total

300
00:21:54.630 --> 00:21:56.650 
carbon emission. So we have a value there

301
00:21:57.160 --> 00:22:00.470 
which is 0.3 kilograms

302
00:22:01.450 --> 00:22:05.690 
and then equivalent carbon emission of 16

303
00:22:05.690 --> 00:22:08.410 
percent which is 0.16 percent

304
00:22:09.150 --> 00:22:13.510 
of weekly american household emissions and this is also equivalent

305
00:22:13.510 --> 00:22:20.230 
to one miles driven and three hours of thirty two inch LCD tv watched.

306
00:22:20.340 --> 00:22:24.510 
This training took about fifty three minutes on our sample data set

307
00:22:25.050 --> 00:22:29.720 
and then it was run on the same

308
00:22:29.770 --> 00:22:30.600 
infrastructure.

309
00:22:34.350 --> 00:22:38.450 
So the idea is we want to have a visual

310
00:22:38.450 --> 00:22:43.850 
representation as well as of descriptive values

311
00:22:44.300 --> 00:22:48.120 
and an outcome later to what we want to implement

312
00:22:48.120 --> 00:22:49.570 
in the next phase.

313
00:22:51.590 --> 00:22:55.070 
So what are the outlook and what are the

314
00:22:55.070 --> 00:23:01.700 
next steps for us? So one we want to make this an integrated dashboard.

315
00:23:02.590 --> 00:23:06.680 
We had seen that the carbon footprint view but

316
00:23:06.690 --> 00:23:11.260 
we want to integrate a training experiment set up view where

317
00:23:11.780 --> 00:23:15.230 
person running the training could actually compare

318
00:23:15.230 --> 00:23:17.620 
and contrast the different experiments run

319
00:23:18.100 --> 00:23:22.810 
and then see the trade-off between accuracy and

320
00:23:23.060 --> 00:23:24.170 
energy efficiency.

321
00:23:25.530 --> 00:23:28.110 
The other one as I mentioned before, we want to have sort of

322
00:23:28.490 --> 00:23:31.760 
automatic generation of the visualizations for the carbon footprint

323
00:23:33.420 --> 00:23:37.160 
and also what is very important is having integration for the

324
00:23:37.510 --> 00:23:40.310 
cloud carbon footprint. We want our tool to run in the cloud

325
00:23:40.310 --> 00:23:42.490 
and then be able to sort of measure

326
00:23:43.100 --> 00:23:45.770 
the carbon emission for Google,

327
00:23:47.130 --> 00:23:49.070 
AWS and Microsoft Azure

328
00:23:50.520 --> 00:23:54.250 
and also the intention is to have

329
00:23:56.180 --> 00:24:00.110 
a proactive and intervention driven approach to stop

330
00:24:00.110 --> 00:24:02.050 
the model training.

331
00:24:02.930 --> 00:24:06.190 
A set threshold of environmental cost is exceeded,

332
00:24:06.660 --> 00:24:09.470 
then we can give the person running the experiment to have

333
00:24:09.470 --> 00:24:13.570 
this kind of flexibility to decide what to do

334
00:24:13.850 --> 00:24:18.830 
and then in the end we want our tool to be a python package

335
00:24:19.380 --> 00:24:24.110 
and then it could be easily applied to a different pattern code basis.

336
00:24:28.490 --> 00:24:33.340 
Thank you for the presentation, I think it was very interesting to see this

337
00:24:33.450 --> 00:24:37.550 
tool being presented by you and I can see that we already have

338
00:24:37.550 --> 00:24:42.860 
one clapping from the zoom set and yeah I think after the presentation

339
00:24:42.860 --> 00:24:46.950 
we can now head over to the QnA session as always so if

340
00:24:46.950 --> 00:24:50.910 
there's anyone in the call who has any questions you can either

341
00:24:50.910 --> 00:24:52.760 
just raise your hand so that we can pick you

342
00:24:53.340 --> 00:24:57.070 
or speak out your question right away if there's nobody else talking right now.

343
00:24:57.250 --> 00:25:01.060 
And so I would just wait one or two seconds is there

344
00:25:01.060 --> 00:25:03.040 
already anyone having a question right now?

345
00:25:06.470 --> 00:25:11.000 
I think I see a hand up, not sure

346
00:25:12.100 --> 00:25:14.120 
and yes I guess that's mine.

347
00:25:15.640 --> 00:25:20.160 
And I have a question regarding the PUE,

348
00:25:21.460 --> 00:25:24.710 
do you have any kind of solution for the problem? Because I think

349
00:25:25.430 --> 00:25:27.340 
it's not only I guess, it's not only

350
00:25:28.900 --> 00:25:32.410 
different PUE in different locations but I guess it's

351
00:25:32.710 --> 00:25:35.630 
also during summer time and during winter time.

352
00:25:35.630 --> 00:25:38.440 
It's also different because in summer time the cooling

353
00:25:39.530 --> 00:25:42.030 
I mean you need more energy for the cooling during summer

354
00:25:42.030 --> 00:25:43.500 
do you have any solution for that?

355
00:25:44.610 --> 00:25:48.490 
That's a good question, yeah we haven't really

356
00:25:48.610 --> 00:25:51.780 
focused on the optimization of the PUE but

357
00:25:51.780 --> 00:25:54.390 
I think that that's also one factor that needs to

358
00:25:54.390 --> 00:25:57.550 
be looked at if this is kind of a first

359
00:25:58.280 --> 00:26:02.010 
try like in building the tool but there's quite room for

360
00:26:02.130 --> 00:26:03.840 
a lot of improvement.

361
00:26:07.540 --> 00:26:10.700 
I can already see that we have one other question in the chat

362
00:26:11.220 --> 00:26:16.550 
by deadlift how do you determine or measure the raw energy

363
00:26:16.770 --> 00:26:19.310 
from your familiar earlier thing? I think you can also just

364
00:26:19.320 --> 00:26:20.770 
go back in these slides if you want to.

365
00:26:28.370 --> 00:26:32.790 
Wwhat we're currently using is

366
00:26:32.920 --> 00:26:35.070 
we've collected some data sets of different

367
00:26:35.590 --> 00:26:39.770 
kind of benchmarks of different CPU models and GPUs.

368
00:26:40.510 --> 00:26:42.530 
So we're currently actually applying

369
00:26:43.240 --> 00:26:46.670 
that data set so the measures or the benchmarks from that

370
00:26:46.670 --> 00:26:50.480 
data set to two and then we try to measure the

371
00:26:50.900 --> 00:26:53.160 
the kind of the power consumption with

372
00:26:53.940 --> 00:26:57.390 
it's flexible we can set the threshold for the time interval.

373
00:26:57.990 --> 00:27:01.150 
We're just using now like fifteen seconds but it could be kind of

374
00:27:01.650 --> 00:27:03.530 
a number of factors, a number of

375
00:27:04.380 --> 00:27:09.370 
possibilities are there so we're actually using already benchmarked

376
00:27:10.390 --> 00:27:13.170 
values for the power consumption.

377
00:27:14.370 --> 00:27:17.820 


378
00:27:19.140 --> 00:27:20.680 
Just a follow up, so

379
00:27:22.020 --> 00:27:27.050 
you just mentioned using a benchmarks or you also mentioned measure?

380
00:27:27.280 --> 00:27:30.590 
Does this mean you have a for example power meter on a

381
00:27:30.610 --> 00:27:34.070 
dedicated server that you can read to measure the electricity consumption.

382
00:27:34.590 --> 00:27:35.840 
Was it really just

383
00:27:37.130 --> 00:27:41.380 
using the benchmarks? Using the benchmarks for now

384
00:27:42.090 --> 00:27:45.340 
first test case.

385
00:27:48.030 --> 00:27:50.250 
Ok thanks, so I think one more question

386
00:27:51.290 --> 00:27:53.160 
that we had here in the HPI,

387
00:27:53.890 --> 00:27:57.450 
Do you plan on open sourcing your tool or maybe as a further

388
00:27:57.620 --> 00:28:00.710 
follow up question and how is it available currently? So

389
00:28:00.730 --> 00:28:04.820 
could I use it as a user for myself at home or

390
00:28:05.390 --> 00:28:09.050 
do I have to ask the Krammlen AG or what's the plan for that?

391
00:28:10.010 --> 00:28:12.610 
we haven't really discussed about it but i think it's

392
00:28:13.110 --> 00:28:17.850 
more nice as an open source. Yeah I think we have to

393
00:28:17.850 --> 00:28:19.330 
talk about it but

394
00:28:19.940 --> 00:28:23.080 
it would be more interesting for other people to also extended their

395
00:28:23.240 --> 00:28:27.590 
ideas and I think that will be more important for collaborative effort.

396
00:28:27.760 --> 00:28:32.020 
Yes I think if I remember correctly, you said that you wanted

397
00:28:32.020 --> 00:28:33.980 
to create a python package?

398
00:28:35.320 --> 00:28:39.730 
I think that's one of the plans to extend it

399
00:28:39.730 --> 00:28:42.030 
and I think then it would be quite easy for anyone

400
00:28:42.520 --> 00:28:46.860 
to use it. Yes so right now is there any way I could use the

401
00:28:46.860 --> 00:28:50.900 
common monitor already or is it just in production

402
00:28:50.930 --> 00:28:53.370 
at the moment? It's in production at the moment because it's

403
00:28:53.520 --> 00:28:57.620 
a lot of development remaining, but

404
00:28:57.790 --> 00:29:02.090 
definitely there will be soon a way to use it.

405
00:29:02.390 --> 00:29:06.290 
Yes maybe we can do some follow up if you have made it available

406
00:29:06.550 --> 00:29:10.360 
in some money, I mean the idea is we want

407
00:29:10.550 --> 00:29:14.370 
a state building the curriculum, we want to kind of

408
00:29:15.170 --> 00:29:18.300 
people to use it in a way like it doesn't have to be only

409
00:29:18.300 --> 00:29:21.170 
theoretical so they can play with different algorithms,

410
00:29:21.180 --> 00:29:26.060 
measure the carbon emissions and try to find out what

411
00:29:26.060 --> 00:29:30.420 
is reasonable or if we can optimize and find a tradeoff?

412
00:29:30.740 --> 00:29:35.700 
Yes right there and I see this one and what question from the chair

413
00:29:36.100 --> 00:29:39.460 
where can we read more on your tool is there any kind of documentation

414
00:29:39.460 --> 00:29:42.390 
or other presentations or online resources?

415
00:29:42.820 --> 00:29:46.550 
This is actually the first presentation we're doing,

416
00:29:46.550 --> 00:29:50.080 
but I think we'll make it available. We have sort of internally documented it,

417
00:29:50.540 --> 00:29:53.490 
but I think once we

418
00:29:53.900 --> 00:29:58.430 
finalize the python package then we can have a fuller

419
00:29:59.010 --> 00:30:02.730 
version of the documentation.

420
00:30:04.050 --> 00:30:08.910 
Yeah i would again ask into the round anyone else having a question you can

421
00:30:09.210 --> 00:30:10.490 
go ahead and unmute yourself

422
00:30:11.280 --> 00:30:12.000 
if you want to.

423
00:30:16.110 --> 00:30:17.660 
I see another question from the chat

424
00:30:18.350 --> 00:30:20.940 
would it make sense to include the emission related to the

425
00:30:20.940 --> 00:30:25.290 
hardware manufacturing? So I think you've only talked about the

426
00:30:25.430 --> 00:30:28.560 
usage part. So from the hardware for training

427
00:30:29.190 --> 00:30:33.670 
I think that's true because now at the moment we focused

428
00:30:33.840 --> 00:30:37.310 
mainly on the machine learning part, how much is emitted

429
00:30:37.320 --> 00:30:41.250 
with that, but I think that the next steps definitely as you also mentioned

430
00:30:41.530 --> 00:30:44.530 
related to cloud and other infrastructure would be

431
00:30:45.140 --> 00:30:48.090 
important to include to have a comprehensive

432
00:30:48.880 --> 00:30:54.120 
measurement. But it's not possible as of yet.

433
00:30:54.160 --> 00:30:56.630 


434
00:30:58.190 --> 00:31:01.730 
Ok any more questions from anyone?

435
00:31:03.000 --> 00:31:09.280 
Perfect, thank you, I think then we have

436
00:31:09.280 --> 00:31:12.740 
come to the end, a little shorter session today. Yeah because

437
00:31:12.740 --> 00:31:15.050 
I haven't prepared any questions myself and so I

438
00:31:15.980 --> 00:31:18.450 
think it was very very interesting to hear about the tool and

439
00:31:18.450 --> 00:31:20.720 
I'm looking forward to presenting it

440
00:31:21.320 --> 00:31:22.880 
sometime again if you have,

441
00:31:23.930 --> 00:31:27.440 
I'll be really happy, we'll be happy to do that yeah.

442
00:31:28.140 --> 00:31:32.290 
Yes so I think before we close the session, I'm going to

443
00:31:32.290 --> 00:31:34.590 
quickly restart the poll from the beginning

444
00:31:35.610 --> 00:31:37.680 
which I hope you can see now again.

445
00:31:39.040 --> 00:31:42.820 
Okay perfect, so while we are

446
00:31:43.530 --> 00:31:45.890 
there's one more question is the recording of this session

447
00:31:46.370 --> 00:31:49.720 
available as part of the cleanIT course,

448
00:31:49.720 --> 00:31:52.930 
we will upload the session again maybe by the end of the week

449
00:31:52.930 --> 00:31:57.440 
or in the next days sometime as always and

450
00:31:58.120 --> 00:32:02.320 
yeah that leads me to the end of the session. So thank you all

451
00:32:02.320 --> 00:32:05.890 
for joining us, thank you to be very much for your presentation and for

452
00:32:06.160 --> 00:32:07.650 
also answering the questions.

453
00:32:08.510 --> 00:32:13.570 
In the process as always I can announce the next session already

454
00:32:13.570 --> 00:32:15.970 
so in exactly four weeks again as always

455
00:32:16.520 --> 00:32:19.840 
we will have York Foreman here from the Just take AG

456
00:32:20.360 --> 00:32:23.810 
who will be talking about minimizing climate hazards of AI

457
00:32:23.930 --> 00:32:27.050 
and how to prevent rebound effects so this is kind of also

458
00:32:27.060 --> 00:32:30.710 
one very important topic, a rebound effect which people often

459
00:32:30.710 --> 00:32:34.630 
forget about and so we will be talking about that in around four weeks.

460
00:32:34.990 --> 00:32:39.310 
And yeah I see that a lot of people have answered the questions from the

461
00:32:39.440 --> 00:32:41.290 
poll, thanks a lot and

462
00:32:42.180 --> 00:32:46.280 
with that being said I think we can stop for today

463
00:32:47.040 --> 00:32:49.620 
and I hope we can see you again in four weeks. Thank you all

464
00:32:49.620 --> 00:32:54.210 
for coming by and have a good day.
