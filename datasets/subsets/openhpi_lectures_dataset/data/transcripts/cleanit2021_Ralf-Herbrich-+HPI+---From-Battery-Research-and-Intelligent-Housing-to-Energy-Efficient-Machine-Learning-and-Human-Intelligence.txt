WEBVTT

1
00:00:00.740 --> 00:00:04.309 
Welcome everyone.

2
00:00:04.320 --> 00:00:08.449 
Welcome back. Thank you for joining in again to the openXchange live talk.

3
00:00:08.939 --> 00:00:17.609 
This is our last live talk before the summer break again, so we will make one break and then start with a new schedule in

4
00:00:17.620 --> 00:00:26.089 
presumably August or September and yeah, I'm here as always, my name is Nils König from the clean-IT team. Today, I'm unfortunately

5
00:00:26.089 --> 00:00:35.799 
alone  usually Sophie would be by my side but instead we have a wonderful guest today which is Ralf Herbrich. Ralf Herbrich joined the HPI

6
00:00:35.799 --> 00:00:43.560 
also only very recently as he has been leading the group on artificial intelligence and sustainability since May 2022.

7
00:00:44.140 --> 00:00:48.850 
Previously, he served as a senior Vice President of artificial intelligence at Zalando.

8
00:00:49.340 --> 00:00:52.159 
and was the Director of machine learning at Amazon in Berlin.

9
00:00:52.640 --> 00:00:59.859 
Prior to these roles at Amazon, he led the Facebook's Unified Ranking and Allocation team and before that he served as

10
00:00:59.859 --> 00:01:07.109 
the director of Microsoft's Future Social Experiences Lab in the UK and also worked there for nine years at the Microsoft

11
00:01:07.109 --> 00:01:08.359 
Research Lab in Cambridge.

12
00:01:09.040 --> 00:01:13.359 
Ralph has published over 100 peer reviewed papers and holds over 50 patents.

13
00:01:14.040 --> 00:01:21.260 
He holds a PhD in statistics from the Technical University of Berlin and also obtained his diploma from the same institution.

14
00:01:21.840 --> 00:01:27.599 
His research interests include Bayesian inference and decision making, natural language processing, computer vision, learning

15
00:01:27.599 --> 00:01:35.140 
theory, robotics, distributed systems and programming languages, but he's also interested in computer games matchmaking

16
00:01:35.150 --> 00:01:41.849 
as he is one of the inventors of the Drivatars™ system at Forza Motorsport series as well as the TrueSkill ranking

17
00:01:41.849 --> 00:01:46.159 
and matchmaking system in Xbox live. In today's talk,

18
00:01:46.170 --> 00:01:52.409 
Ralph will give an overview of the problems that the newly founded group on artificial intelligence and sustainability will

19
00:01:52.409 --> 00:01:54.629 
be working on. For some of the problems,

20
00:01:54.629 --> 00:01:56.959 
he will even demonstrate some preliminary results.

21
00:01:57.640 --> 00:02:04.920 
He believes that an energy aware perspective is imperative for developing true artificial intelligence and that an AI first

22
00:02:04.920 --> 00:02:10.460 
approach is imperative for solving the challenge of transitioning to a sustainable future based on renewable energy.

23
00:02:11.240 --> 00:02:17.550 
Up until today, the primary focus of research on AI methods has been on predictive accuracy and its dependence on the amount

24
00:02:17.550 --> 00:02:21.650 
of training data rather than the amount of energy that is necessary for the training.

25
00:02:22.240 --> 00:02:29.069 
However, going forward, data is typically abundant for most tasks, but on the other hand, energy is becoming a limiting and

26
00:02:29.069 --> 00:02:29.810 
economical thing.

27
00:02:30.639 --> 00:02:35.860 
We are very happy to have you with us today and we're looking forward to your presentation and the discussion afterwards.

28
00:02:35.870 --> 00:02:36.669 
Welcome Ralf Herbrich.

29
00:02:38.340 --> 00:02:39.150 
Thank you.

30
00:02:39.159 --> 00:02:45.090 
Thanks Nils and thanks for the invitation and  broad introduction.

31
00:02:45.099 --> 00:02:54.300 
so as Nils was saying, this is mostly a talk about problems, not solutions, I will present some preliminary solutions in

32
00:02:54.300 --> 00:03:03.409 
one area, but I wanted to share a bit of light how someone with this background is ending up being focused on AI as an

33
00:03:03.409 --> 00:03:05.370 
area and sustainability as another.

34
00:03:05.379 --> 00:03:15.439 
So with that  let me get started, I basically have prepared about 15 to 20 minutes of material, so I really look forward

35
00:03:15.439 --> 00:03:17.069 
to some questions and discussion.

36
00:03:17.080 --> 00:03:24.629 
I'll start with a bit of background like - what is AI? Why energy? By the way, I've chosen the energy angle here

37
00:03:24.629 --> 00:03:28.150 
more as a very specific one, you'll see in a minute why.

38
00:03:28.539 --> 00:03:38.719 
and then we'll give after the full overview and then sort of a further deep dive into the energy for AI perspective, why

39
00:03:38.719 --> 00:03:47.330 
it matters and then the AI for energy perspective  and one problem that I have or this department will specifically work

40
00:03:47.330 --> 00:03:56.930 
on  and finally I want to make a call out to a new initiative that I'm very happy to be a sponsor for Nils',

41
00:03:56.939 --> 00:03:59.750 
Malta's and Sophie's Climate Club.

42
00:03:59.750 --> 00:04:06.159 
So I'll finish with a call for action and the background of what we mean here.

43
00:04:06.740 --> 00:04:16.550 
So on the background side, I myself have been doing or working in the area of AI since 1994-95.

44
00:04:16.939 --> 00:04:25.300 
First time I implemented checkers search engine that plays against, that can play reasonably strong against people.

45
00:04:25.310 --> 00:04:34.910 
But what is AI because when I started the field was called AI then when I wrote my PhD thesis  it started to become

46
00:04:34.920 --> 00:04:37.740 
a work "non grata" better not to use.

47
00:04:37.750 --> 00:04:44.480 
So machine learning was more a name for it and now the term AI aspect, what is AI and I think if I look back

48
00:04:44.480 --> 00:04:51.389 
at the nearly 30 years I've been looking at, I've been working in this field, I would say AI is the study of intelligent agents,

49
00:04:51.389 --> 00:05:00.069 
computational agents that basically are capable of doing three things in sequence and continuously. One is to perceive their

50
00:05:00.069 --> 00:05:00.769 
environment.

51
00:05:00.779 --> 00:05:05.449 
So an agent can't do this that sends us the environment through data.

52
00:05:05.839 --> 00:05:07.779 
Can't really exhibit some intelligence.

53
00:05:07.779 --> 00:05:09.689 
We naturally do this with our senses.

54
00:05:09.699 --> 00:05:15.689 
But for an AI system to do this is, the ability to perceive the environment to compute predictions.

55
00:05:15.689 --> 00:05:22.850 
So from the momentary perception of the scene and this could be a virtual scene like a purchase situation online or it could

56
00:05:22.860 --> 00:05:31.759 
be a robotic situation sensing with lighter sensors or motion sensors. Compute what is likely going to happen to the environment

57
00:05:31.759 --> 00:05:32.550 
in particular,

58
00:05:32.939 --> 00:05:35.439 
as the agent might take actions themselves.

59
00:05:35.449 --> 00:05:43.189 
So that's typically the area that we call, machine learning, the ability to make, you know, predictions within the second,

60
00:05:43.199 --> 00:05:47.410 
half second up to a year long future horizon range.

61
00:05:47.420 --> 00:05:54.839 
And then lastly to use those predictions to automatically decide computation and automatically decide to take actions in

62
00:05:54.839 --> 00:05:57.129 
this environment to achieve these goals.

63
00:05:57.139 --> 00:06:04.689 
So when its web search, it's about what the results to show and if it's e-commerce, it's about which products to show which

64
00:06:04.689 --> 00:06:13.519 
products to recommend actively when it's in the name, in the form of gaming, it's literally what control actions should the

65
00:06:13.519 --> 00:06:19.089 
car take in order to stay competitive to the computer gamer when its ranking

66
00:06:19.100 --> 00:06:27.300 
it's what two people that are currently seeking to play against each other or against other players should be matched

67
00:06:27.300 --> 00:06:27.629 
together.

68
00:06:27.629 --> 00:06:29.209 
That's the action of the system should take.

69
00:06:29.220 --> 00:06:32.259 
So actions come in various shapes, they are not just physical actions.

70
00:06:33.240 --> 00:06:40.439 
Now, a lot of algorithms have been, I would say nearly in the order of thousands in the machine learning space, decision

71
00:06:40.439 --> 00:06:42.060 
making has been predominantly the domain.

72
00:06:42.060 --> 00:06:47.350 
That's been researched in the field of probabilistic or econometric reasoning.

73
00:06:47.350 --> 00:06:53.550 
So in the statistics field, data sensing is much more an IoT or hardware domain.

74
00:06:54.449 --> 00:07:02.000 
If I look at the field of AI one of the things that's pretty apparent is it's a constantly growing field still now.

75
00:07:02.009 --> 00:07:05.269 
So what you see here is the number is from an HR article.

76
00:07:05.269 --> 00:07:07.660 
So the links are in the top right to all the sources.

77
00:07:08.139 --> 00:07:14.889 
It's a number of AI articles are published each year, peer reviewed from a nature article.

78
00:07:14.889 --> 00:07:18.029 
And you can see to go back to the last 20 years.

79
00:07:18.040 --> 00:07:20.720 
So the study goes to 2017.

80
00:07:20.730 --> 00:07:24.269 
The total number, which is the sum of the four graphs.

81
00:07:24.279 --> 00:07:32.959 
You know, it's now trending in the region of 50 to 75,000 publications per year.

82
00:07:33.339 --> 00:07:38.089 
And that's a pretty large number if you just imagine you wanna ever read that.

83
00:07:38.100 --> 00:07:40.660 
So given a year has 360 days.

84
00:07:41.040 --> 00:07:47.550 
So you have to reach in the order of 20 papers each day, people just wanted to keep up what's published.

85
00:07:47.550 --> 00:07:55.959 
So it's a pretty big one and what's remarking about the field,  as I was able to witness it, it's rough in this

86
00:07:55.959 --> 00:07:59.310 
period is that there was a race to accuracy.

87
00:07:59.319 --> 00:08:07.500 
So everyone that worked in this field was focused on the predictive accuracy of these methods when they acted in the environment

88
00:08:07.500 --> 00:08:08.850 
or when it predicted the future.

89
00:08:09.240 --> 00:08:13.829 
And what that led to is some remarkable achievements in the last 10 years.

90
00:08:13.829 --> 00:08:16.129 
So one of them is AlphaGo (2016).

91
00:08:16.139 --> 00:08:23.620 
So the ability to play a game whose search space you cannot explore exhaustively, it's just too big.

92
00:08:23.629 --> 00:08:25.860 
There's not enough atoms in the known universe

93
00:08:26.240 --> 00:08:30.199 
that could capture or represent each possible goal positions.

94
00:08:30.209 --> 00:08:37.559 
Yet with learning from past games and by self play, the field was able to demonstrate that it can play this game which was

95
00:08:37.570 --> 00:08:45.450 
meant to be an unbeatable to human intelligence strength by 2016 against the strongest human player or with the ImageNet

96
00:08:45.450 --> 00:08:46.370 
content,

97
00:08:46.379 --> 00:08:49.159 
around 2015,

98
00:08:49.169 --> 00:08:54.889 
the algorithms were for the first time able to predict with a higher accuracy than any individual human could predict the

99
00:08:54.889 --> 00:08:57.200 
object classes on these images.

100
00:08:57.210 --> 00:08:58.980 
So, these are huge successes.

101
00:08:58.990 --> 00:09:01.110 
Now, what's wrong with that?

102
00:09:01.120 --> 00:09:03.129 
Actually nothing wrong in terms of accuracy.

103
00:09:03.129 --> 00:09:07.470 
But when concerned, I see now and we see it environmentally now.

104
00:09:07.470 --> 00:09:13.240 
But even five years ago in industrial application, which I had the luxury to be involved in for many years.

105
00:09:13.250 --> 00:09:14.820 
It's the cost of that prediction.

106
00:09:14.830 --> 00:09:23.799 
The cost in terms of energy or initially in terms of money, if you look at the just the doubling rate of the amount

107
00:09:23.799 --> 00:09:31.299 
of compute necessary to perform a certain operation in ML it doubled nearly every 3.5 months.

108
00:09:31.299 --> 00:09:39.330 
So since 2012, the same methods are nearly a million times more expensive to perform, of course, on bigger data, but that's

109
00:09:39.330 --> 00:09:40.470 
an enormous factor.

110
00:09:40.470 --> 00:09:41.649 
That's of enormous magnitude.

111
00:09:42.139 --> 00:09:47.649 
And just as an example, OpenAI a few years ago I had a demonstration of the grasping task.

112
00:09:47.659 --> 00:09:51.480 
So this is a from task for a gripper to grasp an object.

113
00:09:51.480 --> 00:10:01.679 
Reliably that training itself from self play or simulated experiences consume two and more than 2.5 bigger

114
00:10:01.679 --> 00:10:04.639 
Watt hours of training alone.

115
00:10:04.639 --> 00:10:11.850 
There's other studies that show, you know, to train an NLP model on modern dataset sizes takes the equivalent of the energy

116
00:10:11.850 --> 00:10:15.500 
to fly a four passenger plane from New York to San Francisco.

117
00:10:15.509 --> 00:10:23.620 
So, the energy that these feats take that is raised to accuracy, is growing out of bound and that's problematic,

118
00:10:23.629 --> 00:10:30.820 
I mean, the field itself has obviously many ideas and many applications, there is hardly any experience today yet, the energy

119
00:10:30.820 --> 00:10:38.120 
is considerably too large and I'm saying too large that when you compare what the human brain takes, that's about 20

120
00:10:38.120 --> 00:10:40.649 
to 25 watts constantly.

121
00:10:40.940 --> 00:10:47.440 
You know, this is several orders of magnitude bigger than what we are able to exhibit intelligence with.

122
00:10:48.440 --> 00:10:49.730 
I looked on the other side.

123
00:10:49.769 --> 00:10:53.659 
Energy, how, how much of this resources available.

124
00:10:53.769 --> 00:11:02.399 
The good news is there's still two orders of magnitude more energy that arise from the sun and every second on planet earth

125
00:11:02.409 --> 00:11:06.590 
than the human mankind would possibly to exist and to function.

126
00:11:06.600 --> 00:11:15.860 
However, what ends up happening is that the way in which we can make use of that energy today is rather limited.

127
00:11:15.870 --> 00:11:25.629 
So when you see here is the last 40 years of, this is taken from the statistical vault energy review that comes out

128
00:11:25.629 --> 00:11:26.559 
every year.

129
00:11:26.570 --> 00:11:28.460 
So the next one comes actually out tomorrow.

130
00:11:28.940 --> 00:11:37.330 
So this is obviously from from 1965 to 2020, what you see here is a decomposition of the worldwide energy consumption across

131
00:11:37.330 --> 00:11:40.659 
all states in terms of its sources.

132
00:11:40.669 --> 00:11:50.730 
So the only sources that are remotely renewable are renewable obviously and maybe hydroelectric, which are dams and

133
00:11:50.730 --> 00:11:58.120 
store energy or gain it from the potential energy difference in heights of water flowing.

134
00:11:58.129 --> 00:12:01.230 
So that's not available to every part of the world.

135
00:12:01.240 --> 00:12:04.389 
Nevertheless, what you see here is that it's an enormous difference.

136
00:12:04.389 --> 00:12:07.190 
The vast majority comes from coal, gas or oil.

137
00:12:07.240 --> 00:12:08.830 
And that's still true today.

138
00:12:08.919 --> 00:12:15.509 
And if you were to not look only on energy but on electricity because computers work with electricity and a lot of supply

139
00:12:15.519 --> 00:12:17.049 
appliances work with electricity.

140
00:12:17.340 --> 00:12:26.419 
The picture looks a little better but only a little because there's 11.9% of today of all the electricity that we use comes

141
00:12:26.419 --> 00:12:27.360 
from renewable energy.

142
00:12:27.940 --> 00:12:31.000 
Still the vast majority comes from coal and gas.

143
00:12:31.009 --> 00:12:33.629 
Now I wanted to show comparison.

144
00:12:33.629 --> 00:12:34.399 
This is worldwide.

145
00:12:34.399 --> 00:12:36.740 
Something over all states of this world.

146
00:12:36.750 --> 00:12:39.370 
If you look at Germany picture looks a bit different.

147
00:12:39.379 --> 00:12:42.720 
Obviously the population hasn't grown as much over the last 40 years.

148
00:12:42.720 --> 00:12:44.519 
So the curve is a little flatter.

149
00:12:44.519 --> 00:12:47.779 
In fact the curve is declining and the amount of green

150
00:12:47.789 --> 00:12:53.519 
so this is the amount of renewable energy or renewable electricity is significantly larger.

151
00:12:53.679 --> 00:13:02.409 
And maybe a little known fact, there's two countries in the world that have more than 40% of electricity from

152
00:13:02.419 --> 00:13:05.379 
renewable energy and this is the UK

153
00:13:05.379 --> 00:13:06.049 
and Germany.

154
00:13:07.039 --> 00:13:10.039 
Now why am I showing you these figures?

155
00:13:10.039 --> 00:13:14.379 
Because there is a consequence of this growing amount of energy consumption.

156
00:13:14.389 --> 00:13:18.519 
The way we currently arrive at it because it isn't renewable is the

157
00:13:18.519 --> 00:13:22.090 
CO2 emissions which have disastrous consequences on the climate.

158
00:13:22.100 --> 00:13:23.659 
So look at the worldwide CO2.

159
00:13:23.659 --> 00:13:30.779 
emissions, they keep climbing almost at exactly the rate than the energy consumption, which is explainable by the composition

160
00:13:30.779 --> 00:13:31.200 
of it.

161
00:13:31.259 --> 00:13:33.549 
The composition is mostly in terms of fossil fuel.

162
00:13:34.039 --> 00:13:37.409 
If you look at the one in Germany it declines and it seems to decline at a faster rate.

163
00:13:37.409 --> 00:13:39.210 
In fact if you divide the two.

164
00:13:39.220 --> 00:13:46.529 
So this is literally just a division of the emissions graph measured in mega tons on the Y-axis.

165
00:13:46.529 --> 00:13:54.450 
By the consumption graph which is measured in exa, this is 10 raised to the power of 18, exa joules.

166
00:13:54.940 --> 00:13:58.120 
You arrived at the unit of grams of CO2

167
00:13:58.120 --> 00:14:01.870 
emissions in terms of mega joules of energy consumed.

168
00:14:01.879 --> 00:14:09.799 
You can see that why initially the larger coal and oil sources Germany made it above the average of the world.

169
00:14:09.809 --> 00:14:18.440 
It's now in terms of the amount of emissions per mega joule of energy produced, you know, ahead.

170
00:14:18.440 --> 00:14:25.700 
And that speaks a lot more thinking about how can we accelerate that transition to renewable because overall it will lead

171
00:14:25.700 --> 00:14:33.909 
to a much cleaner way of the society moving and it will actually lead to more efficient business models because if

172
00:14:33.909 --> 00:14:38.350 
we compute with AI then that's that needs electricity.

173
00:14:38.840 --> 00:14:42.070 
And so the five focus areas where I see AI

174
00:14:42.070 --> 00:14:49.850 
and energy helping each other is when I look at it as from a marketplace perspective, there's a substantial amount of energy

175
00:14:49.850 --> 00:14:50.899 
that's supplied.

176
00:14:50.909 --> 00:15:00.049 
and the the renewable one comes in the form of solar power and wind when being a consequence of the heating of the atmosphere

177
00:15:00.539 --> 00:15:07.860 
And then there's a certain amount of demand and what you see on the demand side is a recent statistics for worldwide.

178
00:15:07.870 --> 00:15:09.259 
Sorry, this is USA.

179
00:15:09.269 --> 00:15:16.730 
So you see if we take all the energy that's consumed in a given year and be labelled by the type of usage, not by

180
00:15:16.730 --> 00:15:17.850 
the source of it.

181
00:15:18.139 --> 00:15:23.840 
You can see that 20% of all US energy is for residential use.

182
00:15:23.840 --> 00:15:27.350 
So that's your houses and half of this, 10% is residential space heating.

183
00:15:28.139 --> 00:15:30.330 
You can see that 36%,

184
00:15:30.330 --> 00:15:32.360 
the majority is in transportation.

185
00:15:32.360 --> 00:15:34.759 
Cars make a vast amount.

186
00:15:35.139 --> 00:15:42.429 
That's why I moved towards limiting  the the usage of non renewable and cars will be a big believer.

187
00:15:42.440 --> 00:15:44.809 
But you can also see other industries.

188
00:15:44.809 --> 00:15:53.059 
This is an agriculture, mining  and services together taking about 20% the same as manufacturing.

189
00:15:53.539 --> 00:16:02.090 
And I'm showing you this because if one, you know sort of two levers on which we can get better  in this marketplace the

190
00:16:02.100 --> 00:16:03.620 
supply has to meet demand.

191
00:16:03.629 --> 00:16:11.029 
So either we can lower demand and some of the work that this group will be focused on is in making a big lever is

192
00:16:11.029 --> 00:16:12.320 
in the residential space heating.

193
00:16:12.330 --> 00:16:19.409 
So the amount of energy you can save by heating houses really only when inhabitants needed at a certain temperature because

194
00:16:19.409 --> 00:16:20.740 
all of this is manual today.

195
00:16:20.750 --> 00:16:30.889 
So this is predictive systems in the household, smart homes. Data centres themselves make about  4% of all energy

196
00:16:30.889 --> 00:16:31.399 
consumption.

197
00:16:31.399 --> 00:16:37.980 
This is absolutely in the services sector or algorithms which appear in more and more of the appliances in manufacturing

198
00:16:37.980 --> 00:16:46.779 
more markets, automated transportation in the services industry, even residential housing. On the supply side, in order

199
00:16:46.779 --> 00:16:50.929 
to really use renewable as well as a constant and plentiful source,

200
00:16:50.940 --> 00:16:55.830 
it's kind of important to know where is how much wind and sun available when and that

201
00:16:55.830 --> 00:17:02.070 
these are predictive tasks for planning and why we talk about planning because this marketplace isn't instantaneous.

202
00:17:02.639 --> 00:17:07.589 
The problem why we can't use all the solar energy is that it doesn't arrive uniformly on the planet.

203
00:17:07.599 --> 00:17:14.180 
So the way that if you wanted to use this marketplace to exchange supply somewhere else, let's say in the desert, where there is

204
00:17:14.180 --> 00:17:22.859 
a lot of sun with demand that somewhere else, maybe the household up in Oslo or in Norway, you need ways to store energy.

205
00:17:22.869 --> 00:17:28.349 
Now we do know one source of storage energy that's oil or gas that has a high energy density.

206
00:17:28.349 --> 00:17:29.269 
We'll talk about in a minute.

207
00:17:29.640 --> 00:17:36.640 
But if you really wanted to make this marketplace work, the storage is an important area too.

208
00:17:36.650 --> 00:17:42.630 
And so those six areas, the areas that the group will be focused on, the two, I will dive on a little deeper.

209
00:17:42.640 --> 00:17:49.259 
I'll start with the algorithms, how do you make, you know what, what kind of work needed to make algorithms more energy aware.

210
00:17:49.339 --> 00:17:57.349 
There's one aspect that I spoke about in detail and then how do you improve the energy storage systems such as battery

211
00:17:57.740 --> 00:18:02.799 
both in terms of managing their lifetime as well as the material science needed.

212
00:18:02.809 --> 00:18:05.059 
I'll touch upon those in the second half.

213
00:18:06.039 --> 00:18:10.019 
So let's start with the energy for AI itself.

214
00:18:10.029 --> 00:18:12.460 
So that was the last bullet point on the slide previously.

215
00:18:13.240 --> 00:18:16.059 
So there's sort of three areas I want to highlight.

216
00:18:16.440 --> 00:18:18.289 
The field is huge.

217
00:18:18.299 --> 00:18:22.980 
We just saw that about 60,000 to 70,000, papers that are published each

218
00:18:22.980 --> 00:18:24.740 
year by this field.

219
00:18:24.750 --> 00:18:28.150 
So how do you see your field that has tens of thousands of researches

220
00:18:28.160 --> 00:18:32.670 
and that output a lot of there's obviously a lot of activity taking on.

221
00:18:33.039 --> 00:18:42.299 
And the interesting thing is that when you look at the last 20-30 years, the way that the field itself took a turn by many

222
00:18:42.299 --> 00:18:44.410 
researchers working on relevant problems.

223
00:18:44.410 --> 00:18:50.170 
Initially the accuracy problems in the feasibility problems of intelligence is through benchmarks.

224
00:18:50.640 --> 00:18:58.019 
So one of the first times this happened is in 1990 to 1995 in the StatLog project.

225
00:18:58.029 --> 00:19:08.150 
So this was when the statistics field couldn't compare very well with the ML field, and D. Michie and C.C. Taylor provided

226
00:19:08.150 --> 00:19:09.890 
a bunch of data sets.

227
00:19:09.890 --> 00:19:18.029 
And what they did really is make it easy and comparable for classical statistical methods like regression or decision

228
00:19:18.029 --> 00:19:26.829 
tree and boosting, to  bootstrapping to be compared to more modern methods at the time

229
00:19:26.839 --> 00:19:33.769 
which were like the decision tree algorithms like C4.5 for the early neural network models and the outcome really was that

230
00:19:33.769 --> 00:19:39.660 
this time your networks were pretty accurate and it was also easier to see on what type of tasks.

231
00:19:40.240 --> 00:19:46.559 
And later on following this came the ability basically at the UCI Davies,

232
00:19:46.940 --> 00:19:51.359 
University of California, Irvine hosted a benchmark dataset

233
00:19:51.359 --> 00:19:58.789 
that must have been used in tens of thousands of master and PhD thesis since because it became the de facto standard

234
00:19:58.799 --> 00:20:09.259 
to compare algorithms at every level of the academic education, one on digits MNIST and it was probably the most used

235
00:20:09.259 --> 00:20:11.920 
data sets before ImageNet had arrived.

236
00:20:11.930 --> 00:20:20.500 
And what it allows, what the focus was is to make machine learning which has its established as a field make that one comparable

237
00:20:20.509 --> 00:20:23.170 
against each other in terms of the accuracy alone.

238
00:20:23.940 --> 00:20:32.190 
And so what happened is that kernel methods so a way of linear methods by making them non linear without the complexity of

239
00:20:32.190 --> 00:20:33.730 
the optimization increasing.

240
00:20:33.740 --> 00:20:41.279 
But those became dominant because on the use of the benchmark datasets they tend to be highly accurate compared to the

241
00:20:41.279 --> 00:20:50.240 
computational complexity and the algorithmic complexity. And around 2010 that a couple of researchers

242
00:20:50.240 --> 00:20:59.799 
or a group of researchers at Stanford had collected enough data to really study how much more accuracy up to human level

243
00:20:59.809 --> 00:21:10.089 
are we able, as the field is able to generate if we have you know hundreds of millions to even billions of examples of sentence

244
00:21:10.089 --> 00:21:17.630 
information, images in this case later on a bunch of other data sets from other sentence resources were added and I would

245
00:21:17.640 --> 00:21:24.549 
postulate that without those benchmarks, the deep learning field wouldn't have seen the advent so much and wouldn't have seen

246
00:21:24.549 --> 00:21:27.079 
the superiority that they have when you learned from lots of data.

247
00:21:27.089 --> 00:21:28.900 
So that benchmark was a key.

248
00:21:28.910 --> 00:21:37.039 
Making the benchmark was a key asset to really highlight where and how much deep learning as a methodology and deep learning

249
00:21:37.039 --> 00:21:42.630 
systems as a setup are able to advance in this race of accuracy.

250
00:21:42.640 --> 00:21:48.589 
And I would now say that one of the areas that we don't have is there's no benchmark to compare algorithms not with respect

251
00:21:48.589 --> 00:21:52.140 
to the accuracy or about with respect to the systems

252
00:21:52.140 --> 00:21:59.720 
question of can it handle streams of training data but can it achieve accuracy at a minimum amount of energy footprint.

253
00:21:59.730 --> 00:22:07.269 
So that's one area where I see a big lever for steering the community. Now, how would that happen?

254
00:22:07.640 --> 00:22:13.859 
So I kind of foresee three areas where three algorithmic approaches to do that.

255
00:22:13.859 --> 00:22:22.529 
So the first one is to simply reduce computations and to give you an example on existing on most existing processing architectures,

256
00:22:22.529 --> 00:22:25.000 
multiplication is more expensive than addition.

257
00:22:25.009 --> 00:22:32.960 
So if in an algorithm implementation inequality of the symbolic nature of A times B or at least the numbers plus A

258
00:22:32.960 --> 00:22:34.670 
times C is carried out.

259
00:22:34.680 --> 00:22:36.250 
That's literally implemented that way.

260
00:22:36.259 --> 00:22:42.730 
If you know, this requires at least one addition and two multiplication and the same exact result

261
00:22:42.730 --> 00:22:46.450 
what we've got to use an inequality like the distributed law.

262
00:22:47.039 --> 00:22:55.549 
And you may think this is very simple but it underlines a vast number of computational efficient procedures that are in existence

263
00:22:55.549 --> 00:22:56.329 
today.

264
00:22:56.339 --> 00:23:01.009 
You know, and I think I believe there's more projections of a similar example if you use.

265
00:23:01.019 --> 00:23:06.259 
But how to mention that it's effectively actually not carry around the additional dimensions.

266
00:23:07.140 --> 00:23:15.920 
The second kind of methodological approach is in not doing exact computations, which the first one doesn't change the outcome.

267
00:23:15.920 --> 00:23:20.420 
It's not that A times B plus A times C gives any other number than A times B plus C.

268
00:23:20.420 --> 00:23:26.960 
Computationally even with numerical inaccuracy taken into account the result is the same.

269
00:23:27.440 --> 00:23:36.009 
But what I'm talking about in the second is to look into algorithms that work on inexact with inexact computation

270
00:23:36.009 --> 00:23:39.910 
So one of them is if you think of low precision arithmetic.

271
00:23:39.920 --> 00:23:43.769 
So 4.4 bit arithmetic or even 1 bit arithmetic.

272
00:23:44.140 --> 00:23:52.059 
One way to think of this is it's arithmetic where the true number lies in an integral between 4 bit case 2 to the power

273
00:23:52.059 --> 00:23:57.740 
-4, (+/-) 2 to the power -4 or with 1 bit arithmetic, you know, plus minus a half.

274
00:23:58.640 --> 00:24:01.240 
These are approximate computations of your hardware.

275
00:24:01.240 --> 00:24:08.190 
If you basically reduce your hardware to really only carry out operations at this accuracy the same as saying I can only

276
00:24:08.190 --> 00:24:10.630 
compute results approximately. Yet,

277
00:24:10.640 --> 00:24:15.450 
it turns out for most of the optimizations and the inference procedures.

278
00:24:15.839 --> 00:24:23.299 
But our study today and that's developed procedure, another way that can be achieved is to actually lower voltage and frequency

279
00:24:23.299 --> 00:24:25.970 
of the processor to the point where inaccuracy,

280
00:24:25.970 --> 00:24:32.759 
so the error correction of the bit are no longer applying and sort of some label noise in the computation itself.

281
00:24:33.339 --> 00:24:38.579 
These kind of procedures are also core to some of the low energy process of technology today.

282
00:24:38.589 --> 00:24:46.930 
Except we're not tolerating inaccurate computations in today's applications because in most applications, particularly accounting

283
00:24:46.940 --> 00:24:48.690 
you do not want to tolerate an inaccurate bit.

284
00:24:49.240 --> 00:24:52.019 
That's a bit different when you, when you do inference algorithms.

285
00:24:52.029 --> 00:24:58.190 
And lastly, a third area of approximation is to even consider alternative hardware that works very differently.

286
00:24:58.190 --> 00:25:02.980 
And right now our hardware is based on the assumption that there's many users at the same time.

287
00:25:02.980 --> 00:25:06.779 
So it's oversubscribed, there's too little supply of computation, too much demand.

288
00:25:06.789 --> 00:25:08.130 
Therefore it's constantly running.

289
00:25:08.130 --> 00:25:13.859 
There's a clock rate by which the information and memory or the CPU processing happens.

290
00:25:14.339 --> 00:25:19.680 
But when you compare that to the way that the human brain operates, it really is more event based.

291
00:25:19.690 --> 00:25:29.190 
So whenever a signal arrives at the retina, this is when there's only energy spent in the processing of information, there's

292
00:25:29.190 --> 00:25:30.089 
a bunch of projects.

293
00:25:30.089 --> 00:25:38.349 
So for example, one in Dresden is an example where they're looking into new network implementations on hardware that's

294
00:25:38.349 --> 00:25:46.000 
event based, an alternative is if you use the effect that any form of computation on a circuit,  it's actually happening

295
00:25:46.000 --> 00:25:49.099 
on the device that's performing a differential equation.

296
00:25:49.109 --> 00:25:52.519 
Why not take this as the primitive rather than discretizing it?

297
00:25:52.529 --> 00:25:55.769 
And then simulating it through computation.

298
00:25:56.940 --> 00:26:03.950 
And lastly in the theory part, we also have no real theory today  that tries to explain why machine learning works with

299
00:26:03.950 --> 00:26:07.099 
respect to energy.

300
00:26:07.109 --> 00:26:15.269 
What we have seen is that each of the theories were sometimes leading often shortly lagging behind in the explanation why

301
00:26:15.740 --> 00:26:17.490 
an algorithm by a machine,

302
00:26:17.500 --> 00:26:23.789 
first an algorithm and later a machine is able to learn from little data and make accurate predictions about the

303
00:26:23.789 --> 00:26:24.319 
future.

304
00:26:24.329 --> 00:26:36.190 
So the first such theory was established in the 70s by these two Russian fellows Vapnik and Chervonenkis, and there are many others after. Their

305
00:26:36.190 --> 00:26:43.690 
main focus was on studying how much accuracy can you statistically get when you take the complexity of the function class

306
00:26:43.700 --> 00:26:47.529 
that's used for the approximation into account.

307
00:26:47.539 --> 00:26:51.470 
This is where the famous Vapnik and Chervonenkis dimension came from.

308
00:26:51.470 --> 00:26:56.220 
Its the complexity measure of a set of functions of their linear of the decision trees.

309
00:26:56.230 --> 00:27:02.400 
There's a whole developed theory now. But the key question that was studied is not how much accuracy you get in

310
00:27:02.400 --> 00:27:04.759 
terms of the amount of training data necessarily.

311
00:27:04.759 --> 00:27:12.119 
But the key question is unknown to the complexity of the function class, irrespective of the actual algorithm you chose,

312
00:27:12.130 --> 00:27:19.950 
but later, about 10 years later,  and computers were actually carrying out these computations, Valiant produces

313
00:27:20.240 --> 00:27:26.819 
notion or steered the field by this theoretical work on how much accuracy you get relative to the computational complexity

314
00:27:26.819 --> 00:27:31.789 
class that it would take to compute that and lots of other work happened.

315
00:27:31.799 --> 00:27:40.089 
One other  sort of piece of work, there were some build on, I want to point out is when you actually take the optimization

316
00:27:40.089 --> 00:27:45.210 
procedure, the recipe of computation into account the steps that the algorithm take.

317
00:27:45.220 --> 00:27:53.670 
So how much accuracy can you expect when the algorithm is iterative for the compression scheme or is a scheme where little

318
00:27:53.670 --> 00:28:01.740 
data suffices, subset of the training data suffices because not many functions are effectively revisited and tested on the

319
00:28:01.740 --> 00:28:02.789 
training data.

320
00:28:02.799 --> 00:28:11.640 
The area that I think I'd like this group to focus on is and also now to not only take into account the accuracy respect

321
00:28:11.640 --> 00:28:19.799 
to the complexity function class or the complexity of the computation or the specific steps taken but the amount of

322
00:28:19.809 --> 00:28:21.009 
energy that gets consumed.

323
00:28:21.009 --> 00:28:26.730 
So how much  generalization error or how much prediction accuracy can you gain?

324
00:28:26.740 --> 00:28:32.670 
You're willing to invest a certain amount of fuel and energy for a computation necessary to achieve this.

325
00:28:33.940 --> 00:28:35.829 
So that was a bit of an outlook.

326
00:28:35.829 --> 00:28:43.519 
As I said, this is more forward looking, a huge bunch of problems and focus areas to focus on. Now in the AI

327
00:28:43.670 --> 00:28:45.890 
for energy specification,

328
00:28:45.900 --> 00:28:49.049 
I have picked up one area which is batteries.

329
00:28:49.049 --> 00:28:50.460 
So how does the battery work?

330
00:28:50.839 --> 00:28:54.519 
If you look at the battery, this is the schematic picture of the battery and pretty much every battery,

331
00:28:54.519 --> 00:29:02.220 
your car battery that drives basically just your ignition, but also the car battery or your battery that runs

332
00:29:02.220 --> 00:29:04.789 
your computer or your battery that runs your torch.

333
00:29:04.799 --> 00:29:07.549 
They all work the same way, the galvanic element.

334
00:29:07.549 --> 00:29:15.849 
And what that means is you have a chemical reaction where in one compartment you have a negative current collector, on the

335
00:29:15.849 --> 00:29:16.579 
one side.

336
00:29:16.589 --> 00:29:23.049 
So either cylindrical or it could be like a rectangle.

337
00:29:23.440 --> 00:29:33.180 
You have a positive current collection on the other certain material and attached to this material is a contact called

338
00:29:33.180 --> 00:29:35.369 
the anode and contact called the cathode.

339
00:29:35.380 --> 00:29:37.450 
And the most important thing is that both are separated.

340
00:29:38.140 --> 00:29:45.289 
So there's a separation and there is an over representation of a chemical, of a set of ions.

341
00:29:45.299 --> 00:29:50.769 
So there's more electrons and electron difference on the catholic side with respect to the anode side.

342
00:29:51.339 --> 00:30:00.829 
So if you charge, it means that you inject ions, electrons on the anode side.

343
00:30:00.839 --> 00:30:07.579 
And that happens when you put energy into this circuit because the top part of the wire is when the appliance gets applied

344
00:30:07.579 --> 00:30:12.359 
if you discharge it means that you use these electrons now flow from the anode to the cathode.

345
00:30:12.549 --> 00:30:15.779 
And that produces energy such as light.

346
00:30:15.789 --> 00:30:19.240 
If you want to see a light bulb or drive an engine drive a motor.

347
00:30:19.240 --> 00:30:23.259 
If it's about moving a physical object forward.

348
00:30:23.269 --> 00:30:25.930 
So that's how roughly battery works.

349
00:30:25.930 --> 00:30:33.430 
It's two elements called anode and a catholic, made of the same element because it's the same ions that get produced.

350
00:30:33.440 --> 00:30:42.569 
And  what you see here is the material properties of the anode and cathode, and of the separator matter a great deal.

351
00:30:42.579 --> 00:30:51.319 
In fact, I forgot to say one thing that the anode and cathode in an electrolyte, that's the solvent over which this goes. Now if you

352
00:30:51.329 --> 00:30:52.460 
consider your triple A (AAA)

353
00:30:52.460 --> 00:31:00.000 
battery or your double A (AA) battery that's typically made of nickel cadmium and the two important properties for battery

354
00:31:00.009 --> 00:31:07.259 
if you think of it as a storage element for energy is how much energy do I get out of respect to the volume?

355
00:31:07.640 --> 00:31:08.700 
So how big it is?

356
00:31:08.710 --> 00:31:11.170 
The size and with respect to the weight.

357
00:31:11.180 --> 00:31:15.529 
So the energy is measured in the amount of power per time.

358
00:31:15.529 --> 00:31:19.500 
So watt hours and how many watt hours do I get out of a battery?

359
00:31:19.509 --> 00:31:23.259 
In terms of the litres of liquid it needs.

360
00:31:23.269 --> 00:31:24.460 
That's the X axis.

361
00:31:24.539 --> 00:31:27.859 
And how much power do I get out over full charge?

362
00:31:28.039 --> 00:31:30.259 
In terms of the weight that the battery has.

363
00:31:30.640 --> 00:31:35.279 
So these two are called specific energy densities.

364
00:31:35.289 --> 00:31:40.269 
So something with the low energy density is further to the origin.

365
00:31:41.240 --> 00:31:54.420 
So the closer something is to the origin here as a material, the bigger or smaller, the heavier the object is when

366
00:31:54.420 --> 00:31:59.549 
the battery object itself is when you use it as a storage medium.

367
00:31:59.940 --> 00:32:08.710 
And of course if the weight or the volume of a battery is too small and then it's not worth transporting it because if you

368
00:32:08.940 --> 00:32:17.190 
want to transport it so you can move energy from the place it's produced such as a sunny place, a very windy place, you need

369
00:32:17.190 --> 00:32:26.519 
a high energy density and for it to be economical to harvest, so to speak, at the place of lots of wind or sun and consume

370
00:32:26.519 --> 00:32:27.960 
it at a place where that's not present.

371
00:32:29.039 --> 00:32:30.190 
That's what a battery is for.

372
00:32:30.200 --> 00:32:35.960 
So your nickel cadmium has unfortunately does not have such a high density.

373
00:32:36.440 --> 00:32:43.319 
When you compare it to your lithium ion, which is typically what's in your laptop and the modern batteries like lithium oxygen,

374
00:32:43.329 --> 00:32:48.089 
they're almost twice the density on both dimensions.

375
00:32:48.099 --> 00:32:55.859 
And if you want to put this in perspective, what is the densest material for energy?

376
00:32:56.440 --> 00:33:02.259 
I want to show you the volumetric energy density for coal, oil and gas.

377
00:33:02.269 --> 00:33:08.759 
And so I couldn't plot this on this graph because there'd be 6500 on the y axis, going over 12,000 or 15,000.

378
00:33:08.759 --> 00:33:11.990 
So it's almost a factor of 50 larger.

379
00:33:12.000 --> 00:33:19.730 
20 to 50 depending on the material than the current existing battery material, which is why it's still sort of one of the

380
00:33:19.730 --> 00:33:22.529 
most dense parts of energy.

381
00:33:22.529 --> 00:33:24.980 
But of course it's also the least renewable.

382
00:33:24.990 --> 00:33:28.279 
It takes tens of thousands of years to produce.

383
00:33:28.289 --> 00:33:35.450 
And when you burn it to get the electricity back produces these emissions that hurt our climate and hurt our planet ultimately.

384
00:33:35.940 --> 00:33:41.579 
But our goal in particular the material science research, because you can see the difference is not that the batteries built

385
00:33:41.579 --> 00:33:42.170 
any different.

386
00:33:42.170 --> 00:33:48.980 
It's more the material properties used in the anode and the cathode that make the density or can increase the density of energy.

387
00:33:48.980 --> 00:33:51.259 
And that denser energy is the denser batteries.

388
00:33:51.740 --> 00:33:57.259 
The more worthwhile it is to actually use it as a mobile medium for energy itself.

389
00:33:58.240 --> 00:34:07.160 
Now, one of the key problems that a battery has is that process I just described to you charging and discharging is destructive.

390
00:34:07.640 --> 00:34:11.329 
So in your nickel cadmium, it's not designed to ever be reversed.

391
00:34:11.340 --> 00:34:18.559 
But in your typical laptop battery, so lithium ion battery, you can charge it around 3000 times.

392
00:34:18.940 --> 00:34:28.150 
And depending on the way that you charge, you could possibly even double or triple the amount of charges that you can

393
00:34:28.150 --> 00:34:34.860 
do and sort of total energy you can store, depends on the way that the battery is managed itself.

394
00:34:35.940 --> 00:34:43.469 
So, here's an idea that is worth pursuing where I can help us with getting better storage system without any change of material

395
00:34:44.340 --> 00:34:49.230 
if we are able to use an electrical or we use an unknown electrical.

396
00:34:49.239 --> 00:34:53.809 
That's physics; thermal, that's physics; aging or chemical,

397
00:34:53.820 --> 00:35:01.239 
forward model by this, I mean a model like we learn in physics, I'll show you one in a minute; then, to describe

398
00:35:01.250 --> 00:35:07.889 
the operational behavior of battery is what's the current temperature and time

399
00:35:07.889 --> 00:35:15.349 
series as a function of the, sorry, what's the voltage and temperature time series as a function of the current that gets

400
00:35:15.349 --> 00:35:15.820 
applied.

401
00:35:15.820 --> 00:35:23.829 
So how much Ampere get either charged or discharged by the battery, then we could simulate the battery years in advance to know how

402
00:35:23.829 --> 00:35:28.860 
it will degrade as it's used in particular usage scenarios.

403
00:35:28.869 --> 00:35:36.489 
Now we would like to know is these hidden quantities like the degradation of the anode, of the cathode separator

404
00:35:36.500 --> 00:35:41.389 
to the so called state of health, but we can never measure it without destroying the batteries.

405
00:35:41.389 --> 00:35:47.059 
So why not take the operational parameters that we observe, the voltage and temperature as a function of current.

406
00:35:47.539 --> 00:35:52.250 
And use the fact that ML is all about inverting a forward process, in this case,

407
00:35:52.250 --> 00:36:01.000 
the forward process that is well known comes from physics and chemistry in order to ensure those and even the proper

408
00:36:01.000 --> 00:36:03.050 
cause of prediction of what's going to happen.

409
00:36:03.530 --> 00:36:09.110 
Now, what's nice about such a setup is because we would use physics and chemistry, we have a causal model where it's already

410
00:36:09.110 --> 00:36:14.920 
been established in related fields that the, you know, the relationship of causal effect is established.

411
00:36:14.920 --> 00:36:22.849 
So general is very well, if you want to generalize the system for battery management and secondly, it's highly data efficient

412
00:36:22.849 --> 00:36:28.460 
because we use a lot of prior knowledge and when I say a battery management system, today's batteries that are used in your

413
00:36:28.460 --> 00:36:32.429 
laptop or in the car or in a home appliance,

414
00:36:32.440 --> 00:36:39.619 
each of them has a little microcontroller attached to them because the batteries that we saw, the chemical reaction that

415
00:36:39.619 --> 00:36:48.360 
we saw in lithium ion, it's really only safe when it happens below 46 degrees centigrade; if the temperature ever rises

416
00:36:48.360 --> 00:36:48.980 
higher,

417
00:36:49.070 --> 00:36:55.969 
there's a risk of a thermal runaway reaction and that was always a big fear that people had before lithium ion

418
00:36:55.969 --> 00:36:59.599 
batteries were used in the everyday life, are they safe enough?

419
00:36:59.610 --> 00:37:09.070 
So every lithium ion battery consists of many cells being put in series or in parallel electrically, and the microcontroller

420
00:37:09.070 --> 00:37:16.090 
makes sure that the chemical reaction is being slowed down or even stopped when the temperature

421
00:37:16.099 --> 00:37:18.840 
goes outside of the boundary ranges of the battery.

422
00:37:18.849 --> 00:37:23.650 
To put the risk of a thermal runaway reaction close to zero, it's not currently used.

423
00:37:23.650 --> 00:37:27.250 
It runs software, it's not currently used to extend the battery life.

424
00:37:27.730 --> 00:37:30.769 
And so the idea that you see here is such an idea.

425
00:37:30.780 --> 00:37:37.010 
So if you look at the battery again, one way that we've modeled this in a recent project is that we said, we have two

426
00:37:37.010 --> 00:37:38.969 
parameters we can constantly observe.

427
00:37:38.980 --> 00:37:42.519 
Typically at the 1 to 15 second time frequency.

428
00:37:42.519 --> 00:37:46.289 
So within an hour we have hundreds of observations within a day or

429
00:37:46.289 --> 00:37:51.769 
thousands, which is the temporary voltage that we can read.

430
00:37:51.780 --> 00:37:52.019 
You know,

431
00:37:52.019 --> 00:37:56.559 
is it 4.2 volt or is it 4.1 volts or 3.8 volts and the temperature.

432
00:37:56.559 --> 00:37:57.840 
How many degrees Centigrade?

433
00:37:58.030 --> 00:37:59.969 
Or what kelvin is the battery at?

434
00:38:00.420 --> 00:38:01.650 
So we can observe that.

435
00:38:02.219 --> 00:38:06.380 
And the input is how much current gets currently drawn from the appliance for.

436
00:38:06.389 --> 00:38:07.820 
Are we charging the battery with?

437
00:38:08.320 --> 00:38:12.550 
And so your iPhone or your laptop.

438
00:38:12.559 --> 00:38:13.539 
They do this all the time.

439
00:38:14.519 --> 00:38:20.400 
Now there's something that we cannot observe but it's important for us because we would like to control those parameters

440
00:38:20.400 --> 00:38:21.840 
even though we never get ground truth.

441
00:38:22.320 --> 00:38:24.119 
And that's the state of charge.

442
00:38:24.130 --> 00:38:25.730 
So this is your bar.

443
00:38:25.739 --> 00:38:32.989 
How much capacity is left on the, from the left to the right before it is considered empty and we have to charge it again.

444
00:38:33.000 --> 00:38:34.250 
What's the state of health?

445
00:38:34.250 --> 00:38:38.380 
How degraded is the separator or the anodes or cathodes?

446
00:38:38.389 --> 00:38:41.440 
That's about four types of chemical reactions that integrate them.

447
00:38:41.920 --> 00:38:45.079 
I'm not gonna go in there and then electrical circus.

448
00:38:45.090 --> 00:38:46.840 
It behaves a bit like a capacitor.

449
00:38:46.840 --> 00:38:52.840 
So if you make a change of current and that's typically with time delay ending up in a change of voltage.

450
00:38:53.519 --> 00:38:55.309 
And so the electrical model would give us,

451
00:38:55.309 --> 00:39:00.489 
and this is relatively simple based on Kirchhoff's law and Ohm's Law gives us,

452
00:39:00.500 --> 00:39:09.659 
first an equation what's the output voltage as a function of the input temperature and the input voltage and the input

453
00:39:09.659 --> 00:39:10.250 
current.

454
00:39:10.820 --> 00:39:16.840 
Roughly saying that the health of the battery is proportionate to the internal resistance it solves.

455
00:39:16.849 --> 00:39:23.610 
And the state of charge is depending on the state of health, how much total capacity does the battery still have, given some

456
00:39:23.610 --> 00:39:25.780 
lithium is no longer movable.

457
00:39:25.789 --> 00:39:27.429 
And how much charge do I have before?

458
00:39:27.440 --> 00:39:28.679 
How much current do I draw?

459
00:39:29.719 --> 00:39:31.539 
So that's an electrical model.

460
00:39:31.820 --> 00:39:41.409 
You know, basic physics predicts how that looks like and then you have to obviously update also the the capacitive

461
00:39:41.420 --> 00:39:45.099 
current or the capacitive voltage of the battery.

462
00:39:45.110 --> 00:39:51.389 
Then you have a temperature model and this is where you really have to look into what's the physical design of the battery.

463
00:39:51.389 --> 00:39:54.219 
Is a cylindrical or is it like a rectangular?

464
00:39:54.219 --> 00:39:55.840 
It's like a block, like a concrete?

465
00:39:56.119 --> 00:39:58.900 
And I give you an idea of the heat exchange that can actually happen.

466
00:39:58.900 --> 00:40:02.599 
Plus of course what heat exchanges or cooling systems are in the battery.

467
00:40:02.610 --> 00:40:12.329 
So it depends on the state of charge the battery has as well as the output current, the output voltage and the temperature.

468
00:40:12.710 --> 00:40:19.039 
And lastly, the state of health is a function of how heavy was the charge or discharge?

469
00:40:19.050 --> 00:40:25.260 
What was the health before and at which temperature can make a reaction meaning, you know, how much could

470
00:40:25.269 --> 00:40:30.769 
each of these four elements of better react with the still free moving lithium in this case.

471
00:40:30.780 --> 00:40:40.679 
So we built a simulator that can do this a million times within seconds and simulate that forward model which has

472
00:40:40.690 --> 00:40:47.829 
a current as a cause, the voltage and the temperature as an effect and the state of charge.

473
00:40:48.210 --> 00:40:53.369 
How much charge the battery still has in the cycle, the state of health, how much longer would it live?

474
00:40:53.380 --> 00:40:58.139 
And the voltage of the capacitor with latent variables.

475
00:40:58.150 --> 00:41:06.670 
And we then use the method known as Gaussian processes to say we don't know what this blue curve is.

476
00:41:06.670 --> 00:41:09.719 
So this isn't a simulation where it's rather simple where we could simulate that.

477
00:41:09.719 --> 00:41:11.469 
We assume we have one cell.

478
00:41:11.480 --> 00:41:14.739 
The cell is really behaving like in our physical and chemical model.

479
00:41:15.110 --> 00:41:23.239 
And we gave the algorithm just a trace of 1000 time steps, that was 1500 seconds or roughly half an hour of operation.

480
00:41:23.610 --> 00:41:28.090 
And we asked what was the initial state of health because we we didn't know it.

481
00:41:28.090 --> 00:41:38.670 
So the system was in blind system, just got two time series of voltage and temperature over half hour period with a given

482
00:41:38.679 --> 00:41:44.050 
current being charged and then discharged in alteration.

483
00:41:44.059 --> 00:41:48.349 
And it had to learn by approximating in the learning process.

484
00:41:48.349 --> 00:41:57.039 
This blue function as you can see it's pretty clever because it learns quickly that probably most of the peak is around 70%

485
00:41:57.050 --> 00:41:57.739 
and learns that.

486
00:41:57.750 --> 00:41:59.119 
And why we use this?

487
00:41:59.130 --> 00:42:07.079 
Well there is a device that we have analyzed which is made out of car batteries that are coming out of their first life.

488
00:42:07.090 --> 00:42:12.340 
And I say first life, I mean after about 1500 to 2000 charge cycles.

489
00:42:12.349 --> 00:42:17.269 
Car battery, the battery that drives cars like, you know,

490
00:42:17.449 --> 00:42:20.550 
Audi A3 or Tesla or Renault ZOE.

491
00:42:20.559 --> 00:42:22.429 
They they're still fine.

492
00:42:22.440 --> 00:42:30.610 
They still have 70-80% of capacity but they no longer have enough mileage in them for a whole round trip that was promised.

493
00:42:30.610 --> 00:42:35.150 
So they have to be recycled but they shouldn't be recycled into its raw materials.

494
00:42:35.150 --> 00:42:38.469 
They should actually be still used for the second life, at least

495
00:42:38.469 --> 00:42:40.730 
another 1500 charge cycles or more.

496
00:42:41.099 --> 00:42:44.130 
In the second life though we don't know what each of the cell's

497
00:42:44.139 --> 00:42:45.239 
battery health is.

498
00:42:45.250 --> 00:42:47.599 
What's the state of health of each of these cells?

499
00:42:47.730 --> 00:42:56.349 
Here's an example where 14 of these cells get put together in this block, see out there, and here we simulated the same algorithm

500
00:42:56.349 --> 00:43:01.389 
you saw now by this time about 1000 trials in a 14 dimensional parameter space.

501
00:43:01.389 --> 00:43:06.449 
So that was a little harder but also you can see here, the red line being the ground truth and the blue

502
00:43:06.449 --> 00:43:09.780 
line being the learned one that these methods that you know from AI

503
00:43:09.780 --> 00:43:17.920 
for optimization of unknown objective functions that come out of a physical system are pretty efficient in learning

504
00:43:17.929 --> 00:43:24.269 
what the optimal initial configuration that we couldn't observe in practice.

505
00:43:24.280 --> 00:43:30.920 
And that's an example where I think AI really helps because from now on where this you could then really steer not only control

506
00:43:30.920 --> 00:43:38.530 
the exchange of energy within the cell, across the cells but also the assembly of these second life batteries or the microcontroller

507
00:43:38.530 --> 00:43:46.320 
reprogramming and to steer these batteries better to extend from 1500 to 3000 cycles of second life.

508
00:43:46.800 --> 00:43:54.739 
So before it closed and open for questions, I just wanted to make a call out for climate clubs because as we got

509
00:43:54.739 --> 00:44:04.130 
together here, you know, we are almost like a climate club in that we are here in a student driven network that's

510
00:44:04.130 --> 00:44:11.239 
between people from companies, people from academia and policy makers that are working on the topic of sustainability.

511
00:44:11.250 --> 00:44:13.039 
Climate club is not a new invention.

512
00:44:13.150 --> 00:44:21.260 
This already exists as a concept and one of the things that we would like to do is really set up such a climate club around

513
00:44:21.269 --> 00:44:22.409 
clean IT

514
00:44:22.409 --> 00:44:25.769 
or sustainability with a focus on information technology

515
00:44:25.780 --> 00:44:34.780 
from out of this forum, what we already have is the openXchange talks like we have this one since June

516
00:44:34.789 --> 00:44:37.590 
last year. We had the annual clean-IT

517
00:44:37.590 --> 00:44:45.000 
conference about three months ago and MOOC came, hosted on openHPI

518
00:44:45.039 --> 00:44:51.380 
that came out of this and launched in April and if you think this is a really great idea we should really do this

519
00:44:51.389 --> 00:44:54.719 
in fact we want to learn how to set up these climate clubs.

520
00:44:55.190 --> 00:45:04.340 
I'm here to then have a blueprint and have that many, many climate clubs created in the next few years.

521
00:45:04.349 --> 00:45:11.530 
And if you find this is an interesting concept, I would have to ask you first get in contact with Nils, Sophie and Malte

522
00:45:11.539 --> 00:45:17.250 
to be part of founding team because three of them are in the process of setting this up.

523
00:45:17.260 --> 00:45:19.340 
I'm very happy being a sponsor.

524
00:45:19.340 --> 00:45:24.719 
We met this morning to discuss some of the responsibilities that each of us would have there.

525
00:45:24.730 --> 00:45:31.000 
And even more so if you yourself are interested or even if you're not and you can't make it, but you think this is worth

526
00:45:31.039 --> 00:45:38.219 
doing, please look through your network all the people you know that you find might be interested and speak to them

527
00:45:38.219 --> 00:45:45.809 
and ask them to contact the three of them to be part of founding team or to connect them in areas that are

528
00:45:46.389 --> 00:45:54.050 
research and their specific academic institutions, applications in their companies or questions how to best regulate in terms

529
00:45:54.050 --> 00:45:57.420 
of the policy making activities that they're involved.

530
00:45:57.789 --> 00:45:58.300 
Thank you.

531
00:45:59.789 --> 00:46:01.559 
Thank you very much for your presentation.

532
00:46:01.570 --> 00:46:06.400 
I hope you can all hear me because I had some, no! I think you cannot.

533
00:46:07.280 --> 00:46:08.210 
Can you hear me now?

534
00:46:10.780 --> 00:46:12.449 
Okay, perfect.

535
00:46:12.460 --> 00:46:14.070 
Thanks a lot for the presentation.

536
00:46:14.079 --> 00:46:21.130 
Very unfortunately the time has also advanced quite quickly but maybe we can accept one or two questions before Ralf has

537
00:46:21.130 --> 00:46:21.400 
to go.

538
00:46:21.400 --> 00:46:22.090 
Unfortunately.

539
00:46:22.579 --> 00:46:24.449 
I saw that one question in

540
00:46:24.449 --> 00:46:32.210 
the chat for example was "would it be meaningful to collect big data from electric car batteries in order to optimize them?"

541
00:46:34.380 --> 00:46:35.760 
Yeah, I can answer this.

542
00:46:35.769 --> 00:46:37.590 
So it would be meaningful.

543
00:46:37.590 --> 00:46:46.059 
In fact there is a policy making site, there is regulation in work to create something known as a battery passport to

544
00:46:46.059 --> 00:46:48.170 
make it exchangeable across manufacturers.

545
00:46:48.170 --> 00:46:50.000 
So it's not just manufacturing goal.

546
00:46:50.480 --> 00:46:51.630 
However, I should say.

547
00:46:51.630 --> 00:46:56.510 
However, we have to give you a sense that about 10 million

548
00:46:56.510 --> 00:47:03.500 
EV cars currently on the roads and it's the first year in the next seven years where those cars will get out of there,

549
00:47:03.500 --> 00:47:09.389 
first out of service in the sense of their first life batteries, the cars and the frame will continue to run but the batteries

550
00:47:09.389 --> 00:47:10.000 
need changing.

551
00:47:10.480 --> 00:47:16.710 
So in the next seven years we're gonna have 10 million cars worldwide coming back from the car manufacturers

552
00:47:17.079 --> 00:47:19.710 
with their batteries replaced.

553
00:47:20.079 --> 00:47:31.019 
Those batteries were put in place in 2013-14 the first time, meaning, we don't have the data from first life, we don't

554
00:47:31.019 --> 00:47:35.380 
have much data from first life because the software was written in 2012.

555
00:47:35.389 --> 00:47:40.179 
So we have rudimentary data, collection frequency is not as high.

556
00:47:40.190 --> 00:47:44.800 
We may have auxiliary data from the cars.

557
00:47:45.179 --> 00:47:51.320 
So in the future we'll have much more because there's already much more data being logged and there's now a standardization

558
00:47:51.329 --> 00:48:00.010 
but for a second large application, those will really only be meaningful in 2028 to 2030. So I think it's worthwhile to, you know, for

559
00:48:00.010 --> 00:48:01.150 
us to research also.

560
00:48:01.159 --> 00:48:08.420 
What data can you get out from first life when the logging frequency was low and maybe from some of the auxiliary

561
00:48:08.420 --> 00:48:14.800 
data usage as such as the mileage driven different per week.

562
00:48:14.809 --> 00:48:19.900 
The data is basically in the car sector manufactured in 2012 to 2017-18.

563
00:48:20.769 --> 00:48:21.949 
But absolutely.

564
00:48:21.960 --> 00:48:23.889 
So hopefully that answers the question.

565
00:48:24.469 --> 00:48:32.789 
I think so if not the person can of course also get in touch again and amuse themselves maybe and maybe I can just

566
00:48:32.829 --> 00:48:34.510 
ask the next question from the chat.

567
00:48:34.519 --> 00:48:39.190 
So this was about the energy density slide which you presented a few minutes ago.

568
00:48:39.199 --> 00:48:45.030 
And do you happen to know the energy density of uranium for example?

569
00:48:45.039 --> 00:48:47.079 
No, no.

570
00:48:47.230 --> 00:48:49.989 
Do you mean like for nuclear energy?

571
00:48:50.769 --> 00:48:55.239 
I think for the nuclear energy. Yeah, I don't know, I think it's very high.

572
00:48:55.250 --> 00:48:57.849 
But there are other risks with nuclear energy.

573
00:48:57.860 --> 00:49:03.610 
I mean there's risks that are substantial, but I don't know from top of my head, so I don't want to make it up.

574
00:49:03.619 --> 00:49:07.800 
I can, I will get back, I'll definitely look it up and get back and augment the presentation.

575
00:49:07.809 --> 00:49:08.500 
That's helpful.

576
00:49:08.869 --> 00:49:13.480 
We can also just post the link in the chat if we have found some kind of resource for that.

577
00:49:13.489 --> 00:49:21.019 
Sure, okay, so yeah, maybe I will just open for the round here, if somebody wants to unmute themselves or raise

578
00:49:21.019 --> 00:49:22.789 
their hand to ask a question per person.

579
00:49:23.369 --> 00:49:27.869 
You got your chance right now,

580
00:49:27.869 --> 00:49:33.699 
but if nobody seems to be interested right now, I have one more question.

581
00:49:34.070 --> 00:49:40.349 
So you talked a little bit about this benchmarking stuff and the trade off between energy consumption

582
00:49:40.349 --> 00:49:41.690 
and accuracy of machine learning.

583
00:49:42.170 --> 00:49:50.639 
And so most of the optimizations in the AI topics so far has resolved around the production of the inference phase because

584
00:49:50.639 --> 00:49:54.500 
you only tried to optimize neural networks once you have already trained them to the end.

585
00:49:54.969 --> 00:50:01.449 
And so the question would be, how important and how relevant in the future will the entire life cycle, like also the training

586
00:50:01.449 --> 00:50:06.880 
and maybe even the data collection will be and what role will it play in this benchmarking area?

587
00:50:09.659 --> 00:50:11.239 
Very good question.

588
00:50:11.239 --> 00:50:16.960 
So I think

589
00:50:16.960 --> 00:50:23.800 
I think it will play a huge role because of two reasons.

590
00:50:23.809 --> 00:50:36.250 
So one reason is the ephemeral nature of predictions and that has to do with, so there's applications such as object recognition

591
00:50:36.260 --> 00:50:39.280 
where ground truth is not changing with time.

592
00:50:39.659 --> 00:50:41.789 
you know, there's not much.

593
00:50:41.800 --> 00:50:49.469 
So the way a car looks and the tree looks and bike looks, you know, all these categories hasn't changed so substantially.

594
00:50:49.469 --> 00:50:52.449 
So in our environments, cars changed a bit of an appearance.

595
00:50:52.449 --> 00:50:57.909 
But animals and humans and physical things in nature don't really change that much.

596
00:50:57.920 --> 00:51:03.679 
So the concept, as you say, machine learning, the concept of the target class exhibits no drift.

597
00:51:04.559 --> 00:51:09.389 
But that's the first rate of applications where we see computer vision being used.

598
00:51:09.760 --> 00:51:13.059 
Now if we start to use them more and more in our social interactions.

599
00:51:13.070 --> 00:51:17.530 
So in pictures like an art, there is no target concept.

600
00:51:17.530 --> 00:51:22.389 
There's art of the 1600s, 1700s, 1900s; there's art every decade.

601
00:51:22.760 --> 00:51:33.199 
You know, if you use them for finer material where the seasonality or a trend, then whatever you learn is not

602
00:51:33.199 --> 00:51:39.860 
gonna be for internal use or for multi-year use, but for a shorter time.

603
00:51:39.869 --> 00:51:43.019 
So I've learned this myself first when I was working in the fashion.

604
00:51:43.030 --> 00:51:51.269 
So when you look at fashion data, in a catalog of electronic catalog every six months, it's new because by the nature of it

605
00:51:51.559 --> 00:52:00.269 
you know, what was in fashion in terms of shirts and skirts and trousers. In summer 2022 is no longer in fashion in 2023.

606
00:52:00.280 --> 00:52:06.590 
So whatever you learn needs to be a particular for the next six months, otherwise you could learn, but it has no use

607
00:52:06.590 --> 00:52:10.980 
you cannot sell more fashion items, you can't resell more of them.

608
00:52:11.449 --> 00:52:20.210 
And when AI or methods of AI are further penetrating in the consumer areas that are more

609
00:52:20.210 --> 00:52:21.179 
ephemeral in nature.

610
00:52:22.050 --> 00:52:30.170 
I think the amount of the energy you need for training will be substantially more important.

611
00:52:30.170 --> 00:52:35.530 
Right now, we consider the fixed cost because the concepts we assume are not drifting.

612
00:52:35.539 --> 00:52:43.730 
So if I train on sound or if I train on languages, if I train on object categories in nature, it's okay because I can

613
00:52:43.730 --> 00:52:45.260 
use it for the next 10 years.

614
00:52:45.449 --> 00:52:52.820 
But if I train a model on something that has a lifetime of six months, every six months, then the training costs becomes

615
00:52:52.820 --> 00:52:54.699 
a bigger part of the training.

616
00:52:54.710 --> 00:52:59.920 
And something that's really only gonna last for four weeks or for eight weeks because there is some adversary in nature,

617
00:52:59.920 --> 00:53:01.650 
like social media content.

618
00:53:01.650 --> 00:53:07.289 
Textual content of that has, you know, that has some time decay of it.

619
00:53:07.289 --> 00:53:13.050 
Or maybe there's a party that changes the distribution of the data because it wants to get distribution for free through

620
00:53:13.050 --> 00:53:20.199 
an advert, the training becomes a substantially bigger part in the total and actually of the unit that's to be learned

621
00:53:20.210 --> 00:53:21.059 
and predicted from.

622
00:53:23.349 --> 00:53:30.750 
So it does get kind of more relevant. And it will get more relevant the deeper AI enters into everyday application.

623
00:53:30.760 --> 00:53:31.699 
Yeah.

624
00:53:31.710 --> 00:53:32.920 
And what do you think?

625
00:53:33.190 --> 00:53:36.789 
I think you mentioned the energy bench on one of these slides earlier.

626
00:53:36.800 --> 00:53:38.110 
So what do you think?

627
00:53:38.119 --> 00:53:44.269 
How far are we with these benchmarking kind of institutions or benchmarking metrics and everything?

628
00:53:44.650 --> 00:53:53.570 
Do we already have some really reasonable benchmark and metrics methods for the energy and accuracy trade off or are we just

629
00:53:53.570 --> 00:53:56.170 
at the beginning and how long until we kind of get there?

630
00:53:57.650 --> 00:54:02.789 
I will answer the first because on the second I think I'm a terror predictor of the future.

631
00:54:02.789 --> 00:54:09.530 
I've always been by the view that you know, I'm better at inventing the future than predicting it

632
00:54:09.539 --> 00:54:13.590 
so, but on the first, how far are we right now?

633
00:54:13.590 --> 00:54:23.309 
I would say it's very encouraging to see two things as a number of efforts by independent researchers and by groups to

634
00:54:23.309 --> 00:54:33.360 
build up a framework or a computational as well as interface framework for the assessment of algorithms.

635
00:54:33.739 --> 00:54:37.480 
I think there's a number of big problems.

636
00:54:37.480 --> 00:54:45.980 
So one is a number of relevant forms and it's solving if you want to assess objectively an algorithm's footprint, you need

637
00:54:45.980 --> 00:54:51.250 
to run it objectively on some hardware and that means you transfer some intellectual property in that process.

638
00:54:51.250 --> 00:54:58.460 
So, you know, it's hard to bring standardized hardware, it's easier to bring a dataset to everyone you make the

639
00:54:58.460 --> 00:54:59.260 
file available.

640
00:54:59.440 --> 00:55:02.170 
It's harder to bring the standardized hardware to everyone that can make it.

641
00:55:02.340 --> 00:55:09.219 
Yet if you, you know, in particular if you're not a non-for-profit or for-profit organization, it's really hard to

642
00:55:09.219 --> 00:55:10.559 
deal with the IP

643
00:55:10.940 --> 00:55:13.820 
data when you have a key considerations when you make that.

644
00:55:13.829 --> 00:55:17.539 
So we need to find interfaces by which you can package another.

645
00:55:17.539 --> 00:55:21.429 
Maybe it's a container  and the containerization helps.

646
00:55:21.440 --> 00:55:29.219 
But then you have a further abstract to hardware but it's encouraging to see that there's

647
00:55:29.219 --> 00:55:33.650 
actually already a number of efforts and I can link a few in the comments if people are interested.

648
00:55:33.820 --> 00:55:44.090 
But the other thing that's also encouraging I hear from a number of policymaker and funding bodies like

649
00:55:44.099 --> 00:55:50.659 
Fraunhofer and that they are seeing it as a major effort to steer the field and they are willing to invest in it.

650
00:55:50.670 --> 00:55:55.389 
So I think we, from a financial, from an investing perspective or getting it funded,

651
00:55:55.389 --> 00:55:59.500 
it seems promising, it is not something where you have to beg a lot.

652
00:55:59.510 --> 00:56:10.900 
But how to do it without an incentive system because maybe you have to tie some form of economic

653
00:56:10.900 --> 00:56:12.619 
reward or authenticity to it.

654
00:56:12.619 --> 00:56:14.659 
It has been a failed attempt,

655
00:56:14.659 --> 00:56:22.980 
I would say that ML field try to get basically on our rules, that reproducibility gets established, gets encouraged yet

656
00:56:22.989 --> 00:56:26.960 
you can still publish papers without necessarily ensuring reproducibility in the field.

657
00:56:27.329 --> 00:56:31.369 
So we need to learn from those mistakes done.

658
00:56:31.380 --> 00:56:33.440 
and we need to make sure that the IP

659
00:56:33.440 --> 00:56:35.550 
question is properly addressed.

660
00:56:36.730 --> 00:56:37.349 
Okay!

661
00:56:37.360 --> 00:56:43.219 
I think there's a lot of factors contributing to that, but it's kind of encouraging to hear that

662
00:56:43.219 --> 00:56:45.960 
there's a lot of attempts already going in that direction.

663
00:56:46.429 --> 00:56:51.260 
Yeah, I think with respect to time, I will close this session now.

664
00:56:51.269 --> 00:56:57.599 
I think there's also no more questions coming in from the audience so far, so thank you again very, very much for this interesting

665
00:56:57.599 --> 00:57:03.159 
presentation and also thanks everyone in the audience for coming by today and asking your questions.

666
00:57:03.530 --> 00:57:08.739 
We will of course just upload the recording in a few days time probably.

667
00:57:08.750 --> 00:57:16.719 
And yeah, as I said in the beginning we won't have any talks for the next two months probably, so we might see

668
00:57:16.719 --> 00:57:23.860 
each other again in September, I think we will make the first talk again and as Ralf mentioned, we are trying to build

669
00:57:23.860 --> 00:57:29.980 
up some kind of climate club here over the next months or over the summer break, essentially.

670
00:57:29.980 --> 00:57:39.639 
So, yeah, we will try to organize more events, organize more different types of events and everything and be sure

671
00:57:39.639 --> 00:57:42.110 
to keep yourself updated through the clean-IT forum

672
00:57:42.110 --> 00:57:45.309 
so we will probably post every updates into there.

673
00:57:47.530 --> 00:57:50.489 
I see that there is some questions to the climate club.

674
00:57:50.500 --> 00:57:51.980 
We will post everything in the chat.

675
00:57:51.980 --> 00:57:58.750 
So we're really in the beginning as of now, but you will get every information that you need through the clean-IT forum.

676
00:57:58.829 --> 00:58:00.599 
And I hope you're all ready.

677
00:58:00.599 --> 00:58:04.849 
Subscribe there and if not, go ahead and please join there right away to stay updated.

678
00:58:05.429 --> 00:58:08.750 
Yeah, so thanks again everyone and have a nice week.

679
00:58:08.760 --> 00:58:12.239 
And I hope we will see each other again in a few weeks.

680
00:58:13.829 --> 00:58:14.289 
Bye.

681
00:58:14.300 --> 00:58:15.030 
Thank you.

682
00:58:15.039 --> 00:58:15.840 
Bye bye.
