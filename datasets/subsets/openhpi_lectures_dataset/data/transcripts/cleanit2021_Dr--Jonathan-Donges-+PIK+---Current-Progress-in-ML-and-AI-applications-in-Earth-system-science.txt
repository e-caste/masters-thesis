WEBVTT

1
00:00:03.359 --> 00:00:04.259 
Welcome everyone.

2
00:00:04.269 --> 00:00:06.790 
Welcome back to our first clean IT

3
00:00:06.790 --> 00:00:10.800 
Open Exchange live talk in the second half of 2022.

4
00:00:10.810 --> 00:00:15.630 
We've had a little bit of a summer break for around two months but we are very happy to see that a lot of people

5
00:00:15.630 --> 00:00:20.339 
have joined in again in our first talk of this season.

6
00:00:20.750 --> 00:00:28.969 
Um I'm as always here with Sophie and also my talbot, we are all three part of the CleanIT team at HPI

7
00:00:28.969 --> 00:00:29.149 


8
00:00:29.149 --> 00:00:29.260 


9
00:00:29.260 --> 00:00:37.810 
And we are organizing these talks and hopefully also a few other events in the future and today as our guest with us is Jonathan

10
00:00:37.810 --> 00:00:46.399 
Donges. Jonathan is the co-leader of the Future Lab on Rarth Resilience in the Anthropocene and he's also the working group

11
00:00:46.399 --> 00:00:51.729 
leader on the Whole Earth System Analysis at the Potsdam Institute for Climate Impact Research.

12
00:00:51.740 --> 00:00:57.560 
You can already see that he's working a lot with different models and interactive dynamics.

13
00:00:57.570 --> 00:01:02.350 
Um and and big systems like interactions between nature and humanity.

14
00:01:02.789 --> 00:01:10.489 
His research work focuses on dynamics of planetary scale, socio ecological systems, climatic and social tipping elements

15
00:01:10.500 --> 00:01:12.590 
and their dynamics and interactions.

16
00:01:12.599 --> 00:01:21.689 
He also works on decarbonization, dynamic sustainability transformations as well as conceptual models and of socio environment

17
00:01:21.689 --> 00:01:23.329 
co evolutionary dynamics.

18
00:01:23.939 --> 00:01:32.000 
He studied physics mostly in Potsdam but also in Bonn for around two years and he holds a PhD in theoretical physics. Since

19
00:01:32.000 --> 00:01:33.140 
2013

20
00:01:33.140 --> 00:01:39.700 
he has been working as a researcher on various projects, mostly at the Potsdam Institute for climate impact research, but

21
00:01:39.700 --> 00:01:47.430 
also at other institutes, for example, the Stockholm resilience center. In today's talk Jonathan will be talking about the current

22
00:01:47.430 --> 00:01:52.709 
progress in machine learning and AI applications in the field of Earth System Science.

23
00:01:53.219 --> 00:01:56.310 
I'm very much looking forward to the talk and the discussion afterwards.

24
00:01:56.319 --> 00:02:04.000 
So please welcome with me Jonathan Donges.

25
00:02:04.000 --> 00:02:06.780 
And if you want you can start your presentation now.

26
00:02:07.409 --> 00:02:08.229 
Great.

27
00:02:08.240 --> 00:02:16.969 
Thanks a lot for your kind introduction and for inviting me to um to your seminar series.

28
00:02:16.969 --> 00:02:19.360 
So can you see the slides?

29
00:02:19.370 --> 00:02:21.030 
Great, Perfect.

30
00:02:21.030 --> 00:02:28.250 
So yeah and it's great that it works this time because last time we had some some problems and with organization and then

31
00:02:28.259 --> 00:02:32.300 
we had to skip it on short notice but this time it works out.

32
00:02:32.300 --> 00:02:43.080 
So what I would like to do today is um basically give you some some insights on how machine learning techniques

33
00:02:43.080 --> 00:02:53.169 
and artificial intelligence are being getting more used now in in earth system Science and modeling and

34
00:02:53.180 --> 00:02:59.250 
also some glimpses into work that I've been involved and that has used these techniques.

35
00:02:59.259 --> 00:03:04.960 
I must say like in needs introduction.

36
00:03:04.969 --> 00:03:07.870 
He already mentioned that I'm a physicist by training.

37
00:03:07.870 --> 00:03:15.280 
I'm by no means an expert in machine learning or artificial intelligence and I'm also not a computer scientist.

38
00:03:15.280 --> 00:03:18.900 
So please bear that in mind.

39
00:03:18.909 --> 00:03:21.650 
So I'm more from a user perspective in that sense.

40
00:03:21.659 --> 00:03:23.259 
I talk about some things here.

41
00:03:23.270 --> 00:03:30.210 
So yeah, certainly let's get started. Certainly

42
00:03:30.219 --> 00:03:42.550 
machine learning um and modern methods from that field are increasingly recognized as something that might be helpful

43
00:03:42.550 --> 00:03:45.419 
in earth system science in different aspects.

44
00:03:45.419 --> 00:03:54.919 
So there's a lot of publications coming out in recent, very recently that make a case why these techniques,

45
00:03:54.930 --> 00:04:04.349 
you know, including, for example, deep reinforcement learning or other modern methods of machine learning where they

46
00:04:04.360 --> 00:04:13.020 
would be useful in in this field and at the same time, people are already starting to apply these methods more concretely

47
00:04:13.020 --> 00:04:23.589 
and examples include um improving, for example, trying to improve climate models, trying to get better information out of

48
00:04:23.600 --> 00:04:33.060 
observational data on the earth system, trying to and improving models  might include better, you know,

49
00:04:33.069 --> 00:04:43.990 
better predictions, better process representations, also trying to learn representations of processes which are hard to to

50
00:04:43.990 --> 00:04:47.769 
derive from first physics principles like cloud dynamics for example.

51
00:04:47.769 --> 00:05:00.009 
So, all these kinds of things are being discussed in this field now and u to look a bit more in detail

52
00:05:00.009 --> 00:05:00.740 
into this.

53
00:05:00.750 --> 00:05:06.709 
Um there is, for example, this paper in Nature Machine Intelligence, which came out recently relatively recently,

54
00:05:06.709 --> 00:05:19.829 
which expands a bit more on these things and they split the application areas for what they call a so called

55
00:05:19.829 --> 00:05:24.730 
neural system modeling into 3 areas.

56
00:05:24.730 --> 00:05:32.800 
So to say that might merge at some point into some type of novel earth system modeling and basically the idea

57
00:05:32.800 --> 00:05:40.639 
in this type of earth system modeling is that physical equation driven modeling that is currently used in all

58
00:05:40.639 --> 00:05:44.009 
of the projections of global warming,

59
00:05:44.040 --> 00:05:51.470 
so really based on the equations of fluid dynamics and thermodynamics and so on, um you know, should be combined with

60
00:05:51.470 --> 00:06:01.040 
data driven machine learning um to for example, um compensate the lack of process knowledge on cloud dynamics as I mentioned

61
00:06:01.040 --> 00:06:02.709 
but also other processes.

62
00:06:02.720 --> 00:06:11.680 
Um and to identify areas where physics informed machine learning can outperform traditional models and traditional

63
00:06:11.680 --> 00:06:21.029 
parametrization because traditionally many of these processes have been represented by then very simple equations

64
00:06:21.029 --> 00:06:29.569 
for example, linear regression or some other very simple models that have been fitted to data but in this field,

65
00:06:29.569 --> 00:06:38.699 
the hope is that modern machine learning can improve things and there are already models around that

66
00:06:38.699 --> 00:06:48.490 
do this, that and the hope is here in this field that that perspective um these these physics equation driven modeling

67
00:06:48.490 --> 00:06:56.529 
and data driven machine learning can be, can become more intertwined over time and be more

68
00:06:57.149 --> 00:07:03.829 
so that that that there would be a new type of model that emerges out of this, up to the point that

69
00:07:03.829 --> 00:07:12.370 
people have basically claimed or you know, there's a vision that earth system models might be completely data driven and might

70
00:07:12.370 --> 00:07:23.279 
might be so that's um physics physics equation driven representations might not be needed at more anymore at some

71
00:07:23.279 --> 00:07:28.519 
point this is I don't really think this would be useful.

72
00:07:28.519 --> 00:07:38.089 
I rather think it should be this hybrid form that that uses um knowledge about how physical reality works that is already

73
00:07:38.089 --> 00:07:41.759 
there but combines it with more data driven approaches.

74
00:07:41.769 --> 00:07:44.509 
This is also where the field is developing.

75
00:07:44.519 --> 00:07:55.079 
Um yeah, 1 example which goes a bit into this um direction of how can we get a better understanding of the system interaction

76
00:07:55.079 --> 00:07:59.420 
networks or system processes using observational data.

77
00:07:59.430 --> 00:08:03.629 
Um It's something that I have been involved in quite a bit over the past years.

78
00:08:03.629 --> 00:08:13.069 
And these are the projects that use complex network theory and different techniques for constructing interaction networks

79
00:08:13.069 --> 00:08:16.670 
and causal interaction networks from data.

80
00:08:16.800 --> 00:08:19.680 
And this is what you see here is an example.

81
00:08:19.689 --> 00:08:27.680 
It's a very early example of work that we did already more than 10 years ago where we constructed a very simple causal

82
00:08:27.689 --> 00:08:35.919 
I mean it's not cause it's not a causal network at all actually in this case it's a correlation network representing correlations

83
00:08:35.919 --> 00:08:40.620 
between different surface air temperature time series.

84
00:08:40.629 --> 00:08:47.700 
So what you can and then we did, we basically included edges in this network that have a high that represent a high

85
00:08:47.700 --> 00:08:56.399 
correlation between different areas and then we fitted this network keeping only edges in this network that have high so

86
00:08:56.399 --> 00:09:03.110 
called edge between the centrality, which means that a lot of um interaction pathways are running through these edges.

87
00:09:03.120 --> 00:09:10.804 
And 1 finding the that we made already here is that even in such a very simple interaction network it's possible to see

88
00:09:10.815 --> 00:09:19.514 
ocean currents like the north atlantic circulation that you can see here in the tropical atlantic and also major tropical

89
00:09:19.524 --> 00:09:23.375 
circulation systems like the walker circulation turn up.

90
00:09:23.375 --> 00:09:30.524 
So it's possible even using this very crude approach to identify some very important key features of the Earth's climate

91
00:09:30.524 --> 00:09:31.355 
system.

92
00:09:31.365 --> 00:09:41.169 
And this has been refined a lot over the years. Jakob Runge in Jena and now Berlin has has done a lot of work and

93
00:09:41.169 --> 00:09:49.250 
I have been collaborating a bit with him on this where we developed a technique to reconstruct so called cause and

94
00:09:49.250 --> 00:09:52.190 
effect networks from time series data.

95
00:09:52.200 --> 00:10:01.850 
So basically take um take a complex system a special temporary grid of time series like in panel A here um. This is typically

96
00:10:01.850 --> 00:10:04.460 
the form that data and earth system science has.

97
00:10:04.460 --> 00:10:12.190 
So we have uh we have a lot of data that is available on a global on a grid and um we have

98
00:10:12.200 --> 00:10:12.960 
on each grid point.

99
00:10:12.960 --> 00:10:16.669 
We have a time series that might have a different resolution, different time span.

100
00:10:16.679 --> 00:10:17.679 
Um and so on.

101
00:10:17.679 --> 00:10:19.799 
But this is typically the form it takes.

102
00:10:19.809 --> 00:10:31.019 
And then what we did in this particular approach here is that we apply a dimensional reduction to to identify important

103
00:10:31.029 --> 00:10:34.379 
components that explain a lot of variants in this data.

104
00:10:34.389 --> 00:10:42.879 
This is certificate, this is a very simple approach, some rotated PCA type of analysis which then leads to a smaller number.

105
00:10:42.879 --> 00:10:54.059 
So except um normally you have 10,000 grid points or so in such a dataset, which is usually too much for um for these causes

106
00:10:54.070 --> 00:10:57.710 
effect network reconstruction techniques to be computational feasible.

107
00:10:57.720 --> 00:11:02.340 
Also you run into a causal dimensionality problems because the time series are not long.

108
00:11:02.350 --> 00:11:12.049 
Typically there are just a few, you know, decades of um and this is usually if you wanted to do reconstruction on the

109
00:11:12.070 --> 00:11:13.429 
whole dataset does get problematic.

110
00:11:13.429 --> 00:11:20.840 
So we do that dimension reduction which is already some can be done by by machine learning approaches and then the causal

111
00:11:20.840 --> 00:11:30.149 
reconstructions that occurs, which is about identifying connections between these different components, which are

112
00:11:30.159 --> 00:11:35.100 
more can be interpreted in a more causeway than than a mere correlations.

113
00:11:35.100 --> 00:11:43.080 
So this is about getting rid of um indirect pathways, getting rid of common drivers, effects etcetera.

114
00:11:43.360 --> 00:11:49.950 
And this can then this leads to them to a cleaner network that is called a causal effect network which is shown in panel D.

115
00:11:49.960 --> 00:11:59.480 
And this can then in the next step be analyzed using um specifically developed methods from that include information on information

116
00:11:59.480 --> 00:12:01.210 
flux is through different nodes.

117
00:12:01.220 --> 00:12:04.769 
The importance of different nodes for the dynamics of the solar system.

118
00:12:04.779 --> 00:12:14.960 
And one of these measures can then be used ideally to can be used to improve climate models by identifying areas, for

119
00:12:14.960 --> 00:12:18.539 
example where which are particularly important in this system.

120
00:12:18.549 --> 00:12:25.179 
They can be used to check whether certain key features in this causal network are represented in the model.

121
00:12:25.179 --> 00:12:32.259 
When you compare the causal network reconstructed from modern data, for example with a network constructed from observational

122
00:12:32.259 --> 00:12:32.519 
data.

123
00:12:32.519 --> 00:12:36.639 
So there's a lot of stuff that you can do using using these causal effect networks.

124
00:12:36.639 --> 00:12:46.039 
And one example here is from a dataset of now surface air pressure I believe.

125
00:12:46.039 --> 00:12:55.269 
So it's it has to do something with variability of atmospheric pressure which is basically basic weather variability across

126
00:12:55.269 --> 00:13:04.179 
the globe and here causal effect network was reconstructed and measures of aggregate information flow were constructed

127
00:13:04.179 --> 00:13:12.240 
And one measure that is plotted here is the so called MP measure.

128
00:13:12.250 --> 00:13:18.779 
And this is um something similar to between the centrality in a in a standard network in a standard complex network which

129
00:13:18.779 --> 00:13:20.059 
you might have seen before.

130
00:13:20.070 --> 00:13:27.970 
But it's again this measure that has showed before in this surface air temperature network where notes that have a high um

131
00:13:27.980 --> 00:13:36.049 
in this case mediated causal effect strengths are very important for this tributing perturbations, you could say or

132
00:13:36.049 --> 00:13:37.450 
information in this whole network.

133
00:13:37.450 --> 00:13:44.879 
So, in a sense here, the ideas that these nodes which are particularly found in the tropics in this case,

134
00:13:44.879 --> 00:13:49.139 
so that's the nodes that are dark green are found particularly in the tropics.

135
00:13:49.210 --> 00:13:55.690 
And it turns out in terms of information flows through the whole system in terms of vulnerability to perturbations.

136
00:13:55.700 --> 00:13:58.039 
The tropics seem to be particularly important.

137
00:13:58.230 --> 00:13:59.710 
And then this is just an example.

138
00:13:59.710 --> 00:14:09.009 
A lot more can be done with these types of reconstruction techniques and yeah, this is then comparing these nodes that

139
00:14:09.009 --> 00:14:12.899 
have been identified to the tropical walker circulation again.

140
00:14:12.909 --> 00:14:22.740 
And um it turns out that these nodes that have this high information flow centrality actually are the main points where the

141
00:14:22.740 --> 00:14:32.820 
walker circulation um either rises into the higher levels of the atmosphere or goes down again.

142
00:14:32.820 --> 00:14:35.240 
So they are the major centers of convection in the tropics.

143
00:14:35.240 --> 00:14:41.769 
And this makes so the message here is that this makes also a lot of sense in terms of physics.

144
00:14:41.779 --> 00:14:49.169 
Um so the results that we get from this from this causal reconstruction technique, from this machine learning techniques

145
00:14:49.179 --> 00:14:56.000 
are consistent with the physical understanding and this is of course very good and gives hope that these types of methods

146
00:14:56.000 --> 00:15:03.409 
can also be made even more intertwined and more comfortable in these hybrid system models that people are working on now

147
00:15:03.419 --> 00:15:12.750 
that can improve hopefully future climate projections and our general understanding of the climate system.

148
00:15:14.190 --> 00:15:17.519 
Maybe I should also mention, I didn't do that.

149
00:15:17.529 --> 00:15:27.370 
Let me just turn back to this type of this this community that is emerging around these hybrid

150
00:15:27.370 --> 00:15:33.029 
earth system models, it's also it's not only about improving the models, it's also about making them more efficient.

151
00:15:33.029 --> 00:15:42.960 
So this is linking also a bit to your topic and there's hope that very complicated and costly computations um that

152
00:15:42.960 --> 00:15:55.210 
are done now in these models can be emulated and can be made much more lightweight and energy saving when

153
00:15:55.220 --> 00:16:01.070 
certain complex um neural network models are used instead that can emulate.

154
00:16:01.070 --> 00:16:08.769 
So it's always this idea about emulating the output of a very complex, costly model with a simpler structure which might

155
00:16:08.769 --> 00:16:10.200 
be a neural network.

156
00:16:12.210 --> 00:16:20.259 
Okay, so, I wanted to say this before I forget, but let me go back quickly to round a bit off on these

157
00:16:20.259 --> 00:16:21.529 
causal effect networks.

158
00:16:21.539 --> 00:16:28.360 
Um so these causal effect networks, they allowed to reduce spurious interaction links due to common drivers and indirect

159
00:16:28.360 --> 00:16:28.710 
coupling.

160
00:16:28.710 --> 00:16:33.019 
So very important for a better understanding of the system based purely on data.

161
00:16:33.320 --> 00:16:41.090 
And in that way they allow a more rigorous data driven investigation of hypotheses and causal interaction mechanisms in

162
00:16:41.100 --> 00:16:52.039 
the climate system and hence they can be used to improve also the process driven models and um one particular area that we're

163
00:16:52.039 --> 00:16:56.299 
interested in is to use this to constraint interactions between tipping elements.

164
00:16:56.309 --> 00:17:03.960 
Um these elements that have threshold behavior and could have disastrous consequences for human societies if they were

165
00:17:03.960 --> 00:17:05.910 
triggered like the Greenland

166
00:17:05.910 --> 00:17:09.740 
the atlantic ocean circulation, Amazon rainforest and so on.

167
00:17:09.750 --> 00:17:16.460 
So this is something that we're actually actively working on at the moment and we we hope that these these types of techniques

168
00:17:16.460 --> 00:17:22.140 
and other machine learning techniques can help us to get a better handle of these interactions between highly nonlinear elements

169
00:17:22.140 --> 00:17:26.559 
in your system from available observational data.

170
00:17:27.170 --> 00:17:37.690 
Yeah so this of course a lot of data is needed for these types of studies and there's a

171
00:17:37.690 --> 00:17:48.049 
move towards so called earth system data cubes where the data sets are made are brought together and made consistent

172
00:17:48.049 --> 00:17:57.960 
in a certain sense by by making sure that they they exist on common grids that they are as many biases and problems

173
00:17:57.960 --> 00:18:02.569 
are removed before the data is provided to people for analysis.

174
00:18:02.569 --> 00:18:10.670 
And of course these types of um of data sets are key to use modern machine learning techniques and so on to the

175
00:18:10.680 --> 00:18:14.400 
to the highest uh possible benefit.

176
00:18:14.440 --> 00:18:20.210 
And um I wanted to point this out because this is a project that's um this is still available and it might be a

177
00:18:20.210 --> 00:18:26.549 
nice basis for further for further applications in our system science.

178
00:18:26.549 --> 00:18:30.720 
So maybe maybe there's also some some of you are interested in looking into this type of data.

179
00:18:32.390 --> 00:18:43.559 
Now, I would like to to go over to a second um application area that that we've also been working on

180
00:18:43.559 --> 00:18:45.289 
And this goes a bit more.

181
00:18:45.299 --> 00:18:57.740 
This is a bit less about constrained data constrained improvement or emulation of system models or getting

182
00:18:57.740 --> 00:18:59.950 
learning patterns and processes from data.

183
00:18:59.960 --> 00:19:08.980 
But it goes a bit more into simulation and harnessing techniques such as Mighty Age and deep reinforcement

184
00:19:08.980 --> 00:19:10.380 
learning and so on, for example.

185
00:19:10.390 --> 00:19:20.190 
So, it's an area and I just wanted to point this paper, it's out it's quite an interesting overview of different

186
00:19:20.200 --> 00:19:26.829 
perspectives of modern machine learning, artificial intelligence techniques.

187
00:19:27.000 --> 00:19:35.309 
And it has a lot of the examples that are discussed in this paper are discussed with reference to a system science application

188
00:19:35.309 --> 00:19:38.970 
sustainability science transformations and so on.

189
00:19:38.970 --> 00:19:40.670 
So, it's kind of interesting.

190
00:19:40.670 --> 00:19:47.900 
It's quite a broad and complex exposition that they have there.

191
00:19:47.910 --> 00:20:00.170 
But I would like to go into and  show you one example, particularly on reinforcement learning because this is relevant

192
00:20:00.170 --> 00:20:03.549 
to the agent based modeling that we're doing a lot.

193
00:20:03.559 --> 00:20:13.089 
So needs also mentioned in his introduction that I'm working on these planetary scale social ecological models and

194
00:20:13.089 --> 00:20:20.609 
1 particular important tool in this for us is so called agent based modeling.

195
00:20:20.619 --> 00:20:29.609 
And this is basically the idea is that an agent or multiple agents representing individuals,

196
00:20:29.619 --> 00:20:39.089 
human individuals but they might also represent certain institutions firms organizations or similar larger groups so to say

197
00:20:39.099 --> 00:20:49.420 
or institutions, these agents interact with an environment and this environment is in our case the earth system in some

198
00:20:49.430 --> 00:20:51.539 
in some or the other forms.

199
00:20:51.539 --> 00:20:57.660 
So usually we we have models that of course only represent a certain aspect of the

200
00:20:57.660 --> 00:20:58.009 
earth systems.

201
00:20:58.019 --> 00:20:59.269 
Not all of it.

202
00:20:59.279 --> 00:21:08.019 
And the agents can also be this can range from one agent um that represent some kind of a global planner like similar

203
00:21:08.019 --> 00:21:15.970 
to what the economists do up to a multiple agents that could for example represent different countries that would like

204
00:21:15.970 --> 00:21:18.140 
to undergo climate negotiations.

205
00:21:19.029 --> 00:21:25.750 
And there is in this framework of agent environment systems from computer science or robotics,

206
00:21:25.759 --> 00:21:35.480 
this can be conceptualized as the agent having a set of actions or management options that it can use to have an influence

207
00:21:35.480 --> 00:21:45.339 
on the environment and then the environment returns a reward uh to the agent via changes in its state.

208
00:21:45.349 --> 00:21:51.750 
So the the actions can change the state of the environment and the environment changes and has its own dynamics which then

209
00:21:51.750 --> 00:21:52.990 
has some effect on the agent.

210
00:21:52.990 --> 00:22:00.480 
And this can be conceptualized in being compatible with deep reinforcement learning and reinforcement learning paradigms

211
00:22:00.480 --> 00:22:07.349 
as a reward but it could of course also be negative reward could be a punishment or suffering or a kind of damage that

212
00:22:07.349 --> 00:22:18.019 
the agent receives. And management options in um in the example of climate change models include for example, having introducing

213
00:22:18.019 --> 00:22:26.140 
a carbon tax to the economy, um introducing subsidies for renewable energy, what to enforce some kind of nature um produce

214
00:22:26.150 --> 00:22:26.900 
protection policy.

215
00:22:26.900 --> 00:22:28.650 
These are just some examples, right?

216
00:22:28.660 --> 00:22:37.430 
The reward could be from a reward from a healthy environment in tech nature, but it could also be punishment

217
00:22:37.430 --> 00:22:43.710 
or damage from climate change, impact etcetera.

218
00:22:43.720 --> 00:22:54.569 
And in this particular study, published in Chaos here, that I would like to briefly talk about here, we had exactly

219
00:22:54.569 --> 00:22:56.950 
that we had these different management options.

220
00:22:56.960 --> 00:23:06.849 
We had a very simple model that represents the environment and the reward functions in this particular case where we

221
00:23:06.849 --> 00:23:15.650 
had two variants, we had one which was just about survivors, whether the agent survives a certain um certain development

222
00:23:15.650 --> 00:23:17.059 
trajectory or not.

223
00:23:17.069 --> 00:23:22.799 
And the other was distance to a certain planetary boundary of climate change.

224
00:23:22.799 --> 00:23:28.640 
So how the better the further away from the boundary, the better it is.

225
00:23:28.650 --> 00:23:38.740 
Then we used um deep reinforcement learning kind of standard set of algorithms based on q learning here to to to train

226
00:23:38.750 --> 00:23:42.420 
this agent um in interacting with this environment.

227
00:23:42.930 --> 00:23:48.170 
And yeah, I just really wanted to give you a glimpse of how this looks.

228
00:23:48.180 --> 00:23:51.339 
So in this, in this particular model, it's a really simple model.

229
00:23:51.339 --> 00:23:54.160 
It just has three different state variables it has.

230
00:23:54.170 --> 00:23:57.099 
So the environment consists of three different state variables.

231
00:23:57.109 --> 00:24:01.230 
Um and they are the carbon stock in the atmosphere.

232
00:24:01.250 --> 00:24:07.789 
This is basically a measure of climate change. They are economic output, which is a measure of the state of society.

233
00:24:07.789 --> 00:24:15.829 
So how wealthy or prosperous society is and then um the state variable which is renewable knowledge stock.

234
00:24:15.829 --> 00:24:19.569 
So this is basically how advanced the knowledge the science system of the society is.

235
00:24:19.940 --> 00:24:27.569 
And um so this environment consists of a set of three ordinary differential equations which are covered in a nonlinear

236
00:24:27.569 --> 00:24:27.769 
way.

237
00:24:27.769 --> 00:24:37.740 
And this agent can interact with this environment by by these actions which are again carbon tax subsidies for renewables

238
00:24:37.740 --> 00:24:39.029 
and nature protection.

239
00:24:39.039 --> 00:24:48.670 
And there are these the agent is trained using this deep reinforcement learning and what one can basically see is that

240
00:24:48.680 --> 00:24:55.579 
in only some cases the agent can learn to to navigate to this what is called a shelter here.

241
00:24:55.589 --> 00:25:05.980 
This is basically a good place to be where climate change is still relatively moderate and economy is relatively prosperous

242
00:25:05.990 --> 00:25:14.869 
because there's a high knowledge about renewable energy in this case. In some in many cases the system also collapses

243
00:25:14.880 --> 00:25:18.240 
down to a state where the economic output is low.

244
00:25:18.240 --> 00:25:28.089 
This is the lower right and um where climate change is relatively strong. So that this is just one first application um

245
00:25:28.099 --> 00:25:37.369 
of how we could go about using really all the advances that have been made in this field of deep reinforcement learning

246
00:25:37.380 --> 00:25:42.940 
and applied to funding strategies for sustainable development in the earth system.

247
00:25:43.240 --> 00:25:49.710 
And I think a particularly interesting and relevant area is really multi agent reinforcement learning when it comes to

248
00:25:49.710 --> 00:25:52.140 
strategic interactions between agents.

249
00:25:52.150 --> 00:25:59.319 
When you think, for example about states that have vested interests, lobbying groups, different types of actors on multiple

250
00:25:59.319 --> 00:25:59.910 
levels.

251
00:25:59.920 --> 00:26:05.140 
Um this this would be a very, very interesting to study this and no one is doing this so far.

252
00:26:06.430 --> 00:26:12.160 
Yeah, with that, I hope I could give you a little bit of a glimpse of what is going on in that field and

253
00:26:12.170 --> 00:26:13.980 
thanks a lot.

254
00:26:13.980 --> 00:26:21.809 
And if you have any questions, I hope I can answer them. Thank you.

255
00:26:21.819 --> 00:26:23.069 
Thanks a lot.

256
00:26:23.079 --> 00:26:24.119 
Thank you very much

257
00:26:24.130 --> 00:26:26.500 
Jonathan on for a very, very interesting talk.

258
00:26:26.509 --> 00:26:32.890 
I think we've touched a lot of topics and I think it's particularly interesting because as you said in the beginning, you

259
00:26:32.890 --> 00:26:36.519 
are kind of more on the user side of artificial intelligence.

260
00:26:36.519 --> 00:26:38.250 
So you're not a computer scientist yourself.

261
00:26:38.250 --> 00:26:43.930 
And so you're just using what other people have developed in the artificial intelligence area.

262
00:26:43.930 --> 00:26:50.980 
And so I think this is very, very interesting, not just to see how it can be used, but particularly how artificial intelligence

263
00:26:50.980 --> 00:26:57.349 
can of course be used to improve climate models and thus help climate research which is basically just as important

264
00:26:57.349 --> 00:27:02.059 
as making artificial intelligence more sustainable itself.

265
00:27:02.069 --> 00:27:06.319 
Yeah I think we can just head over to the QnA session right away.

266
00:27:06.319 --> 00:27:13.130 
So um just as a quick reminder you can answer ask questions in person if you want to just please raise your hand so we

267
00:27:13.130 --> 00:27:20.289 
can kind of find an order in which to ask those questions or if you don't want to be recognized at all

268
00:27:20.289 --> 00:27:25.880 
you can also just type your question in the chat and then I will answer or say them out loud.

269
00:27:25.890 --> 00:27:34.049 
And yeah so with that being said we already have one question during the presentation which said how do you prepare your

270
00:27:34.049 --> 00:27:38.279 
data so that it takes exactly to your requirements and needs.

271
00:27:43.390 --> 00:27:43.730 
Yeah.

272
00:27:43.740 --> 00:27:47.490 
So,

273
00:27:47.490 --> 00:27:57.549 
I mean this really depends on, I can say for example, for this case of the causal effect

274
00:27:57.549 --> 00:28:07.130 
networks, there's of course pre processing steps so what you typically have to make sure is that the data is

275
00:28:07.140 --> 00:28:16.710 
on for these methods on a sample on the same temporary grid so that you have measurements at all um at all grid points or

276
00:28:16.710 --> 00:28:20.039 
at the same time.

277
00:28:20.049 --> 00:28:27.880 
And for in regular time introverts it's also it's possible to generalize the methods to relax that a little bit but then

278
00:28:27.880 --> 00:28:36.589 
it gets much more complicated but in fact we have many situations where we we don't have equally sampled data for example

279
00:28:36.589 --> 00:28:42.619 
paleo climate is extremely important in this field, especially when it comes to interactions between tipping elements

280
00:28:42.619 --> 00:28:47.490 
which have a really long time to get some of them change over times of hundreds and thousands of years.

281
00:28:47.500 --> 00:28:57.140 
And we have data from archives in the earth system sediment cores, ice cores, stalagmites, tree rings and so on that

282
00:28:57.140 --> 00:29:04.410 
we can use to reconstruct these climate dynamics of the past, thousands and millions of years but but they are not available

283
00:29:04.410 --> 00:29:05.390 
in a very nice way.

284
00:29:05.390 --> 00:29:08.500 
So then if you want to use this data, you have more problems.

285
00:29:08.500 --> 00:29:12.930 
If you use modern data from satellite area also from satellite area it's easier.

286
00:29:13.079 --> 00:29:19.779 
But then this is just okay, very simply have the data on the same time

287
00:29:19.980 --> 00:29:27.359 
and in regular intervals but then it comes more to what you typically have to do is to do some kind of de trending um

288
00:29:27.369 --> 00:29:33.299 
and get rid of modes of variability that you think are not relevant for causal interactions.

289
00:29:33.299 --> 00:29:37.579 
So some kind of long, long term trends or common, common forcing.

290
00:29:37.589 --> 00:29:49.630 
So sometimes you have to try to get rid of changes in the solar intensity

291
00:29:49.630 --> 00:29:52.240 
for example, over several years and decades and so on.

292
00:29:52.240 --> 00:30:00.269 
And so it's always important to have a little bit of an understanding of what might drive the system and what you

293
00:30:00.279 --> 00:30:05.970 
want to get rid of before before you do your causal effect analysis.

294
00:30:06.559 --> 00:30:12.529 
Um so it's a bit like you need, you need this, you cannot do it completely blind and it's better to have some kind

295
00:30:12.529 --> 00:30:16.970 
of expert insight into what the system is actually doing.

296
00:30:17.579 --> 00:30:18.160 
Sure.

297
00:30:18.170 --> 00:30:21.069 
Yeah, I hope that answers the question.

298
00:30:21.079 --> 00:30:27.920 
Maybe if not you can also just type in again and maybe I have just 1 follow up question.

299
00:30:28.039 --> 00:30:36.640 
So I think in many artificial intelligence applications you would usually use this kind of labeled data where you have data

300
00:30:36.640 --> 00:30:40.779 
samples and then you have some kind of label for them which you want to predict in a way.

301
00:30:40.779 --> 00:30:43.180 
And this is for a lot of applications.

302
00:30:43.190 --> 00:30:49.529 
This is often a problem that you don't have enough labeled data to train your like neural networks or other types of models.

303
00:30:49.539 --> 00:30:56.730 
And so my question would be, do you also see these kind of problems in the earth system analysis fields where you need labeled

304
00:30:56.730 --> 00:31:03.220 
data and you would have to, I don't know, pay other people's to label some data first? Or do you rather use these kinds of

305
00:31:03.230 --> 00:31:07.980 
agents which are interacting with the system where maybe you don't need that much labeled data.

306
00:31:11.329 --> 00:31:15.220 
Yeah I think

307
00:31:18.480 --> 00:31:24.619 
so what you would typically - I think labeled data is not if I understand it correctly.

308
00:31:24.619 --> 00:31:32.099 
So what I understand is is this thing that you have for example, if you want an image recognition algorithm right that recognizes

309
00:31:32.099 --> 00:31:37.279 
that you have to have a lot of labeled pictures that where it says apple right.

310
00:31:38.700 --> 00:31:49.089 
And this is not what in many cases in the earth system model field where they try to introduce

311
00:31:49.099 --> 00:31:50.470 
neural networks.

312
00:31:50.480 --> 00:31:59.819 
I think this is not so much of what you need but what you rather need is what you usually

313
00:31:59.819 --> 00:32:08.769 
try to do is to predict based on um for think about for example about cloud dynamics.

314
00:32:08.779 --> 00:32:14.450 
What you would like to do is to, it's a process that happens on very small spatial scales.

315
00:32:14.460 --> 00:32:20.000 
Sometimes it's actually factor so clouds are self similar over many orders of magnitude.

316
00:32:20.000 --> 00:32:26.539 
And that means that sometimes things on the scale of millimeters or centimeters are important and then but also things on

317
00:32:26.539 --> 00:32:30.450 
the scale of hundreds and thousands of meters are important.

318
00:32:30.660 --> 00:32:37.160 
And this is something you cannot represent numerically in a global model, you cannot have a grid that has a resolution

319
00:32:37.160 --> 00:32:38.200 
of one centimeter.

320
00:32:38.210 --> 00:32:47.299 
So what you need is to learn somehow from data that if when there's data available for example from measurement

321
00:32:47.299 --> 00:32:57.349 
campaigns where where people have related very small scale measurements with larger scale macroscopic variables like you

322
00:32:57.349 --> 00:33:07.240 
would like to know for example based on overall temperature and humidity and air pressure and so on.

323
00:33:07.250 --> 00:33:09.779 
What is the what type of cloud forms?

324
00:33:09.789 --> 00:33:12.380 
What what is the idea of the cloud?

325
00:33:12.380 --> 00:33:14.180 
What how much light does it reflect?

326
00:33:14.190 --> 00:33:17.599 
Um What's the what's the optical signal and so on?

327
00:33:17.599 --> 00:33:25.799 
And um so you have to try so you have this data and then you try to learn a macroscopic representation of this transfer

328
00:33:25.799 --> 00:33:27.220 
function in some sense.

329
00:33:27.220 --> 00:33:27.440 
Right.

330
00:33:27.440 --> 00:33:37.440 
So I think the labeling is more you have already you have data and then you try to learn a simplified representation of this

331
00:33:37.440 --> 00:33:39.220 
data rather than having labeled data.

332
00:33:39.230 --> 00:33:40.329 
Does this make sense?

333
00:33:41.079 --> 00:33:42.250 
Yeah, I think it does.

334
00:33:42.259 --> 00:33:49.109 
I wasn't expecting, I was kind of expecting that you would say that you don't need that much labeled data which might be

335
00:33:49.109 --> 00:33:51.799 
a positive effect in some ways.

336
00:33:51.799 --> 00:33:53.720 
But of course then you have other challenges.

337
00:33:53.720 --> 00:33:54.109 
Of course.

338
00:33:54.109 --> 00:33:54.839 
Yeah.

339
00:33:54.849 --> 00:34:02.210 
Okay I think and I don't see anyone raising their hands so far so maybe I would have one question that goes kind of

340
00:34:02.210 --> 00:34:06.069 
into this sustainability and energy consumption direction.

341
00:34:06.240 --> 00:34:13.190 
So you already said that you are more of a typical energy artificial intelligence user.

342
00:34:13.199 --> 00:34:19.920 
And so my question would be what role does the energy consumption play for you maybe also beforehand?

343
00:34:19.920 --> 00:34:23.869 
So if you plan on using artificial intelligence

344
00:34:23.869 --> 00:34:32.449 
in some kind of fields for a research project, do you have to kind of estimate the possible energy

345
00:34:32.449 --> 00:34:42.280 
consumption beforehand and weigh the benefits and intelligence or do you just try it out and see how much it costs or not

346
00:34:42.280 --> 00:34:43.860 
pay that much attention to it?

347
00:34:49.300 --> 00:35:02.360 
Yeah usually, I mean we always try to think a bit before we compute too much if it's really

348
00:35:02.360 --> 00:35:04.289 
necessary and so on.

349
00:35:04.300 --> 00:35:17.949 
But usually, I mean there there's basically this how it works practically for us is that we try to

350
00:35:17.949 --> 00:35:22.550 
optimize as much as possible then we run and and and and do some benchmarking.

351
00:35:22.550 --> 00:35:23.639 
We try to optimize again.

352
00:35:23.639 --> 00:35:27.429 
So it's it's a bit um along those lines.

353
00:35:27.429 --> 00:35:34.920 
And the main constraint for us is usually at the Potsdam Institute that the cluster is full anyways, it's computing all

354
00:35:34.920 --> 00:35:39.159 
the time and then you have to wait and so on.

355
00:35:39.170 --> 00:35:48.940 
So if you have a more lightweight program, you get into the queue faster so to say.

356
00:35:48.949 --> 00:35:58.090 
So this is mainly how it's done practically and there's not so much people now thinking actively about how can we

357
00:35:58.090 --> 00:36:00.679 
improve our code to make it more energy efficient or something?

358
00:36:00.679 --> 00:36:08.440 
I mean there is what we do is that we have to service that have a lot of GPUs so

359
00:36:08.440 --> 00:36:13.260 
there's some attempt to to use GPUs for more efficient computing.

360
00:36:13.269 --> 00:36:15.239 
For example,

361
00:36:15.250 --> 00:36:24.619 
yeah but I think overall I mean there is an awareness that 11 needs to look at into this and and at least the

362
00:36:24.619 --> 00:36:31.150 
Potsdam Institute is also running on you know renewable energy on renewable energy contract.

363
00:36:32.420 --> 00:36:39.260 
Yeah I think I can understand that you try to I mean building lightweight models in general is of course always more

364
00:36:39.260 --> 00:36:46.440 
efficient because then you also have, you don't need to look at the run time and everything so much so maybe apart

365
00:36:46.440 --> 00:36:53.469 
from not just the energy perspective but have you made any experiences with using machine learning?

366
00:36:53.480 --> 00:37:01.730 
So you already said that you try to combine both methods like the standard or traditional way of modeling these interactions

367
00:37:01.730 --> 00:37:06.460 
and everything and then using machine learning for some parts of the process.

368
00:37:06.469 --> 00:37:13.219 
So have you already made some experiences regarding maybe the energy consumption but also like the run time and the development

369
00:37:13.219 --> 00:37:14.010 
process?

370
00:37:14.019 --> 00:37:19.880 
Does it take longer to utilize machine learning in these fields or is it a lot easier so far?

371
00:37:24.840 --> 00:37:32.690 
Yeah personally, you know so personally I can't sorry I can't really answer that because personally I haven't

372
00:37:32.699 --> 00:37:39.949 
be used these techniques to replace parts of the model with your network for example.

373
00:37:40.210 --> 00:37:50.090 
Okay so this is something that people are actively researching and I mean I think one thing that I've seen

374
00:37:50.090 --> 00:37:54.070 
in the literature is that it can really save on computation time.

375
00:37:54.070 --> 00:37:59.250 
I mean that's 1 motivation and in that sense hence it also saves energy.

376
00:37:59.260 --> 00:37:59.780 
Right?

377
00:37:59.789 --> 00:38:02.639 
But usually it leads to of course some kind of rebound effects.

378
00:38:02.650 --> 00:38:12.030 
Then you can compute more and run a larger ensemble and so on, for example, which is by the way, that's also some

379
00:38:12.030 --> 00:38:20.900 
important benefit because in many cases you would get much better projections or estimates of uncertainty of different climate

380
00:38:20.900 --> 00:38:24.869 
developments if you could have a larger number of simulation runs, right?

381
00:38:24.869 --> 00:38:27.690 
Not just two or 10, but 100 or 1000.

382
00:38:27.699 --> 00:38:29.199 
And that would be

383
00:38:29.210 --> 00:38:36.670 
and that's why these emulation emulation techniques are super important to to try to get a larger to a better representation

384
00:38:36.670 --> 00:38:38.889 
of the structural uncertainties.

385
00:38:39.969 --> 00:38:40.219 
Yeah.

386
00:38:40.230 --> 00:38:40.530 
Okay.

387
00:38:40.530 --> 00:38:41.710 
That makes perfect sense.

388
00:38:41.710 --> 00:38:42.119 
Of course.

389
00:38:42.119 --> 00:38:42.550 
Yeah.

390
00:38:42.559 --> 00:38:49.750 
And I think it's also important to think of the kind of rebound effect because that's often overlooked that

391
00:38:49.760 --> 00:38:57.500 
if you just make things more efficient that people tend to just use things more so you don't have any overall benefit

392
00:38:57.500 --> 00:38:58.150 
in the end.

393
00:38:58.389 --> 00:39:02.239 
Um so there was one more question in the chat, which kind of tools do you use?

394
00:39:02.239 --> 00:39:08.070 
And I also wanted to ask which kind of machine learning applications or algorithms have you already used?

395
00:39:08.079 --> 00:39:10.929 
So I think these questions kind of go hand in hand.

396
00:39:16.710 --> 00:39:17.440 
Okay.

397
00:39:17.449 --> 00:39:19.409 
Yeah, yeah.

398
00:39:19.409 --> 00:39:22.900 
I just typed it because it's always easier to find if you type it.

399
00:39:22.900 --> 00:39:23.389 
Right.

400
00:39:23.400 --> 00:39:26.539 
So you asked about what what did you ask about first?

401
00:39:26.539 --> 00:39:26.820 
Sorry.

402
00:39:26.820 --> 00:39:28.309 
The tools.

403
00:39:28.320 --> 00:39:28.989 
Yeah.

404
00:39:29.250 --> 00:39:29.739 
Right.

405
00:39:29.739 --> 00:39:30.300 
Yeah.

406
00:39:30.309 --> 00:39:40.199 
So so we do a lot of our work using python and different frameworks that I mean for example this this work on

407
00:39:40.199 --> 00:39:48.869 
deep reinforcement learning in this, um you know, very simple earth system model that showed here.

408
00:39:48.880 --> 00:39:58.989 
Um this is um this was done using these standard google libraries for deep reinforcement learning and so on

409
00:39:58.989 --> 00:39:59.369 
Right.

410
00:39:59.670 --> 00:40:04.340 
And Felix, the master student was doing that at that time maybe.

411
00:40:04.349 --> 00:40:10.780 
What we also did is we developed our own tools with for this clan network analysis that they showed.

412
00:40:10.780 --> 00:40:19.800 
This is one tool that I developed called Unicorn together with the group and still around and still being updated

413
00:40:19.800 --> 00:40:20.130 
and so on.

414
00:40:20.130 --> 00:40:26.559 
And then there's this tool for caus effealct networks is called So that's another tool for this is really more of the

415
00:40:26.559 --> 00:40:27.719 
data on the other side.

416
00:40:27.730 --> 00:40:31.829 
So when when it's about analyzing the data, getting the causal effect networks and so on.

417
00:40:31.840 --> 00:40:42.750 
Um and the people people doing this in in climate modeling and they probably have their own source frameworks for that too.

418
00:40:42.760 --> 00:40:49.579 
So there's a lot going on and and usually it's all embedded in the standard ecosystem of towards status around in

419
00:40:49.579 --> 00:40:50.349 
that field.

420
00:40:51.079 --> 00:40:52.070 
I can imagine.

421
00:40:52.079 --> 00:40:52.420 
Yeah.

422
00:40:53.460 --> 00:41:02.610 
Okay, so I think we've kind of reached the end of time in a sense, and I don't see any open questions so far.

423
00:41:02.610 --> 00:41:08.449 
So this is like the last call, if anyone has has another open question, go ahead right now.

424
00:41:08.849 --> 00:41:15.559 
But if that's not the case, I want to thank you again very much everyone for attending this year again.

425
00:41:15.559 --> 00:41:17.539 
So we will see each other in four weeks again.

426
00:41:17.550 --> 00:41:22.920 
Thank you, Jonathan of course, for your very interesting presentation and for answering these questions, even if you're not

427
00:41:22.929 --> 00:41:30.610 
a computer scientist expert, I think it was very interesting to kind of see this usage perspective and so yeah, I can for

428
00:41:30.610 --> 00:41:32.519 
some reason share my own slides right now.

429
00:41:32.519 --> 00:41:41.019 
So I just have to say in exactly four weeks again we will have another talk and this time our guest will be, let me

430
00:41:41.019 --> 00:41:43.369 
just find it out very quick, Tibebu Tesfaye Biru from the KRALLMANN AG,

431
00:41:43.380 --> 00:41:49.690 
he will be presenting the carbon monitor for machine learning.

432
00:41:49.690 --> 00:41:57.650 
So we will kind of stick to the carbon machine and machine learning field for a while and yeah, I hope we can

433
00:41:57.650 --> 00:42:04.050 
see you all again right there, you can of course, as always find the schedule on the cleanIT forum on openHPI

434
00:42:04.059 --> 00:42:10.590 
and we will send announcements of course, as always and yeah, if you have any further questions after the talk, maybe you

435
00:42:10.590 --> 00:42:12.840 
can also put them in the forum there, of course.

436
00:42:12.840 --> 00:42:16.030 
And we will also recall upload the recording as always.

437
00:42:16.030 --> 00:42:17.110 
So, yeah.

438
00:42:17.119 --> 00:42:17.960 
Thanks again, everyone.

439
00:42:17.960 --> 00:42:18.769 
Thanks for attending.

440
00:42:18.780 --> 00:42:19.119 
Thank you

441
00:42:19.119 --> 00:42:22.219 
Jonathan very much and see you again in four weeks.

442
00:42:22.219 --> 00:42:22.750 
Hopefully.

443
00:42:24.510 --> 00:42:24.760 
Good. Bye
