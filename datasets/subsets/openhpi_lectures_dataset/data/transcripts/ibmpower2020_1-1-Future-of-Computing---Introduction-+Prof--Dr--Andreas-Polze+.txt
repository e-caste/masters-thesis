WEBVTT

1
00:00:00.000 --> 00:00:06.320 
Welcome to our MOOC, to our second
iteration of the online course

2
00:00:06.750 --> 00:00:09.540 
Future of Computing - on the
Road to Quantum Computing.

3
00:00:09.990 --> 00:00:15.040 
My name is Andreas Polze and I'm at the
Hasso Plattner Institute responsible for the

4
00:00:15.290 --> 00:00:17.440 
operating systems and
middleware group.

5
00:00:18.110 --> 00:00:23.660 
In this course, we work together
with IBM and talk about

6
00:00:24.040 --> 00:00:29.360 
some topics that might
not firsthand be

7
00:00:29.360 --> 00:00:32.870 
computer architecture topics but
turn out to be very relevant

8
00:00:32.870 --> 00:00:35.710 
topics today if we talk
about future in computing.

9
00:00:36.240 --> 00:00:41.060 
The first agenda item I want to
touch is computing ethics. So what

10
00:00:41.200 --> 00:00:47.300 
if AI and all the modern systems,
they make decisions and

11
00:00:47.450 --> 00:00:53.230 
have to make decisions and avoid
risks and make decisions

12
00:00:53.230 --> 00:00:54.970 
that impact humans' life?

13
00:00:56.010 --> 00:00:59.090 
The second point I
want to touch briefly.

14
00:00:59.550 --> 00:01:03.130 
This is computer architecture
related and it's about energy and

15
00:01:03.130 --> 00:01:07.070 
we will figure out that the
energy usage in a real sense

16
00:01:07.080 --> 00:01:11.790 
of a single computer is maybe negligible
but of the entire computing

17
00:01:12.110 --> 00:01:16.090 
infrastructure of the ecosystem,
this is quite substantial and

18
00:01:16.090 --> 00:01:23.180 
something that needs to be discussed. And then we
look at dependability. Traditionally dependability

19
00:01:23.330 --> 00:01:28.210 
is one of the features in the
server computing arena and we

20
00:01:28.210 --> 00:01:32.910 
will see a transition from
hardware to software in this field.

21
00:01:34.500 --> 00:01:39.420 
Talking about artificial intelligence,
this is a little story that comes

22
00:01:39.690 --> 00:01:44.130 
out of New York Times from 2018. It's

23
00:01:44.130 --> 00:01:48.120 
about Uber and Uber
drivers and how they are

24
00:01:48.440 --> 00:01:53.080 
being treated by the system.
And the story is basically

25
00:01:53.080 --> 00:01:56.130 
if there are problems among the
passengers and the driver

26
00:01:56.550 --> 00:02:02.610 
then the passenger will be
able to evaluate the driver and

27
00:02:02.850 --> 00:02:08.080 
the situation if there are

28
00:02:08.740 --> 00:02:12.930 
drivers basically
mistreated or not

29
00:02:13.670 --> 00:02:19.010 
or treated in not in an appropriate
manner by the passenger. This situation

30
00:02:19.230 --> 00:02:23.740 
there's no significant or no
appropriate approach to deal with it.

31
00:02:24.180 --> 00:02:28.520 
Instead it's rather like the
system will make sure that the same

32
00:02:28.750 --> 00:02:33.050 
driver will not be matched
with the same passenger again

33
00:02:33.270 --> 00:02:37.410 
but if there are a number of such
cases and complaints, many

34
00:02:37.410 --> 00:02:40.310 
complaints about a particular
driver then the system will

35
00:02:40.310 --> 00:02:45.810 
deactivate the driver. So basically there is
a story that the computer algorithm

36
00:02:46.090 --> 00:02:50.790 
will make a decision about the
future life of a human being.

37
00:02:51.080 --> 00:02:56.570 
And the problem with that is
computers are neither objective

38
00:02:56.570 --> 00:03:01.390 
nor neutral or even but
this is just probabilities and

39
00:03:01.390 --> 00:03:03.030 
statistics what we
are looking at.

40
00:03:04.980 --> 00:03:08.720 
Another story, this is an interview
again from New York Times

41
00:03:09.030 --> 00:03:11.660 
talking with
Donald Knuth.

42
00:03:12.300 --> 00:03:17.460 
Donald Knuth wrote the book the
art of computer programming

43
00:03:17.470 --> 00:03:22.930 
actually series of books that
supposedly cover every single algorithm

44
00:03:23.080 --> 00:03:28.150 
that is relevant to computer
programmers. And he states

45
00:03:28.150 --> 00:03:30.690 
in the interview that he is
worried that the algorithms are

46
00:03:30.690 --> 00:03:34.330 
getting too prominent
in a word and

47
00:03:35.080 --> 00:03:39.360 
in the beginning when the computer scientist
expressed the problems then nobody would

48
00:03:39.770 --> 00:03:45.430 
but listen. And now it's
at a point that everybody

49
00:03:45.920 --> 00:03:49.450 
developed trust and
believes in algorithms

50
00:03:49.930 --> 00:03:54.320 
which is
inappropriate easily.

51
00:03:54.960 --> 00:04:02.110 
So it's basically a warning not
to trust the data and the

52
00:04:02.230 --> 00:04:04.460 
AI algorithms too much.

53
00:04:06.490 --> 00:04:10.360 
If you look at algorithms, data
and problems how do they match?

54
00:04:11.000 --> 00:04:14.740 
We have the engineers, the
scientists and the artists

55
00:04:15.120 --> 00:04:18.780 
who are teaming up to solve real
world problems today and the

56
00:04:18.780 --> 00:04:23.160 
algorithms are written by humans
and we are making progress,

57
00:04:23.160 --> 00:04:26.350 
we are tackling harder and harder
problems and produce code

58
00:04:26.770 --> 00:04:32.480 
with bugs and biases. And this is difficult
but this is how the world works today.

59
00:04:32.810 --> 00:04:38.810 
But tomorrow we if we look at algorithms
that are not written by humans maybe,

60
00:04:39.260 --> 00:04:43.500 
that are written by the machine
as it learns and the data is

61
00:04:43.500 --> 00:04:48.100 
the new domain of biases and bugs
and these bugs they are very

62
00:04:48.100 --> 00:04:52.190 
difficult to find and to pinpoint and
there's very little expertise on how to

63
00:04:52.660 --> 00:04:57.140 
analyze these data in comparison
to the more than fifty years

64
00:04:57.140 --> 00:04:59.370 
in computer science
expertise we have now.

65
00:05:00.070 --> 00:05:04.910 
And talking about data, it's
by the way tremendous amounts

66
00:05:04.910 --> 00:05:10.000 
of data we're talking about. For instance, if
you look at this autonomous driving and

67
00:05:10.220 --> 00:05:15.330 
features that you have in a car
then nowadays they put process

68
00:05:15.700 --> 00:05:20.440 
about up to three hundred pages of data just
for learning for training the algorithm

69
00:05:20.660 --> 00:05:25.090 
and then they achieve a
level of trust which is

70
00:05:25.090 --> 00:05:26.530 
close to ninety percent.

71
00:05:27.170 --> 00:05:32.650 
Ninety percent may sound like
a big figure but if you

72
00:05:32.650 --> 00:05:39.070 
look at control systems, at certifiable
systems, at safety properties in systems,

73
00:05:39.300 --> 00:05:42.990 
then it is quite inacceptable.
But you won't have

74
00:05:43.510 --> 00:05:46.150 
probabilities and safety
values in the range of

75
00:05:46.750 --> 00:05:50.920 
ninety nine point nine nine nine
percent, three nines, four nines,

76
00:05:51.190 --> 00:05:56.790 
this is what we are striving for and
data generated or AI algorithms

77
00:05:57.130 --> 00:06:00.060 
are not even close
to that figure today.

78
00:06:02.440 --> 00:06:05.020 
Another problem is the so
called trolley problem.

79
00:06:05.420 --> 00:06:09.410 
Just assume that there is an
autonomous driving system and

80
00:06:09.410 --> 00:06:14.900 
this is driving a trolley and
the trolley could move to

81
00:06:14.900 --> 00:06:20.750 
one route and hit five passengers or
five people on the street. However

82
00:06:20.970 --> 00:06:27.200 
the algorithm could also be able to
throw a lever and change track and

83
00:06:27.590 --> 00:06:30.270 
go to the other route and
hit only on one person.

84
00:06:30.940 --> 00:06:34.590 
So what is the right decision
the algorithm should do here?

85
00:06:35.060 --> 00:06:42.400 
And today the human driver would
react and it would be a subjective

86
00:06:42.870 --> 00:06:46.720 
decision by the driver. Obviously
there is no correct answer

87
00:06:46.720 --> 00:06:48.710 
to the problem right?

88
00:06:49.760 --> 00:06:54.000 
And it is only an indication
that we need to discuss an

89
00:06:54.000 --> 00:06:57.660 
entirely new field which
is ethics in computer science.

90
00:07:00.290 --> 00:07:03.720 
If we talk ethics there is another
bigger problem, the global

91
00:07:03.720 --> 00:07:08.770 
warming that affects all of us.
So and it stimates that a

92
00:07:08.770 --> 00:07:13.660 
computing system  account today for an
estimated thirty percent of the electricity

93
00:07:14.070 --> 00:07:19.550 
used in office buildings. There's
also other statistics telling

94
00:07:19.550 --> 00:07:23.380 
that the entire internet is using
anywhere between seven and

95
00:07:23.670 --> 00:07:27.120 
eleven per cent of the
worldwide energy consumption.

96
00:07:30.770 --> 00:07:35.520 
This means that IT infrastructure
is critical infrastructure

97
00:07:35.520 --> 00:07:41.080 
today, it also means that we
need to talk about green IT

98
00:07:41.290 --> 00:07:46.250 
if we want a deal or if we want to
use energy in an ethical manner.

99
00:07:46.490 --> 00:07:50.690 
And green IT, this means
server consolidation,

100
00:07:51.140 --> 00:07:56.630 
this means also virtualization and
this means in the beginning

101
00:07:56.630 --> 00:08:01.430 
that we need to be able to measure
our energy footprint. By the way,

102
00:08:01.630 --> 00:08:04.950 
talking about virtualization it's
not clear whether it's more

103
00:08:04.950 --> 00:08:09.390 
effective to have a single program run
to completion as quickly as possible

104
00:08:09.650 --> 00:08:13.260 
or whether it's better to use
virtualization to run as many

105
00:08:13.260 --> 00:08:18.550 
problems or as many programs in
simultaneously as possible.

106
00:08:20.500 --> 00:08:25.240 
If you look at standard systems
like the windows, like the linux

107
00:08:25.540 --> 00:08:30.780 
on an x64, on an ARM
architecture, then we have compact

108
00:08:30.780 --> 00:08:34.660 
and dense systems, we have multi-core/
multi-threading, we have

109
00:08:34.670 --> 00:08:39.400 
virtualization, and we have certain
trustworthiness and security, we have clustering.

110
00:08:39.640 --> 00:08:44.330 
But there are new programming
models on the horizon, new software

111
00:08:44.330 --> 00:08:46.270 
architectures and
new services.

112
00:08:47.750 --> 00:08:51.460 
If it comes to complexity or
to hardware, if it comes to

113
00:08:51.460 --> 00:08:53.560 
hardware then we talk
about heterogeneity.

114
00:08:54.240 --> 00:08:59.270 
So, for instance we have FPGA based systems
or Field Programmable Gate Arrays,

115
00:08:59.810 --> 00:09:05.320 
we have the GPU
computing device and we have

116
00:09:05.510 --> 00:09:11.420 
machine learning processes that integrate
both our GPU engine and also

117
00:09:11.720 --> 00:09:15.740 
the regular CPU and we have
systems like the POWER9,

118
00:09:16.130 --> 00:09:19.800 
where there is a close integration
with NV link and the GPU

119
00:09:19.800 --> 00:09:24.560 
devise by NVIDIA. There are
other interfaces on the horizon

120
00:09:24.770 --> 00:09:30.470 
like PCIe Gen4 that allow for
high bandwidth and connects to

121
00:09:30.760 --> 00:09:34.840 
a right number of
different hardware devices.

122
00:09:37.150 --> 00:09:41.400 
If we look at these systems then
we figure out that our CPUs

123
00:09:41.400 --> 00:09:46.360 
and GPUs and FPGAs, they need to
be connected and this is where

124
00:09:46.710 --> 00:09:50.980 
the learning from the high-performance
computing would come into play.

125
00:09:51.180 --> 00:09:56.640 
So the system architecture needs to
provide a tremendous amount of bandwidth

126
00:09:57.300 --> 00:10:02.130 
and then it's still, you still
look at a system that is

127
00:10:02.800 --> 00:10:06.040 
distributed from a programmer's point
of view. So we need not only

128
00:10:06.290 --> 00:10:10.070 
bandwidth among the units but
you also need unification and

129
00:10:10.070 --> 00:10:12.230 
a unified programming
model for all of them.

130
00:10:12.690 --> 00:10:17.110 
So for instance, if you look
at the GPU, then we see

131
00:10:17.110 --> 00:10:21.650 
a power computer
here, assembly system

132
00:10:21.890 --> 00:10:24.610 
where the memory
is dispersed among

133
00:10:25.120 --> 00:10:26.570 
the GPU course.

134
00:10:29.070 --> 00:10:33.920 
The need to measure, if you
look at all the vendors

135
00:10:33.920 --> 00:10:37.850 
then they will provide you with
all administrative tools and

136
00:10:38.170 --> 00:10:44.050 
these tools they allow to put
power cappings and allow to

137
00:10:44.150 --> 00:10:47.950 
shift workloads from those to
other nodes in order to balance

138
00:10:47.950 --> 00:10:51.980 
the usage of energy. So this is
something which is very important.

139
00:10:51.980 --> 00:10:55.970 
It's also true that the consolidation
of service increases efficiency.

140
00:10:57.890 --> 00:11:03.140 
It's not so easy to make a decision
where to play the particular

141
00:11:03.780 --> 00:11:07.690 
computation. So this is a couple
of graphs that come out of

142
00:11:07.690 --> 00:11:14.190 
a paper which has
just been submitted to ROSS 2020

143
00:11:14.390 --> 00:11:19.010 
and it basically
tells if you run programs

144
00:11:19.170 --> 00:11:25.240 
on a Jetson TX2
port than using the CPU

145
00:11:25.240 --> 00:11:31.460 
is more power efficient than using
GPU. It also shows you that the

146
00:11:32.510 --> 00:11:38.070 
CPU will take a little longer
than the GPU to compute results.

147
00:11:38.330 --> 00:11:42.260 
So there is a trade-off between
run time and power usage and

148
00:11:42.270 --> 00:11:44.510 
it's not clear how to manage
that trade-off. You could

149
00:11:44.930 --> 00:11:49.520 
give in a little bit of run time
and earn a lot in terms of power

150
00:11:49.700 --> 00:11:50.840 
or vice versa.

151
00:11:54.920 --> 00:11:58.920 
This was energy. Now let's talk a
little bit about another, about

152
00:11:58.920 --> 00:12:05.440 
the key properties of server systems which are
reliability, availability and serviceability

153
00:12:05.920 --> 00:12:11.170 
and the dependability topic, this is
basically the question how much

154
00:12:11.390 --> 00:12:16.330 
reliance can we place on computer
systems. And there's a

155
00:12:16.330 --> 00:12:20.600 
classification by Laprie which is
depicted here and tells you basically

156
00:12:20.940 --> 00:12:24.940 
there is again the question of
how to manage trade-off, the

157
00:12:24.940 --> 00:12:28.400 
trade-off between cost,
performance and dependability.

158
00:12:30.700 --> 00:12:34.250 
And if you look at the time axis
it was quite clear in the beginning

159
00:12:34.380 --> 00:12:37.280 
if there are mission critical
applications, they need their

160
00:12:37.280 --> 00:12:40.360 
own mission-critical systems, computer
systems and we need to have

161
00:12:40.610 --> 00:12:42.150 
particular hardware
solutions.

162
00:12:42.790 --> 00:12:46.450 
Later on we moved on to purely
software solutions like

163
00:12:46.450 --> 00:12:50.690 
big data centers and today
we look at combined solutions.

164
00:12:50.690 --> 00:12:54.330 
So we have large scale many core
servers and we have still

165
00:12:54.330 --> 00:12:58.300 
virtualization layers, virtualization is
everywhere and we will be able

166
00:12:58.450 --> 00:13:03.200 
hopefully to move complete load
from one node to another and so forth.

167
00:13:04.820 --> 00:13:10.190 
This is something that can be
observed in standard systems today where

168
00:13:10.700 --> 00:13:17.010 
we have the traditional memory
hierarchy, we have an even higher

169
00:13:17.370 --> 00:13:26.190 
integration of course in two processes,
where we have interconnects and

170
00:13:26.790 --> 00:13:30.630 
topologies inside the
system that remind of

171
00:13:31.760 --> 00:13:33.390 
supercomputers
of the past.

172
00:13:34.070 --> 00:13:37.080 
Looking at the memory hierarchy,
there is a new kid on the block

173
00:13:37.080 --> 00:13:40.940 
by the way which is a non-volatile
memory, which is not depicted

174
00:13:40.940 --> 00:13:44.640 
here yet but still it's not clear
how to deal with it, right.

175
00:13:45.070 --> 00:13:49.100 
If you look at first implementations
intel optane and how you

176
00:13:49.100 --> 00:13:54.460 
address this in linux then you
would rather use it as a separate

177
00:13:55.020 --> 00:14:02.070 
pool of memory like using mmap,
malloc to allocate memory from there

178
00:14:02.310 --> 00:14:05.000 
but is not usable for
instance as memory

179
00:14:05.400 --> 00:14:09.390 
where the stack resides on.
So it's a different piece.

180
00:14:09.390 --> 00:14:14.010 
It's not just replacing DRAM, but it's
a new kind of memory which comes

181
00:14:14.350 --> 00:14:17.520 
in addition and the programmer
needs to

182
00:14:17.960 --> 00:14:22.490 
make a decision which
allocations to place where.

183
00:14:22.910 --> 00:14:26.580 
And it's not clear how to
address this from software.

184
00:14:28.900 --> 00:14:34.220 
There is a question that lets
starts on the single core but

185
00:14:34.220 --> 00:14:38.900 
reaches up to the cloud and the question
is always about resource management

186
00:14:39.030 --> 00:14:43.450 
and where to put the computation. Just
to show one of the biggest systems

187
00:14:43.700 --> 00:14:49.620 
this is an SGI UV-300H
system that is now

188
00:14:49.930 --> 00:14:57.520 
being distributed in a similar
manner or similar topology by HPE

189
00:14:57.970 --> 00:15:02.490 
but this system we have
sixteen sockets, two hundred

190
00:15:02.490 --> 00:15:08.020 
forty cores, up to twelve TB memory.
So quite some size and the question on

191
00:15:08.180 --> 00:15:14.000 
where to place computation and where
to allocate the corresponding memory,

192
00:15:14.390 --> 00:15:18.820 
this question needs to be
answered and will have a big

193
00:15:18.820 --> 00:15:21.820 
impact on the performance
of a particular program.

194
00:15:23.670 --> 00:15:28.730 
More questions. If we look at acceleration
and in the traditional model,

195
00:15:28.930 --> 00:15:33.800 
we had the processor, we had the memory
and we had maybe device driver and that

196
00:15:34.120 --> 00:15:38.740 
driver would be intermediary and
the processor would in the end

197
00:15:39.080 --> 00:15:43.180 
move data from memory to the
accelerator in order to foster some

198
00:15:43.390 --> 00:15:50.620 
computation. There's power9, there's CAPI,
there's the idea that there's a direct link

199
00:15:50.840 --> 00:15:57.020 
and we have a cache
coherent view on

200
00:15:57.020 --> 00:16:00.320 
the accelerator or both the CPU
and accelerator have cache

201
00:16:00.320 --> 00:16:01.500 
coherent view in the memory.

202
00:16:02.150 --> 00:16:04.000 
This is a feature
which is being

203
00:16:04.920 --> 00:16:08.760 
taken even further with discussions
and developments in power10, where

204
00:16:09.100 --> 00:16:12.630 
people talk about memory inception
and the idea of using the

205
00:16:12.630 --> 00:16:17.000 
memory on a different computer and putting
it in the same address space, so extending

206
00:16:17.510 --> 00:16:21.880 
the concept of processes
and address spaces

207
00:16:23.520 --> 00:16:27.850 
with the goal of providing
ever higher and ever

208
00:16:27.850 --> 00:16:29.140 
bigger capacities.

209
00:16:32.430 --> 00:16:37.310 
The problem is with distributing data
and distributing computation

210
00:16:37.310 --> 00:16:43.790 
you can build bigger system and basically
harvest more power or more performance

211
00:16:44.110 --> 00:16:47.310 
from the same
computer. However,

212
00:16:48.110 --> 00:16:53.920 
we also have more components to deal
with, components that simply may fail.

213
00:16:54.290 --> 00:16:58.870 
And alone the fact that the
memory increases significantly in

214
00:16:59.240 --> 00:17:03.270 
size that will lead to the
effect that we have more for

215
00:17:03.270 --> 00:17:08.460 
fault classes and less error containment.
So this means nothing but

216
00:17:08.460 --> 00:17:12.380 
the software needs to be aware
of the problems. In traditional

217
00:17:12.380 --> 00:17:15.470 
systems, traditional service
systems often times the firmware

218
00:17:15.470 --> 00:17:21.010 
and the operating system will hide
problems from the applications of it.

219
00:17:21.310 --> 00:17:25.280 
So this is at risk, right?
We we are now at the point

220
00:17:25.550 --> 00:17:30.280 
the failure rates depend on
processor account and where we

221
00:17:30.280 --> 00:17:34.830 
have the situation that not
everything can be hidden beneath

222
00:17:34.840 --> 00:17:41.480 
the safety firmware and that applications often
use to deal with changes in topology,

223
00:17:41.780 --> 00:17:46.550 
with reallocation of memory. This may
be even restart of the questions.

224
00:17:48.150 --> 00:17:52.300 
So observations, the traditional
hardware fault models need an update,

225
00:17:52.810 --> 00:17:58.520 
we have to look at more
pro-active models, the reactive

226
00:17:58.520 --> 00:18:01.500 
fault tolerance gets inappropriate

227
00:18:02.280 --> 00:18:07.390 
and if you have reactive
models it just will not scale.

228
00:18:08.910 --> 00:18:13.050 
Next point virtualization. The
virtualization is a new system

229
00:18:13.050 --> 00:18:17.880 
layer that will be present
whatever the system is.

230
00:18:19.790 --> 00:18:24.550 
This is some, this has been true for
mainframe systems for many years,

231
00:18:24.840 --> 00:18:28.920 
for power systems, systems there are
still options run the system

232
00:18:28.920 --> 00:18:33.190 
basically with little
virtualization but most systems

233
00:18:33.190 --> 00:18:37.090 
run with a virtualization layer as
the basic layer

234
00:18:37.660 --> 00:18:44.510 
and this means basically we
have a new level

235
00:18:44.510 --> 00:18:47.630 
of resource management and a system
that needs to be dealt with.

236
00:18:49.100 --> 00:18:55.990 
And the last point there's little
support for reliability research.

237
00:18:56.330 --> 00:19:02.730 
The systems still work, I would
say too good or they fail

238
00:19:02.910 --> 00:19:08.720 
too seldomly and we need to think
about means like fault injection

239
00:19:08.720 --> 00:19:14.900 
in order to do research
in below OS testing and

240
00:19:15.200 --> 00:19:16.440 
reliability research.

241
00:19:19.990 --> 00:19:24.500 
This is a little advertisement.
If you are interested in that

242
00:19:24.500 --> 00:19:29.100 
kind of researched then there is a, besides
this online course we are talking about,

243
00:19:29.580 --> 00:19:33.920 
the futureSOC lab at HPI.
The futureSOC lab has

244
00:19:33.920 --> 00:19:37.640 
been set up in order to allow for
collaboration with the industry,

245
00:19:38.090 --> 00:19:41.520 
for research on next generation
hardware. We started out with

246
00:19:41.520 --> 00:19:46.740 
the classical intel systems
but nowadays there are many

247
00:19:46.740 --> 00:19:52.040 
systems from INVIDIA, there are ARM based
systems, there are power systems. So

248
00:19:53.490 --> 00:19:56.670 
understanding of new fault
classes, failure prediction,

249
00:19:57.080 --> 00:20:01.720 
virtual machine migration; these are
topics that are being researched

250
00:20:01.720 --> 00:20:05.280 
in the futureSOC lab and with
the lab twice a year we have

251
00:20:05.280 --> 00:20:09.210 
a call for projects and we have the
futureSOC lab day. So something you

252
00:20:09.470 --> 00:20:14.190 
you may want to look at if you would be
interested to work together with us.

253
00:20:15.720 --> 00:20:20.370 
Here is just one example and this is
VM migration based on fault protection,

254
00:20:20.730 --> 00:20:24.980 
a feature that is present in
the high ends of a system.

255
00:20:25.740 --> 00:20:30.170 
In IBM words it's
called power HA,

256
00:20:30.620 --> 00:20:35.830 
in the power system it is called parallel
sysplex in the mainframe. Idea is simple.

257
00:20:36.140 --> 00:20:40.600 
You look at your system,
you do some VM based

258
00:20:41.170 --> 00:20:46.610 
monitoring and you have a
virtualization cluster management and

259
00:20:47.000 --> 00:20:52.810 
if there are problems on one
system or if the load is uneven,

260
00:20:53.130 --> 00:20:59.070 
then you just move a virtual machine
from one system to the other system.

261
00:20:59.550 --> 00:21:04.030 
This is done in an incremental
fashion and the blackout period

262
00:21:04.200 --> 00:21:08.460 
where services are not available,
the blackout period can be

263
00:21:08.550 --> 00:21:12.270 
kept quite small to just
a couple of milliseconds.

264
00:21:13.700 --> 00:21:16.970 
Conclusions: there are many advances
in server technology, the

265
00:21:16.970 --> 00:21:19.000 
number of CPU cores grows

266
00:21:19.660 --> 00:21:23.450 
all the time. We are now looking
at systems with

267
00:21:23.490 --> 00:21:25.160 
tremendous amounts
of memory.

268
00:21:25.880 --> 00:21:28.860 
The non-volatile memory
I mentioned already.

269
00:21:29.390 --> 00:21:35.120 
It's a promising hardware
technology. However the integration

270
00:21:35.120 --> 00:21:39.800 
of the software with the programming
models is not fully

271
00:21:39.800 --> 00:21:40.720 
completed yet.

272
00:21:43.020 --> 00:21:48.750 
If you talk about reliability, then we
would state that this is the most important

273
00:21:48.910 --> 00:21:53.570 
feature or property of a server
system anyway and with the

274
00:21:53.570 --> 00:21:57.990 
high level of integration and
shrinking structure sizes

275
00:21:58.090 --> 00:22:01.630 
we now see the problem that
we need to deal with multi-bit

276
00:22:01.630 --> 00:22:06.080 
errors in future systems and
the suggestion is that we

277
00:22:06.080 --> 00:22:10.720 
will use fault prediction and dynamic
reconfiguration as features to deal with

278
00:22:11.010 --> 00:22:11.940 
this situation.

279
00:22:12.810 --> 00:22:16.760 
And of course you want to have
isolation against fault propagation

280
00:22:17.040 --> 00:22:21.390 
and you can do this in a cluster
context just using blades,

281
00:22:21.610 --> 00:22:26.160 
or you can do this using logical
partitioning like on the power server.

282
00:22:27.920 --> 00:22:31.270 
I mentioned a couple of times that the
programming models need to change

283
00:22:31.410 --> 00:22:35.330 
and future services will require
this new programming model

284
00:22:35.880 --> 00:22:40.010 
like microsoft architectures and
the topic of energy-aware computing.

285
00:22:42.850 --> 00:22:47.530 
To put the entire presentation in one
slide, that would be maybe this one,

286
00:22:47.830 --> 00:22:51.730 
which basically tells that
the computer architecture

287
00:22:52.430 --> 00:22:58.640 
is still moving and moving forward and the
changes in the computer architecture will

288
00:22:58.910 --> 00:23:03.220 
drive change in system software.
This is about the server.

289
00:23:03.890 --> 00:23:07.100 
Servers and the new form factors,
the standard architectures, the

290
00:23:07.100 --> 00:23:10.840 
multi-core/multi-threaded programming.
This is about advances

291
00:23:10.840 --> 00:23:15.960 
in operating systems like the virtualization
and trustworthiness, the security,

292
00:23:16.160 --> 00:23:18.410 
the clustering.

293
00:23:19.190 --> 00:23:25.160 
There are new virtualization problems
also, like the virtualization is just

294
00:23:25.280 --> 00:23:30.020 
presenting an extended attack
surface. You can

295
00:23:30.020 --> 00:23:33.940 
have new kinds of malware like
virtualization based malware and

296
00:23:33.940 --> 00:23:40.500 
whatever your system is, you have to trust
the hypervisor. Somebody manages to

297
00:23:40.910 --> 00:23:45.570 
get into the hypervisor,
then he basically may

298
00:23:45.990 --> 00:23:50.480 
manage to get into the entire
or all workloads

299
00:23:50.480 --> 00:23:51.190 
on the system.

300
00:23:53.660 --> 00:23:59.150 
Of course the defenders try
to address these problems and

301
00:23:59.300 --> 00:24:04.010 
oftentimes there are solutions
but we have seen with Meltdown

302
00:24:04.010 --> 00:24:08.240 
Spectre recently that some
of the solutions may require

303
00:24:08.240 --> 00:24:13.110 
partitioning and may require
procedures by the

304
00:24:13.110 --> 00:24:16.990 
administrator not putting
the different workloads on

305
00:24:16.990 --> 00:24:21.110 
the same server and so forth which has an
impact on the cloud computing as well.

306
00:24:21.780 --> 00:24:22.550 
Cloud computing

307
00:24:23.880 --> 00:24:27.430 
has been made available or
made possible only because

308
00:24:27.830 --> 00:24:33.560 
of standardization in the software market
and many people nowadays think that

309
00:24:33.920 --> 00:24:35.640 
services don't require

310
00:24:36.470 --> 00:24:38.600 
infrastructure at all
because there is the cloud.

311
00:24:39.080 --> 00:24:44.730 
However we have to still,
we have to obstruct

312
00:24:44.730 --> 00:24:46.020 
the very underlying
hardware

313
00:24:46.930 --> 00:24:51.660 
properties. We have to be elastic and we
need to implement a paper use spaces,

314
00:24:51.960 --> 00:24:57.900 
which may or may not be difficult
four the several different cloud

315
00:24:58.420 --> 00:25:02.600 
vendors and offerings. We talked
about new programming models.

316
00:25:02.920 --> 00:25:07.290 
The most important feature or the
most important characteristics

317
00:25:07.710 --> 00:25:13.210 
is the world of hybrid computing.
We all know the CPU but nowadays

318
00:25:13.420 --> 00:25:17.390 
they are basically two big trends, one
trend as introducing accelerators

319
00:25:17.710 --> 00:25:22.570 
like GPU, like FPGA, the other
trend is enhancing the CPU

320
00:25:22.570 --> 00:25:25.030 
by implementing new hardware
features in the CPU

321
00:25:25.430 --> 00:25:31.730 
and we see both features in particular in
the power architecture being addressed.

322
00:25:33.470 --> 00:25:38.880 
At this point in time I want to finish
my introductory presentation and

323
00:25:38.990 --> 00:25:44.010 
wish a good success and
also joy and pleasure

324
00:25:44.410 --> 00:25:49.150 
with our MOOC Future in Computing - on
the road to Quantum Computing.
