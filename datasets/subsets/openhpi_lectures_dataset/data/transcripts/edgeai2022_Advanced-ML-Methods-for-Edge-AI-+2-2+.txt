WEBVTT

1
00:00:00.890 --> 00:00:02.450 
Hello and welcome.

2
00:00:02.459 --> 00:00:07.940 
This video will briefly discuss more intensively developed machine learning methods

3
00:00:07.940 --> 00:00:16.879 
For edgeAI. Moreover, I will also briefly introduce a new research direction that tackles the unknown class problem in the edgeAI

4
00:00:16.879 --> 00:00:17.750 
scenarios.

5
00:00:20.289 --> 00:00:29.890 
In recent years, contrastive learning has received extensive attention in computer vision and NLP domain and the learned

6
00:00:29.890 --> 00:00:37.179 
representation vectors have achieved the state of their art performance on various downstream task.

7
00:00:38.070 --> 00:00:47.189 
We can see that compared to supervised learning methods, contrastive learning can be divided into supervised and self supervised

8
00:00:47.189 --> 00:00:53.429 
categories because self supervised contrastive learning does not rely on label data.

9
00:00:53.439 --> 00:00:56.219 
It is an unsupervised learning method.

10
00:00:56.899 --> 00:01:02.229 
Contrastive methods only need to learn discrimination in the future space.

11
00:01:02.329 --> 00:01:11.379 
Therefore they will not pay too much attention to pixel details but can focus on abstract semantic information.

12
00:01:12.079 --> 00:01:21.519 
It directly uses the data as supervision information to learn feature expressions, making it easier to learn general knowledge

13
00:01:21.530 --> 00:01:24.140 
and suitable for downstream tasks.

14
00:01:26.159 --> 00:01:32.819 
Now, let's take a look at the general paradigm of contrastive learning. For any data x

15
00:01:32.829 --> 00:01:44.560 
So for any data x the objective of contrastive learning is to learn an encoder f gives that the similarity score of f(x) and

16
00:01:44.560 --> 00:01:53.049 
f(x+) are much larger than the same score of f(x) and f(x-)

17
00:01:53.049 --> 00:01:56.390 
where x+ and x-

18
00:01:56.390 --> 00:02:05.670 
denote the positive and negative examples relatively. And the sinscore is the measurement function measures the similarity

19
00:02:05.670 --> 00:02:06.810 
between examples.

20
00:02:06.819 --> 00:02:09.610 
So, positive means similar examples.

21
00:02:10.439 --> 00:02:19.300 
If the vector in inner product is used to calculate the similarity measurement and similarity of two samples and the loss

22
00:02:19.300 --> 00:02:29.460 
function of contrasting learning can be expressed as following. And in the formula, the corresponding example x has one positive

23
00:02:29.460 --> 00:02:33.469 
example and n-1 negative examples.

24
00:02:33.479 --> 00:02:38.909 
We can find that this form is similar to the cross entropy loss function.

25
00:02:39.800 --> 00:02:48.840 
The goal of learning is to make the feature of x more similar to the feature of positive examples and meanwhile less similar

26
00:02:48.840 --> 00:02:50.319 
to the negative ones.

27
00:02:51.090 --> 00:02:54.039 
This loss function is called InfoNCE

28
00:02:54.039 --> 00:02:59.039 
loss in the related literature of contrastive learning.

29
00:03:00.689 --> 00:03:08.150 
Other works called this loss function multi class n-pair loss or ranking based NCE loss.

30
00:03:09.449 --> 00:03:18.349 
But this loss function has become a commonly used the loss function in the contrasting learning community. As an example of

31
00:03:18.349 --> 00:03:27.750 
supervised contrastive learning Google proposed FaceNet in 2015 to solve the problem of large scale face verification problem.

32
00:03:28.319 --> 00:03:33.050 
Since the problem emphasizes this massive object identification,

33
00:03:33.060 --> 00:03:39.569 
learning the difference between fase samples or metrics is more efficient.

34
00:03:40.280 --> 00:03:48.550 
The network consists of a bunch of input layers and a deep convolutional neural network followed by L2 normalization layer

35
00:03:48.560 --> 00:03:59.259 
which results in the face embedding. Basically we will map the input examples into the learned embedding space, then calculate

36
00:03:59.259 --> 00:04:01.800 
the distance between sample pairs.

37
00:04:01.810 --> 00:04:05.689 
This is followed by a triplet loss during the training.

38
00:04:06.819 --> 00:04:16.379 
Its definition is to minimize the distance between anchor points and the positive examples with the same identity and enlarge

39
00:04:16.389 --> 00:04:23.069 
the distance between anchor points and the negative examples with different identities. At the same time,

40
00:04:23.079 --> 00:04:32.540 
to prevent the features of sample from converging into a very small space, the author introduce a minimum margin value

41
00:04:32.540 --> 00:04:36.490 
alpha between a negative examples and a positive one.

42
00:04:36.819 --> 00:04:45.300 
We can see that in this example, all data is labeled. Therefore it belongs to supervise contrasted learning.

43
00:04:45.310 --> 00:04:56.120 
In addition, the optimization goal is actually to learn the Euclidean distance differences between positive and negative

44
00:04:56.120 --> 00:04:58.540 
examples in the embedding space.

45
00:05:00.920 --> 00:05:11.470 
Next we introduce a self supervised contrasted learning some example and this method called simCLR. The work is also from google

46
00:05:11.470 --> 00:05:12.399 
researchers.

47
00:05:12.410 --> 00:05:22.810 
Its idea is very simple. Visual representation should be in variant to inputs from different perspectives of the same target.

48
00:05:23.720 --> 00:05:33.110 
This architecture consists of two identical network modules. For each meeting batch input to the network,

49
00:05:33.120 --> 00:05:43.089 
it performs two random data augmentation like random cropping, color filtering, grayscale etcetera. On each input picture

50
00:05:43.100 --> 00:05:48.129 
in the mini batch to obtain two different perspectives of the image.

51
00:05:48.680 --> 00:05:58.089 
Then they send the obtained tool representations to two convolutional encoders to obtain abstract representations and then

52
00:05:58.089 --> 00:06:03.009 
apply the nonlinear transformations to obtain the projection representations.

53
00:06:03.019 --> 00:06:10.579 
Finally, it used the cosine metrics to measure the similarity between the two projections.

54
00:06:11.500 --> 00:06:20.800 
So the contrastive loss is used to maximize the similarity of the same object under the different perspectives and

55
00:06:20.800 --> 00:06:25.329 
minimize the similarity between the different objects.

56
00:06:28.100 --> 00:06:36.550 
The convolution and fully connect layers are trained simultaneously to yield a projection that are similar to augmented

57
00:06:36.550 --> 00:06:41.810 
version of the same image while being dissimilar for different images.

58
00:06:41.819 --> 00:06:50.819 
Even if those images are out of the same class of objects we see that seems there are methods

59
00:06:50.829 --> 00:06:59.410 
its performance is close to fully supervised method and outperforming all the previous unsupervised methods with a large

60
00:06:59.410 --> 00:07:02.310 
margin which is pretty impressive.

61
00:07:02.550 --> 00:07:15.649 
And one possible disadvantage of this method is that it relies on 128 GPUs for the training and a large batch size of 8182

62
00:07:15.660 --> 00:07:17.639 
for building their models.

63
00:07:17.649 --> 00:07:24.680 
So it's definitely difficult for the standard research lab to achieving this hardware.

64
00:07:26.189 --> 00:07:32.199 
So few shot learning is of great significance and challenge in machine learning.

65
00:07:32.209 --> 00:07:41.779 
Whether it can learn and generalize from a small number of samples is a clear dividing point between artificial intelligence

66
00:07:41.790 --> 00:07:51.639 
and human intelligence because humans can quickly build awareness of new objects through a few samples. At the same time,

67
00:07:51.670 --> 00:07:59.560 
machine learning algorithms serially require thousands of supervised samples to construct the generalization ability.

68
00:08:00.970 --> 00:08:03.899 
Given a task T specific dataset

69
00:08:03.899 --> 00:08:13.100 
DT containing a small amount of supervised information and the supporting data set DA unrelated to T

70
00:08:13.110 --> 00:08:14.170 
Where DA

71
00:08:14.170 --> 00:08:17.949 
does not contain any categories in the task T.

72
00:08:19.550 --> 00:08:24.519 
Few shot learning aims to construct a function F for the task T.

73
00:08:24.529 --> 00:08:30.310 
The task completion utilize the little supervision information of DT

74
00:08:30.319 --> 00:08:32.279 
and the knowledge in the DA

75
00:08:32.279 --> 00:08:34.830 
to map the input to the target domain.

76
00:08:34.840 --> 00:08:41.080 
In short the core target it should learn the degree of similarity of objects.

77
00:08:43.049 --> 00:08:45.460 
Let's take a look at the example.

78
00:08:45.639 --> 00:08:47.929 
Given the training dataset DT

79
00:08:47.929 --> 00:08:51.070 
with five classes,

80
00:08:51.070 --> 00:09:00.210 
there are a number of label samples for each class and there is a supervised training set. Here

81
00:09:00.210 --> 00:09:04.090 
we can also use the metrics learning method triplet loss

82
00:09:04.100 --> 00:09:13.929 
to train a neural network model with an embedding layer, we can create triple impulse an anchor for example, a tiger image

83
00:09:13.929 --> 00:09:17.320 
a positive example and another tiger image.

84
00:09:17.330 --> 00:09:20.990 
And with a different view.

85
00:09:21.000 --> 00:09:23.769 
A negative example is a picture of an elephant.

86
00:09:24.610 --> 00:09:33.570 
We then train the deep network and then embedding layer in the embedding space we attract the distance of positive pairs

87
00:09:33.580 --> 00:09:36.549 
and ripple between negative pairs.

88
00:09:37.090 --> 00:09:45.659 
So after training, the model is able to predict the distance of two individual objects

89
00:09:45.659 --> 00:09:46.830 
for testing.

90
00:09:46.840 --> 00:09:48.690 
We will have support set DA

91
00:09:48.690 --> 00:09:49.210 


92
00:09:49.220 --> 00:09:50.960 
And the category of DA

93
00:09:50.960 --> 00:09:51.259 


94
00:09:51.269 --> 00:09:53.940 
are all different from the classes

95
00:09:53.950 --> 00:09:56.480 
from the training set DT

96
00:09:56.480 --> 00:09:57.210 


97
00:09:57.220 --> 00:10:07.559 
In this example we have a six way one shot support set six way means that means six new classes and one shot

98
00:10:07.559 --> 00:10:11.220 
means one supporting image is available for each class.

99
00:10:11.720 --> 00:10:13.419 
For a query image,

100
00:10:13.429 --> 00:10:22.450 
we will use the trained model to predict the distance or the similarity of the query and the images from the support set.

101
00:10:23.620 --> 00:10:30.669 
The class with the lowest distance is our prediction result. In this example, it is a squirrel.

102
00:10:34.529 --> 00:10:43.759 
Most of the methods we discussed before we have a strong assumption that the sample classes of the dataset use are unknown.

103
00:10:43.769 --> 00:10:48.629 
We only consider if the examples were label or not.

104
00:10:48.639 --> 00:10:57.840 
But in real world applications especially in the edgeAI scenarios, they're often unknown data categories that is unknown

105
00:10:57.840 --> 00:11:04.080 
task. In this case the non set based machine learning methods do not work.

106
00:11:05.639 --> 00:11:15.320 
Therefore open set recognition is according edge research direction In the recent academia community, the definition of open

107
00:11:15.320 --> 00:11:20.379 
set here is that the category of the given examples are unknown.

108
00:11:20.389 --> 00:11:24.639 
This research direction is divided into two subfields.

109
00:11:24.649 --> 00:11:35.409 
One is to identify the unknown categories as noise and isolate related examples to prevent them from harming

110
00:11:35.409 --> 00:11:37.419 
the known set based model.

111
00:11:38.179 --> 00:11:42.909 
The other is a more challenging task novel class discovery.

112
00:11:43.679 --> 00:11:53.309 
It will discover the unknown class, explore the semantic connection to the known classes and then develop into a new class.

113
00:11:53.980 --> 00:11:54.769 


114
00:11:54.779 --> 00:12:03.309 
In other words, the current research topic is how to utilize the knowledge learned from the non set to handle open set.

115
00:12:04.129 --> 00:12:13.090 
This direction is being researched by academia and related techniques come from knowledge transfer, unsupervised learning,

116
00:12:13.100 --> 00:12:16.789 
matrix learning, contrastive learning and so on.

117
00:12:17.360 --> 00:12:21.340 
We already briefly talked about it in the previous videos.

118
00:12:22.659 --> 00:12:30.179 
We look forward to the research result in this field because solving the data problem in the edge AI scenario is of great

119
00:12:30.179 --> 00:12:31.210 
significance.

120
00:12:33.960 --> 00:12:35.070 
Thank you for watching
