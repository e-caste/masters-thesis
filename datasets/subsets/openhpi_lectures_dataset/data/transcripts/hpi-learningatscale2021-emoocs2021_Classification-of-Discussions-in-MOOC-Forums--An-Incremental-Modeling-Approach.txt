WEBVTT

1
00:00:00.000 --> 00:00:03.500 
hello my name is anastasios. and i will present you

2
00:00:03.500 --> 00:00:08.390 
the study classification of discussions in MOOC forms
an incremental modeling approach

3
00:00:08.810 --> 00:00:11.480 
which was performed via the collaboration of university of

4
00:00:11.500 --> 00:00:13.360 
patras with university of adelaide.

5
00:00:14.300 --> 00:00:17.380 
in massive open online courses or MOOCs for a certain

6
00:00:17.870 --> 00:00:21.810 
the diverse learner backgrounds. and the scale of
participation in the form

7
00:00:21.930 --> 00:00:25.680 
has shown that it can affect negatively the support
that is provided to learners

8
00:00:26.000 --> 00:00:31.030 
by the facilitators.
this is referred to the literature as a bandwidth problem.

9
00:00:31.190 --> 00:00:33.920 
one of the main approaches that has been followed in order

10
00:00:33.920 --> 00:00:37.760 
to address this issue is automatic classification of form discussions.

11
00:00:38.260 --> 00:00:41.710 
the goal of this approach is to draw the attention of facilitators

12
00:00:41.870 --> 00:00:43.950 
to posts that require their intervention.

13
00:00:44.410 --> 00:00:48.750 
this task requires the training and development of classification models.

14
00:00:49.300 --> 00:00:52.660 
one common approach is supervised modelling where models are

15
00:00:52.670 --> 00:00:56.170 
trained with a set of data that are manually labelled by human

16
00:00:56.170 --> 00:00:58.290 
coders into specific categories.

17
00:00:58.960 --> 00:01:02.210 
the drinking approach though is considered to be an expensive

18
00:01:02.210 --> 00:01:07.050 
and time consuming process in addressing this issue semi-supervised

19
00:01:07.050 --> 00:01:10.420 
techniques selective learning have provided promising insights,

20
00:01:10.610 --> 00:01:13.890 
while unsupervised techniques like topic modeling have shown

21
00:01:14.140 --> 00:01:17.570 
that they can reduce the human workload needed for the training states.

22
00:01:17.740 --> 00:01:20.780 
but they do not always provide the desirable results.

23
00:01:21.590 --> 00:01:25.950 
a promising approach that has been followed is
the incremental training of models

24
00:01:26.060 --> 00:01:30.480 
with data that are progressively reached as the
course progresses over time.

25
00:01:30.920 --> 00:01:34.790 
this approach though known as temporal modeling has been mainly

26
00:01:34.790 --> 00:01:38.290 
performed on dropout prediction problems. and it is worth exploring

27
00:01:38.290 --> 00:01:42.840 
if it could be applied on form discussion classification tasks.

28
00:01:43.490 --> 00:01:46.650 
therefore there is a need for methods that could help reduce the human

29
00:01:46.650 --> 00:01:50.990 
workload required for the preparation of
training data sets in this context.

30
00:01:51.720 --> 00:01:55.450 
in this study we address this problem by following a novel

31
00:01:55.450 --> 00:01:59.810 
approach in training supervised models via an incremental
modeling method.

32
00:02:00.460 --> 00:02:03.750 
the classification problem that we're them to solve is to classify

33
00:02:03.750 --> 00:02:06.100 
discussions in one of the following categories.

34
00:02:06.840 --> 00:02:10.770 
those related to the course content those related
to the course logistics

35
00:02:11.440 --> 00:02:14.390 
discussions where no action is required by the facilitator.

36
00:02:15.580 --> 00:02:18.710 
the study was applied on three moocs of different subject matter

37
00:02:19.000 --> 00:02:21.690 
which were offered on the math greek movie platform.

38
00:02:22.270 --> 00:02:25.600 
the first course was introduction to python the second was

39
00:02:25.610 --> 00:02:28.850 
internet of things in action. and the third was world history

40
00:02:28.850 --> 00:02:33.250 
of religion man versus divine the way that we develop the models

41
00:02:33.330 --> 00:02:36.580 
was to train them at the specific week of the course with data

42
00:02:36.580 --> 00:02:40.360 
derived from all the previous ones. then we evaluated the models

43
00:02:40.370 --> 00:02:43.640 
on the remaining discussions till the end of the respective course.

44
00:02:44.310 --> 00:02:48.720 
the base training features that were employed
were the regular tf idea features.

45
00:02:49.050 --> 00:02:52.970 
the main problem with such features in our case is that especially

46
00:02:52.970 --> 00:02:57.300 
at the beginning of the course they would be limited.
to tackle this issue,

47
00:02:57.540 --> 00:03:02.610 
we used two additional supportive features
derived from a city topic modeling approach.

48
00:03:03.170 --> 00:03:06.360 
these features were the prediction probabilities from the model

49
00:03:06.700 --> 00:03:11.100 
and the semantic similarities with the linguistic
content of the derived topics.

50
00:03:11.760 --> 00:03:15.710 
see the topic modelling uses a technological set of seats in

51
00:03:15.710 --> 00:03:19.810 
order to bias the topics with respect to a relevant domain knowledge.

52
00:03:20.580 --> 00:03:23.580 
in our case we created three lexical sets.

53
00:03:24.080 --> 00:03:27.480 
each one corresponding to a given category for classification problem.

54
00:03:27.990 --> 00:03:30.920 
for the content related category we use the video transcripts

55
00:03:30.940 --> 00:03:34.150 
and text documents found in the environment of each mooc,

56
00:03:34.150 --> 00:03:37.510 
and for the other two categories we used two additional mixed data sets

57
00:03:37.730 --> 00:03:40.000 
as sources for the respective categories.

58
00:03:40.640 --> 00:03:43.610 
therefore the first research question that we explore

59
00:03:44.250 --> 00:03:48.120 
is if we can build a supervised model via an incremental modeling approach

60
00:03:48.350 --> 00:03:51.730 
that can effectively classify posts to their appropriate categories?

61
00:03:52.530 --> 00:03:57.690 
while the second research question explores if the supportive items cannot perform

62
00:03:57.820 --> 00:04:01.890 
the best ninety-five day features in terms of classification performance

63
00:04:02.560 --> 00:04:06.160 
within our methodology two coders manually labeled all the

64
00:04:06.160 --> 00:04:08.910 
form discussions with regards to our three categories.

65
00:04:09.430 --> 00:04:12.640 
video lecture transcripts logistic documents and the supportive

66
00:04:12.640 --> 00:04:15.640 
courses were used to extract the lexical seats.

67
00:04:16.100 --> 00:04:20.590 
then by using the lexical seats we performed the siddiq
topic modeling approach

68
00:04:20.770 --> 00:04:24.490 
and won specifically the uncut correlation explanation method

69
00:04:24.670 --> 00:04:28.870 
which led to the extraction of the two aforementioned
supportive features.

70
00:04:29.380 --> 00:04:32.530 
and finally we trained a decision tree classifier.

71
00:04:33.590 --> 00:04:36.900 
moving on to the results section for the first research question,

72
00:04:36.900 --> 00:04:39.950 
it was found that the cortex features could support the building

73
00:04:39.950 --> 00:04:44.380 
of a substantial classifier in terms of overall accuracy approximately

74
00:04:44.480 --> 00:04:49.490 
in the third week for all the courses.
for the world history and python courses

75
00:04:50.160 --> 00:04:53.490 
the performance of the models started from moderate results

76
00:04:53.700 --> 00:04:57.660 
well for the ot course the performance was poor. due to the

77
00:04:57.820 --> 00:05:01.860 
small number of discussions accumulated in the first two weeks of the course.

78
00:05:02.590 --> 00:05:06.770 
the results revealed that all models had mixed miss classifications

79
00:05:06.810 --> 00:05:09.990 
in predicting content related and logistics related posts.

80
00:05:10.570 --> 00:05:13.370 
by inspecting the misclassified documents,
it was found that

81
00:05:13.370 --> 00:05:16.830 
some logistics related posts contained terms that are also

82
00:05:16.830 --> 00:05:20.320 
found in the corresponding courses terminology which led to

83
00:05:20.320 --> 00:05:23.640 
several miss classifications.
for the second research question.

84
00:05:23.700 --> 00:05:26.590 
the comparison of the proposed modelling approach with the

85
00:05:26.590 --> 00:05:31.490 
baseline t five f approach showed that the supportive
features that were employed

86
00:05:31.710 --> 00:05:35.260 
boosted further the decision tree classifier performance to

87
00:05:35.260 --> 00:05:38.820 
make more reliable predictions during the run of its course.

88
00:05:39.360 --> 00:05:43.550 
specifically it was found that in almost every week of for all courses,

89
00:05:43.760 --> 00:05:46.660 
our proposed approach scored a higher performance

90
00:05:47.220 --> 00:05:48.780 
than the regular t five idea.

91
00:05:50.080 --> 00:05:53.620 
moving on to the conclusions of this study we found that the

92
00:05:53.620 --> 00:05:56.140 
cortex features could support the building of a substantial

93
00:05:56.140 --> 00:05:58.280 
classifier in terms of overall accuracy.

94
00:05:58.930 --> 00:06:01.940 
the evaluation metrics provided evidence about the week in

95
00:06:01.940 --> 00:06:05.190 
which the model could be possibly employed. and according to

96
00:06:05.190 --> 00:06:08.320 
the main issue that we address by narrowing down the leveling

97
00:06:08.320 --> 00:06:12.870 
process in the first two to three weeks. i live with substantially,

98
00:06:13.010 --> 00:06:16.970 
the human effort needed for the training of a reliable supervised model.

99
00:06:17.310 --> 00:06:21.520 
moreover it was found that the supportive features led to a model that

100
00:06:21.670 --> 00:06:25.190 
performed the baseline idea of approach. and that they were

101
00:06:25.190 --> 00:06:28.620 
boosting the base idea of the features towards more precise predictions

102
00:06:28.620 --> 00:06:30.150 
quite early in the course.

103
00:06:30.760 --> 00:06:33.570 
the results also highlighted the benefits of using data that

104
00:06:33.570 --> 00:06:35.750 
exist within the mco online environment.

105
00:06:36.220 --> 00:06:39.180 
for our future research we plan on further investigating

106
00:06:39.630 --> 00:06:43.510 
classifications between the content related to logistics related posts

107
00:06:43.620 --> 00:06:47.430 
and to validator methodology in new courses with higher participation

108
00:06:47.530 --> 00:06:51.190 
and of different subject matters. moreover we plan on experimenting

109
00:06:51.190 --> 00:06:53.770 
with more additional features that would provide a further

110
00:06:53.770 --> 00:06:57.430 
boost in the performance of our modern like sentiments course.

111
00:06:57.800 --> 00:06:59.050 
thank you and goodbye.
