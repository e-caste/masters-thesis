WEBVTT

1
00:00:00.890 --> 00:00:08.120 
Hello. My name is Bruno Mesnet. I'm working in
IBM and working on hardware acceleration enablement.

2
00:00:08.590 --> 00:00:13.400 
So, I wanted to show you
how by combining some different technologies

3
00:00:13.400 --> 00:00:18.320 
like POWER CAPI, SNAP and FPGA,
we can have great results.

4
00:00:18.730 --> 00:00:21.070 
And this will help
you to accelerate

5
00:00:21.770 --> 00:00:25.730 
your routines or your programs by
a very very big factor.

6
00:00:26.340 --> 00:00:32.730 
So, let's go to the topic we
have built a rocket and we now

7
00:00:33.340 --> 00:00:38.030 
need a driver and this can
be you. There's nothing really special

8
00:00:38.040 --> 00:00:42.290 
to know or to have. You
just need to know C or C++

9
00:00:43.550 --> 00:00:49.670 
and have a few hours to start on
that and we find a way to

10
00:00:49.670 --> 00:00:50.900 
to provide you
an environment

11
00:00:51.580 --> 00:00:53.360 
where everything is built
for a very

12
00:00:53.960 --> 00:00:57.060 
low price, a few
cents per hour.

13
00:00:58.450 --> 00:01:01.440 
So let's start and understand on what and

14
00:01:02.160 --> 00:01:06.610 
how we can accelerate things. So just
imagine that you have a function

15
00:01:06.970 --> 00:01:12.990 
which is executed in a CPU, that's
the software classic way of doing things

16
00:01:13.420 --> 00:01:17.710 
and you want to accelerate this
function or even just offload it.

17
00:01:18.210 --> 00:01:22.250 
So you will have
an accelerator code

18
00:01:22.750 --> 00:01:29.670 
and this function will receive the data
and the execution program by the CPU

19
00:01:30.190 --> 00:01:32.300 
but everything will be
executed on this

20
00:01:32.820 --> 00:01:35.140 
on this accelerator card.

21
00:01:36.430 --> 00:01:40.780 
The other thing, the other way to
see things is to get the data

22
00:01:40.990 --> 00:01:43.720 
or to send the data
outside through this card

23
00:01:44.340 --> 00:01:48.930 
and this can be done
with cards like FPGA and

24
00:01:50.350 --> 00:01:54.590 
this is something that can go
directly to your network or directly

25
00:01:54.590 --> 00:01:58.870 
to your storage, to your disk
and just imagine that all the

26
00:01:58.870 --> 00:02:01.310 
data can flow
from the storage

27
00:02:01.920 --> 00:02:06.860 
to your CPU with the compression on
the compression, or encryption on the

28
00:02:07.670 --> 00:02:13.510 
decryption on that. So,
now two options to

29
00:02:14.070 --> 00:02:19.120 
do these two different
accelerator - you have two options,

30
00:02:19.290 --> 00:02:22.790 
the one is the most well
known thing is the GPU. The

31
00:02:23.590 --> 00:02:26.830 
GPU is thousands of
CPU using a

32
00:02:28.090 --> 00:02:32.730 
high prioritization, so that's perfect for
an image where you can

33
00:02:33.310 --> 00:02:36.650 
compute everything, you
need per pixel.

34
00:02:38.230 --> 00:02:42.100 
The second option is
the old

35
00:02:42.990 --> 00:02:46.040 
old fashioned FPGA, I would
say but which has been

36
00:02:46.990 --> 00:02:51.410 
resurrected. FPGA is
very different

37
00:02:52.880 --> 00:02:56.000 
in the way that you
are building the logic

38
00:02:57.920 --> 00:03:00.550 
depending on your

39
00:03:01.240 --> 00:03:05.890 
program. So you will have no
processor in it, no operating system

40
00:03:06.070 --> 00:03:10.300 
but all the logic which will
be connected together, will be

41
00:03:10.300 --> 00:03:12.970 
just for your program and you
can paralyze things a lot.

42
00:03:13.580 --> 00:03:15.100 
If you have a look to the

43
00:03:16.230 --> 00:03:19.220 
card, you have connectors
on the left

44
00:03:20.420 --> 00:03:25.010 
and even on the right also. So on the
left this means that you can connect ethernet

45
00:03:26.010 --> 00:03:29.440 
connectors to go to your
storage or your network.

46
00:03:31.640 --> 00:03:35.990 
Just imagine that this card for example
you can have four characters, so

47
00:03:36.310 --> 00:03:40.740 
up to fifty gigabyte
per second data entering,

48
00:03:41.170 --> 00:03:43.250 
computed on the black

49
00:03:43.860 --> 00:03:47.950 
box in the middle which is
the FPGA and then going out

50
00:03:48.290 --> 00:03:51.010 
through connectors on the
right. And all this

51
00:03:51.800 --> 00:03:53.030 
enables to have a

52
00:03:55.420 --> 00:03:57.170 
on the fly execution.

53
00:03:58.390 --> 00:04:03.840 
So two different accelerator cards, one on the
on the left which is very fast

54
00:04:04.400 --> 00:04:09.850 
but the other one on the right which
is the FPGA is not fast but

55
00:04:09.940 --> 00:04:13.140 
is doing a real time and this
is really something which is different.

56
00:04:15.380 --> 00:04:18.580 
Okay, so just to understand what
we can do with these cards

57
00:04:18.580 --> 00:04:23.250 
and when we can use them.
Just imagine that you have an

58
00:04:23.820 --> 00:04:25.750 
encoding of a video.

59
00:04:27.190 --> 00:04:30.720 
This is something that can be done
on the fly and we can use

60
00:04:30.720 --> 00:04:36.440 
FPGA with this very
efficient computer capabilities.

61
00:04:36.920 --> 00:04:39.990 
This is something for which

62
00:04:40.660 --> 00:04:44.760 
CPU will have big problems to do
because we need more and more

63
00:04:44.760 --> 00:04:48.980 
resource to do that. Other cases
where you can find FPGA

64
00:04:49.410 --> 00:04:54.270 
is well, if you want to put
some real time processing in between

65
00:04:54.270 --> 00:04:56.630 
the CPU and the DRAM

66
00:04:57.430 --> 00:05:00.200 
just imagine that you add
compression of the compression you

67
00:05:00.200 --> 00:05:02.030 
will be able
to have more

68
00:05:02.920 --> 00:05:04.550 
more data in less space.

69
00:05:06.510 --> 00:05:10.990 
So, earning money behind that. The third
case we are working also

70
00:05:10.990 --> 00:05:13.410 
on is if you want
to do compute only,

71
00:05:14.870 --> 00:05:19.080 
like a bitcoin or
SHA3 encryption keys

72
00:05:19.670 --> 00:05:24.160 
and we will see here that we have
been able to do a buy thirty five

73
00:05:24.500 --> 00:05:26.700 
versus competing
to a CPU.

74
00:05:28.380 --> 00:05:32.440 
So let's go a bit further and
try to understand you have plenty

75
00:05:32.440 --> 00:05:35.110 
of other use case it's not
limited to these three ones.

76
00:05:35.970 --> 00:05:39.430 
I will not go through all of
these but these are examples that

77
00:05:40.330 --> 00:05:45.090 
you can take maybe in one of these
case, so it's going to be string

78
00:05:45.270 --> 00:05:50.470 
matching or compression or,
well, anything you want to do

79
00:05:50.830 --> 00:05:52.530 
can can be done
with these things.

80
00:05:54.060 --> 00:05:56.580 
So, let's go and
understand how things are

81
00:05:57.070 --> 00:06:01.040 
working today and what we are
bringing with CAPI. And I will

82
00:06:01.040 --> 00:06:02.670 
come back on
what CAPI means.

83
00:06:03.660 --> 00:06:05.920 
So, just imagine that
you have two tables

84
00:06:06.700 --> 00:06:09.640 
hich are
one terabyte each.

85
00:06:10.420 --> 00:06:15.860 
You want to work on them and get
the common elements of these two tables.

86
00:06:16.380 --> 00:06:19.530 
So one table will
be in the host memory

87
00:06:20.230 --> 00:06:25.150 
and the second one will be somewhere
in the network in your disk.

88
00:06:25.510 --> 00:06:28.110 
So if you want to
compute that, you have

89
00:06:29.270 --> 00:06:33.350 
an application which will
call this intersection function

90
00:06:33.930 --> 00:06:38.330 
and which function will pull the
data from the host memory.

91
00:06:38.330 --> 00:06:41.290 
That's quite easy because it has
a direct access to that,

92
00:06:42.020 --> 00:06:45.480 
but he has to pull the
data from the storage and

93
00:06:46.290 --> 00:06:49.570 
this may take time and
this may take resource,

94
00:06:50.090 --> 00:06:52.890 
and just to let
you have an idea

95
00:06:53.730 --> 00:06:59.480 
one terabyte just from a
disk to the host memory

96
00:06:59.910 --> 00:07:03.080 
will take something like
twenty seconds. So, just

97
00:07:03.700 --> 00:07:07.760 
don't think about just accelerating
a function but see the

98
00:07:07.760 --> 00:07:13.010 
whole picture - where your data is located and
this is, I think, a very very

99
00:07:13.330 --> 00:07:15.590 
important point in
an acceleration.

100
00:07:16.550 --> 00:07:23.290 
So, now that you have done that, we
say okay, just put like all classic things

101
00:07:23.760 --> 00:07:28.410 
just pull the FPGA card, this
FPGA card will receive your function,

102
00:07:28.410 --> 00:07:32.380 
will compute your function and all the
function will be able to get

103
00:07:32.750 --> 00:07:36.730 
directly to the storage or
to the network without any

104
00:07:37.890 --> 00:07:39.910 
without taking any
network crystals.

105
00:07:40.810 --> 00:07:45.680 
Well that's good, that's a good point.
You will free some tools. The

106
00:07:45.870 --> 00:07:50.450 
pain point on this is that you
need a driver and this driver

107
00:07:50.450 --> 00:07:53.870 
will be executed on this for you,
meaning that it will take some

108
00:07:54.210 --> 00:07:55.760 
time. It will also

109
00:07:57.120 --> 00:08:02.510 
copy the data from the host
memory to his driver location and

110
00:08:02.510 --> 00:08:05.610 
from this driver memory location

111
00:08:06.050 --> 00:08:09.660 
to the function. So the
data copies you are

112
00:08:10.390 --> 00:08:16.230 
spending wasting memory on
that and you are

113
00:08:16.650 --> 00:08:18.570 
losing the coherency
of the data.

114
00:08:19.700 --> 00:08:23.630 
So, that's a solution but
that's not a good solution and

115
00:08:24.180 --> 00:08:29.120 
so IBM worked on that and tried to
find a way to do things in a

116
00:08:29.500 --> 00:08:32.340 
more smart way and so

117
00:08:33.240 --> 00:08:36.810 
IBM tried to put
what we call the

118
00:08:38.350 --> 00:08:43.970 
CAPI proxy or CAPI is short for
Current Accelerator Processor Interface meaning

119
00:08:45.630 --> 00:08:48.710 
in a nutshell that we
have put the driver

120
00:08:49.700 --> 00:08:54.640 
in the CPU chip and
this is a hardware driver.

121
00:08:55.080 --> 00:08:58.820 
So, what does it bring? It
brings a lot of things.

122
00:08:59.570 --> 00:09:05.790 
The first thing is the card is now
master. It doesn't need any driver.

123
00:09:07.040 --> 00:09:09.060 
The card is able to
go and fetch the

124
00:09:09.700 --> 00:09:13.440 
data directly in host memory and
not all the data but

125
00:09:13.520 --> 00:09:17.610 
only the data he needs.
So we're not transferring everything

126
00:09:17.670 --> 00:09:18.770 
if we just
need a little.

127
00:09:20.090 --> 00:09:25.340 
The second point is that a very interesting
thing if you have in the application

128
00:09:25.870 --> 00:09:27.500 
an address one thousand, the

129
00:09:29.300 --> 00:09:34.670 
function in the GPGA will be able to know
when to use the same address one thousand.

130
00:09:35.350 --> 00:09:40.260 
So this means that the host memory
is just becoming a shared memory

131
00:09:40.660 --> 00:09:44.220 
and we're not using any more CPU.
So that's a good thing because

132
00:09:44.220 --> 00:09:48.040 
we are freeing some resource,
networking resource from the FPGA

133
00:09:48.300 --> 00:09:51.920 
direct access to the storage,
we're freeing the

134
00:09:54.390 --> 00:10:00.610 
host memory due to the driver
and we are freeing also resource

135
00:10:01.910 --> 00:10:04.050 
by removing this driver
from the CPU.

136
00:10:06.130 --> 00:10:11.330 
The good thing is a evolution
of CAPI will bring much smaller

137
00:10:11.330 --> 00:10:15.220 
latency. And we will come back
on that, very high bandwidth and

138
00:10:15.220 --> 00:10:19.740 
also we keep the very good
thing that CAPI had is

139
00:10:20.190 --> 00:10:24.870 
we are card manufacturer independent, meaning
that you can come with your

140
00:10:25.040 --> 00:10:29.450 
FPGA card provider and enable
it for your use.

141
00:10:32.050 --> 00:10:36.320 
Okay, so now let's
talk about bandwith or performance.

142
00:10:37.910 --> 00:10:42.240 
We have we are already at the
second generation of processor with CAPI.

143
00:10:42.500 --> 00:10:45.160 
The first one was what
we call the Power8

144
00:10:45.570 --> 00:10:48.520 
which is CAPI 1.0.
This was just for a try.

145
00:10:49.790 --> 00:10:53.310 
So we had bad
latency, bad bandwidth but

146
00:10:53.770 --> 00:10:57.890 
this was just to understand what we could
do with that because it was very

147
00:10:58.230 --> 00:11:03.260 
new and the second thing is we
have identified where were the

148
00:11:03.480 --> 00:11:08.670 
bottlenecks and we have been able to sort
of all that. So, now Power9

149
00:11:10.850 --> 00:11:15.100 
we have two things. The first one is
CAPI 2.0, which is just

150
00:11:15.390 --> 00:11:20.770 
an evolution of the CAPI 1.0.
Everything goes through the

151
00:11:21.050 --> 00:11:26.020 
PCIexpress all the data go through the
PCIexpress and we are having today

152
00:11:27.210 --> 00:11:33.190 
using gen four by eight or three by sixteen
and we are having quite good results

153
00:11:33.430 --> 00:11:38.440 
meaning that on a sixteen gigabit per
second link, we are able to have

154
00:11:39.660 --> 00:11:42.440 
almost fourteen gigabytes
per second.

155
00:11:43.250 --> 00:11:45.350 
So that's the
the good thing,

156
00:11:46.010 --> 00:11:49.600 
it is what we call
the standard PCI express and

157
00:11:50.810 --> 00:11:54.240 
the second thing we are having on
Power9 is what we call

158
00:11:54.240 --> 00:11:57.430 
CAPI 3.0 or
open CAPI now.

159
00:11:58.250 --> 00:12:03.080 
It uses the same

160
00:12:03.690 --> 00:12:08.460 
CAPI mechanism but we are
using a new link which is

161
00:12:08.460 --> 00:12:12.610 
not the PCI express but what we
call the openCAPI link which is

162
00:12:12.720 --> 00:12:15.600 
the CAPI you see plugged
in the second code

163
00:12:16.290 --> 00:12:22.540 
and by removing, by creating this
new link we have removed all

164
00:12:22.540 --> 00:12:28.360 
the PCI express overhead and we are
able now to have very very

165
00:12:28.360 --> 00:12:31.520 
low latency. And this is I
think a very good point because

166
00:12:32.680 --> 00:12:38.900 
this is what people who worked in
a very tight environment need to

167
00:12:39.130 --> 00:12:45.110 
have. So, today what has been
measured - we are up to twenty

168
00:12:45.160 --> 00:12:47.020 
two gigabyte per second

169
00:12:47.680 --> 00:12:50.950 
and lower than four
hundred nanoseconds total

170
00:12:51.780 --> 00:12:54.670 
for the round trip, so
these are really good.
