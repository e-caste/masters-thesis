WEBVTT

1
00:00:00.520 --> 00:00:04.869 
Welcome to this video clip in which we discuss the practical aspects of Manual

2
00:00:04.870 --> 00:00:05.870 
Conformance Checking.

3
00:00:07.930 --> 00:00:12.519 
More and more tools in practice also provide the possibility

4
00:00:12.520 --> 00:00:16.690 
to conduct conformance checking, so they come with certain conformal seeking

5
00:00:16.900 --> 00:00:20.779 
capabilities. In the following, we will use LANA fromLana Labs

6
00:00:21.610 --> 00:00:25.577 
to illustrate how conformance checking practice can be done and how

7
00:00:26.050 --> 00:00:29.859 
it works. It's, of course, important to highlight that there are many other tools

8
00:00:29.860 --> 00:00:33.690 
available and that they have similar capabilities

9
00:00:35.200 --> 00:00:38.630 
but we use, of course, one specific tool here to really illustrate how

10
00:00:39.820 --> 00:00:44.499 
it can work and how the different facets that we have discussed can be, where

11
00:00:44.500 --> 00:00:46.420 
they can be found and how they can be used.

12
00:00:46.960 --> 00:00:51.229 
More details on LANA can be found on the web page lanalabs.com.

13
00:00:51.520 --> 00:00:54.656 
What we will use in the remainder of this clip and also the next

14
00:00:56.140 --> 00:00:59.710 
clip is a variation of the noisy event log we have already seen.

15
00:00:59.950 --> 00:01:04.628 
So, this is the noisy event log based on process model 3 from week

16
00:01:04.629 --> 00:01:05.629 
one.

17
00:01:07.350 --> 00:01:11.909 
The first step is, of course, always the same, if you would

18
00:01:11.910 --> 00:01:16.439 
like to do process mining, you have to upload the log, this is sort of a little

19
00:01:16.440 --> 00:01:21.150 
surprising. This is  also typically not very complicated, the only

20
00:01:21.450 --> 00:01:25.919 
aspect that we would like to highlight here with LANA is that LANA does

21
00:01:25.920 --> 00:01:30.180 
not work with XES Files, but it actually expects you to provide a

22
00:01:30.570 --> 00:01:33.089 
CSV file, a comma separated file.

23
00:01:33.120 --> 00:01:37.769 
What does it mean? Well, it does not mean too much, they actually

24
00:01:37.770 --> 00:01:42.239 
also provide a tool that can convert from XES to CSV and the other

25
00:01:42.240 --> 00:01:46.889 
way around, also many other process mining tools offer that possibility.

26
00:01:47.280 --> 00:01:49.754 
The advantage of CSV formats are

27
00:01:51.810 --> 00:01:55.950 
that you can more easily look at the data.

28
00:01:56.190 --> 00:01:58.542 
So, what you see here are actually two examples.

29
00:01:59.230 --> 00:02:03.719 
So this is the same event like event log that we will use once in

30
00:02:03.720 --> 00:02:07.836 
this CSV format, we can see when you open the CSV file with a text editor, then here

31
00:02:08.150 --> 00:02:09.150 
are all the headers.

32
00:02:10.949 --> 00:02:15.201 
So, we have a Case ID, we have an activity, the resource, we have a start

33
00:02:15.510 --> 00:02:20.279 
timestamp, we have a complete timestamp, then you see that, well, each row contains

34
00:02:20.280 --> 00:02:23.808 
a record respectively, with these values separated from each other using

35
00:02:24.960 --> 00:02:29.729 
semicolon and if we open the very same file in Excel,

36
00:02:29.730 --> 00:02:34.259 
for instance, or any other tool that allows

37
00:02:34.260 --> 00:02:38.699 
you to then split the data based on delimiter here, in this

38
00:02:38.700 --> 00:02:43.529 
case, it's a semicolon, then you can also look at the data in a structured

39
00:02:43.530 --> 00:02:46.666 
way, which I would argue can come with some advantages, at least

40
00:02:48.060 --> 00:02:50.920 
if you want to take a first look at the data.

41
00:02:51.120 --> 00:02:55.619 
So, this is the format that LANA expects

42
00:02:55.620 --> 00:02:58.119 
here at this point. So, you need to select an event

43
00:03:00.120 --> 00:03:03.369 
log in the CSV format and upload this respectively.

44
00:03:04.200 --> 00:03:08.729 
The next step is then to configure log attributes, this is something that we

45
00:03:08.730 --> 00:03:12.120 
have also seen with Disco last week.

46
00:03:12.390 --> 00:03:17.189 
So, there are certain attributes, as you know, that are required, so you remember

47
00:03:17.190 --> 00:03:19.885 
that every process mining tool expects you to provide a

48
00:03:21.630 --> 00:03:26.639 
Case ID, it expects you to provide an activity and it also expects

49
00:03:26.640 --> 00:03:30.900 
you to provide a timestamp. So, here what also LANA does is

50
00:03:31.140 --> 00:03:35.789 
it parses the file that you provide and tries to understand, OK, what are the different

51
00:03:35.790 --> 00:03:40.115 
attributes, it's able to identify in the different columns

52
00:03:40.380 --> 00:03:45.149 
and here it has already figured that the attribute Case ID relates

53
00:03:45.150 --> 00:03:49.050 
to Case ID, that here, the action

54
00:03:49.890 --> 00:03:54.659 
on here in the column activity actually relates to what LANA calls an action

55
00:03:55.050 --> 00:03:59.669 
and that the column resource is a categorical attribute, we could now also

56
00:04:00.060 --> 00:04:04.583 
actually configure retrospectively and tell LANA this is a resource

57
00:04:04.980 --> 00:04:08.999 
and then you see here there are two timestamps, and LANA has also here already

58
00:04:09.000 --> 00:04:13.559 
automatically figured out that this is a start and a complete

59
00:04:13.560 --> 00:04:18.179 
timestamp. So, in case the interpretation of this import

60
00:04:18.480 --> 00:04:21.028 
agent does not match well, what you have had in mind

61
00:04:22.980 --> 00:04:26.759 
or what you have defined, you can change it respectively, which is, of course, an

62
00:04:26.760 --> 00:04:28.800 
important step in the input procedure.

63
00:04:29.370 --> 00:04:32.947 
Once you done with that, you can click the finish button and you will see

64
00:04:34.290 --> 00:04:38.880 
a first version of a process model and what you obtain is

65
00:04:39.150 --> 00:04:43.085 
very similar to what we have seen last week actually, it's a filtered directly-follows

66
00:04:43.470 --> 00:04:46.067 
graph where you see what we can see, the mean process

67
00:04:48.480 --> 00:04:52.709 
flow. So, you recall the process, of course, you see that

68
00:04:53.010 --> 00:04:57.720 
here we received the claim and we check for completeness and then

69
00:04:57.750 --> 00:05:02.130 
we check the claim internally and there are some, there are the invite

70
00:05:02.250 --> 00:05:06.268 
claim review and receive claim review steps and we decide on the coverage and then

71
00:05:06.720 --> 00:05:09.420 
we make a decision and send a letter in the end.

72
00:05:10.410 --> 00:05:13.301 
What you see here without seeing too much details from from

73
00:05:14.880 --> 00:05:19.790 
this graph, actually, is that it's a very simplified version of our process.

74
00:05:19.800 --> 00:05:23.232 
So, this is not because our log is so noisy that it's actually

75
00:05:24.270 --> 00:05:27.749 
able to simplify the process so much, but it's a configuration of LANA.

76
00:05:28.242 --> 00:05:30.741 
So, what you see here is that you can configure how

77
00:05:32.670 --> 00:05:36.689 
many so-called variant groups are being shown, so you see that LANA detected

78
00:05:37.200 --> 00:05:40.260 
28 variant groups and we are only seeing 2 of them.

79
00:05:40.710 --> 00:05:45.209 
So, for this model, the standard configuration that we have

80
00:05:45.210 --> 00:05:49.230 
encountered and you also see what this means, so we only see

81
00:05:50.460 --> 00:05:54.899 
43.9% of all the cases and of course we are interested in seeing more so we can

82
00:05:54.900 --> 00:05:58.085 
adapt that we can change that setting and if we adapt the setting

83
00:05:59.550 --> 00:06:02.539 
to all the trace variance, then to 100% of the cases, then we

84
00:06:04.080 --> 00:06:08.996 
end up with this model. So, this now provides a complete view on the process execution.

85
00:06:10.120 --> 00:06:13.029 
Well, is this now helpful for our analysis?

86
00:06:14.080 --> 00:06:17.314 
Well, it is, of course, the issue, of course, or to in many cases,

87
00:06:18.880 --> 00:06:23.350 
we have to realize that conformance or that nonconforming traces are

88
00:06:23.590 --> 00:06:27.280 
rare or at least are less infrequent than the standard behavior.

89
00:06:28.150 --> 00:06:32.380 
So, we actually if we want to manually detect such behavior,

90
00:06:32.740 --> 00:06:36.850 
then we need to include all these exceptional variants as well.

91
00:06:37.420 --> 00:06:41.829 
Here, in this case, we end up with this model, I'll zoom in, in a second, so you can also

92
00:06:41.830 --> 00:06:43.310 
see some details.

93
00:06:43.840 --> 00:06:48.339 
So here, it's actually feasible but you have to keep in mind, and this is,

94
00:06:48.340 --> 00:06:52.809 
of course, the limitation of any manual conformance analysis, is that in

95
00:06:52.810 --> 00:06:57.730 
practice you may actually expect that this graph looks much more complicated.

96
00:06:57.880 --> 00:07:02.380 
So, even though we have generated some noise,

97
00:07:02.740 --> 00:07:06.850 
that is something that you have seen last week already, this is still a very

98
00:07:07.480 --> 00:07:10.861 
simple process, of course, a process model or a process that does not

99
00:07:11.920 --> 00:07:14.129 
come with a lot of variations.

100
00:07:14.140 --> 00:07:18.692 
So, this is still something that is not considered to be very complex.

101
00:07:18.820 --> 00:07:22.005 
In practice you should expect this to be much worse, which is why

102
00:07:23.290 --> 00:07:25.710 
we also talk about automated analysis.

103
00:07:25.870 --> 00:07:29.739 
But let's see, first of all, what we can do manually with this.

104
00:07:30.070 --> 00:07:33.874 
So, let's zoom in a little bit and let's look at violation patterns

105
00:07:34.660 --> 00:07:39.399 
and what you see here is that violation patterns are actually not easy to spot.

106
00:07:40.240 --> 00:07:43.420 
So, if we take a look, what can we see?

107
00:07:44.050 --> 00:07:48.479 
So, if you keep in mind a little bit how the process flows,

108
00:07:48.490 --> 00:07:52.659 
you remember, of course, that we have to check for completeness and then we have these

109
00:07:52.660 --> 00:07:56.049 
internal review and we have the external review, which we invite.

110
00:07:56.620 --> 00:08:00.785 
You see that if you look at the model here, that there are some arcs going from check

111
00:08:01.240 --> 00:08:04.866 
claim completeness directly to decide claim coverage, so this is something

112
00:08:05.680 --> 00:08:09.986 
we see. So, it does seem from this representation here that

113
00:08:10.990 --> 00:08:15.019 
there are cases where we take the decision right after checking the claim completeness.

114
00:08:15.040 --> 00:08:17.899 
So, this is something that we can spot already.

115
00:08:18.790 --> 00:08:23.230 
We can also see that there are quite a few cases where we at least

116
00:08:25.780 --> 00:08:30.220 
do not conduct this internal check, so we immediately go to invite to claim review.

117
00:08:31.420 --> 00:08:33.970 
We can also see that there are cases where we

118
00:08:36.010 --> 00:08:40.330 
jump directly from receiving the claim review to

119
00:08:40.659 --> 00:08:44.739 
an activity that comes after the decision, so this is going out of this picture here, but

120
00:08:44.740 --> 00:08:48.366 
there is this this arc and we can also see that there is an arc going back

121
00:08:49.330 --> 00:08:53.299 
from this side and claim coverage to receive the claim review, which indicates if

122
00:08:53.830 --> 00:08:58.191 
we reflect on this, that something needs to be executed in wrong order, because typically

123
00:08:58.600 --> 00:09:03.049 
you would expect that this activity is executed first and only then we decide.

124
00:09:03.340 --> 00:09:08.110 
So, the fact that there is this arc going back already indicates that something

125
00:09:08.530 --> 00:09:12.970 
seems to be wrong. So the challenge is two-fold, on the one hand,

126
00:09:13.510 --> 00:09:17.234 
if we want to do a manual analysis, on the one hand, we need to have in mind

127
00:09:18.190 --> 00:09:22.779 
how the blueprint might looks like, so we need to really understand and have

128
00:09:22.780 --> 00:09:27.557 
in our mind how does it work and what is the process flow that we would expect

129
00:09:27.940 --> 00:09:32.679 
and then we can, of course, go into this and try to analyze whether

130
00:09:32.680 --> 00:09:37.359 
there are any deviations, the challenge here related to that is then that

131
00:09:37.360 --> 00:09:40.990 
this directly follows graph does not clearly show us

132
00:09:41.980 --> 00:09:45.969 
whether there is certain constructs or not explicitly shown.

133
00:09:46.150 --> 00:09:49.874 
So,the directly follows graph only shows that one activity follows after the

134
00:09:50.590 --> 00:09:54.902 
other, whether there is some concurrency or whether there has been a choice is something

135
00:09:54.940 --> 00:09:59.799 
we have to derive from either looking at the entire

136
00:09:59.800 --> 00:10:02.740 
model and then looking at several of these arcs together, or

137
00:10:04.360 --> 00:10:06.700 
in some cases it's not possible at all.

138
00:10:06.730 --> 00:10:10.289 
So, there are many challenges associated with such a manual analysis.

139
00:10:10.450 --> 00:10:13.978 
It's possible it can provide you with a first overview, but it's clearly

140
00:10:15.130 --> 00:10:19.510 
challenging. And again, keep in mind that this is a rather

141
00:10:19.720 --> 00:10:24.489 
simple model and there are not many different path

142
00:10:24.490 --> 00:10:28.750 
here included. You can imagine in practice this graph to be even bigger.

143
00:10:28.840 --> 00:10:33.639 
So to conclude, it's clear that an automated analysis

144
00:10:33.640 --> 00:10:37.609 
would really help us here to obtain insights and to detect violation patterns and

145
00:10:38.590 --> 00:10:42.657 
of course, for such an automated analysis, we require a so-called group and process

146
00:10:43.270 --> 00:10:47.350 
model and this is what we are going to look at in the next clip.
