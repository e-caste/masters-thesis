WEBVTT

1
00:00:00.760 --> 00:00:04.440 
hi everyone i am Ali Darvishi, a phd student in learning analytics at

2
00:00:04.440 --> 00:00:08.620 
the university of Queensland. my supervisor Dr. Hassan Khosravl,
and  professor Shazia Sadiq

3
00:00:09.610 --> 00:00:12.690 
will come to the stuck on and following peer review to evaluate

4
00:00:12.690 --> 00:00:15.470 
the quality of a student generated content at escape

5
00:00:16.040 --> 00:00:18.100 
a trust propagation approach.

6
00:00:20.030 --> 00:00:23.290 
engaging a student in creating novel content has been demonstrated

7
00:00:23.290 --> 00:00:27.850 
as a viable method for supporting learner centred learning at escape.

8
00:00:28.170 --> 00:00:32.010 
it recognizes a student as a partner in learning and engage

9
00:00:32.010 --> 00:00:36.700 
them in higher order learning. an important question to consider is

10
00:00:37.010 --> 00:00:39.960 
can a student create high-quality learning resources?

11
00:00:40.460 --> 00:00:44.480 
well there seemed to be enough evidence suggesting that they

12
00:00:44.480 --> 00:00:48.830 
can create high quality content. however,
it is likely that some of

13
00:00:48.980 --> 00:00:53.570 
the learning resources developed by the student might be ineffective

14
00:00:53.630 --> 00:00:57.530 
innappropriate or even incorrect. so how can we separate high

15
00:00:57.530 --> 00:01:02.820 
quality from low quality resources in a large
repository of student generated content.

16
00:01:03.890 --> 00:01:07.990 
and a scaleable approach is to use a peer review process where

17
00:01:07.990 --> 00:01:13.060 
students are asked to assess the quality of
resources authored by their peers.

18
00:01:14.540 --> 00:01:17.280 
however, this method of using peer review

19
00:01:17.880 --> 00:01:20.410 
causes the problem of truth inference.

20
00:01:21.710 --> 00:01:25.810 
as the judgment of a student as expert in training cannot wholly

21
00:01:25.810 --> 00:01:30.100 
be trusted. this figure provides a prix analysis based on near

22
00:01:30.530 --> 00:01:34.460 
seven hundred resources with five thousand student ratings

23
00:01:34.560 --> 00:01:37.670 
that had also received instructors moderation.

24
00:01:38.090 --> 00:01:42.300 
it mainly demonstrates that identifying low quality resources

25
00:01:42.300 --> 00:01:47.190 
based on peer-review is a challenging task. since in cases where

26
00:01:47.190 --> 00:01:52.150 
instructor have rejected a resource
the chance of a student also rejected

27
00:01:52.350 --> 00:01:56.080 
rejecting that resource is less than fourteen percent.

28
00:01:57.310 --> 00:02:00.810 
here is the definition of our problem and some common solution

29
00:02:00.810 --> 00:02:02.990 
of consensus inferences methods.

30
00:02:04.230 --> 00:02:08.690 
how can we use subjective rating of a student on a resource

31
00:02:08.700 --> 00:02:13.670 
to infer its true quality or aim is to identify reliability

32
00:02:13.990 --> 00:02:17.880 
for each user as their decision weight, such that the quality

33
00:02:17.880 --> 00:02:22.170 
can be inferred using a weighted average consensus inference method.

34
00:02:24.530 --> 00:02:27.850 
first we take a set of well known aggregation approaches baseline

35
00:02:27.870 --> 00:02:31.830 
including majority vote mean and media. these approaches assume

36
00:02:32.150 --> 00:02:36.240 
an equal weight for all moderators. so the results are in favour

37
00:02:36.240 --> 00:02:41.220 
of the majority in these models assuming the inferred quality

38
00:02:41.220 --> 00:02:44.960 
of three would pass the moderation all of these models would

39
00:02:44.980 --> 00:02:50.290 
approve this example resource. however,
a number of resource including this one

40
00:02:50.480 --> 00:02:54.580 
have been also inspected by instructors.
as we can see it is

41
00:02:54.580 --> 00:02:58.610 
rejected by the instructor which shows the failure of the baseline

42
00:02:58.840 --> 00:02:59.900 
in this example.

43
00:03:01.940 --> 00:03:06.990 
current model implemented in our platform
is a weighted aggregation approach inspired by

44
00:03:07.150 --> 00:03:09.330 
expectation maximization technique.

45
00:03:09.970 --> 00:03:12.900 
in this model first the reliability score of all the student

46
00:03:12.900 --> 00:03:17.930 
are set to an initial value. in the expectation step the quality

47
00:03:17.930 --> 00:03:21.710 
of a resource is inferred and in the maximization step the

48
00:03:21.710 --> 00:03:26.090 
reliability of user are updated. as we can see this result is

49
00:03:26.090 --> 00:03:29.230 
a still bias toward the majority who overate.

50
00:03:30.960 --> 00:03:33.780 
this is a small example of how this model works.

51
00:03:34.320 --> 00:03:38.680 
resource quality is inferred based on the current
value of a student reliability

52
00:03:39.120 --> 00:03:43.380 
then based on the goodness of a student rating
compared to the inferred quality.

53
00:03:43.590 --> 00:03:45.490 
their reliability would be updated.

54
00:03:46.240 --> 00:03:50.630 
the system continues the same process for other other resources

55
00:03:51.020 --> 00:03:55.410 
and in some challenging cases with low confident decision

56
00:03:55.880 --> 00:03:59.200 
flights a resource for instructor's inspection.

57
00:04:00.950 --> 00:04:05.080 
in the spot check resources the inferred quality would be said

58
00:04:05.310 --> 00:04:09.160 
to the instructor decision and the student reliability would

59
00:04:09.160 --> 00:04:11.440 
be updated based on this decision.

60
00:04:12.450 --> 00:04:18.080 
at the end of this process only few student reliability
were directly adjusted using

61
00:04:18.660 --> 00:04:20.470 
expert judgment.

62
00:04:22.880 --> 00:04:25.460 
now i present our proposed method.

63
00:04:26.980 --> 00:04:30.750 
here we formulated the problem in the form of a moderation graph

64
00:04:30.940 --> 00:04:37.500 
which consists of four kinds of note
student decision rating resources and instructors.

65
00:04:37.620 --> 00:04:41.280 
the first two step in this model are similar to e-m, however

66
00:04:41.370 --> 00:04:46.170 
there is a service that the moderator's reliability would propagate

67
00:04:46.180 --> 00:04:47.830 
in a network of users.

68
00:04:49.070 --> 00:04:53.830 
this scenario starts similar to the em approach, however, user

69
00:04:53.830 --> 00:04:58.370 
scores would be changed based on the quality of their own decision

70
00:04:58.530 --> 00:05:01.950 
in the current task and also the quality of their peers' decision

71
00:05:01.950 --> 00:05:06.550 
in the future task. in this model users would receive an updated

72
00:05:06.560 --> 00:05:11.680 
score from the most reliable moderator in a future moderation which is

73
00:05:11.880 --> 00:05:14.990 
based on the similarity between them in terms of agreement

74
00:05:14.990 --> 00:05:18.350 
and disagreement in previous collaboration. instructor's spot

75
00:05:18.350 --> 00:05:22.020 
check not only change the current moderator reliability,

76
00:05:22.020 --> 00:05:24.050 
but also propagate through the network.

77
00:05:24.780 --> 00:05:28.610 
fast forwarding the process we can see in addition to those

78
00:05:28.650 --> 00:05:33.220 
fewer student with direct adjustment in their reliability another

79
00:05:33.220 --> 00:05:39.780 
sort of student also receive an in direct adjustment
as a result of instructor's intervention

80
00:05:40.780 --> 00:05:42.290 
evaluation on future work.

81
00:05:43.450 --> 00:05:46.350 
we have collected data from piloting an adaptive educational

82
00:05:46.350 --> 00:05:50.570 
system called ripple in five courses with more than two thousand students

83
00:05:50.680 --> 00:05:54.410 
or finding show that identifying low quality resources based on

84
00:05:54.580 --> 00:05:58.230 
peer review is a challenging task as many of the student tend

85
00:05:58.230 --> 00:06:03.460 
to be easy graders.
results show that the graph-based trust propagation model

86
00:06:03.610 --> 00:06:07.160 
works well by identifying the trust versus student moderator

87
00:06:07.320 --> 00:06:10.150 
with optimal use of instructor's intervention.

88
00:06:10.660 --> 00:06:14.930 
there are several interesting directions to pursue in future work.

89
00:06:15.410 --> 00:06:19.080 
we are working on updating the current implementation and conducting

90
00:06:19.080 --> 00:06:24.820 
randomized experiment to explore impact on accuracy
explainability and student behavior.

91
00:06:24.990 --> 00:06:27.930 
next we cannot take the spot checking recommendation algorithm

92
00:06:27.930 --> 00:06:32.770 
to consider resources that would propagate higher
amount of reliability between the

93
00:06:32.950 --> 00:06:37.220 
network. also our recent a study showed a direct correlation

94
00:06:37.220 --> 00:06:40.870 
between the quality of picture feedback or provided comment

95
00:06:40.940 --> 00:06:45.540 
and the quality of moderation.
so we want to employ advanced ai and

96
00:06:45.650 --> 00:06:48.950 
nlp methods for evaluating the quality of moderation based

97
00:06:48.950 --> 00:06:52.680 
on the provided comments.
and finally we are going to focus

98
00:06:52.680 --> 00:06:56.560 
on development of processes and mechanism to provide training

99
00:06:56.630 --> 00:06:59.720 
support and feedback literacy at the scale.

100
00:07:00.570 --> 00:07:02.160 
thank you for your attention.
