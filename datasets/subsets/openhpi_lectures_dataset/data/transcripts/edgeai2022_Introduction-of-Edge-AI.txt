WEBVTT

1
00:00:00.730 --> 00:00:01.770 
Hello.

2
00:00:01.780 --> 00:00:06.240 
Starting from this video, we will discuss the emerging field of edge

3
00:00:06.240 --> 00:00:06.830 
AI

4
00:00:06.839 --> 00:00:16.929 
in the next two weeks. We will analyze the technical research directions of this field and the projects of industrial applications

5
00:00:16.929 --> 00:00:22.870 
from multiple perspectives such as AI algorithms, software, and hardware.

6
00:00:26.309 --> 00:00:36.329 
According to Gartners forecast by 2020, the number of global IOT devices will exceed 20 billion.

7
00:00:36.929 --> 00:00:42.590 
At the same time, the equipment itself has become more and more intelligent.

8
00:00:42.630 --> 00:00:52.369 
Therefore, edge AI has become a rapidly developing field in the past few years. According to the Gartner report, it may reach its

9
00:00:52.369 --> 00:00:55.609 
peak popularity in the next three years.

10
00:00:56.890 --> 00:01:08.370 
In the year 2020, 50% of enterprise generated data will be perceived outside of the traditional data centers are outside of

11
00:01:08.370 --> 00:01:14.439 
the cloud, and this number was less than 10% in 2018.

12
00:01:15.299 --> 00:01:16.890 
Why did this happen?

13
00:01:17.780 --> 00:01:26.310 
Cloud computing has successfully alleviated the storage and management problems caused by the increasing amount of data in

14
00:01:26.310 --> 00:01:27.760 
the past 10 years.

15
00:01:28.500 --> 00:01:37.980 
However, the current growth rate of network bandwidth is far behind the growth rate of data and the cost of network bandwidth

16
00:01:38.010 --> 00:01:44.060 
is falling much slower than the cost of hardware resources such as GPU and RAM.

17
00:01:45.269 --> 00:01:52.430 
At the same time, the complex network environment makes it challenging to improve the latency.

18
00:01:52.439 --> 00:01:59.400 
Therefore, traditional cloud computing cannot meet the high response time in the security requirements.

19
00:02:00.379 --> 00:02:03.109 
Take the self driving car as an example.

20
00:02:03.750 --> 00:02:12.400 
So driving at high speeds needs to response with immediate seconds once the system response time increases due to the data

21
00:02:12.400 --> 00:02:17.879 
transmission and the network problems it will cause serious consequences.

22
00:02:19.400 --> 00:02:25.120 
In addition, cloud computing also faces the problem of insufficient endeavors.

23
00:02:26.039 --> 00:02:35.639 
If all the data generated by age devices are transmitted to the cloud network bandwidth, view pressure, for example, the

24
00:02:35.639 --> 00:02:42.889 
Boeing 787 airplane generated more than five gigabytes of data per second.

25
00:02:42.900 --> 00:02:52.080 
But the bandwidth between the airplane and the satellite is insufficient to support real time data transmission, therefore

26
00:02:52.090 --> 00:03:02.979 
relying on only the cloud computing is insufficient to support application operations and massive data processing in some specific

27
00:03:02.979 --> 00:03:06.389 
domains such as IOT,cloud, edge AI

28
00:03:06.389 --> 00:03:14.669 
can solve many problems efficiently.

29
00:03:14.669 --> 00:03:23.840 
Across size definition of edge AI is offloading AI capabilities from the cloud to the edge, that's closer to user data.

30
00:03:24.960 --> 00:03:34.169 
The industry urgently needs more efficient AI technology to make it possible to develop more extensive AI applications.

31
00:03:34.919 --> 00:03:41.780 
Currently, the AI paradigm is mainly based on the cloud computing, which has many limitations.

32
00:03:41.789 --> 00:03:51.310 
For example, since most of the data is generated from the edge or client side, it cannot guarantee applicability under low

33
00:03:51.310 --> 00:03:53.189 
bandwidth and low latency.

34
00:03:53.939 --> 00:04:02.030 
Since the data needs to be transmitted to the data center, privacy and security are always challenging issues.

35
00:04:02.719 --> 00:04:09.800 
Cloud providers suffer from the high cost of large scale AI computing.

36
00:04:09.810 --> 00:04:19.579 
On the other hand, we cannot ensure offline autonomy of applications and if the networking fails, your AI application aced up.

37
00:04:19.579 --> 00:04:31.620 
These factors have significant restricted the application of AI in some traditional industries, such as agriculture and

38
00:04:31.620 --> 00:04:32.639 
manufacturing.

39
00:04:33.500 --> 00:04:42.319 
It also substantially influences other applications requiring real time performance, like autonomous driving and robotics.

40
00:04:43.240 --> 00:04:52.170 
Also the applications that generate vast amounts of data on the client side, such as video conferencing systems, mobile gaming,

41
00:04:52.180 --> 00:04:58.360 
we are in a AI applications.

42
00:04:58.360 --> 00:05:07.810 
As aforementioned, AI algorithms heavily rely on solid computing power, computation power and that most of the current AI

43
00:05:07.810 --> 00:05:12.189 
devices and services are provided on the cloud platform.

44
00:05:12.790 --> 00:05:20.550 
However, it brings limitations like weak privacy protection and limited interaction and connections.

45
00:05:20.560 --> 00:05:30.379 
For example, moving a large amount of data from client to the data center brings large delays and significant increase in

46
00:05:30.379 --> 00:05:31.060 
costs.

47
00:05:31.459 --> 00:05:33.949 
For instance, according to ESA's

48
00:05:33.949 --> 00:05:34.180 


49
00:05:34.189 --> 00:05:34.569 


50
00:05:34.569 --> 00:05:46.060 
report more than 150 terabyte of data may be generated daily in traditional saturday to remote sensing, I'm assuming that

51
00:05:46.069 --> 00:05:54.600 
even with 500 megabyte connection, it will take four days to transport this data to the ground data center.

52
00:05:55.389 --> 00:06:03.209 
And if we can directly protest data, analyze data on the client on the device, it will bring substantial savings.

53
00:06:05.879 --> 00:06:14.720 
The biggest obstacle to developing AI models at the age is the high computational complexity of the model.

54
00:06:15.660 --> 00:06:21.019 
Most client devices cannot afford the number of computations of a big model.

55
00:06:21.939 --> 00:06:29.970 
The current solution is to apply compression techniques to create a small model and use it on the device.

56
00:06:31.009 --> 00:06:34.779 
However, there are still many serious restrictions.

57
00:06:34.790 --> 00:06:43.430 
First, the small model security loss is significant, which strongly limits the applicability of age applications.

58
00:06:44.240 --> 00:06:49.610 
It also increases development complexity for AI applications.

59
00:06:49.790 --> 00:07:00.160 
For example, if Tiktok wants to develop a new real time official effect, they often need to build several different versions

60
00:07:00.160 --> 00:07:10.180 
of client side models to fulfill the requirements of the various mobile devices with extra computing power, hardware configurations,

61
00:07:10.189 --> 00:07:12.980 
and different battery life and so on.

62
00:07:12.990 --> 00:07:14.339 
Many factors.

63
00:07:14.350 --> 00:07:24.019 
It is just too challenging to serve a large varity of mobile devices for each model, it is also hard to meet the needs of

64
00:07:24.029 --> 00:07:26.620 
massive amounts of mobile applications.

65
00:07:29.750 --> 00:07:39.480 
With the rapid development of digitalization and 5G technology, the carrier of future applications will quickly transfer

66
00:07:39.490 --> 00:07:42.370 
to edge and to client side devices.

67
00:07:43.220 --> 00:07:46.360 
It means offloading computation to the edge.

68
00:07:47.230 --> 00:07:49.120 
Why can we achieve it?

69
00:07:49.180 --> 00:07:59.709 
First of all, 5G will bring significant increase in bandwitdth, imagine that if the bandwidth can be increased by 100 times

70
00:07:59.930 --> 00:08:07.230 
then many impossible interactions can be realized and the novel interaction can promote application innovation.

71
00:08:08.250 --> 00:08:15.269 
Second, the hardware at the edge in the future will have a I computing capacity.

72
00:08:16.360 --> 00:08:26.790 
Edge GPUs are installed more devices such as routers or base stations, which effectively increase the edge side computing

73
00:08:26.790 --> 00:08:33.480 
power and can collaborate with client devices and support the client side AI applications.

74
00:08:34.190 --> 00:08:43.000 
Therefore, future applications are highly interactive and can support massive connections and the future AI computing will

75
00:08:43.000 --> 00:08:47.950 
become highly efficient, decentralized and highly collaborative.

76
00:08:50.769 --> 00:09:00.330 
Currently, a big model cannot be deployed on low power client edge devices, but if we can solve this issue of communication

77
00:09:00.330 --> 00:09:10.169 
benefits and achieve extremely low latency, we may be able to leverage many edge nodes to perform a collaborative inference

78
00:09:10.179 --> 00:09:19.149 
for running such a big model, such a dense centralized and distributed computing paradigm will become visible in the

79
00:09:19.159 --> 00:09:20.279 
5G era.

80
00:09:20.289 --> 00:09:29.909 
The form of the Ai model, the interaction method and some software structure will undergo fundamental change in the future

81
00:09:33.440 --> 00:09:35.100 
What challenges need edge

82
00:09:35.100 --> 00:09:35.330 
AI first?

83
00:09:35.330 --> 00:09:35.429 


84
00:09:35.429 --> 00:09:38.649 
First a significant challenge of edgeAI

85
00:09:38.659 --> 00:09:38.919 


86
00:09:38.919 --> 00:09:39.129 


87
00:09:39.139 --> 00:09:42.169 
Is the heterogeneity of each edge node.

88
00:09:42.809 --> 00:09:49.519 
We have to deal with diverse hardware, architectures, operation system and AI software frameworks.

89
00:09:50.240 --> 00:09:59.149 
We can see that the heterogeneous et of these three different dimensions significantly increase the difficulty of implementation.

90
00:10:00.000 --> 00:10:09.179 
Another critical issue is better protecting data privacy in the edgeAI scenario and I think this should be an advantage of

91
00:10:09.190 --> 00:10:11.850 
edgeAI technology stock.

92
00:10:12.480 --> 00:10:20.960 
However, from another perspective, stricter data privacy policies may lead to data silence problems.

93
00:10:23.940 --> 00:10:30.059 
The data are geographical distribution on the edge.

94
00:10:31.529 --> 00:10:37.039 
Eerily they cannot be shared due to the privacy protection and other reasons.

95
00:10:37.049 --> 00:10:43.799 
Therefore, the AI algorithm cannot efficiently use the data of each edge node together.

96
00:10:44.379 --> 00:10:53.590 
The traditional centralized AI method brings significant performance degradation, such as lower convergence speed and a bad

97
00:10:53.590 --> 00:10:56.610 
model accuracy in edge scenarios.

98
00:10:57.370 --> 00:11:02.909 
In traditional supervised learning research IID,

99
00:11:02.909 --> 00:11:03.539 


100
00:11:03.549 --> 00:11:13.759 
also called independent and identically distributed, is an important assumption or early when we do the machine learning

101
00:11:13.759 --> 00:11:23.720 
task, we assume that our training and testing data have the same distribution and examples are independent. For example, in

102
00:11:23.720 --> 00:11:29.700 
the CIFAR data set, the training set and the testing set are evenly divided.

103
00:11:29.710 --> 00:11:34.049 
If you randomly select example from these two sets,

104
00:11:34.059 --> 00:11:39.600 
the probability that it belongs to one of the classes is 10%.

105
00:11:40.210 --> 00:11:41.090 
This is IID

106
00:11:41.090 --> 00:11:41.460 


107
00:11:41.470 --> 00:11:46.100 
10% because they have 10 classes to predict. This is IID,

108
00:11:46.100 --> 00:11:46.210 


109
00:11:46.210 --> 00:11:46.679 


110
00:11:47.220 --> 00:11:54.039 
so called identical distribution and independent samples. In the practice,

111
00:11:54.049 --> 00:11:58.620 
there are considerable differences in the data distribution of edge nodes.

112
00:11:58.629 --> 00:12:07.090 
In addition, the data distribution of the pre trained model and the test data distribution of the edge node may also differ

113
00:12:07.090 --> 00:12:07.750 
a lot.

114
00:12:08.529 --> 00:12:11.970 
So we are facing actually the non IID

115
00:12:11.970 --> 00:12:12.070 


116
00:12:12.070 --> 00:12:12.330 


117
00:12:12.330 --> 00:12:13.090 
Problem.

118
00:12:15.580 --> 00:12:26.210 
Edge nodes ususally only have limited resources, for example its power supply, computing and storage resources are much lower

119
00:12:26.220 --> 00:12:27.940 
than cloud side devices.

120
00:12:28.539 --> 00:12:32.299 
In addition, bandwidth is also a possible bottle neck.

121
00:12:33.000 --> 00:12:43.970 
These issues needs to be considered when we design algorithms and hardware and software in addition to the uneven distribution

122
00:12:43.970 --> 00:12:53.029 
of edge side data, we may also face the problem of too few examples and thus cannot efficiently carry out the model training.

123
00:12:53.659 --> 00:13:01.039 
In addition we may meet unknown data classes leading to the complete failure of supervised learning method.

124
00:13:01.690 --> 00:13:11.710 
Okay we have summarized these challenges of edge AI at present which may not be comprehensive enough but these are the problems

125
00:13:11.710 --> 00:13:16.360 
that research community and industries are currently solving.

126
00:13:18.519 --> 00:13:20.139 
Thank you for watching the video.
