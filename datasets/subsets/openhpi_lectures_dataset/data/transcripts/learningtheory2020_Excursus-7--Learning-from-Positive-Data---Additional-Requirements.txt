WEBVTT

1
00:00:00.750 --> 00:00:06.630 
So we've seen various ways to
learn data and various data to

2
00:00:06.630 --> 00:00:11.890 
be learned. So for example how to identify
a cat or a butterfly or different

3
00:00:12.190 --> 00:00:15.710 
other animals. We've
seen that we can have

4
00:00:16.450 --> 00:00:21.380 
positive and negative information and
also only positive information.

5
00:00:22.210 --> 00:00:24.020 
We've seen all of that

6
00:00:24.640 --> 00:00:29.170 
and now we will look into the
additional requirements we can

7
00:00:29.760 --> 00:00:35.070 
make when facing a learning
task. So for example let's

8
00:00:35.070 --> 00:00:36.310 
start with the
motivation.

9
00:00:37.000 --> 00:00:41.760 
So we have one language. So now we don't
have any pictures, we simply have

10
00:00:42.060 --> 00:00:46.360 
one set of dots
or numbers

11
00:00:47.070 --> 00:00:49.250 
and we call this L1.

12
00:00:50.290 --> 00:00:54.550 
We may have another set
L2, another language L2.

13
00:00:55.630 --> 00:00:59.150 
We may have a completely
different language L3

14
00:00:59.150 --> 00:01:02.330 
and we may have one
language L4 which

15
00:01:03.980 --> 00:01:06.120 
contains everything
a little bit.

16
00:01:07.800 --> 00:01:13.990 
And now we can get some data. Okay. So we
got this point and now we ask ourselves

17
00:01:15.600 --> 00:01:17.520 
which set could
it belong to.

18
00:01:18.240 --> 00:01:23.100 
Ok so it may be obvious
that it's not the set L3

19
00:01:23.810 --> 00:01:28.920 
but it may be L1, L2 or L4. And
now we have to make a guess.

20
00:01:29.190 --> 00:01:34.120 
So let's say we make
the guess L2,

21
00:01:35.190 --> 00:01:36.510 
we see another data

22
00:01:37.650 --> 00:01:42.560 
and this guess is still correct. So now we
can think about changing the guess or

23
00:01:42.810 --> 00:01:46.080 
keeping with it and we
decide to keep it

24
00:01:47.200 --> 00:01:51.420 
and see the next data
and now we see ok

25
00:01:52.140 --> 00:01:57.140 
we are or our previous
guess was not correct. So

26
00:01:57.980 --> 00:02:01.930 
we probably should change our
guess. Another question is should

27
00:02:01.930 --> 00:02:05.480 
we actually change it? So I mean
okay it may seem obvious we are

28
00:02:05.480 --> 00:02:11.850 
not consistent with the data we've seen.
So it's a good time to change our

29
00:02:12.370 --> 00:02:17.680 
our guess. Say from
L2 to L1 or L4.

30
00:02:18.830 --> 00:02:23.190 
However the question is,
is it really a good idea

31
00:02:24.560 --> 00:02:29.410 
and we will later see whether
it is or whether it is not to

32
00:02:29.660 --> 00:02:33.500 
a good idea to stay consistent
with the data all the time.

33
00:02:34.090 --> 00:02:38.620 
So let's say for example, okay,
we decide to stay consistent

34
00:02:39.060 --> 00:02:44.530 
and we change to let's say L4.
Okay, because this is what

35
00:02:44.540 --> 00:02:47.310 
we believe to be
the true set.

36
00:02:48.910 --> 00:02:52.200 
Now we see a new
datum and ok we are

37
00:02:52.890 --> 00:02:54.130 
not consistent again.

38
00:02:54.920 --> 00:03:01.400 
So what we could do now is like ok keep
L4 and stay inconsistent for a while,

39
00:03:02.000 --> 00:03:08.430 
or we say, okay, let's change to L1
because it's consistent with everything.

40
00:03:09.280 --> 00:03:14.840 
And now however if we change
to L1 we also disregard some

41
00:03:15.240 --> 00:03:18.480 
elements we guessed before.
For example all this

42
00:03:19.000 --> 00:03:23.940 
part of L4 which is not in
L1 would be disregarded.

43
00:03:25.200 --> 00:03:29.520 
Aand this is, and now we can also
ask ourselves do we really need

44
00:03:29.530 --> 00:03:32.360 
to do this in order to
learn? Do we really

45
00:03:32.850 --> 00:03:37.360 
want to do this, like in order to
achieve full learning power?

46
00:03:37.530 --> 00:03:41.440 
Do we really want
to disregard

47
00:03:42.740 --> 00:03:47.130 
guesses we made already, because I
mean when we made these guesses

48
00:03:47.130 --> 00:03:50.030 
we thought about it right?
We made the discusses

49
00:03:50.890 --> 00:03:53.270 
because of some reason.
We didn't just like

50
00:03:54.220 --> 00:03:58.730 
guess arbitrarily right? So why
should we change it now? Okay.

51
00:03:59.240 --> 00:04:02.640 
So this is what we will
be thinking about, like

52
00:04:03.860 --> 00:04:06.930 
do additional requirements
makes sense today

53
00:04:07.490 --> 00:04:09.800 
restrict our
learning power

54
00:04:10.620 --> 00:04:12.720 
or is it like,
okay, we can

55
00:04:13.500 --> 00:04:19.310 
we can just uh require them and nothing
happens? So it's basically the same.

56
00:04:19.680 --> 00:04:24.550 
Ok to conclude our example we
may now see other points

57
00:04:25.010 --> 00:04:29.090 
and by now we
should be pretty

58
00:04:30.320 --> 00:04:33.000 
certain that we are
learning the set L1.

59
00:04:33.840 --> 00:04:38.860 
Even now if we see something
that is in L4 we still say ok

60
00:04:39.290 --> 00:04:43.000 
we go with L1 which is
then the correct guess.

61
00:04:43.990 --> 00:04:49.220 
So now if we stay with L1 forever
and see only the element from L1

62
00:04:49.510 --> 00:04:52.150 
we learned
correctly. Okay,

63
00:04:53.530 --> 00:04:58.460 
now we look at the same
configuration of sets

64
00:04:58.980 --> 00:05:00.980 
and now when we
make our guesses

65
00:05:01.750 --> 00:05:05.460 
we number these guesses.
So for example

66
00:05:05.910 --> 00:05:11.920 
the leftmost set L3 has numbers
that's H1. This is our

67
00:05:12.010 --> 00:05:15.620 
so to say the the first
guess in our list.

68
00:05:16.310 --> 00:05:22.300 
Then we have H2, H3 and H4. So are
the possible guesses we may make

69
00:05:22.950 --> 00:05:26.050 
are numbered and the numbering
doesn't have to be the same

70
00:05:26.050 --> 00:05:28.770 
as the numbering of the
languages. So for example

71
00:05:29.190 --> 00:05:32.260 
L4 and H2

72
00:05:32.970 --> 00:05:36.960 
correspond to the same thing, however
the numbering is different. And

73
00:05:37.550 --> 00:05:43.100 
there may be a different set at
all which is not part of the

74
00:05:43.540 --> 00:05:47.260 
languages we are targeting
but it may be there to,

75
00:05:47.730 --> 00:05:50.250 
so to say, to confuse us
or to help us even.

76
00:05:50.970 --> 00:05:57.980 
And now, let's say, okay we want to
learn something consistently. So

77
00:05:58.340 --> 00:06:03.920 
for example we see a data and we want
the data to be consistent with our

78
00:06:04.220 --> 00:06:09.650 
guess no matter what. Okay, so
for example we see this point.

79
00:06:10.080 --> 00:06:14.940 
okay it's in the set L1, L2
and L4 now we can say ok

80
00:06:15.410 --> 00:06:17.940 
we simply output
the smallest set

81
00:06:19.330 --> 00:06:23.290 
the smallest guess where this
element is part of it. So

82
00:06:23.880 --> 00:06:28.930 
in this example it would be H2 because
if we go through the numbering ok

83
00:06:29.180 --> 00:06:31.390 
I know this element
is not in H1,

84
00:06:32.310 --> 00:06:34.810 
then I check ok this
element is in H2.

85
00:06:35.350 --> 00:06:39.470 
So I guess the language is
simply H2, I'm consistent

86
00:06:40.080 --> 00:06:42.700 
I didn't do
anything wrong.

87
00:06:43.650 --> 00:06:49.070 
So it probably doesn't
hurt to make this guess.

88
00:06:50.010 --> 00:06:51.740 
Okay I see another
element.

89
00:06:52.500 --> 00:06:54.880 
It's still consistent
with what I guessed

90
00:06:55.650 --> 00:06:57.960 
so I'll stick to that.

91
00:06:58.720 --> 00:07:02.690 
I see another element, still
everything alright. I see another

92
00:07:02.690 --> 00:07:06.750 
elements still everything
alright. However no one may

93
00:07:07.390 --> 00:07:11.620 
now one may see that maybe our
guess wasn't correct at all.

94
00:07:12.120 --> 00:07:14.680 
We were consistent.
However

95
00:07:15.330 --> 00:07:17.610 
the target language was

96
00:07:18.450 --> 00:07:23.310 
let's say obviously the set L2 which
corresponds to the guess H4.

97
00:07:24.020 --> 00:07:27.680 
However we guessed H2 the whole
time. So we didn't learn

98
00:07:27.680 --> 00:07:31.940 
it correctly, we simply made the wrong
choice or the wrong guess all the time

99
00:07:32.340 --> 00:07:34.150 
although we were
consistent, right?

100
00:07:34.800 --> 00:07:39.770 
So we see ok consistency
may be tricky

101
00:07:40.520 --> 00:07:44.270 
and maybe may not
be easy at all

102
00:07:45.080 --> 00:07:48.920 
to handle. Okay, so this
was the motivation. Now

103
00:07:49.440 --> 00:07:52.940 
we will quickly
skim through the

104
00:07:53.600 --> 00:07:56.160 
formal definitions
for completeness.

105
00:07:56.820 --> 00:08:01.950 
So we have a a set of languages
these are numbered and for

106
00:08:01.950 --> 00:08:04.340 
all of the
languages I can

107
00:08:05.730 --> 00:08:09.250 
I know whether an element
is inside or not

108
00:08:10.350 --> 00:08:17.150 
and this we call an indexed family.
So what does it mean? Okay I have

109
00:08:17.740 --> 00:08:19.620 
the this whole family
of languages.

110
00:08:20.510 --> 00:08:25.420 
Every language has a number and
for every of these languages

111
00:08:26.300 --> 00:08:28.840 
I have a function, a
computable function.

112
00:08:29.400 --> 00:08:32.360 
Now I have a computable function
such that for every of these

113
00:08:32.870 --> 00:08:37.030 
languages I can decide whether an
element is inside or not. So

114
00:08:37.030 --> 00:08:38.440 
this is what
this f does.

115
00:08:39.790 --> 00:08:45.060 
And for example we can look at
the family where for each k

116
00:08:46.060 --> 00:08:48.930 
Lk is simply the

117
00:08:49.590 --> 00:08:55.310 
set k times n, so on
multiples of k.

118
00:08:55.800 --> 00:09:01.220 
Ok and this we can write as an index
family and this would be the

119
00:09:02.030 --> 00:09:05.370 
computable function
which decides

120
00:09:06.080 --> 00:09:10.610 
whether the element
x is in the k

121
00:09:11.110 --> 00:09:17.220 
language, namely by saying
ok if x is a multiple of

122
00:09:17.220 --> 00:09:20.580 
k then it is in the language,
if not its not. Okay.

123
00:09:21.020 --> 00:09:24.910 
So we will be looking
at such families

124
00:09:25.750 --> 00:09:29.290 
and now when learning we
also said ok we need some

125
00:09:31.880 --> 00:09:37.240 
some numbering for the hypothesis
and this numbering will also be

126
00:09:37.660 --> 00:09:42.410 
an indexed family. So the
set up looks like this.

127
00:09:42.940 --> 00:09:47.720 
So we have an index family, these
will be be our languages we

128
00:09:47.720 --> 00:09:51.600 
are interested to learn and we
will have a hypothesis space.

129
00:09:51.600 --> 00:09:56.070 
So basically we say ok when
we get elements we or

130
00:09:56.530 --> 00:09:59.610 
data we say ok
this belongs to

131
00:10:00.410 --> 00:10:04.860 
hypothesis number five or something like
that and then we know ok we meant

132
00:10:05.480 --> 00:10:07.890 
H5, whatever
H5 then is.

133
00:10:08.830 --> 00:10:13.020 
Ok so both of these are
indexed families.

134
00:10:15.230 --> 00:10:18.910 
So now what does
it mean to learn

135
00:10:19.670 --> 00:10:22.330 
to learn L with
respect to H?

136
00:10:23.000 --> 00:10:28.360 
In particular to learn L with
respect to H from text

137
00:10:29.990 --> 00:10:31.940 
it means that
we have one

138
00:10:32.870 --> 00:10:36.020 
computable function which
we call a learner

139
00:10:36.450 --> 00:10:41.020 
which for every language and for a
retext of the language remember

140
00:10:41.020 --> 00:10:46.570 
a text is simply a list where all and
only the elements from that language

141
00:10:46.890 --> 00:10:51.630 
appear. So we have that every
element appears at least once.

142
00:10:51.930 --> 00:10:55.210 
However we do not know
whether it may appear twice

143
00:10:55.670 --> 00:11:00.170 
or even more. But it may it
has to appear once and

144
00:11:01.590 --> 00:11:04.050 
elements which do not
belong to the language

145
00:11:04.710 --> 00:11:09.430 
won't appear so that we know
that we've already seen.

146
00:11:10.110 --> 00:11:12.510 
And now we say
that uh H

147
00:11:13.540 --> 00:11:16.680 
TxtGEx learns L
with respect to

148
00:11:18.070 --> 00:11:23.720 
to the hypothesis space. This TxtGEx
is simply the abbreviation for

149
00:11:24.110 --> 00:11:26.360 
we're learning from text
we're explanatory

150
00:11:26.970 --> 00:11:31.070 
and we have full
information and

151
00:11:33.580 --> 00:11:38.330 
H learns L from text T
correctly if there exists an

152
00:11:38.960 --> 00:11:42.750 
j such that for all
but finitely many n

153
00:11:43.700 --> 00:11:51.090 
H makes this guess j or on text
T. So for example you can

154
00:11:51.090 --> 00:11:55.080 
imagine this like like we did in the beginning
right. So we got some information,

155
00:11:55.290 --> 00:11:59.250 
this was some information from a
text and we made some guesses.

156
00:11:59.250 --> 00:12:02.830 
Okay, so some of the guesses may be wrong,
some of the guesses may be right.

157
00:12:03.720 --> 00:12:06.300 
However from some
point onwards

158
00:12:07.320 --> 00:12:09.260 
we always have to
stick to one

159
00:12:10.280 --> 00:12:15.530 
and the same correct guess. So
what is written here is that we

160
00:12:15.530 --> 00:12:17.580 
have to stick
to one guess

161
00:12:18.580 --> 00:12:22.030 
and now this says also this
guess has to be correct. So

162
00:12:22.480 --> 00:12:28.560 
the chief hypothesis has to equal
the language we are learning.

163
00:12:28.830 --> 00:12:31.200 
And then we said say
that we learned

164
00:12:31.820 --> 00:12:36.260 
L correctly from text T and now if
you learn every language from

165
00:12:36.490 --> 00:12:38.580 
each of its texts
correctly

166
00:12:39.650 --> 00:12:43.230 
we say we learned the

167
00:12:44.010 --> 00:12:46.090 
family of languages L

168
00:12:46.810 --> 00:12:48.000 
with respect to H.

169
00:12:49.100 --> 00:12:54.080 
Okay and now we come so this we have
seen already in previous lectures.

170
00:12:54.650 --> 00:12:57.810 
Now we come to the
additional requirements.

171
00:12:58.500 --> 00:13:04.110 
And now we say a learner H
is consistent on a text T

172
00:13:04.700 --> 00:13:11.610 
if for every at every point
in time the content of the

173
00:13:11.610 --> 00:13:15.560 
text so far, so, that is what we
have seen so far, the elements

174
00:13:15.560 --> 00:13:19.850 
we have seen so far,
is a subset of the

175
00:13:20.770 --> 00:13:24.820 
hypothesis we make at this point.
So this is just a way to

176
00:13:24.820 --> 00:13:29.780 
write exactly down what what we
talked about. So at every point

177
00:13:30.370 --> 00:13:31.800 
if I want to be
consistent

178
00:13:32.710 --> 00:13:37.520 
I have to include the data I
have seen in my hypothesis.

179
00:13:38.360 --> 00:13:42.480 
Okay this is one restriction
we will be looking at

180
00:13:42.950 --> 00:13:47.670 
and another one is so called
being strongly monotone

181
00:13:48.250 --> 00:13:49.620 
abbreviated with S1

182
00:13:51.040 --> 00:13:56.170 
where the guesses may only grow,
so if I at some point make a

183
00:13:56.760 --> 00:14:03.950 
let's say, my guess is like, okay,
it's the element it's the set of

184
00:14:04.690 --> 00:14:06.190 
I don't know
all elements,

185
00:14:07.490 --> 00:14:13.170 
all multiples of four and then
later I may only make guesses

186
00:14:13.170 --> 00:14:16.960 
which include all these elements
I've guessed before. So I may

187
00:14:16.960 --> 00:14:20.370 
not say ok it's the
multiples of three,

188
00:14:21.230 --> 00:14:26.050 
because then I disregard many elements.
Okay and this is a problem.

189
00:14:26.280 --> 00:14:30.070 
Actually it's a problem if I disregard
one element. So many elements it's like

190
00:14:30.940 --> 00:14:32.860 
very much a problem and

191
00:14:33.920 --> 00:14:37.170 
so what it means to be
strongly monotone is

192
00:14:38.590 --> 00:14:40.710 
if I make a guess,
my next guess

193
00:14:41.400 --> 00:14:45.970 
may stay equal or has to become
larger. Okay so I may only add

194
00:14:45.970 --> 00:14:48.480 
elements. I may not
disregard elements

195
00:14:49.190 --> 00:14:51.590 
and we've also seen that
at the beginning.

196
00:14:52.390 --> 00:14:55.260 
And now just for the

197
00:14:56.260 --> 00:15:01.040 
for clarity or for
explanation, so to

198
00:15:02.070 --> 00:15:05.140 
get our everything together
we say that the learner

199
00:15:05.720 --> 00:15:11.350 
TxtGConsEx learns L with respect
to age now again this a

200
00:15:11.810 --> 00:15:16.240 
this TxtGConsEx may seem a bit
cryptic. However it simply

201
00:15:16.240 --> 00:15:21.690 
says ok I have the information
from text, the G stands for I

202
00:15:21.690 --> 00:15:26.830 
have full information, so I
can rely my hypothesis on

203
00:15:27.170 --> 00:15:29.550 
the order I saw the
elements in, and

204
00:15:30.440 --> 00:15:32.200 
which elements
exactly it were

205
00:15:32.950 --> 00:15:36.920 
cons a stands for consistency.
We've seen this

206
00:15:37.590 --> 00:15:39.650 
the abbreviation
here in the top

207
00:15:40.460 --> 00:15:44.010 
and Ex stands for ok we want
to learn explanatory.

208
00:15:44.750 --> 00:15:48.380 
This is just a way to write
things down. It will be nice at

209
00:15:48.390 --> 00:15:51.730 
the last slide because then we
can write things very nicely

210
00:15:51.730 --> 00:15:57.420 
in a very nice picture. Ok now what
does this mean? It simply means I

211
00:15:57.900 --> 00:16:02.940 
stick together each part of the definition
of k so for every language in the

212
00:16:03.360 --> 00:16:06.130 
class of language
and for every text

213
00:16:07.710 --> 00:16:12.060 
there I say it's a learned this
way if there exists in j

214
00:16:12.250 --> 00:16:15.820 
such that for all but finitely
many n, we have that we stick

215
00:16:15.820 --> 00:16:19.780 
to this j in our hypothesis.
We saw this this was part of

216
00:16:19.790 --> 00:16:21.400 
the TxtGEx learning.

217
00:16:22.500 --> 00:16:26.690 
And this has to be correct. This was
also part of the TxtGEx learning.

218
00:16:26.930 --> 00:16:29.500 
And now we add like a

219
00:16:30.560 --> 00:16:33.670 
like another
piece to that.

220
00:16:34.530 --> 00:16:40.440 
We add that this has to be
consistent on text T. Ok so as you

221
00:16:40.440 --> 00:16:43.320 
can see it's simply putting pieces
together. So you have like

222
00:16:43.660 --> 00:16:46.750 
this this kind of learning,
you have the requirements

223
00:16:47.070 --> 00:16:50.790 
and now you want to study both at the same
time just simply stick them together.

224
00:16:50.970 --> 00:16:54.110 
And that you can see also nicely
the definition is really just

225
00:16:54.730 --> 00:16:57.190 
putting pieces
together. And now

226
00:16:58.310 --> 00:17:02.400 
the same we could do for
S1 instead of cons or

227
00:17:02.700 --> 00:17:05.450 
even additionally to cons, that's
the nice thing right? We can

228
00:17:05.450 --> 00:17:06.760 
put pieces together as

229
00:17:07.410 --> 00:17:08.410 
we want basically.

230
00:17:10.030 --> 00:17:15.920 
Now we return to this so now we've
seen the formal definition.

231
00:17:15.920 --> 00:17:17.580 
Now we return to this

232
00:17:19.100 --> 00:17:21.220 
to the question we had at
the beginning, namely

233
00:17:22.390 --> 00:17:24.370 
if you look at each
of these free

234
00:17:24.980 --> 00:17:29.360 
learning types, so like
learning without requirement

235
00:17:30.100 --> 00:17:34.510 
without additional requirement,
this is the one on top. The H is

236
00:17:34.900 --> 00:17:39.340 
subscript is simply to indicate okay
we're learning with respect to some

237
00:17:39.920 --> 00:17:41.330 
hypothesis space

238
00:17:42.650 --> 00:17:44.380 
and then we
compare with

239
00:17:45.280 --> 00:17:47.980 
consistent and strongly
monotone case.

240
00:17:48.650 --> 00:17:53.580 
We may now see ok whatever
I can learn consistently,

241
00:17:54.300 --> 00:17:57.720 
I can also learn without requirement
right? I mean if I can

242
00:17:58.030 --> 00:18:00.660 
learn it with an additional
requirement I can also

243
00:18:01.070 --> 00:18:04.790 
in particular learn it without this
requirement. The same goes for

244
00:18:04.980 --> 00:18:06.980 
from strong
monotonicity.

245
00:18:08.210 --> 00:18:10.360 
However if I can learn
something strong

246
00:18:11.270 --> 00:18:16.490 
monotone it's not immediately
clear what I can learn

247
00:18:16.490 --> 00:18:18.700 
it consistently and
vice versa. Okay,

248
00:18:20.320 --> 00:18:24.760 
and now we return to the
question from the beginning

249
00:18:26.480 --> 00:18:29.980 
is does it to make a
difference if I add this

250
00:18:30.930 --> 00:18:33.640 
say consistency of
strong monotonicity?

251
00:18:34.190 --> 00:18:38.090 
And as it turns out in
this particular setting

252
00:18:38.500 --> 00:18:43.950 
consistency doesn't make a difference. So
uh this is uh indicated by this box.

253
00:18:46.420 --> 00:18:48.190 
It doesn't make
a difference.

254
00:18:48.850 --> 00:18:53.220 
We've seen that our initial idea
is simply to put our output the

255
00:18:53.340 --> 00:18:59.170 
smallest consistent hypothesis doesn't
work. So you actually need another idea,

256
00:18:59.970 --> 00:19:04.770 
namely, that you say okay I assume I can
learn something without requirement

257
00:19:05.280 --> 00:19:07.920 
and now I make it
consistent by

258
00:19:08.530 --> 00:19:13.750 
changing to the smallest consistent
hypothesis only if my original

259
00:19:13.750 --> 00:19:15.970 
lerner which was
without requirements

260
00:19:16.860 --> 00:19:21.450 
is inconsistent. And this then
works out because a once you

261
00:19:21.450 --> 00:19:24.500 
learn the language correctly, you
are consistent. So you don't

262
00:19:24.500 --> 00:19:26.490 
change this particular
hypothesis

263
00:19:28.060 --> 00:19:31.390 
but you change like all the
inconsistent hypotheses before.

264
00:19:31.680 --> 00:19:36.140 
Okay this works in this particular
setting. There are other

265
00:19:36.140 --> 00:19:39.390 
settings where this doesn't work or
other settings where this works again.

266
00:19:39.610 --> 00:19:42.630 
So it's a very
interesting thing.

267
00:19:43.610 --> 00:19:49.250 
And now the question is, okay, our initial
idea for consistency didn't work

268
00:19:49.370 --> 00:19:53.500 
now we have figured the way it
works. Can we do the same for a

269
00:19:54.290 --> 00:19:58.440 
strong monotonicity? And
the answer is actually no

270
00:19:59.220 --> 00:20:06.080 
because uh we can always trick
a strongly monotone learner

271
00:20:06.710 --> 00:20:12.670 
to output a larger set too early.
And then it cannot go back. Okay.

272
00:20:13.130 --> 00:20:16.850 
So we can wait for it to
output a large set,

273
00:20:17.480 --> 00:20:22.460 
then it cannot return and then we say ok
you should have returned. So we see

274
00:20:23.200 --> 00:20:26.160 
there are
restrictions which

275
00:20:26.930 --> 00:20:31.530 
actually restrict the learning power,
the what we can learn with a learner,

276
00:20:32.010 --> 00:20:35.290 
and there are restrictions with
which do not. For example here

277
00:20:35.530 --> 00:20:39.110 
strong monotonicity
and consistency and

278
00:20:40.590 --> 00:20:44.920 
this is quite interesting because
both of the restrictions

279
00:20:44.920 --> 00:20:48.790 
are fairly natural, right? I mean
being consistent with the data

280
00:20:48.790 --> 00:20:51.540 
you've seen is a natural thing,
if you learn something you try

281
00:20:51.540 --> 00:20:56.180 
to be consistent with it. If you on the
other hand if you learn something

282
00:20:56.580 --> 00:20:59.730 
try to stay strongly
monotone with it. You like

283
00:21:00.360 --> 00:21:04.870 
try to build up on that right? You
don't like disregard half of it

284
00:21:05.000 --> 00:21:05.770 
at some point.

285
00:21:07.030 --> 00:21:10.390 
And here the study shows
that some of those are

286
00:21:11.720 --> 00:21:16.100 
important and and actually
restricting you and some are not.
