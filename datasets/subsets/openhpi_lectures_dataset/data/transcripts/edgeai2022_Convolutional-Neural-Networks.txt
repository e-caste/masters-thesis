WEBVTT

1
00:00:00.540 --> 00:00:01.760 
Hello and welcome.

2
00:00:02.339 --> 00:00:08.259 
This video will briefly present the basic working ideas of convolutional neural networks.

3
00:00:10.740 --> 00:00:19.050 
Convolutional neural network is one of the amazing technologies that bring us many breakthroughs in the current AI revolution.

4
00:00:19.839 --> 00:00:29.039 
For example, beating human champions in strategy game, surpassing human performance in various computer vision tasks. Confidence

5
00:00:29.050 --> 00:00:37.759 
are widely used in various applications such as autonomous driving, medical imaging, material science and so on and so forth.

6
00:00:39.539 --> 00:00:43.060 
Another proof of the performance of CompNets.

7
00:00:43.920 --> 00:00:50.460 
Let's briefly look at the previous champion algorithms of ImageNet challenge.

8
00:00:51.039 --> 00:01:02.259 
We can see that starting from AlexNet In 2012, the champions are all CompNets with different architectures. Compared with

9
00:01:02.259 --> 00:01:03.899 
the traditional methods,

10
00:01:03.909 --> 00:01:11.959 
they have a great improvement in accuracy by more than 20% compared to the previous approach.

11
00:01:12.439 --> 00:01:21.390 
CompNet has achieved many seemingly amazing results. However, in fact, its principle is very simple.

12
00:01:21.530 --> 00:01:26.640 
So let's briefly recap it.

13
00:01:26.640 --> 00:01:31.870 
For convolution computation, there is an input image and await filter.

14
00:01:31.879 --> 00:01:37.049 
Normally they have three dimensions namely width heights and depths.

15
00:01:37.640 --> 00:01:40.459 
The depth here means the number of channels.

16
00:01:41.239 --> 00:01:44.370 
Convolution computation is actually used

17
00:01:44.370 --> 00:01:55.010 
the weight filter to slice over the input image especially and compute the dot products. Dot product means the pixel wise

18
00:01:55.010 --> 00:01:57.959 
multiplication and then sum them up.

19
00:01:58.609 --> 00:02:06.540 
In this example, the input image has the dimension of 32 x 32 x 3.

20
00:02:06.540 --> 00:02:09.659 
And the filter size is 5 x 5 x 3.

21
00:02:11.439 --> 00:02:22.039 
We can calculate the output dimension according to this formula. And in this case the output size is 28 x 28. By using the

22
00:02:22.039 --> 00:02:23.250 
Strike Equal one.

23
00:02:26.539 --> 00:02:29.330 
This just generate one output feature map.

24
00:02:29.340 --> 00:02:39.240 
If there are 4 weight filters, then output feature map channels increases to 4.

25
00:02:39.240 --> 00:02:41.210 
In convolutional neural networks,

26
00:02:41.310 --> 00:02:45.449 
we often talk about the concept of receptive field.

27
00:02:46.039 --> 00:02:50.759 
What is this receptive field? Actually, it is very simple.

28
00:02:51.240 --> 00:02:59.550 
That is the number of related pixels in the input tensor corresponding to each pixel in the output feature map.

29
00:02:59.939 --> 00:03:06.560 
Obviously, this actually equals the total number of pixels of the weight filters.

30
00:03:07.340 --> 00:03:15.560 
In this example, the size of the receptive field is 5 x 5 x 3 equals 75.

31
00:03:18.439 --> 00:03:22.360 
This animation intuitively shows the process of convolution.

32
00:03:22.840 --> 00:03:28.900 
We can see that the three input channels correspond to the 3 filter channels.

33
00:03:28.909 --> 00:03:40.479 
Each step the convolution view recalculate the pixel wise product and then sum the results and finally it adds a bias parameter

34
00:03:40.479 --> 00:03:49.860 
to generate pixel value of the output map. Filters can scan the entire space of the input image.

35
00:03:51.639 --> 00:04:01.750 
Next, let's take a look at how to perform padding and stride operation in the convolutional layer. Giving a 7 x 7 input.

36
00:04:02.639 --> 00:04:11.060 
So if we use the 3 x 3 filter with stride equals one, then we will get a 5 x 5 output map.

37
00:04:13.639 --> 00:04:19.850 
If the stride equals 2 then then we will gather 3 x 3 output feature map.

38
00:04:22.139 --> 00:04:22.860 
Now,

39
00:04:23.240 --> 00:04:31.160 
the problem comes if the stride equals three, then the input map is too small to get a valid result.

40
00:04:32.639 --> 00:04:34.269 
How should we do here?

41
00:04:34.329 --> 00:04:37.759 
In this case we just need to introduce the padding.

42
00:04:38.139 --> 00:04:39.670 
So this is a few

43
00:04:39.680 --> 00:04:44.889 
pixels whose value is zero on the boundary of the input map.

44
00:04:44.899 --> 00:04:48.139 
To expand the range of the input feature map.

45
00:04:48.149 --> 00:04:58.389 
In this example, when the stride equals equals three, we only need to add padding, one equals one to successfully complete

46
00:04:58.389 --> 00:05:03.459 
the convolution operation And we will get a 3 x 3 output feature map.

47
00:05:05.040 --> 00:05:13.480 
In addition to zero padding, the commonly used the padding methods also include repeating boundary pixel for the padding

48
00:05:13.490 --> 00:05:17.060 
reflection padding and constant value pad.

49
00:05:20.600 --> 00:05:22.550 
The responsible ideas.

50
00:05:22.939 --> 00:05:32.990 
In the reasonable direction can help us to learn the knowledge more effectively and the reasonable ideas and direction

51
00:05:33.000 --> 00:05:34.779 
are so called prior

52
00:05:34.790 --> 00:05:42.259 
in the context of machine learning. Prior knowledge is generally important for machine learning models.

53
00:05:42.269 --> 00:05:51.029 
one may want to ask this question why CompNets works much better than other deep deep neural network or other machine learning

54
00:05:51.029 --> 00:05:53.160 
methods in computer vision problem.

55
00:05:53.939 --> 00:06:00.360 
An intuitive explanation is that CompNets have a strong prior, the locality.

56
00:06:00.839 --> 00:06:06.699 
It can learn local context very well and then converge to the global context.

57
00:06:07.240 --> 00:06:16.629 
Why gradient boosting or random forest methods are better than CompNets in the cargo challenge for table data or other structure

58
00:06:16.629 --> 00:06:17.060 
data?

59
00:06:17.540 --> 00:06:24.339 
A possible reason might be table data lacks of local correlations.

60
00:06:24.339 --> 00:06:25.370 
In this video

61
00:06:25.379 --> 00:06:29.660 
we have been talking about how the convolutional neural network works.

62
00:06:30.040 --> 00:06:34.899 
We introduced the basic operations of the convolutional neural network.

63
00:06:34.910 --> 00:06:40.449 
We learn how to compute its primitives and how to utilize stride and padding.

64
00:06:40.939 --> 00:06:51.639 
We offer a brief explanation of the characteristics like weight sharing and the important prior of CompNets.

65
00:06:51.639 --> 00:06:53.759 
In the practical session of this week,

66
00:06:54.339 --> 00:07:03.360 
so as I already introduced in the first video, we will have a practical task for each week we will learn how to implement

67
00:07:03.370 --> 00:07:11.250 
and suggested gradient descent and complete the training loop of a neural network from scratch in the first week.

68
00:07:12.339 --> 00:07:22.220 
So Joseph will work with you to complete this task in the next video and this time required for complete practical task is

69
00:07:22.220 --> 00:07:24.250 
about 2-3 hours.

70
00:07:24.839 --> 00:07:28.459 
So I wish you all have fun and great success.

71
00:07:31.240 --> 00:07:32.350 
Thank you for watching.
