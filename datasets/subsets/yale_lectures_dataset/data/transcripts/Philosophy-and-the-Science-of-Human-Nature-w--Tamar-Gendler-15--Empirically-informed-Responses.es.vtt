WEBVTT
Kind: captions
Language: es

00:00:01.633 --> 00:00:08.100
Catedrática Tamar Gendler: La
última clase nos quedamos

00:00:08.100 --> 00:00:11.900
con una situación un poco
desconcertante.

00:00:11.900 --> 00:00:16.700
Analizamos los escenarios particulares

00:00:16.700 --> 00:00:21.033
que Judy Thomson plantea en su
documento del tranvía.

00:00:21.033 --> 00:00:24.633
Y descubrimos un rasgo
aparentemente desconcertante

00:00:24.633 --> 00:00:28.300
en las respuestas que ustedes dieron.

00:00:28.300 --> 00:00:33.333
En el llamado caso clásico
del transeúnte,

00:00:33.333 --> 00:00:38.167
donde un transeúnte está parado
al lado de un tranvía,

00:00:38.167 --> 00:00:42.267
que se dirige hacia 5 personas,

00:00:42.267 --> 00:00:46.067
y el transeúnte puede
desviarlo a otra vía

00:00:46.067 --> 00:00:49.000
para que choque solo contra una persona,

00:00:49.000 --> 00:00:52.200
ustedes respondieron lo siguiente:

00:00:52.200 --> 00:00:55.967
Más o menos el 15% pensaba que
era moralmente obligatorio

00:00:55.967 --> 00:00:58.933
desviar el tranvía de las
5 personas a 1.

00:00:58.933 --> 00:01:02.900
El 70% pensaba que estaba
moralmente permitido desviarlo.

00:01:02.900 --> 00:01:07.833
Y solo el 15% pensaba que
estaba moralmente prohibido

00:01:07.833 --> 00:01:11.933
desviarlo de las 5 personas a 1.

00:01:11.933 --> 00:01:15.367
Por otra parte, terminamos la clase

00:01:15.367 --> 00:01:18.667
con el famoso caso de
Thomson del hombre gordo.

00:01:18.667 --> 00:01:23.500
En este caso, el transeúnte está
parado al lado del tranvía,

00:01:23.500 --> 00:01:27.867
que va en dirección a
matar a 5 personas,

00:01:27.867 --> 00:01:33.333
y el transeúnte tiene a su
disposición algún medio para
detenerlo.

00:01:33.333 --> 00:01:36.467
En vez de desviar el
tranvía a otra vía,

00:01:36.467 --> 00:01:41.833
el medio disponible es tirar al
hombre gordo desde un puente

00:01:41.833 --> 00:01:44.967
y así detener al tranvía en su vía.

00:01:44.967 --> 00:01:47.733
En este caso,

00:01:47.733 --> 00:01:53.433
sus respuestas fueron muy
distintas a las del primer caso.

00:01:53.433 --> 00:01:56.567
Mientras que en el primer
caso el 15% pensaba

00:01:56.567 --> 00:02:00.933
que estaba prohibido desviar el tranvía

00:02:00.933 --> 00:02:04.400
para que matara a 1 persona en vez de 5;

00:02:04.400 --> 00:02:12.300
en el caso del hombre gordo, el
78%, 4/5 partes de la clase,

00:02:12.300 --> 00:02:16.733
pensaba que usar a otra persona para
desviar o detener el tranvía

00:02:16.733 --> 00:02:22.800
estaba moralmente prohibido.

00:02:22.800 --> 00:02:24.833
El problema que esto plantea,

00:02:24.833 --> 00:02:27.367
como vimos al final de la clase pasada,

00:02:27.367 --> 00:02:32.567
es que al parecer en ambos
casos del transeúnte…

00:02:32.567 --> 00:02:36.167
¡Lo siento! El problema es: En
el caso del transeúnte,

00:02:36.167 --> 00:02:43.000
parece que la mayoría tiene claro que
matar a una persona es malo,

00:02:43.000 --> 00:02:47.600
pero dejar que 5 mueran es peor.

00:02:47.600 --> 00:02:50.533
Mientras que en el caso
del hombre gordo,

00:02:50.533 --> 00:02:54.367
parece justo lo contrario.

00:02:54.367 --> 00:02:58.800
Thomson nos pregunta al
final de ese documento,

00:02:58.800 --> 00:03:00.700
después de haber visto varios casos,

00:03:00.700 --> 00:03:04.500
incluyendo algunos que no he
mencionado en este resumen:

00:03:04.500 --> 00:03:08.367
¿Cómo se pueden explicar
nuestras diferentes reacciones

00:03:08.367 --> 00:03:11.200
en el caso del transeúnte y en
el caso del hombre gordo?

00:03:11.200 --> 00:03:12.567
Ella sugiere que

00:03:12.567 --> 00:03:19.967
mientras la utilidad prohíbe
dejar morir a 5, es decir,

00:03:19.967 --> 00:03:24.900
que sería mejor cuantitativamente
salvar 5 vidas en vez de 1,

00:03:24.900 --> 00:03:31.033
la idea del derecho prohíbe
matar a una persona

00:03:31.033 --> 00:03:33.000
en el caso del hombre gordo.

00:03:33.000 --> 00:03:36.500
Thomson sugiere que en el
caso del hombre gordo,

00:03:36.500 --> 00:03:39.433
se interfiere con sus derechos

00:03:39.433 --> 00:03:44.233
al usarlo como un medio para alcanzar el
fin de salvar a otras personas.

00:03:44.233 --> 00:03:52.900
Mientras que en el caso del
transeúnte, no se viola ningún
derecho.

00:03:52.900 --> 00:03:58.100
Thomson sugiere que "los derechos son
más importantes que la utilidad".

00:03:58.100 --> 00:04:01.033
Es obligatorio apegarse

00:04:01.033 --> 00:04:05.800
a lo que el derecho prohíbe en
el caso del hombre gordo.

00:04:05.800 --> 00:04:11.567
Ahí fue donde nos quedamos al
final de la clase pasada.

00:04:11.567 --> 00:04:16.633
La solución que Thomson proponía
era lo que llamaríamos

00:04:16.633 --> 00:04:20.633
una solución clásica a dilemas
similares al del tranvía.

00:04:20.633 --> 00:04:24.300
Es una solución que asume que
el caso del hombre gordo

00:04:24.300 --> 00:04:28.267
y el del transeúnte tienen
obligaciones morales diferentes

00:04:28.267 --> 00:04:31.567
debido a una diferencia moral profunda

00:04:31.567 --> 00:04:37.767
codificada en esos casos.

00:04:37.767 --> 00:04:41.033
La diferencia entre nuestra
respuesta al caso del hombre gordo

00:04:41.033 --> 00:04:42.500
y al del transeúnte,

00:04:42.500 --> 00:04:45.433
dice Thomson en su artículo de 1985,

00:04:45.433 --> 00:04:47.433
es una diferencia que debemos respetar.

00:04:47.433 --> 00:04:51.767
Y debemos respetar dicha diferencia

00:04:51.767 --> 00:04:58.067
porque obedece a una
diferencia moral profunda,

00:04:58.067 --> 00:05:00.333
concretamente en el caso
del hombre gordo,

00:05:00.333 --> 00:05:02.200
pero no en el caso del transeúnte,

00:05:02.200 --> 00:05:06.333
se violan los derechos de un individuo.

00:05:06.333 --> 00:05:11.933
En la clase de hoy quiero explicarles

00:05:11.933 --> 00:05:17.633
3 respuestas no clásicas al
caso del tranvía.

00:05:17.633 --> 00:05:20.600
Podrán usar sus clickers

00:05:20.600 --> 00:05:24.333
en la primera y en la tercera.

00:05:24.333 --> 00:05:25.600
Vayan preparando sus clickers

00:05:25.600 --> 00:05:28.567
para lo que va a pasar en los
próximos minutos.

00:05:28.567 --> 00:05:30.867
¿Cuáles son las 3
respuestas no clásicas?

00:05:30.867 --> 00:05:33.000
Recuerden, en una respuesta clásica,

00:05:33.000 --> 00:05:34.967
se afirma que el caso del hombre
gordo y el del transeúnte

00:05:34.967 --> 00:05:36.533
tienen distintos mandatos morales

00:05:36.533 --> 00:05:39.167
y esa es una diferencia

00:05:39.167 --> 00:05:41.267
moralmente relevante entre ellos.

00:05:41.267 --> 00:05:45.300
Hoy vamos a analizar 2 respuestas

00:05:45.300 --> 00:05:48.467
que sugieren que el caso del hombre
gordo y el del transeúnte

00:05:48.467 --> 00:05:52.167
no tienen distintos mandatos morales.

00:05:52.167 --> 00:05:56.133
El primer ejemplo que les voy a explicar

00:05:56.133 --> 00:06:00.700
es una reconsideración de Judy
Thomson de los casos del tranvía,

00:06:00.700 --> 00:06:06.233
en un documento de 2008 en el
que termina por asimilar

00:06:06.233 --> 00:06:10.367
el caso del transeúnte con
el del hombre gordo.

00:06:10.367 --> 00:06:15.833
Y propone que en ninguno de los
casos está permitido

00:06:15.833 --> 00:06:18.767
matar a 1 persona para salvar a 5.

00:06:18.767 --> 00:06:24.300
El segundo ejemplo que
veremos es de Josh Greene,

00:06:24.300 --> 00:06:27.900
que dice que lo correcto en ambos casos,

00:06:27.900 --> 00:06:32.100
el del hombre gordo y el
del transeúnte,

00:06:32.100 --> 00:06:38.400
es evitar que el tranvía
choque contra 5 personas

00:06:38.400 --> 00:06:42.733
y hacer que a cambio mate a 1 persona.

00:06:42.733 --> 00:06:46.833
Por último, estoy forzando
esto porque en realidad

00:06:46.833 --> 00:06:50.433
Sunstein coincide más con
Greene que con Thomson.

00:06:50.433 --> 00:06:56.933
Pero podríamos usar su idea
para mantener la postura

00:06:56.933 --> 00:07:01.067
de que aunque nuestras respuestas
difieren en ambos casos,

00:07:01.067 --> 00:07:06.233
los casos son básicamente iguales.

00:07:06.233 --> 00:07:07.933
Sunstein va a sugerir

00:07:07.933 --> 00:07:10.433
que aventemos al hombre gordo.

00:07:10.433 --> 00:07:13.867
Entonces, aquí tenemos 3
visiones distintas.

00:07:13.867 --> 00:07:15.700
Thomson dice que los casos
coinciden en decirnos

00:07:15.700 --> 00:07:20.267
que nunca debemos matar a 1
persona para salvar a 5.

00:07:20.267 --> 00:07:22.300
Greene dice que los casos
coinciden en decirnos

00:07:22.300 --> 00:07:26.933
que siempre debemos matar a 1
persona para salvar a 5.

00:07:26.933 --> 00:07:30.000
Y tal vez, la idea de Sunstein

00:07:30.000 --> 00:07:32.833
nos dice que los casos no coinciden.

00:07:32.833 --> 00:07:35.633
Estas 3 respuestas no
clásicas son interesantes

00:07:35.633 --> 00:07:38.133
no solo por su contenido diferente,

00:07:38.133 --> 00:07:43.100
pienso que también nos
sirven en esta clase

00:07:43.100 --> 00:07:47.200
porque cada una usa una
metodología de argumentación

00:07:47.200 --> 00:07:50.367
un poco distinta.

00:07:50.367 --> 00:07:54.000
Y no hay razón para que las
metodologías y las respuestas

00:07:54.000 --> 00:07:56.633
se alinearan de la forma
que lo hicieron.

00:07:56.633 --> 00:08:00.033
Una cosa que quiero que piensen,

00:08:00.033 --> 00:08:02.033
en la clase de hoy,

00:08:02.033 --> 00:08:07.300
es cómo podríamos usar cada una
de estas metodologías

00:08:07.300 --> 00:08:10.300
para hacer uno de los
argumentos alternativos.

00:08:10.300 --> 00:08:12.367
Thomson opina

00:08:12.367 --> 00:08:16.467
que no deberíamos desviar el tranvía
en el caso del transeúnte,

00:08:16.467 --> 00:08:20.833
y nos invita,

00:08:20.833 --> 00:08:22.533
igual que yo lo haré más adelante,

00:08:22.533 --> 00:08:26.000
a considerar casos
hipotéticos adicionales.

00:08:26.000 --> 00:08:32.867
Después, les pide que sean
consistentes con sus respuestas

00:08:32.867 --> 00:08:38.667
en los casos que no difieren
en sentido moral.

00:08:38.667 --> 00:08:40.533
La metodología de Thomson

00:08:40.533 --> 00:08:43.233
es la misma que usó en su
documento de 1985,

00:08:43.233 --> 00:08:46.533
solo ha agregado un nuevo caso.

00:08:46.533 --> 00:08:48.967
La metodología de Sunstein

00:08:48.967 --> 00:08:52.633
es agrupar una gran
selección de literatura

00:08:52.633 --> 00:08:54.833
bajo la tradición del sesgo
y la heurística,

00:08:54.833 --> 00:08:57.900
y sugiere que el razonamiento moral

00:08:57.900 --> 00:09:02.333
no es diferente a ningún
otro razonamiento.

00:09:02.333 --> 00:09:05.367
El método de Josh Greene

00:09:05.367 --> 00:09:11.000
obviamente es usar los
resultados de neuroimágenes

00:09:11.000 --> 00:09:18.333
para argumentar su postura de que
se nos exige moralmente

00:09:18.333 --> 00:09:21.100
tener una cierta postura utilitaria.

00:09:21.100 --> 00:09:25.033
Van a necesitar sus clickers.

00:09:25.033 --> 00:09:29.033
Comencemos con los otros
casos hipotéticos

00:09:29.033 --> 00:09:32.900
que convencieron a Judy Thomson, y
podrían convencerlos a ustedes,

00:09:32.900 --> 00:09:37.867
de que no está bien desviar el
tranvía en el caso del transeúnte.

00:09:37.867 --> 00:09:42.067
El caso que Thomson nos presenta

00:09:42.067 --> 00:09:45.667
lo llamaremos las tres
opciones del transeúnte.

00:09:45.667 --> 00:09:47.767
Aquí está el pobre Jim,

00:09:47.767 --> 00:09:52.533
arrepintiéndose de haberse
inscrito a esta clase,

00:09:52.533 --> 00:09:57.233
en el dilema clásico,

00:09:57.233 --> 00:09:59.000
parado al lado del tranvía que va a
chocar contra 5 personas,

00:09:59.000 --> 00:10:02.267
pero Jim puede desviarlo para
que choque contra 1.

00:10:02.267 --> 00:10:09.200
Como Jim vive en un experimento
mental de Judy Thomson,

00:10:09.200 --> 00:10:12.300
ella ha ideado, de forma un poco ruin,

00:10:12.300 --> 00:10:17.067
poner una tercera vía al
final de la cual,

00:10:17.067 --> 00:10:23.533
desafortunadamente para Jim,
está él parado.

00:10:23.533 --> 00:10:28.500
Este es el dilema de las 3
opciones de Jim:

00:10:28.500 --> 00:10:38.500
1.Dejar que el tranvía
continúe su trayecto original

00:10:38.500 --> 00:10:41.867
y mate a las 5 personas.

00:10:41.867 --> 00:10:50.867
2. Desviar el tranvía para que
choque contra la otra persona.

00:10:50.867 --> 00:10:55.600
3.Desviar el tranvía para que no
choque contra las 5 personas,

00:10:55.600 --> 00:10:59.500
sino contra Jim.

00:10:59.500 --> 00:11:04.600
Pregunta: En las 3 opciones
del transeúnte,

00:11:04.600 --> 00:11:08.733
vamos a ignorar la opción de dejar

00:11:08.733 --> 00:11:11.367
que choque contra las 5 personas,

00:11:11.367 --> 00:11:17.800
supongamos que Jim ha decidido desviar
el tranvía, la pregunta es:

00:11:17.800 --> 00:11:22.867
¿Es moralmente obligatorio
que desvíe el tranvía

00:11:22.867 --> 00:11:26.833
a la vía donde hay otra
persona en vez de él?

00:11:26.833 --> 00:11:31.100
¿Está moralmente permitido, pero
no es moralmente obligatorio

00:11:31.100 --> 00:11:33.867
que lo desvíe a la vía

00:11:33.867 --> 00:11:36.733
donde está otra persona en vez de él?

00:11:36.733 --> 00:11:42.000
¿O está moralmente
prohibido que lo desvíe

00:11:42.000 --> 00:11:45.167
hacia la otra persona en vez de él?

00:11:45.167 --> 00:11:48.467
Estamos asumiendo que Jim ha
tomado la decisión

00:11:48.467 --> 00:11:49.867
de desviar el tranvía de
las 5 personas.

00:11:49.867 --> 00:11:53.333
Después de todo, es un caso
convencional del transeúnte.

00:11:53.333 --> 00:11:56.267
Si no desvía el tranvía, va a
chocar contra 5 personas.

00:11:56.267 --> 00:12:01.233
El 78% había dicho antes
que en este caso

00:12:01.233 --> 00:12:04.467
se debía o que por lo menos estaba
permitido desviar el tranvía.

00:12:04.467 --> 00:12:07.833
¿Por qué nadie ha respondido?

00:12:07.833 --> 00:12:09.867
Alumnos: [voces interrumpiendo]

00:12:09.867 --> 00:12:11.800
Catedrática Tamar Gendler: ¿No
funciona? ¡Dios mío!

00:12:11.800 --> 00:12:14.467
Bien. ¿Por qué no está
abierta para ustedes?

00:12:14.467 --> 00:12:15.100
Vamos a intentarlo.

00:12:15.100 --> 00:12:16.233
¿Ahora está abierta?

00:12:16.233 --> 00:12:17.367
Alumno: No.

00:12:17.367 --> 00:12:18.167
Catedrática Tamar Gendler: Es terrible.

00:12:18.167 --> 00:12:21.000
Realmente es algo muy horrible.

00:12:21.000 --> 00:12:22.267
Eso no funcionó.

00:12:22.267 --> 00:12:28.233
Toda la clase de hoy depende
de que esto funcione.

00:12:28.233 --> 00:12:29.900
Vamos a volver a intentarlo.

00:12:29.900 --> 00:12:35.967
Díganme si funciona.

00:12:35.967 --> 00:12:37.733
¿Funciona?

00:12:37.733 --> 00:12:39.233
Ok.

00:12:39.233 --> 00:12:49.467
¿Ahora? ¿No? ¿Todavía no? ¿No?

00:12:49.467 --> 00:12:54.667
Bien. Mmm. Vamos a...

00:12:54.667 --> 00:12:58.667
Pienso que no puedo hacer nada.

00:12:58.667 --> 00:13:03.200
Voy a intentar reiniciar una vez
más y a ver si funciona.

00:13:03.200 --> 00:13:07.467
Voy a intentar eliminar y
después regresar el receptor.

00:13:07.467 --> 00:13:11.000
Si no funciona, lo haremos a la antigua,

00:13:11.000 --> 00:13:14.200
levantando la mano y mis
maravillosas diapositivas

00:13:14.200 --> 00:13:17.900
no habrán servido de nada,
pero no importa.

00:13:17.900 --> 00:13:20.467
Peores cosas han pasado en el mundo.

00:13:20.467 --> 00:13:22.767
Bien. Vuelvan a intentar.

00:13:22.767 --> 00:13:24.233
¡Sí! Genial.

00:13:24.233 --> 00:13:25.633
No tengo idea de qué hice.

00:13:25.633 --> 00:13:27.800
Ok. Respondiendo a la pregunta.

00:13:27.800 --> 00:13:29.267
¡Vaya! Hay 64 respuestas.

00:13:29.267 --> 00:13:30.300
Hay 71 respuestas.

00:13:30.300 --> 00:13:31.400
Hagamos la cuenta regresiva.

00:13:31.400 --> 00:13:36.467
10, 9, 8... Veamos cómo
salen los resultados.

00:13:36.467 --> 00:13:41.167
4, 3, 2, 1... ¡Qué emocionante!

00:13:41.167 --> 00:13:43.100
Especialmente porque primero sufrimos.

00:13:43.100 --> 00:13:44.100
El contraste.

00:13:44.100 --> 00:13:46.933
Ok. En este caso,

00:13:46.933 --> 00:13:50.533
el 6% piensa que es
moralmente obligatorio

00:13:50.533 --> 00:13:52.767
que Jim desvíe el tranvía
hacia la otra persona.

00:13:52.767 --> 00:13:57.833
Pero ustedes son el 6%
fuera de lo común,

00:13:57.833 --> 00:13:58.900
tal vez son gente muy distinta.

00:13:58.900 --> 00:14:00.700
Pero veamos qué está pasando.

00:14:00.700 --> 00:14:04.333
El 61% piensa que está
moralmente permitido

00:14:04.333 --> 00:14:06.767
que desvíe el tranvía
hacia la otra persona.

00:14:06.767 --> 00:14:12.100
Y el 32% piensa que está
moralmente prohibido

00:14:12.100 --> 00:14:14.100
que lo desvíe.

00:14:14.100 --> 00:14:17.767
Curiosamente, Judy Thomson espera

00:14:17.767 --> 00:14:22.133
que más personas caigan en
esta categoría.

00:14:22.133 --> 00:14:26.500
Es interesante que pensemos como grupo

00:14:26.500 --> 00:14:29.667
por qué ella tiene la impresión

00:14:29.667 --> 00:14:36.367
de que la respuesta que ustedes
dieron es un poco sorprendente.

00:14:36.367 --> 00:14:40.667
Bueno, pasemos a otro caso para comparar

00:14:40.667 --> 00:14:42.000
y veamos qué pasa.

00:14:42.000 --> 00:14:47.833
Ok. Supongamos que ahora solo
tienen un caso con 2 opciones.

00:14:47.833 --> 00:14:53.800
En el caso del transeúnte con 2
opciones, Jim solo tiene 2 opciones.

00:14:53.800 --> 00:14:58.100
El tranvía va a chocar
contra 5 personas

00:14:58.100 --> 00:15:03.033
o puede desviarlo para que
choque contra él.

00:15:03.033 --> 00:15:06.900
Quiero regresar para anotar los
números de la diapositiva pasada,

00:15:06.900 --> 00:15:13.233
olvidé anotarlos porque estaba
confundida con nuestra situación.

00:15:13.233 --> 00:15:16.700
Permítanme apuntar esto. 6%, 61% y 32%.

00:15:16.700 --> 00:15:18.900
Ok. Pasemos al nuevo caso.

00:15:18.900 --> 00:15:21.200
Es un caso de tranvía con 2
opciones y la pregunta es:

00:15:21.200 --> 00:15:23.500
En el caso del transeúnte
con dos opciones,

00:15:23.500 --> 00:15:26.667
¿es moralmente obligatorio
que el transeúnte deje

00:15:26.667 --> 00:15:28.233
que el tranvía choque contra las 5
personas en vez de contra él?,

00:15:28.233 --> 00:15:33.400
¿está moralmente permitido?

00:15:33.400 --> 00:15:39.533
o ¿está moralmente prohibido?

00:15:39.533 --> 00:15:42.000
¿De acuerdo? Analicemos ese caso.

00:15:42.000 --> 00:15:43.433
Recuerden que es un caso con 2 opciones.

00:15:43.433 --> 00:15:45.233
El tranvía se dirige hacia 5 personas.

00:15:45.233 --> 00:15:46.500
La pregunta es:

00:15:46.500 --> 00:15:51.033
¿Es obligatorio, está permitido o
está prohibido desviar el tranvía

00:15:51.033 --> 00:15:55.200
para que vaya contra él en vez
de contra las 5 personas?

00:15:55.200 --> 00:15:59.133
Ok. Veamos los resultados.

00:15:59.133 --> 00:16:01.867
Tenemos 10 segundos aproximadamente

00:16:01.867 --> 00:16:06.367
para descubrir si la distribución
será similar o distinta.

00:16:08.900 --> 00:16:14.933
Estos son los resultados: 8%, 70% y 22%.

00:16:14.933 --> 00:16:19.433
Esto queremos compararlo

00:16:19.433 --> 00:16:23.767
con el caso clásico del transeúnte.

00:16:23.767 --> 00:16:26.267
En el caso clásico del transeúnte,

00:16:26.267 --> 00:16:29.633
más personas pensaban que era
moralmente obligatorio

00:16:29.633 --> 00:16:34.000
desviar el tranvía a
diferencia de este caso.

00:16:34.000 --> 00:16:36.967
En el caso clásico del
transeúnte, curiosamente,

00:16:36.967 --> 00:16:39.067
pensaban más o menos igual al respecto

00:16:39.067 --> 00:16:42.500
de si estaba moralmente permitido.

00:16:42.500 --> 00:16:47.867
Y más personas piensan que está
moralmente prohibido que deje

00:16:47.867 --> 00:16:50.600
que el tranvía choque contra las 5
personas en vez de contra él.

00:16:50.600 --> 00:16:54.067
Esta es la diferencia interesante.

00:16:54.067 --> 00:16:59.133
Tuvieron una actitud distinta sobre
si es moralmente obligatorio

00:16:59.133 --> 00:17:03.100
desviar el tranvía cuando la
persona contra la que va a chocar

00:17:03.100 --> 00:17:07.600
es él mismo o cuando se
trata de otra persona.

00:17:07.600 --> 00:17:13.167
Volvamos a hacer un caso clásico del
transeúnte para descubrir,

00:17:13.167 --> 00:17:15.900
si como resultado de haber
analizado este caso,

00:17:15.900 --> 00:17:18.667
hay un cambio en sus intuiciones.

00:17:18.667 --> 00:17:22.600
Este es simplemente el caso típico
del transeúnte que ya conocen.

00:17:22.600 --> 00:17:26.100
En el caso clásico del
transeúnte con 2 opciones,

00:17:26.100 --> 00:17:29.967
¿es moralmente obligatorio,
está moralmente permitido

00:17:29.967 --> 00:17:33.933
o está moralmente prohibido que
Jim desvíe el tranvía?

00:17:46.133 --> 00:17:50.433
Quedan 3, 2, 1.

00:17:50.433 --> 00:17:52.867
Veamos los resultados.

00:17:52.867 --> 00:17:55.967
20%, 65% y 15%.

00:17:55.967 --> 00:18:01.933
Como resultado de haber pensado en la
analogía de la primera persona,

00:18:01.933 --> 00:18:05.300
algunos han cambiado su opinión,

00:18:05.300 --> 00:18:09.600
pero menos de los que yo pensaba.

00:18:09.600 --> 00:18:12.833
Mientras originalmente, el 15% pensaba

00:18:12.833 --> 00:18:15.433
que era moralmente obligatorio
desviar el tranvía,

00:18:15.433 --> 00:18:16.600
ahora cambiaron de parecer

00:18:16.600 --> 00:18:19.700
justo en la dirección contraria
de lo que yo esperaba.

00:18:19.700 --> 00:18:21.133
Tenemos un misterio.

00:18:21.133 --> 00:18:23.333
Tenemos un poco de
filosofía experimental

00:18:23.333 --> 00:18:24.633
hecha en nuestro salón de clases.

00:18:24.633 --> 00:18:28.067
Thomson pronosticaba que...

00:18:28.067 --> 00:18:30.967
Y veremos en las secciones
por qué no fue así.

00:18:30.967 --> 00:18:36.000
Thomson pronosticaba que
actuarían de esta otra forma.

00:18:36.000 --> 00:18:38.667
Si no es moralmente obligatorio

00:18:38.667 --> 00:18:40.833
que desvíe el tranvía hacia mí mismo,

00:18:40.833 --> 00:18:43.200
entonces no es moralmente obligatorio,

00:18:43.200 --> 00:18:50.767
ni está moralmente permitido que lo
desvíe hacia otra persona.

00:18:50.767 --> 00:18:56.433
Si yo no estoy dispuesto a
recibir el golpe en ese caso,

00:18:56.433 --> 00:19:01.033
no debería decidir

00:19:01.033 --> 00:19:02.800
que otra persona lo recibiera.

00:19:02.800 --> 00:19:05.433
Quiero que piensen

00:19:05.433 --> 00:19:12.367
por qué a Thomson le parecía obvio

00:19:12.367 --> 00:19:15.667
que después de considerar el
caso en primera persona

00:19:15.667 --> 00:19:19.100
la gente reconsideraría el caso
de la tercera persona.

00:19:19.100 --> 00:19:23.467
Tengo que decir que yo al leer el
documento de Thomson de 2008

00:19:23.467 --> 00:19:27.067
llegué fácilmente al modo de
pensar que ella describe.

00:19:27.067 --> 00:19:30.600
Me parece sorprendente y
sumamente interesante

00:19:30.600 --> 00:19:33.433
ver que no ha sido así
en este contexto.

00:19:33.433 --> 00:19:38.567
Sin embargo, supongamos que por lo
menos algunos de ustedes

00:19:38.567 --> 00:19:41.600
han cambiado sus intuiciones

00:19:41.600 --> 00:19:46.033
tras considerar el caso
como Thomson sugiere.

00:19:46.033 --> 00:19:50.000
En la visión antigua del
caso del transeúnte,

00:19:50.000 --> 00:19:52.500
ustedes pensaban que lo
correcto era matar a 1

00:19:52.500 --> 00:19:54.433
en vez de dejar que 5 murieran.

00:19:54.433 --> 00:19:58.500
En el caso clásico del desvío, así
piensa la mayoría de ustedes.

00:19:58.500 --> 00:20:00.233
En el caso del transeúnte estándar,

00:20:00.233 --> 00:20:04.633
la mayoría de ustedes piensa que
lo correcto es matar a 1

00:20:04.633 --> 00:20:07.000
en vez de dejar morir a 5.

00:20:07.000 --> 00:20:13.233
Thomson dice que al pensar el
caso en primera persona,

00:20:13.233 --> 00:20:16.367
deben darse cuenta de que el
caso del transeúnte

00:20:16.367 --> 00:20:20.433
se parece más de lo que pensaban
al caso del hombre gordo.

00:20:20.433 --> 00:20:26.000
En la medida en que ustedes rechazan
esa intuición de Thomson,

00:20:26.000 --> 00:20:29.500
pueden estar en desacuerdo con ella.

00:20:29.500 --> 00:20:32.100
Pasemos a la visión

00:20:32.100 --> 00:20:34.800
con la que pienso que la mayoría
va a estar de acuerdo,

00:20:34.800 --> 00:20:37.433
porque es precisamente lo opuesto
a lo que dice Thomson,

00:20:37.433 --> 00:20:39.333
me refiero al argumento de Greene

00:20:39.333 --> 00:20:41.233
que dice que la asimilación
debería ir en el otro sentido.

00:20:41.233 --> 00:20:43.567
Recordemos el panorama,

00:20:43.567 --> 00:20:47.033
el problema inicial era que la
gente respondía distinto

00:20:47.033 --> 00:20:49.067
al caso del transeúnte

00:20:49.067 --> 00:20:50.833
y al del hombre gordo,

00:20:50.833 --> 00:20:54.300
y Thomson intentó
eliminar este problema

00:20:54.300 --> 00:20:57.267
haciendo que asimilaran el
caso del transeúnte

00:20:57.267 --> 00:20:59.233
con el del hombre gordo.

00:20:59.233 --> 00:21:01.767
En los casos de Thomson

00:21:01.767 --> 00:21:05.200
yo no logré cambiar sus intuiciones.

00:21:05.200 --> 00:21:08.300
Tenemos el problema de esta
diferencia residual

00:21:08.300 --> 00:21:09.933
entre sus respuestas.

00:21:09.933 --> 00:21:14.833
La mayoría piensa que está bien
desviarlo en el caso del transeúnte,

00:21:14.833 --> 00:21:17.167
aunque no lo desviarían hacia ustedes,

00:21:17.167 --> 00:21:22.400
pero no están de acuerdo en aventar al
hombre gordo desde el puente.

00:21:22.400 --> 00:21:27.133
Greene nos ofrece una segunda
opción de pensamiento

00:21:27.133 --> 00:21:30.633
que nos podría ayudar a
unir ambas respuestas.

00:21:30.633 --> 00:21:33.767
Su argumento es el siguiente:

00:21:33.767 --> 00:21:38.933
Por lo general, no podemos determinar

00:21:38.933 --> 00:21:44.000
qué hay detrás de
nuestro razonamiento.

00:21:44.000 --> 00:21:47.733
Hay toda una tradición en la
psicología social,

00:21:47.733 --> 00:21:50.667
de la que ya hablé en clases pasadas,

00:21:50.667 --> 00:21:55.833
cuyo objetivo es mostrar
que muchas personas

00:21:55.833 --> 00:22:00.867
al tomar decisiones hacen una
racionalización a posteriori

00:22:00.867 --> 00:22:03.800
de las respuestas
intuitivas que tuvieron,

00:22:03.800 --> 00:22:05.967
las cuales no obedecían a los aspectos

00:22:05.967 --> 00:22:10.833
que ellas consideraban
relevantes de la situación.

00:22:10.833 --> 00:22:15.533
Se sabe que es más probable que
la gente elija un objeto

00:22:15.533 --> 00:22:19.500
que está en el campo visual
de la mano izquierda

00:22:19.500 --> 00:22:23.067
que un objeto que está en el campo
visual de la mano derecha.

00:22:23.067 --> 00:22:25.467
Pero al tomar su decisión,

00:22:25.467 --> 00:22:28.967
no dicen que se deba a la
ubicación del objeto,

00:22:28.967 --> 00:22:30.867
sino que dan una explicación

00:22:30.867 --> 00:22:33.367
que haga referencia a otro
rasgo del objeto.

00:22:33.367 --> 00:22:38.333
En la segunda clase vimos los
resultados de la confabulación

00:22:38.333 --> 00:22:41.700
en sujetos que han sufrido
una comisurotonomía,

00:22:41.700 --> 00:22:44.433
un corte en el cuerpo calloso,

00:22:44.433 --> 00:22:47.333
y sus hemisferios derecho e
izquierdo del cerebro

00:22:47.333 --> 00:22:50.500
no están comunicados.

00:22:50.500 --> 00:22:54.067
Cuando realizan una acción
que está basada

00:22:54.067 --> 00:22:58.933
en un estímulo del cerebro
derecho, el cerebro izquierdo,

00:22:58.933 --> 00:23:00.433
que controla la parte lingüística,

00:23:00.433 --> 00:23:03.433
crea una explicación para
su comportamiento

00:23:03.433 --> 00:23:08.467
que obviamente no es la fuente
real del comportamiento.

00:23:08.467 --> 00:23:12.067
Greene señala que hay muchos casos

00:23:12.067 --> 00:23:15.933
en los que desconocemos
nuestras motivaciones.

00:23:15.933 --> 00:23:18.167
Pensamos que estamos
respondiendo a una cosa

00:23:18.167 --> 00:23:21.200
y de hecho estamos
respondiendo a algo distinto.

00:23:21.200 --> 00:23:25.700
Greene dice que uno de esos casos

00:23:25.700 --> 00:23:30.533
es la diferencia en nuestra
respuesta al caso del hombre gordo

00:23:30.533 --> 00:23:32.600
y al del transeúnte.

00:23:32.600 --> 00:23:36.533
Lo que pasa en el caso del transeúnte,

00:23:36.533 --> 00:23:39.400
cuando intentamos decidir si
desviar el tranvía

00:23:39.400 --> 00:23:41.133
de las 5 personas a 1,

00:23:41.133 --> 00:23:46.667
se activa nuestro sistema de
procesamiento racional.

00:23:46.667 --> 00:23:50.267
Greene tiene la hipótesis,

00:23:50.267 --> 00:23:51.900
y veremos algunas pruebas más tarde,

00:23:51.900 --> 00:23:54.767
de que en el caso del hombre gordo

00:23:54.767 --> 00:24:00.667
se activa nuestro sistema de
procesamiento emocional.

00:24:00.667 --> 00:24:05.433
Greene dice que teniendo la opción

00:24:05.433 --> 00:24:10.000
entre nuestro sistema
racional y emocional,

00:24:10.000 --> 00:24:15.933
deberíamos confiar en las
decisiones del sistema racional.

00:24:15.933 --> 00:24:24.067
Greene dice que lo correcto
moralmente en este caso

00:24:24.067 --> 00:24:27.033
es aventar al hombre gordo.

00:24:27.033 --> 00:24:31.833
Tengan en cuenta que es un
argumento de varios pasos

00:24:31.833 --> 00:24:38.267
y algunas de sus premisas son
más polémicas que otras.

00:24:38.267 --> 00:24:41.867
La premisa de que a menudo nuestras
motivaciones son desconocidas

00:24:41.867 --> 00:24:46.933
es indiscutible para todos.

00:24:46.933 --> 00:24:50.700
No hay duda de que a veces
no somos conscientes

00:24:50.700 --> 00:24:55.633
de qué está provocando
nuestras respuestas.

00:24:55.633 --> 00:25:01.733
Podría sentirme irritada porque
mis pies están mojados

00:25:01.733 --> 00:25:04.933
y no darme cuenta de que la razón

00:25:04.933 --> 00:25:07.433
por la que reacciono de
mala gana con ustedes

00:25:07.433 --> 00:25:09.967
no es porque me estén molestando

00:25:09.967 --> 00:25:12.900
sino porque mis pies están incómodos.

00:25:12.900 --> 00:25:16.267
Este fenómeno es innegable.

00:25:16.267 --> 00:25:20.700
La cuestión de qué explica
nuestras diferentes respuestas

00:25:20.700 --> 00:25:25.867
en estos dos casos es una pregunta
empírica muy interesante.

00:25:25.867 --> 00:25:30.367
En la última década más o menos,

00:25:30.367 --> 00:25:34.267
se han recopilado
neuroimágenes muy
interesantes

00:25:34.267 --> 00:25:39.233
que sugieren que existen diferencias
de activación sistemáticas

00:25:39.233 --> 00:25:44.567
sobre qué pasa cuando la gente da
respuestas utilitarias a los casos

00:25:44.567 --> 00:25:48.067
y qué pasa cuando la
gente da respuestas

00:25:48.067 --> 00:25:52.933
que parecen tener las
nociones deontológicas.

00:25:52.933 --> 00:25:55.500
Nociones como los derechos.

00:25:55.500 --> 00:26:00.000
Hay una cierta cantidad de evidencia

00:26:00.000 --> 00:26:01.767
proveniente de otra investigación

00:26:01.767 --> 00:26:06.067
de que las distintas áreas que se
activan en esos 2 casos

00:26:06.067 --> 00:26:08.067
se corresponden por un lado,

00:26:08.067 --> 00:26:10.133
con lo que a menudo se considera

00:26:10.133 --> 00:26:12.600
el sistema de procesamiento racional,

00:26:12.600 --> 00:26:14.600
un sistema de procesamiento calculador,

00:26:14.600 --> 00:26:15.867
y por otro lado,

00:26:15.867 --> 00:26:19.467
con áreas del cerebro que han
estado involucradas

00:26:19.467 --> 00:26:24.200
en casos independientes en el
procesamiento emocional.

00:26:24.200 --> 00:26:26.733
La primera premisa no es polémica.

00:26:26.733 --> 00:26:30.367
La segunda premisa está
bien fundamentada.

00:26:30.367 --> 00:26:32.367
Existe polémica acerca de los datos,

00:26:32.367 --> 00:26:36.700
pero hay pruebas científicas
que avalan el argumento

00:26:36.700 --> 00:26:40.733
que demuestra más o menos lo
que está escrito aquí.

00:26:40.733 --> 00:26:43.500
El tema polémico es determinar

00:26:43.500 --> 00:26:48.400
si aunque las dos primeras
premisas son ciertas,

00:26:48.400 --> 00:26:52.700
la tercera premisa normativa
también es cierta.

00:26:52.700 --> 00:26:58.533
Si nuestras respuestas en el
caso del hombre gordo

00:26:58.533 --> 00:27:00.300
están activadas por la emoción

00:27:00.300 --> 00:27:02.433
y en el caso del transeúnte

00:27:02.433 --> 00:27:04.667
por el sistema racional,

00:27:04.667 --> 00:27:10.033
¿deberíamos hacer caso al
sistema racional?

00:27:10.033 --> 00:27:15.433
Esa es una afirmación
normativa, no empírica.

00:27:15.433 --> 00:27:19.400
Aunque los argumentos que
vamos a considerar

00:27:19.400 --> 00:27:23.633
hayan establecido correctamente la
veracidad de la segunda premisa,

00:27:23.633 --> 00:27:30.467
aún no sabemos si la tercera
premisa es verdadera.

00:27:30.467 --> 00:27:32.933
Hablemos de la evidencia

00:27:32.933 --> 00:27:38.133
que Greene descubrió a favor
de la segunda premisa:

00:27:38.133 --> 00:27:42.400
a favor de que en el caso
del hombre gordo

00:27:42.400 --> 00:27:44.233
hay una respuesta emocional

00:27:44.233 --> 00:27:47.233
y de que en el caso del transeúnte

00:27:47.233 --> 00:27:49.367
hay una respuesta racional.

00:27:49.367 --> 00:27:52.333
En la última década,

00:27:52.333 --> 00:27:58.233
Greene ha estudiado a personas
con máquinas IRMf,

00:27:58.233 --> 00:28:04.133
escáneres que rastrean el flujo
de sangre en el cerebro,

00:28:04.133 --> 00:28:10.600
y les ha presentado 3 tipos de dilemas.

00:28:10.600 --> 00:28:12.367
El primer tipo

00:28:12.367 --> 00:28:16.767
son dilemas que ha denominado
dilemas morales y personales.

00:28:16.767 --> 00:28:18.600
Como el dilema del hombre gordo

00:28:18.600 --> 00:28:20.033
en el que se les pregunta

00:28:20.033 --> 00:28:22.933
si aventarían al hombre
gordo del puente.

00:28:22.933 --> 00:28:24.967
Como el del doctor,

00:28:24.967 --> 00:28:26.133
donde estamos considerando

00:28:26.133 --> 00:28:27.800
descuartizar a un paciente sano

00:28:27.800 --> 00:28:29.233
para salvar a otros.

00:28:29.233 --> 00:28:31.167
Como el del bote salvavidas

00:28:31.167 --> 00:28:34.200
en el que no hay suficiente comida
ni agua para sobrevivir

00:28:34.200 --> 00:28:35.200
y deben decidir

00:28:35.200 --> 00:28:37.767
si se deshacen de una persona

00:28:37.767 --> 00:28:42.500
para que haya suficiente comida
y bebida para el resto.

00:28:42.500 --> 00:28:44.433
Ese es el primer tipo de casos

00:28:44.433 --> 00:28:47.800
que presenta a los sujetos
en los escáneres.

00:28:47.800 --> 00:28:49.300
El segundo tipo de casos

00:28:49.300 --> 00:28:51.167
que presenta a las personas
en los escáneres

00:28:51.167 --> 00:28:54.933
son los que denomina
morales e impersonales.

00:28:54.933 --> 00:28:57.767
Casos como el del transeúnte
y el cambio de vía,

00:28:57.767 --> 00:28:59.533
donde se enfrentan a un dilema moral,

00:28:59.533 --> 00:29:01.800
pero no se imaginan

00:29:01.800 --> 00:29:03.933
de forma personal y cercana

00:29:03.933 --> 00:29:05.800
causando daño

00:29:05.800 --> 00:29:08.633
a un individuo en
particular que esté cerca.

00:29:08.633 --> 00:29:11.933
Casos donde se encuentran
una cartera perdida

00:29:11.933 --> 00:29:14.167
y necesitan decidir si la regresan.

00:29:14.167 --> 00:29:16.700
Casos en los que votan por una política

00:29:16.700 --> 00:29:19.633
que tendrá ciertos efectos en la gente,

00:29:19.633 --> 00:29:24.633
pero esos efectos son
relativamente remotos para
ustedes.

00:29:24.633 --> 00:29:25.600
Por último,

00:29:25.600 --> 00:29:29.100
les presenta dilemas no morales.

00:29:29.100 --> 00:29:33.133
Preguntas como: Si quiero ir de
Cleveland a Chicago,

00:29:33.133 --> 00:29:36.500
¿debería ir en
autobús, tren o avión?

00:29:36.500 --> 00:29:39.967
O si quiero decidir qué
cupón usar en Internet

00:29:39.967 --> 00:29:44.100
para ahorrar en el envío,
¿debería hacer esto o aquello?

00:29:44.100 --> 00:29:47.267
Casos que implican los mismos tipos
de objetos, ¿de acuerdo?

00:29:47.267 --> 00:29:49.833
En el caso del hombre gordo hay trenes.

00:29:49.833 --> 00:29:52.600
En el caso del autobús o
el tren hay trenes.

00:29:52.600 --> 00:29:57.800
Podría ser que el caso del cupón
sea para comprar un barco.

00:29:57.800 --> 00:30:00.267
En el caso del bote
salvavidas hay un bote.

00:30:00.267 --> 00:30:02.633
Coloca a los sujetos en el escáner

00:30:02.633 --> 00:30:05.233
y les presenta este tipo de casos.

00:30:05.233 --> 00:30:08.300
Notarán que puse una
cajita de color aquí,

00:30:08.300 --> 00:30:11.367
con negro, gris y blanco.

00:30:11.367 --> 00:30:15.967
Greene descubrió en su
trabajo de 2001...

00:30:15.967 --> 00:30:19.367
Permítanme decir que desde entonces

00:30:19.367 --> 00:30:22.200
algunos de estos datos han
sido reanalizados

00:30:22.200 --> 00:30:28.933
y algunos siguen vigentes y otros no.

00:30:28.933 --> 00:30:33.433
Greene descubrió que sí
creemos, como la mayoría,

00:30:33.433 --> 00:30:38.500
que las áreas del cerebro listadas
aquí, como el giro frontal medial,

00:30:38.500 --> 00:30:42.167
el giro angular y el giro cingular
posterior, son zonas asociadas

00:30:42.167 --> 00:30:45.600
con la emoción, entonces
tenemos una buena evidencia

00:30:45.600 --> 00:30:50.767
de que en los casos morales/personales

00:30:50.767 --> 00:30:55.400
se activan las zonas del cerebro
asociadas con las emociones.

00:30:55.400 --> 00:30:59.433
Mientras que en los casos
morales/impersonales y no morales

00:30:59.433 --> 00:31:01.833
no pasa esto.

00:31:01.833 --> 00:31:05.867
Por el contrario, parece que
un montón de zonas

00:31:05.867 --> 00:31:09.833
que generalmente están asociadas
con la memoria de trabajo,

00:31:09.833 --> 00:31:12.100
como el lóbulo parietal y el
giro frontal medial,

00:31:12.100 --> 00:31:16.633
están más activas en el
caso impersonal

00:31:16.633 --> 00:31:22.733
y en el caso no moral que en
el caso personal.

00:31:22.733 --> 00:31:26.933
Aquí está la famosa imagen del
documento de Greene de 2001,

00:31:26.933 --> 00:31:29.333
reproducida en muchos
documentos desde entonces,

00:31:29.333 --> 00:31:32.833
que muestra las zonas del
cerebro que presentan

00:31:32.833 --> 00:31:36.067
una respuesta diferencial en los
casos morales/personales

00:31:36.067 --> 00:31:40.167
comparados con los otros casos.

00:31:40.167 --> 00:31:46.733
Parece que existe alguna
evidencia, tal vez decisiva,

00:31:46.733 --> 00:31:51.167
a favor de la segunda premisa de Greene.

00:31:51.167 --> 00:31:56.933
A favor de la premisa de que en los
casos morales/personales

00:31:56.933 --> 00:32:00.967
se activa una parte del cerebro
asociada con la emoción,

00:32:00.967 --> 00:32:04.467
mientras que en los casos
como el del transeúnte

00:32:04.467 --> 00:32:09.733
se activa una parte del cerebro
asociada con el razonamiento

00:32:09.733 --> 00:32:15.933
y con otros procesos más controlados.

00:32:15.933 --> 00:32:18.800
Además, dice Greene,

00:32:18.800 --> 00:32:26.733
hay muchísimas pruebas
conductuales que apoyan la
hipótesis

00:32:26.733 --> 00:32:33.767
de que cuando respondemos a
dilemas morales hipotéticos

00:32:33.767 --> 00:32:36.333
analizamos rasgos del caso

00:32:36.333 --> 00:32:38.767
que no son relevantes moralmente.

00:32:38.767 --> 00:32:44.267
Como un estudio de principios
de los años 2000,

00:32:44.267 --> 00:32:47.267
de los economistas conductuales
Small y Loewenstein,

00:32:47.267 --> 00:32:54.900
que señala que en un sentido muy
profundo, las víctimas identificables

00:32:54.900 --> 00:32:59.100
nos producen una respuesta
emocional más poderosa

00:32:59.100 --> 00:33:01.067
que las víctimas no identificables.

00:33:01.067 --> 00:33:05.067
Esto no se refiere solo a la
diferencia entre una foto

00:33:05.067 --> 00:33:07.333
o una descripción de un niño de Oxfam

00:33:07.333 --> 00:33:11.500
que recibirá las donaciones que hagan.

00:33:11.500 --> 00:33:17.433
De hecho, hay una
sorprendente diferencia

00:33:17.433 --> 00:33:23.167
entre la disposición de una persona
a dar parte de sus premios

00:33:23.167 --> 00:33:30.700
en un juego en un
laboratorio a la Persona #4,

00:33:30.700 --> 00:33:36.300
cuando eligen al azar el papel
que dice Persona #4,

00:33:36.300 --> 00:33:39.100
que en los casos en los que se les pide

00:33:39.100 --> 00:33:42.033
que decidan cuánto dinero
quieren dar a la persona

00:33:42.033 --> 00:33:47.000
cuyo número van a elegir al azar.

00:33:47.000 --> 00:33:50.633
En ninguno de los casos

00:33:50.633 --> 00:33:53.633
saben quién será la Persona #4.

00:33:53.633 --> 00:33:56.333
Pero en el primer caso,

00:33:56.333 --> 00:34:00.067
eligen al azar el papel que dice
Persona #4 y piensan:

00:34:00.067 --> 00:34:02.800
"daré esta cantidad de mis
ganancias a esta persona".

00:34:02.800 --> 00:34:04.300
Mientras que en el segundo caso,

00:34:04.300 --> 00:34:07.367
deciden qué cantidad de sus ganancias

00:34:07.367 --> 00:34:11.433
quieren dar a una persona cuyo
número van a elegir al azar.

00:34:11.433 --> 00:34:18.267
El hecho de que eso produce respuestas
distintas sistemáticamente

00:34:18.267 --> 00:34:24.533
en los sujetos sugiere a
Greene, y tal vez a ustedes,

00:34:24.533 --> 00:34:31.500
que es posible que utilizar nuestras
intuiciones sobre estos casos

00:34:31.500 --> 00:34:37.400
para construir nuestras teorías
morales no sea lo mejor,

00:34:37.400 --> 00:34:41.667
dado que supuestamente
algunos de ustedes piensan

00:34:41.667 --> 00:34:45.633
que hay una diferencia moral relevante

00:34:45.633 --> 00:34:51.767
entre saber el número de la persona

00:34:51.767 --> 00:34:56.267
o estar a punto de descubrir el
número de la persona

00:34:56.267 --> 00:34:58.667
a la que van a dar el regalo.

00:34:58.667 --> 00:35:01.833
Hay algo más que parece afectar

00:35:01.833 --> 00:35:04.533
nuestras respuestas morales a los casos.

00:35:04.533 --> 00:35:11.500
Este es un trabajo realizado
por Jonathan Haidt,

00:35:11.500 --> 00:35:15.233
el autor de La hipótesis de la
felicidad, con varios colaboradores.

00:35:15.233 --> 00:35:17.900
Cuando están decidiendo
cuánto castigar a alguien,

00:35:17.900 --> 00:35:20.967
cuando están decidiendo que
tan mala es una acción,

00:35:20.967 --> 00:35:26.167
si fueron inducidos para sentir asco,

00:35:26.167 --> 00:35:29.267
ya sea sentándose en una mesa sucia

00:35:29.267 --> 00:35:34.033
o habiendo sido entrenados para
asociar ciertos términos

00:35:34.033 --> 00:35:37.733
con el asco mediante la hipnosis,

00:35:37.733 --> 00:35:44.667
serán más duros al castigar a las
personas por sus fechorías.

00:35:44.667 --> 00:35:48.167
Supongo que la mayoría de
ustedes no piensa

00:35:48.167 --> 00:35:50.800
que la gente merece un
castigo más fuerte

00:35:50.800 --> 00:35:54.000
cuando ustedes tienen asco

00:35:54.000 --> 00:35:56.200
porque la mesa de enfrente está sucia.

00:35:56.200 --> 00:35:57.367
Supongo que ustedes piensan

00:35:57.367 --> 00:36:00.667
que evaluar qué tan mala es
una acción de alguien

00:36:00.667 --> 00:36:05.367
es independiente de que
ustedes sientan asco.

00:36:05.367 --> 00:36:08.833
Pero parece que una de las cosas
que influyen en la condena

00:36:08.833 --> 00:36:11.467
es ese sentimiento.

00:36:11.467 --> 00:36:14.200
En un momento, veremos
cómo se relaciona

00:36:14.200 --> 00:36:18.200
con el debate más general de
Sunstein sobre la heurística.

00:36:18.200 --> 00:36:23.867
Por último, un trabajo de David
Pizarro, un Dr.de Yale,

00:36:23.867 --> 00:36:27.833
sugiere que podemos cambiar

00:36:27.833 --> 00:36:31.067
las intuiciones de las personas
en casos específicos,

00:36:31.067 --> 00:36:33.267
como el del hombre gordo,

00:36:33.267 --> 00:36:37.000
variando aspectos que la gente considera

00:36:37.000 --> 00:36:40.500
moralmente irrelevantes.

00:36:40.500 --> 00:36:43.567
Pizarro presenta a los sujetos

00:36:43.567 --> 00:36:46.500
2 versiones distintas del
caso del hombre gordo.

00:36:46.500 --> 00:36:51.167
En el primero, les pregunta si es
obligatorio moralmente

00:36:51.167 --> 00:36:52.667
o si está permitido o prohibido

00:36:52.667 --> 00:36:58.200
aventar a un hombre llamado
Tyrone Peyton desde un puente

00:36:58.200 --> 00:37:02.467
para salvar a 100 miembros de la
filarmónica de Nueva York.

00:37:02.467 --> 00:37:06.500
En el segundo, les pregunta si
es moralmente aceptable

00:37:06.500 --> 00:37:11.333
aventar a Chip Ellsworth
III desde un puente

00:37:11.333 --> 00:37:17.200
para salvar a 100 integrantes de
la Harlem Jazz Orchestra.

00:37:17.200 --> 00:37:21.033
La pregunta es si aventar a un
hombre blanco desde el puente

00:37:21.033 --> 00:37:24.833
para salvar a 100
descendientes de africanos

00:37:24.833 --> 00:37:27.300
o aventar a un hombre negro

00:37:27.300 --> 00:37:30.667
para salvar a 100
descendientes de europeos

00:37:30.667 --> 00:37:34.267
produciría distintas respuestas.

00:37:34.267 --> 00:37:39.933
Curiosamente, tal vez como resultado de
cierto tipo de autocorrección,

00:37:39.933 --> 00:37:43.800
los liberales dijeron que es
menos aceptable moralmente

00:37:43.800 --> 00:37:49.067
aventar desde el puente a Tyrone
Peyton que a Chip Ellsworth.

00:37:49.067 --> 00:37:52.433
Sin importar la dirección
de los resultados,

00:37:52.433 --> 00:37:55.600
lo interesante es que fueron diferentes

00:37:55.600 --> 00:37:59.267
al analizar un rasgo que la
mayoría pensaría

00:37:59.267 --> 00:38:02.833
que es moralmente irrelevante.

00:38:02.833 --> 00:38:08.933
Parece que esto refuerza la
segunda premisa de Greene,

00:38:08.933 --> 00:38:13.633
y es un argumento que él
explica más a detalle

00:38:13.633 --> 00:38:16.567
en un documento que leeremos
después las vacaciones,

00:38:16.567 --> 00:38:18.867
llamado "La broma secreta
del alma de Kant".

00:38:18.867 --> 00:38:22.900
Parece que hay suficientes
razones para pensar

00:38:22.900 --> 00:38:27.067
que algunas respuestas a estos casos

00:38:27.067 --> 00:38:31.567
siguen rasgos que no
aprobamos reflexivamente.

00:38:31.567 --> 00:38:36.233
Greene considera especialmente en
el caso del hombre gordo,

00:38:36.233 --> 00:38:40.233
que nuestra renuencia a
aventarlo obedece

00:38:40.233 --> 00:38:44.900
a uno de esos rasgos
moralmente irrelevantes.

00:38:44.900 --> 00:38:48.500
Greene dice que los
juicios deontológicos,

00:38:48.500 --> 00:38:52.233
donde no queremos tomar una
decisión utilitaria,

00:38:52.233 --> 00:38:56.633
están controlados por
respuestas emocionales.

00:38:56.633 --> 00:38:58.067
Los juicios consecuencialistas

00:38:58.067 --> 00:39:00.000
están controlados por
respuestas cognitivas.

00:39:00.000 --> 00:39:05.733
Y las respuestas deontológicas
carecen de relevancia moral.

00:39:05.733 --> 00:39:12.500
De hecho, la deontología es una
especie de confabulación moral.

00:39:12.500 --> 00:39:16.633
Daré a Kant la última
palabra en esta clase.

00:39:16.633 --> 00:39:20.267
Quienes estén muriendo por escuchar
la sabiduría de Konigsberg,

00:39:20.267 --> 00:39:24.733
sepan que tendrá realmente la
última palabra de hoy

00:39:24.733 --> 00:39:27.767
y la presentaré junto con una
bella imagen de su rostro.

00:39:27.767 --> 00:39:34.233
Pero antes de eso, quiero usar los
últimos 10 minutos de la clase

00:39:34.233 --> 00:39:40.100
para explicarles el tercer texto de hoy,

00:39:40.100 --> 00:39:42.933
el artículo de Cass Sunstein.

00:39:42.933 --> 00:39:47.167
Sunstein, coincide de cierta
manera con Greene,

00:39:47.167 --> 00:39:50.233
aunque recurre a una literatura
ligeramente distinta,

00:39:50.233 --> 00:39:55.100
y argumenta que una buena parte de
nuestro razonamiento moral

00:39:55.100 --> 00:40:00.000
opera exactamente igual que
nuestro razonamiento cotidiano,

00:40:00.000 --> 00:40:03.033
es decir, mediante la heurística,

00:40:03.033 --> 00:40:06.833
que ya vimos en la clase del 20 de enero

00:40:06.833 --> 00:40:08.100
sobre el procesamiento doble.

00:40:08.100 --> 00:40:10.633
La heurística proporciona
herramientas rápidas y frugales

00:40:10.633 --> 00:40:13.600
para enfrentarnos a la
complejidad del mundo

00:40:13.600 --> 00:40:18.600
ante tareas urgentes o ante la
toma de decisiones.

00:40:18.600 --> 00:40:24.200
La heurística funciona de
una forma muy hábil.

00:40:24.200 --> 00:40:28.933
Funciona a través de algo llamado
sustitución de atributos.

00:40:28.933 --> 00:40:31.967
Nos interesa un atributo de destino:

00:40:31.967 --> 00:40:36.367
algo que es relativamente complicado
de descubrir sobre el mundo.

00:40:36.367 --> 00:40:43.300
Y nos enfocamos en un
atributo heurístico:

00:40:43.300 --> 00:40:47.433
algo que es relativamente fácil de
descubrir sobre el mundo.

00:40:47.433 --> 00:40:51.933
Algunos podrían usar esto
cuando intentan reconocer

00:40:51.933 --> 00:40:55.467
su teléfono entre los
teléfonos de los demás.

00:40:55.467 --> 00:40:59.100
El atributo de destino, lo
que les interesa,

00:40:59.100 --> 00:41:01.167
es saber cuál es su teléfono.

00:41:01.167 --> 00:41:03.267
Digamos que es algo que solo
podrían determinar

00:41:03.267 --> 00:41:06.000
encendiendo el teléfono

00:41:06.000 --> 00:41:08.933
y viendo si los contactos
guardados son los suyos.

00:41:08.933 --> 00:41:13.933
Pero podrían facilitar las cosas
si le ponen una funda,

00:41:13.933 --> 00:41:17.533
una estampa o algún otro rasgo
superficial a su teléfono

00:41:17.533 --> 00:41:22.600
para identificarlo bien y rápido.

00:41:22.600 --> 00:41:27.500
¿De acuerdo? Van a usar un
atributo fácil de encontrar

00:41:27.500 --> 00:41:31.867
en vez de uno difícil.

00:41:31.867 --> 00:41:38.400
En general, es una excelente forma
de conducirnos en el mundo.

00:41:38.400 --> 00:41:42.567
Los atributos de destino y los
heurísticos por lo general coinciden.

00:41:42.567 --> 00:41:44.300
Por eso los atributos heurísticos

00:41:44.300 --> 00:41:48.733
llegaron a usarse como indicadores
del atributo de destino.

00:41:48.733 --> 00:41:53.767
Requiere mucho menos esfuerzo
procesar los rasgos superficiales

00:41:53.767 --> 00:41:58.867
del mundo que pasarse el
tiempo viendo los detalles

00:41:58.867 --> 00:42:03.600
de cada cosa que les interesa entender.

00:42:03.600 --> 00:42:08.733
Me di cuenta de que esta mañana
usé un atributo heurístico

00:42:08.733 --> 00:42:11.433
en mi camino a la escuela.

00:42:11.433 --> 00:42:15.800
Estaba parada en un semáforo en
rojo y de reojo me di cuenta

00:42:15.800 --> 00:42:19.367
de que el carro de al lado
comenzaba a avanzar.

00:42:19.367 --> 00:42:22.600
Obviamente, el atributo
que me interesaba

00:42:22.600 --> 00:42:26.933
era saber si la luz había
cambiado a verde.

00:42:26.933 --> 00:42:31.733
Pero no podía ver bien el
semáforo desde donde estaba

00:42:31.733 --> 00:42:36.667
y usé el movimiento del
carro de al lado

00:42:36.667 --> 00:42:40.067
como indicador de lo que me interesaba.

00:42:40.067 --> 00:42:44.333
Obviamente, en este caso la
heurística se pudo haber equivocado.

00:42:44.333 --> 00:42:46.367
Podría ser que ese carro
estuviera avanzando

00:42:46.367 --> 00:42:47.467
aunque el semáforo siguiera en rojo.

00:42:47.467 --> 00:42:50.267
Podría ser que ese carro estuviera
avanzando en el carril izquierdo

00:42:50.267 --> 00:42:52.533
y tuviera un semáforo
especial distinto al mío.

00:42:52.533 --> 00:43:00.133
Pero en general, usamos la heurística
todo el tiempo y nos ayuda.

00:43:00.133 --> 00:43:03.433
El argumento de Sunstein es que
en los casos no morales

00:43:03.433 --> 00:43:05.233
la gente suele usar la heurística.

00:43:05.233 --> 00:43:09.233
Aunque esto sea útil, podría
llevarnos a cometer errores.

00:43:09.233 --> 00:43:12.633
Y en los casos morales,

00:43:12.633 --> 00:43:17.733
la gente también suele
usar la heurística.

00:43:17.733 --> 00:43:22.400
De la misma forma que puede
llevarnos a cometer errores

00:43:22.400 --> 00:43:26.700
en los casos no morales, también
puede pasar en los casos morales.

00:43:26.700 --> 00:43:31.033
En especial, Sunstein
piensa que esto pasa

00:43:31.033 --> 00:43:34.500
en una serie de casos que explica.

00:43:34.500 --> 00:43:39.233
Me acabo de dar cuenta de que
tenemos que ir cerrando.

00:43:39.233 --> 00:43:40.800
Había dicho que Kant tendría
la última palabra,

00:43:40.800 --> 00:43:43.733
pero tendrá la última
palabra el jueves.

00:43:43.733 --> 00:43:46.233
Veremos a Sunstein y uno
de sus ejemplos,

00:43:46.233 --> 00:43:47.500
y después llegaremos a Kant.

00:43:47.500 --> 00:43:51.067
Sunstein señala que hay una heurística

00:43:51.067 --> 00:43:53.033
llamada heurística de disponibilidad.

00:43:53.033 --> 00:43:55.967
Es la heurística que usamos si
estamos tratando de descubrir

00:43:55.967 --> 00:43:57.867
qué tan probable es que algo pase,

00:43:57.867 --> 00:44:00.767
es una buena forma de determinar qué
tan probable es que algo pase.

00:44:00.767 --> 00:44:04.700
¿Qué tan fácil es para mí pensar en
casos donde eso realmente pasó?

00:44:04.700 --> 00:44:07.900
Cuando me preocupo de que vayan a
secuestrar a mis hijos,

00:44:07.900 --> 00:44:11.267
pienso en cuantos amigos conozco

00:44:11.267 --> 00:44:13.400
a quienes les hayan
secuestrado a sus hijos.

00:44:13.400 --> 00:44:15.767
¿A cuántas personas conozco que les
hayan secuestrado a sus hijos?

00:44:15.767 --> 00:44:19.833
Me doy cuenta de que a nadie y
entonces me relajo.

00:44:19.833 --> 00:44:22.700
Este tipo de heurística por lo
general es correcta,

00:44:22.700 --> 00:44:24.767
pero puede llevarnos por el mal camino.

00:44:24.767 --> 00:44:30.067
Por ejemplo, supongamos que les
preguntan si es más probable

00:44:30.067 --> 00:44:34.267
que haya más palabras en
inglés que terminen en -ING

00:44:34.267 --> 00:44:45.167
o más palabras en inglés que su
penúltima letra sea N.

00:44:45.167 --> 00:44:48.700
Es mucho más fácil pensar en
palabras que terminen en -ING

00:44:48.700 --> 00:44:53.467
que en palabras

00:44:53.467 --> 00:44:56.367
que su penúltima letra sea N.

00:44:56.367 --> 00:45:00.867
Pero obviamente, todas las
palabras que terminan en -ING

00:45:00.867 --> 00:45:04.833
son palabras cuya penúltima letra es N.

00:45:04.833 --> 00:45:09.933
Se engatusaron con la
heurística de disponibilidad.

00:45:09.933 --> 00:45:11.300
O supongamos que usan

00:45:11.300 --> 00:45:14.467
la llamada heurística de
representatividad.

00:45:14.467 --> 00:45:16.933
Que la probabilidad de que algo ocurra

00:45:16.933 --> 00:45:19.667
depende de su grado de normalidad.

00:45:19.667 --> 00:45:22.867
Esto también suele ser correcto.

00:45:22.867 --> 00:45:24.967
Algo que suele ser un caso típico

00:45:24.967 --> 00:45:29.333
debe ser un caso que ocurra
con mayor frecuencia.

00:45:29.333 --> 00:45:32.133
Pero como saben, por los
casos de Linda la cajera

00:45:32.133 --> 00:45:33.967
o el granjero con un tractor,

00:45:33.967 --> 00:45:39.333
si les pregunto si es más probable que
un residente al azar de Iowa

00:45:39.333 --> 00:45:45.533
sea un granjero o un
granjero con un tractor,

00:45:45.533 --> 00:45:48.900
la heurística de representatividad
les hará inclinarse a decir

00:45:48.900 --> 00:45:52.267
que es más probable que se trate de
un granjero con un tractor.

00:45:52.267 --> 00:45:53.600
Pero obviamente,

00:45:53.600 --> 00:45:58.567
todos los granjeros con un tractor
también son granjeros.

00:45:58.567 --> 00:46:04.900
Recuerden que los argumentos de
Sunstein para el caso 1 y 2

00:46:04.900 --> 00:46:07.767
son fáciles de hacer porque
tenemos una forma independiente

00:46:07.767 --> 00:46:13.100
de determinar si alguien ha
cometido un error en esos casos.

00:46:13.100 --> 00:46:16.033
Podemos ver en qué fallaron la
heurística de disponibilidad

00:46:16.033 --> 00:46:17.567
y la de representatividad
porque podemos ver

00:46:17.567 --> 00:46:22.267
que de hecho es más probable

00:46:22.267 --> 00:46:24.800
que la penúltima letra de
una palabra sea N

00:46:24.800 --> 00:46:29.767
y no que las últimas tres letras
de una palabra sean -ING.

00:46:29.767 --> 00:46:33.133
Podemos ver que es más probable
que alguien sea un granjero

00:46:33.133 --> 00:46:36.700
y no un granjero con un tractor.

00:46:36.700 --> 00:46:38.533
Porque en ambos casos,

00:46:38.533 --> 00:46:42.300
una condición es un caso
especial de la otra condición.

00:46:42.300 --> 00:46:46.300
El argumento de Sunstein de
la heurística moral

00:46:46.300 --> 00:46:49.000
irá más allá.

00:46:49.000 --> 00:46:53.633
Porque no le basta con demostrar
que en los casos morales

00:46:53.633 --> 00:46:58.100
la gente suele usar la heurística,

00:46:58.100 --> 00:47:05.033
también necesita demostrar que al
hacerlo están cometiendo errores.

00:47:05.033 --> 00:47:08.433
Aquí la cuestión de obtener una
explicación independiente

00:47:08.433 --> 00:47:13.167
sobre qué significa cometer un
error es bastante complicada.

00:47:13.167 --> 00:47:18.000
Primero pensemos en cuál es
su argumento a favor

00:47:18.000 --> 00:47:22.967
de que en los casos morales la gente
suele utilizar la heurística.

00:47:22.967 --> 00:47:26.233
Voy a concluir la clase de hoy con 2
ejemplos que da Sunstein.

00:47:26.233 --> 00:47:30.933
Comenzaremos el jueves repasando
algunos casos particulares

00:47:30.933 --> 00:47:33.167
donde les pediré su opinión.

00:47:33.167 --> 00:47:36.000
Uno de los ejemplos que
proporciona es, otra vez,

00:47:36.000 --> 00:47:38.767
un trabajo de Jonathan Haidt
sobre un fenómeno conocido

00:47:38.767 --> 00:47:40.533
como el desconcierto moral.

00:47:40.533 --> 00:47:44.133
Como saben, tras haber leído
el texto de Sunstein,

00:47:44.133 --> 00:47:47.100
cuando a la gente se le pregunta si

00:47:47.100 --> 00:47:51.167
"¿es moralmente aceptable que
un hermano y una hermana

00:47:51.167 --> 00:47:57.033
tengan relaciones incestuosas
consentidas y sin daños?"

00:47:57.033 --> 00:48:00.867
suelen responder que es
moralmente inaceptable.

00:48:00.867 --> 00:48:06.400
Pero cuando se les pide que
justifiquen su respuesta,

00:48:06.400 --> 00:48:10.367
tienen dificultades para hacerlo.

00:48:10.367 --> 00:48:13.367
De la misma manera, muchas personas
tienen la inclinación a pensar

00:48:13.367 --> 00:48:18.633
que hay un problema moral con
trapear el piso del baño

00:48:18.633 --> 00:48:25.500
con una bandera o con comerse a su
perro si un coche lo atropella,

00:48:25.500 --> 00:48:34.333
pero les cuesta trabajo explicar sus
razones para esas respuestas.

00:48:34.333 --> 00:48:41.333
Sunstein sugiere que la razón es
un exceso de heurística.

00:48:41.333 --> 00:48:44.800
De la misma forma, señala que en
los casos con un marco moral,

00:48:44.800 --> 00:48:47.400
que veremos en la próxima clase,

00:48:47.400 --> 00:48:50.300
como el caso de la enfermedad asiática

00:48:50.300 --> 00:48:54.033
que les presenté en nuestra
clase del 20 de enero,

00:48:54.033 --> 00:49:00.800
cuando se les presenta un dilema
moral que implica salvar vidas

00:49:00.800 --> 00:49:04.333
a diferencia de perder vidas,

00:49:04.333 --> 00:49:09.567
aunque sean descripciones
complementarias del mismo resultado,

00:49:09.567 --> 00:49:14.800
la gente suele tener
distintas respuestas.

00:49:14.800 --> 00:49:21.033
Sunstein concluye que la gente usa la
heurística en el razonamiento

00:49:21.033 --> 00:49:26.967
moral de la misma forma que lo hace
en el razonamiento no moral.

00:49:26.967 --> 00:49:32.200
Comenzaremos el jueves con el debate
de Sunstein sobre esos casos,

00:49:32.200 --> 00:49:34.367
y después dejaremos que Kant y Mill

00:49:34.367 --> 00:49:36.400
tengan la última palabra sobre
el debate del tranvía.

00:49:36.400 --> 00:49:37.300
Nos vemos el jueves.

