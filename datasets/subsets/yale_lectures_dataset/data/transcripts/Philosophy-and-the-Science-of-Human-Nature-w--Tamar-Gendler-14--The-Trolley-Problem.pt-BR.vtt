WEBVTT
Kind: captions
Language: pt-BR

00:00:01.100 --> 00:00:03.767
Profª. Tamar Gendler: Então,
precisamos fazer 2 coisas

00:00:03.767 --> 00:00:05.367
na aula de hoje.

00:00:05.367 --> 00:00:09.200
A 1ª é terminar a nossa
discussão de deontologia,

00:00:09.200 --> 00:00:12.600
que foi adiantada de propósito.

00:00:12.600 --> 00:00:14.700
Estamos tentando dar Kant em
1 aula, basicamente.

00:00:14.700 --> 00:00:19.100
Mas eu quero chegar ao final
desta discussão.

00:00:19.100 --> 00:00:22.533
E a 2ª, que permitirá que
vocês usem os seus clickers

00:00:22.533 --> 00:00:23.833
e expressem as suas opiniões,

00:00:23.833 --> 00:00:30.267
é comentar sobre a estrutura do
artigo de Judy Thomson.

00:00:30.267 --> 00:00:33.967
Portanto, vocês se lembram
da última aula,

00:00:33.967 --> 00:00:38.733
em que o nosso objetivo ao
compreender a seleção de

00:00:38.733 --> 00:00:41.567
Fundamentação da Metafísica dos
Costumes de Kant era tentar

00:00:41.567 --> 00:00:48.433
dar sentido às 3
proposições que ele faz

00:00:48.433 --> 00:00:54.633
no 1º capítulo do 1º volume.

00:00:54.633 --> 00:00:58.533
E essas proposições, que eu
tenho aqui destacadas,

00:00:58.533 --> 00:00:59.867
são as seguintes.

00:00:59.867 --> 00:01:03.533
A 1ª afirma que, para ter valor moral,

00:01:03.533 --> 00:01:08.233
uma ação precisa ser feita
por causa do dever.

00:01:08.233 --> 00:01:11.500
E a distinção realizada por
Kant é a distinção

00:01:11.500 --> 00:01:16.233
entre fazer algo em conformidade
com o dever, isto é,

00:01:16.233 --> 00:01:20.400
algo que está em conformidade com o
que a moralidade exige de você,

00:01:20.400 --> 00:01:23.033
e fazer algo não apenas em
conformidade com,

00:01:23.033 --> 00:01:26.067
mas também por causa do dever.

00:01:26.067 --> 00:01:31.300
E a imagem kantiana é que o valor
moral de uma ação é determinada

00:01:31.300 --> 00:01:35.633
não somente por ela estar em
conformidade com o dever.

00:01:35.633 --> 00:01:39.667
Essa é uma condição
necessária, mas não suficiente.

00:01:39.667 --> 00:01:42.533
O que determina o valor
moral de uma ação

00:01:42.533 --> 00:01:45.400
é que ela seja feita em
conformidade com o dever

00:01:45.400 --> 00:01:49.200
para o bem de estar de
acordo com o dever,

00:01:49.200 --> 00:01:52.800
isto é, ser feita por causa do dever.

00:01:52.800 --> 00:01:55.600
A 2ª coisa que Kant diz,

00:01:55.600 --> 00:01:59.400
a 2ª proposição que ele busca
defender na Fundamentação,

00:01:59.400 --> 00:02:02.200
é que uma ação feita
por causa do dever

00:02:02.200 --> 00:02:04.433
– que é o que comentávamos
na 1ª afirmação –

00:02:04.433 --> 00:02:07.600
tem o seu valor moral

00:02:07.600 --> 00:02:11.367
não no propósito que deve
ser atingido por ela,

00:02:11.367 --> 00:02:17.333
não o que os gregos chamam de telos,
a sua meta, o seu objetivo,

00:02:17.333 --> 00:02:23.800
mas sim na máxima de acordo com a
qual a ação é determinada.

00:02:23.800 --> 00:02:27.700
Ou seja, o que determina a moralidade
da ação na imagem kantiana

00:02:27.700 --> 00:02:33.067
é a descrição sob a qual a
ação é executada.

00:02:33.067 --> 00:02:36.433
Agora, alguns de vocês vieram para o
horário de trabalho ontem

00:02:36.433 --> 00:02:40.800
e nós tivemos uma discussão
animada sobre como se determinam

00:02:40.800 --> 00:02:43.500
as coisas que contam como máximas.

00:02:43.500 --> 00:02:46.400
E eu estimulo os que
estão interessados ??

00:02:46.400 --> 00:02:48.200
nessa pergunta a fazerem um
curso de ética,

00:02:48.200 --> 00:02:51.500
onde é possível trabalhar a
questão nos escritos de Kant

00:02:51.500 --> 00:02:52.867
de forma mais detalhada.

00:02:52.867 --> 00:02:54.400
Para efeitos desta classe,

00:02:54.400 --> 00:02:57.733
tudo o que precisamos é nos
manter com a simples ideia

00:02:57.733 --> 00:03:02.400
de que o que Kant está
interessado aqui são nos atos sob

00:03:02.400 --> 00:03:05.367
uma descrição e que essa
descrição terá de satisfazer

00:03:05.367 --> 00:03:09.233
um certo tipo de teste, como vamos
descobrir daqui a pouco.

00:03:09.233 --> 00:03:11.267
Então, essa é a 2ª
proposição de Kant.

00:03:11.267 --> 00:03:14.367
A 3ª alegação

00:03:14.367 --> 00:03:17.533
é a que o dever, a noção
central da deontologia

00:03:17.533 --> 00:03:21.400
– deon, o dever está no
núcleo da deontologia –,

00:03:21.400 --> 00:03:29.600
é a necessidade de uma ação
por respeito à lei.

00:03:29.600 --> 00:03:36.067
E a ideia aqui é que você não só
precisa agir com o objetivo

00:03:36.067 --> 00:03:38.467
de estar em conformidade
com a lei em mente,

00:03:38.467 --> 00:03:43.800
você não só precisa fazer isso
articulando as suas ações

00:03:43.800 --> 00:03:47.733
segundo essa norma,

00:03:47.733 --> 00:03:53.400
mas fazer isso porque você
toma a lei moral

00:03:53.400 --> 00:03:56.767
como sendo moralmente obrigatória,

00:03:56.767 --> 00:04:03.733
porque você reconhece que é o que a
racionalidade exige de você.

00:04:03.733 --> 00:04:11.833
A lei moral acaba por ser a lei
que rege o comportamento

00:04:11.833 --> 00:04:17.400
que você definiu para você
mesmo como um ser racional.

00:04:17.400 --> 00:04:23.033
É o único aspecto do seu
comportamento na imagem kantiana

00:04:23.033 --> 00:04:24.667
que não é determinado

00:04:24.667 --> 00:04:28.300
pelas forças contingentes do
mundo ao seu redor.

00:04:28.300 --> 00:04:33.933
É determinado pelo seu
reconhecimento do seu papel

00:04:33.933 --> 00:04:38.833
como alguém capaz de obrigá-las

00:04:38.833 --> 00:04:43.100
a uma lei definidas por elas mesmas.

00:04:43.100 --> 00:04:50.100
Então, como eu disse, a razão
pela qual nós interessava

00:04:50.100 --> 00:04:53.400
esses 3 princípios era chegar
à famosa formulação

00:04:53.400 --> 00:04:55.233
do imperativo categórico de Kant.

00:04:55.233 --> 00:05:00.000
E fechamos a última aula
conhecendo um membro da família

00:05:00.000 --> 00:05:06.967
do imperativo categórico, em
resposta à pergunta de Kant:

00:05:06.967 --> 00:05:12.667
"Que lei pode ser então essa,
cuja representação,

00:05:12.667 --> 00:05:14.700
mesmo sem tomar em consideração o
efeito que dela se espera,

00:05:14.700 --> 00:05:16.467
tem de determinar a vontade para
que esta se possa chamar

00:05:16.467 --> 00:05:18.800
boa absolutamente e sem restrição?"

00:05:18.800 --> 00:05:23.233
O próprio Kant aplica um
suspense à pergunta

00:05:23.233 --> 00:05:26.867
e a responde com o 1º
membro da família

00:05:26.867 --> 00:05:29.300
de imperativo categórico.

00:05:29.300 --> 00:05:33.100
É "a conformidade a uma lei universal

00:05:33.100 --> 00:05:34.900
das ações em geral" da vontade.

00:05:34.900 --> 00:05:44.233
Só assim é possível agir de forma
autônoma e não heteronomamente.

00:05:44.233 --> 00:05:48.600
O que significa agir de forma autônoma
em oposição a heteronomamente?

00:05:48.600 --> 00:05:53.267
Vejamos as palavras:
autônomo, heterônomo.

00:05:53.267 --> 00:05:59.100
Vocês podem perceber que ambas
têm nomos, ou seja, lei.

00:05:59.100 --> 00:06:05.067
E elas distinguem a lei a que
vocês estão sujeitos

00:06:05.067 --> 00:06:13.267
dizendo que num caso é um auto-nomos
e no outro, um hetero-nomos.

00:06:13.267 --> 00:06:15.467
Auto-nomos.

00:06:15.467 --> 00:06:17.033
O que poderia ser?

00:06:17.033 --> 00:06:20.867
Vamos pensar em outras palavras,
onde temos o prefixo auto-.

00:06:20.867 --> 00:06:23.033
Que tal automóvel?

00:06:23.033 --> 00:06:32.400
O que é um automóvel? Um automóvel é
algo que é auto-propulsionado.

00:06:32.400 --> 00:06:35.367
É impulsionado por sua própria força.

00:06:35.367 --> 00:06:40.700
Atuar de forma autônoma,
na imagem de Kant,

00:06:40.700 --> 00:06:47.600
é agir com base numa lei
imposta por você.

00:06:47.600 --> 00:06:55.133
Você é auto-nomos, sujeito a
uma lei que vem de dentro.

00:06:55.133 --> 00:07:01.367
Por outro lado, o que é hetero-nomos?

00:07:01.367 --> 00:07:06.267
Bem, o que é ser heterossexual?

00:07:06.267 --> 00:07:13.433
Ser heterossexual é se sentir
atraído sexualmente por pessoas

00:07:13.433 --> 00:07:17.767
de um gênero diferente do seu.

00:07:17.767 --> 00:07:20.433
Então o que é ser hetero-nomos?

00:07:20.433 --> 00:07:25.300
É ter uma lei imposta a
você que vem de fora,

00:07:25.300 --> 00:07:29.400
que vem de algo diferente de você.

00:07:29.400 --> 00:07:36.767
A imagem kantiana é que a
autonomia, a autoimposição da lei,

00:07:36.767 --> 00:07:44.200
só é possível quando a lei a que
você conforma o seu comportamento

00:07:44.200 --> 00:07:52.367
não vem das contingências do
mundo, e sim de dentro.

00:07:52.367 --> 00:07:56.033
Dessa forma, Kant está preocupado

00:07:56.033 --> 00:08:01.700
com os mesmos tipos de
questionamentos que Epicteto e
Boécio.

00:08:01.700 --> 00:08:04.200
Ambos estão profundamente preocupados

00:08:04.200 --> 00:08:08.300
em como a liberdade humana é possível

00:08:08.300 --> 00:08:14.233
e a imagem de Kant é que a
liberdade humana é possível

00:08:14.233 --> 00:08:18.533
quando você governa as suas ações

00:08:18.533 --> 00:08:24.533
com base no que você decide ser,

00:08:24.533 --> 00:08:28.367
as normas que você pretende conformar.

00:08:28.367 --> 00:08:30.767
Em especial,

00:08:30.767 --> 00:08:35.767
quando você conforma as suas ações
com o imperativo categórico,

00:08:35.767 --> 00:08:39.633
que diz, na formulação que vimos
no início desta seção,

00:08:39.633 --> 00:08:43.233
que você deve "agir apenas
segundo uma máxima"...

00:08:43.233 --> 00:08:49.000
aí está a sua máxima novamente...

00:08:49.000 --> 00:08:52.667
"tal que possas ao mesmo tempo querer
que ela se torne lei universal".

00:08:52.667 --> 00:08:55.733
Quando você age de tal modo

00:08:55.733 --> 00:09:02.367
que não considere as
contingências da sua situação

00:09:02.367 --> 00:09:09.900
– mas, em vez disso, pense em si
mesmo como 1 entre qualquer

00:09:09.900 --> 00:09:14.867
milhões de seres que no seu lugar fariam
exatamente o que você faz –,

00:09:14.867 --> 00:09:21.300
só então você se torna livre das
contingências das circunstâncias.

00:09:21.300 --> 00:09:25.267
Portanto, a imagem é que,
em alguns aspectos,

00:09:25.267 --> 00:09:27.433
por pisar além dos limites

00:09:27.433 --> 00:09:30.233
das características
contingentes da sua
experiência,

00:09:30.233 --> 00:09:33.833
por pisar além dos limites de
si mesmo, você, assim,

00:09:33.833 --> 00:09:42.600
ganha a liberdade a partir das
contingências do mundo ao seu redor.

00:09:42.600 --> 00:09:49.167
E Kant sugere que se você tomar
isso como uma imagem,

00:09:49.167 --> 00:09:56.600
você vai ver que ela está em
conformidade com as regras da
racionalidade.

00:09:56.600 --> 00:09:59.933
Então, diz ele, vamos supor que
você seja confrontado

00:09:59.933 --> 00:10:04.500
com um caso muito particular de um
ato que você deseja executar

00:10:04.500 --> 00:10:06.467
sob uma máxima particular.

00:10:06.467 --> 00:10:08.233
A máxima que você definiu
para si mesmo é:

00:10:08.233 --> 00:10:09.800
"quando eu faço uma promessa

00:10:09.800 --> 00:10:12.900
que será complicada para mim,

00:10:12.900 --> 00:10:15.500
eu vou quebrar essa promessa".

00:10:15.500 --> 00:10:22.800
Ou seja, a máxima é: "está tudo bem
se eu fizer promessas falsas".

00:10:22.800 --> 00:10:27.200
E Kant pergunta, vamos
supor que você fez,

00:10:27.200 --> 00:10:28.433
de acordo com essa descrição,

00:10:28.433 --> 00:10:31.700
uma promessa que você não tinha
a intenção de seguir.

00:10:31.700 --> 00:10:36.800
Aquela máxima pode ser universalizada?

00:10:36.800 --> 00:10:39.000
Bem, ele diz, vamos supor que ela fosse.

00:10:39.000 --> 00:10:42.767
Vamos supor que todo mundo,
ao fazer promessas,

00:10:42.767 --> 00:10:46.367
as façam com o pensamento de
que eles vão mantê-las

00:10:46.367 --> 00:10:47.400
quando forem conveniente

00:10:47.400 --> 00:10:50.333
e que não quando elas
forem inconvenientes.

00:10:50.333 --> 00:10:53.833
Se isso ocorresse, diz Kant,

00:10:53.833 --> 00:10:59.433
não haveria tal coisa como uma
prometedor confiável.

00:10:59.433 --> 00:11:06.400
Por quê? Bem, porque as
promessas são marquises.

00:11:06.400 --> 00:11:12.867
Nós não saímos a uma marquise
se há uma boa chance

00:11:12.867 --> 00:11:16.333
de ela cair quando pisarmos nela.

00:11:16.333 --> 00:11:20.367
E não nos arriscamos em promessas,

00:11:20.367 --> 00:11:23.067
em compromissos feitos por
outras pessoas,

00:11:23.067 --> 00:11:26.500
a menos que estejamos
próximos da certeza

00:11:26.500 --> 00:11:30.667
de que essa promessa será preservada.

00:11:30.667 --> 00:11:39.567
Portanto, diz Kant, já que a
prática de prometer seria quebrada

00:11:39.567 --> 00:11:45.933
se todos que achassem isso
conveniente fizessem promessas
falsas,

00:11:45.933 --> 00:11:52.200
não está em conformidade com o que
a lei moral exige de nós

00:11:52.200 --> 00:11:57.633
fazermos uma promessa falsa.

00:11:57.633 --> 00:12:02.533
E, Kant sugere, este quadro

00:12:02.533 --> 00:12:10.200
pode ser estendido a todos
os tipos de tarefas.

00:12:10.200 --> 00:12:15.700
Segundo Kant, existem 2
categorias de obrigação

00:12:15.700 --> 00:12:19.100
para com nós mesmos e com os outros.

00:12:19.100 --> 00:12:21.467
Nós temos deveres para com nós mesmos

00:12:21.467 --> 00:12:23.567
e deveres para com as outras pessoas.

00:12:23.567 --> 00:12:27.400
E, além disso, afirma Kant,
temos deveres perfeitos,

00:12:27.400 --> 00:12:30.200
coisas que sempre temos de fazer,

00:12:30.200 --> 00:12:35.767
e deveres imperfeitos, coisas que,
por vezes, temos de fazer.

00:12:35.767 --> 00:12:42.233
Em todos esses casos, Kant
destaca a presença

00:12:42.233 --> 00:12:49.333
do imperativo categórico nos
dando orientações

00:12:49.333 --> 00:12:54.633
se uma ação sob uma
máxima é permitida.

00:12:54.633 --> 00:12:57.833
A ação sob a máxima será permitida

00:12:57.833 --> 00:13:03.267
se ela puder ser universalizada e
será proibida se não.

00:13:03.267 --> 00:13:05.533
Portanto, se perguntarmos

00:13:05.533 --> 00:13:09.000
"Está bem fazer promessas falsas?"

00:13:09.000 --> 00:13:10.067
e dissermos para nós mesmos

00:13:10.067 --> 00:13:12.833
"Vamos supor que todos façam
promessas falsas",

00:13:12.833 --> 00:13:16.967
descobriremos que esse ato é proibido

00:13:16.967 --> 00:13:20.167
pelo imperativo categórico

00:13:20.167 --> 00:13:22.800
porque ele pode não pode
ser universalizado.

00:13:22.800 --> 00:13:24.333
Imaginem esta questão:

00:13:24.333 --> 00:13:30.967
"Está bem cometer suicídio ao se
sentir frustrado com o mundo?".

00:13:30.967 --> 00:13:35.867
E Kant diz: vamos supor que
todos façam isso.

00:13:35.867 --> 00:13:40.133
A prática, o argumento
complicado poderia ser quebrado,

00:13:40.133 --> 00:13:44.133
porque não sobraria
ninguém para se suicidar.

00:13:44.133 --> 00:13:46.033
Então aqui vai o argumento.

00:13:46.033 --> 00:13:49.667
Vamos supor que nos perguntem

00:13:49.667 --> 00:13:52.800
se temos o dever de cultivar
os nossos talentos?

00:13:52.800 --> 00:13:56.533
Kant afirma: vamos supor que
ninguém cultive os seus talentos.

00:13:56.533 --> 00:14:01.100
O mundo no qual vivemos seria um mundo

00:14:01.100 --> 00:14:05.067
em que ninguém gostaria de viver.

00:14:05.067 --> 00:14:09.500
E, consequentemente, temos a
obrigação moral de fazê-lo.

00:14:09.500 --> 00:14:11.767
Por fim, ele pergunta:

00:14:11.767 --> 00:14:16.167
nós temos a obrigação de dar
dinheiro aos necessitados?

00:14:16.167 --> 00:14:17.500
E continua:

00:14:17.500 --> 00:14:20.633
o que aconteceria se fosse
uma lei universal

00:14:20.633 --> 00:14:24.167
que ninguém desse dinheiro
aos necessitados?

00:14:24.167 --> 00:14:29.100
E mais uma vez descobrimos uma
ruptura de um mundo ordenado

00:14:29.100 --> 00:14:31.267
em que queremos sobreviver.

00:14:31.267 --> 00:14:34.733
Bom, há espaço para o
questionamento...

00:14:34.733 --> 00:14:39.000
Na verdade, há espaço para
questionar todas essas 4 derivações,

00:14:39.000 --> 00:14:42.533
embora seja geralmente aceito

00:14:42.533 --> 00:14:44.967
que a da promessa falsa é a
mais eficaz delas.

00:14:44.967 --> 00:14:51.367
Mas em vez do que Kant diz sobre elas,

00:14:51.367 --> 00:14:56.000
vamos analisar se estas
derivações funcionam.

00:14:56.000 --> 00:14:56.967
Kant afirma:

00:14:56.967 --> 00:15:00.500
"Estes são apenas alguns dos
muitos deveres reais

00:15:00.500 --> 00:15:05.467
cuja derivação do princípio
único ressalta bem clara".

00:15:05.467 --> 00:15:08.033
"Bem clara" é um pouco exagerado,

00:15:08.033 --> 00:15:10.867
mas podemos ver como seria
essa derivação.

00:15:10.867 --> 00:15:15.367
O que isso nos diz sobre a moralidade?

00:15:15.367 --> 00:15:21.833
Para Kant, nos diz que
quando pegamos um ato

00:15:21.833 --> 00:15:25.300
e tentamos determinar se ele é moral,

00:15:25.300 --> 00:15:28.200
é preciso checar e ver

00:15:28.200 --> 00:15:32.000
se estamos criando uma
exceção para nós mesmos.

00:15:32.000 --> 00:15:34.500
Quando agimos, temos de ser
capazes de querer

00:15:34.500 --> 00:15:38.433
que uma máxima de nossas ações
se torne uma lei universal.

00:15:38.433 --> 00:15:42.267
Quando transgredimos, diz Kant,

00:15:42.267 --> 00:15:45.767
não querer que a nossa máxima se
torne uma lei universal,

00:15:45.767 --> 00:15:51.400
mas sim que o oposto dessa máxima
continue sendo uma lei universal.

00:15:51.400 --> 00:15:55.600
Então, vamos supor que você
goste de se sentar

00:15:55.600 --> 00:15:59.267
nos últimos 2 assentos de uma fila,

00:15:59.267 --> 00:16:03.433
mesmo sem chegar atrasado.

00:16:03.433 --> 00:16:07.700
Você quer que isso se torne
uma lei universal

00:16:07.700 --> 00:16:10.533
ou é algo que só funciona para você

00:16:10.533 --> 00:16:15.200
se os outros estão dispostos a se
sentar mais para dentro,

00:16:15.200 --> 00:16:18.067
de modo que haja espaço nas laterais?

00:16:18.067 --> 00:16:25.900
Kant diria que a lei moral exige de
você se mover para dentro,

00:16:25.900 --> 00:16:30.033
porque sentar nesses 2
últimos assentos,

00:16:30.033 --> 00:16:32.333
apesar de não ter chegado tarde,

00:16:32.333 --> 00:16:38.000
depende de outras pessoas
fazerem algo diferente.

00:16:38.000 --> 00:16:43.333
Roubar depende de outras pessoas

00:16:43.333 --> 00:16:46.467
respeitarem as leis de forma adequada.

00:16:46.467 --> 00:16:51.333
Não pagar a passagem de metrô

00:16:51.333 --> 00:16:53.600
depende de outras pessoas
pagarem a passagem,

00:16:53.600 --> 00:16:57.600
de modo que haja dinheiro
suficiente para manter o metrô.

00:16:57.600 --> 00:17:04.367
Quando você faz uma exceção
para si mesmo, diz Kant,

00:17:04.367 --> 00:17:07.200
você viola a lei moral.

00:17:07.200 --> 00:17:09.033
E vamos voltar a isso

00:17:09.033 --> 00:17:13.067
na abertura da nossa discussão
sobre filosofia política,

00:17:13.067 --> 00:17:16.967
quando falamos sobre os
dilemas do prisioneiro.

00:17:16.967 --> 00:17:22.200
Agora, eu mencionei rapidamente que
vocês conheceram um membro

00:17:22.200 --> 00:17:25.600
da família do imperativo categórico,

00:17:25.600 --> 00:17:28.133
algo que às vezes é chamado

00:17:28.133 --> 00:17:30.200
de a fórmula da lei universal

00:17:30.200 --> 00:17:33.767
... que alguém só deve agir em
conformidade com aquela máxima

00:17:33.767 --> 00:17:39.300
pela qual você quer, ao mesmo tempo,
que se torne uma lei universal.

00:17:39.300 --> 00:17:46.433
Kant situa os imperativos
categóricos de 4 maneiras
diferentes

00:17:46.433 --> 00:17:48.967
por uma série de motivos.

00:17:48.967 --> 00:17:53.333
Um deles, diz Kant, é que
em certos casos

00:17:53.333 --> 00:17:57.367
é mais fácil ver como aplicar o
imperativo categórico

00:17:57.367 --> 00:18:01.667
se o enquadrarmos numa forma
ligeiramente diferente.

00:18:01.667 --> 00:18:05.367
Eu quero apresentá-los às outras 3,

00:18:05.367 --> 00:18:09.967
em grande parte porque a 2ª vai
desempenhar um papel central

00:18:09.967 --> 00:18:14.200
na metade final da aula de hoje.

00:18:14.200 --> 00:18:22.300
Portanto, Kant alega que

00:18:22.300 --> 00:18:23.633
dizer para agir de tal maneira

00:18:23.633 --> 00:18:26.567
que a sua máxima se torne
uma lei universal

00:18:26.567 --> 00:18:28.567
é o equivalente a dizer:

00:18:28.567 --> 00:18:31.733
"de tal maneira que use a humanidade,

00:18:31.733 --> 00:18:34.833
tanto na tua pessoa como na
pessoa de qualquer outro,

00:18:34.833 --> 00:18:43.933
sempre e simultaneamente como fim e
nunca simplesmente como meio".

00:18:43.933 --> 00:18:49.000
Não se use como um meio para um fim

00:18:49.000 --> 00:18:54.833
e não use os outros nas suas
interações com eles simplesmente

00:18:54.833 --> 00:18:58.500
como meio.

00:18:58.500 --> 00:19:08.133
Trate a humanidade e todos os
outros como fins em si mesmos.

00:19:08.133 --> 00:19:13.567
O equivalente a isso, diz Kant, é
a fórmula da autonomia,

00:19:13.567 --> 00:19:15.933
que nós já comentamos.

00:19:15.933 --> 00:19:18.533
Aja pela sua máxima, de modo que

00:19:18.533 --> 00:19:23.567
você possa ser um legislador
das leis universais.

00:19:23.567 --> 00:19:27.333
Aja de tal maneira que você
é o autolegislador

00:19:27.333 --> 00:19:30.733
em relação às regras
endossadas pela razão.

00:19:30.733 --> 00:19:34.833
E, finalmente, uma noção
bastante complicada,

00:19:34.833 --> 00:19:37.867
às vezes chamada de o reino dos fins...

00:19:37.867 --> 00:19:41.300
agir de acordo com as máximas de
um membro determinando

00:19:41.300 --> 00:19:46.400
leis universais para um
possível reino dos fins.

00:19:46.400 --> 00:19:49.300
Uma sociedade harmoniosa em
que todo mundo existe

00:19:49.300 --> 00:19:52.433
conforme as leis definidas por você.

00:19:52.433 --> 00:19:57.000
Como eu disse, temos apenas
cerca de 1 hora para Kant,

00:19:57.000 --> 00:19:59.767
por isso não vamos abordar o 3º e 4º.

00:19:59.767 --> 00:20:04.967
Mas eu quero chamar a atenção de vocês
para a fórmula da humanidade,

00:20:04.967 --> 00:20:07.500
porque ela vai desempenhar
um papel central

00:20:07.500 --> 00:20:11.333
no diagnóstico de Judy Thomson,

00:20:11.333 --> 00:20:15.500
do que pode estar ocorrendo
em nossas intuições

00:20:15.500 --> 00:20:17.733
sobre os casos do Trolley.

00:20:17.733 --> 00:20:23.233
Então deixa eu fechar a discussão de
Kant tentando reconectá-la

00:20:23.233 --> 00:20:28.200
à miniunidade da qual ela faz parte.

00:20:28.200 --> 00:20:33.733
Vocês devem se lembrar que nós
começamos esta seção do curso

00:20:33.733 --> 00:20:35.500
na última quinta-feira

00:20:35.500 --> 00:20:40.800
pensando no consequencialismo
como uma teoria moral.

00:20:40.800 --> 00:20:44.800
E a pergunta que eu quero fazer é:

00:20:44.800 --> 00:20:53.000
o que as 2 teorias morais
concretas têm em comum

00:20:53.000 --> 00:20:56.833
na nossa abordagem de
início desta unidade?

00:20:56.833 --> 00:20:59.733
Até agora, vimos algumas
das diferenças

00:20:59.733 --> 00:21:04.000
entre o consequencialismo
e a deontologia.

00:21:04.000 --> 00:21:06.067
Mas eu acho que é importante,

00:21:06.067 --> 00:21:09.033
passando para algumas de suas
aplicações práticas,

00:21:09.033 --> 00:21:11.433
refletir sobre o que elas têm em comum.

00:21:11.433 --> 00:21:16.633
E o que elas têm em comum é
que tanto a teleologia,

00:21:16.633 --> 00:21:21.733
o consequencialismo – utilitarismo, na
forma particular que encontramos –

00:21:21.733 --> 00:21:28.200
e a deontologia proíbem a
excepcionalidade da 1ª pessoa.

00:21:28.200 --> 00:21:33.533
Kant afirma: o meu desejo
pode servir de base

00:21:33.533 --> 00:21:37.167
para as ações intencionais só se
eu puder, simultaneamente,

00:21:37.167 --> 00:21:41.800
de forma coerente, querer que os outros,
em circunstâncias semelhantes,

00:21:41.800 --> 00:21:46.033
ajam da mesma forma que eu
estou escolhendo agir.

00:21:46.033 --> 00:21:50.967
Eu só estou autorizado a
fazer as coisas assumindo

00:21:50.967 --> 00:21:53.600
que as outras pessoas também
estão autorizadas a fazê-las.

00:21:53.600 --> 00:22:01.433
E Bentham, citado em Mill... Bentham, o
bisavô do utilitarismo, diz:

00:22:01.433 --> 00:22:08.200
"todo mundo conta por um,
ninguém por mais de um".

00:22:08.200 --> 00:22:10.233
Mill, no seu princípio da
maior felicidade,

00:22:10.233 --> 00:22:13.233
fala do bem-estar de todos,

00:22:13.233 --> 00:22:17.000
não do bem-estar do ponto
de vista subjetivo.

00:22:17.000 --> 00:22:28.167
Portanto, o desafio da moralidade é
ver o mundo não da postura

00:22:28.167 --> 00:22:34.233
das suas próprias necessidades
como o conjunto mais central

00:22:34.233 --> 00:22:38.967
das necessidades do mundo,
mas sim da perspectiva

00:22:38.967 --> 00:22:45.933
das suas próprias necessidades como
o conjunto de necessidades

00:22:45.933 --> 00:22:50.533
entre os 6 bilhões de seres
igualmente sencientes.

00:22:50.533 --> 00:22:53.867
O problema da moralidade

00:22:53.867 --> 00:22:58.733
é que a tendência para a
excepcionalidade da 1ª pessoa,

00:22:58.733 --> 00:23:04.033
a de tomar as suas próprias
necessidades como mais importantes

00:23:04.033 --> 00:23:08.767
que as necessidades de
qualquer outra pessoa,

00:23:08.767 --> 00:23:14.800
talvez seja o viés psicológico
mais difundido e onipresente.

00:23:14.800 --> 00:23:19.500
E quando chegarmos à unidade
sobre filosofia política,

00:23:19.500 --> 00:23:20.933
após a pausa de março,

00:23:20.933 --> 00:23:26.433
falaremos sobre as formas que
as estruturas sociais

00:23:26.433 --> 00:23:34.067
são postas em prática para ajudar a
lidar com esse tipo de tensão.

00:23:34.067 --> 00:23:40.033
Mesmo nos trechos de Mill da
quinta-feira passada,

00:23:40.033 --> 00:23:46.833
ele fala sobre que tipo de atitudes é
importante cultivar nos indivíduos

00:23:46.833 --> 00:23:52.633
para que eles comecem a ver o mundo
sob uma perspectiva moral.

00:23:52.633 --> 00:23:58.067
Nos enxertos que lemos no Livro X
do Ética a Nicômaco,

00:23:58.067 --> 00:24:00.333
Aristóteles pergunta:

00:24:00.333 --> 00:24:03.633
de que forma a sociedade
deve ser estruturada

00:24:03.633 --> 00:24:08.367
para tornar mais fácil que as
pessoas ajam moralmente?

00:24:08.367 --> 00:24:12.800
E, de certa forma, a questão com a
qual vamos encerrar o curso

00:24:12.800 --> 00:24:17.967
– como funciona a persuasão
racional versus a não-racional,

00:24:17.967 --> 00:24:21.033
quais são os papéis dos literários

00:24:21.033 --> 00:24:24.533
em oposição às representações
argumentativos da boa vida –

00:24:24.533 --> 00:24:31.900
é uma versão
operacionalizada deste
dilema.

00:24:31.900 --> 00:24:36.633
Dada uma tendência humana
inevitável a considerar

00:24:36.633 --> 00:24:39.400
as nossas necessidades como mais
importantes que a dos outros,

00:24:39.400 --> 00:24:43.500
como é possível estruturar a sociedade

00:24:43.500 --> 00:24:47.233
de tal forma que as necessidades
de todos sejam atendidas?

00:24:47.233 --> 00:24:52.367
É isso que eu quero dizer sobre Kant.

00:24:52.367 --> 00:24:54.000
E para restante da aula,

00:24:54.000 --> 00:25:02.567
peguem os seus clickers e
aproveitem o passeio.

00:25:02.567 --> 00:25:08.100
Portanto, como vocês
sabem, o texto de hoje

00:25:08.100 --> 00:25:16.867
é um grande e complexo artigo da
filósofa Judith Jarvis Thomson,

00:25:16.867 --> 00:25:22.933
escrito em meados dos anos 1980, em
resposta a um artigo anterior

00:25:22.933 --> 00:25:27.533
de outra filósofa, da metade do
século passado, Philippa Foot.

00:25:27.533 --> 00:25:34.267
E Philippa Foot e Judy Thomson
estão interessadas

00:25:34.267 --> 00:25:43.900
na exploração sistemática de uma
série de casos que parece evocar,

00:25:43.900 --> 00:25:46.400
na maioria dos indivíduos,

00:25:46.400 --> 00:25:52.467
intuições muito fortes sobre qual
é a coisa certa a fazer,

00:25:52.467 --> 00:25:56.467
mas que parece apresentar intuições

00:25:56.467 --> 00:26:03.067
para a explicação
difícil de sistematizar.

00:26:03.067 --> 00:26:06.600
Então, como vocês sabem bem,
este é o 1º caso,

00:26:06.600 --> 00:26:09.800
que chamaremos de o
maquinista do trem...

00:26:09.800 --> 00:26:12.667
aqui está ele.

00:26:12.667 --> 00:26:15.933
Há um trem desgovernado pelos trilhos,

00:26:15.933 --> 00:26:21.933
de tal forma que matará 5 pessoas.

00:26:21.933 --> 00:26:27.833
Mas acontece que existe outra via

00:26:27.833 --> 00:26:34.867
para a qual o trem pode ser desviado,
onde está somente 1 pessoa.

00:26:34.867 --> 00:26:40.500
E a pergunta agora é esta.O
maquinista está conduzindo o trem.

00:26:40.500 --> 00:26:47.000
O trem vai em direção a 5 pessoas,
de tal modo que matará as 5.

00:26:47.000 --> 00:26:53.233
O maquinista está moralmente
obrigatório, moralmente proibido

00:26:53.233 --> 00:26:59.533
ou, talvez, nem proibido nem
exigido, mas apenas permitido,

00:26:59.533 --> 00:27:05.000
a desviar o trem, onde está
somente 1 pessoa?

00:27:05.000 --> 00:27:10.067
Agora observem que, embora esteja
enquadrado como um problema

00:27:10.067 --> 00:27:14.433
idealizado, o desvio de ameaças é algo

00:27:14.433 --> 00:27:19.067
que os tomadores de decisão
enfrentam o tempo todo.

00:27:19.067 --> 00:27:24.900
Vamos supor que um avião com
problemas esteja em queda

00:27:24.900 --> 00:27:29.733
e ele deve pousar numa cidade grande,

00:27:29.733 --> 00:27:32.267
e existe a possibilidade de desviá-lo

00:27:32.267 --> 00:27:37.500
para cair numa área menos povoada.

00:27:37.500 --> 00:27:41.967
Vamos supor que exista uma doença

00:27:41.967 --> 00:27:45.467
que esteja tirando a vida
de muitas pessoas,

00:27:45.467 --> 00:27:50.100
mas se as colocarmos em quarentena,

00:27:50.100 --> 00:27:53.100
causando a morte desse número,

00:27:53.100 --> 00:27:57.333
o resto da população será salva.

00:27:57.333 --> 00:28:01.867
Caso após caso, estamos
diante de dilemas

00:28:01.867 --> 00:28:05.600
com mais ou menos a
estrutura do Trolley.

00:28:05.600 --> 00:28:10.100
Portanto, embora estes casos
sejam idealizados,

00:28:10.100 --> 00:28:14.333
no sentido de que estamos
concedendo a nós mesmos

00:28:14.333 --> 00:28:16.500
a certeza dos resultados,

00:28:16.500 --> 00:28:20.367
este não é, penso eu, um
exercício inútil,

00:28:20.367 --> 00:28:23.833
mesmo que a nossa preocupação seja
com a moralidade do mundo real,

00:28:23.833 --> 00:28:28.000
refletir sobre a coisa certa a fazer.

00:28:28.000 --> 00:28:35.733
Então vamos começar com o caso
do maquinista do trem.

00:28:35.733 --> 00:28:40.333
O trem vai pelos trilhos

00:28:40.333 --> 00:28:44.967
de tal forma que o maquinista matará
5 pessoas se não o desvia.

00:28:44.967 --> 00:28:49.567
Ele enfrenta a escolha de virar
o trem para o trilho

00:28:49.567 --> 00:28:51.067
onde está 1 pessoa.

00:28:51.067 --> 00:28:55.700
Questão: É moralmente obrigatório

00:28:55.700 --> 00:28:58.967
desviar um trem de 5 pessoas para 1?

00:28:58.967 --> 00:29:02.933
É moralmente permitido, mas não
moralmente obrigatório,

00:29:02.933 --> 00:29:05.800
desviar o trem de 5 pessoas para 1?

00:29:05.800 --> 00:29:09.433
Ou é moralmente proibido

00:29:09.433 --> 00:29:13.000
desviar o trem de 5 pessoas para 1?

00:29:22.300 --> 00:29:26.667
OK. E vamos ver os números que saem.

00:29:26.667 --> 00:29:30.233
Eu vou anotá-los, porque vamos
precisar deles mais tarde.

00:29:30.233 --> 00:29:34.867
Assim, 7% de vocês, um
número muito pequeno,

00:29:34.867 --> 00:29:39.033
acham que é moralmente proibido
para ele desviar o trem.

00:29:39.033 --> 00:29:45.800
A grande maioria, perto dos 2/3, acha
que é moralmente permitido,

00:29:45.800 --> 00:29:48.967
mas não moralmente
obrigatório, ele desviar o
trem.

00:29:48.967 --> 00:29:51.933
E cerca de 30% de vocês, 1/3,

00:29:51.933 --> 00:29:58.233
acham que ele está moralmente
obrigado a fazer tal manobra.

00:29:58.233 --> 00:30:04.233
Caso número dois: Transplante.

00:30:04.233 --> 00:30:06.633
Você trabalha num hospital.

00:30:06.633 --> 00:30:13.100
5 pessoas dão entrada no hospital,
todas destinadas a morrer,

00:30:13.100 --> 00:30:16.967
porque 1 precisa de um
pulmão, 1 de um coração,

00:30:16.967 --> 00:30:22.600
1 de um rim, 1 de um fígado
e 1 de um cérebro.

00:30:22.600 --> 00:30:27.600
Então, elas estão prestes a
morrer e você é o médico.

00:30:27.600 --> 00:30:30.600
E, na sala de emergência,

00:30:30.600 --> 00:30:36.067
entra um jovem perfeitamente
saudável que tem um coração,

00:30:36.067 --> 00:30:41.067
um pulmão, um fígado, um rim
e um cérebro ativos.

00:30:41.067 --> 00:30:46.633
Se você fatiar o homem

00:30:46.633 --> 00:30:51.000
e dar as partes dele aos 5
indivíduos em agonia,

00:30:51.000 --> 00:30:55.567
você pode salvar os 5 a custo de 1.

00:30:55.567 --> 00:31:00.400
Questão: Para o médico, é A)
moralmente obrigatório

00:31:00.400 --> 00:31:03.400
fatiar o homem saudável
para salvar os 5;

00:31:03.400 --> 00:31:05.300
B) moralmente permitido,

00:31:05.300 --> 00:31:09.233
mas não moralmente obrigatório
fatiar o homem saudável;

00:31:09.233 --> 00:31:14.500
ou C) moralmente proibido
fatiar o homem saudável?

00:31:18.500 --> 00:31:22.233
Então vamos ver os números
que saem. Portanto...

00:31:31.133 --> 00:31:35.167
85% de vocês acham que é
moralmente proibido

00:31:35.167 --> 00:31:38.333
cortar 1 pessoa para salvar 5.

00:31:38.333 --> 00:31:41.567
9% de vocês acham que é
moralmente permitido,

00:31:41.567 --> 00:31:43.867
mas não moralmente obrigatório.

00:31:43.867 --> 00:31:51.033
E 6% – fiquem longe do
curso de Medicina! –

00:31:51.033 --> 00:31:55.867
acha que é moralmente
obrigatório fatiar o homem.

00:31:55.867 --> 00:31:59.267
Então o que está acontecendo aqui?

00:31:59.267 --> 00:32:04.867
Philippa Foot, a pessoa que inicialmente
apresentou esta justaposição,

00:32:04.867 --> 00:32:05.733
tem uma hipótese.

00:32:05.733 --> 00:32:08.033
E a hipótese dela é esta.

00:32:08.033 --> 00:32:10.333
Que no caso do maquinista,

00:32:10.333 --> 00:32:16.167
a escolha que ele enfrenta é
entre matar 1 e matar 5.

00:32:16.167 --> 00:32:19.200
Ao passo que, no caso do transplante,

00:32:19.200 --> 00:32:25.000
a escolha enfrentada pelo médico é
entre matar 1 e deixar 5 morrerem.

00:32:25.000 --> 00:32:29.800
Se colocamos isso num gráfico, que eu
chamarei de "medidor-do-mau",

00:32:29.800 --> 00:32:32.667
que nos diz o quão ruim as coisas são,

00:32:32.667 --> 00:32:40.167
descobrimos que deixar 5
pessoas morrerem é ruim,

00:32:40.167 --> 00:32:48.767
mas matar é pior, e matar
5 é ainda pior.

00:32:48.767 --> 00:32:50.933
E parece que isso nos dá a resposta

00:32:50.933 --> 00:32:53.967
que matar 5 é pior que matar 1,

00:32:53.967 --> 00:32:57.967
portanto no caso do maquinista,
está bem ele desviar o trem,

00:32:57.967 --> 00:33:01.733
mas como matar 1 é pior que
deixar 5 morrerem,

00:33:01.733 --> 00:33:06.767
no caso do médico, não está
bem fatiar 1 homem.

00:33:06.767 --> 00:33:10.267
Porque no caso do médico, você tem
de matar 1 para salvar 5,

00:33:10.267 --> 00:33:12.033
enquanto que no caso do trem,

00:33:12.033 --> 00:33:16.733
o maquinista tem de matar 1 a
fim de não matar 5.

00:33:16.733 --> 00:33:21.200
E isso parece estar muito bem de acordo
com as intuições de vocês.

00:33:21.200 --> 00:33:26.700
93% acham que é permitido, no
caso do trem, desviá-lo,

00:33:26.700 --> 00:33:30.267
enquanto que apenas 14%
acham que é permitido,

00:33:30.267 --> 00:33:33.600
no caso do médico, matar o homem.

00:33:33.600 --> 00:33:38.100
Portanto, parece que
medidor-do-mau é muito bom em
captar

00:33:38.100 --> 00:33:41.033
a intuição dos presentes nesta sala.

00:33:41.033 --> 00:33:43.700
E, de fato, os estudos
empíricos realizados

00:33:43.700 --> 00:33:46.767
em milhares de pessoas em todo o mundo

00:33:46.767 --> 00:33:49.567
sugerem que as intuições de vocês
estão praticamente alinhadas

00:33:49.567 --> 00:33:51.933
com as intuições da maioria.

00:33:51.933 --> 00:33:54.933
Mas há um problema.

00:33:54.933 --> 00:33:59.100
Caso número 3: testemunha do trem.

00:33:59.100 --> 00:34:00.167
Aqui está Jim.

00:34:00.167 --> 00:34:00.900
Coitado do Jim.

00:34:00.900 --> 00:34:02.367
Muito azar.

00:34:02.367 --> 00:34:04.167
1º, ele aparece numa
cidade latino-americana

00:34:04.167 --> 00:34:05.933
e tem de atirar em alguns índios.

00:34:05.933 --> 00:34:09.767
Agora, aqui está ele, próximo
a um trem desgovernado

00:34:09.767 --> 00:34:11.300
que está a ponto de matar 5 pessoas.

00:34:11.300 --> 00:34:17.267
Mas aqui, no meio da via, há uma
alavanca que possibilita a Jim

00:34:17.267 --> 00:34:19.633
desviar o trem para matar 1.

00:34:19.633 --> 00:34:23.867
Questão: Para Jim, a testemunha,

00:34:23.867 --> 00:34:28.033
é moralmente obrigatório
desviar o trem de modo que,

00:34:28.033 --> 00:34:33.000
em vez de o trem se chocar com
5 pessoas, atinja 1?

00:34:33.000 --> 00:34:35.233
É moralmente permitido,

00:34:35.233 --> 00:34:38.100
mas não moralmente obrigatório
para ele desviar o trem?

00:34:38.100 --> 00:34:39.533
Essa é a resposta 2.

00:34:39.533 --> 00:34:45.267
Ou é moralmente proibido para
ele desviar o trem?

00:34:45.267 --> 00:34:49.100
Vamos ver como saem estes números.

00:34:59.100 --> 00:35:01.233
OK. E aqui estão os seus números.

00:35:01.233 --> 00:35:03.533
15, 70, 15.

00:35:03.533 --> 00:35:07.000
Eles são muito parecidos

00:35:07.000 --> 00:35:11.533
com a distribuição de respostas
dada no caso do maquinista.

00:35:11.533 --> 00:35:13.000
No caso do maquinista,

00:35:13.000 --> 00:35:16.667
63% de vocês acharam que era
moralmente permitido,

00:35:16.667 --> 00:35:20.533
ao passo que agora 70% acham que
é moralmente permitido.

00:35:20.533 --> 00:35:21.767
No caso do maquinista,

00:35:21.767 --> 00:35:24.600
30% acharam que era
moralmente obrigatório.

00:35:24.600 --> 00:35:28.833
Desta vez, um pouco menos acha que é
moralmente obrigatório:15%.

00:35:28.833 --> 00:35:33.867
E, no caso do maquinista, 7% de
vocês acharam que era proibido.

00:35:33.867 --> 00:35:36.900
Aqui, 15% acham que é
moralmente proibido.

00:35:36.900 --> 00:35:41.000
Portanto, há uma pequena
mudança, mas não muita.

00:35:41.000 --> 00:35:44.267
Aqui está o problema.

00:35:44.267 --> 00:35:49.467
Lembrem-se que na análise
do caso de Foot,

00:35:49.467 --> 00:35:52.967
sabíamos que deixar 5 pessoas
morrerem era um pouco ruim,

00:35:52.967 --> 00:35:59.733
que matar 1 era pior e que
matar 5 era ainda pior.

00:35:59.733 --> 00:36:03.667
O maquinista enfrentou a escolha
de matar 1 contra matar 5.

00:36:03.667 --> 00:36:06.600
No transplante, você enfrenta
a escolha de matar 1

00:36:06.600 --> 00:36:08.700
contra deixar 5 morrerem.

00:36:08.700 --> 00:36:14.533
Mas o que sucede no caso da testemunha?

00:36:14.533 --> 00:36:19.833
Bem, no caso da testemunha,
Jim, o azarado Jim,

00:36:19.833 --> 00:36:23.867
enfrenta uma escolha entre matar 1

00:36:23.867 --> 00:36:30.233
– desviando o trem de tal forma
que Jim mata este cara –

00:36:30.233 --> 00:36:35.267
ou deixar 5 morrerem.

00:36:35.267 --> 00:36:40.667
Deixar o trem atingir 5 pessoas, que
seriam atingidas inevitavelmente.

00:36:40.667 --> 00:36:44.333
Mas em contraste com o caso do médico,

00:36:44.333 --> 00:36:50.000
onde 85% de vocês acharam que
era proibido matar 1

00:36:50.000 --> 00:36:54.200
para salvar 5 pessoas que, de
outra forma, morreriam;

00:36:54.200 --> 00:37:00.900
neste caso, 85% de vocês acham que
é, no mínimo, permitido

00:37:00.900 --> 00:37:06.533
matar 1 para evitar a morte de 5.

00:37:06.533 --> 00:37:08.200
Vou fazer isso novamente.

00:37:08.200 --> 00:37:15.767
85% de vocês... vejam o medidor... acham
que ele vai para o outro lado.

00:37:15.767 --> 00:37:17.400
O que está acontecendo agora?

00:37:17.400 --> 00:37:19.833
Pensávamos que tínhamos uma
solução para o problema.

00:37:19.833 --> 00:37:23.967
A solução para o problema que
diferenciava o transplante do maquinista

00:37:23.967 --> 00:37:27.800
foi a distinção entre
matar e deixar morrer.

00:37:27.800 --> 00:37:32.400
E, de repente, muitos de vocês
parecem estar dizendo,

00:37:32.400 --> 00:37:38.033
no caso da testemunha, que deixar 5
morrerem é pior que matar 1.

00:37:38.033 --> 00:37:41.033
Vocês devem achar ou
não deveriam achar

00:37:41.033 --> 00:37:46.567
que é moralmente permitido
para ele desviar o trem.

00:37:46.567 --> 00:37:52.367
Mas a coisa fica ainda pior.

00:37:52.367 --> 00:37:58.567
Vamos supor no caso do
hospital da seguinte forma.

00:37:58.567 --> 00:38:05.633
5 indivíduos saudáveis
??apresentam-se no hospital e um
médico

00:38:05.633 --> 00:38:09.367
– seja porque ele está cansado ou
porque ele quer obter os benefícios

00:38:09.367 --> 00:38:13.500
do seguro em que é um beneficiário

00:38:13.500 --> 00:38:16.100
caso haja muitos pacientes
doentes no seu hospital –

00:38:16.100 --> 00:38:18.567
envenena os 5,

00:38:18.567 --> 00:38:21.367
de tal forma que 1 deles
precisa de um fígado,

00:38:21.367 --> 00:38:22.967
1 precisa de um rim, 1 de
pulmões, 1 de um coração

00:38:22.967 --> 00:38:25.200
e 1 precisa de um cérebro.

00:38:25.200 --> 00:38:29.700
E assim, como resultado do
que esse homem fez,

00:38:29.700 --> 00:38:33.633
essas 5 pessoas vão morrer.

00:38:33.633 --> 00:38:36.533
E algumas horas mais tarde, ele pensa:

00:38:36.533 --> 00:38:40.733
"Oh! Eu esqueci o
imperativo categórico!

00:38:40.733 --> 00:38:43.900
Droga! O que eu vou fazer?"

00:38:43.900 --> 00:38:47.867
E entra um indivíduo
saudável e ele pensa:

00:38:47.867 --> 00:38:52.233
"Ah, ótimo! Eu tenho uma solução,
aqui, eu posso cortá-lo.

00:38:52.233 --> 00:38:56.700
Coração, pulmão, rins,
fígado, cérebro...

00:38:56.700 --> 00:39:00.167
posso salvar os 5. OK".

00:39:00.167 --> 00:39:03.000
Questão: Para o médico que envenenou
os 5 indivíduos do hospital,

00:39:03.000 --> 00:39:04.400
que enfrenta agora a opção de
salvar as vidas deles

00:39:04.400 --> 00:39:09.467
matando 1, é

00:39:09.467 --> 00:39:12.967
A) moralmente obrigatório
cortar o homem saudável;

00:39:12.967 --> 00:39:14.900
B) moralmente permitido,

00:39:14.900 --> 00:39:17.600
mas não é moralmente obrigatório
fatiar o homem saudável;

00:39:17.600 --> 00:39:21.867
ou C) moralmente proibido
cortar o homem saudável?

00:39:21.867 --> 00:39:25.133
E vamos ver os números que saem.

00:39:32.800 --> 00:39:36.733
Tudo bem. So.

00:39:36.733 --> 00:39:39.567
82%, 11%, 7%.

00:39:39.567 --> 00:39:41.833
Os seus números aqui são
quase idênticos

00:39:41.833 --> 00:39:45.267
ao que eram no caso original do médico.

00:39:45.267 --> 00:39:50.533
Daquela vez, foram 6, 9 e 85;
aqui são 7, 11 e 82.

00:39:50.533 --> 00:39:53.100
Quase não há diferença.

00:39:53.100 --> 00:39:57.033
Mas vamos voltar ao nosso
medidor-do-mau.

00:39:57.033 --> 00:40:01.167
Vamos deixar de lado a questão
de matar e deixar morrer

00:40:01.167 --> 00:40:04.133
e nos concentrar em matar
1 contra matar 5.

00:40:04.133 --> 00:40:09.967
Nós sabemos pelo maquinista do trem
que matar 1 é muito ruim.

00:40:09.967 --> 00:40:12.367
Mas de acordo com a maioria de vocês,

00:40:12.367 --> 00:40:19.767
de acordo com 93%, matar 5
é pior que matar 1.

00:40:19.767 --> 00:40:24.333
OK. Médico do veneno.

00:40:24.333 --> 00:40:29.133
Aqui está a escolha
enfrentada pelo médico.

00:40:29.133 --> 00:40:35.733
Ele pode matar 5... certo? Ele os
envenenou e agora eles vão morrer.

00:40:35.733 --> 00:40:41.067
Ou ele pode matar 1, um cara
saudável, que acaba de aparecer.

00:40:41.067 --> 00:40:43.867
E os outros 5 não vão morrer.

00:40:43.867 --> 00:40:54.600
82% de vocês me disseram que era
melhor ele matar 5 que matar 1.

00:40:54.600 --> 00:40:57.600
Deixa eu mostrar isso de
novo, no medidor.

00:40:57.600 --> 00:41:06.700
85% de vocês acharam que era
melhor ele matar 5 que matar 1.

00:41:06.700 --> 00:41:10.867
Então, temos esses 2
excelentes princípios

00:41:10.867 --> 00:41:14.500
que parecem explicar o que
ocorria no caso do trem.

00:41:14.500 --> 00:41:18.867
Por um lado, que matar 1 era pior
que deixar 5 morrerem e,

00:41:18.867 --> 00:41:20.700
então, de repente, a
testemunha nos faz pensar:

00:41:20.700 --> 00:41:22.967
Oh, não, nós não temos
essa intuição.

00:41:22.967 --> 00:41:26.833
Temos a intuição de que matar 1 deles

00:41:26.833 --> 00:41:28.700
era melhor que matar 5...

00:41:28.700 --> 00:41:33.633
e o caso do veneno nos faz
repensar isso outra vez.

00:41:33.633 --> 00:41:36.667
Agora, há uma questão óbvia

00:41:36.667 --> 00:41:39.567
que pode estar fazendo a
diferença moral aqui.

00:41:39.567 --> 00:41:41.633
Há uma diferença temporal

00:41:41.633 --> 00:41:46.000
entre quando acontece a morte
de 1 e a morte de 5.

00:41:46.000 --> 00:41:48.033
E talvez, diz Thomson,

00:41:48.033 --> 00:41:53.900
isso é o que explica a nossa
intuição, no caso do médico.

00:41:53.900 --> 00:42:00.267
Talvez seja porque a morte de 5 se
tornou um deixar morrer,

00:42:00.267 --> 00:42:03.667
como resultado do tempo, que é enganoso

00:42:03.667 --> 00:42:08.800
descrever isso como um caso de
matar 1 contra matar 5.

00:42:08.800 --> 00:42:12.133
Mas o temporal não atua

00:42:12.133 --> 00:42:16.467
no caso do transplante
versus o da testemunha.

00:42:16.467 --> 00:42:20.967
Parece muito claro que em ambos casos

00:42:20.967 --> 00:42:27.267
se enfrenta a escolha entre matar
1 e deixar 5 morrerem.

00:42:27.267 --> 00:42:30.233
E ao passo que isso parecia
bastante claro para a maioria

00:42:30.233 --> 00:42:32.200
de vocês no transplante,

00:42:32.200 --> 00:42:35.067
que matar 1 era pior que
deixar 5 morrerem,

00:42:35.067 --> 00:42:39.900
na testemunha,

00:42:39.900 --> 00:42:42.300
parece bastante claro o contrário.

00:42:42.300 --> 00:42:44.000
Portanto, o problema do trem

00:42:44.000 --> 00:42:50.367
é o problema levantado por
estas setas de dança.

00:42:50.367 --> 00:42:56.367
Como é que sistematizamos as
nossas intuições sobre matar

00:42:56.367 --> 00:43:01.700
e deixar morrer, já que elas
parecem desconexas?

00:43:01.700 --> 00:43:07.100
Thomson sugere que ainda que o
caso do transplante

00:43:07.100 --> 00:43:09.933
nos dê uma escolha entre matar
1 e deixar 5 morrerem,

00:43:09.933 --> 00:43:12.133
como o da testemunha,

00:43:12.133 --> 00:43:16.800
existe uma diferença relevante
de potencial entre eles.

00:43:16.800 --> 00:43:20.633
E isso porque, no caso do transplante,

00:43:20.633 --> 00:43:25.600
você está usando 1
pessoa como um meio.

00:43:25.600 --> 00:43:30.367
Você está usando-a como uma forma
de alcançar o resultado

00:43:30.367 --> 00:43:32.267
de salvar os outros 5.

00:43:32.267 --> 00:43:34.533
Ao passo que, na testemunha,

00:43:34.533 --> 00:43:38.867
quando você desvia o trem para a
via onde um indivíduo está,

00:43:38.867 --> 00:43:41.967
você não está usando esse
indivíduo como um meio e...

00:43:41.967 --> 00:43:44.600
oh meu Deus, eu disse que
voltaríamos a Kant, e aqui estamos!

00:43:44.600 --> 00:43:46.600
O que diz a fórmula da
humanidade de Kant?

00:43:46.600 --> 00:43:48.300
A fórmula da humanidade de
Kant diz para agir

00:43:48.300 --> 00:43:50.733
"de tal maneira que use a humanidade,

00:43:50.733 --> 00:43:53.567
tanto na tua pessoa como na
pessoa de qualquer outro,

00:43:53.567 --> 00:43:55.233
sempre e simultaneamente como fim

00:43:55.233 --> 00:43:59.000
e nunca simplesmente como meio".

00:43:59.000 --> 00:44:01.200
Talvez essa seja a nossa solução.

00:44:01.200 --> 00:44:04.500
Talvez o problema na testemunha

00:44:04.500 --> 00:44:08.167
seja que como você não está
tratando como um meio,

00:44:08.167 --> 00:44:10.033
não há problema em matar 1.

00:44:10.033 --> 00:44:11.500
Enquanto que, no transplante,

00:44:11.500 --> 00:44:16.033
você está tratando como um meio,
não está bem matar 1 e,

00:44:16.033 --> 00:44:17.167
consequentemente,

00:44:17.167 --> 00:44:22.000
você é moralmente obrigado a
deixar os 5 morrerem.

00:44:22.000 --> 00:44:26.267
Bem, diz Thomson, isso
não é bem assim.

00:44:26.267 --> 00:44:30.600
Vamos supor que você seja o Jim,
de pé ao lado do trem.

00:44:30.600 --> 00:44:32.433
O trem está no seu caminho habitual

00:44:32.433 --> 00:44:33.300
para matar 5.

00:44:33.300 --> 00:44:37.200
Mas em vez da via em linha reta,

00:44:37.200 --> 00:44:42.900
há uma via em circuito, e 1
pessoa está no meio da via

00:44:42.900 --> 00:44:45.567
de tal forma que se você
desviar o trem,

00:44:45.567 --> 00:44:50.533
ele vai bater nela,
salvando as outras 5.

00:44:50.533 --> 00:44:56.267
Questão. No caso em que Thomson
chama de "circuito", é

00:44:56.267 --> 00:45:00.367
A) moralmente obrigatório
desviar o trem.

00:45:00.367 --> 00:45:03.767
B) Moralmente permitido, mas não
moralmente obrigatório;

00:45:03.767 --> 00:45:05.233
ou C) moralmente proibido?

00:45:05.233 --> 00:45:09.000
Lembrem-se que trem está indo na via
em direção às 5 pessoas.

00:45:09.000 --> 00:45:10.533
Você é o Jim.

00:45:10.533 --> 00:45:12.467
O trem vai atingir os 5

00:45:12.467 --> 00:45:15.733
ou você pode desviar o trem
para a via com 1,

00:45:15.733 --> 00:45:24.400
e porque há 1 pessoa lá, você
fará com que o trem pare.

00:45:24.400 --> 00:45:28.533
OK? Então vamos ver os
números que saem desta vez.

00:45:38.667 --> 00:45:44.633
OK. 68, 18, 14.

00:45:44.633 --> 00:45:47.833
Não muita diferentes.

00:45:47.833 --> 00:45:53.000
Vocês responderam quase da mesma forma

00:45:53.000 --> 00:45:55.200
que responderam a todos os outros
casos envolvendo o trem.

00:45:55.200 --> 00:45:59.633
Em geral, a distribuição
foi de 15, 70, 15.

00:45:59.633 --> 00:46:00.900
Essa foi a da testemunha.

00:46:00.900 --> 00:46:04.000
Desta vez: 14, 68, 18.

00:46:04.000 --> 00:46:06.800
Mas observem que, neste caso,

00:46:06.800 --> 00:46:10.900
vocês estavam usando o cara
na via como um meio!

00:46:10.900 --> 00:46:13.200
Vocês estão usando ele como
um meio para o seu fim.

00:46:13.200 --> 00:46:18.433
Vocês estão tentando parar o
trem usando o corpo dele.

00:46:18.433 --> 00:46:23.067
Kant não nos ajudou em
nada! Reabastecendo.

00:46:23.067 --> 00:46:25.600
Vamos fazer um novo
balanço, diz Thomson.

00:46:25.600 --> 00:46:29.133
Talvez um pouco do trabalho
esteja sendo feito

00:46:29.133 --> 00:46:32.533
por alguma noção de direitos.

00:46:32.533 --> 00:46:36.800
Talvez o que esteja acontecendo
no caso do transplante,

00:46:36.800 --> 00:46:40.733
aquele em que vocês não deixam que o
médico fatie o homem saudável,

00:46:40.733 --> 00:46:43.800
é que você estaria violando
os direitos do homem.

00:46:43.800 --> 00:46:45.233
E talvez seja verdade que

00:46:45.233 --> 00:46:47.500
"os direitos triunfem
sobre a utilidade".

00:46:47.500 --> 00:46:50.933
Isto é, que quando alguém tem
direito à integridade física,

00:46:50.933 --> 00:46:55.667
isso tem prioridade sobre as
necessidades de muitos.

00:46:55.667 --> 00:46:58.900
As utilidades dos 5 que serão salvos.

00:46:58.900 --> 00:47:02.733
E vamos terminar esta aula com
um último exemplo,

00:47:02.733 --> 00:47:06.333
destinado a testar essa hipótese.

00:47:06.333 --> 00:47:09.033
E vamos começar a próxima aula falando

00:47:09.033 --> 00:47:12.300
sobre algumas das razões que as
pessoas tendem a dar esta resposta.

00:47:12.300 --> 00:47:18.067
Vamos supor agora que, em vez do
circuito, exista uma ponte.

00:47:18.067 --> 00:47:25.467
E que naquela ponte esteja um
senhor bastante gordo.

00:47:25.467 --> 00:47:30.000
E agora vocês enfrentam o
seguinte dilema.

00:47:30.000 --> 00:47:31.800
O trem segue pelos trilhos.

00:47:31.800 --> 00:47:33.333
Está prestes a matar 5 pessoas.

00:47:33.333 --> 00:47:37.433
E assim é como Jim, a
testemunha, pode pará-lo.

00:47:37.433 --> 00:47:42.567
Ele pode empurrar o homem gordo
da ponte e fazer com

00:47:42.567 --> 00:47:46.667
que o trem pare devido ao peso do homem.

00:47:46.667 --> 00:47:50.567
Questão. Para a
testemunha no homem gordo,

00:47:50.567 --> 00:47:53.433
é moralmente obrigatório empurrá-lo,

00:47:53.433 --> 00:47:56.833
moralmente permitido, mas não
moralmente obrigatório,

00:47:56.833 --> 00:48:00.500
ou moralmente proibido empurrá-lo?

00:48:00.500 --> 00:48:04.267
Vamos dar as respostas e eu vou
deixar vocês com esses números

00:48:04.267 --> 00:48:08.133
e uma observação sobre eles
em nosso encerramento.

00:48:08.133 --> 00:48:13.833
Então, vamos ver se temos alguma
mudança no caso do homem gordo.

00:48:13.833 --> 00:48:16.867
Meu Deus! Isso parece
completamente diferente.

00:48:16.867 --> 00:48:19.033
O que está acontecendo?

00:48:19.033 --> 00:48:21.633
Lembrem-se que a nossa
distribuição clássica

00:48:21.633 --> 00:48:25.733
é a que temos uns 70% aqui, e não
mais de 10% em proibido.

00:48:25.733 --> 00:48:29.133
De repente, 78% de vocês
pensam que é proibido.

00:48:29.133 --> 00:48:30.767
O que está acontecendo?

00:48:30.767 --> 00:48:32.333
Suspense!

00:48:32.333 --> 00:48:35.333
Falaremos sobre isso na terça.

