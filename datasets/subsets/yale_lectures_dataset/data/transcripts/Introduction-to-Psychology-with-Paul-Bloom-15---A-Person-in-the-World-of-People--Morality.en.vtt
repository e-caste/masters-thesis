WEBVTT
Kind: captions
Language: en

00:00:12.800 --> 00:00:16.737
Professor Paul Bloom:
Let me begin by just reminding

00:00:16.737 --> 00:00:20.945
us where we are in this course,
reminding us of what we've done

00:00:20.945 --> 00:00:25.112
and what we have yet to do.
We started by talking about the

00:00:25.112 --> 00:00:27.640
brain, the physical basis of
thought.

00:00:27.640 --> 00:00:30.826
And then we moved to some
general introductions to some

00:00:30.826 --> 00:00:33.481
foundational ideas in the study
of psychology,

00:00:33.481 --> 00:00:36.611
Freud and Skinner.
We spent a bit of time on more

00:00:36.611 --> 00:00:38.320
cognitive stuff:
development,

00:00:38.320 --> 00:00:40.030
language, vision,
memory.

00:00:40.030 --> 00:00:43.850
Then we took a little break and
the dean told us about love.

00:00:43.850 --> 00:00:47.949
Then we dealt with the
emotions, rationality,

00:00:47.949 --> 00:00:51.210
and evolution,
and a lot of that.

00:00:51.210 --> 00:00:54.778
What we learned particularly
regarding the evolution of the

00:00:54.778 --> 00:00:58.040
mind provided supporting
material for what follows.

00:00:58.040 --> 00:01:04.328
We learned about cognitive
neuroscience using the study of

00:01:04.328 --> 00:01:11.500
face recognition as an important
case study--human differences,

00:01:11.500 --> 00:01:14.757
behavioral genetics,
nature and nurture,

00:01:14.757 --> 00:01:18.790
sex and food.
My lecture was on sex.

00:01:18.790 --> 00:01:20.525
Dr.
Brownell came and spoke to us

00:01:20.525 --> 00:01:23.500
about food.
Today, morality.

00:01:23.500 --> 00:01:29.168
Next week, social thought and
social behavior,

00:01:29.168 --> 00:01:32.560
mysteries;
basically, a series of topics

00:01:32.560 --> 00:01:35.931
that don't fit anywhere in the
course and really make

00:01:35.931 --> 00:01:38.330
psychologists scratch their
heads.

00:01:38.330 --> 00:01:44.550
These topics are sleep,
laughter, and religion,

00:01:44.550 --> 00:01:50.230
mental illness,
two lectures on madness,

00:01:50.230 --> 00:01:54.665
what can go wrong in your
minds, and a last lecture on

00:01:54.665 --> 00:01:58.810
happiness.
And then you're just done.

00:01:58.810 --> 00:02:02.943
You know a lot of psychology
and a lot of stuff and you're

00:02:02.943 --> 00:02:06.859
well prepared for your ultimate
major in psychology,

00:02:06.859 --> 00:02:09.889
ultimately graduate training at
a good school.

00:02:09.889 --> 00:02:15.642
How many people here are either
psych majors or expect to become

00:02:15.642 --> 00:02:20.389
psych majors or cognitive
science as though you could

00:02:20.389 --> 00:02:23.360
raise your hand to?
Okay.

00:02:23.360 --> 00:02:26.328
Good.
It's nowhere near enough

00:02:26.328 --> 00:02:29.224
[laughter]
and so I'll ask the question

00:02:29.224 --> 00:02:31.527
again.
Once you deal with happiness

00:02:31.527 --> 00:02:34.416
and then mysteries,
you're really not going to want

00:02:34.416 --> 00:02:36.600
to--What is there?
Chemistry?

00:02:36.600 --> 00:02:39.250
Anthropology?
[laughter] Pre-med?

00:02:39.250 --> 00:02:41.349
Give me a break.
[laughter] Okay.

00:02:41.349 --> 00:02:46.199
We're going to deal with three
facets of morality.

00:02:46.199 --> 00:02:49.935
I'm going to talk about moral
feelings, moral judgments,

00:02:49.935 --> 00:02:53.602
and then moral action with
particular focus on why good

00:02:53.602 --> 00:02:57.480
people do bad things,
which will lead us to review

00:02:57.480 --> 00:03:01.840
and discuss the Milgram study,
which was presented in the

00:03:01.840 --> 00:03:06.292
movie on Monday.
Now, moral feeling is what

00:03:06.292 --> 00:03:12.809
we'll start off with and we've
already discussed this in a

00:03:12.809 --> 00:03:16.198
different context.
The question is,

00:03:16.198 --> 00:03:18.360
'How could moral feelings
evolve?"

00:03:18.360 --> 00:03:22.059
So, moral feelings we could
view as feelings of

00:03:22.059 --> 00:03:24.713
condemnation,
shame, emotions like

00:03:24.713 --> 00:03:26.928
that--shame,
condemnation,

00:03:26.928 --> 00:03:30.430
pride, righteous anger,
but also simple affection,

00:03:30.430 --> 00:03:34.045
caring for other people,
wanting to do well by them,

00:03:34.045 --> 00:03:37.229
being upset if an injustice is
to be done by them.

00:03:37.229 --> 00:03:41.887
And you might think that the
existence of these feelings is a

00:03:41.887 --> 00:03:45.379
mystery from an evolutionary
point of view.

00:03:45.379 --> 00:03:50.584
If evolution is survival of the
fittest, nature red in tooth and

00:03:50.584 --> 00:03:54.550
claw, how could animals evolve
moral feelings?

00:03:54.550 --> 00:03:58.080
But in fact,
we know the answer to this.

00:03:58.080 --> 00:03:59.490
And there are two answers to
this.

00:03:59.490 --> 00:04:03.913
One answer is kin selection.
So, evolution works at a level

00:04:03.913 --> 00:04:09.003
of the genes and because of that
it could give rise to animals

00:04:09.003 --> 00:04:13.349
that are themselves altruistic.
And they're altruistic because

00:04:13.349 --> 00:04:16.017
they act to preserve other
animals that share the same

00:04:16.017 --> 00:04:18.333
genes.
And so, I'm not going to spend

00:04:18.333 --> 00:04:21.750
any time on this because we've
discussed it in detail,

00:04:21.750 --> 00:04:25.510
but we know from previous
lectures that people will be

00:04:25.510 --> 00:04:28.875
generous to others.
And there's an evolutionary

00:04:28.875 --> 00:04:32.000
explanation for your generosity
towards kin.

00:04:32.000 --> 00:04:34.060
It could be mathematically
worked out.

00:04:34.060 --> 00:04:36.780
Your caring,
your moral feelings towards

00:04:36.780 --> 00:04:41.244
other creatures to the extent of
the proportion of genes that you

00:04:41.244 --> 00:04:45.155
share with them.
The most altruistic behavior of

00:04:45.155 --> 00:04:49.780
all, giving your life to help
another, can be explained in

00:04:49.780 --> 00:04:54.713
cold-blooded evolutionary terms.
Animals that are altruistic

00:04:54.713 --> 00:04:57.969
even to the point of dying to
help another,

00:04:57.969 --> 00:05:01.558
those genes will,
under some circumstances,

00:05:01.558 --> 00:05:06.370
be preserved over the genes of
people who are less caring.

00:05:06.370 --> 00:05:10.160
And that is one force towards
kindness.

00:05:10.160 --> 00:05:15.600
A second force towards kindness
is cooperation.

00:05:15.600 --> 00:05:20.360
Even if animals are unrelated,
they are nice to one another.

00:05:20.360 --> 00:05:24.084
Animals will give warning
cries, they will groom one

00:05:24.084 --> 00:05:26.639
another, they will exchange
food,

00:05:26.639 --> 00:05:30.806
and the reason for this is that
animals have evolved,

00:05:30.806 --> 00:05:34.197
our minds have evolved,
to enter into sort of

00:05:34.197 --> 00:05:37.830
cooperative situations with
other people and to surmount

00:05:37.830 --> 00:05:41.807
prisoner's dilemmas,
to surmount deception and

00:05:41.807 --> 00:05:45.084
cheating.
This gives rise to some emotion

00:05:45.084 --> 00:05:49.449
including emotions that could be
viewed as moral emotions,

00:05:49.449 --> 00:05:55.080
like guilt and anger,
and again, grounds altruistic

00:05:55.080 --> 00:05:59.810
behavior in an evolutionary
perspective.

00:05:59.810 --> 00:06:04.275
This is all by means of review
but the question you can now ask

00:06:04.275 --> 00:06:07.294
is, "Fine.
That's why moral feelings might

00:06:07.294 --> 00:06:10.978
evolve, but what do we know as
psychologists about the

00:06:10.978 --> 00:06:14.870
emergence in nature of moral
feelings in individuals?

00:06:14.870 --> 00:06:17.500
What's the psychology of moral
feeling?"

00:06:17.500 --> 00:06:20.680
And this is an issue I'm going
to talk about now but I'm going

00:06:20.680 --> 00:06:23.861
to return to next week when we
deal with issues such as liking

00:06:23.861 --> 00:06:26.964
and disliking,
racial prejudice and other

00:06:26.964 --> 00:06:29.310
things.
But I want to deal now with a

00:06:29.310 --> 00:06:32.438
couple of interesting case
studies about moral feelings

00:06:32.438 --> 00:06:34.639
from a psychological point of
view.

00:06:34.639 --> 00:06:39.009
The first one I want to deal
with is empathy.

00:06:39.009 --> 00:06:45.834
And empathy has different
definitions but we can simply

00:06:45.834 --> 00:06:52.660
view it as the feeling that your
pain matters to me.

00:06:52.660 --> 00:06:55.752
If you are hurt,
that is, in some sense,

00:06:55.752 --> 00:06:58.387
painful for me.
If you are sad,

00:06:58.387 --> 00:07:02.199
that affects my own mood.
I am not a selfish creature.

00:07:02.199 --> 00:07:06.740
I am built, I am hard wired,
to be attuned to your pain.

00:07:06.740 --> 00:07:11.268
This is an old observation.
Adam Smith, who is often

00:07:11.268 --> 00:07:16.251
falsely viewed as a proponent of
selfishness and hardheadedness,

00:07:16.251 --> 00:07:19.890
was quite explicit about the
pull this has.

00:07:19.890 --> 00:07:22.681
He notes: 
When we see a stroke

00:07:22.681 --> 00:07:25.315
aimed and just ready to fall
upon the leg or arm of another

00:07:25.315 --> 00:07:27.328
person,
we naturally shrink and draw

00:07:27.328 --> 00:07:30.834
back our own leg or arm and when
it does fall we feel it in some

00:07:30.834 --> 00:07:33.839
measure and are hurt by it as
well as the sufferer.

00:07:33.839 --> 00:07:37.616
If you see somebody being
kicked in the groin in a movie,

00:07:37.616 --> 00:07:41.899
you might yourself tense up.
If you see somebody bang their

00:07:41.899 --> 00:07:45.290
thumb with a hammer,
you might cringe.

00:07:45.290 --> 00:07:48.920
Here is a good illustration of
somebody in anticipatory pain.

00:07:54.139 --> 00:07:59.927
[laughter]
Now--It's a very British face

00:07:59.927 --> 00:08:02.288
actually.
[laughter]

00:08:02.288 --> 00:08:05.641
Now, we know certain things
about this empathy,

00:08:05.641 --> 00:08:10.992
some which might be surprising.
The pain of others is aversive

00:08:10.992 --> 00:08:15.260
even for babies.
We know this because if babies

00:08:15.260 --> 00:08:19.310
hear other babies crying they
will get upset.

00:08:19.310 --> 00:08:22.850
The crying of babies is
aversive to babies.

00:08:22.850 --> 00:08:26.142
Now, some of you may be
sufficiently cynical to say,

00:08:26.142 --> 00:08:28.790
"That could be explained in
other ways.

00:08:28.790 --> 00:08:31.970
For one thing,
one theory is that babies hear

00:08:31.970 --> 00:08:35.223
other babies cry,
because babies are so stupid

00:08:35.223 --> 00:08:38.259
they think they themselves are
crying;

00:08:38.259 --> 00:08:41.847
if they're crying they must be
in some sort of pain so they cry

00:08:41.847 --> 00:08:44.919
some more."
But clever psychologists have

00:08:44.919 --> 00:08:48.344
ruled this out.
What they did was a study where

00:08:48.344 --> 00:08:51.872
they exposed babies to
tape-recorded sounds of other

00:08:51.872 --> 00:08:56.230
babies crying and tape recorded
sounds of themselves crying.

00:08:56.230 --> 00:09:01.625
Babies cry more to this pain of
other babies than they do to

00:09:01.625 --> 00:09:05.051
their own pain,
suggesting that their response

00:09:05.051 --> 00:09:08.356
is to some extent a response to
the "otherness" of the

00:09:08.356 --> 00:09:11.520
characters.
We know pain is--of others is

00:09:11.520 --> 00:09:16.179
aversive for chimpanzees and we
know this in certain ways.

00:09:16.179 --> 00:09:17.785
But we know this,
in particular,

00:09:17.785 --> 00:09:20.892
from a series of studies that
would be unethical if they were

00:09:20.892 --> 00:09:23.762
to be done today.
In these studies,

00:09:23.762 --> 00:09:29.320
they put a chimpanzee in a room
and there's a lever.

00:09:29.320 --> 00:09:33.460
And when the chimpanzee slaps
the lever, it gets some food.

00:09:33.460 --> 00:09:35.990
Trivial, smart animal,
piece of cake.

00:09:35.990 --> 00:09:39.759
But the room has a window
leading to another room.

00:09:39.759 --> 00:09:43.720
And in the other room another
chimpanzee is placed.

00:09:43.720 --> 00:09:48.670
This second chimpanzee is not a
relative of the first chimpanzee

00:09:48.670 --> 00:09:52.049
and they've never seen each
other before.

00:09:52.049 --> 00:09:55.991
Now, when the first chimpanzee
hits the lever the second

00:09:55.991 --> 00:09:58.858
chimpanzee gets a painful
electric shock,

00:09:58.858 --> 00:10:02.799
putting the first chimpanzee in
a horrible dilemma.

00:10:02.799 --> 00:10:05.672
In order to feed himself,
he has to torture another

00:10:05.672 --> 00:10:07.641
animal.
Chimpanzees do not starve

00:10:07.641 --> 00:10:10.639
themselves to death.
It's very unlikely any of you

00:10:10.639 --> 00:10:13.647
would either but they go a long
time without food,

00:10:13.647 --> 00:10:17.146
suggesting they do not want to
cause this other chimpanzee

00:10:17.146 --> 00:10:20.789
pain.
It only works within species.

00:10:20.789 --> 00:10:24.019
So, in another experiment they
put a rabbit in the other room

00:10:24.019 --> 00:10:27.303
and the chimpanzee would slap
the lever repeatedly to make the

00:10:27.303 --> 00:10:29.779
rabbit scream in pain [laughter]
and jump.

00:10:29.779 --> 00:10:36.677
Now, we've known for a long
time that empathetic feeling is

00:10:36.677 --> 00:10:40.840
not logically linked to
morality.

00:10:40.840 --> 00:10:42.919
This is a point made by
Aristotle.

00:10:42.919 --> 00:10:44.860
I could see you writhing in
pain.

00:10:44.860 --> 00:10:48.197
That could cause me pain but it
doesn't mean I'm going to be

00:10:48.197 --> 00:10:50.340
nice to you.
I could run away from you.

00:10:50.340 --> 00:10:54.539
I could turn my head or I could
blame you for causing me this

00:10:54.539 --> 00:10:57.193
misery.
But it does happen that

00:10:57.193 --> 00:11:01.944
emotional--that this sort of
empathy does lead to moral

00:11:01.944 --> 00:11:05.658
concern and action.
If we do an experiment and we

00:11:05.658 --> 00:11:09.338
induce you to feel empathetic to
somebody, we get you to feel

00:11:09.338 --> 00:11:12.275
what they're feeling,
you're more likely to be nice

00:11:12.275 --> 00:11:14.800
to them.
And people differ in the extent

00:11:14.800 --> 00:11:18.972
to which they feel empathy.
People differ to the extent it

00:11:18.972 --> 00:11:23.269
will hurt them to watch me slam
my thumb with a hammer.

00:11:23.269 --> 00:11:26.618
If you are high empathy,
you're more likely to be a nice

00:11:26.618 --> 00:11:28.809
person than if you're low
empathy,

00:11:28.809 --> 00:11:32.075
suggesting there is some
connection between empathetic

00:11:32.075 --> 00:11:35.865
feeling and liking.
Now, empathetic feeling,

00:11:35.865 --> 00:11:41.480
like any other human capacity,
differs across people.

00:11:41.480 --> 00:11:44.976
Some of us have a lot of it.
Some of us don't have much of

00:11:44.976 --> 00:11:47.117
it.
There is some reason to believe

00:11:47.117 --> 00:11:49.950
that in the population known as
"psychopaths,"

00:11:49.950 --> 00:11:54.259
a population we'll return to
later on when we discuss mental

00:11:54.259 --> 00:11:57.911
illness, this sort of
instinctive empathy is broken

00:11:57.911 --> 00:12:02.440
and the pain of others just
doesn't bother them very much.

00:12:02.440 --> 00:12:04.809
I have some illustrative quotes
here.

00:12:04.809 --> 00:12:07.533
In Damon's book,
a wonderful book on

00:12:07.533 --> 00:12:11.967
psychopathy, he talks about a
thirteen-year-old mugger who

00:12:11.967 --> 00:12:15.080
specialized in mugging blind
people.

00:12:15.080 --> 00:12:17.885
And when asked about the pain
he caused his victims he

00:12:17.885 --> 00:12:20.946
responded, "What do I care?
I'm not her," which is

00:12:20.946 --> 00:12:24.000
logically correct but,
in a sense, inhuman.

00:12:24.000 --> 00:12:26.929
The fact that it's another
person should make you care.

00:12:26.929 --> 00:12:30.777
The serial killer Gary Gilmore
basically said the pain of

00:12:30.777 --> 00:12:34.900
others gratified him and caused
him no unhappiness at all.

00:12:34.900 --> 00:12:39.634
"I was always capable of murder.
I can become totally devoid of

00:12:39.634 --> 00:12:41.740
feelings of others,
unemotional.

00:12:41.740 --> 00:12:44.966
I know I'm doing something
grossly--" and here is a very

00:12:44.966 --> 00:12:48.559
bad word "--wrong.
I can still go ahead and do it."

00:12:48.559 --> 00:12:52.649
And Ted Bundy,
when interviewed at one point,

00:12:52.649 --> 00:12:57.854
said he was astonished that
people made such a fuss about

00:12:57.854 --> 00:13:01.480
all of his murders because he
said,

00:13:01.480 --> 00:13:04.509
"I mean, there are so many
people."

00:13:04.509 --> 00:13:08.701
And if any of you here are
nodding in agreement at these

00:13:08.701 --> 00:13:12.740
sentiments, [laughter]
that's not such a good sign.

00:13:12.740 --> 00:13:16.524
These are particularly callous
and cold-blooded statements

00:13:16.524 --> 00:13:19.379
suggesting that this instinctive
empathy,

00:13:19.379 --> 00:13:24.979
this aspect of moral thought,
is not--is present in most of

00:13:24.979 --> 00:13:29.637
us but not in all of us.
The second case study of moral

00:13:29.637 --> 00:13:32.429
feeling is "in-group" and
"out-group."

00:13:32.429 --> 00:13:34.678
In our affections,
in our caring,

00:13:34.678 --> 00:13:36.996
who we like,
who we feel close to,

00:13:36.996 --> 00:13:40.720
whose pain bothers us,
we are not indiscriminate.

00:13:40.720 --> 00:13:44.887
I care a lot more about my
children than I do about my

00:13:44.887 --> 00:13:49.369
friends and I care more about my
friends than I care about

00:13:49.369 --> 00:13:52.279
strangers.
We're all like that.

00:13:52.279 --> 00:13:57.030
We also favor our group over
others in every possible way.

00:13:57.030 --> 00:14:00.160
You are a member of many groups.
You are men.

00:14:00.160 --> 00:14:02.200
You are women.
You're Yale students.

00:14:02.200 --> 00:14:05.023
You're young.
You're white,

00:14:05.023 --> 00:14:07.529
you're black,
you're Asian.

00:14:07.529 --> 00:14:10.783
You're a member of these groups
and, as we will discuss

00:14:10.783 --> 00:14:14.156
repeatedly when we talk about
social cognition and social

00:14:14.156 --> 00:14:16.766
behavior,
this membership matters a lot

00:14:16.766 --> 00:14:19.231
to you.
What's particularly interesting

00:14:19.231 --> 00:14:23.090
is even groups that are formed,
that you were not born with,

00:14:23.090 --> 00:14:26.526
that are formed on the fly,
exert a huge amount of control

00:14:26.526 --> 00:14:29.360
over your moral feelings and
moral attitudes.

00:14:29.360 --> 00:14:33.769
And the best example of this is
discussed in detail in the

00:14:33.769 --> 00:14:37.326
textbook.
And this is the Robber's Cave

00:14:37.326 --> 00:14:40.191
study.
And this Robber's Cave study

00:14:40.191 --> 00:14:44.929
serves as a nice illustration of
morality in everyday life.

00:14:44.929 --> 00:14:48.073
The study was,
eleven- and 12-year-old boys at

00:14:48.073 --> 00:14:51.653
a camping program.
These were well-adjusted,

00:14:51.653 --> 00:14:54.971
pretty rich kids,
racially homogeneous,

00:14:54.971 --> 00:14:58.639
and they were put into separate
cabins.

00:14:58.639 --> 00:15:02.472
And the cabins were given
leaders and they gave themselves

00:15:02.472 --> 00:15:04.958
names.
Being unimaginative boys,

00:15:04.958 --> 00:15:09.401
they called themselves "The
Eagles" and "The Rattlers" but

00:15:09.401 --> 00:15:13.651
as--what happened was,
being separated they developed

00:15:13.651 --> 00:15:15.340
distinctive cultures.

00:15:19.509 --> 00:15:24.337
And when these groups were set
in competition against each

00:15:24.337 --> 00:15:28.910
other, the Eagles versus the
Rattlers, the within-group

00:15:28.910 --> 00:15:32.238
intensity grew.
The Eaglers began--Eagles began

00:15:32.238 --> 00:15:35.730
to care a lot more about other
Eagles than about anybody else.

00:15:35.730 --> 00:15:40.250
So, there's within-group
solidarity.

00:15:40.250 --> 00:15:42.730
And then there were negative
stereotypes.

00:15:42.730 --> 00:15:45.690
So, these groups developed
different cultures.

00:15:45.690 --> 00:15:48.543
It was a randomly cut
apart--kind of like Yale College

00:15:48.543 --> 00:15:51.720
is actually, where you get a
random assortment of people.

00:15:51.720 --> 00:15:54.536
But despite the fact that the
assortment is random,

00:15:54.536 --> 00:15:57.409
the division is random,
cultures begin to emerge.

00:15:57.409 --> 00:16:01.659
The Eagles prided themselves on
being clean living,

00:16:01.659 --> 00:16:05.740
not using cuss words and
treating each other with

00:16:05.740 --> 00:16:09.053
respect.
They viewed the Rattlers as

00:16:09.053 --> 00:16:12.789
dirty and tough and kind of
slovenly slobs.

00:16:12.789 --> 00:16:17.930
The Rattlers viewed the Eagles
as goody-goody kids.

00:16:17.930 --> 00:16:22.329
It's cruel.
Finally, [laughter]

00:16:22.329 --> 00:16:28.019
it all evolved into
hostilities, raids and violence.

00:16:28.019 --> 00:16:33.108
The Eagles burnt a Rattlers
banner, cuss words were

00:16:33.108 --> 00:16:36.669
occasionally used,
and so Sherif,

00:16:36.669 --> 00:16:39.909
the psychologist designing all
of this, went,

00:16:39.909 --> 00:16:43.737
"Excellent," [laughter]
and then the problem--He then

00:16:43.737 --> 00:16:45.931
says,
"Now we've created two

00:16:45.931 --> 00:16:49.210
different warring cultures.
That was fun.

00:16:49.210 --> 00:16:52.436
[laughter]
What do we do to make them

00:16:52.436 --> 00:16:55.000
friends again?
And then we figure out how

00:16:55.000 --> 00:16:57.304
to--now we've done that and
this'll solve all sorts of

00:16:57.304 --> 00:16:59.200
problems."
So they started off.

00:16:59.200 --> 00:17:02.541
They wanted to have--They set
up peace talks where a

00:17:02.541 --> 00:17:06.602
representative of the Eagle and
a representative of the Rattler

00:17:06.602 --> 00:17:10.467
were set to meet and plan ways
so that they could disarm and

00:17:10.467 --> 00:17:13.940
stop using cuss words and
everything like that.

00:17:13.940 --> 00:17:18.307
This failed.
The kids who engaged in the

00:17:18.307 --> 00:17:22.780
peace talks were ostracized by
their own groups as treasonists.

00:17:22.780 --> 00:17:26.100
That failed.
They decided to set up

00:17:26.100 --> 00:17:29.923
individual competitions like the
Olympics where they--where

00:17:29.923 --> 00:17:33.549
people wouldn't compete as
Eagles or Rattlers but rather

00:17:33.549 --> 00:17:36.120
they would compete as
individuals.

00:17:36.120 --> 00:17:39.169
That failed too.
Like the Olympics,

00:17:39.169 --> 00:17:42.175
people--the teams took
their--they took their

00:17:42.175 --> 00:17:46.205
individual accomplishments as
reflecting on the group and it

00:17:46.205 --> 00:17:49.279
evolved into Eagles versus The
Rattlers.

00:17:49.279 --> 00:17:53.658
They shared meals,
they turned--which turned into

00:17:53.658 --> 00:17:58.691
food fights and more cuss words.
They shared movies,

00:17:58.691 --> 00:18:01.740
more fights,
more cuss words.

00:18:01.740 --> 00:18:03.695
They shared fun with
firecrackers,

00:18:03.695 --> 00:18:05.947
[laughter]
which was a disastrous thing

00:18:05.947 --> 00:18:08.910
which nearly brought the
experiment to an end.

00:18:08.910 --> 00:18:12.335
[laughter]
They brought in a religious

00:18:12.335 --> 00:18:16.779
figure to give them sermons on
brotherly love.

00:18:16.779 --> 00:18:18.627
[laughter]
The sermons were entirely

00:18:18.627 --> 00:18:21.496
unsuccessful.
What's interesting is they--the

00:18:21.496 --> 00:18:24.759
Eagle--they took them to heart.
These were good kids.

00:18:24.759 --> 00:18:27.218
They were respectful of
religious authority but the

00:18:27.218 --> 00:18:29.971
lessons they took from them is
"I should learn to love my

00:18:29.971 --> 00:18:31.430
neighbor."
If I'm a Rattler,

00:18:31.430 --> 00:18:33.879
I should learn to love my
fellow Rattler and appreciate

00:18:33.879 --> 00:18:35.330
him as a fellow,
as a person.

00:18:35.330 --> 00:18:38.212
"I love him.
It's love, not like those

00:18:38.212 --> 00:18:44.340
scummy Eagles."
[laughter] They all failed.

00:18:44.340 --> 00:18:46.010
Here's what worked.

00:18:49.750 --> 00:18:55.233
Sherif told the kids--all of
the kids--that the water line to

00:18:55.233 --> 00:19:00.259
the camp was cut and they all
had to defend the camp.

00:19:00.259 --> 00:19:03.754
What this did was it
established a super ordinate

00:19:03.754 --> 00:19:06.811
goal, that is a goal that
everybody shared,

00:19:06.811 --> 00:19:10.160
and perhaps more important a
common enemy.

00:19:10.160 --> 00:19:13.824
This is where the solution,
by the way, to bringing

00:19:13.824 --> 00:19:18.222
together--and you could write
this down--to bringing together

00:19:18.222 --> 00:19:22.547
all the warring countries and
religions of this planet is an

00:19:22.547 --> 00:19:24.666
alien attack.
[laughter]

00:19:24.666 --> 00:19:29.026
By the logic of the Sherif it
will bring us all together as a

00:19:29.026 --> 00:19:31.541
group.
A different question is,

00:19:31.541 --> 00:19:36.116
there in that experiment the
"groupiness" was established in

00:19:36.116 --> 00:19:39.152
a very powerful way.
They lived separately,

00:19:39.152 --> 00:19:42.509
they interacted with each
other, they had their own names.

00:19:42.509 --> 00:19:47.901
The psychologist Tajfel after
World War II was interested in

00:19:47.901 --> 00:19:51.740
the question of what could make
a group.

00:19:51.740 --> 00:19:55.032
In other words,
what do I have to do to you to

00:19:55.032 --> 00:19:57.960
put you in a different group
from him?

00:19:57.960 --> 00:20:00.862
What do I have to do to this
class--this side of the class to

00:20:00.862 --> 00:20:03.570
put you in a different group
from this side and different

00:20:03.570 --> 00:20:06.848
from that side?
And what would I have to do for

00:20:06.848 --> 00:20:10.500
those groups to matter such
that, for instance,

00:20:10.500 --> 00:20:14.632
if I separate you in one group
and you're in another group and

00:20:14.632 --> 00:20:18.630
I give you a hundred dollars
will you give the money more to

00:20:18.630 --> 00:20:20.990
him or to him,
will you give it more to your

00:20:20.990 --> 00:20:26.476
own group or to another group?
And what he found was you don't

00:20:26.476 --> 00:20:30.159
need much.
In one experiment he showed

00:20:30.159 --> 00:20:34.981
people pictures of modern art
and based on their responses he

00:20:34.981 --> 00:20:39.240
described them as Klee lovers or
Kandinsky lovers.

00:20:39.240 --> 00:20:41.969
Now, this is all made up.
They were just random

00:20:41.969 --> 00:20:45.113
assignments but the Klee lovers
viewed themselves as more

00:20:45.113 --> 00:20:48.719
similar to other Klee lovers.
They thought the Klee lovers

00:20:48.719 --> 00:20:52.469
tended to be smarter than the
Kandinsky lovers and the Klee

00:20:52.469 --> 00:20:56.024
lovers would devote more
resources to themselves than to

00:20:56.024 --> 00:20:58.219
others.
This is why it's called

00:20:58.219 --> 00:21:01.355
"minimal groups."
You don't need much to make you

00:21:01.355 --> 00:21:03.208
into a group.
And in fact,

00:21:03.208 --> 00:21:06.259
later experiments just flipped
a coin.

00:21:06.259 --> 00:21:09.200
So the lot--the experiment goes
like this.

00:21:09.200 --> 00:21:11.110
I ask everybody in this class
to take out a coin.

00:21:11.110 --> 00:21:13.479
You all flip it.
Everyone who has heads,

00:21:13.479 --> 00:21:15.983
you're one group.
Everyone who has tails,

00:21:15.983 --> 00:21:18.840
you're the other group.
Then I ask people in the heads

00:21:18.840 --> 00:21:21.058
group, "Which group do
you--Putting yourself aside,

00:21:21.058 --> 00:21:23.319
which group on average do you
think is smarter?"

00:21:23.319 --> 00:21:25.774
You'd say, "Well,
you know, it kind of works out

00:21:25.774 --> 00:21:28.125
that the heads group is kind of
really--heads,

00:21:28.125 --> 00:21:29.992
smart."
Which group--"Here is some

00:21:29.992 --> 00:21:32.369
money.
You have to distribute it."

00:21:32.369 --> 00:21:35.969
You're more likely--It's a
subtle effect when you make the

00:21:35.969 --> 00:21:39.632
groups so minimal but you're
more likely to give it to your

00:21:39.632 --> 00:21:42.916
own group than to others and
this suggests that moral

00:21:42.916 --> 00:21:46.390
feelings are exquisitely attuned
not necessarily only to

00:21:46.390 --> 00:21:49.990
individuals but also to the
psychology of groups.

00:21:53.130 --> 00:21:55.460
Any questions at this point
about moral feelings?

00:22:07.110 --> 00:22:11.369
Yes.
Student:

00:22:11.369 --> 00:22:17.150
How you formed the groups--How
is that morality?

00:22:17.150 --> 00:22:19.097
Professor Paul Bloom:
It's morality--It bears on

00:22:19.097 --> 00:22:20.359
morality because it bears
on--So,

00:22:20.359 --> 00:22:22.304
the question is,
"How does group membership,

00:22:22.304 --> 00:22:24.519
how does that relate to the
topic of morality?"

00:22:24.519 --> 00:22:27.545
And the answer is the moral
feelings we're talking about are

00:22:27.545 --> 00:22:29.339
feelings like empathy and
caring.

00:22:29.339 --> 00:22:33.157
For me to have a moral feeling
towards you means you matter to

00:22:33.157 --> 00:22:34.587
me.
If you were to be harmed,

00:22:34.587 --> 00:22:36.995
I would view it as wrong.
And the group experiment

00:22:36.995 --> 00:22:39.744
suggests that the extent to
which these moral feelings

00:22:39.744 --> 00:22:43.064
operate are partially determined
by the groups to which we belong

00:22:43.064 --> 00:22:45.691
to.
If I'm American and you're from

00:22:45.691 --> 00:22:48.901
another country,
I will view myself--this is a

00:22:48.901 --> 00:22:52.539
very--kind of obvious
finding--my obligations to you

00:22:52.539 --> 00:22:56.819
will be seen as less than if you
were another American.

00:22:56.819 --> 00:22:59.180
If I'm a Klee lover and you're
a Kandinsky lover,

00:22:59.180 --> 00:23:01.540
I don't think you quite deserve
as much as me.

00:23:07.230 --> 00:23:12.444
Moral judgment is an area that
is tremendously exciting and

00:23:12.444 --> 00:23:16.309
there's a lot of recent research
on this.

00:23:16.309 --> 00:23:19.373
By moral judgment I mean not
empathetic feelings,

00:23:19.373 --> 00:23:23.329
not feelings of caring and love
or approval and disapproval,

00:23:23.329 --> 00:23:26.867
so they're not feelings of
caring and love and empathy,

00:23:26.867 --> 00:23:29.750
but notions like something is
good or bad,

00:23:29.750 --> 00:23:34.059
something--like something is
fair or unfair.

00:23:34.059 --> 00:23:40.309
So, there are three hallmarks
for moral judgments.

00:23:40.309 --> 00:23:44.400
So, suppose I say I don't like
strawberry ice cream.

00:23:44.400 --> 00:23:48.268
That's an evaluation.
That's a judgment but it's not

00:23:48.268 --> 00:23:51.089
a moral judgment.
Why not?

00:23:51.089 --> 00:23:55.099
Because I don't think it
carries a sense of obligation.

00:23:55.099 --> 00:23:58.426
I don't think anybody's obliged
to eat or not to eat strawberry

00:23:58.426 --> 00:24:00.912
ice cream.
And it doesn't carry a notion

00:24:00.912 --> 00:24:03.579
of sanctions,
meaning I don't think anybody

00:24:03.579 --> 00:24:07.009
should be punished for eating
strawberry ice cream.

00:24:07.009 --> 00:24:11.251
On the other hand,
if I say I don't like baby

00:24:11.251 --> 00:24:16.650
killers, that actually is a
moral judgment in my case.

00:24:16.650 --> 00:24:18.000
So [inaudible]
I say, "Well,

00:24:18.000 --> 00:24:20.619
I don't like baby killers.
You like to kill babies.

00:24:20.619 --> 00:24:25.910
I actually think we are obliged
not to kill babies."

00:24:25.910 --> 00:24:28.853
If you disagree with me,
you're wrong and you should

00:24:28.853 --> 00:24:31.058
stop killing those babies.
[laughter]

00:24:31.058 --> 00:24:33.650
Should you fail to stop killing
those babies,

00:24:33.650 --> 00:24:36.829
I think you should be punished
for killing babies."

00:24:36.829 --> 00:24:40.708
And that's what my judgment
about "no killing babies" makes

00:24:40.708 --> 00:24:44.407
it a moral judgment.
Now, some people attempted to

00:24:44.407 --> 00:24:47.710
look at this the wrong way and
say, "Look.

00:24:47.710 --> 00:24:51.540
What a weird topic, morality.
I don't believe in morality.

00:24:51.540 --> 00:24:56.674
I believe in Nietzsche.
I don't believe in ethics," but

00:24:56.674 --> 00:25:01.820
I don't believe you if you were
to say that because morality

00:25:01.820 --> 00:25:07.141
isn't--morality as we talk about
it in this context isn't just

00:25:07.141 --> 00:25:12.462
regarding your position on big
questions like political issues

00:25:12.462 --> 00:25:18.220
or big moral questions like
abortion or capital punishment.

00:25:18.220 --> 00:25:22.477
Rather, some sort of moral
judgment happens all the time,

00:25:22.477 --> 00:25:26.227
often unconsciously.
So, as you live your life you

00:25:26.227 --> 00:25:29.880
have to answer questions like
what should you eat?

00:25:29.880 --> 00:25:35.811
Any moral vegetarians here?
I'm just raising my hand to

00:25:35.811 --> 00:25:39.910
encourage people.
[laughter] Okay.

00:25:39.910 --> 00:25:44.560
Anybody give to charity?
Anybody not give to charity?

00:25:44.560 --> 00:25:47.140
Good.
[laughter]

00:25:47.140 --> 00:25:49.780
Different from the moral
vegetarians I noticed.

00:25:49.780 --> 00:25:53.549
Who do you socialize with?
There's homeless people around

00:25:53.549 --> 00:25:55.710
Yale and New Haven.
What do you give to them?

00:25:55.710 --> 00:25:59.642
Do you avoid their eyes?
Do you--What do you want to do

00:25:59.642 --> 00:26:03.940
with your life?
Who do you have sex with?

00:26:03.940 --> 00:26:07.480
Under what context or
conditions?

00:26:07.480 --> 00:26:12.222
These are moral questions.
My favorite moral dilemma is as

00:26:12.222 --> 00:26:17.369
I'm walking down the street and
I see somebody I sort of know,

00:26:17.369 --> 00:26:21.091
do I avoid eye so we don't have
a conversation [laughter]

00:26:21.091 --> 00:26:22.420
or do I say,
"Hey.

00:26:22.420 --> 00:26:25.440
How are you doing?"
or do I kind of do the nod

00:26:25.440 --> 00:26:28.369
hoping that there won't be more
than this nod?

00:26:28.369 --> 00:26:29.785
[laughter]
And then after I leave and I

00:26:29.785 --> 00:26:32.020
say, "Oh, I should have made eye
contact with that person.

00:26:32.020 --> 00:26:34.857
I'm such a jerk.
[laughter]

00:26:34.857 --> 00:26:37.549
There is a homeless person"
[laughter]

00:26:37.549 --> 00:26:41.987
and--but these are day-to-day
moral questions we struggle with

00:26:41.987 --> 00:26:46.280
all the time and so there's a
centrality in the study of how

00:26:46.280 --> 00:26:49.689
we do moral reasoning.
So, what do we know about moral

00:26:49.689 --> 00:26:54.169
reasoning?
Well, we know that there are

00:26:54.169 --> 00:26:58.403
some universals.
There are some aspects of moral

00:26:58.403 --> 00:27:00.950
reasoning that show up
everywhere on earth.

00:27:00.950 --> 00:27:04.560
And there is some evidence,
though it's not particularly

00:27:04.560 --> 00:27:07.946
strong at this point,
that these same intuitions show

00:27:07.946 --> 00:27:10.912
up in young children and in
nonhuman primates like

00:27:10.912 --> 00:27:13.880
chimpanzees,
capuchins, macaques and so on.

00:27:13.880 --> 00:27:17.117
And these are things like anger
at cheaters, gratitude toward

00:27:17.117 --> 00:27:20.138
sharers, the sort of things
you'd expect to come out in a

00:27:20.138 --> 00:27:23.648
prisoner's dilemma,
feelings that some things are

00:27:23.648 --> 00:27:29.200
right and some things are wrong.
These are foundational.

00:27:29.200 --> 00:27:32.360
But at the same time the study
of moral reasoning is a

00:27:32.360 --> 00:27:35.819
fascinated--fascinating issue
for those of us interested in

00:27:35.819 --> 00:27:38.682
cross-cultural psychology
because there are plain

00:27:38.682 --> 00:27:43.440
differences across cultures.
So, the anthropologist Richard

00:27:43.440 --> 00:27:47.900
Shweder gives a list here of
human differences:

00:27:47.900 --> 00:27:50.155
People have found it
quite natural to be

00:27:50.155 --> 00:27:51.910
spontaneously appalled,
outraged,

00:27:51.910 --> 00:27:54.469
indignant, proud,
disgusted, guilty and ashamed

00:27:54.469 --> 00:27:57.255
by all sorts of things.
Then there's a long list:

00:27:57.255 --> 00:27:58.819
"masturbation,
homosexuality,

00:27:58.819 --> 00:28:00.549
sexual abstinence,
polygamy,

00:28:00.549 --> 00:28:02.345
abortion, circumcision,
corporal punishment,

00:28:02.345 --> 00:28:04.099
capital punishment,
Islam, Christianity,

00:28:04.099 --> 00:28:06.299
Judaism, capitalism,
democracy, flag burning,

00:28:06.299 --> 00:28:07.950
miniskirts, long hair,
no hair,

00:28:07.950 --> 00:28:10.692
blah blah, parents and children
sleeping in the same bed,

00:28:10.692 --> 00:28:13.240
parents and children not
sleeping in the same bed,

00:28:13.240 --> 00:28:15.077
women being allowed to work,
women not being allowed to

00:28:15.077 --> 00:28:17.652
work.
If I put it down in a list and

00:28:17.652 --> 00:28:20.992
got people to tick it off,
what you all thought,

00:28:20.992 --> 00:28:23.480
there would be some
differences.

00:28:23.480 --> 00:28:25.820
Some of you think meat eating
is okay.

00:28:25.820 --> 00:28:30.232
Some of you do not.
Some of you--You might have

00:28:30.232 --> 00:28:33.923
different views about divorce.
Most of you believe women

00:28:33.923 --> 00:28:39.650
should be allowed to work.
Most of you will be in favor or

00:28:39.650 --> 00:28:44.420
not morally scolding of
homosexuality.

00:28:44.420 --> 00:28:47.200
You'll be lukewarm about
polygamy.

00:28:47.200 --> 00:28:51.349
Nobody would like abstinence
and so on.

00:28:51.349 --> 00:28:53.483
[laughter]
But if we gave that same list

00:28:53.483 --> 00:28:56.108
to people in a different
culture, they'd tick off

00:28:56.108 --> 00:29:00.408
entirely different things.
These are ways in which people

00:29:00.408 --> 00:29:02.815
vary.
I don't think people vary in

00:29:02.815 --> 00:29:05.160
their feelings about baby
killing.

00:29:05.160 --> 00:29:08.764
I don't think people vary about
the feelings of I do something

00:29:08.764 --> 00:29:11.660
for you and then you don't do
something for me.

00:29:11.660 --> 00:29:14.917
I think that's gut-level,
hard-wired, evolved to solve

00:29:14.917 --> 00:29:18.282
prisoner's dilemmas.
But these are important issues

00:29:18.282 --> 00:29:21.905
and these vary a lot from
culture to culture and a good

00:29:21.905 --> 00:29:25.662
theory of psychology has to
explain how these differences

00:29:25.662 --> 00:29:28.701
arise.
And Shweder has a theory which

00:29:28.701 --> 00:29:32.827
is quite interesting.
Shweder argues that there are

00:29:32.827 --> 00:29:37.283
three styles of thought,
three different frameworks of

00:29:37.283 --> 00:29:40.730
moral thought,
three different ethics.

00:29:40.730 --> 00:29:46.303
There's an ethics of autonomy.
This is what moral philosophers

00:29:46.303 --> 00:29:50.367
within our culture view as
morality, notions of rights,

00:29:50.367 --> 00:29:52.400
of equality,
of freedom.

00:29:52.400 --> 00:29:56.122
But many cultures focus on an
ethics of community,

00:29:56.122 --> 00:29:59.236
bringing together duty,
status, hierarchy,

00:29:59.236 --> 00:30:03.764
and interdependence.
Other cultures focused more on

00:30:03.764 --> 00:30:08.272
an ethics of divinity where
notions such as purity,

00:30:08.272 --> 00:30:12.240
sanctity, pollution and sin are
relevant.

00:30:12.240 --> 00:30:15.467
So for example,
when we're talking about the

00:30:15.467 --> 00:30:20.269
rights of men and women and what
they should be allowed to do,

00:30:20.269 --> 00:30:23.966
many people in our society
following an ethics of autonomy

00:30:23.966 --> 00:30:27.986
will argue that they should have
equal rights in all domains of

00:30:27.986 --> 00:30:30.047
behavior.
Since they are sentient,

00:30:30.047 --> 00:30:32.329
free creatures,
they should have a right to do

00:30:32.329 --> 00:30:35.524
whatever they want unless there
is a compelling argument against

00:30:35.524 --> 00:30:38.263
it and a compelling argument
would have to involve some

00:30:38.263 --> 00:30:40.849
infringement of the freedom of
other people.

00:30:40.849 --> 00:30:43.138
On the other hand,
if you're in an ethics of

00:30:43.138 --> 00:30:46.224
community you might argue that
men and women have different

00:30:46.224 --> 00:30:48.460
rights and different
responsibilities.

00:30:48.460 --> 00:30:53.009
They may be born to perform
certain things and as such

00:30:53.009 --> 00:30:56.099
they're duty bound to follow
them.

00:30:56.099 --> 00:31:00.343
If you're from an ethics of
divinity, you may appeal to

00:31:00.343 --> 00:31:04.901
religious injunctions against
certain actions and behaviors

00:31:04.901 --> 00:31:09.616
and these may differentially
restrict the behavior of men and

00:31:09.616 --> 00:31:12.331
women.
You might believe for instance,

00:31:12.331 --> 00:31:15.703
that women should not prepare
food when menstruating because

00:31:15.703 --> 00:31:18.632
it would contaminate the food.
You may believe that

00:31:18.632 --> 00:31:21.395
there's--there are severe
restrictions about who could

00:31:21.395 --> 00:31:24.366
have sex with one another that
don't have to do with human

00:31:24.366 --> 00:31:27.795
rights and human freedom.
It has to do with the way

00:31:27.795 --> 00:31:32.049
things should be because of
issues of pollution and sin.

00:31:32.049 --> 00:31:35.368
Now, Western cultures,
as I've said,

00:31:35.368 --> 00:31:40.110
are highly invested in an
ethics of autonomy and so

00:31:40.110 --> 00:31:45.989
debates we have in our culture
tend to be framed in terms of an

00:31:45.989 --> 00:31:50.046
ethics of autonomy.
If we have a debate about

00:31:50.046 --> 00:31:53.622
abortion in this class,
people--some people might say,

00:31:53.622 --> 00:31:56.696
"Look.
The fetus is a sentient being

00:31:56.696 --> 00:32:01.799
and as such it has a right to
survive and shouldn't be killed

00:32:01.799 --> 00:32:05.210
by its mother."
Other people would argue, "No.

00:32:05.210 --> 00:32:08.433
A woman has full freedom over
her own body and as long as a

00:32:08.433 --> 00:32:11.545
fetus is within the body
they--she has a right to control

00:32:11.545 --> 00:32:13.611
it."
If we're arguing about hate

00:32:13.611 --> 00:32:17.214
speech, we could talk about the
balance between the rights of

00:32:17.214 --> 00:32:20.877
the freedom of speech versus the
right to a certain quality of

00:32:20.877 --> 00:32:23.880
education free of harassment and
humiliation.

00:32:23.880 --> 00:32:27.620
Those are the ways we frame
things but one of the more

00:32:27.620 --> 00:32:31.856
interesting discoveries in this
field is that although people

00:32:31.856 --> 00:32:35.950
think that they're governed by
the ethics of autonomy,

00:32:35.950 --> 00:32:40.230
even people within our culture,
even highly educated people

00:32:40.230 --> 00:32:44.290
within our culture,
even people like you show moral

00:32:44.290 --> 00:32:47.529
judgments that are not quite as
simple.

00:32:47.529 --> 00:32:51.127
So, this is the work of
Jonathan Haidt at University of

00:32:51.127 --> 00:32:53.483
Virginia.
And Haidt finds if you ask

00:32:53.483 --> 00:32:56.916
people, they believe in our
culture that they hold to an

00:32:56.916 --> 00:33:00.250
ethics of autonomy.
If it doesn't harm anyone,

00:33:00.250 --> 00:33:02.810
it's okay.
So, if I was to ask you your

00:33:02.810 --> 00:33:05.900
attitudes about sex,
most of you--not all of you,

00:33:05.900 --> 00:33:08.531
you come from different
cultures, you have different

00:33:08.531 --> 00:33:11.524
attitudes--but most of you would
say sex between consenting

00:33:11.524 --> 00:33:13.950
adults is okay as long as nobody
gets hurt,

00:33:13.950 --> 00:33:18.779
as long as nobody gets hurt
people's rights are respected.

00:33:18.779 --> 00:33:21.447
So, gay marriage,
for instance,

00:33:21.447 --> 00:33:26.516
or gay sex would be okay with
you because it is--nobody is

00:33:26.516 --> 00:33:30.339
harmed and these are consenting
adults.

00:33:30.339 --> 00:33:33.694
Haidt points out that there are
certain problems with this

00:33:33.694 --> 00:33:37.226
argument and he illustrates this
problem--these problems with

00:33:37.226 --> 00:33:38.580
stories like this:

00:33:42.089 --> 00:33:44.890
Julie and Mark are
brother and sister.

00:33:44.890 --> 00:33:50.152
They are traveling together in
France on summer vacation from

00:33:50.152 --> 00:33:52.448
college.
One night they are staying

00:33:52.448 --> 00:33:55.511
alone in a cabin near the beach.
They decide it would be

00:33:55.511 --> 00:33:58.089
interesting and fun if they
tried making love.

00:33:58.089 --> 00:34:00.871
At the very least,
it would be a new experience

00:34:00.871 --> 00:34:04.287
for each of them.
Julie was already taking birth

00:34:04.287 --> 00:34:08.670
control pills but Mark uses a
condom too just to be safe.

00:34:08.670 --> 00:34:13.059
They both enjoy making love but
they decide not to do it again.

00:34:13.059 --> 00:34:17.241
They keep that night a special
secret which makes them feel

00:34:17.241 --> 00:34:20.900
even closer to each other.
What do you think about that?

00:34:20.900 --> 00:34:22.970
Was it okay for them to make
love?

00:34:22.970 --> 00:34:31.000
Who says yes?
Good.

00:34:31.000 --> 00:34:33.281
I know that some people would
say yes, shoot up their hands,

00:34:33.281 --> 00:34:35.408
and they look around in
astonishment that no one else is

00:34:35.408 --> 00:34:37.800
with them.
[laughter] Who says no?

00:34:37.800 --> 00:34:39.870
Okay.
Who is not sure?

00:34:39.870 --> 00:34:45.380
You're not sure.
That's the weirdest of all.

00:34:45.380 --> 00:34:47.916
[laughter]
Haidt finds that the

00:34:47.916 --> 00:34:51.719
distribution even among this--If
you--Look.

00:34:51.719 --> 00:34:55.381
If you go home and you ask your
parents, they say,

00:34:55.381 --> 00:34:59.880
"Ew.
What is--What are you learning

00:34:59.880 --> 00:35:01.969
at Yale?"
[laughter]

00:35:01.969 --> 00:35:06.408
This is a very unusual culture
and where some people will say

00:35:06.408 --> 00:35:09.416
it's okay.
What Haidt finds is most people

00:35:09.416 --> 00:35:12.253
say it doesn't and then he
simply asks them,

00:35:12.253 --> 00:35:14.630
being a good psychologist,
"Okay.

00:35:14.630 --> 00:35:19.196
What's wrong with it?"
And this is the brother/sister

00:35:19.196 --> 00:35:21.864
case.
And the responses are

00:35:21.864 --> 00:35:25.079
interesting.
Because people view themselves

00:35:25.079 --> 00:35:28.687
as committed to an ethics of
autonomy, they can't just say

00:35:28.687 --> 00:35:31.435
it's disgusting.
So, they exhibit what Haidt

00:35:31.435 --> 00:35:34.356
describes as "moral
dumbfounding," meaning that they

00:35:34.356 --> 00:35:37.948
struggle to find an explanation.
They say it's terrible because

00:35:37.948 --> 00:35:41.020
they'll have a kid and the
kid'll grow up freaky [laughter]

00:35:41.020 --> 00:35:44.410
and then the experimenter--it's
an interview situation--says,

00:35:44.410 --> 00:35:46.372
"Well, no.
Remember they're both using a

00:35:46.372 --> 00:35:50.060
lot of birth control."
"Maybe she's under age."

00:35:50.060 --> 00:35:53.072
"No, not under age."
And finally,

00:35:53.072 --> 00:35:59.522
"Well, it's just wrong."
Similarly, another one of the

00:35:59.522 --> 00:36:07.195
scenarios--[laughter]
This isn't as bad as you might

00:36:07.195 --> 00:36:09.901
expect.
[laughter]

00:36:09.901 --> 00:36:16.750
The family dog is playing
outside and gets hit by a car.

00:36:16.750 --> 00:36:19.687
[laughter]
They bring it in and they say,

00:36:19.687 --> 00:36:21.817
"Oh, Fido's dead,
Fido's dead,

00:36:21.817 --> 00:36:25.690
but what's for dinner?"
So, they cook it and eat it.

00:36:25.690 --> 00:36:31.170
Who says it's okay?
Good.

00:36:31.170 --> 00:36:33.230
[laughter]
Who says it's not okay?

00:36:33.230 --> 00:36:38.182
Okay.
Then they notice that their

00:36:38.182 --> 00:36:47.238
toilet is kind of dirty.
"But whoa, there is an American

00:36:47.238 --> 00:36:49.664
flag."
[laughter]

00:36:49.664 --> 00:36:54.130
They then use the toilet to
clean the flag.

00:36:54.130 --> 00:36:58.304
Who says that's okay?
[laughter]

00:36:58.304 --> 00:37:02.143
Anybody think it's not okay?
And just keep in mind we're

00:37:02.143 --> 00:37:03.969
getting sort of even responses
here.

00:37:03.969 --> 00:37:06.846
On all of these,
the majority of people who are

00:37:06.846 --> 00:37:09.723
not college students in elite
universities say,

00:37:09.723 --> 00:37:14.010
"Oh, that's so wrong."
Finally, there is this one.

00:37:14.010 --> 00:37:19.269
And this one really is as bad
as one might expect.

00:37:19.269 --> 00:37:23.690
[laughter]
A guy is lonely so he purchases

00:37:23.690 --> 00:37:29.727
a frozen chicken from the
supermarket, brings it home and

00:37:29.727 --> 00:37:32.960
has relations with it.
[laughter]

00:37:32.960 --> 00:37:36.670
Then he cooks it and eats it.
[laughter] Look.

00:37:36.670 --> 00:37:43.298
This is a scientific paper in
the Psych Review.

00:37:43.298 --> 00:37:45.550
[laughter]
Okay.

00:37:45.550 --> 00:37:49.630
Who says that's okay?
[laughter] Good.

00:37:49.630 --> 00:37:55.170
And I notice there is
consistency among people.

00:37:55.170 --> 00:37:59.959
The people who think it's okay
have every right to say that

00:37:59.959 --> 00:38:02.519
they believe,
if they really,

00:38:02.519 --> 00:38:05.647
sincerely believe it's okay,
they are committed to an ethics

00:38:05.647 --> 00:38:08.930
of autonomy.
Those of you who think it's not

00:38:08.930 --> 00:38:12.783
okay, none of these,
should ask yourself why and

00:38:12.783 --> 00:38:15.980
should then scrutinize your
reasons.

00:38:15.980 --> 00:38:19.924
People are very smart and they
could present--easily present

00:38:19.924 --> 00:38:21.868
reasons why.
They could say,

00:38:21.868 --> 00:38:25.699
"Oh, disease," but these
reasons tend not to be sincere.

00:38:25.699 --> 00:38:28.898
If you take away the
considerations that the reaction

00:38:28.898 --> 00:38:31.520
stays.
And these are then interesting

00:38:31.520 --> 00:38:35.782
case studies of how our moral
judgment is governed by factors

00:38:35.782 --> 00:38:38.409
that we might not be conscious
of.

00:38:38.409 --> 00:38:39.950
Our moral intuitions can
surprise us.

00:38:47.280 --> 00:38:52.452
The motivation for Milgram's
work, and this is the final

00:38:52.452 --> 00:38:57.436
thing we'll talk about in the
context of morality--The

00:38:57.436 --> 00:39:02.797
motivation for Milgram's work
was the Holocaust and he was

00:39:02.797 --> 00:39:08.440
interested in exploring why such
a thing could happen.

00:39:14.110 --> 00:39:19.316
I should note by the way--you
know from the movie that Milgram

00:39:19.316 --> 00:39:24.610
was a Yale professor.
He left Yale when he didn't get

00:39:24.610 --> 00:39:30.519
tenure, moved to Harvard,
didn't get tenure there too.

00:39:30.519 --> 00:39:34.800
He was--He had a reputation by
then as a mad doctor.

00:39:34.800 --> 00:39:39.089
He ended up at City University
of New York, became a full

00:39:39.089 --> 00:39:44.122
professor at age thirty three,
died in his early '50s,

00:39:44.122 --> 00:39:50.860
did not lead a good life but
had extraordinary discoveries.

00:39:50.860 --> 00:39:53.867
Another discovery which we'll
talk about next week is--Has

00:39:53.867 --> 00:39:56.769
anybody heard the phrase "six
degrees of separation?"

00:39:56.769 --> 00:39:59.889
Milgram, and we'll talk about
that later.

00:39:59.889 --> 00:40:03.770
Milgram had a powerful
imagination.

00:40:03.770 --> 00:40:07.900
Okay.
So we know--This is all review.

00:40:07.900 --> 00:40:12.106
There is the guy.
How many of you laughed when

00:40:12.106 --> 00:40:16.136
you saw the movie ?
Interesting question why and

00:40:16.136 --> 00:40:19.060
we'll talk about that in a
little while.

00:40:19.060 --> 00:40:25.037
Shocks, "slight shock" to "XXX."
There is--This is just

00:40:25.037 --> 00:40:29.870
repeating what you've seen.
The learner protests as he's

00:40:29.870 --> 00:40:33.877
being shocked more and more but
the experimenter continues to

00:40:33.877 --> 00:40:36.969
request obedience.
For those of you who haven't

00:40:36.969 --> 00:40:39.685
seen the movie,
again, the setup is someone is

00:40:39.685 --> 00:40:42.354
a subject.
They don't know--They think

00:40:42.354 --> 00:40:46.473
that they're teaching somebody
in a memory game but actually

00:40:46.473 --> 00:40:50.802
the person who is being shocked
is a confederate who is trained

00:40:50.802 --> 00:40:55.340
to react in certain ways as he's
being increasingly shocked.

00:40:55.340 --> 00:40:59.931
And the finding is that the
majority of people will deliver

00:40:59.931 --> 00:41:04.839
fatal shocks to this person who
they had never met based on the

00:41:04.839 --> 00:41:10.359
instructions of another person.
Now, there are some immediate

00:41:10.359 --> 00:41:15.665
bad explanations for this.
One explanation is these are

00:41:15.665 --> 00:41:19.552
really strange people.
"These are an abnormal group of

00:41:19.552 --> 00:41:21.969
psychopaths."
But we know that's not true.

00:41:21.969 --> 00:41:24.179
It's been replicated with many
subjects.

00:41:24.179 --> 00:41:28.931
There's no reason to believe
that the subjects in Milgram's

00:41:28.931 --> 00:41:32.289
original study were in any way
unusual.

00:41:32.289 --> 00:41:34.791
It's also a misreading to say
that people are,

00:41:34.791 --> 00:41:37.659
in general, sadistic.
You remember from the movie

00:41:37.659 --> 00:41:40.250
nobody got pleasure from giving
the shocks.

00:41:40.250 --> 00:41:42.472
They felt acutely
uncomfortable,

00:41:42.472 --> 00:41:45.556
embarrassed,
conflicted, under a huge amount

00:41:45.556 --> 00:41:50.750
of stress.
They weren't liking doing this.

00:41:50.750 --> 00:41:54.469
There were follow-up studies.
This is the original study.

00:41:54.469 --> 00:41:58.432
If you take it away from Yale,
some of the authority goes

00:41:58.432 --> 00:42:01.899
away, and similarly,
the extent to which there are

00:42:01.899 --> 00:42:07.462
fatal shocks goes down.
As the teacher is with the

00:42:07.462 --> 00:42:12.380
learner next to him,
it goes down.

00:42:12.380 --> 00:42:18.018
If you have to put the guy's
hand on it, you're less likely

00:42:18.018 --> 00:42:21.993
to kill him.
If the experimenter gives you

00:42:21.993 --> 00:42:26.679
instructions by phone,
you're less likely to do it.

00:42:26.679 --> 00:42:30.173
If an ordinary man,
not the guy in a white lab coat

00:42:30.173 --> 00:42:32.130
but an ordinary guy,
says,

00:42:32.130 --> 00:42:35.024
"Hey, keep shocking him,
that's okay," you're less

00:42:35.024 --> 00:42:37.800
likely to do it,
and if there is a rebellion,

00:42:37.800 --> 00:42:40.580
if somebody else rebels and
says, "I won't do it," you are

00:42:40.580 --> 00:42:42.580
much more likely not to do it
yourself.

00:42:46.060 --> 00:42:51.213
There are some--Oh, sorry.
Yeah, and if you could get to

00:42:51.213 --> 00:42:54.868
choose your own shock level,
you could keep--then very,

00:42:54.868 --> 00:42:58.952
very few people go all the way.
So, these are an important list

00:42:58.952 --> 00:43:02.114
of factors as to the factors
that can make somebody less

00:43:02.114 --> 00:43:04.760
likely to bring it up to the
killing level.

00:43:04.760 --> 00:43:08.321
And as a result we can look at
those factors and think about

00:43:08.321 --> 00:43:12.003
what is the perfect situation
for making somebody do something

00:43:12.003 --> 00:43:14.840
like this and the perfect
situation not to.

00:43:14.840 --> 00:43:20.158
Some more serious critiques of
Milgram: Milgram's experiment is

00:43:20.158 --> 00:43:23.590
why we have human-subjects
committees.

00:43:23.590 --> 00:43:28.337
This is a terribly stressful
experiment to do to people and,

00:43:28.337 --> 00:43:33.005
as I say now about a lot of
studies that I describe in this

00:43:33.005 --> 00:43:35.579
class,
it would not today be done.

00:43:35.579 --> 00:43:41.104
People did say they were happy
to have participated and only 2%

00:43:41.104 --> 00:43:45.982
said that they were sorry,
but still serious damage could

00:43:45.982 --> 00:43:48.920
have been done and perhaps was
done.

00:43:48.920 --> 00:43:52.746
These people left the lab
having learnt about themselves

00:43:52.746 --> 00:43:56.920
that they'll kill another person
if someone tells them to,

00:43:56.920 --> 00:44:02.442
and as psychologists I don't
think we have any right to do

00:44:02.442 --> 00:44:05.061
that to people.
I think people can learn

00:44:05.061 --> 00:44:06.559
this--these things about
themselves.

00:44:06.559 --> 00:44:10.791
We have no right to put you in
a circumstance where you believe

00:44:10.791 --> 00:44:14.886
you killed somebody and then
tell you it was just pretend--we

00:44:14.886 --> 00:44:19.647
just made you kill somebody.
And that's a serious ethical

00:44:19.647 --> 00:44:22.741
criticism.
Historians and sociologists

00:44:22.741 --> 00:44:27.366
have brought in things back to
the questions that Milgram was

00:44:27.366 --> 00:44:31.528
interested in and argue--and
this is controversial--the

00:44:31.528 --> 00:44:36.076
extent to which obedience really
is a good model for acts of

00:44:36.076 --> 00:44:39.718
genocide.
So, just to take one example

00:44:39.718 --> 00:44:44.620
among many, Goldhagen argued
that the participants in Nazi

00:44:44.620 --> 00:44:49.437
Germany and in the Holocaust
were actually not people who

00:44:49.437 --> 00:44:55.200
were obediently following orders
but rather were enthusiastic,

00:44:55.200 --> 00:44:57.610
people who volunteered to do it.

00:45:01.250 --> 00:45:04.789
Still Milgram's work is
interesting in many--for many

00:45:04.789 --> 00:45:08.872
reasons, in large part because
he provides an illustration of

00:45:08.872 --> 00:45:12.207
the perfect situation for
getting somebody to do a

00:45:12.207 --> 00:45:15.678
terrible thing and the perfect
situation has certain

00:45:15.678 --> 00:45:19.030
ingredients.
It includes authority,

00:45:19.030 --> 00:45:23.914
in this case the authority of
Yale and the authority of

00:45:23.914 --> 00:45:27.913
science.
"This is an experiment that

00:45:27.913 --> 00:45:30.948
must go on."
The notion of a self-assured

00:45:30.948 --> 00:45:34.067
experimenter--The results would
be very different if the

00:45:34.067 --> 00:45:36.280
experimenter himself seemed
nervous,

00:45:36.280 --> 00:45:40.981
unwilling to proceed,
confused, but he was confident

00:45:40.981 --> 00:45:45.960
and he kept saying that he will
take responsibility.

00:45:45.960 --> 00:45:48.880
There was distance between the
learner and the experimenter.

00:45:48.880 --> 00:45:52.507
Recall you get less of an
effect if you have to touch the

00:45:52.507 --> 00:45:56.070
guy but distance makes it easier
for you to kill him.

00:45:56.070 --> 00:45:59.241
And finally,
there's a new situation and no

00:45:59.241 --> 00:46:03.096
model of how to behave.
One of the reasons why the

00:46:03.096 --> 00:46:07.408
Milgram experiment is so nice to
know is that if this ever

00:46:07.408 --> 00:46:10.526
happens to you,
not as an experiment but in

00:46:10.526 --> 00:46:13.389
real life, it will no longer be
new to you.

00:46:13.389 --> 00:46:17.609
You'll know what sort of thing
this is and you'll be able to

00:46:17.609 --> 00:46:21.997
examine it in that light.
I want to end this lecture

00:46:21.997 --> 00:46:27.670
summing up, drawing a lot upon
Milgram and some other work,

00:46:27.670 --> 00:46:31.557
and talk first about two forces
for evil and then to end by

00:46:31.557 --> 00:46:33.969
talking about two forces for
good.

00:46:33.969 --> 00:46:38.449
The first force for evil is
deindividuation of self.

00:46:38.449 --> 00:46:45.054
And what this means is--one
reason why people are so bad in

00:46:45.054 --> 00:46:51.659
groups is because you could
diffuse your responsibility.

00:46:51.659 --> 00:46:55.355
If I'm running through the
street alone with a baseball bat

00:46:55.355 --> 00:46:58.860
smashing through windows,
it's me and I know it's me.

00:46:58.860 --> 00:47:03.320
If I'm with twenty other
people, it's not me anymore.

00:47:03.320 --> 00:47:06.810
It's part of the group and I
don't feel as bad.

00:47:06.810 --> 00:47:10.573
Responsibility becomes diffuse.
One of the powers of a group

00:47:10.573 --> 00:47:12.829
then is it diminishes
responsibility.

00:47:12.829 --> 00:47:15.329
You could diminish
responsibility in other ways.

00:47:15.329 --> 00:47:17.818
Another way of diminishing
responsibility is you could

00:47:17.818 --> 00:47:19.690
accept orders.
It's not me.

00:47:19.690 --> 00:47:23.578
I'm just an instrument of
somebody else telling me what to

00:47:23.578 --> 00:47:25.418
do.
And yet another way of

00:47:25.418 --> 00:47:28.210
diminishing responsibility is
anonymity.

00:47:28.210 --> 00:47:34.651
Here's a question.
In so many violent acts and so

00:47:34.651 --> 00:47:39.262
many people go to war,
what they do is they paint

00:47:39.262 --> 00:47:42.720
their faces or they put on
masks.

00:47:42.720 --> 00:47:46.400
Why?
Well, there's anonymity from

00:47:46.400 --> 00:47:49.316
others.
If I'm wearing a mask as I do

00:47:49.316 --> 00:47:52.662
my terrible stuff,
nobody will know it's me,

00:47:52.662 --> 00:47:56.086
but there's also a
psychologically liberating

00:47:56.086 --> 00:47:58.621
effect.
If I'm anonymous,

00:47:58.621 --> 00:48:03.991
it's not me and I could do
terrible things without feeling

00:48:03.991 --> 00:48:09.011
the same moral responsibility.
This analysis has explained why

00:48:09.011 --> 00:48:11.539
people don't always help others
in need.

00:48:11.539 --> 00:48:14.613
If there's a group,
responsibility to help

00:48:14.613 --> 00:48:19.111
decreases and this is captured
in different ways but the main

00:48:19.111 --> 00:48:23.610
idea is we all think someone
else will help so we don't.

00:48:23.610 --> 00:48:27.681
There's a diffusion.
This just summarizes some

00:48:27.681 --> 00:48:32.210
studies--some famous studies
supporting this.

00:48:32.210 --> 00:48:36.401
And the classic example,
which is discussed in detail in

00:48:36.401 --> 00:48:39.373
the textbook,
is the Kitty Genovese case

00:48:39.373 --> 00:48:43.869
where somebody was murdered in
the common lot that apartment

00:48:43.869 --> 00:48:48.289
buildings surrounded while
dozens of people watched,

00:48:48.289 --> 00:48:51.247
dozens of good,
normal people watched and did

00:48:51.247 --> 00:48:53.948
nothing.
If there's some advice I've

00:48:53.948 --> 00:48:57.103
heard on this,
which is pretty good advice:

00:48:57.103 --> 00:49:01.010
If you're ever in a predicament
on a city street,

00:49:01.010 --> 00:49:03.724
you have a heart attack,
you broke your leg,

00:49:03.724 --> 00:49:06.059
you're being mugged and
everything,

00:49:06.059 --> 00:49:08.902
and there's--this is based on
the research,

00:49:08.902 --> 00:49:12.894
screaming "Help" is often not
very successful because if I'm

00:49:12.894 --> 00:49:16.820
with ten people and there's
somebody screaming "Help,"

00:49:16.820 --> 00:49:19.790
I look at the other nine people.
They're not doing anything.

00:49:19.790 --> 00:49:21.640
They're looking at me.
I'm not doing anything.

00:49:21.640 --> 00:49:26.194
We keep walking.
What is useful is point to

00:49:26.194 --> 00:49:30.402
somebody and say,
"You in the green sweater,

00:49:30.402 --> 00:49:33.994
call the police,"
and the psychological evidence

00:49:33.994 --> 00:49:37.372
is if you--if somebody's--if I
am wearing the green sweater and

00:49:37.372 --> 00:49:40.750
somebody asks me to call the
police I will call the police.

00:49:40.750 --> 00:49:43.829
I'm a good guy.
I wouldn't sit aside when

00:49:43.829 --> 00:49:46.852
somebody's being harmed.
On the other hand,

00:49:46.852 --> 00:49:50.328
if somebody says,
"Somebody call the police,"

00:49:50.328 --> 00:49:54.910
well, I got things to do and so
diffusion of responsibility

00:49:54.910 --> 00:49:59.809
explains both when we're willing
to do terrible things and also

00:49:59.809 --> 00:50:04.550
when we're willing to help
people who are in trouble.

00:50:04.550 --> 00:50:07.607
Denigration of others.
There's a lot of ways to make

00:50:07.607 --> 00:50:10.190
other people matter less.
So, this is the flip side.

00:50:10.190 --> 00:50:13.107
The way to do terrible
things--One way to do terrible

00:50:13.107 --> 00:50:16.530
things is to lose yourself so
you're not an individual anymore

00:50:16.530 --> 00:50:19.784
but another way to do terrible
things is so that the person

00:50:19.784 --> 00:50:22.310
you're doing it to isn't an
individual.

00:50:22.310 --> 00:50:26.450
How do you do that?
Well, you have psychological

00:50:26.450 --> 00:50:31.257
distance or physical distance.
I'm more likely to kill you if

00:50:31.257 --> 00:50:34.909
you're very far away than if
you're close.

00:50:34.909 --> 00:50:39.431
I don't--I could describe you
and start to think about you not

00:50:39.431 --> 00:50:42.989
as a person and language can be
used for this.

00:50:42.989 --> 00:50:47.116
Instead of people you could use
terms like "cargo," instead of

00:50:47.116 --> 00:50:51.356
murder, extermination.
Humor is very powerful in

00:50:51.356 --> 00:50:56.216
denigrating and demoting people.
When you start laughing at

00:50:56.216 --> 00:50:59.407
somebody you think of them as
less of a person and we'll get

00:50:59.407 --> 00:51:02.490
to that a little bit more when
we talk about laughter.

00:51:02.490 --> 00:51:07.802
You could take away their names.
One of the more interesting

00:51:07.802 --> 00:51:11.896
things in the United Nations
Declaration of Human Rights is a

00:51:11.896 --> 00:51:15.958
very interesting right.
It says, "Every person has a

00:51:15.958 --> 00:51:19.502
right to a name."
And you might think what a

00:51:19.502 --> 00:51:23.170
strange right but there's a
cleverness to it.

00:51:23.170 --> 00:51:27.510
When you take away somebody's
name they matter less.

00:51:27.510 --> 00:51:30.315
People have names.
People have distinct,

00:51:30.315 --> 00:51:34.168
individual names that mark them
as people and once you know

00:51:34.168 --> 00:51:38.420
somebody's name you are less
likely to do bad things to them.

00:51:38.420 --> 00:51:42.174
And another option which I'm
interested in from the

00:51:42.174 --> 00:51:46.153
standpoint of my own research is
you could see them as

00:51:46.153 --> 00:51:50.548
disgusting.
Disgust is what Paul Rozin has

00:51:50.548 --> 00:51:54.469
called "the body and soul
emotion."

00:51:54.469 --> 00:51:56.530
And we know certain things
about disgust.

00:51:56.530 --> 00:52:01.282
It is a human universal.
It is a basic emotion with a

00:52:01.282 --> 00:52:04.599
characteristic facial
expression.

00:52:04.599 --> 00:52:07.355
Remember Paul Ekman's work on
the basic emotions,

00:52:07.355 --> 00:52:09.710
the universals of emotional
expression?

00:52:09.710 --> 00:52:17.289
Disgust is one of them and it
is universally elicited by

00:52:17.289 --> 00:52:22.918
certain things like this list.
Wherever you go,

00:52:22.918 --> 00:52:24.898
feces, urine,
blood, vomit,

00:52:24.898 --> 00:52:28.630
rotten flesh and most meat will
be disgusting.

00:52:28.630 --> 00:52:32.309
Now, if that was all we had to
say about disgust,

00:52:32.309 --> 00:52:36.373
it wouldn't affect morality
very much but we know that

00:52:36.373 --> 00:52:39.210
people can be seen as
disgusting.

00:52:39.210 --> 00:52:42.650
And Charles Darwin actually,
who was an astute observer of

00:52:42.650 --> 00:52:44.823
human behavior,
tells a nice story to

00:52:44.823 --> 00:52:47.600
illustrate this:
how "a native touched with his

00:52:47.600 --> 00:52:51.222
finger some cold preserved meat
and plainly showed disgust at

00:52:51.222 --> 00:52:55.085
its softness whilst I felt utter
disgust at my food being touched

00:52:55.085 --> 00:52:59.130
by a naked savage though his
hands did not appear dirty."

00:52:59.130 --> 00:53:05.084
People can be disgusting and if
people are seen as disgusting

00:53:05.084 --> 00:53:08.926
they matter less.
The philosopher and legal

00:53:08.926 --> 00:53:12.525
scholar Martha Nussbaum nicely
summarizes this:

00:53:12.525 --> 00:53:14.356
"Thus,
throughout history certain

00:53:14.356 --> 00:53:16.739
disgust properties have
repeatedly and monotonously been

00:53:16.739 --> 00:53:18.973
associated with Jews,
women, homosexuals,

00:53:18.973 --> 00:53:21.110
untouchables,
lower class people.

00:53:21.110 --> 00:53:25.038
All of those are imagined as
tainted by the dirt of the

00:53:25.038 --> 00:53:28.879
body."
Any--I won't read this but this

00:53:28.879 --> 00:53:32.769
is a typical bit of Nazi
propaganda.

00:53:32.769 --> 00:53:38.041
Any genocidal movement that has
left behind a written record has

00:53:38.041 --> 00:53:43.228
been shown to use the mechanism
of disgust to dehumanize people

00:53:43.228 --> 00:53:49.179
and make them easier to kill.
I'll skip that.

00:53:49.179 --> 00:53:53.039
I want to end though on a
positive note.

00:53:53.039 --> 00:53:56.860
And the positive note are
forces for good.

00:53:56.860 --> 00:54:01.778
So, forces for bad are to lose
yourself as an individual,

00:54:01.778 --> 00:54:05.830
lose yourself in a crowd,
lose yourself because there is

00:54:05.830 --> 00:54:08.911
some authority using you as an
instrument, lose yourself

00:54:08.911 --> 00:54:12.935
because you're anonymous,
plus treat others not as

00:54:12.935 --> 00:54:17.436
people, as numbers,
as objects, as disgusting

00:54:17.436 --> 00:54:23.017
things,
but there are some forces for

00:54:23.017 --> 00:54:25.908
good.
These include "contact" and

00:54:25.908 --> 00:54:29.801
"interdependence."
What this often--What this can

00:54:29.801 --> 00:54:32.996
be viewed as,
as an extended version of

00:54:32.996 --> 00:54:36.808
selfish gene theory,
which is that to the extent

00:54:36.808 --> 00:54:41.192
you're interconnected with other
people you care about them more

00:54:41.192 --> 00:54:45.378
for purely selfish reasons.
Robert Wright presented this in

00:54:45.378 --> 00:54:48.561
a very blunt way,
but I think his quote is quite

00:54:48.561 --> 00:54:52.353
moving: "One of the many reasons
I don't want to bomb the

00:54:52.353 --> 00:54:55.400
Japanese is that they built my
minivan."

00:54:55.400 --> 00:54:58.420
And the idea is he has economic
codependence with these people.

00:54:58.420 --> 00:55:01.931
They're a different group.
He might want to kill them

00:55:01.931 --> 00:55:06.688
under normal circumstances but
the interdependence gives rise

00:55:06.688 --> 00:55:10.666
to a moral connection.
Thomas Friedman proposed the

00:55:10.666 --> 00:55:14.871
"Golden Arches Theory of Human
Conflict," which said that no

00:55:14.871 --> 00:55:19.220
two countries which each have a
McDonald's will ever go to war

00:55:19.220 --> 00:55:23.070
because McDonald's forces global
interdependence.

00:55:23.070 --> 00:55:26.971
This was falsified in the NATO
bombing of, I think,

00:55:26.971 --> 00:55:31.030
Sarajevo but still his heart's
in the right place,

00:55:31.030 --> 00:55:35.136
the idea that interconnection
makes you more likely to get

00:55:35.136 --> 00:55:38.291
along with other people.
More generally,

00:55:38.291 --> 00:55:42.820
there's what's been called "The
Contact Hypothesis."

00:55:42.820 --> 00:55:46.996
So, interdependence is one
thing but what's maybe more

00:55:46.996 --> 00:55:51.329
interesting is that simple
contact with other people.

00:55:51.329 --> 00:55:56.112
Particularly if you're of equal
status, you have a common goal,

00:55:56.112 --> 00:56:00.510
and you have social support
makes you like people more.

00:56:00.510 --> 00:56:02.762
There are now dozens,
probably hundreds,

00:56:02.762 --> 00:56:05.996
of studies that show that
people who would otherwise show

00:56:05.996 --> 00:56:09.857
animosity towards one another,
like blacks and whites in the

00:56:09.857 --> 00:56:12.801
United States,
like each other more if they're

00:56:12.801 --> 00:56:15.710
brought together.
And there's a lot of social

00:56:15.710 --> 00:56:19.266
psychology research as to the
conditions in which you have to

00:56:19.266 --> 00:56:22.744
bring them together.
The Robber's Cave study talked

00:56:22.744 --> 00:56:27.173
about before is a nice example.
It was not easy to bring them

00:56:27.173 --> 00:56:31.070
together but when they had a
common goal that brought

00:56:31.070 --> 00:56:34.742
them--that caused the
interconnection and then the

00:56:34.742 --> 00:56:39.624
contact led to moral feeling.
The military is a superb

00:56:39.624 --> 00:56:42.182
example.
The military in the United

00:56:42.182 --> 00:56:45.742
States was a situation which
brought together people who

00:56:45.742 --> 00:56:49.238
wouldn't otherwise have any
contact and they liked each

00:56:49.238 --> 00:56:51.096
other.
There has been study after

00:56:51.096 --> 00:56:53.829
study showing that people in the
military who were otherwise,

00:56:53.829 --> 00:56:56.471
for instance,
racists after working with

00:56:56.471 --> 00:57:00.738
people of different races liked
them more because you had all of

00:57:00.738 --> 00:57:04.371
the right ingredients.
You had--They had--They worked

00:57:04.371 --> 00:57:07.990
together for a common goal,
the military supported bringing

00:57:07.990 --> 00:57:11.394
these people together,
and they were brought together

00:57:11.394 --> 00:57:14.499
on an equal and fair footing.
There is, of course,

00:57:14.499 --> 00:57:17.647
a lot of debate about
universities like Yale to the

00:57:17.647 --> 00:57:21.110
extent in which they promote
interdependence--sorry,

00:57:21.110 --> 00:57:24.510
they promote positive contact
between groups.

00:57:24.510 --> 00:57:27.269
And you could think of yourself
as an exercise.

00:57:27.269 --> 00:57:32.713
If these are the conditions for
contact, to what extent are they

00:57:32.713 --> 00:57:36.170
met in the university setting
between,

00:57:36.170 --> 00:57:39.544
say blacks and whites,
people from the American South

00:57:39.544 --> 00:57:42.139
versus people from the American
North,

00:57:42.139 --> 00:57:44.733
people from other countries
versus people from the United

00:57:44.733 --> 00:57:46.696
States?
And I know there's debate on

00:57:46.696 --> 00:57:50.175
campus about the extent to which
there is segregation within the

00:57:50.175 --> 00:57:52.564
Yale community.
And you could ask yourself

00:57:52.564 --> 00:57:55.406
the--about the extent of that
segregation and how that

00:57:55.406 --> 00:57:58.731
reflects--what role that should
play with regard to the Contact

00:57:58.731 --> 00:58:01.369
Hypothesis.
Finally, and this is the last

00:58:01.369 --> 00:58:04.009
thing I'll say:
If you take another person's

00:58:04.009 --> 00:58:06.710
perspective, you'll care more
about them.

00:58:06.710 --> 00:58:11.769
This is the final force for
good from a moral perspective.

00:58:11.769 --> 00:58:15.810
JFK, when making the plea for
equal rights,

00:58:15.810 --> 00:58:20.813
didn't produce an abstract
philosophical argument but

00:58:20.813 --> 00:58:25.912
rather tried to invite his
listeners who were white to

00:58:25.912 --> 00:58:30.227
engage in perspective taking.
If an American,

00:58:30.227 --> 00:58:32.302
because his skin is dark,
cannot eat lunch in a

00:58:32.302 --> 00:58:34.738
restaurant open to the
public--[and so on and so on and

00:58:34.738 --> 00:58:36.422
so on],
then who among us would be

00:58:36.422 --> 00:58:39.104
content to have the color of his
skin changed and stand in his

00:58:39.104 --> 00:58:41.075
place?
Who among us would be content

00:58:41.075 --> 00:58:43.630
with the counsels of patience
and delay?

00:58:43.630 --> 00:58:47.931
Again, Nussbaum goes on and
talks about how in Greek

00:58:47.931 --> 00:58:52.907
dramas--Greek dramas invited
people to take the perspectives

00:58:52.907 --> 00:58:57.630
of those who they would never
imaginably be or even be in

00:58:57.630 --> 00:59:02.521
contact with and argue that this
gave--led to an empathetic

00:59:02.521 --> 00:59:05.764
expansion.
I think one of the greatest

00:59:05.764 --> 00:59:08.958
circles for moral good is
storytelling where you're

00:59:08.958 --> 00:59:12.919
invited to take the perspective
of another and see the world as

00:59:12.919 --> 00:59:18.199
they do.
Finally, there are direct ways.

00:59:18.199 --> 00:59:21.394
You can ask people--and this is
a way which we talk to our

00:59:21.394 --> 00:59:24.812
children when we try to get our
children to expand their moral

00:59:24.812 --> 00:59:27.496
concern of compassion.
We say, "Try to see it from

00:59:27.496 --> 00:59:30.399
their point of view.
How would you feel if--"Then

00:59:30.399 --> 00:59:35.286
there's indirect ways.
You can, for instance,

00:59:35.286 --> 00:59:41.176
use the power of metaphor.
There could be familiar things

00:59:41.176 --> 00:59:44.641
that you are close to and you
could bring in together new

00:59:44.641 --> 00:59:48.539
things as falling under the
rubric of these familiar things.

00:59:48.539 --> 00:59:52.437
So, if I wanted to cause you to
feel moral concern for a fetus,

00:59:52.437 --> 00:59:55.769
I would do well to describe it
as a pre-born child.

00:59:55.769 --> 01:00:00.113
If I wanted you to care about
an animal, I would do well to

01:00:00.113 --> 01:00:05.147
describe it as if it were human.
If I wanted to think about all

01:00:05.147 --> 01:00:10.040
of you and get--and establish
more of a connection with you,

01:00:10.040 --> 01:00:14.269
I would not describe you as
unrelated strangers.

01:00:14.269 --> 01:00:18.809
Rather, you are my brothers and
my sisters.

01:00:18.809 --> 01:00:21.354
And of course,
any political movement that

01:00:21.354 --> 01:00:23.961
tries to bring us
together--people together

01:00:23.961 --> 01:00:29.029
says--uses a family metaphor.
Finally, when Steven Spielberg

01:00:29.029 --> 01:00:35.471
tried to get us to entertain the
notion that computers and robots

01:00:35.471 --> 01:00:41.912
are sentient moral beings he did
not show us one that looked like

01:00:41.912 --> 01:00:45.063
this .
He showed us one that looked

01:00:45.063 --> 01:00:47.559
like that .
Okay.

01:00:47.559 --> 01:00:51.030
The reading response for next
week is a simple one.

01:00:51.030 --> 01:00:53.270
I know I've been giving
difficult reading responses.

01:00:53.270 --> 01:00:55.485
This is simple.
You could write it up very

01:00:55.485 --> 01:00:58.409
short and that will be a passing
grade if you just write it up

01:00:58.409 --> 01:01:00.480
very short.
You could also write it up a

01:01:00.480 --> 01:01:03.337
bit longer.
Suppose the Milgram experiment

01:01:03.337 --> 01:01:07.777
had never been done and it was
being done for the first time

01:01:07.777 --> 01:01:11.530
here.
What would you do?

01:01:11.530 --> 01:01:13.460
What do you think everyone else
would do?

01:01:13.460 --> 01:01:17.000
Okay.
I'll see you next week.

