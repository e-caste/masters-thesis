WEBVTT
Kind: captions
Language: en

00:00:01.330 --> 00:00:09.490
So, what I want to talk about
today in lecture is a game

00:00:09.490 --> 00:00:15.090
theoretic notion known as The
Prisoners' Dilemma, which can

00:00:15.090 --> 00:00:21.300
be used to characterize a
structure that is brought out

00:00:21.300 --> 00:00:27.900
both in Book Two of Plato's
Republic and in chapter 13 of

00:00:27.900 --> 00:00:29.410
Hobbes' Leviathan.

00:00:29.410 --> 00:00:34.220
And the purpose of introducing
you to this way of thinking

00:00:34.220 --> 00:00:39.000
about questions is exactly what
we have been doing all

00:00:39.000 --> 00:00:40.370
semester long.

00:00:40.370 --> 00:00:45.330
It's taking a traditional set
of philosophical issues and

00:00:45.330 --> 00:00:51.420
asking how it is that another
discipline's methodology can

00:00:51.420 --> 00:00:56.760
shed light on those questions
in a complementary way.

00:00:56.760 --> 00:01:01.400
So you'll recall at the
beginning of the last lecture

00:01:01.400 --> 00:01:06.540
that I started off with a quote
from the beginning of

00:01:06.540 --> 00:01:11.480
Book Two of Plato's Republic
when Glaucon is answering

00:01:11.480 --> 00:01:15.440
Socrates' challenge to
articulate the nature and

00:01:15.440 --> 00:01:19.750
origins of justice--the nature
and origins of, roughly

00:01:19.750 --> 00:01:22.870
speaking, pro-social behavior.

00:01:22.870 --> 00:01:28.039
And I pointed out that the claim
that Glaucon makes there

00:01:28.039 --> 00:01:31.390
takes the form as follows. "They
say that to do justice--

00:01:31.390 --> 00:01:34.780
injustice is naturally good,
to suffer injustice is bad,

00:01:34.780 --> 00:01:37.480
but that the badness of
suffering so far exceeds the

00:01:37.480 --> 00:01:39.860
goodness of doing it that
those who have done and

00:01:39.860 --> 00:01:43.790
suffered injustice and taken
both but lack the power to do

00:01:43.790 --> 00:01:47.390
it and avoid suffering, decide
that it's profitable to come

00:01:47.390 --> 00:01:50.090
to an agreement with each other
neither to do injustice

00:01:50.090 --> 00:01:51.110
nor suffer it."

00:01:51.110 --> 00:01:53.840
And we illustrated that with
the example of the two

00:01:53.840 --> 00:01:58.420
shepherds, one of whom steals
another's horses and gains a

00:01:58.420 --> 00:02:01.280
certain amount of pleasure from
it, but not as much as

00:02:01.280 --> 00:02:04.880
the displeasure that the
stolen fellow receives

00:02:04.880 --> 00:02:09.730
likewise when the second
steals the first.

00:02:09.730 --> 00:02:13.660
So both of them end up in a
situation with less utility

00:02:13.660 --> 00:02:17.280
than they would have if they
were cooperating and they come

00:02:17.280 --> 00:02:21.830
together and form some
sort of pact.

00:02:21.830 --> 00:02:25.370
Glaucon continues with the
passage that I also read you

00:02:25.370 --> 00:02:26.210
last class.

00:02:26.210 --> 00:02:29.790
He says, "Justice is
intermediate between the best

00:02:29.790 --> 00:02:32.720
and the worst. The best is to
do injustice without paying

00:02:32.720 --> 00:02:33.810
the penalty.

00:02:33.810 --> 00:02:35.900
The worst is to suffer
it without being

00:02:35.900 --> 00:02:37.440
able to take revenge.

00:02:37.440 --> 00:02:41.500
Justice is a mean between
these two extremes."

00:02:41.500 --> 00:02:45.810
But I didn't read you the
sentence that follows that,

00:02:45.810 --> 00:02:51.080
which is one on which we'll be
focusing in today's lecture.

00:02:51.080 --> 00:02:57.520
Because Glaucon continues by
pointing out that on his view,

00:02:57.520 --> 00:03:00.410
and it will turn out, if you
were thinking of justice as

00:03:00.410 --> 00:03:03.550
this kind of coordination,
on anybody's view

00:03:03.550 --> 00:03:04.650
mathematically--

00:03:04.650 --> 00:03:07.460
can I ask one of the TFs to
fix the door so that it

00:03:07.460 --> 00:03:09.640
doesn't slam as people
walk in?

00:03:09.640 --> 00:03:14.090
What he says is, "People value
it not because it is a good,

00:03:14.090 --> 00:03:17.840
but because they are too weak
to do injustice with

00:03:17.840 --> 00:03:19.670
impunity."

00:03:19.670 --> 00:03:24.810
Someone who has the power to
harm another without being

00:03:24.810 --> 00:03:28.260
harmed himself, someone who
has the power to do this,

00:03:28.260 --> 00:03:32.400
however, wouldn't make an
agreement with anyone not to

00:03:32.400 --> 00:03:35.050
do injustice in order
not to suffer it.

00:03:35.050 --> 00:03:39.290
"For him, that would
be madness."

00:03:39.290 --> 00:03:43.410
So Glaucon has given us an
argument that we're going to

00:03:43.410 --> 00:03:46.300
see again in a minute in
Hobbes that takes the

00:03:46.300 --> 00:03:48.090
following form.

00:03:48.090 --> 00:03:54.220
It is rational when you think
there is no choice but to

00:03:54.220 --> 00:03:56.960
cooperate, to cooperate.

00:03:56.960 --> 00:04:02.450
But if you think you can get
away with having the other

00:04:02.450 --> 00:04:07.880
person cooperate while you act
in a non-cooperative fashion,

00:04:07.880 --> 00:04:13.550
it would be insane for
you to cooperate.

00:04:13.550 --> 00:04:16.758
It would be madness.

00:04:16.758 --> 00:04:21.440
Hobbes makes exactly
the same point in

00:04:21.440 --> 00:04:24.320
Chapter 13 of Leviathan.

00:04:24.320 --> 00:04:28.000
You'll remember that he
articulates there the first

00:04:28.000 --> 00:04:29.980
two laws of nature.

00:04:29.980 --> 00:04:35.770
Laws of nature, remember, are
norms to which rational beings

00:04:35.770 --> 00:04:40.990
qua rational beings are bound,
because they recognize that in

00:04:40.990 --> 00:04:45.230
following those norms they
increase the likelihood of

00:04:45.230 --> 00:04:49.650
preservation and flourishing
in their own lives.

00:04:49.650 --> 00:04:55.290
So the first law of nature
is a two-part law.

00:04:55.290 --> 00:04:59.490
It says seek peace if there's
a chance of obtaining peace,

00:04:59.490 --> 00:05:05.610
and if there is not,
engage in war.

00:05:05.610 --> 00:05:09.000
The second law of nature,
if you'll recall, also

00:05:09.000 --> 00:05:13.050
articulates a conditional
commitment to giving up a

00:05:13.050 --> 00:05:15.090
certain sort of freedom.

00:05:15.090 --> 00:05:18.600
The second law of nature tells
you to be willing to lay down

00:05:18.600 --> 00:05:21.830
your rights to the extent that
others are willing to do the

00:05:21.830 --> 00:05:26.390
same, and to content yourself
with as much liberty against

00:05:26.390 --> 00:05:30.300
others as they have
against you.

00:05:30.300 --> 00:05:36.180
So again, as in the first law
of nature, the giving up of

00:05:36.180 --> 00:05:40.130
rights is conditional
on others giving

00:05:40.130 --> 00:05:43.390
up rights as well.

00:05:43.390 --> 00:05:52.340
Like Glaucon, Hobbes gives voice
to the concern that this

00:05:52.340 --> 00:05:55.170
may not be feasible.

00:05:55.170 --> 00:05:59.750
He writes, "If other men will
not lay down their right as

00:05:59.750 --> 00:06:04.370
well as he, there is no
reason for anyone to

00:06:04.370 --> 00:06:07.090
divest himself of his.

00:06:07.090 --> 00:06:11.950
For to do that would be to
expose himself to prey which

00:06:11.950 --> 00:06:17.540
no man is bound to, rather than
to dispose himself to

00:06:17.540 --> 00:06:19.270
peace."

00:06:19.270 --> 00:06:23.010
We're going to be using the
clickers after the next slide,

00:06:23.010 --> 00:06:26.340
so if you get your clickers
out you'll be

00:06:26.340 --> 00:06:28.310
prepared for that.

00:06:28.310 --> 00:06:33.110
Now, I know that some of you
in this class are economics

00:06:33.110 --> 00:06:36.660
majors and some of you in this
class have taken game theory.

00:06:36.660 --> 00:06:39.880
And to those of you, I apologize
in the way that I

00:06:39.880 --> 00:06:43.790
apologize to the philosophy
majors for introducing you at

00:06:43.790 --> 00:06:46.040
a basic level to Plato's
Republic.

00:06:46.040 --> 00:06:49.840
But this is a resource that all
of us need to understand

00:06:49.840 --> 00:06:53.060
the class, and I promise that
there are some actual games

00:06:53.060 --> 00:06:55.840
that we'll be playing
in a few minutes.

00:06:55.840 --> 00:07:01.950
So the Prisoners' Dilemma is a
way of representing in graphic

00:07:01.950 --> 00:07:05.510
form the structure
to which both

00:07:05.510 --> 00:07:09.060
Glaucon and Hobbes adverted.

00:07:09.060 --> 00:07:14.810
And it involves representing a
pair of choices by a pair of

00:07:14.810 --> 00:07:19.810
people on a two-by-two matrix.

00:07:19.810 --> 00:07:26.100
So there is on the one hand an
individual, A, who faces two

00:07:26.100 --> 00:07:28.750
possibilities for action.

00:07:28.750 --> 00:07:33.660
The first is that she can behave
in a peaceful way, lay

00:07:33.660 --> 00:07:40.520
down her rights to attack her
enemy and thereby give up a

00:07:40.520 --> 00:07:42.870
certain kind of freedom.

00:07:42.870 --> 00:07:50.080
Or she can reserve for herself
the right to war and thereby

00:07:50.080 --> 00:07:57.250
produce in her challenger a
feeling of threat throughout.

00:07:57.250 --> 00:08:01.370
Her counterpart, B,
faces exactly the

00:08:01.370 --> 00:08:04.470
same pair of choices.

00:08:04.470 --> 00:08:11.690
He can behave peacefully and lay
down his right to attack,

00:08:11.690 --> 00:08:17.320
or he can reserve the pleasures
of war for moments

00:08:17.320 --> 00:08:22.820
when he feels himself, either
preemptively or retaliatorily,

00:08:22.820 --> 00:08:26.970
to need to engage in threatening
behavior.

00:08:26.970 --> 00:08:31.340
Now what's important to notice
about the prisoners'--

00:08:31.340 --> 00:08:31.570
Sorry.

00:08:31.570 --> 00:08:34.820
So that gives us four
possibilities.

00:08:34.820 --> 00:08:39.920
Either A and B can both behave
in peaceful fashion.

00:08:39.920 --> 00:08:44.910
That is, they satisfy the
initial clause of Hobbes'

00:08:44.910 --> 00:08:46.620
first law of nature.

00:08:46.620 --> 00:08:50.710
They do the handshake of
Glaucon's challenge; they each

00:08:50.710 --> 00:08:54.790
give up to the same amount of
what Hobbes talks about in the

00:08:54.790 --> 00:08:57.190
second law of nature.

00:08:57.190 --> 00:09:02.800
Or, they can both be in a state
of war with one another.

00:09:02.800 --> 00:09:05.800
This is what Glaucon thinks will
naturally arise and what

00:09:05.800 --> 00:09:09.460
Hobbes thinks is the case
in the state of nature.

00:09:09.460 --> 00:09:14.410
Or it can be the case that A,
the letter on the left refers

00:09:14.410 --> 00:09:18.630
to A, behaves peacefully,
whereas B behaves in a

00:09:18.630 --> 00:09:20.550
war-like fashion.

00:09:20.550 --> 00:09:24.280
Or it can be the case that A
behaves in a war-like fashion,

00:09:24.280 --> 00:09:28.420
whereas B behaves in a
peace-like fashion.

00:09:28.420 --> 00:09:32.130
Now what's important to notice
about the structure of The

00:09:32.130 --> 00:09:37.610
Prisoners' Dilemma, is
that A has control

00:09:37.610 --> 00:09:40.590
over which row obtains.

00:09:40.590 --> 00:09:46.030
A can determine whether we're
in this row or this row.

00:09:46.030 --> 00:09:52.050
But A has no control over
which column obtains.

00:09:52.050 --> 00:09:58.520
B, by contrast, has control over
which column obtains, and

00:09:58.520 --> 00:10:02.500
no control over which
row obtains.

00:10:02.500 --> 00:10:06.770
B can determine whether we're on
the left hand column or the

00:10:06.770 --> 00:10:12.370
right hand column, but B can't
determine through his direct

00:10:12.370 --> 00:10:18.050
behavior whether we're in the
top row or the bottom row.

00:10:18.050 --> 00:10:22.060
Now, I want to just start by
making sure that everybody has

00:10:22.060 --> 00:10:24.570
understood the structure of
this problem, because as I

00:10:24.570 --> 00:10:27.570
said I'm about to put some real
money on the line for

00:10:27.570 --> 00:10:29.920
you, and I want to make sure
that when you make the

00:10:29.920 --> 00:10:32.130
decision, you make it
understanding the

00:10:32.130 --> 00:10:33.950
structure of the case.

00:10:33.950 --> 00:10:39.240
So let me start by telling you
what A's preference structure

00:10:39.240 --> 00:10:42.670
is with regard to outcome, and
then ask you with your

00:10:42.670 --> 00:10:45.090
clickers to tell me
which choice is

00:10:45.090 --> 00:10:47.200
rational for A to make.

00:10:47.200 --> 00:10:53.750
So as we know from Glaucon,
everybody's first choice is to

00:10:53.750 --> 00:10:58.790
reserve for themselves all the
rights, but to have their

00:10:58.790 --> 00:11:01.820
opponent lay down his rights.

00:11:01.820 --> 00:11:06.790
So A's first choice is that
A is war-like and B is

00:11:06.790 --> 00:11:08.750
peace-like.

00:11:08.750 --> 00:11:13.050
Everybody's fourth choice, as
Glaucon points out, is to be

00:11:13.050 --> 00:11:15.700
stuck having laid down
their arms when their

00:11:15.700 --> 00:11:17.870
enemy hasn't done so.

00:11:17.870 --> 00:11:22.490
To be cooperating when their
enemy is failing to cooperate.

00:11:22.490 --> 00:11:25.960
So that's A's fourth choice.

00:11:25.960 --> 00:11:31.500
But as Glaucon and Hobbes both
point out, between the choice

00:11:31.500 --> 00:11:37.480
of peace-peace and war-war, that
is, a state of nature or

00:11:37.480 --> 00:11:40.270
a state of society where there's
been a mutual laying

00:11:40.270 --> 00:11:44.440
down of rights, it is
everybody's second choice, in

00:11:44.440 --> 00:11:49.450
particular A's second choice, to
be in a peaceful state and

00:11:49.450 --> 00:11:55.870
A's third choice to be in
a state of total war.

00:11:55.870 --> 00:12:00.220
So the question that I
want you to answer--

00:12:00.220 --> 00:12:05.450
so the choice that A makes
is which row we're in.

00:12:05.450 --> 00:12:09.010
A can put herself in a row where
she's either going to

00:12:09.010 --> 00:12:12.600
get her second choice or
her fourth choice.

00:12:12.600 --> 00:12:16.290
Or she can put herself in a row
where she's going to get

00:12:16.290 --> 00:12:19.830
either her first choice
or her third choice.

00:12:19.830 --> 00:12:22.730
That's the decision
A has to make.

00:12:22.730 --> 00:12:28.470
Second or fourth choice, versus
first or third choice.

00:12:28.470 --> 00:12:29.960
That's it.

00:12:29.960 --> 00:12:35.430
So, question, if you'll take
out your clickers, is this.

00:12:35.430 --> 00:12:39.110
Which choice, given
this matrix, is it

00:12:39.110 --> 00:12:41.900
rational for A to make?

00:12:41.900 --> 00:12:46.880
Is it rational for A to choose
row one, where she will get

00:12:46.880 --> 00:12:50.870
either her second or fourth
choice, or is it rational for

00:12:50.870 --> 00:12:53.600
A to choose row two, where
she'll get her

00:12:53.600 --> 00:12:55.400
first or third choice?

00:12:59.850 --> 00:13:01.000
OK.

00:13:01.000 --> 00:13:03.820
So.

00:13:03.820 --> 00:13:07.330
The 4% of you who want to punish
the guy who didn't do

00:13:07.330 --> 00:13:10.290
things that are wrong, to cut
up the guy who showed up

00:13:10.290 --> 00:13:18.100
naively at the hospital, and to
choose the dominated choice

00:13:18.100 --> 00:13:22.580
in a prisoners' dilemma matrix
are here with us always.

00:13:22.580 --> 00:13:25.470
Those of you reading psychology
articles who wonder

00:13:25.470 --> 00:13:29.170
why it is that in doing
statistical analysis one needs

00:13:29.170 --> 00:13:33.220
to leave room for experimental
error, can see over and over

00:13:33.220 --> 00:13:35.840
in our classroom environment
why that is so.

00:13:35.840 --> 00:13:42.830
But 96% of the answers brought
out what is inherently the

00:13:42.830 --> 00:13:47.100
structure of this situation,
namely, that given a choice

00:13:47.100 --> 00:13:50.300
between peace, where A will
get her second or fourth

00:13:50.300 --> 00:13:54.090
choice, and war, will she get
her first or third, the

00:13:54.090 --> 00:13:59.860
obvious thing for A to do is
to choose the lower row.

00:13:59.860 --> 00:14:04.180
So now we have A's
decision made.

00:14:04.180 --> 00:14:09.700
What is rational for A to do
is to choose the lower row.

00:14:09.700 --> 00:14:15.000
The situation for B is of course
exactly symmetric.

00:14:15.000 --> 00:14:19.660
B gets to choose the column,
so B can choose--

00:14:19.660 --> 00:14:24.010
B's first choice would be that
A is peaceful while B is

00:14:24.010 --> 00:14:28.140
war-like, B's fourth choice is
that A is war-like, while he's

00:14:28.140 --> 00:14:29.170
peace-like.

00:14:29.170 --> 00:14:32.610
B's second choice is peace-peace
and B's third

00:14:32.610 --> 00:14:34.420
choice is war-war.

00:14:34.420 --> 00:14:37.150
So just to check again and let's
see if I can get rid of

00:14:37.150 --> 00:14:40.770
that residual 4%,
let's try again.

00:14:40.770 --> 00:14:44.220
What is the rational
choice for B to

00:14:44.220 --> 00:14:45.390
make in this situation?

00:14:45.390 --> 00:14:48.080
If you do a good job on
this, we'll go to

00:14:48.080 --> 00:14:49.700
the real money one.

00:14:49.700 --> 00:14:52.890
What is the rational choice
for B to make in this

00:14:52.890 --> 00:14:56.960
situation, given that peace will
give him his second or

00:14:56.960 --> 00:15:00.800
fourth choice and war will give
him his first or third?

00:15:00.800 --> 00:15:06.052
So let's see how the numbers
come out this time for us.

00:15:06.052 --> 00:15:10.150
Three, two, one second, and--

00:15:13.184 --> 00:15:14.550
[LAUGHTER]

00:15:14.550 --> 00:15:15.800
PROFESSOR: Ha, ha, ha.

00:15:18.030 --> 00:15:19.200
All right.

00:15:19.200 --> 00:15:20.010
Excellent.

00:15:20.010 --> 00:15:22.680
So there we go.

00:15:22.680 --> 00:15:26.890
Ninety-two percent of you on
eternity on the internet have

00:15:26.890 --> 00:15:31.170
given a rational answer,
and 8% of you forever,

00:15:31.170 --> 00:15:34.336
anonymously, will be known
to have put yourself

00:15:34.336 --> 00:15:35.980
in situation one.

00:15:35.980 --> 00:15:38.820
So the structure of The
Prisoners' Dilemma with regard

00:15:38.820 --> 00:15:43.890
to B is also that the column
that is rejected is the

00:15:43.890 --> 00:15:45.270
peaceful column.

00:15:45.270 --> 00:15:49.800
So what we have is a situation
where A determines the row,

00:15:49.800 --> 00:15:52.770
sorry, where B determines the
column, and chooses the

00:15:52.770 --> 00:15:54.160
war-like column.

00:15:54.160 --> 00:15:58.220
A determines the row and chooses
the war-like row.

00:15:58.220 --> 00:16:04.810
And the result of this is that
it is a stable situation in

00:16:04.810 --> 00:16:09.930
dilemmas of this kind that
everybody ends up with their

00:16:09.930 --> 00:16:11.830
third choice.

00:16:11.830 --> 00:16:16.510
Now, the structure that we've
just described in the context

00:16:16.510 --> 00:16:22.430
of the Glaucon-Hobbes style
social contract question is of

00:16:22.430 --> 00:16:27.329
course a structure that emerges
over and over again.

00:16:27.329 --> 00:16:32.839
Any choice situation where the
person choosing the column has

00:16:32.839 --> 00:16:36.329
an array like this, and the
person choosing the row has an

00:16:36.329 --> 00:16:37.599
array like this.

00:16:37.599 --> 00:16:42.040
That is, any situation where
there is asymmetric first and

00:16:42.040 --> 00:16:46.640
fourth choices and symmetric
second and third choices, will

00:16:46.640 --> 00:16:50.980
end up stably putting people in
this situation where they

00:16:50.980 --> 00:16:53.920
both end up with their
third choice.

00:16:53.920 --> 00:16:59.910
So, for example, if
we put people--

00:16:59.910 --> 00:17:04.380
we're police officers and we
put criminals in a dilemma,

00:17:04.380 --> 00:17:06.830
this is why it's called The
Prisoners' Dilemma --

00:17:06.830 --> 00:17:13.100
where we incentivize unilateral
confession over

00:17:13.100 --> 00:17:18.990
staying silent, it will turn out
that both prisoners will

00:17:18.990 --> 00:17:23.450
be motivated to confess, ending
up with their third

00:17:23.450 --> 00:17:27.480
choice rather than what would
have been their second, both

00:17:27.480 --> 00:17:29.150
staying silent.

00:17:29.150 --> 00:17:33.680
If we are in a nuclear arms
race with another country

00:17:33.680 --> 00:17:38.020
where mutual disarmament would
leave both countries with a

00:17:38.020 --> 00:17:42.780
peace dividend, it will
nonetheless be the case that

00:17:42.780 --> 00:17:47.760
the fear of the other party
defecting and the fear of

00:17:47.760 --> 00:17:52.120
perhaps ending up in one of
these cells, will push both

00:17:52.120 --> 00:17:54.040
parties to the third choice.

00:17:54.040 --> 00:17:55.690
Third choice.

00:17:55.690 --> 00:18:00.330
If we are in the situation
described at the beginning of

00:18:00.330 --> 00:18:06.180
today's reading, Hume's story
of two individuals, both of

00:18:06.180 --> 00:18:09.630
whom would benefit if they put
in the effort to drain the

00:18:09.630 --> 00:18:14.360
swamp outside of their field,
neither of whom wants to be

00:18:14.360 --> 00:18:17.955
the only one to do it,
you will get a

00:18:17.955 --> 00:18:20.680
non-cooperative situation.

00:18:20.680 --> 00:18:24.590
And you face analogous
situations with any sort of

00:18:24.590 --> 00:18:30.190
cooperative scenario where
multiple people cooperating

00:18:30.190 --> 00:18:32.850
would produce an outcome that
was beneficial for the group

00:18:32.850 --> 00:18:38.180
as a whole, but no individual
wants to be the one who takes

00:18:38.180 --> 00:18:41.480
on an undue burden.

00:18:41.480 --> 00:18:45.900
So vaccination is another
example of

00:18:45.900 --> 00:18:47.910
a prisoners' dilemma.

00:18:47.910 --> 00:18:53.930
There's a certain low risk
associated with vaccinating

00:18:53.930 --> 00:18:56.890
your child or yourself
against a disease.

00:18:56.890 --> 00:19:00.140
There's a very, very low risk
that the child will get very

00:19:00.140 --> 00:19:03.560
ill and a somewhat moderate risk
that the child will have

00:19:03.560 --> 00:19:04.850
slight illness.

00:19:04.850 --> 00:19:10.640
On the other hand, if nobody
engaged in vaccination, we

00:19:10.640 --> 00:19:13.460
would be much worse off.

00:19:13.460 --> 00:19:16.060
And, in fact, the motivation
not to

00:19:16.060 --> 00:19:19.090
vaccinate would dissipate.

00:19:19.090 --> 00:19:24.590
So more generally, prisoners'
dilemmas arise when the

00:19:24.590 --> 00:19:28.350
cooperative situation
is dominated

00:19:28.350 --> 00:19:31.780
by the defect situation.

00:19:31.780 --> 00:19:36.390
And the puzzle that we will
talk about after we run

00:19:36.390 --> 00:19:41.510
through a few more examples is
how, if at all, it's possible

00:19:41.510 --> 00:19:47.090
to move from this cell
to this cell.

00:19:47.090 --> 00:19:51.430
So as I pointed out, prisoners'
dilemmas arise in

00:19:51.430 --> 00:19:55.340
asymmetric cases where one-sided
cooperation is the

00:19:55.340 --> 00:20:00.060
most costly option, where
one-sided defection is the

00:20:00.060 --> 00:20:05.160
most beneficial option, where
two-sided defection is

00:20:05.160 --> 00:20:08.577
somewhat costly, and where
two-sided defection

00:20:08.577 --> 00:20:09.110
[correction: cooperation]

00:20:09.110 --> 00:20:11.890
is somewhat beneficial.

00:20:11.890 --> 00:20:17.490
Now, how are we going to
do that in this class?

00:20:17.490 --> 00:20:19.970
Here's what I came up with.

00:20:19.970 --> 00:20:25.750
This is the classroom dilemma,
and it's for real.

00:20:25.750 --> 00:20:27.460
It's for real.

00:20:27.460 --> 00:20:32.220
The money's right here and I
have a list of the names of

00:20:32.220 --> 00:20:36.040
the students who are actually
going to get money from this

00:20:36.040 --> 00:20:37.480
for each dilemma that we play.

00:20:37.480 --> 00:20:39.230
We're playing three right now.

00:20:39.230 --> 00:20:43.570
One of you, and I'll tell you
afterwards, will actually get

00:20:43.570 --> 00:20:46.300
one of the following payoffs.

00:20:46.300 --> 00:20:50.790
If you choose one, and the
majority of the class chooses

00:20:50.790 --> 00:20:54.500
one, you will get $15.

00:20:54.500 --> 00:20:57.630
If you choose one, and the
majority of the class chooses

00:20:57.630 --> 00:20:59.340
one, you will get $15.

00:20:59.340 --> 00:21:01.100
Here's a twenty right
here, and I will

00:21:01.100 --> 00:21:03.990
make change for you.

00:21:03.990 --> 00:21:08.400
If you choose two, and the
majority of the class chooses

00:21:08.400 --> 00:21:11.770
one, you will get $50.

00:21:11.770 --> 00:21:12.780
Fifty dollars.

00:21:12.780 --> 00:21:16.290
I'm betting on game
theory here.

00:21:16.290 --> 00:21:19.710
If you choose one and
the majority of the

00:21:19.710 --> 00:21:21.410
class chooses two--

00:21:21.410 --> 00:21:23.986
I wanted to put in a
penalty here but I

00:21:23.986 --> 00:21:25.460
couldn't ask you for money.

00:21:25.460 --> 00:21:29.330
So you'll just get nothing.

00:21:29.330 --> 00:21:32.940
And if you choose two and the
majority of the class chooses

00:21:32.940 --> 00:21:36.560
two, you will get $5.

00:21:36.560 --> 00:21:41.390
Now, just to point out that I am
good on my word, Sarah Cox,

00:21:41.390 --> 00:21:42.710
are you here today?

00:21:42.710 --> 00:21:43.540
Sarah Cox.

00:21:43.540 --> 00:21:47.790
Sarah Cox, did you get
$5 from me on March--

00:21:47.790 --> 00:21:49.640
I'm sorry, on February 15?

00:21:49.640 --> 00:21:49.900
Yeah.

00:21:49.900 --> 00:21:51.980
Sarah Cox did get $5.

00:21:51.980 --> 00:21:55.790
And looking back over my notes
made me realize that I never

00:21:55.790 --> 00:22:00.210
selected somebody for the second
prize, and March 22 and

00:22:00.210 --> 00:22:04.230
24 were last week, so Tara
Abraham, are you here?

00:22:04.230 --> 00:22:04.950
Wow.

00:22:04.950 --> 00:22:08.190
Tara Abraham, you will get
either, you will actually get

00:22:08.190 --> 00:22:10.470
$6, because I'm just going
to assume that

00:22:10.470 --> 00:22:12.130
you were in the 97%.

00:22:12.130 --> 00:22:14.660
So come up after class
and get your money.

00:22:14.660 --> 00:22:15.280
OK.

00:22:15.280 --> 00:22:19.120
So I want to tell you that I'm
serious, and here's the

00:22:19.120 --> 00:22:20.930
classroom dilemma.

00:22:20.930 --> 00:22:22.230
Here it is.

00:22:22.230 --> 00:22:28.290
If you choose one, you will
get either $15 or zero

00:22:28.290 --> 00:22:32.990
dollars, depending on what the
majority of the class does.

00:22:32.990 --> 00:22:37.100
If you choose two-- swear,
I'm totally serious--

00:22:37.100 --> 00:22:41.920
you will get either $50 or $5,
depending on what the rest of

00:22:41.920 --> 00:22:43.910
the class does.

00:22:43.910 --> 00:22:45.980
I mean it.

00:22:45.980 --> 00:22:46.920
Start clicking.

00:22:46.920 --> 00:22:47.700
Only eight of you?

00:22:47.700 --> 00:22:48.810
Nobody wants the money?

00:22:48.810 --> 00:22:50.680
I'm going to start the timer.

00:22:50.680 --> 00:22:52.210
Don't miss your chance.

00:22:52.210 --> 00:22:54.060
This is real money.

00:22:54.060 --> 00:22:57.780
There is a list of names
right here, for real.

00:22:57.780 --> 00:22:59.740
Those two people that I called
are really here.

00:22:59.740 --> 00:23:00.840
These are not plants.

00:23:00.840 --> 00:23:03.900
If you're not here somebody
else will get the money.

00:23:03.900 --> 00:23:05.920
So bid away.

00:23:05.920 --> 00:23:10.530
You have 10, 9, 8, let's
see whether game

00:23:10.530 --> 00:23:14.270
theory is on my side.

00:23:14.270 --> 00:23:18.020
All right, let's see
what we got.

00:23:18.020 --> 00:23:18.400
OK.

00:23:18.400 --> 00:23:23.080
The majority of the class chose
two, so there I am.

00:23:23.080 --> 00:23:28.730
And the individual selected
is Charles Holmes.

00:23:28.730 --> 00:23:32.460
Charles Holmes, are you here?

00:23:32.460 --> 00:23:38.200
Charles Holmes is not getting
what Charles Holmes might have

00:23:38.200 --> 00:23:42.290
gotten, which is either
zero or $5--

00:23:42.290 --> 00:23:44.870
well, Charles Holmes is getting
zero dollars, but not

00:23:44.870 --> 00:23:46.830
as a result of this.

00:23:46.830 --> 00:23:48.970
Sello Lekalakala are you here?

00:23:48.970 --> 00:23:55.520
Sello Lekalakala Sello
Lekalakala Did you give an

00:23:55.520 --> 00:23:59.660
answer, Sello, of one or two?

00:23:59.660 --> 00:24:00.770
You gave an answer of two.

00:24:00.770 --> 00:24:04.890
Sello, after class, you may
come up and get $5.

00:24:04.890 --> 00:24:06.230
Let's try it again.

00:24:06.230 --> 00:24:10.750
Let's see whether I am going
to have to pay my $50.

00:24:10.750 --> 00:24:11.540
OK?

00:24:11.540 --> 00:24:15.740
I was betting that I would have
to give $5, and I did.

00:24:15.740 --> 00:24:17.930
Notice, you guys, you ended up
in the bottom right hand

00:24:17.930 --> 00:24:19.220
corner of the prisoners'
dilemma.

00:24:19.220 --> 00:24:19.680
OK?

00:24:19.680 --> 00:24:21.130
Let's try it again.

00:24:21.130 --> 00:24:22.670
Same game.

00:24:22.670 --> 00:24:23.950
Trying it again.

00:24:23.950 --> 00:24:27.260
I'm really risking, right?

00:24:27.260 --> 00:24:28.750
Go ahead.

00:24:28.750 --> 00:24:30.360
Do what you can.

00:24:30.360 --> 00:24:32.270
Try to get your $50.

00:24:32.270 --> 00:24:34.200
Give it your best shot.

00:24:34.200 --> 00:24:34.820
All right.

00:24:34.820 --> 00:24:35.560
Forty-nine of you.

00:24:35.560 --> 00:24:38.340
Let me start the timer,
and let's see how the

00:24:38.340 --> 00:24:40.360
numbers come out.

00:24:40.360 --> 00:24:48.110
Let's see in our 4, 3, 2, 1
second live for television

00:24:48.110 --> 00:24:51.320
audiences, 68 and 32.

00:24:51.320 --> 00:24:56.820
OK, so once again the majority
has put us in two.

00:24:56.820 --> 00:25:02.170
So let's see whether the victor,
what the victor is

00:25:02.170 --> 00:25:02.910
going to get.

00:25:02.910 --> 00:25:06.280
Either $50 or $5.

00:25:06.280 --> 00:25:08.410
Sorry, either zero or $5.

00:25:08.410 --> 00:25:10.840
The winner this time
is Helen Wang.

00:25:10.840 --> 00:25:13.350
Helen Wang, are you going
to get zero, or $5?

00:25:13.350 --> 00:25:14.700
Are you here, Helen?

00:25:14.700 --> 00:25:15.250
OK.

00:25:15.250 --> 00:25:17.320
Helen, did you give--

00:25:17.320 --> 00:25:21.050
are you getting zero
dollars or $5?

00:25:21.050 --> 00:25:23.400
You're getting $5.

00:25:23.400 --> 00:25:23.910
Excellent.

00:25:23.910 --> 00:25:24.250
All right.

00:25:24.250 --> 00:25:25.260
I'm out another $5.

00:25:25.260 --> 00:25:27.220
Let's try it one more time.

00:25:27.220 --> 00:25:28.700
Game theory on my side.

00:25:28.700 --> 00:25:30.600
Guys, you're in the bottom
right hand corner.

00:25:30.600 --> 00:25:31.510
What's up?

00:25:31.510 --> 00:25:33.810
This is the prisoners'
dilemma for you.

00:25:33.810 --> 00:25:35.970
Let's try it one more time.

00:25:35.970 --> 00:25:37.150
Which do you choose?

00:25:37.150 --> 00:25:39.890
Same bet all over again.

00:25:39.890 --> 00:25:41.020
OK?

00:25:41.020 --> 00:25:42.950
I have all the money
right here.

00:25:42.950 --> 00:25:48.130
I stole it actually from my
son's Bar Mitzvah folder.

00:25:48.130 --> 00:25:51.360
I don't have cash at home
but he had a lot.

00:25:51.360 --> 00:25:51.710
All right.

00:25:51.710 --> 00:25:55.530
But I will fortunately be able
to pay him back most of it, so

00:25:55.530 --> 00:25:56.920
he'll be grateful.

00:25:56.920 --> 00:25:58.360
OK.

00:25:58.360 --> 00:26:00.080
So let's see how our
numbers are going.

00:26:00.080 --> 00:26:01.550
Forty-nine of you
up there again.

00:26:01.550 --> 00:26:09.980
Ten, nine, eight, seven, six,
five, four, three, two, one.

00:26:09.980 --> 00:26:13.720
Let's see whether I'm going
to lose some money.

00:26:13.720 --> 00:26:14.190
Fifty-four percent.

00:26:14.190 --> 00:26:15.590
You're getting closer.

00:26:15.590 --> 00:26:16.260
Ah ha.

00:26:16.260 --> 00:26:19.600
I put it up three times,
thinking very, very hard that

00:26:19.600 --> 00:26:21.550
I didn't want to put
it up a fourth.

00:26:21.550 --> 00:26:22.310
OK.

00:26:22.310 --> 00:26:25.020
So the winner this time,
Jared Jones.

00:26:25.020 --> 00:26:26.700
Jared Jones, are you here?

00:26:26.700 --> 00:26:27.890
Jared Jones, OK.

00:26:27.890 --> 00:26:32.050
Jared, do you get zero
dollars or $5?

00:26:32.050 --> 00:26:32.800
You picked two.

00:26:32.800 --> 00:26:37.330
So once again $5, and we are
in the bottom right hand

00:26:37.330 --> 00:26:39.460
corner of the prisoners'
dilemma.

00:26:39.460 --> 00:26:43.610
OK, dudes, you missed out on
the peace dividend, right?

00:26:43.610 --> 00:26:47.810
You would have been better off
if somehow we could have ended

00:26:47.810 --> 00:26:50.170
up in the fifteen-fifteen
cell.

00:26:50.170 --> 00:26:53.290
And the cooperation dividend,
which was unavailable to you

00:26:53.290 --> 00:26:55.520
because of course this is a big
room and you're seated in

00:26:55.520 --> 00:26:57.860
rows and you couldn't collude
and there were no enforcement

00:26:57.860 --> 00:27:01.590
mechanisms. The cooperation
dividend was

00:27:01.590 --> 00:27:03.250
unavailable to you.

00:27:03.250 --> 00:27:05.380
What's the cooperation
dividend look like?

00:27:05.380 --> 00:27:06.640
Well, it looks like this.

00:27:06.640 --> 00:27:12.280
Here are our two shepherds in
the state of nature and each

00:27:12.280 --> 00:27:15.030
of them grows a garden.

00:27:15.030 --> 00:27:20.450
But because it's the state of
nature, the green guy goes

00:27:20.450 --> 00:27:25.070
over to the red guy's garden and
steals a tomato, and the

00:27:25.070 --> 00:27:28.340
red guy, angry at the green guy,
goes over to the green

00:27:28.340 --> 00:27:32.660
guy's garden and smashes it
up with his pitchfork.

00:27:32.660 --> 00:27:36.610
So the green guy says, I don't
want the red guy smashing up

00:27:36.610 --> 00:27:38.440
my garden with his pitchfork.

00:27:38.440 --> 00:27:41.560
I'm going to put a fence around
my garden, and he uses

00:27:41.560 --> 00:27:43.230
his effort to do that.

00:27:43.230 --> 00:27:46.410
And the red guy says, I don't
want the green guy stealing my

00:27:46.410 --> 00:27:50.870
tomatoes, and he puts a fence
around his garden.

00:27:50.870 --> 00:27:56.750
If, however, they had somehow
been able to cooperate, to

00:27:56.750 --> 00:28:01.610
make some sort of agreement
whereby they would keep their

00:28:01.610 --> 00:28:05.220
hands off the other fellow's
garden, instead of putting

00:28:05.220 --> 00:28:10.260
that effort into building the
fences, they could have put

00:28:10.260 --> 00:28:15.300
their effort into what Hobbes
calls the features of

00:28:15.300 --> 00:28:16.330
commodious living.

00:28:16.330 --> 00:28:19.530
So the green fellow could've had
a beautiful flower garden

00:28:19.530 --> 00:28:23.050
that attracts hummingbirds, and
the red fellow could have

00:28:23.050 --> 00:28:28.770
developed a device that allows
him to predict the motion of

00:28:28.770 --> 00:28:30.100
the planets.

00:28:30.100 --> 00:28:36.070
When we don't have to expend
energy on things like

00:28:36.070 --> 00:28:40.890
protecting our property, we have
extra energy left over

00:28:40.890 --> 00:28:43.670
for things like commodious
living.

00:28:43.670 --> 00:28:47.710
And just to remind you where
that fits in the context of

00:28:47.710 --> 00:28:53.700
things, this is Hobbes'
explanation for why it is

00:28:53.700 --> 00:28:59.680
rational for us to engage
in a social contract.

00:28:59.680 --> 00:29:03.490
What I want to do now is to
introduce you to a second

00:29:03.490 --> 00:29:07.330
notion closely related to that
of The Prisoners' Dilemma.

00:29:07.330 --> 00:29:10.110
Namely, The Problem
of the Commons.

00:29:10.110 --> 00:29:12.410
And I'll give you three examples
of that, and then

00:29:12.410 --> 00:29:15.370
we'll get to play
one more game.

00:29:15.370 --> 00:29:18.190
And there's real money on the
line there, so let me say I

00:29:18.190 --> 00:29:20.450
have a lot left over from
the last round.

00:29:20.450 --> 00:29:24.380
So here's The Problem
of the Commons.

00:29:24.380 --> 00:29:26.090
Tragedy of the Commons.

00:29:26.090 --> 00:29:34.340
So suppose you live around a
beautiful green area and you

00:29:34.340 --> 00:29:38.980
and your fellow shepherds
each have a cow.

00:29:38.980 --> 00:29:43.150
So you put your cow out on
the pasture to graze, and

00:29:43.150 --> 00:29:45.530
everything's going fine.

00:29:45.530 --> 00:29:49.120
Now there's a nice big pasture
there, and in fact you would

00:29:49.120 --> 00:29:53.970
be better off if you had
not one but two cows.

00:29:53.970 --> 00:30:00.770
So you and each of your fellow
shepherds gets a second cow,

00:30:00.770 --> 00:30:03.650
and puts it out in
the pasture.

00:30:03.650 --> 00:30:08.830
But of course if two cows were
good, three cows are better.

00:30:08.830 --> 00:30:14.460
So you and each of your fellow
shepherds puts your extra cow

00:30:14.460 --> 00:30:19.910
out, and now you have
three cows apiece.

00:30:19.910 --> 00:30:24.800
Three cows great, four
cows, super duper.

00:30:24.800 --> 00:30:29.550
Each of you gets a fourth cow,
puts it out to pasture.

00:30:29.550 --> 00:30:34.990
And the result, if the clicker
will work, the result is that

00:30:34.990 --> 00:30:38.370
there is no more space
left to graze.

00:30:38.370 --> 00:30:42.400
The pasture gets destroyed.

00:30:42.400 --> 00:30:47.050
So scarce resources become
depleted through The Tragedy

00:30:47.050 --> 00:30:49.440
of the Commons.

00:30:49.440 --> 00:30:53.610
Likewise, it's now the
industrial revolution.

00:30:53.610 --> 00:30:56.800
We've made it past our
shepherd days.

00:30:56.800 --> 00:31:00.750
You and your fellow
industrialists each create one

00:31:00.750 --> 00:31:04.870
polluting plant,
and here it is.

00:31:04.870 --> 00:31:07.190
Putting out a little
bit of pollution.

00:31:07.190 --> 00:31:12.370
One polluting plant good, two
polluting plants better, so

00:31:12.370 --> 00:31:15.660
out you go, and there's
the profit.

00:31:15.660 --> 00:31:19.170
No idea why these are going
non-cooperatively.

00:31:19.170 --> 00:31:20.120
There we go.

00:31:20.120 --> 00:31:22.090
You got your third plant
super fast on

00:31:22.090 --> 00:31:24.116
account of the clicker.

00:31:24.116 --> 00:31:27.490
And out comes the fourth
plant for each of you.

00:31:27.490 --> 00:31:31.920
Result, the entire environment
is polluted.

00:31:31.920 --> 00:31:34.970
Each of you did the thing that
was rational, but the

00:31:34.970 --> 00:31:39.750
coordinated effect of your
actions gave you a wildly

00:31:39.750 --> 00:31:45.000
sub-optimal result, an
environment full of pollution.

00:31:45.000 --> 00:31:50.930
Notice that we can think of
everybody in this class'

00:31:50.930 --> 00:31:57.980
favorite problem, the problem
of procrastination, in light

00:31:57.980 --> 00:32:01.606
of The Tragedy of the Commons.

00:32:01.606 --> 00:32:04.410
Suppose this is a representation
of the

00:32:04.410 --> 00:32:07.360
hours in your day.

00:32:07.360 --> 00:32:12.350
And this is your 9 a. m. self,
and this is your noon self,

00:32:12.350 --> 00:32:17.800
and this is your 6 p.m. self,
and this is your 10 p.m. self.

00:32:17.800 --> 00:32:22.550
Now, your 9 a.m. self and your
noon self and your 6 p.m.

00:32:22.550 --> 00:32:28.060
self, and your evening self,
all want to play a round of

00:32:28.060 --> 00:32:30.520
Angry Birds.

00:32:30.520 --> 00:32:31.560
But, you know what?

00:32:31.560 --> 00:32:34.330
One round good, two
rounds better.

00:32:34.330 --> 00:32:37.850
Two rounds, good, three
rounds great.

00:32:37.850 --> 00:32:40.580
Three rounds great, four rounds
super, and all of a

00:32:40.580 --> 00:32:45.210
sudden you've spent your day
playing Angry Birds.

00:32:45.210 --> 00:32:49.260
So the structure that The
Tragedy of the Commons

00:32:49.260 --> 00:32:55.240
confronts us with is not just
one of depletion of resources.

00:32:55.240 --> 00:33:00.590
It's not just one of pollution
of the environment and other

00:33:00.590 --> 00:33:05.410
sorts of degradation that result
from actions that are

00:33:05.410 --> 00:33:09.920
individually non-problematic,
but as an aggregate, lead to

00:33:09.920 --> 00:33:11.540
bad outcomes.

00:33:11.540 --> 00:33:16.120
It's also a way of thinking
about one of the questions

00:33:16.120 --> 00:33:19.200
we've asked ourselves over
and over in this course.

00:33:19.200 --> 00:33:24.760
Which is, how do we structure
our lives in such a way that

00:33:24.760 --> 00:33:28.639
our long-term goals are
the ones we achieve?

00:33:28.639 --> 00:33:32.550
And when I say I'm not kidding
that the trope of the

00:33:32.550 --> 00:33:36.929
Republic, that the individual
and society mirror one another

00:33:36.929 --> 00:33:40.389
in important ways, here's
another place

00:33:40.389 --> 00:33:43.330
that I'm not kidding.

00:33:43.330 --> 00:33:48.360
So let's play our own Tragedy
of the Commons game.

00:33:48.360 --> 00:33:50.949
So here's how our Tragedy
of the Commons

00:33:50.949 --> 00:33:54.429
game is going to go.

00:33:54.429 --> 00:33:55.230
OK.

00:33:55.230 --> 00:33:57.470
So the deal is this.

00:33:57.470 --> 00:34:02.219
Each of you can decide whether
in this game, if you are the

00:34:02.219 --> 00:34:05.800
name called, and I have more
names on my list, if you are

00:34:05.800 --> 00:34:08.880
the name called, whether you
will take a reward of $1.

00:34:08.880 --> 00:34:10.670
If so, push one.

00:34:10.670 --> 00:34:13.570
Whether you will take
a reward of $2, in

00:34:13.570 --> 00:34:15.270
which case, push two.

00:34:15.270 --> 00:34:16.570
Or whether you will take--

00:34:16.570 --> 00:34:18.660
I'm sorry, of $10, push two.

00:34:18.660 --> 00:34:23.500
Or whether you will take a
reward if called, of $50.

00:34:23.500 --> 00:34:24.120
Fifty dollars.

00:34:24.120 --> 00:34:26.525
There's a name on this list.
There's roughly a hundred

00:34:26.525 --> 00:34:30.590
clickers, you have a one in
100 chance of $50 if you

00:34:30.590 --> 00:34:31.690
choose three.

00:34:31.690 --> 00:34:33.670
But here's the deal.

00:34:33.670 --> 00:34:39.540
If the total requested is less
than $150, I'll reward the

00:34:39.540 --> 00:34:41.570
winning student with
the amount that

00:34:41.570 --> 00:34:43.580
he or she has requested.

00:34:43.580 --> 00:34:46.320
But if the total requested,
and I will say, I thought

00:34:46.320 --> 00:34:49.190
there would be more clickers
than there are, this is a

00:34:49.190 --> 00:34:51.910
riskier game than I
meant myself to be

00:34:51.910 --> 00:34:54.290
playing, but we will see.

00:34:54.290 --> 00:34:58.400
If the total requested is more
than $150, Tragedy of the

00:34:58.400 --> 00:35:04.350
Commons, bank goes bust, too
many requests, no reward.

00:35:04.350 --> 00:35:05.140
OK?

00:35:05.140 --> 00:35:09.120
So, the game is there,
22, 23, 24--

00:35:09.120 --> 00:35:09.930
I'm going to hold off.

00:35:09.930 --> 00:35:12.460
I want a lot of responses
to this game.

00:35:12.460 --> 00:35:14.670
Let's see how these
numbers come in.

00:35:14.670 --> 00:35:16.605
All right, I am going
to play fair.

00:35:16.605 --> 00:35:18.660
I'm going to start
count down now.

00:35:18.660 --> 00:35:26.870
Ten, nine, eight, seven, six,
five, four, three, two, one.

00:35:26.870 --> 00:35:28.760
You only came in at
85 responses?

00:35:28.760 --> 00:35:30.390
I may have to do some math.

00:35:30.390 --> 00:35:32.700
No, I don't have to
do some math.

00:35:32.700 --> 00:35:33.110
Busted.

00:35:33.110 --> 00:35:34.970
You guys bankrupted the bank.

00:35:34.970 --> 00:35:36.000
There's no way, right?

00:35:36.000 --> 00:35:39.580
I mean, at 30 times 10, you're
way over the $150.

00:35:39.580 --> 00:35:41.380
Greedy, greedy, greedy.

00:35:41.380 --> 00:35:43.220
Who didn't get their dollar?

00:35:43.220 --> 00:35:45.070
Kyle Cooper, I'm sorry.

00:35:45.070 --> 00:35:48.060
You would've gotten some money
and you got nothing.

00:35:48.060 --> 00:35:49.040
All right.

00:35:49.040 --> 00:35:51.540
Now, that's an interesting
psychological question, why

00:35:51.540 --> 00:35:54.150
it's worse to have gotten
nothing that way than the way

00:35:54.150 --> 00:35:56.880
that all the rest of
you got nothing?

00:35:56.880 --> 00:35:57.560
OK.

00:35:57.560 --> 00:36:03.370
So, what's going on in The
Tragedy of the Commons is what

00:36:03.370 --> 00:36:04.460
you see here.

00:36:04.460 --> 00:36:07.560
That is, each of you did what
was individually rational, I

00:36:07.560 --> 00:36:11.410
mean, 18% percent of you
went for the big money.

00:36:11.410 --> 00:36:13.680
But 38% of you went for $10.

00:36:13.680 --> 00:36:18.540
Only 45% of the students chose
the option that was possible

00:36:18.540 --> 00:36:20.350
for everybody to take.

00:36:20.350 --> 00:36:23.805
You violated the categorical
imperative.

00:36:23.805 --> 00:36:24.190
All right.

00:36:24.190 --> 00:36:25.640
Well, that's life.

00:36:25.640 --> 00:36:29.600
But the question is, now that
we've presented ourselves with

00:36:29.600 --> 00:36:31.980
these two versions of the
puzzle, The Prisoners' Dilemma

00:36:31.980 --> 00:36:35.460
on the one hand and The Tragedy
of the Commons on the

00:36:35.460 --> 00:36:39.430
other, what kind of strategies
there are for escape.

00:36:39.430 --> 00:36:42.670
And in the last 10 minutes of
lecture, I just want to talk

00:36:42.670 --> 00:36:46.990
through at a very general level
what kinds of strategies

00:36:46.990 --> 00:36:48.340
are available.

00:36:48.340 --> 00:36:50.960
So remember, the
issue is this.

00:36:50.960 --> 00:36:54.510
Three out of three times, you
all ended up in the bottom

00:36:54.510 --> 00:36:57.360
right hand corner of The
Prisoners' Dilemma.

00:36:57.360 --> 00:37:01.070
You ended up with your third
choice rather than what could

00:37:01.070 --> 00:37:04.950
also potentially have been a
stable outcome, your second.

00:37:04.950 --> 00:37:08.940
And in The Tragedy of the
Commons, you all, as a result

00:37:08.940 --> 00:37:12.950
of your expression of rational
self-interest, ended up in a

00:37:12.950 --> 00:37:18.090
situation where, as an
aggregate, you were worse off.

00:37:18.090 --> 00:37:22.690
So what do we need to do to
escape this situation?

00:37:22.690 --> 00:37:27.950
We need somehow to structure the
decision situation so that

00:37:27.950 --> 00:37:30.900
we either decrease the relative
utility of the

00:37:30.900 --> 00:37:35.050
sub-optimal behavior, or
increase the relative utility

00:37:35.050 --> 00:37:37.210
of the optimal behavior.

00:37:37.210 --> 00:37:41.570
That is, somehow we want to make
it the case that B isn't

00:37:41.570 --> 00:37:45.350
moving us over to the right,
and that A isn't moving us

00:37:45.350 --> 00:37:47.540
down to the bottom.

00:37:47.540 --> 00:37:52.810
That's the only way for us to
get out of this situation.

00:37:52.810 --> 00:37:59.520
So we have various mechanisms
that are available to us for

00:37:59.520 --> 00:38:01.050
doing this.

00:38:01.050 --> 00:38:07.230
We can introduce some sort of
penalty or reward for the

00:38:07.230 --> 00:38:13.400
asymmetric cells in a way that
will either make the one less

00:38:13.400 --> 00:38:18.640
appealing, or the four
less repulsive.

00:38:18.640 --> 00:38:24.100
So that the siren call of the
first choice doesn't beckon B

00:38:24.100 --> 00:38:30.230
in the same way to defect, and
the fear of the fourth choice

00:38:30.230 --> 00:38:34.530
doesn't beckon A to defect.

00:38:34.530 --> 00:38:40.650
The result of having done this
will be to create the

00:38:40.650 --> 00:38:47.360
potential for some sort
of stable, sustainable

00:38:47.360 --> 00:38:50.610
equilibrium at the
preferred cell.

00:38:50.610 --> 00:38:55.620
At our two-two, rather
than our three-three.

00:38:55.620 --> 00:39:01.490
So what sort of mechanisms are
available in this context?

00:39:01.490 --> 00:39:06.010
Well, the first place we might
look is to external penalties

00:39:06.010 --> 00:39:08.580
and external rewards.

00:39:08.580 --> 00:39:13.660
So one thing that we can do is
simply to incentivize the

00:39:13.660 --> 00:39:15.600
cooperative behavior.

00:39:15.600 --> 00:39:19.870
We can do it with material
incentives, like increased

00:39:19.870 --> 00:39:24.240
money or goods, things
that are valuable.

00:39:24.240 --> 00:39:27.590
We can do it with social
incentives.

00:39:27.590 --> 00:39:32.540
We can have status markers
associated with cooperation.

00:39:32.540 --> 00:39:36.200
We can bring reputation
costs into play.

00:39:36.200 --> 00:39:40.050
And when we play prisoners'
dilemma games in sections next

00:39:40.050 --> 00:39:43.860
week, you'll have an opportunity
to try out all of

00:39:43.860 --> 00:39:45.515
these things.

00:39:45.515 --> 00:39:50.580
Or we can induce certain kinds
of personal incentives.

00:39:50.580 --> 00:39:55.700
We can increase your freedoms or
your privileges as a result

00:39:55.700 --> 00:39:59.026
of your having cooperated.

00:39:59.026 --> 00:40:02.460
And with respect to each of
these kinds of incentives,

00:40:02.460 --> 00:40:07.830
there are counterparts
which are penalties.

00:40:07.830 --> 00:40:11.730
So, there can be material
penalties associated with

00:40:11.730 --> 00:40:13.080
non-cooperation.

00:40:13.080 --> 00:40:15.060
We can decrease your
amount of money.

00:40:15.060 --> 00:40:17.460
We can take away some
of your goods.

00:40:17.460 --> 00:40:20.260
There can be social penalties
associated with

00:40:20.260 --> 00:40:21.740
non-cooperation.

00:40:21.740 --> 00:40:24.750
You could face a decrease in
status or a decrease in

00:40:24.750 --> 00:40:26.340
reputation.

00:40:26.340 --> 00:40:30.150
Or, there could be personal
costs associated with

00:40:30.150 --> 00:40:31.690
non-cooperation.

00:40:31.690 --> 00:40:36.650
Decreases in freedom, or
decreases in your privileges.

00:40:36.650 --> 00:40:43.000
So these are the sorts of
penalties and rewards that can

00:40:43.000 --> 00:40:48.505
be imposed in such a way to
change the incentive structure

00:40:48.505 --> 00:40:51.590
of The Prisoners' Dilemma.

00:40:51.590 --> 00:40:56.080
But in addition to there being
different sorts of incentives

00:40:56.080 --> 00:40:59.580
and penalties, one of the things
that's important to

00:40:59.580 --> 00:41:02.712
recognize in thinking about this
question is that there

00:41:02.712 --> 00:41:07.560
can also be different sorts of
mechanisms of enforcement that

00:41:07.560 --> 00:41:09.700
are put into play.

00:41:09.700 --> 00:41:14.550
And this will ultimately bring
us to why it is that Hobbes

00:41:14.550 --> 00:41:18.370
thinks it's required that we
have the sort of external

00:41:18.370 --> 00:41:20.850
force that the government
provides.

00:41:20.850 --> 00:41:27.090
So we might on the one hand have
mechanisms of enforcement

00:41:27.090 --> 00:41:29.060
that are intrapersonal.

00:41:29.060 --> 00:41:32.280
We might create within ourselves
certain kinds of

00:41:32.280 --> 00:41:35.390
attitudes that cause us to

00:41:35.390 --> 00:41:38.460
cultivate cooperative behavior.

00:41:38.460 --> 00:41:46.290
Conscience is an instance of an
intrapersonal solution to

00:41:46.290 --> 00:41:50.950
coordination problems. You
internalize social norms, it

00:41:50.950 --> 00:41:54.660
becomes part of your
self-conception, and as a

00:41:54.660 --> 00:42:00.060
result, you behave in
pro-social ways.

00:42:00.060 --> 00:42:03.760
It could be in the context of
The Tragedy of the Commons.

00:42:03.760 --> 00:42:06.540
It could be in the context of
The Prisoners' Dilemma.

00:42:06.540 --> 00:42:11.600
It could be in the context of
your own cultivation of habits

00:42:11.600 --> 00:42:16.350
to overcome that intrapersonal,
cross-temporal

00:42:16.350 --> 00:42:20.420
prisoners' dilemma that we all
face with regard to the

00:42:20.420 --> 00:42:24.540
temptations of Angry Birds.

00:42:24.540 --> 00:42:29.670
It could be some sort of
informal, interpersonal,

00:42:29.670 --> 00:42:33.370
implicit or explicit schema.

00:42:33.370 --> 00:42:37.380
So, for example, you might
adopt a strategy of

00:42:37.380 --> 00:42:42.490
cooperating in the first round
of a prisoners' dilemma game,

00:42:42.490 --> 00:42:47.330
and then, following the lead
of whatever your co-player

00:42:47.330 --> 00:42:51.150
does, in subsequent rounds
of the game.

00:42:51.150 --> 00:42:53.960
That, as you know from your
reading, is called the

00:42:53.960 --> 00:42:55.940
tit-for-tat strategy.

00:42:55.940 --> 00:43:00.330
And a supplementary reading,
which I will post for you,

00:43:00.330 --> 00:43:03.530
given the sort of war theme
that has run through the

00:43:03.530 --> 00:43:08.430
course, is a wonderful piece
by Robert Axelrod about the

00:43:08.430 --> 00:43:13.030
evolution of a tit-for-tat
strategy in trench warfare

00:43:13.030 --> 00:43:15.190
during World War I.
And that will be

00:43:15.190 --> 00:43:16.500
up later this afternoon.

00:43:16.500 --> 00:43:21.830
So sometimes informal
cooperative strategies arise,

00:43:21.830 --> 00:43:25.850
and either implicitly or
explicitly people engage in

00:43:25.850 --> 00:43:29.690
relatively stable rounds
of cooperation.

00:43:29.690 --> 00:43:34.660
We can put into place formal,
interpersonal, formal

00:43:34.660 --> 00:43:38.200
impersonal, institutional
structures.

00:43:38.200 --> 00:43:43.460
Things like laws, and the
state, where there's in

00:43:43.460 --> 00:43:49.460
position a regulation from
an outside force.

00:43:49.460 --> 00:43:54.340
And we can finally put in
place various kinds of

00:43:54.340 --> 00:43:57.110
technological controls.

00:43:57.110 --> 00:44:01.360
Turning off the wireless
Internet on your computer.

00:44:01.360 --> 00:44:06.950
Setting up the missiles during
the Cold War so that they fire

00:44:06.950 --> 00:44:09.930
without human intervention
under certain situations.

00:44:09.930 --> 00:44:15.440
And those two can serve the
function of enforcement.

00:44:15.440 --> 00:44:21.470
So the ways of getting out of
The Prisoners' Dilemma, The

00:44:21.470 --> 00:44:25.300
Problem of the Commons,
are manifold.

00:44:25.300 --> 00:44:30.010
And they make use of virtually
all of the sorts of

00:44:30.010 --> 00:44:32.950
considerations that
we've looked at

00:44:32.950 --> 00:44:36.100
in class this semester.

00:44:36.100 --> 00:44:41.530
What I want to close with is
by letting you see how much

00:44:41.530 --> 00:44:46.740
more clearly thinking about
things in this way has, I

00:44:46.740 --> 00:44:51.660
hope, enabled you to understand
the final bit of

00:44:51.660 --> 00:44:55.700
Hobbes that we read for
Tuesday's class.

00:44:55.700 --> 00:44:57.830
So you'll recall I gave
you the first and

00:44:57.830 --> 00:44:59.370
second laws of nature.

00:44:59.370 --> 00:45:03.060
That the first law of nature
said, make peace where

00:45:03.060 --> 00:45:07.280
possible, reserve war
where necessary.

00:45:07.280 --> 00:45:10.130
And the second said, lay down
your rights exactly to the

00:45:10.130 --> 00:45:12.882
extent that others are willing
to lay down theirs.

00:45:12.882 --> 00:45:16.950
The third law of nature, says
Hobbes, is to perform your

00:45:16.950 --> 00:45:23.360
covenants, but he points out
that you will be unable to

00:45:23.360 --> 00:45:28.143
follow this law that
self-interest demands if you

00:45:28.143 --> 00:45:33.420
face the live possibility that
the other party will renege.

00:45:33.420 --> 00:45:37.070
Because if that happens you
will move from your second

00:45:37.070 --> 00:45:40.612
choice to your fourth choice.

00:45:40.612 --> 00:45:45.060
And no one wants to
end up there.

00:45:45.060 --> 00:45:50.530
So, says Hobbes, in order to
have covenants which will

00:45:50.530 --> 00:45:54.730
allow you to thrive and flourish
and gain the benefits

00:45:54.730 --> 00:45:59.730
of cooperation, there
must be some sort of

00:45:59.730 --> 00:46:02.880
enforcement in place.

00:46:02.880 --> 00:46:09.550
And what Hobbes suggests there
must be is a coercive power

00:46:09.550 --> 00:46:13.060
that compels men equally to
the performance of their

00:46:13.060 --> 00:46:18.630
covenants by the terror of some
punishment greater than

00:46:18.630 --> 00:46:23.020
the benefit they expect by the
breach of their covenants.

00:46:23.020 --> 00:46:26.990
That is, Hobbes is articulating
in the selections

00:46:26.990 --> 00:46:32.850
that we read from chapter 15
of Leviathan, one of the

00:46:32.850 --> 00:46:37.400
strategies, which by
mathematical analysis of the

00:46:37.400 --> 00:46:42.120
case, we realized would be
sufficient to move people from

00:46:42.120 --> 00:46:46.250
the three-three cell
to the two-two one.

00:46:46.250 --> 00:46:51.100
So what we'll look at next week
are two different kinds

00:46:51.100 --> 00:46:55.530
of justification for various
kinds of social structure.

00:46:55.530 --> 00:47:00.500
We'll look at John Rawls'
appeal to our notions of

00:47:00.500 --> 00:47:04.170
fairness, and Robert Nozick's
discussion of

00:47:04.170 --> 00:47:06.170
the notion of liberty.

00:47:06.170 --> 00:47:11.770
And the four of you to whom I
owe money are welcome to come

00:47:11.770 --> 00:47:14.830
up now to obtain it.

