WEBVTT
Kind: captions
Language: en

00:00:00.600 --> 00:00:05.240
PROFESSOR: OK, so what I want
to do today is to finish up

00:00:05.240 --> 00:00:09.040
the lecture that we were engaged
with last week about

00:00:09.040 --> 00:00:13.950
utilitarianism and then to move
on to what is perhaps the

00:00:13.950 --> 00:00:18.600
most dead-guy-on-Tuesday lecture
of the semester, that

00:00:18.600 --> 00:00:23.480
is, an explanation of the
philosophy of Immanuel Kant.

00:00:23.480 --> 00:00:27.000
So in order to make up for the
fact that the second part of

00:00:27.000 --> 00:00:30.470
the lecture is fairly dry, we'll
have a couple of clicker

00:00:30.470 --> 00:00:33.700
questions in the first
part of the lecture.

00:00:33.700 --> 00:00:41.230
OK, so as you recall from our
lecture last class, John

00:00:41.230 --> 00:00:45.080
Stuart Mill, in the selections
from Utilitarianism that we

00:00:45.080 --> 00:00:49.760
read, says two extraordinarily
famous things that serve in

00:00:49.760 --> 00:00:54.490
some ways as the heart of
the utilitarian view.

00:00:54.490 --> 00:00:57.580
The first thing that he says is
that he articulates what's

00:00:57.580 --> 00:01:00.530
known as the greatest
happiness principle.

00:01:00.530 --> 00:01:04.740
This is a principle that's
supposed to tell you what it

00:01:04.740 --> 00:01:09.140
is for an act to be
morally right.

00:01:09.140 --> 00:01:13.570
And what Mill says is, there's
a proportionality between the

00:01:13.570 --> 00:01:17.570
rightness of the act and
something that it produces.

00:01:17.570 --> 00:01:20.660
In particular, a proportionality
between the

00:01:20.660 --> 00:01:25.030
rightness of the act and the
amount of happiness it

00:01:25.030 --> 00:01:31.010
produces, regardless of how that
happiness is distributed.

00:01:31.010 --> 00:01:34.330
In particular he says "actions
are right in proportion as

00:01:34.330 --> 00:01:37.700
they tend to promote happiness,
they're wrong as

00:01:37.700 --> 00:01:41.470
they tend to promote the reverse
of happiness," and the

00:01:41.470 --> 00:01:44.360
happiness with which we're
concerned is not the agent's

00:01:44.360 --> 00:01:49.746
own happiness but "the happiness
of all concerned."

00:01:49.746 --> 00:01:53.080
The second extraordinarily
famous saying that he says in

00:01:53.080 --> 00:01:57.190
the opening passages of
Utilitarianism is that the

00:01:57.190 --> 00:02:02.160
motive with which an act is
performed is irrelevant to the

00:02:02.160 --> 00:02:03.650
act's moral worth.

00:02:03.650 --> 00:02:06.580
He says the motive has nothing
to do with the

00:02:06.580 --> 00:02:08.310
morality of the action.

00:02:08.310 --> 00:02:11.430
"He who saves another creature
from drowning does what is

00:02:11.430 --> 00:02:16.600
morally right, whether his
motive be duty or the hope of

00:02:16.600 --> 00:02:19.770
being paid for it."

00:02:19.770 --> 00:02:24.650
So we might summarize what
these principles say, as

00:02:24.650 --> 00:02:29.420
saying that the first one tells
us that what matters for

00:02:29.420 --> 00:02:36.990
the morality of an act is the
aggregate amount of happiness

00:02:36.990 --> 00:02:38.970
that it produces.

00:02:38.970 --> 00:02:43.940
And what we're concerned with
here are aggregates, not

00:02:43.940 --> 00:02:45.290
individuals.

00:02:45.290 --> 00:02:51.890
We're interested in how much
good is done overall, not

00:02:51.890 --> 00:02:57.120
where those pieces of good
might happen to fall.

00:02:57.120 --> 00:03:01.070
And what the second principle
tells us is that what the

00:03:01.070 --> 00:03:05.510
utilitarian, who is after all
a consequentialist, is

00:03:05.510 --> 00:03:09.370
concerned with are
consequences.

00:03:09.370 --> 00:03:15.250
They're interested in the
outcome of the act, not the

00:03:15.250 --> 00:03:22.300
process by which that outcome
was achieved.

00:03:22.300 --> 00:03:25.760
So the first reading that we
did for last class was a

00:03:25.760 --> 00:03:28.580
selection from Mill's
Utilitarianism where he

00:03:28.580 --> 00:03:30.870
articulated these principles.

00:03:30.870 --> 00:03:33.550
And it's important to recognize
that these get

00:03:33.550 --> 00:03:37.540
something profoundly right
about what we're thinking

00:03:37.540 --> 00:03:41.650
about, I think, when we try to
articulate what lies behind

00:03:41.650 --> 00:03:43.459
our moral judgment.

00:03:43.459 --> 00:03:47.420
It does seem right that what
we're interested in is what

00:03:47.420 --> 00:03:51.660
the world is like after a
particular action is taken,

00:03:51.660 --> 00:03:54.220
and to the extent that we're
interested in what the world

00:03:54.220 --> 00:03:58.480
is like, our primary interest
is not in how that state of

00:03:58.480 --> 00:04:04.180
affairs came about, but what
that state of affairs is.

00:04:04.180 --> 00:04:07.330
And our primary concern, if
we're taking a moral stance,

00:04:07.330 --> 00:04:11.710
is not in how much we ourselves
have, but rather in

00:04:11.710 --> 00:04:16.730
how much good there is
in the world overall.

00:04:16.730 --> 00:04:22.150
That said, there have been,
since utilitarianism was

00:04:22.150 --> 00:04:28.500
articulated, a classic set of
objections which are raised to

00:04:28.500 --> 00:04:33.300
the view, some of which we'll
talk more about today, and

00:04:33.300 --> 00:04:36.430
some of which we encountered in
the selection from Bernard

00:04:36.430 --> 00:04:40.220
Williams that we read
last class.

00:04:40.220 --> 00:04:46.340
Now you will all recall that
Williams' discussion begins

00:04:46.340 --> 00:04:54.500
with a story of a gentleman that
he calls Jim, who finds

00:04:54.500 --> 00:05:04.350
himself in a South American
village that's run by a rather

00:05:04.350 --> 00:05:07.520
unsavory cowboy.

00:05:07.520 --> 00:05:10.560
And some of the citizens of
that village have been

00:05:10.560 --> 00:05:14.740
protesting the unsavory
cowboy's leadership.

00:05:14.740 --> 00:05:17.960
And so what the unsavory cowboy
has done is he has

00:05:17.960 --> 00:05:22.440
rounded up twenty of those
villagers, and he's

00:05:22.440 --> 00:05:27.260
planning--simply to show the
others that he's in charge--to

00:05:27.260 --> 00:05:30.780
kill those twenty villagers.

00:05:30.780 --> 00:05:38.450
When Jim arrives, Pedro the
cowboy tells him that, if Jim

00:05:38.450 --> 00:05:44.170
is willing to shoot one of the
villagers, the other nineteen

00:05:44.170 --> 00:05:46.080
will be set free.

00:05:46.080 --> 00:05:48.010
So that's the Jim case.

00:05:48.010 --> 00:05:50.020
Jim shows up in a town.

00:05:50.020 --> 00:05:53.720
The sheriff of the town has
selected twenty people at

00:05:53.720 --> 00:05:58.400
random to be shot, but if Jim is
willing to kill one of them

00:05:58.400 --> 00:06:02.150
the other 19 will be
set free, so--

00:06:02.150 --> 00:06:03.400
clickers out--

00:06:05.875 --> 00:06:11.490
Question: In the Jim
case, what is Jim

00:06:11.490 --> 00:06:15.000
morally obliged to do?

00:06:15.000 --> 00:06:19.060
Is the moral thing for Jim to
do in this case to shoot the

00:06:19.060 --> 00:06:24.460
one man, thereby liberating the
other nineteen, or is the

00:06:24.460 --> 00:06:28.580
right thing for him to do to
refuse to shoot the one,

00:06:28.580 --> 00:06:31.470
thereby letting all
twenty die?

00:06:40.120 --> 00:06:43.440
OK, so let's see how the
numbers came out.

00:06:43.440 --> 00:06:49.720
So almost 3/4 of you, actually
more than 3/4 of you, think

00:06:49.720 --> 00:06:53.880
that what the morally right
thing for Jim to do in this

00:06:53.880 --> 00:06:57.680
case is to shoot one
man, thereby

00:06:57.680 --> 00:07:01.230
liberating the other nineteen.

00:07:01.230 --> 00:07:06.000
We'll have a chance next week
to talk a lot in about these

00:07:06.000 --> 00:07:07.140
sorts of questions.

00:07:07.140 --> 00:07:12.380
Our reading for Thursday is a
series of moral dilemmas with

00:07:12.380 --> 00:07:14.120
this structure.

00:07:14.120 --> 00:07:18.510
But what I want to ask those
77% of you, who answered

00:07:18.510 --> 00:07:23.780
"yes," to do now is to think
about whether you take what

00:07:23.780 --> 00:07:30.570
Williams says is the natural
utilitarian next step.

00:07:30.570 --> 00:07:34.960
Williams argues that if you are
a committed utilitarian,

00:07:34.960 --> 00:07:39.490
and you think that the morally
right thing for Jim to do is

00:07:39.490 --> 00:07:45.180
to shoot the one and release the
other nineteen, then you

00:07:45.180 --> 00:07:52.400
ought to feel no moral
compunction about doing so.

00:07:52.400 --> 00:07:55.520
There's a clear right
thing to do.

00:07:55.520 --> 00:07:58.710
The right thing is to
kill the one, so

00:07:58.710 --> 00:08:01.330
it's to save the nineteen.

00:08:01.330 --> 00:08:04.110
You may feel moral
disapprobation--indeed you

00:08:04.110 --> 00:08:07.620
should feel moral
disapprobation--towards Pedro

00:08:07.620 --> 00:08:11.740
who put Jim in this situation.

00:08:11.740 --> 00:08:15.930
But you ought to feel no moral
disapprobation towards Jim,

00:08:15.930 --> 00:08:20.910
and even more importantly
according to Williams, Jim

00:08:20.910 --> 00:08:26.690
himself ought to feel no
moral compunction.

00:08:26.690 --> 00:08:32.630
So among the 77% of you who
answered that Jim did the

00:08:32.630 --> 00:08:37.750
right thing in killing the one
and saving the nineteen, do

00:08:37.750 --> 00:08:42.810
you think that in shooting the
one man, Jim ought to think of

00:08:42.810 --> 00:08:47.610
any hesitation that he feels
as mere squeamishness,

00:08:47.610 --> 00:08:50.950
something that ought
to be overcome?

00:08:50.950 --> 00:08:55.080
Or do you think that Jim ought
to think of the hesitation

00:08:55.080 --> 00:08:59.560
that he feels in doing what the
utilitarian and in what

00:08:59.560 --> 00:09:03.350
you yourself said was the right
thing, do you think he

00:09:03.350 --> 00:09:06.620
ought to think of his hesitation
as being indicative

00:09:06.620 --> 00:09:09.170
of something morally relevant?

00:09:09.170 --> 00:09:11.100
So there's roughly seventy
of you who should

00:09:11.100 --> 00:09:12.350
be answering this.

00:09:14.860 --> 00:09:17.070
Let's see how the numbers
come out.

00:09:24.760 --> 00:09:31.380
OK, so most of you take
on only part of the

00:09:31.380 --> 00:09:34.890
consequentialist picture here,
at least in the way that

00:09:34.890 --> 00:09:36.870
Williams understands it.

00:09:36.870 --> 00:09:40.530
Most of you think that, although
the right thing for

00:09:40.530 --> 00:09:43.900
Jim to do in that case is to
kill the one to save the

00:09:43.900 --> 00:09:48.042
nineteen, it's not the case that
he ought wholeheartedly

00:09:48.042 --> 00:09:54.600
to endorse that as the
right thing to do.

00:09:54.600 --> 00:09:58.780
In a minute, I'm going to
present to you Williams'

00:09:58.780 --> 00:10:05.100
analogy to the case of residual
racism to try to help

00:10:05.100 --> 00:10:10.540
you see why someone who really
has taken on board the

00:10:10.540 --> 00:10:14.910
consequentialist outlook thinks
that the combination of

00:10:14.910 --> 00:10:17.720
views which most of you present,
where you think the

00:10:17.720 --> 00:10:20.470
right thing to do is to kill the
one to save the nineteen,

00:10:20.470 --> 00:10:23.650
but you also think the right
thing to do is to feel bad

00:10:23.650 --> 00:10:30.120
about that in some way, have not
fully appreciated what the

00:10:30.120 --> 00:10:33.230
utilitarian stance provides
you with as a way of

00:10:33.230 --> 00:10:35.640
understanding morality.

00:10:35.640 --> 00:10:38.680
So Williams, as you know,
presents us with two cases.

00:10:38.680 --> 00:10:40.800
The first is the case that I've
just given you, the case

00:10:40.800 --> 00:10:42.910
of Jim and the captive
Indians.

00:10:42.910 --> 00:10:50.020
The second is the case in high
'70's fashion of a man who is

00:10:50.020 --> 00:10:54.170
needing to go back to work
because it's difficult to have

00:10:54.170 --> 00:10:57.912
his wife working outside
of the home.

00:10:57.912 --> 00:11:00.560
I leave that to you
as a period piece.

00:11:00.560 --> 00:11:05.080
But the work which George is
provided in Williams' example

00:11:05.080 --> 00:11:09.330
is work in a bioweapons lab,
something to which George

00:11:09.330 --> 00:11:11.420
feels moral opposition.

00:11:11.420 --> 00:11:15.350
But if George doesn't take the
job in the bioweapons lab a

00:11:15.350 --> 00:11:18.750
much more gung-ho person,
somebody who's likely to

00:11:18.750 --> 00:11:22.030
advocate the use of bioweapons
in all sorts of contexts, will

00:11:22.030 --> 00:11:24.080
get the job instead.

00:11:24.080 --> 00:11:28.290
So the two cases that Williams
presents us with there have a

00:11:28.290 --> 00:11:30.090
common structure.

00:11:30.090 --> 00:11:32.430
And a common structure which
we're going to see again and

00:11:32.430 --> 00:11:35.590
again in moral dilemmas.

00:11:35.590 --> 00:11:40.310
There's one act that the person
can do that leads to a

00:11:40.310 --> 00:11:43.510
particular outcome, another
act that the person can do

00:11:43.510 --> 00:11:47.080
that leads to a different
outcome, where the first act

00:11:47.080 --> 00:11:51.080
is worse on its surface
than the second.

00:11:51.080 --> 00:11:56.570
So Jim has the possibility of
shooting one person, or

00:11:56.570 --> 00:11:58.520
shooting no people.

00:11:58.520 --> 00:12:00.740
Those are the choices
that Jim faces.

00:12:00.740 --> 00:12:05.100
If Jim does the first act,
shooting one person, then

00:12:05.100 --> 00:12:08.390
nineteen people will go free;
if Jim does the second act,

00:12:08.390 --> 00:12:11.350
which is not to shoot anybody
at all, to refuse Pedro's

00:12:11.350 --> 00:12:16.140
bargain, then all twenty
people will be shot.

00:12:16.140 --> 00:12:20.040
Likewise, George faces a choice
between doing one

00:12:20.040 --> 00:12:22.710
thing, taking the job in--

00:12:22.710 --> 00:12:29.560
sorry, George faces the choice
between taking the job in the

00:12:29.560 --> 00:12:33.750
bio lab and not taking the
job in the bio lab.

00:12:33.750 --> 00:12:37.160
If George takes the job in the
bio lab, then the gung-ho

00:12:37.160 --> 00:12:39.160
biological weapons fellow
won't [will]

00:12:39.160 --> 00:12:42.340
get the job, and the outcome
will be better [worse].

00:12:42.340 --> 00:12:45.060
If George doesn't take the
job, then the gung-ho

00:12:45.060 --> 00:12:48.150
biological weapons person won't
get the job and the

00:12:48.150 --> 00:12:50.540
outcome will be better.

00:12:50.540 --> 00:12:55.680
So, in both cases we have an
act killing the one versus

00:12:55.680 --> 00:12:59.770
killing none, taking the job
versus not taking the job,

00:12:59.770 --> 00:13:05.240
which is worse than another, but
the outcomes of those acts

00:13:05.240 --> 00:13:07.950
are inverted.

00:13:07.950 --> 00:13:13.710
The consequentialist tells us
not to look at the act side of

00:13:13.710 --> 00:13:15.540
the equation, but
to look at the

00:13:15.540 --> 00:13:17.912
outcome side of the equation.

00:13:17.912 --> 00:13:20.750
The only things, says the
consequentialist, that we need

00:13:20.750 --> 00:13:25.320
to take into consideration, is
how many people are saved or

00:13:25.320 --> 00:13:28.750
how much bio-weapons
research is done.

00:13:28.750 --> 00:13:31.410
According to the
consequentialist, what we do

00:13:31.410 --> 00:13:35.000
is we look and we see, outcome
one is better than outcome

00:13:35.000 --> 00:13:39.990
two, and then reading back from
that, we decide which

00:13:39.990 --> 00:13:41.610
thing we ought to do.

00:13:41.610 --> 00:13:45.010
We ought to do act one because
it's the thing that produces

00:13:45.010 --> 00:13:47.985
the better outcome.

00:13:47.985 --> 00:13:57.010
The deontologist or virtue
ethicist says, not so fast.

00:13:57.010 --> 00:14:02.445
Don't jump straight to the
consequence, look also at what

00:14:02.445 --> 00:14:07.190
it is that is needed to be
done by the individual to

00:14:07.190 --> 00:14:09.320
bring about that consequence.

00:14:09.320 --> 00:14:14.800
And recognizing that act one
is worse than act two, the

00:14:14.800 --> 00:14:18.670
deontologist or virtue ethicist
says, it's at least

00:14:18.670 --> 00:14:23.200
important to take seriously as
a possibility that the right

00:14:23.200 --> 00:14:28.690
thing to do in this situation is
the second act, even if the

00:14:28.690 --> 00:14:33.710
outcome that it leads
to is worse.

00:14:33.710 --> 00:14:40.610
Now what Williams points out is
that if one takes seriously

00:14:40.610 --> 00:14:44.980
the first of these stances,
the one where what we're

00:14:44.980 --> 00:14:50.390
looking at is the outcome and
not the process which gave

00:14:50.390 --> 00:14:57.740
rise to that outcome, then any
hesitation we feel towards

00:14:57.740 --> 00:15:01.100
bringing about that outcome as
the result of that particular

00:15:01.100 --> 00:15:07.210
act is due to what we might
call a certain kind of

00:15:07.210 --> 00:15:09.070
squeamishness.

00:15:09.070 --> 00:15:13.040
The utilitarian says, and we
started with the quotes from

00:15:13.040 --> 00:15:19.330
Mill for this reason, that
thinking about who does an act

00:15:19.330 --> 00:15:24.010
is morally irrelevant, just as
thinking about who gets the

00:15:24.010 --> 00:15:27.570
goods is morally irrelevant.

00:15:27.570 --> 00:15:31.220
What matters, says the greatest
happiness principle,

00:15:31.220 --> 00:15:37.730
is how much aggregate happiness
is produced; what

00:15:37.730 --> 00:15:41.560
matters not, except in so far
as it affects the amount of

00:15:41.560 --> 00:15:46.650
happiness, is who produces that
happiness or where that

00:15:46.650 --> 00:15:49.100
happiness goes.

00:15:49.100 --> 00:15:52.840
So there is room on the
consequentialist picture for

00:15:52.840 --> 00:15:55.540
second-order thinking about the

00:15:55.540 --> 00:15:57.160
distributions of happiness.

00:15:57.160 --> 00:16:00.700
If gross inequities in the
amount of happiness across a

00:16:00.700 --> 00:16:05.700
society produces itself less
happiness, then we can take

00:16:05.700 --> 00:16:09.280
that into consideration
in our calculus.

00:16:09.280 --> 00:16:12.840
If performing a particular kind
of act produces in an

00:16:12.840 --> 00:16:16.190
individual less happiness,
we can take that into

00:16:16.190 --> 00:16:18.880
consideration in our calculus.

00:16:18.880 --> 00:16:22.910
But ultimately the only things
that go into the equation in

00:16:22.910 --> 00:16:27.210
determining whether an act is
morally right is the amount of

00:16:27.210 --> 00:16:33.010
happiness and not where that
happiness is distributed.

00:16:33.010 --> 00:16:39.069
Now, as Epictetus pointed out,
some things are up to us and

00:16:39.069 --> 00:16:42.640
some things are not up to us.

00:16:42.640 --> 00:16:48.369
And when Jim arrives in Pedro's
village, one of the

00:16:48.369 --> 00:16:54.380
things that is not up to him
is the fact that he faces a

00:16:54.380 --> 00:16:58.670
forced choice of the structure
that Pedro has

00:16:58.670 --> 00:17:01.040
presented him with.

00:17:01.040 --> 00:17:04.320
It goes without saying that
what Pedro has done is

00:17:04.320 --> 00:17:08.540
outrageous, but the structure
of the situation that Jim

00:17:08.540 --> 00:17:10.840
confronts is a very
simple one.

00:17:10.840 --> 00:17:17.250
Either Pedro will kill twenty
people or Jim will kill one

00:17:17.250 --> 00:17:21.160
person and the other nineteen
will not die.

00:17:21.160 --> 00:17:26.460
That's what's there for
Jim to be deciding on.

00:17:26.460 --> 00:17:32.950
Nonetheless, 75% of the 75% of
you who thought that Jim did

00:17:32.950 --> 00:17:37.130
the right thing in that
situation think that Jim ought

00:17:37.130 --> 00:17:43.600
to feel some squeamishness about
carrying out that act.

00:17:43.600 --> 00:17:47.250
What Williams points out is that
if one takes seriously

00:17:47.250 --> 00:17:52.330
the consequentialist picture,
then perhaps the morally right

00:17:52.330 --> 00:17:58.390
thing to do is to try to
cultivate in oneself moral

00:17:58.390 --> 00:18:04.670
sentiments that accord with
one's moral judgments.

00:18:04.670 --> 00:18:11.950
If through rational
argumentation and reflection

00:18:11.950 --> 00:18:16.000
you come to realize of yourself
that--although you

00:18:16.000 --> 00:18:19.410
are committed to racial
equality, although you are

00:18:19.410 --> 00:18:23.720
committed to gender equality,
although you are committed to

00:18:23.720 --> 00:18:27.530
equality regardless of gender
identification, you're

00:18:27.530 --> 00:18:31.780
committed to not being ageist,
you're committed to not being

00:18:31.780 --> 00:18:36.385
discriminatory on the basis of
physical disability--you

00:18:36.385 --> 00:18:39.810
might, as a result of having
lived in a society largely

00:18:39.810 --> 00:18:46.040
structured in ways that encode
a kind of residual racism and

00:18:46.040 --> 00:18:50.250
sexism and homophobia, you might
find in yourself certain

00:18:50.250 --> 00:18:56.530
sentiments that lead you
instantaneously to respond in

00:18:56.530 --> 00:19:00.050
ways that run contrary to what
your moral commitments tell

00:19:00.050 --> 00:19:02.770
you you ought to do.

00:19:02.770 --> 00:19:08.040
In those cases, I take it you
think that there's some moral

00:19:08.040 --> 00:19:12.040
mandate upon you to
try to get rid of

00:19:12.040 --> 00:19:14.780
those instinctive responses.

00:19:14.780 --> 00:19:20.220
If you're really committed to
anti-racism, then you want to

00:19:20.220 --> 00:19:24.330
the extent possible to have a
harmonious soul when engaging

00:19:24.330 --> 00:19:26.610
in interracial encounters.

00:19:26.610 --> 00:19:29.590
If your reason tells you that
you're committed to

00:19:29.590 --> 00:19:33.600
anti-racism, you want your
spirit and appetite to be in

00:19:33.600 --> 00:19:36.780
line in that way.

00:19:36.780 --> 00:19:41.880
So there are instances where
morality on reflection tells

00:19:41.880 --> 00:19:46.020
us that something is right, and
the consequence of that

00:19:46.020 --> 00:19:49.520
for our behavior towards
ourselves is that we ought to

00:19:49.520 --> 00:19:53.040
try to cultivate in ourselves
instincts that

00:19:53.040 --> 00:19:55.380
correspond to that.

00:19:55.380 --> 00:20:03.390
Williams says the utilitarian
should say that in cases like

00:20:03.390 --> 00:20:11.640
the Jim case, Jim is like the
residual racist. He knows what

00:20:11.640 --> 00:20:20.210
the right thing to do is, but he
has a residual tendency to

00:20:20.210 --> 00:20:25.380
be pulled in the morally
wrong direction.

00:20:25.380 --> 00:20:29.840
If you don't think that it's
true that Jim ought to change

00:20:29.840 --> 00:20:35.060
his attitudes in that case,
and you do think that the

00:20:35.060 --> 00:20:40.800
residual implicit racist ought
to try to change her attitude,

00:20:40.800 --> 00:20:44.970
it would be useful to try to
think about what holds those

00:20:44.970 --> 00:20:48.210
two cases apart.

00:20:48.210 --> 00:20:53.730
OK, so that's what I want to
say in closing about the

00:20:53.730 --> 00:20:56.590
utilitarianism and
it's critics.

00:20:56.590 --> 00:21:01.260
And we'll return as I said to
those issues twice more, once

00:21:01.260 --> 00:21:04.300
on Thursday when we read Judy
Thomson's trolley problem

00:21:04.300 --> 00:21:08.390
paper and once next Tuesday when
we look at some empirical

00:21:08.390 --> 00:21:12.880
work on that question, which
suggests a naturalistic

00:21:12.880 --> 00:21:15.620
explanation for why it
is that Jim feels the

00:21:15.620 --> 00:21:17.960
hesitation that he does.

00:21:17.960 --> 00:21:22.890
What I want to do now is to
introduce you to the third of

00:21:22.890 --> 00:21:26.100
all the main moral outlooks that
we're going to consider

00:21:26.100 --> 00:21:27.550
this semester.

00:21:27.550 --> 00:21:31.880
So last lecture we looked very
carefully at consequentialist

00:21:31.880 --> 00:21:35.440
moral theories in the form of
John Stuart Mill, and those

00:21:35.440 --> 00:21:39.150
are theories which locate the
moral value of an act in its

00:21:39.150 --> 00:21:41.060
consequences.

00:21:41.060 --> 00:21:46.230
In the first part of the class
we spent a lot of time looking

00:21:46.230 --> 00:21:51.450
at Aristotle's virtue theory,
which located the moral worth

00:21:51.450 --> 00:21:54.740
of an act in the actor.

00:21:54.740 --> 00:21:58.030
Remember we looked at acts
having more worth only if

00:21:58.030 --> 00:22:01.000
they're done as the result
of a sort of

00:22:01.000 --> 00:22:04.390
constancy of character.

00:22:04.390 --> 00:22:09.570
What we're going to look at
today is the third piece of

00:22:09.570 --> 00:22:15.220
this story, of a moral view
that says the morality

00:22:15.220 --> 00:22:20.300
attached to an action is not the
result of what the actor

00:22:20.300 --> 00:22:23.020
is like, it's not the result of
what the consequences are

00:22:23.020 --> 00:22:28.160
like, rather it is about
the act itself.

00:22:28.160 --> 00:22:30.600
In particular, we're going to
look at the deontological

00:22:30.600 --> 00:22:34.080
theory of Immanuel Kant.

00:22:34.080 --> 00:22:42.130
So, Immanuel Kant was an 18th
century German philosopher

00:22:42.130 --> 00:22:46.820
who, like Plato and Aristotle,
provided a comprehensive and

00:22:46.820 --> 00:22:51.740
systematic philosophical theory
that to this day is

00:22:51.740 --> 00:22:57.710
taken seriously as one of the
ways one might make sense of

00:22:57.710 --> 00:23:00.010
the world as a whole.

00:23:00.010 --> 00:23:03.210
Kant has theories of
metaphysics, that is, what

00:23:03.210 --> 00:23:05.000
kind of stuff there is.

00:23:05.000 --> 00:23:07.850
He has theories of epistemology,
that is, how we

00:23:07.850 --> 00:23:10.200
know about what kind
of stuff there is.

00:23:10.200 --> 00:23:13.900
He has theories of ethics, what
the right thing to do is.

00:23:13.900 --> 00:23:16.630
And he has theories of
aesthetics, that is, what

00:23:16.630 --> 00:23:20.380
gives things aesthetic value.

00:23:20.380 --> 00:23:24.350
Famously, Kant articulated his
views about the three major

00:23:24.350 --> 00:23:30.650
domains of philosophy three
enormous and dense books: the

00:23:30.650 --> 00:23:35.140
first, The Critique of Pure
Reason, which told you about

00:23:35.140 --> 00:23:39.250
what the world is like and how
we know it to be that way,

00:23:39.250 --> 00:23:43.980
which he wrote first in 1781 and
then revised; the second,

00:23:43.980 --> 00:23:46.510
The Critique of Practical
Reason, which is an account of

00:23:46.510 --> 00:23:50.440
the nature of morality; and
the third, The Critique of

00:23:50.440 --> 00:23:53.280
Judgment, which is an account
of the nature

00:23:53.280 --> 00:23:56.350
of aesthetic value.

00:23:56.350 --> 00:24:03.700
But in addition to those dense
works Kant also wrote what he

00:24:03.700 --> 00:24:10.470
took to be more popular
presentations of his view.

00:24:10.470 --> 00:24:13.395
In the case of metaphysics,
he wrote a book called The

00:24:13.395 --> 00:24:17.110
Prolegomena to any Future
Metaphysics.

00:24:17.110 --> 00:24:19.820
And in the case of ethics, he
wrote something that he calls

00:24:19.820 --> 00:24:23.440
the Grounding for the
Metaphysics of Morals, which

00:24:23.440 --> 00:24:26.000
is of course the work
from which we read

00:24:26.000 --> 00:24:29.440
excerpts for today.

00:24:29.440 --> 00:24:33.620
So I give you this context
because I want you to know

00:24:33.620 --> 00:24:38.460
that, as hard as the reading
that we did from Kant was, I

00:24:38.460 --> 00:24:43.430
chose for you perhaps the
easiest part of the easiest

00:24:43.430 --> 00:24:45.110
book that he wrote.

00:24:47.670 --> 00:24:53.460
So, what should you take home
from Kant if you take home

00:24:53.460 --> 00:24:55.790
nothing else?

00:24:55.790 --> 00:25:00.430
If you take home nothing else
from our reading of Kant, I

00:25:00.430 --> 00:25:04.580
want you to take home Kant's
idea of the categorical

00:25:04.580 --> 00:25:05.880
imperative.

00:25:05.880 --> 00:25:10.870
And my goal in the remainder of
lecture today is to bring

00:25:10.870 --> 00:25:16.340
you, by reading through with you
the text of Kant that we

00:25:16.340 --> 00:25:20.770
had today, to a point where you
will be well positioned to

00:25:20.770 --> 00:25:26.615
understand what Kant means by
the categorical imperative.

00:25:26.615 --> 00:25:29.990
And depending on how the next
twenty minutes go, we'll get

00:25:29.990 --> 00:25:33.610
to that either right at the
end of today's lecture or

00:25:33.610 --> 00:25:35.630
right at the beginning
of Thursday's.

00:25:39.150 --> 00:25:43.470
OK, so Kant's text, the
Grounding for the Metaphysics

00:25:43.470 --> 00:25:48.540
of Morals begins with a very
famous passage where Kant

00:25:48.540 --> 00:25:53.330
says, "nothing can be regarded
as good without qualification

00:25:53.330 --> 00:25:59.510
except the good will." This
claim should be familiar to

00:25:59.510 --> 00:26:05.460
you, O readers of Book II
of Plato's The Republic.

00:26:05.460 --> 00:26:09.930
This is the classic distinction
between things

00:26:09.930 --> 00:26:15.470
that have intrinsic value and
things that are merely of

00:26:15.470 --> 00:26:18.110
instrumental worth.

00:26:18.110 --> 00:26:24.790
And indeed much in the way that
Plato's Socrates does,

00:26:24.790 --> 00:26:30.870
Kant goes on to enumerate some
things which fall into the

00:26:30.870 --> 00:26:34.260
other category, the category
of things that are of mere

00:26:34.260 --> 00:26:36.590
instrumental utility.

00:26:36.590 --> 00:26:40.430
Among the things that cannot
be regarded as good without

00:26:40.430 --> 00:26:45.350
qualification, says Kant, are
talents of the mind like

00:26:45.350 --> 00:26:49.100
intelligence and wit, qualities
of temperament like

00:26:49.100 --> 00:26:54.040
courage and perseverance, gifts
of fortune like power

00:26:54.040 --> 00:26:57.170
and riches and honor
and health.

00:26:57.170 --> 00:27:02.590
And he says, taking a direct
gibe at Aristotle, and noting

00:27:02.590 --> 00:27:06.960
as such that he's so doing,
neither can the ancient

00:27:06.960 --> 00:27:12.290
virtues--(oh, my goodness,
how do I close that

00:27:12.290 --> 00:27:22.240
email?)--neither can the ancient
virtues of moderation

00:27:22.240 --> 00:27:26.880
and self control be considered
as good in themselves.

00:27:26.880 --> 00:27:28.380
Why?

00:27:28.380 --> 00:27:32.140
Because though being
intelligent, or brave, or

00:27:32.140 --> 00:27:37.540
rich, or controlled, will help
you to achieve the goals that

00:27:37.540 --> 00:27:44.350
you have, they don't determine
what those goals might be.

00:27:44.350 --> 00:27:47.600
They magnify your effectiveness
as an agent, but

00:27:47.600 --> 00:27:50.190
they don't determine
the valence, the

00:27:50.190 --> 00:27:52.930
value of your agency.

00:27:52.930 --> 00:28:00.110
So, says Kant, a witty,
persevering, rich, healthy,

00:28:00.110 --> 00:28:06.160
moderate thief will be an
outstanding thief--but that

00:28:06.160 --> 00:28:10.570
doesn't make his
thiefdom good.

00:28:10.570 --> 00:28:14.920
Each of the virtues that has
traditionally been extolled as

00:28:14.920 --> 00:28:21.660
a virtue, says Kant, gains its
value only in so far as the

00:28:21.660 --> 00:28:25.650
good will is part of it.

00:28:25.650 --> 00:28:30.710
Now a good will, says Kant, is
good not because of what it

00:28:30.710 --> 00:28:36.990
affects or accomplishes,
it's good in itself.

00:28:36.990 --> 00:28:42.355
When I say that Kant is a critic
of consequentialism I

00:28:42.355 --> 00:28:45.480
am not exaggerating.

00:28:45.480 --> 00:28:50.063
Kant doesn't think that
the outcome of

00:28:50.063 --> 00:28:53.400
the act is what matters.

00:28:53.400 --> 00:28:58.770
And in an extraordinarily famous
passage, famous in part

00:28:58.770 --> 00:29:02.520
because of the rather shocking
translation which has come

00:29:02.520 --> 00:29:08.410
down to us of it, Kant says,
"the good will would remain

00:29:08.410 --> 00:29:14.920
good, even if by the niggardly
provision of step-motherly

00:29:14.920 --> 00:29:21.110
nature it wholly lacked the
power to accomplish its

00:29:21.110 --> 00:29:27.543
purpose." By which he means,
even if you with your good

00:29:27.543 --> 00:29:33.135
will were frustrated in all of
the goals that you set out to

00:29:33.135 --> 00:29:37.500
achieve, your actions would
still have moral worth.

00:29:37.500 --> 00:29:45.400
And somewhat more poetically and
a bit less vocabulary that

00:29:45.400 --> 00:29:49.150
is challenging to the modern
ear, Kant says, even if it

00:29:49.150 --> 00:29:53.740
didn't achieve its outcome "it
would like a jewel still shine

00:29:53.740 --> 00:29:56.250
by its own light as something
which has

00:29:56.250 --> 00:29:58.010
full value in itself.

00:29:58.010 --> 00:30:01.050
Its usefulness or fruitlessness
can neither

00:30:01.050 --> 00:30:04.492
augment nor its value."

00:30:04.492 --> 00:30:07.980
Now the question is this:
How could anybody come

00:30:07.980 --> 00:30:08.840
to have this view?

00:30:08.840 --> 00:30:12.720
How could anybody have a view
of morality that says, what

00:30:12.720 --> 00:30:16.620
matters for an act to be moral
is not the outcome that it

00:30:16.620 --> 00:30:21.150
produces, but rather the
description under which the

00:30:21.150 --> 00:30:22.990
act is done?

00:30:22.990 --> 00:30:26.680
What I want to try to do right
now is to put you inside the

00:30:26.680 --> 00:30:31.050
Kantian picture so that you
get a sense of what that

00:30:31.050 --> 00:30:33.050
worldview looks like.

00:30:33.050 --> 00:30:37.690
So in the passages that we read
for today, Kant makes

00:30:37.690 --> 00:30:42.780
three particular claims. He says
that an action must be

00:30:42.780 --> 00:30:49.130
done from duty in order
to have moral worth.

00:30:49.130 --> 00:30:51.940
The first notion that I want to
try to explicate for you is

00:30:51.940 --> 00:30:53.340
the Kantian notion of something

00:30:53.340 --> 00:30:57.500
being done from duty.

00:30:57.500 --> 00:31:01.220
An action done from duty,
says Kant in his second

00:31:01.220 --> 00:31:05.770
proposition, has its moral worth
not in the purpose that

00:31:05.770 --> 00:31:10.460
is to be attained by it, but
in the maxim according to

00:31:10.460 --> 00:31:14.230
which the action
is determined.

00:31:14.230 --> 00:31:18.580
So the way that an action done
from duty has more worth is

00:31:18.580 --> 00:31:23.500
not by looking to see what
outcome you're expecting from

00:31:23.500 --> 00:31:28.620
it, but rather by looking
to see under what

00:31:28.620 --> 00:31:32.830
characterization did you
perform the act.

00:31:32.830 --> 00:31:36.930
And again, I'll spell out what
each of those terms mean.

00:31:36.930 --> 00:31:41.550
Finally, says Kant, duty, which
lies at the heart of

00:31:41.550 --> 00:31:47.870
deontological moral theory,
"duty is the necessity of an

00:31:47.870 --> 00:31:55.600
action done out of the respect
for the law." Kant believes

00:31:55.600 --> 00:32:02.180
that it is only when you subject
your will to a law

00:32:02.180 --> 00:32:06.530
which you have made for
yourself--that is, the moral

00:32:06.530 --> 00:32:11.750
law whose binding force upon you
you have recognized--it is

00:32:11.750 --> 00:32:17.710
only in that circumstance
that you are truly free.

00:32:17.710 --> 00:32:21.490
So Kant says, "duty is the
necessity of an action done

00:32:21.490 --> 00:32:25.550
out of the respect for the law,"
and when you perform an

00:32:25.550 --> 00:32:31.075
action out of respect for the
moral law, says Kant, then and

00:32:31.075 --> 00:32:34.380
only then do you act
autonomously.

00:32:34.380 --> 00:32:37.900
OK, so three, incredibly
complicated,

00:32:37.900 --> 00:32:40.510
subtle claims from Kant.

00:32:40.510 --> 00:32:45.450
Let's try getting to the bottom
of what they mean.

00:32:45.450 --> 00:32:49.080
So let's start with the first
claim, the claim that an act

00:32:49.080 --> 00:32:55.972
has moral worth only when
it is done from duty.

00:32:55.972 --> 00:32:58.060
So Kant points out that
there's three kinds of

00:32:58.060 --> 00:33:01.800
motivation that we might have
in performing an act.

00:33:01.800 --> 00:33:05.190
We might do an act out of duty,
we might do it out of

00:33:05.190 --> 00:33:11.030
inclination, or we might do it
out of self-interest. Only

00:33:11.030 --> 00:33:16.350
cases of the first kind, in fact
only pure cases of the

00:33:16.350 --> 00:33:22.020
first kind, have moral worth.

00:33:22.020 --> 00:33:26.290
Actions that are done merely in
keeping with, but not from

00:33:26.290 --> 00:33:33.140
moral duty, have no moral
worth according to Kant.

00:33:33.140 --> 00:33:39.120
So if you obey the law but you
do so only out of self

00:33:39.120 --> 00:33:45.679
interest, your obedience, says
Kant, has no moral worth.

00:33:45.679 --> 00:33:50.409
if you rescue the drowning child
from the pond but you do

00:33:50.409 --> 00:33:53.900
so only because there's a sign
on the tree that says, "Rescue

00:33:53.900 --> 00:33:58.159
Drowning Children: $1 Million
Reward," your act

00:33:58.159 --> 00:34:01.620
has no moral worth.

00:34:01.620 --> 00:34:05.659
So we can think about what
Kant's claim amounts to and

00:34:05.659 --> 00:34:08.870
how it differs from the other
ones that we've been looking

00:34:08.870 --> 00:34:12.860
at by thinking of the
question space in

00:34:12.860 --> 00:34:15.880
terms of a flow chart.

00:34:15.880 --> 00:34:18.760
So we're trying to decide
whether a particular action

00:34:18.760 --> 00:34:23.210
has moral worth, and the first
thing we want to ask ourselves

00:34:23.210 --> 00:34:27.070
is: "Does the action
accord with duty?

00:34:27.070 --> 00:34:29.660
If the answer to that is no,
that is, if you've done

00:34:29.660 --> 00:34:34.110
something like lied, or stolen
something, or murdered

00:34:34.110 --> 00:34:38.430
somebody, or allowed something
terrible to happen in front of

00:34:38.430 --> 00:34:40.330
you that you could have
easily, at no cost to

00:34:40.330 --> 00:34:45.470
yourself, prevented, all of the
authors that we've read,

00:34:45.470 --> 00:34:50.580
not surprisingly, say that the
act has no moral worth--

00:34:50.580 --> 00:34:53.230
Oh so, did that just disappear
that was supposed to

00:34:53.230 --> 00:34:54.765
be in red on black?

00:34:54.765 --> 00:34:57.880
Is it completely invisible
from the back?

00:34:57.880 --> 00:34:59.120
Oh, that's a pity--

00:34:59.120 --> 00:35:05.920
OK, so what that says in red
is no lying and stealing--

00:35:05.920 --> 00:35:08.100
but it's in red.

00:35:08.100 --> 00:35:11.520
I can't change it in the middle
of the slides, but I'll

00:35:11.520 --> 00:35:13.590
remind you what those
things say.

00:35:13.590 --> 00:35:14.100
OK--

00:35:14.100 --> 00:35:19.030
The second question that we
ask, having eliminated now

00:35:19.030 --> 00:35:23.260
from the realm of morally worthy
acts those that don't

00:35:23.260 --> 00:35:29.480
accord with duty, is: What
motive the act was done with?

00:35:29.480 --> 00:35:33.530
So perhaps you act in a morally
worthy way out of

00:35:33.530 --> 00:35:36.500
self-interest without immediate
inclinations.

00:35:36.500 --> 00:35:40.170
So you pay your taxes because
if you don't pay your taxes

00:35:40.170 --> 00:35:42.750
you're going to have
to pay more taxes.

00:35:42.750 --> 00:35:45.740
You obey the speed limit but
only because you were afraid

00:35:45.740 --> 00:35:48.280
you might get caught
otherwise.

00:35:48.280 --> 00:35:53.780
Mill says those acts
have moral worth.

00:35:53.780 --> 00:35:58.330
Kant says no, they don't--

00:35:58.330 --> 00:36:01.190
And again, that's supposed
to be in red but it's now

00:36:01.190 --> 00:36:03.210
invisible--

00:36:03.210 --> 00:36:08.240
Suppose that you do an act in
such a way that you have an

00:36:08.240 --> 00:36:10.840
inclination that's in
keeping with duty.

00:36:10.840 --> 00:36:13.830
So Kant thinks you have a duty
not to commit suicide, and he

00:36:13.830 --> 00:36:17.130
considers a case where you fail
to commit suicide because

00:36:17.130 --> 00:36:18.480
you're happy.

00:36:18.480 --> 00:36:22.420
Kant thinks you need to be loyal
to your life partner,

00:36:22.420 --> 00:36:25.030
but he says that there's no
moral worth to remaining loyal

00:36:25.030 --> 00:36:29.040
to your life partner while
you are in love.

00:36:29.040 --> 00:36:32.530
There's no moral worth, says
Kant, to acting kindly towards

00:36:32.530 --> 00:36:37.750
somebody when you feel sympathy
towards them.

00:36:37.750 --> 00:36:43.930
Because in those cases, though
your act is in keeping with

00:36:43.930 --> 00:36:49.640
what morality demands, it's
not done because it is the

00:36:49.640 --> 00:36:51.690
right thing to do.

00:36:51.690 --> 00:36:57.680
You are doing it because your
inclination happens to line up

00:36:57.680 --> 00:37:01.581
with what morality
demands of you.

00:37:01.581 --> 00:37:07.810
Now Aristotle, of course, took
this situation to be the one

00:37:07.810 --> 00:37:13.460
in which moral worth is
paradigmatically expressed.

00:37:13.460 --> 00:37:20.900
But Kant thinks in such cases
you can not tell that an act

00:37:20.900 --> 00:37:24.450
was done from the moral law.

00:37:24.450 --> 00:37:27.850
All you can see is that it was
done in keeping with the moral

00:37:27.850 --> 00:37:32.640
law, it corresponds to what the
moral law demands, but we

00:37:32.640 --> 00:37:38.340
can't see from that that
the motive was duty.

00:37:38.340 --> 00:37:44.050
It's only in the third case,
the case where you act from

00:37:44.050 --> 00:37:49.280
duty without any inclination and
without any self-interest,

00:37:49.280 --> 00:37:51.990
that Kant thinks the
moral worth of an

00:37:51.990 --> 00:37:55.510
action can be seen.

00:37:55.510 --> 00:37:59.610
If you preserve your life when
you feel the inclination to do

00:37:59.610 --> 00:38:04.090
otherwise, if you act kindly in
situations where there's no

00:38:04.090 --> 00:38:09.520
reward for you and you feel no
sympathy, in those cases, says

00:38:09.520 --> 00:38:14.530
Kant, we can see that the act
was done, not merely in

00:38:14.530 --> 00:38:20.270
keeping with, but from
the moral law.

00:38:20.270 --> 00:38:24.320
This isn't to say that Kant
doesn't think a life lived in

00:38:24.320 --> 00:38:28.230
the way that Aristotle suggested
life is lived is a

00:38:28.230 --> 00:38:28.730
badly [well]

00:38:28.730 --> 00:38:30.300
lived life.

00:38:30.300 --> 00:38:34.050
Cases where your inclination
happens to line up with duty

00:38:34.050 --> 00:38:39.470
hopefully keep you out of this
box of doing the wrong thing,

00:38:39.470 --> 00:38:45.130
but they don't allow you to test
your character and see of

00:38:45.130 --> 00:38:49.120
yourself that the motivation
that you have for doing the

00:38:49.120 --> 00:38:53.190
right thing is to conform
to what the moral

00:38:53.190 --> 00:38:56.660
law demands of you.

00:38:56.660 --> 00:39:01.110
So with that understanding of
what it is to act from duty in

00:39:01.110 --> 00:39:06.440
mind, we're now in a position to
make sense of Kant's second

00:39:06.440 --> 00:39:09.660
claim in our reading
for today.

00:39:09.660 --> 00:39:14.810
Then "an action done from duty
has its moral worth not in the

00:39:14.810 --> 00:39:18.560
purpose that's to be obtained
by it, but in the maxim

00:39:18.560 --> 00:39:23.120
according to which the action
is determined." So remember

00:39:23.120 --> 00:39:26.720
we've learned that an action
done from duty is one that you

00:39:26.720 --> 00:39:33.680
do in conformity with what
morality demands, because that

00:39:33.680 --> 00:39:37.340
is what morality demands.

00:39:37.340 --> 00:39:41.940
Not because it's in your self
interest, not because you were

00:39:41.940 --> 00:39:47.490
inclined to behave in that way,
but because that act is

00:39:47.490 --> 00:39:51.250
what morality demands of you.

00:39:51.250 --> 00:39:53.930
But in order to determine
whether an act is what

00:39:53.930 --> 00:39:59.230
morality demands of you, that
act needs to be described in a

00:39:59.230 --> 00:40:02.140
particular way to you.

00:40:02.140 --> 00:40:06.980
And the way that you describe
that act to yourself makes use

00:40:06.980 --> 00:40:13.015
of what Kant calls a maxim,
a subjective principle of

00:40:13.015 --> 00:40:16.810
volition--that is, a description
of something that

00:40:16.810 --> 00:40:23.910
is about you, the subject,
that's says what your desires

00:40:23.910 --> 00:40:26.980
towards behavior are
in that situation.

00:40:26.980 --> 00:40:29.390
A subjective principle of
volition, that is, a

00:40:29.390 --> 00:40:33.060
description under which
the act is done.

00:40:33.060 --> 00:40:39.030
So it takes the form, perhaps:
"In all engagings with all who

00:40:39.030 --> 00:40:45.970
come into my shop, I will
provide them with an honest

00:40:45.970 --> 00:40:51.690
accounting of how much their
transaction is worth,

00:40:51.690 --> 00:40:55.370
regardless of whether I could
be discovered cheating in

00:40:55.370 --> 00:41:00.910
this." Or: "In all of my
encounters with those who are

00:41:00.910 --> 00:41:05.420
weak and in need of my help, I
will provide them with the aid

00:41:05.420 --> 00:41:08.900
that I can regardless of whether
that would be of

00:41:08.900 --> 00:41:11.620
benefit to me."

00:41:11.620 --> 00:41:17.350
"Only by considering the motive
and not by considering

00:41:17.350 --> 00:41:23.590
the outcome can the action be
expressive of the good will

00:41:23.590 --> 00:41:29.470
itself." "The good will is the
only thing that is good in

00:41:29.470 --> 00:41:34.820
itself," says Kant, and it's
only by looking at the

00:41:34.820 --> 00:41:41.290
description under which an act
is done that we can determine

00:41:41.290 --> 00:41:46.680
whether the good will was
implicated in the right way in

00:41:46.680 --> 00:41:51.510
the choice to perform
that action.

00:41:51.510 --> 00:41:57.670
Third claim: "Duty is the
necessity of an action done

00:41:57.670 --> 00:42:01.810
out of the respect for the law."
So we know that an act

00:42:01.810 --> 00:42:05.460
has moral worth only if
it's done from duty.

00:42:05.460 --> 00:42:08.800
We know that in order to be done
from duty it needs to be

00:42:08.800 --> 00:42:12.580
done under a certain
description.

00:42:12.580 --> 00:42:18.430
And now we're told what it is
that this duty amounts to.

00:42:18.430 --> 00:42:23.050
In order for an act to be done
from duty, says Kant, it must

00:42:23.050 --> 00:42:29.010
have been done with explicit
recognition that what one is

00:42:29.010 --> 00:42:33.530
doing at that point is
respecting the moral law in so

00:42:33.530 --> 00:42:39.420
far as it articulates what
morality demands of you.

00:42:39.420 --> 00:42:42.190
Not in so far that it
articulates ways that you

00:42:42.190 --> 00:42:47.340
might have a well-ordered,
harmonious, happy soul.

00:42:47.340 --> 00:42:50.850
Not in so far that it
articulates ways in which lots

00:42:50.850 --> 00:42:55.785
of happiness could be spread
around to lots of people.

00:42:55.785 --> 00:43:00.730
Out of respect rather, says
Kant, for the fact that it is

00:43:00.730 --> 00:43:04.810
what morality demands of you.

00:43:04.810 --> 00:43:11.120
The moral worth of an act, says
Kant, does not lie in its

00:43:11.120 --> 00:43:15.040
effect, for the effect
could have come

00:43:15.040 --> 00:43:17.940
about in multiple ways.

00:43:17.940 --> 00:43:23.540
I can set out to release a
biological gas in a subway

00:43:23.540 --> 00:43:26.840
that's intended to kill
thousands of people, and

00:43:26.840 --> 00:43:30.590
because I'm not very good at
chemistry, the result could be

00:43:30.590 --> 00:43:34.670
that I produce an enormous
amount of joy in those

00:43:34.670 --> 00:43:36.690
thousands of people.

00:43:36.690 --> 00:43:40.660
The effect can come about
in lots of ways.

00:43:40.660 --> 00:43:44.540
Kant says Mill would have to say
that in releasing that gas

00:43:44.540 --> 00:43:47.250
I have done something
with more worth.

00:43:47.250 --> 00:43:54.080
Kant says: No--what matters is
the description under which

00:43:54.080 --> 00:43:57.640
the act is done, and in
particular that that

00:43:57.640 --> 00:44:04.630
description be that one have
respect for the law itself.

00:44:04.630 --> 00:44:08.210
So I told you I was going to
get you to the point of the

00:44:08.210 --> 00:44:11.020
categorical imperative, and I
am going to end the lecture

00:44:11.020 --> 00:44:14.170
today by bringing you right up
to that point, and then next

00:44:14.170 --> 00:44:17.220
class we'll talk about
it in more detail.

00:44:17.220 --> 00:44:18.560
So the question is
this, right?

00:44:18.560 --> 00:44:22.520
This is a pressing, exciting
question in Kant.

00:44:22.520 --> 00:44:24.970
All right, I realize that we're
in the in-Kant part of

00:44:24.970 --> 00:44:27.235
things, but this is
really exciting.

00:44:27.235 --> 00:44:28.930
"What sort of law...?",
says Kant.

00:44:28.930 --> 00:44:31.650
He even puts a "but"
to get you excited.

00:44:31.650 --> 00:44:33.190
But, he says--cliffhanger...--

00:44:33.190 --> 00:44:37.230
"what sort of law can that be,
the thought of which must

00:44:37.230 --> 00:44:39.872
determine the will without
reference to any "intent"

00:44:39.872 --> 00:44:43.080
expected effect, so the will can
be called absolutely good

00:44:43.080 --> 00:44:44.740
without qualification?"
It's so exciting!

00:44:44.740 --> 00:44:47.310
We're finding something that's
going to make us genuinely

00:44:47.310 --> 00:44:50.650
autonomous and free and moral!

00:44:50.650 --> 00:44:53.710
Well remember: it can't be
anything particular, it can't

00:44:53.710 --> 00:44:56.990
be anything specific about the
world or it's outcomes.

00:44:56.990 --> 00:44:58.550
What can it be?

00:44:58.550 --> 00:45:04.370
It can be the will's universal
conformity of its actions to

00:45:04.370 --> 00:45:06.180
law as such!

00:45:06.180 --> 00:45:13.260
That is, what makes the law
binding is the fact that it is

00:45:13.260 --> 00:45:20.250
recognized by all rational
agents as binding.

00:45:20.250 --> 00:45:25.920
In particular, it takes the form
of what Kant calls the

00:45:25.920 --> 00:45:28.870
categorical imperative.

00:45:28.870 --> 00:45:32.750
And here's the formulation of
the categorical imperative

00:45:32.750 --> 00:45:38.590
that we got in our reading for
today: "Never act except in

00:45:38.590 --> 00:45:43.650
such a way that I can also will
that my act maxim should

00:45:43.650 --> 00:45:49.290
become a universal law." Never
do anything that you couldn't

00:45:49.290 --> 00:45:55.050
will everybody else to
do at the same time.

00:45:55.050 --> 00:45:58.780
And we'll begin next lecture
with the example that Kant

00:45:58.780 --> 00:46:02.650
uses to illustrate this, namely
the lying promise, talk

00:46:02.650 --> 00:46:05.330
a little bit more about various
formulations of the

00:46:05.330 --> 00:46:09.260
categorical imperative, and then
move to Judy Thomson's

00:46:09.260 --> 00:46:10.720
trolley problem paper.

00:46:35.525 --> 00:46:37.270
[SIDE CONVERSATION]

